diff --git a/Documentation/DocBook/Makefile b/Documentation/DocBook/Makefile
index a6eb7dcd4dd5..5fd8f5effd0c 100644
--- a/Documentation/DocBook/Makefile
+++ b/Documentation/DocBook/Makefile
@@ -1,277 +1,277 @@
 ###
 # This makefile is used to generate the kernel documentation,
 # primarily based on in-line comments in various source files.
 # See Documentation/kernel-doc-nano-HOWTO.txt for instruction in how
 # to document the SRC - and how to read it.
 # To add a new book the only step required is to add the book to the
 # list of DOCBOOKS.
 
 DOCBOOKS := z8530book.xml  \
 	    kernel-hacking.xml kernel-locking.xml deviceiobook.xml \
 	    writing_usb_driver.xml networking.xml \
 	    kernel-api.xml filesystems.xml lsm.xml kgdb.xml \
 	    gadget.xml libata.xml mtdnand.xml librs.xml rapidio.xml \
-	    genericirq.xml s390-drivers.xml uio-howto.xml scsi.xml \
+	    genericirq.xml s390-drivers.xml scsi.xml \
 	    sh.xml regulator.xml w1.xml \
 	    writing_musb_glue_layer.xml iio.xml
 
 ifeq ($(DOCBOOKS),)
 
 # Skip DocBook build if the user explicitly requested no DOCBOOKS.
 .DEFAULT:
 	@echo "  SKIP    DocBook $@ target (DOCBOOKS=\"\" specified)."
 else
 ifneq ($(SPHINXDIRS),)
 
 # Skip DocBook build if the user explicitly requested a sphinx dir
 .DEFAULT:
 	@echo "  SKIP    DocBook $@ target (SPHINXDIRS specified)."
 else
 
 
 ###
 # The build process is as follows (targets):
 #              (xmldocs) [by docproc]
 # file.tmpl --> file.xml +--> file.ps   (psdocs)   [by db2ps or xmlto]
 #                        +--> file.pdf  (pdfdocs)  [by db2pdf or xmlto]
 #                        +--> DIR=file  (htmldocs) [by xmlto]
 #                        +--> man/      (mandocs)  [by xmlto]
 
 
 # for PDF and PS output you can choose between xmlto and docbook-utils tools
 PDF_METHOD	= $(prefer-db2x)
 PS_METHOD	= $(prefer-db2x)
 
 
 targets += $(DOCBOOKS)
 BOOKS := $(addprefix $(obj)/,$(DOCBOOKS))
 xmldocs: $(BOOKS)
 sgmldocs: xmldocs
 
 PS := $(patsubst %.xml, %.ps, $(BOOKS))
 psdocs: $(PS)
 
 PDF := $(patsubst %.xml, %.pdf, $(BOOKS))
 pdfdocs: $(PDF)
 
 HTML := $(sort $(patsubst %.xml, %.html, $(BOOKS)))
 htmldocs: $(HTML)
 	$(call cmd,build_main_index)
 
 MAN := $(patsubst %.xml, %.9, $(BOOKS))
 mandocs: $(MAN)
 	find $(obj)/man -name '*.9' | xargs gzip -nf
 
 installmandocs: mandocs
 	mkdir -p /usr/local/man/man9/
 	find $(obj)/man -name '*.9.gz' -printf '%h %f\n' | \
 		sort -k 2 -k 1 | uniq -f 1 | sed -e 's: :/:' | \
 		xargs install -m 644 -t /usr/local/man/man9/
 
 # no-op for the DocBook toolchain
 epubdocs:
 latexdocs:
 
 ###
 #External programs used
 KERNELDOCXMLREF = $(srctree)/scripts/kernel-doc-xml-ref
 KERNELDOC       = $(srctree)/scripts/kernel-doc
 DOCPROC         = $(objtree)/scripts/docproc
 CHECK_LC_CTYPE = $(objtree)/scripts/check-lc_ctype
 
 # Use a fixed encoding - UTF-8 if the C library has support built-in
 # or ASCII if not
 LC_CTYPE := $(call try-run, LC_CTYPE=C.UTF-8 $(CHECK_LC_CTYPE),C.UTF-8,C)
 export LC_CTYPE
 
 XMLTOFLAGS = -m $(srctree)/$(src)/stylesheet.xsl
 XMLTOFLAGS += --skip-validation
 
 ###
 # DOCPROC is used for two purposes:
 # 1) To generate a dependency list for a .tmpl file
 # 2) To preprocess a .tmpl file and call kernel-doc with
 #     appropriate parameters.
 # The following rules are used to generate the .xml documentation
 # required to generate the final targets. (ps, pdf, html).
 quiet_cmd_docproc = DOCPROC $@
       cmd_docproc = SRCTREE=$(srctree)/ $(DOCPROC) doc $< >$@
 define rule_docproc
 	set -e;								\
         $(if $($(quiet)cmd_$(1)),echo '  $($(quiet)cmd_$(1))';) 	\
         $(cmd_$(1)); 							\
         ( 								\
           echo 'cmd_$@ := $(cmd_$(1))'; 				\
           echo $@: `SRCTREE=$(srctree) $(DOCPROC) depend $<`; 		\
         ) > $(dir $@).$(notdir $@).cmd
 endef
 
 %.xml: %.tmpl $(KERNELDOC) $(DOCPROC) $(KERNELDOCXMLREF) FORCE
 	$(call if_changed_rule,docproc)
 
 # Tell kbuild to always build the programs
 always := $(hostprogs-y)
 
 notfoundtemplate = echo "*** You have to install docbook-utils or xmlto ***"; \
 		   exit 1
 db2xtemplate = db2TYPE -o $(dir $@) $<
 xmltotemplate = xmlto TYPE $(XMLTOFLAGS) -o $(dir $@) $<
 
 # determine which methods are available
 ifeq ($(shell which db2ps >/dev/null 2>&1 && echo found),found)
 	use-db2x = db2x
 	prefer-db2x = db2x
 else
 	use-db2x = notfound
 	prefer-db2x = $(use-xmlto)
 endif
 ifeq ($(shell which xmlto >/dev/null 2>&1 && echo found),found)
 	use-xmlto = xmlto
 	prefer-xmlto = xmlto
 else
 	use-xmlto = notfound
 	prefer-xmlto = $(use-db2x)
 endif
 
 # the commands, generated from the chosen template
 quiet_cmd_db2ps = PS      $@
       cmd_db2ps = $(subst TYPE,ps, $($(PS_METHOD)template))
 %.ps : %.xml
 	$(call cmd,db2ps)
 
 quiet_cmd_db2pdf = PDF     $@
       cmd_db2pdf = $(subst TYPE,pdf, $($(PDF_METHOD)template))
 %.pdf : %.xml
 	$(call cmd,db2pdf)
 
 
 index = index.html
 main_idx = $(obj)/$(index)
 quiet_cmd_build_main_index = HTML    $(main_idx)
       cmd_build_main_index = rm -rf $(main_idx); \
 		   echo '<h1>Linux Kernel HTML Documentation</h1>' >> $(main_idx) && \
 		   echo '<h2>Kernel Version: $(KERNELVERSION)</h2>' >> $(main_idx) && \
 		   cat $(HTML) >> $(main_idx)
 
 quiet_cmd_db2html = HTML    $@
       cmd_db2html = xmlto html $(XMLTOFLAGS) -o $(patsubst %.html,%,$@) $< && \
 		echo '<a HREF="$(patsubst %.html,%,$(notdir $@))/index.html"> \
 		$(patsubst %.html,%,$(notdir $@))</a><p>' > $@
 
 ###
 # Rules to create an aux XML and .db, and use them to re-process the DocBook XML
 # to fill internal hyperlinks
        gen_aux_xml = :
  quiet_gen_aux_xml = echo '  XMLREF  $@'
 silent_gen_aux_xml = :
 %.aux.xml: %.xml
 	@$($(quiet)gen_aux_xml)
 	@rm -rf $@
 	@(cat $< | egrep "^<refentry id" | egrep -o "\".*\"" | cut -f 2 -d \" > $<.db)
 	@$(KERNELDOCXMLREF) -db $<.db $< > $@
 .PRECIOUS: %.aux.xml
 
 %.html:	%.aux.xml
 	@(which xmlto > /dev/null 2>&1) || \
 	 (echo "*** You need to install xmlto ***"; \
 	  exit 1)
 	@rm -rf $@ $(patsubst %.html,%,$@)
 	$(call cmd,db2html)
 	@if [ ! -z "$(PNG-$(basename $(notdir $@)))" ]; then \
             cp $(PNG-$(basename $(notdir $@))) $(patsubst %.html,%,$@); fi
 
 quiet_cmd_db2man = MAN     $@
       cmd_db2man = if grep -q refentry $<; then xmlto man $(XMLTOFLAGS) -o $(obj)/man/$(*F) $< ; fi
 %.9 : %.xml
 	@(which xmlto > /dev/null 2>&1) || \
 	 (echo "*** You need to install xmlto ***"; \
 	  exit 1)
 	$(Q)mkdir -p $(obj)/man/$(*F)
 	$(call cmd,db2man)
 	@touch $@
 
 ###
 # Rules to generate postscripts and PNG images from .fig format files
 quiet_cmd_fig2eps = FIG2EPS $@
       cmd_fig2eps = fig2dev -Leps $< $@
 
 %.eps: %.fig
 	@(which fig2dev > /dev/null 2>&1) || \
 	 (echo "*** You need to install transfig ***"; \
 	  exit 1)
 	$(call cmd,fig2eps)
 
 quiet_cmd_fig2png = FIG2PNG $@
       cmd_fig2png = fig2dev -Lpng $< $@
 
 %.png: %.fig
 	@(which fig2dev > /dev/null 2>&1) || \
 	 (echo "*** You need to install transfig ***"; \
 	  exit 1)
 	$(call cmd,fig2png)
 
 ###
 # Rule to convert a .c file to inline XML documentation
        gen_xml = :
  quiet_gen_xml = echo '  GEN     $@'
 silent_gen_xml = :
 %.xml: %.c
 	@$($(quiet)gen_xml)
 	@(                            \
 	   echo "<programlisting>";   \
 	   expand --tabs=8 < $< |     \
 	   sed -e "s/&/\\&amp;/g"     \
 	       -e "s/</\\&lt;/g"      \
 	       -e "s/>/\\&gt;/g";     \
 	   echo "</programlisting>")  > $@
 
 endif # DOCBOOKS=""
 endif # SPHINDIR=...
 
 ###
 # Help targets as used by the top-level makefile
 dochelp:
 	@echo  ' Linux kernel internal documentation in different formats (DocBook):'
 	@echo  '  htmldocs        - HTML'
 	@echo  '  pdfdocs         - PDF'
 	@echo  '  psdocs          - Postscript'
 	@echo  '  xmldocs         - XML DocBook'
 	@echo  '  mandocs         - man pages'
 	@echo  '  installmandocs  - install man pages generated by mandocs'
 	@echo  '  cleandocs       - clean all generated DocBook files'
 	@echo
 	@echo  '  make DOCBOOKS="s1.xml s2.xml" [target] Generate only docs s1.xml s2.xml'
 	@echo  '  valid values for DOCBOOKS are: $(DOCBOOKS)'
 	@echo
 	@echo  "  make DOCBOOKS=\"\" [target] Don't generate docs from Docbook"
 	@echo  '     This is useful to generate only the ReST docs (Sphinx)'
 
 
 ###
 # Temporary files left by various tools
 clean-files := $(DOCBOOKS) \
 	$(patsubst %.xml, %.dvi,     $(DOCBOOKS)) \
 	$(patsubst %.xml, %.aux,     $(DOCBOOKS)) \
 	$(patsubst %.xml, %.tex,     $(DOCBOOKS)) \
 	$(patsubst %.xml, %.log,     $(DOCBOOKS)) \
 	$(patsubst %.xml, %.out,     $(DOCBOOKS)) \
 	$(patsubst %.xml, %.ps,      $(DOCBOOKS)) \
 	$(patsubst %.xml, %.pdf,     $(DOCBOOKS)) \
 	$(patsubst %.xml, %.html,    $(DOCBOOKS)) \
 	$(patsubst %.xml, %.9,       $(DOCBOOKS)) \
 	$(patsubst %.xml, %.aux.xml, $(DOCBOOKS)) \
 	$(patsubst %.xml, %.xml.db,  $(DOCBOOKS)) \
 	$(patsubst %.xml, %.xml,     $(DOCBOOKS)) \
 	$(patsubst %.xml, .%.xml.cmd, $(DOCBOOKS)) \
 	$(index)
 
 clean-dirs := $(patsubst %.xml,%,$(DOCBOOKS)) man
 
 cleandocs:
 	$(Q)rm -f $(call objectify, $(clean-files))
 	$(Q)rm -rf $(call objectify, $(clean-dirs))
 
 # Declare the contents of the .PHONY variable as phony.  We keep that
 # information in a variable se we can use it in if_changed and friends.
 
 .PHONY: $(PHONY)
diff --git a/Documentation/DocBook/uio-howto.tmpl b/Documentation/DocBook/uio-howto.tmpl
deleted file mode 100644
index 5210f8a577c6..000000000000
--- a/Documentation/DocBook/uio-howto.tmpl
+++ /dev/null
@@ -1,1112 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!DOCTYPE book PUBLIC "-//OASIS//DTD DocBook XML V4.2//EN"
-"http://www.oasis-open.org/docbook/xml/4.2/docbookx.dtd" []>
-
-<book id="index">
-<bookinfo>
-<title>The Userspace I/O HOWTO</title>
-
-<author>
-      <firstname>Hans-JÃ¼rgen</firstname>
-      <surname>Koch</surname>
-      <authorblurb><para>Linux developer, Linutronix</para></authorblurb>
-	<affiliation>
-	<orgname>
-		<ulink url="http://www.linutronix.de">Linutronix</ulink>
-	</orgname>
-
-	<address>
-	   <email>hjk@hansjkoch.de</email>
-	</address>
-    </affiliation>
-</author>
-
-<copyright>
-	<year>2006-2008</year>
-	<holder>Hans-JÃ¼rgen Koch.</holder>
-</copyright>
-<copyright>
-	<year>2009</year>
-	<holder>Red Hat Inc, Michael S. Tsirkin (mst@redhat.com)</holder>
-</copyright>
-
-<legalnotice>
-<para>
-This documentation is Free Software licensed under the terms of the
-GPL version 2.
-</para>
-</legalnotice>
-
-<pubdate>2006-12-11</pubdate>
-
-<abstract>
-	<para>This HOWTO describes concept and usage of Linux kernel's
-		Userspace I/O system.</para>
-</abstract>
-
-<revhistory>
-	<revision>
-	<revnumber>0.10</revnumber>
-	<date>2016-10-17</date>
-	<authorinitials>sch</authorinitials>
-	<revremark>Added generic hyperv driver
-		</revremark>
-	</revision>
-	<revision>
-	<revnumber>0.9</revnumber>
-	<date>2009-07-16</date>
-	<authorinitials>mst</authorinitials>
-	<revremark>Added generic pci driver
-		</revremark>
-	</revision>
-	<revision>
-	<revnumber>0.8</revnumber>
-	<date>2008-12-24</date>
-	<authorinitials>hjk</authorinitials>
-	<revremark>Added name attributes in mem and portio sysfs directories.
-		</revremark>
-	</revision>
-	<revision>
-	<revnumber>0.7</revnumber>
-	<date>2008-12-23</date>
-	<authorinitials>hjk</authorinitials>
-	<revremark>Added generic platform drivers and offset attribute.</revremark>
-	</revision>
-	<revision>
-	<revnumber>0.6</revnumber>
-	<date>2008-12-05</date>
-	<authorinitials>hjk</authorinitials>
-	<revremark>Added description of portio sysfs attributes.</revremark>
-	</revision>
-	<revision>
-	<revnumber>0.5</revnumber>
-	<date>2008-05-22</date>
-	<authorinitials>hjk</authorinitials>
-	<revremark>Added description of write() function.</revremark>
-	</revision>
-	<revision>
-	<revnumber>0.4</revnumber>
-	<date>2007-11-26</date>
-	<authorinitials>hjk</authorinitials>
-	<revremark>Removed section about uio_dummy.</revremark>
-	</revision>
-	<revision>
-	<revnumber>0.3</revnumber>
-	<date>2007-04-29</date>
-	<authorinitials>hjk</authorinitials>
-	<revremark>Added section about userspace drivers.</revremark>
-	</revision>
-	<revision>
-	<revnumber>0.2</revnumber>
-	<date>2007-02-13</date>
-	<authorinitials>hjk</authorinitials>
-	<revremark>Update after multiple mappings were added.</revremark>
-	</revision>
-	<revision>
-	<revnumber>0.1</revnumber>
-	<date>2006-12-11</date>
-	<authorinitials>hjk</authorinitials>
-	<revremark>First draft.</revremark>
-	</revision>
-</revhistory>
-</bookinfo>
-
-<chapter id="aboutthisdoc">
-<?dbhtml filename="aboutthis.html"?>
-<title>About this document</title>
-
-<sect1 id="translations">
-<?dbhtml filename="translations.html"?>
-<title>Translations</title>
-
-<para>If you know of any translations for this document, or you are
-interested in translating it, please email me
-<email>hjk@hansjkoch.de</email>.
-</para>
-</sect1>
-
-<sect1 id="preface">
-<title>Preface</title>
-	<para>
-	For many types of devices, creating a Linux kernel driver is
-	overkill.  All that is really needed is some way to handle an
-	interrupt and provide access to the memory space of the
-	device.  The logic of controlling the device does not
-	necessarily have to be within the kernel, as the device does
-	not need to take advantage of any of other resources that the
-	kernel provides.  One such common class of devices that are
-	like this are for industrial I/O cards.
-	</para>
-	<para>
-	To address this situation, the userspace I/O system (UIO) was
-	designed.  For typical industrial I/O cards, only a very small
-	kernel module is needed. The main part of the driver will run in
-	user space. This simplifies development and reduces the risk of
-	serious bugs within a kernel module.
-	</para>
-	<para>
-	Please note that UIO is not an universal driver interface. Devices
-	that are already handled well by other kernel subsystems (like
-	networking or serial or USB) are no candidates for an UIO driver.
-	Hardware that is ideally suited for an UIO driver fulfills all of
-	the following:
-	</para>
-<itemizedlist>
-<listitem>
-	<para>The device has memory that can be mapped. The device can be
-	controlled completely by writing to this memory.</para>
-</listitem>
-<listitem>
-	<para>The device usually generates interrupts.</para>
-</listitem>
-<listitem>
-	<para>The device does not fit into one of the standard kernel
-	subsystems.</para>
-</listitem>
-</itemizedlist>
-</sect1>
-
-<sect1 id="thanks">
-<title>Acknowledgments</title>
-	<para>I'd like to thank Thomas Gleixner and Benedikt Spranger of
-	Linutronix, who have not only written most of the UIO code, but also
-	helped greatly writing this HOWTO by giving me all kinds of background
-	information.</para>
-</sect1>
-
-<sect1 id="feedback">
-<title>Feedback</title>
-	<para>Find something wrong with this document? (Or perhaps something
-	right?) I would love to hear from you. Please email me at
-	<email>hjk@hansjkoch.de</email>.</para>
-</sect1>
-</chapter>
-
-<chapter id="about">
-<?dbhtml filename="about.html"?>
-<title>About UIO</title>
-
-<para>If you use UIO for your card's driver, here's what you get:</para>
-
-<itemizedlist>
-<listitem>
-	<para>only one small kernel module to write and maintain.</para>
-</listitem>
-<listitem>
-	<para>develop the main part of your driver in user space,
-	with all the tools and libraries you're used to.</para>
-</listitem>
-<listitem>
-	<para>bugs in your driver won't crash the kernel.</para>
-</listitem>
-<listitem>
-	<para>updates of your driver can take place without recompiling
-	the kernel.</para>
-</listitem>
-</itemizedlist>
-
-<sect1 id="how_uio_works">
-<title>How UIO works</title>
-	<para>
-	Each UIO device is accessed through a device file and several
-	sysfs attribute files. The device file will be called
-	<filename>/dev/uio0</filename> for the first device, and
-	<filename>/dev/uio1</filename>, <filename>/dev/uio2</filename>
-	and so on for subsequent devices.
-	</para>
-
-	<para><filename>/dev/uioX</filename> is used to access the
-	address space of the card. Just use
-	<function>mmap()</function> to access registers or RAM
-	locations of your card.
-	</para>
-
-	<para>
-	Interrupts are handled by reading from
-	<filename>/dev/uioX</filename>. A blocking
-	<function>read()</function> from
-	<filename>/dev/uioX</filename> will return as soon as an
-	interrupt occurs. You can also use
-	<function>select()</function> on
-	<filename>/dev/uioX</filename> to wait for an interrupt. The
-	integer value read from <filename>/dev/uioX</filename>
-	represents the total interrupt count. You can use this number
-	to figure out if you missed some interrupts.
-	</para>
-	<para>
-	For some hardware that has more than one interrupt source internally,
-	but not separate IRQ mask and status registers, there might be
-	situations where userspace cannot determine what the interrupt source
-	was if the kernel handler disables them by writing to the chip's IRQ
-	register. In such a case, the kernel has to disable the IRQ completely
-	to leave the chip's register untouched. Now the userspace part can
-	determine the cause of the interrupt, but it cannot re-enable
-	interrupts. Another cornercase is chips where re-enabling interrupts
-	is a read-modify-write operation to a combined IRQ status/acknowledge
-	register. This would be racy if a new interrupt occurred
-	simultaneously.
-	</para>
-	<para>
-	To address these problems, UIO also implements a write() function. It
-	is normally not used and can be ignored for hardware that has only a
-	single interrupt source or has separate IRQ mask and status registers.
-	If you need it, however, a write to <filename>/dev/uioX</filename>
-	will call the <function>irqcontrol()</function> function implemented
-	by the driver. You have to write a 32-bit value that is usually either
-	0 or 1 to disable or enable interrupts. If a driver does not implement
-	<function>irqcontrol()</function>, <function>write()</function> will
-	return with <varname>-ENOSYS</varname>.
-	</para>
-
-	<para>
-	To handle interrupts properly, your custom kernel module can
-	provide its own interrupt handler. It will automatically be
-	called by the built-in handler.
-	</para>
-
-	<para>
-	For cards that don't generate interrupts but need to be
-	polled, there is the possibility to set up a timer that
-	triggers the interrupt handler at configurable time intervals.
-	This interrupt simulation is done by calling
-	<function>uio_event_notify()</function>
-	from the timer's event handler.
-	</para>
-
-	<para>
-	Each driver provides attributes that are used to read or write
-	variables. These attributes are accessible through sysfs
-	files.  A custom kernel driver module can add its own
-	attributes to the device owned by the uio driver, but not added
-	to the UIO device itself at this time.  This might change in the
-	future if it would be found to be useful.
-	</para>
-
-	<para>
-	The following standard attributes are provided by the UIO
-	framework:
-	</para>
-<itemizedlist>
-<listitem>
-	<para>
-	<filename>name</filename>: The name of your device. It is
-	recommended to use the name of your kernel module for this.
-	</para>
-</listitem>
-<listitem>
-	<para>
-	<filename>version</filename>: A version string defined by your
-	driver. This allows the user space part of your driver to deal
-	with different versions of the kernel module.
-	</para>
-</listitem>
-<listitem>
-	<para>
-	<filename>event</filename>: The total number of interrupts
-	handled by the driver since the last time the device node was
-	read.
-	</para>
-</listitem>
-</itemizedlist>
-<para>
-	These attributes appear under the
-	<filename>/sys/class/uio/uioX</filename> directory.  Please
-	note that this directory might be a symlink, and not a real
-	directory.  Any userspace code that accesses it must be able
-	to handle this.
-</para>
-<para>
-	Each UIO device can make one or more memory regions available for
-	memory mapping. This is necessary because some industrial I/O cards
-	require access to more than one PCI memory region in a driver.
-</para>
-<para>
-	Each mapping has its own directory in sysfs, the first mapping
-	appears as <filename>/sys/class/uio/uioX/maps/map0/</filename>.
-	Subsequent mappings create directories <filename>map1/</filename>,
-	<filename>map2/</filename>, and so on. These directories will only
-	appear if the size of the mapping is not 0.
-</para>
-<para>
-	Each <filename>mapX/</filename> directory contains four read-only files
-	that show attributes of the memory:
-</para>
-<itemizedlist>
-<listitem>
-	<para>
-	<filename>name</filename>: A string identifier for this mapping. This
-	is optional, the string can be empty. Drivers can set this to make it
-	easier for userspace to find the correct mapping.
-	</para>
-</listitem>
-<listitem>
-	<para>
-	<filename>addr</filename>: The address of memory that can be mapped.
-	</para>
-</listitem>
-<listitem>
-	<para>
-	<filename>size</filename>: The size, in bytes, of the memory
-	pointed to by addr.
-	</para>
-</listitem>
-<listitem>
-	<para>
-	<filename>offset</filename>: The offset, in bytes, that has to be
-	added to the pointer returned by <function>mmap()</function> to get
-	to the actual device memory. This is important if the device's memory
-	is not page aligned. Remember that pointers returned by
-	<function>mmap()</function> are always page aligned, so it is good
-	style to always add this offset.
-	</para>
-</listitem>
-</itemizedlist>
-
-<para>
-	From userspace, the different mappings are distinguished by adjusting
-	the <varname>offset</varname> parameter of the
-	<function>mmap()</function> call. To map the memory of mapping N, you
-	have to use N times the page size as your offset:
-</para>
-<programlisting format="linespecific">
-offset = N * getpagesize();
-</programlisting>
-
-<para>
-	Sometimes there is hardware with memory-like regions that can not be
-	mapped with the technique described here, but there are still ways to
-	access them from userspace. The most common example are x86 ioports.
-	On x86 systems, userspace can access these ioports using
-	<function>ioperm()</function>, <function>iopl()</function>,
-	<function>inb()</function>, <function>outb()</function>, and similar
-	functions.
-</para>
-<para>
-	Since these ioport regions can not be mapped, they will not appear under
-	<filename>/sys/class/uio/uioX/maps/</filename> like the normal memory
-	described above. Without information about the port regions a hardware
-	has to offer, it becomes difficult for the userspace part of the
-	driver to find out which ports belong to which UIO device.
-</para>
-<para>
-	To address this situation, the new directory
-	<filename>/sys/class/uio/uioX/portio/</filename> was added. It only
-	exists if the driver wants to pass information about one or more port
-	regions to userspace. If that is the case, subdirectories named
-	<filename>port0</filename>, <filename>port1</filename>, and so on,
-	will appear underneath
-	<filename>/sys/class/uio/uioX/portio/</filename>.
-</para>
-<para>
-	Each <filename>portX/</filename> directory contains four read-only
-	files that show name, start, size, and type of the port region:
-</para>
-<itemizedlist>
-<listitem>
-	<para>
-	<filename>name</filename>: A string identifier for this port region.
-	The string is optional and can be empty. Drivers can set it to make it
-	easier for userspace to find a certain port region.
-	</para>
-</listitem>
-<listitem>
-	<para>
-	<filename>start</filename>: The first port of this region.
-	</para>
-</listitem>
-<listitem>
-	<para>
-	<filename>size</filename>: The number of ports in this region.
-	</para>
-</listitem>
-<listitem>
-	<para>
-	<filename>porttype</filename>: A string describing the type of port.
-	</para>
-</listitem>
-</itemizedlist>
-
-
-</sect1>
-</chapter>
-
-<chapter id="custom_kernel_module" xreflabel="Writing your own kernel module">
-<?dbhtml filename="custom_kernel_module.html"?>
-<title>Writing your own kernel module</title>
-	<para>
-	Please have a look at <filename>uio_cif.c</filename> as an
-	example. The following paragraphs explain the different
-	sections of this file.
-	</para>
-
-<sect1 id="uio_info">
-<title>struct uio_info</title>
-	<para>
-	This structure tells the framework the details of your driver,
-	Some of the members are required, others are optional.
-	</para>
-
-<itemizedlist>
-<listitem><para>
-<varname>const char *name</varname>: Required. The name of your driver as
-it will appear in sysfs. I recommend using the name of your module for this.
-</para></listitem>
-
-<listitem><para>
-<varname>const char *version</varname>: Required. This string appears in
-<filename>/sys/class/uio/uioX/version</filename>.
-</para></listitem>
-
-<listitem><para>
-<varname>struct uio_mem mem[ MAX_UIO_MAPS ]</varname>: Required if you
-have memory that can be mapped with <function>mmap()</function>. For each
-mapping you need to fill one of the <varname>uio_mem</varname> structures.
-See the description below for details.
-</para></listitem>
-
-<listitem><para>
-<varname>struct uio_port port[ MAX_UIO_PORTS_REGIONS ]</varname>: Required
-if you want to pass information about ioports to userspace. For each port
-region you need to fill one of the <varname>uio_port</varname> structures.
-See the description below for details.
-</para></listitem>
-
-<listitem><para>
-<varname>long irq</varname>: Required. If your hardware generates an
-interrupt, it's your modules task to determine the irq number during
-initialization. If you don't have a hardware generated interrupt but
-want to trigger the interrupt handler in some other way, set
-<varname>irq</varname> to <varname>UIO_IRQ_CUSTOM</varname>.
-If you had no interrupt at all, you could set
-<varname>irq</varname> to <varname>UIO_IRQ_NONE</varname>, though this
-rarely makes sense.
-</para></listitem>
-
-<listitem><para>
-<varname>unsigned long irq_flags</varname>: Required if you've set
-<varname>irq</varname> to a hardware interrupt number. The flags given
-here will be used in the call to <function>request_irq()</function>.
-</para></listitem>
-
-<listitem><para>
-<varname>int (*mmap)(struct uio_info *info, struct vm_area_struct
-*vma)</varname>: Optional. If you need a special
-<function>mmap()</function> function, you can set it here. If this
-pointer is not NULL, your <function>mmap()</function> will be called
-instead of the built-in one.
-</para></listitem>
-
-<listitem><para>
-<varname>int (*open)(struct uio_info *info, struct inode *inode)
-</varname>: Optional. You might want to have your own
-<function>open()</function>, e.g. to enable interrupts only when your
-device is actually used.
-</para></listitem>
-
-<listitem><para>
-<varname>int (*release)(struct uio_info *info, struct inode *inode)
-</varname>: Optional. If you define your own
-<function>open()</function>, you will probably also want a custom
-<function>release()</function> function.
-</para></listitem>
-
-<listitem><para>
-<varname>int (*irqcontrol)(struct uio_info *info, s32 irq_on)
-</varname>: Optional. If you need to be able to enable or disable
-interrupts from userspace by writing to <filename>/dev/uioX</filename>,
-you can implement this function. The parameter <varname>irq_on</varname>
-will be 0 to disable interrupts and 1 to enable them.
-</para></listitem>
-</itemizedlist>
-
-<para>
-Usually, your device will have one or more memory regions that can be mapped
-to user space. For each region, you have to set up a
-<varname>struct uio_mem</varname> in the <varname>mem[]</varname> array.
-Here's a description of the fields of <varname>struct uio_mem</varname>:
-</para>
-
-<itemizedlist>
-<listitem><para>
-<varname>const char *name</varname>: Optional. Set this to help identify
-the memory region, it will show up in the corresponding sysfs node.
-</para></listitem>
-
-<listitem><para>
-<varname>int memtype</varname>: Required if the mapping is used. Set this to
-<varname>UIO_MEM_PHYS</varname> if you you have physical memory on your
-card to be mapped. Use <varname>UIO_MEM_LOGICAL</varname> for logical
-memory (e.g. allocated with <function>kmalloc()</function>). There's also
-<varname>UIO_MEM_VIRTUAL</varname> for virtual memory.
-</para></listitem>
-
-<listitem><para>
-<varname>phys_addr_t addr</varname>: Required if the mapping is used.
-Fill in the address of your memory block. This address is the one that
-appears in sysfs.
-</para></listitem>
-
-<listitem><para>
-<varname>resource_size_t size</varname>: Fill in the size of the
-memory block that <varname>addr</varname> points to. If <varname>size</varname>
-is zero, the mapping is considered unused. Note that you
-<emphasis>must</emphasis> initialize <varname>size</varname> with zero for
-all unused mappings.
-</para></listitem>
-
-<listitem><para>
-<varname>void *internal_addr</varname>: If you have to access this memory
-region from within your kernel module, you will want to map it internally by
-using something like <function>ioremap()</function>. Addresses
-returned by this function cannot be mapped to user space, so you must not
-store it in <varname>addr</varname>. Use <varname>internal_addr</varname>
-instead to remember such an address.
-</para></listitem>
-</itemizedlist>
-
-<para>
-Please do not touch the <varname>map</varname> element of
-<varname>struct uio_mem</varname>! It is used by the UIO framework
-to set up sysfs files for this mapping. Simply leave it alone.
-</para>
-
-<para>
-Sometimes, your device can have one or more port regions which can not be
-mapped to userspace. But if there are other possibilities for userspace to
-access these ports, it makes sense to make information about the ports
-available in sysfs. For each region, you have to set up a
-<varname>struct uio_port</varname> in the <varname>port[]</varname> array.
-Here's a description of the fields of <varname>struct uio_port</varname>:
-</para>
-
-<itemizedlist>
-<listitem><para>
-<varname>char *porttype</varname>: Required. Set this to one of the predefined
-constants. Use <varname>UIO_PORT_X86</varname> for the ioports found in x86
-architectures.
-</para></listitem>
-
-<listitem><para>
-<varname>unsigned long start</varname>: Required if the port region is used.
-Fill in the number of the first port of this region.
-</para></listitem>
-
-<listitem><para>
-<varname>unsigned long size</varname>: Fill in the number of ports in this
-region. If <varname>size</varname> is zero, the region is considered unused.
-Note that you <emphasis>must</emphasis> initialize <varname>size</varname>
-with zero for all unused regions.
-</para></listitem>
-</itemizedlist>
-
-<para>
-Please do not touch the <varname>portio</varname> element of
-<varname>struct uio_port</varname>! It is used internally by the UIO
-framework to set up sysfs files for this region. Simply leave it alone.
-</para>
-
-</sect1>
-
-<sect1 id="adding_irq_handler">
-<title>Adding an interrupt handler</title>
-	<para>
-	What you need to do in your interrupt handler depends on your
-	hardware and on how you want to	handle it. You should try to
-	keep the amount of code in your kernel interrupt handler low.
-	If your hardware requires no action that you
-	<emphasis>have</emphasis> to perform after each interrupt,
-	then your handler can be empty.</para> <para>If, on the other
-	hand, your hardware <emphasis>needs</emphasis> some action to
-	be performed after each interrupt, then you
-	<emphasis>must</emphasis> do it in your kernel module. Note
-	that you cannot rely on the userspace part of your driver. Your
-	userspace program can terminate at any time, possibly leaving
-	your hardware in a state where proper interrupt handling is
-	still required.
-	</para>
-
-	<para>
-	There might also be applications where you want to read data
-	from your hardware at each interrupt and buffer it in a piece
-	of kernel memory you've allocated for that purpose.  With this
-	technique you could avoid loss of data if your userspace
-	program misses an interrupt.
-	</para>
-
-	<para>
-	A note on shared interrupts: Your driver should support
-	interrupt sharing whenever this is possible. It is possible if
-	and only if your driver can detect whether your hardware has
-	triggered the interrupt or not. This is usually done by looking
-	at an interrupt status register. If your driver sees that the
-	IRQ bit is actually set, it will perform its actions, and the
-	handler returns IRQ_HANDLED. If the driver detects that it was
-	not your hardware that caused the interrupt, it will do nothing
-	and return IRQ_NONE, allowing the kernel to call the next
-	possible interrupt handler.
-	</para>
-
-	<para>
-	If you decide not to support shared interrupts, your card
-	won't work in computers with no free interrupts. As this
-	frequently happens on the PC platform, you can save yourself a
-	lot of trouble by supporting interrupt sharing.
-	</para>
-</sect1>
-
-<sect1 id="using_uio_pdrv">
-<title>Using uio_pdrv for platform devices</title>
-	<para>
-	In many cases, UIO drivers for platform devices can be handled in a
-	generic way. In the same place where you define your
-	<varname>struct platform_device</varname>, you simply also implement
-	your interrupt handler and fill your
-	<varname>struct uio_info</varname>. A pointer to this
-	<varname>struct uio_info</varname> is then used as
-	<varname>platform_data</varname> for your platform device.
-	</para>
-	<para>
-	You also need to set up an array of <varname>struct resource</varname>
-	containing addresses and sizes of your memory mappings. This
-	information is passed to the driver using the
-	<varname>.resource</varname> and <varname>.num_resources</varname>
-	elements of <varname>struct platform_device</varname>.
-	</para>
-	<para>
-	You now have to set the <varname>.name</varname> element of
-	<varname>struct platform_device</varname> to
-	<varname>"uio_pdrv"</varname> to use the generic UIO platform device
-	driver. This driver will fill the <varname>mem[]</varname> array
-	according to the resources given, and register the device.
-	</para>
-	<para>
-	The advantage of this approach is that you only have to edit a file
-	you need to edit anyway. You do not have to create an extra driver.
-	</para>
-</sect1>
-
-<sect1 id="using_uio_pdrv_genirq">
-<title>Using uio_pdrv_genirq for platform devices</title>
-	<para>
-	Especially in embedded devices, you frequently find chips where the
-	irq pin is tied to its own dedicated interrupt line. In such cases,
-	where you can be really sure the interrupt is not shared, we can take
-	the concept of <varname>uio_pdrv</varname> one step further and use a
-	generic interrupt handler. That's what
-	<varname>uio_pdrv_genirq</varname> does.
-	</para>
-	<para>
-	The setup for this driver is the same as described above for
-	<varname>uio_pdrv</varname>, except that you do not implement an
-	interrupt handler. The <varname>.handler</varname> element of
-	<varname>struct uio_info</varname> must remain
-	<varname>NULL</varname>. The  <varname>.irq_flags</varname> element
-	must not contain <varname>IRQF_SHARED</varname>.
-	</para>
-	<para>
-	You will set the <varname>.name</varname> element of
-	<varname>struct platform_device</varname> to
-	<varname>"uio_pdrv_genirq"</varname> to use this driver.
-	</para>
-	<para>
-	The generic interrupt handler of <varname>uio_pdrv_genirq</varname>
-	will simply disable the interrupt line using
-	<function>disable_irq_nosync()</function>. After doing its work,
-	userspace can reenable the interrupt by writing 0x00000001 to the UIO
-	device file. The driver already implements an
-	<function>irq_control()</function> to make this possible, you must not
-	implement your own.
-	</para>
-	<para>
-	Using <varname>uio_pdrv_genirq</varname> not only saves a few lines of
-	interrupt handler code. You also do not need to know anything about
-	the chip's internal registers to create the kernel part of the driver.
-	All you need to know is the irq number of the pin the chip is
-	connected to.
-	</para>
-</sect1>
-
-<sect1 id="using-uio_dmem_genirq">
-<title>Using uio_dmem_genirq for platform devices</title>
-	<para>
-	In addition to statically allocated memory ranges, they may also be
-	a desire to use dynamically allocated regions in a user space driver.
-	In particular, being able to access memory made available through the
-	dma-mapping API, may be particularly useful.  The
-	<varname>uio_dmem_genirq</varname> driver provides a way to accomplish
-	this.
-	</para>
-	<para>
-	This driver is used in a similar manner to the
-	<varname>"uio_pdrv_genirq"</varname> driver with respect to interrupt
-	configuration and handling.
-	</para>
-	<para>
-	Set the <varname>.name</varname> element of
-	<varname>struct platform_device</varname> to
-	<varname>"uio_dmem_genirq"</varname> to use this driver.
-	</para>
-	<para>
-	When using this driver, fill in the <varname>.platform_data</varname>
-	element of <varname>struct platform_device</varname>, which is of type
-	<varname>struct uio_dmem_genirq_pdata</varname> and which contains the
-	following elements:
-	</para>
-	<itemizedlist>
-	<listitem><para><varname>struct uio_info uioinfo</varname>: The same
-	structure used as the  <varname>uio_pdrv_genirq</varname> platform
-	data</para></listitem>
-	<listitem><para><varname>unsigned int *dynamic_region_sizes</varname>:
-	Pointer to list of sizes of dynamic memory regions to be mapped into
-	user space.
-	</para></listitem>
-	<listitem><para><varname>unsigned int num_dynamic_regions</varname>:
-	Number of elements in <varname>dynamic_region_sizes</varname> array.
-	</para></listitem>
-	</itemizedlist>
-	<para>
-	The dynamic regions defined in the platform data will be appended to
-	the <varname> mem[] </varname> array after the platform device
-	resources, which implies that the total number of static and dynamic
-	memory regions cannot exceed <varname>MAX_UIO_MAPS</varname>.
-	</para>
-	<para>
-	The dynamic memory regions will be allocated when the UIO device file,
-	<varname>/dev/uioX</varname> is opened.
-	Similar to static memory resources, the memory region information for
-	dynamic regions is then visible via sysfs at
-	<varname>/sys/class/uio/uioX/maps/mapY/*</varname>.
-	The dynamic memory regions will be freed when the UIO device file is
-	closed. When no processes are holding the device file open, the address
-	returned to userspace is ~0.
-	</para>
-</sect1>
-
-</chapter>
-
-<chapter id="userspace_driver" xreflabel="Writing a driver in user space">
-<?dbhtml filename="userspace_driver.html"?>
-<title>Writing a driver in userspace</title>
-	<para>
-	Once you have a working kernel module for your hardware, you can
-	write the userspace part of your driver. You don't need any special
-	libraries, your driver can be written in any reasonable language,
-	you can use floating point numbers and so on. In short, you can
-	use all the tools and libraries you'd normally use for writing a
-	userspace application.
-	</para>
-
-<sect1 id="getting_uio_information">
-<title>Getting information about your UIO device</title>
-	<para>
-	Information about all UIO devices is available in sysfs. The
-	first thing you should do in your driver is check
-	<varname>name</varname> and <varname>version</varname> to
-	make sure your talking to the right device and that its kernel
-	driver has the version you expect.
-	</para>
-	<para>
-	You should also make sure that the memory mapping you need
-	exists and has the size you expect.
-	</para>
-	<para>
-	There is a tool called <varname>lsuio</varname> that lists
-	UIO devices and their attributes. It is available here:
-	</para>
-	<para>
-	<ulink url="http://www.osadl.org/projects/downloads/UIO/user/">
-		http://www.osadl.org/projects/downloads/UIO/user/</ulink>
-	</para>
-	<para>
-	With <varname>lsuio</varname> you can quickly check if your
-	kernel module is loaded and which attributes it exports.
-	Have a look at the manpage for details.
-	</para>
-	<para>
-	The source code of <varname>lsuio</varname> can serve as an
-	example for getting information about an UIO device.
-	The file <filename>uio_helper.c</filename> contains a lot of
-	functions you could use in your userspace driver code.
-	</para>
-</sect1>
-
-<sect1 id="mmap_device_memory">
-<title>mmap() device memory</title>
-	<para>
-	After you made sure you've got the right device with the
-	memory mappings you need, all you have to do is to call
-	<function>mmap()</function> to map the device's memory
-	to userspace.
-	</para>
-	<para>
-	The parameter <varname>offset</varname> of the
-	<function>mmap()</function> call has a special meaning
-	for UIO devices: It is used to select which mapping of
-	your device you want to map. To map the memory of
-	mapping N, you have to use N times the page size as
-	your offset:
-	</para>
-<programlisting format="linespecific">
-	offset = N * getpagesize();
-</programlisting>
-	<para>
-	N starts from zero, so if you've got only one memory
-	range to map, set <varname>offset = 0</varname>.
-	A drawback of this technique is that memory is always
-	mapped beginning with its start address.
-	</para>
-</sect1>
-
-<sect1 id="wait_for_interrupts">
-<title>Waiting for interrupts</title>
-	<para>
-	After you successfully mapped your devices memory, you
-	can access it like an ordinary array. Usually, you will
-	perform some initialization. After that, your hardware
-	starts working and will generate an interrupt as soon
-	as it's finished, has some data available, or needs your
-	attention because an error occurred.
-	</para>
-	<para>
-	<filename>/dev/uioX</filename> is a read-only file. A
-	<function>read()</function> will always block until an
-	interrupt occurs. There is only one legal value for the
-	<varname>count</varname> parameter of
-	<function>read()</function>, and that is the size of a
-	signed 32 bit integer (4). Any other value for
-	<varname>count</varname> causes <function>read()</function>
-	to fail. The signed 32 bit integer read is the interrupt
-	count of your device. If the value is one more than the value
-	you read the last time, everything is OK. If the difference
-	is greater than one, you missed interrupts.
-	</para>
-	<para>
-	You can also use <function>select()</function> on
-	<filename>/dev/uioX</filename>.
-	</para>
-</sect1>
-
-</chapter>
-
-<chapter id="uio_pci_generic" xreflabel="Using Generic driver for PCI cards">
-<?dbhtml filename="uio_pci_generic.html"?>
-<title>Generic PCI UIO driver</title>
-	<para>
-	The generic driver is a kernel module named uio_pci_generic.
-	It can work with any device compliant to PCI 2.3 (circa 2002) and
-	any compliant PCI Express device. Using this, you only need to
-        write the userspace driver, removing the need to write
-        a hardware-specific kernel module.
-	</para>
-
-<sect1 id="uio_pci_generic_binding">
-<title>Making the driver recognize the device</title>
-	<para>
-Since the driver does not declare any device ids, it will not get loaded
-automatically and will not automatically bind to any devices, you must load it
-and allocate id to the driver yourself. For example:
-	<programlisting>
- modprobe uio_pci_generic
- echo &quot;8086 10f5&quot; &gt; /sys/bus/pci/drivers/uio_pci_generic/new_id
-	</programlisting>
-	</para>
-	<para>
-If there already is a hardware specific kernel driver for your device, the
-generic driver still won't bind to it, in this case if you want to use the
-generic driver (why would you?) you'll have to manually unbind the hardware
-specific driver and bind the generic driver, like this:
-	<programlisting>
-    echo -n 0000:00:19.0 &gt; /sys/bus/pci/drivers/e1000e/unbind
-    echo -n 0000:00:19.0 &gt; /sys/bus/pci/drivers/uio_pci_generic/bind
-	</programlisting>
-	</para>
-	<para>
-You can verify that the device has been bound to the driver
-by looking for it in sysfs, for example like the following:
-	<programlisting>
-    ls -l /sys/bus/pci/devices/0000:00:19.0/driver
-	</programlisting>
-Which if successful should print
-	<programlisting>
-  .../0000:00:19.0/driver -&gt; ../../../bus/pci/drivers/uio_pci_generic
-	</programlisting>
-Note that the generic driver will not bind to old PCI 2.2 devices.
-If binding the device failed, run the following command:
-	<programlisting>
-  dmesg
-	</programlisting>
-and look in the output for failure reasons
-	</para>
-</sect1>
-
-<sect1 id="uio_pci_generic_internals">
-<title>Things to know about uio_pci_generic</title>
-	<para>
-Interrupts are handled using the Interrupt Disable bit in the PCI command
-register and Interrupt Status bit in the PCI status register.  All devices
-compliant to PCI 2.3 (circa 2002) and all compliant PCI Express devices should
-support these bits.  uio_pci_generic detects this support, and won't bind to
-devices which do not support the Interrupt Disable Bit in the command register.
-	</para>
-	<para>
-On each interrupt, uio_pci_generic sets the Interrupt Disable bit.
-This prevents the device from generating further interrupts
-until the bit is cleared. The userspace driver should clear this
-bit before blocking and waiting for more interrupts.
-	</para>
-</sect1>
-<sect1 id="uio_pci_generic_userspace">
-<title>Writing userspace driver using uio_pci_generic</title>
-	<para>
-Userspace driver can use pci sysfs interface, or the
-libpci libray that wraps it, to talk to the device and to
-re-enable interrupts by writing to the command register.
-	</para>
-</sect1>
-<sect1 id="uio_pci_generic_example">
-<title>Example code using uio_pci_generic</title>
-	<para>
-Here is some sample userspace driver code using uio_pci_generic:
-<programlisting>
-#include &lt;stdlib.h&gt;
-#include &lt;stdio.h&gt;
-#include &lt;unistd.h&gt;
-#include &lt;sys/types.h&gt;
-#include &lt;sys/stat.h&gt;
-#include &lt;fcntl.h&gt;
-#include &lt;errno.h&gt;
-
-int main()
-{
-	int uiofd;
-	int configfd;
-	int err;
-	int i;
-	unsigned icount;
-	unsigned char command_high;
-
-	uiofd = open(&quot;/dev/uio0&quot;, O_RDONLY);
-	if (uiofd &lt; 0) {
-		perror(&quot;uio open:&quot;);
-		return errno;
-	}
-	configfd = open(&quot;/sys/class/uio/uio0/device/config&quot;, O_RDWR);
-	if (configfd &lt; 0) {
-		perror(&quot;config open:&quot;);
-		return errno;
-	}
-
-	/* Read and cache command value */
-	err = pread(configfd, &amp;command_high, 1, 5);
-	if (err != 1) {
-		perror(&quot;command config read:&quot;);
-		return errno;
-	}
-	command_high &amp;= ~0x4;
-
-	for(i = 0;; ++i) {
-		/* Print out a message, for debugging. */
-		if (i == 0)
-			fprintf(stderr, &quot;Started uio test driver.\n&quot;);
-		else
-			fprintf(stderr, &quot;Interrupts: %d\n&quot;, icount);
-
-		/****************************************/
-		/* Here we got an interrupt from the
-		   device. Do something to it. */
-		/****************************************/
-
-		/* Re-enable interrupts. */
-		err = pwrite(configfd, &amp;command_high, 1, 5);
-		if (err != 1) {
-			perror(&quot;config write:&quot;);
-			break;
-		}
-
-		/* Wait for next interrupt. */
-		err = read(uiofd, &amp;icount, 4);
-		if (err != 4) {
-			perror(&quot;uio read:&quot;);
-			break;
-		}
-
-	}
-	return errno;
-}
-
-</programlisting>
-	</para>
-</sect1>
-
-</chapter>
-
-<chapter id="uio_hv_generic" xreflabel="Using Generic driver for Hyper-V VMBUS">
-<?dbhtml filename="uio_hv_generic.html"?>
-<title>Generic Hyper-V UIO driver</title>
-	<para>
-	The generic driver is a kernel module named uio_hv_generic.
-	It supports devices on the Hyper-V VMBus similar to uio_pci_generic
-	on PCI bus.
-	</para>
-
-<sect1 id="uio_hv_generic_binding">
-<title>Making the driver recognize the device</title>
-	<para>
-Since the driver does not declare any device GUID's, it will not get loaded
-automatically and will not automatically bind to any devices, you must load it
-and allocate id to the driver yourself. For example, to use the network device
-GUID:
-	<programlisting>
- modprobe uio_hv_generic
- echo &quot;f8615163-df3e-46c5-913f-f2d2f965ed0e&quot; &gt; /sys/bus/vmbus/drivers/uio_hv_generic/new_id
-	</programlisting>
-	</para>
-	<para>
-If there already is a hardware specific kernel driver for the device, the
-generic driver still won't bind to it, in this case if you want to use the
-generic driver (why would you?) you'll have to manually unbind the hardware
-specific driver and bind the generic driver, like this:
-	<programlisting>
-	  echo -n vmbus-ed963694-e847-4b2a-85af-bc9cfc11d6f3 &gt; /sys/bus/vmbus/drivers/hv_netvsc/unbind
-	  echo -n vmbus-ed963694-e847-4b2a-85af-bc9cfc11d6f3 &gt; /sys/bus/vmbus/drivers/uio_hv_generic/bind
-	</programlisting>
-	</para>
-	<para>
-You can verify that the device has been bound to the driver
-by looking for it in sysfs, for example like the following:
-	<programlisting>
-    ls -l /sys/bus/vmbus/devices/vmbus-ed963694-e847-4b2a-85af-bc9cfc11d6f3/driver
-	</programlisting>
-Which if successful should print
-	<programlisting>
-  .../vmbus-ed963694-e847-4b2a-85af-bc9cfc11d6f3/driver -&gt; ../../../bus/vmbus/drivers/uio_hv_generic
-	</programlisting>
-	</para>
-</sect1>
-
-<sect1 id="uio_hv_generic_internals">
-<title>Things to know about uio_hv_generic</title>
-	<para>
-On each interrupt, uio_hv_generic sets the Interrupt Disable bit.
-This prevents the device from generating further interrupts
-until the bit is cleared. The userspace driver should clear this
-bit before blocking and waiting for more interrupts.
-	</para>
-</sect1>
-</chapter>
-
-<appendix id="app1">
-<title>Further information</title>
-<itemizedlist>
-	<listitem><para>
-			<ulink url="http://www.osadl.org">
-				OSADL homepage.</ulink>
-		</para></listitem>
-	<listitem><para>
-		<ulink url="http://www.linutronix.de">
-		 Linutronix homepage.</ulink>
-		</para></listitem>
-</itemizedlist>
-</appendix>
-
-</book>
diff --git a/Documentation/admin-guide/kernel-parameters.txt b/Documentation/admin-guide/kernel-parameters.txt
index f2e745844d5b..608ba95d9461 100644
--- a/Documentation/admin-guide/kernel-parameters.txt
+++ b/Documentation/admin-guide/kernel-parameters.txt
@@ -1,4395 +1,4399 @@
 	acpi=		[HW,ACPI,X86,ARM64]
 			Advanced Configuration and Power Interface
 			Format: { force | on | off | strict | noirq | rsdt |
 				  copy_dsdt }
 			force -- enable ACPI if default was off
 			on -- enable ACPI but allow fallback to DT [arm64]
 			off -- disable ACPI if default was on
 			noirq -- do not use ACPI for IRQ routing
 			strict -- Be less tolerant of platforms that are not
 				strictly ACPI specification compliant.
 			rsdt -- prefer RSDT over (default) XSDT
 			copy_dsdt -- copy DSDT to memory
 			For ARM64, ONLY "acpi=off", "acpi=on" or "acpi=force"
 			are available
 
 			See also Documentation/power/runtime_pm.txt, pci=noacpi
 
 	acpi_apic_instance=	[ACPI, IOAPIC]
 			Format: <int>
 			2: use 2nd APIC table, if available
 			1,0: use 1st APIC table
 			default: 0
 
 	acpi_backlight=	[HW,ACPI]
 			acpi_backlight=vendor
 			acpi_backlight=video
 			If set to vendor, prefer vendor specific driver
 			(e.g. thinkpad_acpi, sony_acpi, etc.) instead
 			of the ACPI video.ko driver.
 
 	acpi_force_32bit_fadt_addr
 			force FADT to use 32 bit addresses rather than the
 			64 bit X_* addresses. Some firmware have broken 64
 			bit addresses for force ACPI ignore these and use
 			the older legacy 32 bit addresses.
 
 	acpica_no_return_repair [HW, ACPI]
 			Disable AML predefined validation mechanism
 			This mechanism can repair the evaluation result to make
 			the return objects more ACPI specification compliant.
 			This option is useful for developers to identify the
 			root cause of an AML interpreter issue when the issue
 			has something to do with the repair mechanism.
 
 	acpi.debug_layer=	[HW,ACPI,ACPI_DEBUG]
 	acpi.debug_level=	[HW,ACPI,ACPI_DEBUG]
 			Format: <int>
 			CONFIG_ACPI_DEBUG must be enabled to produce any ACPI
 			debug output.  Bits in debug_layer correspond to a
 			_COMPONENT in an ACPI source file, e.g.,
 			    #define _COMPONENT ACPI_PCI_COMPONENT
 			Bits in debug_level correspond to a level in
 			ACPI_DEBUG_PRINT statements, e.g.,
 			    ACPI_DEBUG_PRINT((ACPI_DB_INFO, ...
 			The debug_level mask defaults to "info".  See
 			Documentation/acpi/debug.txt for more information about
 			debug layers and levels.
 
 			Enable processor driver info messages:
 			    acpi.debug_layer=0x20000000
 			Enable PCI/PCI interrupt routing info messages:
 			    acpi.debug_layer=0x400000
 			Enable AML "Debug" output, i.e., stores to the Debug
 			object while interpreting AML:
 			    acpi.debug_layer=0xffffffff acpi.debug_level=0x2
 			Enable all messages related to ACPI hardware:
 			    acpi.debug_layer=0x2 acpi.debug_level=0xffffffff
 
 			Some values produce so much output that the system is
 			unusable.  The "log_buf_len" parameter may be useful
 			if you need to capture more output.
 
 	acpi_enforce_resources=	[ACPI]
 			{ strict | lax | no }
 			Check for resource conflicts between native drivers
 			and ACPI OperationRegions (SystemIO and SystemMemory
 			only). IO ports and memory declared in ACPI might be
 			used by the ACPI subsystem in arbitrary AML code and
 			can interfere with legacy drivers.
 			strict (default): access to resources claimed by ACPI
 			is denied; legacy drivers trying to access reserved
 			resources will fail to bind to device using them.
 			lax: access to resources claimed by ACPI is allowed;
 			legacy drivers trying to access reserved resources
 			will bind successfully but a warning message is logged.
 			no: ACPI OperationRegions are not marked as reserved,
 			no further checks are performed.
 
 	acpi_force_table_verification	[HW,ACPI]
 			Enable table checksum verification during early stage.
 			By default, this is disabled due to x86 early mapping
 			size limitation.
 
 	acpi_irq_balance [HW,ACPI]
 			ACPI will balance active IRQs
 			default in APIC mode
 
 	acpi_irq_nobalance [HW,ACPI]
 			ACPI will not move active IRQs (default)
 			default in PIC mode
 
 	acpi_irq_isa=	[HW,ACPI] If irq_balance, mark listed IRQs used by ISA
 			Format: <irq>,<irq>...
 
 	acpi_irq_pci=	[HW,ACPI] If irq_balance, clear listed IRQs for
 			use by PCI
 			Format: <irq>,<irq>...
 
 	acpi_mask_gpe=  [HW,ACPI]
 			Due to the existence of _Lxx/_Exx, some GPEs triggered
 			by unsupported hardware/firmware features can result in
                         GPE floodings that cannot be automatically disabled by
                         the GPE dispatcher.
 			This facility can be used to prevent such uncontrolled
 			GPE floodings.
 			Format: <int>
 			Support masking of GPEs numbered from 0x00 to 0x7f.
 
 	acpi_no_auto_serialize	[HW,ACPI]
 			Disable auto-serialization of AML methods
 			AML control methods that contain the opcodes to create
 			named objects will be marked as "Serialized" by the
 			auto-serialization feature.
 			This feature is enabled by default.
 			This option allows to turn off the feature.
 
 	acpi_no_memhotplug [ACPI] Disable memory hotplug.  Useful for kdump
 			   kernels.
 
 	acpi_no_static_ssdt	[HW,ACPI]
 			Disable installation of static SSDTs at early boot time
 			By default, SSDTs contained in the RSDT/XSDT will be
 			installed automatically and they will appear under
 			/sys/firmware/acpi/tables.
 			This option turns off this feature.
 			Note that specifying this option does not affect
 			dynamic table installation which will install SSDT
 			tables to /sys/firmware/acpi/tables/dynamic.
 
 	acpi_rsdp=	[ACPI,EFI,KEXEC]
 			Pass the RSDP address to the kernel, mostly used
 			on machines running EFI runtime service to boot the
 			second kernel for kdump.
 
 	acpi_os_name=	[HW,ACPI] Tell ACPI BIOS the name of the OS
 			Format: To spoof as Windows 98: ="Microsoft Windows"
 
 	acpi_rev_override [ACPI] Override the _REV object to return 5 (instead
 			of 2 which is mandated by ACPI 6) as the supported ACPI
 			specification revision (when using this switch, it may
 			be necessary to carry out a cold reboot _twice_ in a
 			row to make it take effect on the platform firmware).
 
 	acpi_osi=	[HW,ACPI] Modify list of supported OS interface strings
 			acpi_osi="string1"	# add string1
 			acpi_osi="!string2"	# remove string2
 			acpi_osi=!*		# remove all strings
 			acpi_osi=!		# disable all built-in OS vendor
 						  strings
 			acpi_osi=!!		# enable all built-in OS vendor
 						  strings
 			acpi_osi=		# disable all strings
 
 			'acpi_osi=!' can be used in combination with single or
 			multiple 'acpi_osi="string1"' to support specific OS
 			vendor string(s).  Note that such command can only
 			affect the default state of the OS vendor strings, thus
 			it cannot affect the default state of the feature group
 			strings and the current state of the OS vendor strings,
 			specifying it multiple times through kernel command line
 			is meaningless.  This command is useful when one do not
 			care about the state of the feature group strings which
 			should be controlled by the OSPM.
 			Examples:
 			  1. 'acpi_osi=! acpi_osi="Windows 2000"' is equivalent
 			     to 'acpi_osi="Windows 2000" acpi_osi=!', they all
 			     can make '_OSI("Windows 2000")' TRUE.
 
 			'acpi_osi=' cannot be used in combination with other
 			'acpi_osi=' command lines, the _OSI method will not
 			exist in the ACPI namespace.  NOTE that such command can
 			only affect the _OSI support state, thus specifying it
 			multiple times through kernel command line is also
 			meaningless.
 			Examples:
 			  1. 'acpi_osi=' can make 'CondRefOf(_OSI, Local1)'
 			     FALSE.
 
 			'acpi_osi=!*' can be used in combination with single or
 			multiple 'acpi_osi="string1"' to support specific
 			string(s).  Note that such command can affect the
 			current state of both the OS vendor strings and the
 			feature group strings, thus specifying it multiple times
 			through kernel command line is meaningful.  But it may
 			still not able to affect the final state of a string if
 			there are quirks related to this string.  This command
 			is useful when one want to control the state of the
 			feature group strings to debug BIOS issues related to
 			the OSPM features.
 			Examples:
 			  1. 'acpi_osi="Module Device" acpi_osi=!*' can make
 			     '_OSI("Module Device")' FALSE.
 			  2. 'acpi_osi=!* acpi_osi="Module Device"' can make
 			     '_OSI("Module Device")' TRUE.
 			  3. 'acpi_osi=! acpi_osi=!* acpi_osi="Windows 2000"' is
 			     equivalent to
 			     'acpi_osi=!* acpi_osi=! acpi_osi="Windows 2000"'
 			     and
 			     'acpi_osi=!* acpi_osi="Windows 2000" acpi_osi=!',
 			     they all will make '_OSI("Windows 2000")' TRUE.
 
 	acpi_pm_good	[X86]
 			Override the pmtimer bug detection: force the kernel
 			to assume that this machine's pmtimer latches its value
 			and always returns good values.
 
 	acpi_sci=	[HW,ACPI] ACPI System Control Interrupt trigger mode
 			Format: { level | edge | high | low }
 
 	acpi_skip_timer_override [HW,ACPI]
 			Recognize and ignore IRQ0/pin2 Interrupt Override.
 			For broken nForce2 BIOS resulting in XT-PIC timer.
 
 	acpi_sleep=	[HW,ACPI] Sleep options
 			Format: { s3_bios, s3_mode, s3_beep, s4_nohwsig,
 				  old_ordering, nonvs, sci_force_enable }
 			See Documentation/power/video.txt for information on
 			s3_bios and s3_mode.
 			s3_beep is for debugging; it makes the PC's speaker beep
 			as soon as the kernel's real-mode entry point is called.
 			s4_nohwsig prevents ACPI hardware signature from being
 			used during resume from hibernation.
 			old_ordering causes the ACPI 1.0 ordering of the _PTS
 			control method, with respect to putting devices into
 			low power states, to be enforced (the ACPI 2.0 ordering
 			of _PTS is used by default).
 			nonvs prevents the kernel from saving/restoring the
 			ACPI NVS memory during suspend/hibernation and resume.
 			sci_force_enable causes the kernel to set SCI_EN directly
 			on resume from S1/S3 (which is against the ACPI spec,
 			but some broken systems don't work without it).
 
 	acpi_use_timer_override [HW,ACPI]
 			Use timer override. For some broken Nvidia NF5 boards
 			that require a timer override, but don't have HPET
 
 	add_efi_memmap	[EFI; X86] Include EFI memory map in
 			kernel's map of available physical RAM.
 
 	agp=		[AGP]
 			{ off | try_unsupported }
 			off: disable AGP support
 			try_unsupported: try to drive unsupported chipsets
 				(may crash computer or cause data corruption)
 
 	ALSA		[HW,ALSA]
 			See Documentation/sound/alsa/alsa-parameters.txt
 
 	alignment=	[KNL,ARM]
 			Allow the default userspace alignment fault handler
 			behaviour to be specified.  Bit 0 enables warnings,
 			bit 1 enables fixups, and bit 2 sends a segfault.
 
 	align_va_addr=	[X86-64]
 			Align virtual addresses by clearing slice [14:12] when
 			allocating a VMA at process creation time. This option
 			gives you up to 3% performance improvement on AMD F15h
 			machines (where it is enabled by default) for a
 			CPU-intensive style benchmark, and it can vary highly in
 			a microbenchmark depending on workload and compiler.
 
 			32: only for 32-bit processes
 			64: only for 64-bit processes
 			on: enable for both 32- and 64-bit processes
 			off: disable for both 32- and 64-bit processes
 
 	alloc_snapshot	[FTRACE]
 			Allocate the ftrace snapshot buffer on boot up when the
 			main buffer is allocated. This is handy if debugging
 			and you need to use tracing_snapshot() on boot up, and
 			do not want to use tracing_snapshot_alloc() as it needs
 			to be done where GFP_KERNEL allocations are allowed.
 
 	amd_iommu=	[HW,X86-64]
 			Pass parameters to the AMD IOMMU driver in the system.
 			Possible values are:
 			fullflush - enable flushing of IO/TLB entries when
 				    they are unmapped. Otherwise they are
 				    flushed before they will be reused, which
 				    is a lot of faster
 			off	  - do not initialize any AMD IOMMU found in
 				    the system
 			force_isolation - Force device isolation for all
 					  devices. The IOMMU driver is not
 					  allowed anymore to lift isolation
 					  requirements as needed. This option
 					  does not override iommu=pt
 
 	amd_iommu_dump=	[HW,X86-64]
 			Enable AMD IOMMU driver option to dump the ACPI table
 			for AMD IOMMU. With this option enabled, AMD IOMMU
 			driver will print ACPI tables for AMD IOMMU during
 			IOMMU initialization.
 
 	amd_iommu_intr=	[HW,X86-64]
 			Specifies one of the following AMD IOMMU interrupt
 			remapping modes:
 			legacy     - Use legacy interrupt remapping mode.
 			vapic      - Use virtual APIC mode, which allows IOMMU
 			             to inject interrupts directly into guest.
 			             This mode requires kvm-amd.avic=1.
 			             (Default when IOMMU HW support is present.)
 
 	amijoy.map=	[HW,JOY] Amiga joystick support
 			Map of devices attached to JOY0DAT and JOY1DAT
 			Format: <a>,<b>
 			See also Documentation/input/joystick.txt
 
 	analog.map=	[HW,JOY] Analog joystick and gamepad support
 			Specifies type or capabilities of an analog joystick
 			connected to one of 16 gameports
 			Format: <type1>,<type2>,..<type16>
 
 	apc=		[HW,SPARC]
 			Power management functions (SPARCstation-4/5 + deriv.)
 			Format: noidle
 			Disable APC CPU standby support. SPARCstation-Fox does
 			not play well with APC CPU idle - disable it if you have
 			APC and your system crashes randomly.
 
 	apic=		[APIC,X86-32] Advanced Programmable Interrupt Controller
 			Change the output verbosity whilst booting
 			Format: { quiet (default) | verbose | debug }
 			Change the amount of debugging information output
 			when initialising the APIC and IO-APIC components.
 
 	apic_extnmi=	[APIC,X86] External NMI delivery setting
 			Format: { bsp (default) | all | none }
 			bsp:  External NMI is delivered only to CPU 0
 			all:  External NMIs are broadcast to all CPUs as a
 			      backup of CPU 0
 			none: External NMI is masked for all CPUs. This is
 			      useful so that a dump capture kernel won't be
 			      shot down by NMI
 
 	autoconf=	[IPV6]
 			See Documentation/networking/ipv6.txt.
 
 	show_lapic=	[APIC,X86] Advanced Programmable Interrupt Controller
 			Limit apic dumping. The parameter defines the maximal
 			number of local apics being dumped. Also it is possible
 			to set it to "all" by meaning -- no limit here.
 			Format: { 1 (default) | 2 | ... | all }.
 			The parameter valid if only apic=debug or
 			apic=verbose is specified.
 			Example: apic=debug show_lapic=all
 
 	apm=		[APM] Advanced Power Management
 			See header of arch/x86/kernel/apm_32.c.
 
 	arcrimi=	[HW,NET] ARCnet - "RIM I" (entirely mem-mapped) cards
 			Format: <io>,<irq>,<nodeID>
 
 	ataflop=	[HW,M68k]
 
 	atarimouse=	[HW,MOUSE] Atari Mouse
 
 	atkbd.extra=	[HW] Enable extra LEDs and keys on IBM RapidAccess,
 			EzKey and similar keyboards
 
 	atkbd.reset=	[HW] Reset keyboard during initialization
 
 	atkbd.set=	[HW] Select keyboard code set
 			Format: <int> (2 = AT (default), 3 = PS/2)
 
 	atkbd.scroll=	[HW] Enable scroll wheel on MS Office and similar
 			keyboards
 
 	atkbd.softraw=	[HW] Choose between synthetic and real raw mode
 			Format: <bool> (0 = real, 1 = synthetic (default))
 
 	atkbd.softrepeat= [HW]
 			Use software keyboard repeat
 
 	audit=		[KNL] Enable the audit sub-system
 			Format: { "0" | "1" } (0 = disabled, 1 = enabled)
 			0 - kernel audit is disabled and can not be enabled
 			    until the next reboot
 			unset - kernel audit is initialized but disabled and
 			    will be fully enabled by the userspace auditd.
 			1 - kernel audit is initialized and partially enabled,
 			    storing at most audit_backlog_limit messages in
 			    RAM until it is fully enabled by the userspace
 			    auditd.
 			Default: unset
 
 	audit_backlog_limit= [KNL] Set the audit queue size limit.
 			Format: <int> (must be >=0)
 			Default: 64
 
 	bau=		[X86_UV] Enable the BAU on SGI UV.  The default
 			behavior is to disable the BAU (i.e. bau=0).
 			Format: { "0" | "1" }
 			0 - Disable the BAU.
 			1 - Enable the BAU.
 			unset - Disable the BAU.
 
 	baycom_epp=	[HW,AX25]
 			Format: <io>,<mode>
 
 	baycom_par=	[HW,AX25] BayCom Parallel Port AX.25 Modem
 			Format: <io>,<mode>
 			See header of drivers/net/hamradio/baycom_par.c.
 
 	baycom_ser_fdx=	[HW,AX25]
 			BayCom Serial Port AX.25 Modem (Full Duplex Mode)
 			Format: <io>,<irq>,<mode>[,<baud>]
 			See header of drivers/net/hamradio/baycom_ser_fdx.c.
 
 	baycom_ser_hdx=	[HW,AX25]
 			BayCom Serial Port AX.25 Modem (Half Duplex Mode)
 			Format: <io>,<irq>,<mode>
 			See header of drivers/net/hamradio/baycom_ser_hdx.c.
 
 	blkdevparts=	Manual partition parsing of block device(s) for
 			embedded devices based on command line input.
 			See Documentation/block/cmdline-partition.txt
 
 	boot_delay=	Milliseconds to delay each printk during boot.
 			Values larger than 10 seconds (10000) are changed to
 			no delay (0).
 			Format: integer
 
 	bootmem_debug	[KNL] Enable bootmem allocator debug messages.
 
 	bert_disable	[ACPI]
 			Disable BERT OS support on buggy BIOSes.
 
 	bttv.card=	[HW,V4L] bttv (bt848 + bt878 based grabber cards)
 	bttv.radio=	Most important insmod options are available as
 			kernel args too.
 	bttv.pll=	See Documentation/video4linux/bttv/Insmod-options
 	bttv.tuner=
 
 	bulk_remove=off	[PPC]  This parameter disables the use of the pSeries
 			firmware feature for flushing multiple hpte entries
 			at a time.
 
 	c101=		[NET] Moxa C101 synchronous serial card
 
 	cachesize=	[BUGS=X86-32] Override level 2 CPU cache size detection.
 			Sometimes CPU hardware bugs make them report the cache
 			size incorrectly. The kernel will attempt work arounds
 			to fix known problems, but for some CPUs it is not
 			possible to determine what the correct size should be.
 			This option provides an override for these situations.
 
 	ca_keys=	[KEYS] This parameter identifies a specific key(s) on
 			the system trusted keyring to be used for certificate
 			trust validation.
 			format: { id:<keyid> | builtin }
 
 	cca=		[MIPS] Override the kernel pages' cache coherency
 			algorithm.  Accepted values range from 0 to 7
 			inclusive. See arch/mips/include/asm/pgtable-bits.h
 			for platform specific values (SB1, Loongson3 and
 			others).
 
 	ccw_timeout_log [S390]
 			See Documentation/s390/CommonIO for details.
 
 	cgroup_disable= [KNL] Disable a particular controller
 			Format: {name of the controller(s) to disable}
 			The effects of cgroup_disable=foo are:
 			- foo isn't auto-mounted if you mount all cgroups in
 			  a single hierarchy
 			- foo isn't visible as an individually mountable
 			  subsystem
 			{Currently only "memory" controller deal with this and
 			cut the overhead, others just disable the usage. So
 			only cgroup_disable=memory is actually worthy}
 
 	cgroup_no_v1=	[KNL] Disable one, multiple, all cgroup controllers in v1
 			Format: { controller[,controller...] | "all" }
 			Like cgroup_disable, but only applies to cgroup v1;
 			the blacklisted controllers remain available in cgroup2.
 
 	cgroup.memory=	[KNL] Pass options to the cgroup memory controller.
 			Format: <string>
 			nosocket -- Disable socket memory accounting.
 			nokmem -- Disable kernel memory accounting.
 
 	checkreqprot	[SELINUX] Set initial checkreqprot flag value.
 			Format: { "0" | "1" }
 			See security/selinux/Kconfig help text.
 			0 -- check protection applied by kernel (includes
 				any implied execute protection).
 			1 -- check protection requested by application.
 			Default value is set via a kernel config option.
 			Value can be changed at runtime via
 				/selinux/checkreqprot.
 
 	cio_ignore=	[S390]
 			See Documentation/s390/CommonIO for details.
 	clk_ignore_unused
 			[CLK]
 			Prevents the clock framework from automatically gating
 			clocks that have not been explicitly enabled by a Linux
 			device driver but are enabled in hardware at reset or
 			by the bootloader/firmware. Note that this does not
 			force such clocks to be always-on nor does it reserve
 			those clocks in any way. This parameter is useful for
 			debug and development, but should not be needed on a
 			platform with proper driver support.  For more
 			information, see Documentation/clk.txt.
 
 	clock=		[BUGS=X86-32, HW] gettimeofday clocksource override.
 			[Deprecated]
 			Forces specified clocksource (if available) to be used
 			when calculating gettimeofday(). If specified
 			clocksource is not available, it defaults to PIT.
 			Format: { pit | tsc | cyclone | pmtmr }
 
 	clocksource=	Override the default clocksource
 			Format: <string>
 			Override the default clocksource and use the clocksource
 			with the name specified.
 			Some clocksource names to choose from, depending on
 			the platform:
 			[all] jiffies (this is the base, fallback clocksource)
 			[ACPI] acpi_pm
 			[ARM] imx_timer1,OSTS,netx_timer,mpu_timer2,
 				pxa_timer,timer3,32k_counter,timer0_1
 			[AVR32] avr32
 			[X86-32] pit,hpet,tsc;
 				scx200_hrt on Geode; cyclone on IBM x440
 			[MIPS] MIPS
 			[PARISC] cr16
 			[S390] tod
 			[SH] SuperH
 			[SPARC64] tick
 			[X86-64] hpet,tsc
 
 	clocksource.arm_arch_timer.evtstrm=
 			[ARM,ARM64]
 			Format: <bool>
 			Enable/disable the eventstream feature of the ARM
 			architected timer so that code using WFE-based polling
 			loops can be debugged more effectively on production
 			systems.
 
 	clearcpuid=BITNUM [X86]
 			Disable CPUID feature X for the kernel. See
 			arch/x86/include/asm/cpufeatures.h for the valid bit
 			numbers. Note the Linux specific bits are not necessarily
 			stable over kernel options, but the vendor specific
 			ones should be.
 			Also note that user programs calling CPUID directly
 			or using the feature without checking anything
 			will still see it. This just prevents it from
 			being used by the kernel or shown in /proc/cpuinfo.
 			Also note the kernel might malfunction if you disable
 			some critical bits.
 
 	cma=nn[MG]@[start[MG][-end[MG]]]
 			[ARM,X86,KNL]
 			Sets the size of kernel global memory area for
 			contiguous memory allocations and optionally the
 			placement constraint by the physical address range of
 			memory allocations. A value of 0 disables CMA
 			altogether. For more information, see
 			include/linux/dma-contiguous.h
 
 	cmo_free_hint=	[PPC] Format: { yes | no }
 			Specify whether pages are marked as being inactive
 			when they are freed.  This is used in CMO environments
 			to determine OS memory pressure for page stealing by
 			a hypervisor.
 			Default: yes
 
 	coherent_pool=nn[KMG]	[ARM,KNL]
 			Sets the size of memory pool for coherent, atomic dma
 			allocations, by default set to 256K.
 
 	code_bytes	[X86] How many bytes of object code to print
 			in an oops report.
 			Range: 0 - 8192
 			Default: 64
 
 	com20020=	[HW,NET] ARCnet - COM20020 chipset
 			Format:
 			<io>[,<irq>[,<nodeID>[,<backplane>[,<ckp>[,<timeout>]]]]]
 
 	com90io=	[HW,NET] ARCnet - COM90xx chipset (IO-mapped buffers)
 			Format: <io>[,<irq>]
 
 	com90xx=	[HW,NET]
 			ARCnet - COM90xx chipset (memory-mapped buffers)
 			Format: <io>[,<irq>[,<memstart>]]
 
 	condev=		[HW,S390] console device
 	conmode=
 
 	console=	[KNL] Output console device and options.
 
 		tty<n>	Use the virtual console device <n>.
 
 		ttyS<n>[,options]
 		ttyUSB0[,options]
 			Use the specified serial port.  The options are of
 			the form "bbbbpnf", where "bbbb" is the baud rate,
 			"p" is parity ("n", "o", or "e"), "n" is number of
 			bits, and "f" is flow control ("r" for RTS or
 			omit it).  Default is "9600n8".
 
 			See Documentation/admin-guide/serial-console.rst for more
 			information.  See
 			Documentation/networking/netconsole.txt for an
 			alternative.
 
 		uart[8250],io,<addr>[,options]
 		uart[8250],mmio,<addr>[,options]
 		uart[8250],mmio16,<addr>[,options]
 		uart[8250],mmio32,<addr>[,options]
 		uart[8250],0x<addr>[,options]
 			Start an early, polled-mode console on the 8250/16550
 			UART at the specified I/O port or MMIO address,
 			switching to the matching ttyS device later.
 			MMIO inter-register address stride is either 8-bit
 			(mmio), 16-bit (mmio16), or 32-bit (mmio32).
 			If none of [io|mmio|mmio16|mmio32], <addr> is assumed
 			to be equivalent to 'mmio'. 'options' are specified in
 			the same format described for ttyS above; if unspecified,
 			the h/w is not re-initialized.
 
 		hvc<n>	Use the hypervisor console device <n>. This is for
 			both Xen and PowerPC hypervisors.
 
                 If the device connected to the port is not a TTY but a braille
                 device, prepend "brl," before the device type, for instance
 			console=brl,ttyS0
 		For now, only VisioBraille is supported.
 
 	consoleblank=	[KNL] The console blank (screen saver) timeout in
 			seconds. Defaults to 10*60 = 10mins. A value of 0
 			disables the blank timer.
 
 	coredump_filter=
 			[KNL] Change the default value for
 			/proc/<pid>/coredump_filter.
 			See also Documentation/filesystems/proc.txt.
 
 	cpuidle.off=1	[CPU_IDLE]
 			disable the cpuidle sub-system
 
 	cpu_init_udelay=N
 			[X86] Delay for N microsec between assert and de-assert
 			of APIC INIT to start processors.  This delay occurs
 			on every CPU online, such as boot, and resume from suspend.
 			Default: 10000
 
 	cpcihp_generic=	[HW,PCI] Generic port I/O CompactPCI driver
 			Format:
 			<first_slot>,<last_slot>,<port>,<enum_bit>[,<debug>]
 
 	crashkernel=size[KMG][@offset[KMG]]
 			[KNL] Using kexec, Linux can switch to a 'crash kernel'
 			upon panic. This parameter reserves the physical
 			memory region [offset, offset + size] for that kernel
 			image. If '@offset' is omitted, then a suitable offset
 			is selected automatically. Check
 			Documentation/kdump/kdump.txt for further details.
 
 	crashkernel=range1:size1[,range2:size2,...][@offset]
 			[KNL] Same as above, but depends on the memory
 			in the running system. The syntax of range is
 			start-[end] where start and end are both
 			a memory unit (amount[KMG]). See also
 			Documentation/kdump/kdump.txt for an example.
 
 	crashkernel=size[KMG],high
 			[KNL, x86_64] range could be above 4G. Allow kernel
 			to allocate physical memory region from top, so could
 			be above 4G if system have more than 4G ram installed.
 			Otherwise memory region will be allocated below 4G, if
 			available.
 			It will be ignored if crashkernel=X is specified.
 	crashkernel=size[KMG],low
 			[KNL, x86_64] range under 4G. When crashkernel=X,high
 			is passed, kernel could allocate physical memory region
 			above 4G, that cause second kernel crash on system
 			that require some amount of low memory, e.g. swiotlb
 			requires at least 64M+32K low memory, also enough extra
 			low memory is needed to make sure DMA buffers for 32-bit
 			devices won't run out. Kernel would try to allocate at
 			at least 256M below 4G automatically.
 			This one let user to specify own low range under 4G
 			for second kernel instead.
 			0: to disable low allocation.
 			It will be ignored when crashkernel=X,high is not used
 			or memory reserved is below 4G.
 
 	cryptomgr.notests
                         [KNL] Disable crypto self-tests
 
 	cs89x0_dma=	[HW,NET]
 			Format: <dma>
 
 	cs89x0_media=	[HW,NET]
 			Format: { rj45 | aui | bnc }
 
 	dasd=		[HW,NET]
 			See header of drivers/s390/block/dasd_devmap.c.
 
 	db9.dev[2|3]=	[HW,JOY] Multisystem joystick support via parallel port
 			(one device per port)
 			Format: <port#>,<type>
 			See also Documentation/input/joystick-parport.txt
 
 	ddebug_query=   [KNL,DYNAMIC_DEBUG] Enable debug messages at early boot
 			time. See Documentation/dynamic-debug-howto.txt for
 			details.  Deprecated, see dyndbg.
 
 	debug		[KNL] Enable kernel debugging (events log level).
 
 	debug_locks_verbose=
 			[KNL] verbose self-tests
 			Format=<0|1>
 			Print debugging info while doing the locking API
 			self-tests.
 			We default to 0 (no extra messages), setting it to
 			1 will print _a lot_ more information - normally
 			only useful to kernel developers.
 
 	debug_objects	[KNL] Enable object debugging
 
 	no_debug_objects
 			[KNL] Disable object debugging
 
 	debug_guardpage_minorder=
 			[KNL] When CONFIG_DEBUG_PAGEALLOC is set, this
 			parameter allows control of the order of pages that will
 			be intentionally kept free (and hence protected) by the
 			buddy allocator. Bigger value increase the probability
 			of catching random memory corruption, but reduce the
 			amount of memory for normal system use. The maximum
 			possible value is MAX_ORDER/2.  Setting this parameter
 			to 1 or 2 should be enough to identify most random
 			memory corruption problems caused by bugs in kernel or
 			driver code when a CPU writes to (or reads from) a
 			random memory location. Note that there exists a class
 			of memory corruptions problems caused by buggy H/W or
 			F/W or by drivers badly programing DMA (basically when
 			memory is written at bus level and the CPU MMU is
 			bypassed) which are not detectable by
 			CONFIG_DEBUG_PAGEALLOC, hence this option will not help
 			tracking down these problems.
 
 	debug_pagealloc=
 			[KNL] When CONFIG_DEBUG_PAGEALLOC is set, this
 			parameter enables the feature at boot time. In
 			default, it is disabled. We can avoid allocating huge
 			chunk of memory for debug pagealloc if we don't enable
 			it at boot time and the system will work mostly same
 			with the kernel built without CONFIG_DEBUG_PAGEALLOC.
 			on: enable the feature
 
 	debugpat	[X86] Enable PAT debugging
 
 	decnet.addr=	[HW,NET]
 			Format: <area>[,<node>]
 			See also Documentation/networking/decnet.txt.
 
 	default_hugepagesz=
 			[same as hugepagesz=] The size of the default
 			HugeTLB page size. This is the size represented by
 			the legacy /proc/ hugepages APIs, used for SHM, and
 			default size when mounting hugetlbfs filesystems.
 			Defaults to the default architecture's huge page size
 			if not specified.
 
 	dhash_entries=	[KNL]
 			Set number of hash buckets for dentry cache.
 
 	disable_1tb_segments [PPC]
 			Disables the use of 1TB hash page table segments. This
 			causes the kernel to fall back to 256MB segments which
 			can be useful when debugging issues that require an SLB
 			miss to occur.
 
 	disable=	[IPV6]
 			See Documentation/networking/ipv6.txt.
 
 	disable_radix	[PPC]
 			Disable RADIX MMU mode on POWER9
 
 	disable_cpu_apicid= [X86,APIC,SMP]
 			Format: <int>
 			The number of initial APIC ID for the
 			corresponding CPU to be disabled at boot,
 			mostly used for the kdump 2nd kernel to
 			disable BSP to wake up multiple CPUs without
 			causing system reset or hang due to sending
 			INIT from AP to BSP.
 
 	disable_ddw     [PPC/PSERIES]
 			Disable Dynamic DMA Window support. Use this if
 			to workaround buggy firmware.
 
 	disable_ipv6=	[IPV6]
 			See Documentation/networking/ipv6.txt.
 
 	disable_mtrr_cleanup [X86]
 			The kernel tries to adjust MTRR layout from continuous
 			to discrete, to make X server driver able to add WB
 			entry later. This parameter disables that.
 
 	disable_mtrr_trim [X86, Intel and AMD only]
 			By default the kernel will trim any uncacheable
 			memory out of your available memory pool based on
 			MTRR settings.  This parameter disables that behavior,
 			possibly causing your machine to run very slowly.
 
 	disable_timer_pin_1 [X86]
 			Disable PIN 1 of APIC timer
 			Can be useful to work around chipset bugs.
 
 	dis_ucode_ldr	[X86] Disable the microcode loader.
 
 	dma_debug=off	If the kernel is compiled with DMA_API_DEBUG support,
 			this option disables the debugging code at boot.
 
 	dma_debug_entries=<number>
 			This option allows to tune the number of preallocated
 			entries for DMA-API debugging code. One entry is
 			required per DMA-API allocation. Use this if the
 			DMA-API debugging code disables itself because the
 			architectural default is too low.
 
 	dma_debug_driver=<driver_name>
 			With this option the DMA-API debugging driver
 			filter feature can be enabled at boot time. Just
 			pass the driver to filter for as the parameter.
 			The filter can be disabled or changed to another
 			driver later using sysfs.
 
 	drm_kms_helper.edid_firmware=[<connector>:]<file>[,[<connector>:]<file>]
 			Broken monitors, graphic adapters, KVMs and EDIDless
 			panels may send no or incorrect EDID data sets.
 			This parameter allows to specify an EDID data sets
 			in the /lib/firmware directory that are used instead.
 			Generic built-in EDID data sets are used, if one of
 			edid/1024x768.bin, edid/1280x1024.bin,
 			edid/1680x1050.bin, or edid/1920x1080.bin is given
 			and no file with the same name exists. Details and
 			instructions how to build your own EDID data are
 			available in Documentation/EDID/HOWTO.txt. An EDID
 			data set will only be used for a particular connector,
 			if its name and a colon are prepended to the EDID
 			name. Each connector may use a unique EDID data
 			set by separating the files with a comma.  An EDID
 			data set with no connector name will be used for
 			any connectors not explicitly specified.
 
 	dscc4.setup=	[NET]
 
 	dump_apple_properties	[X86]
 			Dump name and content of EFI device properties on
 			x86 Macs.  Useful for driver authors to determine
 			what data is available or for reverse-engineering.
 
 	dyndbg[="val"]		[KNL,DYNAMIC_DEBUG]
 	module.dyndbg[="val"]
 			Enable debug messages at boot time.  See
 			Documentation/dynamic-debug-howto.txt for details.
 
 	nompx		[X86] Disables Intel Memory Protection Extensions.
 			See Documentation/x86/intel_mpx.txt for more
 			information about the feature.
 
 	nopku		[X86] Disable Memory Protection Keys CPU feature found
 			in some Intel CPUs.
 
 	module.async_probe [KNL]
 			Enable asynchronous probe on this module.
 
 	early_ioremap_debug [KNL]
 			Enable debug messages in early_ioremap support. This
 			is useful for tracking down temporary early mappings
 			which are not unmapped.
 
 	earlycon=	[KNL] Output early console device and options.
 
 			When used with no options, the early console is
 			determined by the stdout-path property in device
 			tree's chosen node.
 
 		cdns,<addr>[,options]
 			Start an early, polled-mode console on a Cadence
 			(xuartps) serial port at the specified address. Only
 			supported option is baud rate. If baud rate is not
 			specified, the serial port must already be setup and
 			configured.
 
 		uart[8250],io,<addr>[,options]
 		uart[8250],mmio,<addr>[,options]
 		uart[8250],mmio32,<addr>[,options]
 		uart[8250],mmio32be,<addr>[,options]
 		uart[8250],0x<addr>[,options]
 			Start an early, polled-mode console on the 8250/16550
 			UART at the specified I/O port or MMIO address.
 			MMIO inter-register address stride is either 8-bit
 			(mmio) or 32-bit (mmio32 or mmio32be).
 			If none of [io|mmio|mmio32|mmio32be], <addr> is assumed
 			to be equivalent to 'mmio'. 'options' are specified
 			in the same format described for "console=ttyS<n>"; if
 			unspecified, the h/w is not initialized.
 
 		pl011,<addr>
 		pl011,mmio32,<addr>
 			Start an early, polled-mode console on a pl011 serial
 			port at the specified address. The pl011 serial port
 			must already be setup and configured. Options are not
 			yet supported.  If 'mmio32' is specified, then only
 			the driver will use only 32-bit accessors to read/write
 			the device registers.
 
 		meson,<addr>
 			Start an early, polled-mode console on a meson serial
 			port at the specified address. The serial port must
 			already be setup and configured. Options are not yet
 			supported.
 
 		msm_serial,<addr>
 			Start an early, polled-mode console on an msm serial
 			port at the specified address. The serial port
 			must already be setup and configured. Options are not
 			yet supported.
 
 		msm_serial_dm,<addr>
 			Start an early, polled-mode console on an msm serial
 			dm port at the specified address. The serial port
 			must already be setup and configured. Options are not
 			yet supported.
 
 		smh	Use ARM semihosting calls for early console.
 
 		s3c2410,<addr>
 		s3c2412,<addr>
 		s3c2440,<addr>
 		s3c6400,<addr>
 		s5pv210,<addr>
 		exynos4210,<addr>
 			Use early console provided by serial driver available
 			on Samsung SoCs, requires selecting proper type and
 			a correct base address of the selected UART port. The
 			serial port must already be setup and configured.
 			Options are not yet supported.
 
 		lpuart,<addr>
 		lpuart32,<addr>
 			Use early console provided by Freescale LP UART driver
 			found on Freescale Vybrid and QorIQ LS1021A processors.
 			A valid base address must be provided, and the serial
 			port must already be setup and configured.
 
 		armada3700_uart,<addr>
 			Start an early, polled-mode console on the
 			Armada 3700 serial port at the specified
 			address. The serial port must already be setup
 			and configured. Options are not yet supported.
 
 	earlyprintk=	[X86,SH,BLACKFIN,ARM,M68k,S390]
 			earlyprintk=vga
 			earlyprintk=efi
 			earlyprintk=sclp
 			earlyprintk=xen
 			earlyprintk=serial[,ttySn[,baudrate]]
 			earlyprintk=serial[,0x...[,baudrate]]
 			earlyprintk=ttySn[,baudrate]
 			earlyprintk=dbgp[debugController#]
 			earlyprintk=pciserial,bus:device.function[,baudrate]
 
 			earlyprintk is useful when the kernel crashes before
 			the normal console is initialized. It is not enabled by
 			default because it has some cosmetic problems.
 
 			Append ",keep" to not disable it when the real console
 			takes over.
 
 			Only one of vga, efi, serial, or usb debug port can
 			be used at a time.
 
 			Currently only ttyS0 and ttyS1 may be specified by
 			name.  Other I/O ports may be explicitly specified
 			on some architectures (x86 and arm at least) by
 			replacing ttySn with an I/O port address, like this:
 				earlyprintk=serial,0x1008,115200
 			You can find the port for a given device in
 			/proc/tty/driver/serial:
 				2: uart:ST16650V2 port:00001008 irq:18 ...
 
 			Interaction with the standard serial driver is not
 			very good.
 
 			The VGA and EFI output is eventually overwritten by
 			the real console.
 
 			The xen output can only be used by Xen PV guests.
 
 			The sclp output can only be used on s390.
 
 	edac_report=	[HW,EDAC] Control how to report EDAC event
 			Format: {"on" | "off" | "force"}
 			on: enable EDAC to report H/W event. May be overridden
 			by other higher priority error reporting module.
 			off: disable H/W event reporting through EDAC.
 			force: enforce the use of EDAC to report H/W event.
 			default: on.
 
 	ekgdboc=	[X86,KGDB] Allow early kernel console debugging
 			ekgdboc=kbd
 
 			This is designed to be used in conjunction with
 			the boot argument: earlyprintk=vga
 
 	edd=		[EDD]
 			Format: {"off" | "on" | "skip[mbr]"}
 
 	efi=		[EFI]
 			Format: { "old_map", "nochunk", "noruntime", "debug" }
 			old_map [X86-64]: switch to the old ioremap-based EFI
 			runtime services mapping. 32-bit still uses this one by
 			default.
 			nochunk: disable reading files in "chunks" in the EFI
 			boot stub, as chunking can cause problems with some
 			firmware implementations.
 			noruntime : disable EFI runtime services support
 			debug: enable misc debug output
 
 	efi_no_storage_paranoia [EFI; X86]
 			Using this parameter you can use more than 50% of
 			your efi variable storage. Use this parameter only if
 			you are really sure that your UEFI does sane gc and
 			fulfills the spec otherwise your board may brick.
 
 	efi_fake_mem=	nn[KMG]@ss[KMG]:aa[,nn[KMG]@ss[KMG]:aa,..] [EFI; X86]
 			Add arbitrary attribute to specific memory range by
 			updating original EFI memory map.
 			Region of memory which aa attribute is added to is
 			from ss to ss+nn.
 			If efi_fake_mem=2G@4G:0x10000,2G@0x10a0000000:0x10000
 			is specified, EFI_MEMORY_MORE_RELIABLE(0x10000)
 			attribute is added to range 0x100000000-0x180000000 and
 			0x10a0000000-0x1120000000.
 
 			Using this parameter you can do debugging of EFI memmap
 			related feature. For example, you can do debugging of
 			Address Range Mirroring feature even if your box
 			doesn't support it.
 
 	efivar_ssdt=	[EFI; X86] Name of an EFI variable that contains an SSDT
 			that is to be dynamically loaded by Linux. If there are
 			multiple variables with the same name but with different
 			vendor GUIDs, all of them will be loaded. See
 			Documentation/acpi/ssdt-overlays.txt for details.
 
 
 	eisa_irq_edge=	[PARISC,HW]
 			See header of drivers/parisc/eisa.c.
 
 	elanfreq=	[X86-32]
 			See comment before function elanfreq_setup() in
 			arch/x86/kernel/cpu/cpufreq/elanfreq.c.
 
 	elevator=	[IOSCHED]
 			Format: {"cfq" | "deadline" | "noop"}
 			See Documentation/block/cfq-iosched.txt and
 			Documentation/block/deadline-iosched.txt for details.
 
 	elfcorehdr=[size[KMG]@]offset[KMG] [IA64,PPC,SH,X86,S390]
 			Specifies physical address of start of kernel core
 			image elf header and optionally the size. Generally
 			kexec loader will pass this option to capture kernel.
 			See Documentation/kdump/kdump.txt for details.
 
 	enable_mtrr_cleanup [X86]
 			The kernel tries to adjust MTRR layout from continuous
 			to discrete, to make X server driver able to add WB
 			entry later. This parameter enables that.
 
 	enable_timer_pin_1 [X86]
 			Enable PIN 1 of APIC timer
 			Can be useful to work around chipset bugs
 			(in particular on some ATI chipsets).
 			The kernel tries to set a reasonable default.
 
 	enforcing	[SELINUX] Set initial enforcing status.
 			Format: {"0" | "1"}
 			See security/selinux/Kconfig help text.
 			0 -- permissive (log only, no denials).
 			1 -- enforcing (deny and log).
 			Default value is 0.
 			Value can be changed at runtime via /selinux/enforce.
 
 	erst_disable	[ACPI]
 			Disable Error Record Serialization Table (ERST)
 			support.
 
 	ether=		[HW,NET] Ethernet cards parameters
 			This option is obsoleted by the "netdev=" option, which
 			has equivalent usage. See its documentation for details.
 
 	evm=		[EVM]
 			Format: { "fix" }
 			Permit 'security.evm' to be updated regardless of
 			current integrity status.
 
 	failslab=
 	fail_page_alloc=
 	fail_make_request=[KNL]
 			General fault injection mechanism.
 			Format: <interval>,<probability>,<space>,<times>
 			See also Documentation/fault-injection/.
 
 	floppy=		[HW]
 			See Documentation/blockdev/floppy.txt.
 
 	force_pal_cache_flush
 			[IA-64] Avoid check_sal_cache_flush which may hang on
 			buggy SAL_CACHE_FLUSH implementations. Using this
 			parameter will force ia64_sal_cache_flush to call
 			ia64_pal_cache_flush instead of SAL_CACHE_FLUSH.
 
 	forcepae [X86-32]
 			Forcefully enable Physical Address Extension (PAE).
 			Many Pentium M systems disable PAE but may have a
 			functionally usable PAE implementation.
 			Warning: use of this parameter will taint the kernel
 			and may cause unknown problems.
 
 	ftrace=[tracer]
 			[FTRACE] will set and start the specified tracer
 			as early as possible in order to facilitate early
 			boot debugging.
 
 	ftrace_dump_on_oops[=orig_cpu]
 			[FTRACE] will dump the trace buffers on oops.
 			If no parameter is passed, ftrace will dump
 			buffers of all CPUs, but if you pass orig_cpu, it will
 			dump only the buffer of the CPU that triggered the
 			oops.
 
 	ftrace_filter=[function-list]
 			[FTRACE] Limit the functions traced by the function
 			tracer at boot up. function-list is a comma separated
 			list of functions. This list can be changed at run
 			time by the set_ftrace_filter file in the debugfs
 			tracing directory.
 
 	ftrace_notrace=[function-list]
 			[FTRACE] Do not trace the functions specified in
 			function-list. This list can be changed at run time
 			by the set_ftrace_notrace file in the debugfs
 			tracing directory.
 
 	ftrace_graph_filter=[function-list]
 			[FTRACE] Limit the top level callers functions traced
 			by the function graph tracer at boot up.
 			function-list is a comma separated list of functions
 			that can be changed at run time by the
 			set_graph_function file in the debugfs tracing directory.
 
 	ftrace_graph_notrace=[function-list]
 			[FTRACE] Do not trace from the functions specified in
 			function-list.  This list is a comma separated list of
 			functions that can be changed at run time by the
 			set_graph_notrace file in the debugfs tracing directory.
 
 	gamecon.map[2|3]=
 			[HW,JOY] Multisystem joystick and NES/SNES/PSX pad
 			support via parallel port (up to 5 devices per port)
 			Format: <port#>,<pad1>,<pad2>,<pad3>,<pad4>,<pad5>
 			See also Documentation/input/joystick-parport.txt
 
 	gamma=		[HW,DRM]
 
 	gart_fix_e820=  [X86_64] disable the fix e820 for K8 GART
 			Format: off | on
 			default: on
 
 	gcov_persist=	[GCOV] When non-zero (default), profiling data for
 			kernel modules is saved and remains accessible via
 			debugfs, even when the module is unloaded/reloaded.
 			When zero, profiling data is discarded and associated
 			debugfs files are removed at module unload time.
 
+	goldfish	[X86] Enable the goldfish android emulator platform.
+			Don't use this when you are not running on the
+			android emulator
+
 	gpt		[EFI] Forces disk with valid GPT signature but
 			invalid Protective MBR to be treated as GPT. If the
 			primary GPT is corrupted, it enables the backup/alternate
 			GPT to be used instead.
 
 	grcan.enable0=	[HW] Configuration of physical interface 0. Determines
 			the "Enable 0" bit of the configuration register.
 			Format: 0 | 1
 			Default: 0
 	grcan.enable1=	[HW] Configuration of physical interface 1. Determines
 			the "Enable 0" bit of the configuration register.
 			Format: 0 | 1
 			Default: 0
 	grcan.select=	[HW] Select which physical interface to use.
 			Format: 0 | 1
 			Default: 0
 	grcan.txsize=	[HW] Sets the size of the tx buffer.
 			Format: <unsigned int> such that (txsize & ~0x1fffc0) == 0.
 			Default: 1024
 	grcan.rxsize=	[HW] Sets the size of the rx buffer.
 			Format: <unsigned int> such that (rxsize & ~0x1fffc0) == 0.
 			Default: 1024
 
 	gpio-mockup.gpio_mockup_ranges
 			[HW] Sets the ranges of gpiochip of for this device.
 			Format: <start1>,<end1>,<start2>,<end2>...
 
 	hardlockup_all_cpu_backtrace=
 			[KNL] Should the hard-lockup detector generate
 			backtraces on all cpus.
 			Format: <integer>
 
 	hashdist=	[KNL,NUMA] Large hashes allocated during boot
 			are distributed across NUMA nodes.  Defaults on
 			for 64-bit NUMA, off otherwise.
 			Format: 0 | 1 (for off | on)
 
 	hcl=		[IA-64] SGI's Hardware Graph compatibility layer
 
 	hd=		[EIDE] (E)IDE hard drive subsystem geometry
 			Format: <cyl>,<head>,<sect>
 
 	hest_disable	[ACPI]
 			Disable Hardware Error Source Table (HEST) support;
 			corresponding firmware-first mode error processing
 			logic will be disabled.
 
 	highmem=nn[KMG]	[KNL,BOOT] forces the highmem zone to have an exact
 			size of <nn>. This works even on boxes that have no
 			highmem otherwise. This also works to reduce highmem
 			size on bigger boxes.
 
 	highres=	[KNL] Enable/disable high resolution timer mode.
 			Valid parameters: "on", "off"
 			Default: "on"
 
 	hisax=		[HW,ISDN]
 			See Documentation/isdn/README.HiSax.
 
 	hlt		[BUGS=ARM,SH]
 
 	hpet=		[X86-32,HPET] option to control HPET usage
 			Format: { enable (default) | disable | force |
 				verbose }
 			disable: disable HPET and use PIT instead
 			force: allow force enabled of undocumented chips (ICH4,
 				VIA, nVidia)
 			verbose: show contents of HPET registers during setup
 
 	hpet_mmap=	[X86, HPET_MMAP] Allow userspace to mmap HPET
 			registers.  Default set by CONFIG_HPET_MMAP_DEFAULT.
 
 	hugepages=	[HW,X86-32,IA-64] HugeTLB pages to allocate at boot.
 	hugepagesz=	[HW,IA-64,PPC,X86-64] The size of the HugeTLB pages.
 			On x86-64 and powerpc, this option can be specified
 			multiple times interleaved with hugepages= to reserve
 			huge pages of different sizes. Valid pages sizes on
 			x86-64 are 2M (when the CPU supports "pse") and 1G
 			(when the CPU supports the "pdpe1gb" cpuinfo flag).
 
 	hvc_iucv=	[S390] Number of z/VM IUCV hypervisor console (HVC)
 			       terminal devices. Valid values: 0..8
 	hvc_iucv_allow=	[S390] Comma-separated list of z/VM user IDs.
 			       If specified, z/VM IUCV HVC accepts connections
 			       from listed z/VM user IDs only.
 
 	hwthread_map=	[METAG] Comma-separated list of Linux cpu id to
 			        hardware thread id mappings.
 				Format: <cpu>:<hwthread>
 
 	keep_bootcon	[KNL]
 			Do not unregister boot console at start. This is only
 			useful for debugging when something happens in the window
 			between unregistering the boot console and initializing
 			the real console.
 
 	i2c_bus=	[HW] Override the default board specific I2C bus speed
 			     or register an additional I2C bus that is not
 			     registered from board initialization code.
 			     Format:
 			     <bus_id>,<clkrate>
 
 	i8042.debug	[HW] Toggle i8042 debug mode
 	i8042.unmask_kbd_data
 			[HW] Enable printing of interrupt data from the KBD port
 			     (disabled by default, and as a pre-condition
 			     requires that i8042.debug=1 be enabled)
 	i8042.direct	[HW] Put keyboard port into non-translated mode
 	i8042.dumbkbd	[HW] Pretend that controller can only read data from
 			     keyboard and cannot control its state
 			     (Don't attempt to blink the leds)
 	i8042.noaux	[HW] Don't check for auxiliary (== mouse) port
 	i8042.nokbd	[HW] Don't check/create keyboard port
 	i8042.noloop	[HW] Disable the AUX Loopback command while probing
 			     for the AUX port
 	i8042.nomux	[HW] Don't check presence of an active multiplexing
 			     controller
 	i8042.nopnp	[HW] Don't use ACPIPnP / PnPBIOS to discover KBD/AUX
 			     controllers
 	i8042.notimeout	[HW] Ignore timeout condition signalled by controller
 	i8042.reset	[HW] Reset the controller during init, cleanup and
 			     suspend-to-ram transitions, only during s2r
 			     transitions, or never reset
 			Format: { 1 | Y | y | 0 | N | n }
 			1, Y, y: always reset controller
 			0, N, n: don't ever reset controller
 			Default: only on s2r transitions on x86; most other
 			architectures force reset to be always executed
 	i8042.unlock	[HW] Unlock (ignore) the keylock
 	i8042.kbdreset  [HW] Reset device connected to KBD port
 
 	i810=		[HW,DRM]
 
 	i8k.ignore_dmi	[HW] Continue probing hardware even if DMI data
 			indicates that the driver is running on unsupported
 			hardware.
 	i8k.force	[HW] Activate i8k driver even if SMM BIOS signature
 			does not match list of supported models.
 	i8k.power_status
 			[HW] Report power status in /proc/i8k
 			(disabled by default)
 	i8k.restricted	[HW] Allow controlling fans only if SYS_ADMIN
 			capability is set.
 
 	i915.invert_brightness=
 			[DRM] Invert the sense of the variable that is used to
 			set the brightness of the panel backlight. Normally a
 			brightness value of 0 indicates backlight switched off,
 			and the maximum of the brightness value sets the backlight
 			to maximum brightness. If this parameter is set to 0
 			(default) and the machine requires it, or this parameter
 			is set to 1, a brightness value of 0 sets the backlight
 			to maximum brightness, and the maximum of the brightness
 			value switches the backlight off.
 			-1 -- never invert brightness
 			 0 -- machine default
 			 1 -- force brightness inversion
 
 	icn=		[HW,ISDN]
 			Format: <io>[,<membase>[,<icn_id>[,<icn_id2>]]]
 
 	ide-core.nodma=	[HW] (E)IDE subsystem
 			Format: =0.0 to prevent dma on hda, =0.1 hdb =1.0 hdc
 			.vlb_clock .pci_clock .noflush .nohpa .noprobe .nowerr
 			.cdrom .chs .ignore_cable are additional options
 			See Documentation/ide/ide.txt.
 
 	ide-generic.probe-mask= [HW] (E)IDE subsystem
 			Format: <int>
 			Probe mask for legacy ISA IDE ports.  Depending on
 			platform up to 6 ports are supported, enabled by
 			setting corresponding bits in the mask to 1.  The
 			default value is 0x0, which has a special meaning.
 			On systems that have PCI, it triggers scanning the
 			PCI bus for the first and the second port, which
 			are then probed.  On systems without PCI the value
 			of 0x0 enables probing the two first ports as if it
 			was 0x3.
 
 	ide-pci-generic.all-generic-ide [HW] (E)IDE subsystem
 			Claim all unknown PCI IDE storage controllers.
 
 	idle=		[X86]
 			Format: idle=poll, idle=halt, idle=nomwait
 			Poll forces a polling idle loop that can slightly
 			improve the performance of waking up a idle CPU, but
 			will use a lot of power and make the system run hot.
 			Not recommended.
 			idle=halt: Halt is forced to be used for CPU idle.
 			In such case C2/C3 won't be used again.
 			idle=nomwait: Disable mwait for CPU C-states
 
 	ieee754=	[MIPS] Select IEEE Std 754 conformance mode
 			Format: { strict | legacy | 2008 | relaxed }
 			Default: strict
 
 			Choose which programs will be accepted for execution
 			based on the IEEE 754 NaN encoding(s) supported by
 			the FPU and the NaN encoding requested with the value
 			of an ELF file header flag individually set by each
 			binary.  Hardware implementations are permitted to
 			support either or both of the legacy and the 2008 NaN
 			encoding mode.
 
 			Available settings are as follows:
 			strict	accept binaries that request a NaN encoding
 				supported by the FPU
 			legacy	only accept legacy-NaN binaries, if supported
 				by the FPU
 			2008	only accept 2008-NaN binaries, if supported
 				by the FPU
 			relaxed	accept any binaries regardless of whether
 				supported by the FPU
 
 			The FPU emulator is always able to support both NaN
 			encodings, so if no FPU hardware is present or it has
 			been disabled with 'nofpu', then the settings of
 			'legacy' and '2008' strap the emulator accordingly,
 			'relaxed' straps the emulator for both legacy-NaN and
 			2008-NaN, whereas 'strict' enables legacy-NaN only on
 			legacy processors and both NaN encodings on MIPS32 or
 			MIPS64 CPUs.
 
 			The setting for ABS.fmt/NEG.fmt instruction execution
 			mode generally follows that for the NaN encoding,
 			except where unsupported by hardware.
 
 	ignore_loglevel	[KNL]
 			Ignore loglevel setting - this will print /all/
 			kernel messages to the console. Useful for debugging.
 			We also add it as printk module parameter, so users
 			could change it dynamically, usually by
 			/sys/module/printk/parameters/ignore_loglevel.
 
 	ignore_rlimit_data
 			Ignore RLIMIT_DATA setting for data mappings,
 			print warning at first misuse.  Can be changed via
 			/sys/module/kernel/parameters/ignore_rlimit_data.
 
 	ihash_entries=	[KNL]
 			Set number of hash buckets for inode cache.
 
 	ima_appraise=	[IMA] appraise integrity measurements
 			Format: { "off" | "enforce" | "fix" | "log" }
 			default: "enforce"
 
 	ima_appraise_tcb [IMA]
 			The builtin appraise policy appraises all files
 			owned by uid=0.
 
 	ima_canonical_fmt [IMA]
 			Use the canonical format for the binary runtime
 			measurements, instead of host native format.
 
 	ima_hash=	[IMA]
 			Format: { md5 | sha1 | rmd160 | sha256 | sha384
 				   | sha512 | ... }
 			default: "sha1"
 
 			The list of supported hash algorithms is defined
 			in crypto/hash_info.h.
 
 	ima_policy=	[IMA]
 			The builtin measurement policy to load during IMA
 			setup.  Specyfing "tcb" as the value, measures all
 			programs exec'd, files mmap'd for exec, and all files
 			opened with the read mode bit set by either the
 			effective uid (euid=0) or uid=0.
 			Format: "tcb"
 
 	ima_tcb		[IMA] Deprecated.  Use ima_policy= instead.
 			Load a policy which meets the needs of the Trusted
 			Computing Base.  This means IMA will measure all
 			programs exec'd, files mmap'd for exec, and all files
 			opened for read by uid=0.
 
 	ima_template=   [IMA]
 			Select one of defined IMA measurements template formats.
 			Formats: { "ima" | "ima-ng" | "ima-sig" }
 			Default: "ima-ng"
 
 	ima_template_fmt=
 	                [IMA] Define a custom template format.
 			Format: { "field1|...|fieldN" }
 
 	ima.ahash_minsize= [IMA] Minimum file size for asynchronous hash usage
 			Format: <min_file_size>
 			Set the minimal file size for using asynchronous hash.
 			If left unspecified, ahash usage is disabled.
 
 			ahash performance varies for different data sizes on
 			different crypto accelerators. This option can be used
 			to achieve the best performance for a particular HW.
 
 	ima.ahash_bufsize= [IMA] Asynchronous hash buffer size
 			Format: <bufsize>
 			Set hashing buffer size. Default: 4k.
 
 			ahash performance varies for different chunk sizes on
 			different crypto accelerators. This option can be used
 			to achieve best performance for particular HW.
 
 	init=		[KNL]
 			Format: <full_path>
 			Run specified binary instead of /sbin/init as init
 			process.
 
 	initcall_debug	[KNL] Trace initcalls as they are executed.  Useful
 			for working out where the kernel is dying during
 			startup.
 
 	initcall_blacklist=  [KNL] Do not execute a comma-separated list of
 			initcall functions.  Useful for debugging built-in
 			modules and initcalls.
 
 	initrd=		[BOOT] Specify the location of the initial ramdisk
 
 	init_pkru=	[x86] Specify the default memory protection keys rights
 			register contents for all processes.  0x55555554 by
 			default (disallow access to all but pkey 0).  Can
 			override in debugfs after boot.
 
 	inport.irq=	[HW] Inport (ATI XL and Microsoft) busmouse driver
 			Format: <irq>
 
 	int_pln_enable  [x86] Enable power limit notification interrupt
 
 	integrity_audit=[IMA]
 			Format: { "0" | "1" }
 			0 -- basic integrity auditing messages. (Default)
 			1 -- additional integrity auditing messages.
 
 	intel_iommu=	[DMAR] Intel IOMMU driver (DMAR) option
 		on
 			Enable intel iommu driver.
 		off
 			Disable intel iommu driver.
 		igfx_off [Default Off]
 			By default, gfx is mapped as normal device. If a gfx
 			device has a dedicated DMAR unit, the DMAR unit is
 			bypassed by not enabling DMAR with this option. In
 			this case, gfx device will use physical address for
 			DMA.
 		forcedac [x86_64]
 			With this option iommu will not optimize to look
 			for io virtual address below 32-bit forcing dual
 			address cycle on pci bus for cards supporting greater
 			than 32-bit addressing. The default is to look
 			for translation below 32-bit and if not available
 			then look in the higher range.
 		strict [Default Off]
 			With this option on every unmap_single operation will
 			result in a hardware IOTLB flush operation as opposed
 			to batching them for performance.
 		sp_off [Default Off]
 			By default, super page will be supported if Intel IOMMU
 			has the capability. With this option, super page will
 			not be supported.
 		ecs_off [Default Off]
 			By default, extended context tables will be supported if
 			the hardware advertises that it has support both for the
 			extended tables themselves, and also PASID support. With
 			this option set, extended tables will not be used even
 			on hardware which claims to support them.
 
 	intel_idle.max_cstate=	[KNL,HW,ACPI,X86]
 			0	disables intel_idle and fall back on acpi_idle.
 			1 to 9	specify maximum depth of C-state.
 
 	intel_pstate=  [X86]
 		       disable
 		         Do not enable intel_pstate as the default
 		         scaling driver for the supported processors
 		       passive
 			 Use intel_pstate as a scaling driver, but configure it
 			 to work with generic cpufreq governors (instead of
 			 enabling its internal governor).  This mode cannot be
 			 used along with the hardware-managed P-states (HWP)
 			 feature.
 		       force
 			 Enable intel_pstate on systems that prohibit it by default
 			 in favor of acpi-cpufreq. Forcing the intel_pstate driver
 			 instead of acpi-cpufreq may disable platform features, such
 			 as thermal controls and power capping, that rely on ACPI
 			 P-States information being indicated to OSPM and therefore
 			 should be used with caution. This option does not work with
 			 processors that aren't supported by the intel_pstate driver
 			 or on platforms that use pcc-cpufreq instead of acpi-cpufreq.
 		       no_hwp
 		         Do not enable hardware P state control (HWP)
 			 if available.
 		hwp_only
 			Only load intel_pstate on systems which support
 			hardware P state control (HWP) if available.
 		support_acpi_ppc
 			Enforce ACPI _PPC performance limits. If the Fixed ACPI
 			Description Table, specifies preferred power management
 			profile as "Enterprise Server" or "Performance Server",
 			then this feature is turned on by default.
 		per_cpu_perf_limits
 			Allow per-logical-CPU P-State performance control limits using
 			cpufreq sysfs interface
 
 	intremap=	[X86-64, Intel-IOMMU]
 			on	enable Interrupt Remapping (default)
 			off	disable Interrupt Remapping
 			nosid	disable Source ID checking
 			no_x2apic_optout
 				BIOS x2APIC opt-out request will be ignored
 			nopost	disable Interrupt Posting
 
 	iomem=		Disable strict checking of access to MMIO memory
 		strict	regions from userspace.
 		relaxed
 
 	iommu=		[x86]
 		off
 		force
 		noforce
 		biomerge
 		panic
 		nopanic
 		merge
 		nomerge
 		forcesac
 		soft
 		pt		[x86, IA-64]
 		nobypass	[PPC/POWERNV]
 			Disable IOMMU bypass, using IOMMU for PCI devices.
 
 
 	io7=		[HW] IO7 for Marvel based alpha systems
 			See comment before marvel_specify_io7 in
 			arch/alpha/kernel/core_marvel.c.
 
 	io_delay=	[X86] I/O delay method
 		0x80
 			Standard port 0x80 based delay
 		0xed
 			Alternate port 0xed based delay (needed on some systems)
 		udelay
 			Simple two microseconds delay
 		none
 			No delay
 
 	ip=		[IP_PNP]
 			See Documentation/filesystems/nfs/nfsroot.txt.
 
 	irqaffinity=	[SMP] Set the default irq affinity mask
 			The argument is a cpu list, as described above.
 
 	irqfixup	[HW]
 			When an interrupt is not handled search all handlers
 			for it. Intended to get systems with badly broken
 			firmware running.
 
 	irqpoll		[HW]
 			When an interrupt is not handled search all handlers
 			for it. Also check all handlers each timer
 			interrupt. Intended to get systems with badly broken
 			firmware running.
 
 	isapnp=		[ISAPNP]
 			Format: <RDP>,<reset>,<pci_scan>,<verbosity>
 
 	isolcpus=	[KNL,SMP] Isolate CPUs from the general scheduler.
 			The argument is a cpu list, as described above.
 
 			This option can be used to specify one or more CPUs
 			to isolate from the general SMP balancing and scheduling
 			algorithms. You can move a process onto or off an
 			"isolated" CPU via the CPU affinity syscalls or cpuset.
 			<cpu number> begins at 0 and the maximum value is
 			"number of CPUs in system - 1".
 
 			This option is the preferred way to isolate CPUs. The
 			alternative -- manually setting the CPU mask of all
 			tasks in the system -- can cause problems and
 			suboptimal load balancer performance.
 
 	iucv=		[HW,NET]
 
 	ivrs_ioapic	[HW,X86_64]
 			Provide an override to the IOAPIC-ID<->DEVICE-ID
 			mapping provided in the IVRS ACPI table. For
 			example, to map IOAPIC-ID decimal 10 to
 			PCI device 00:14.0 write the parameter as:
 				ivrs_ioapic[10]=00:14.0
 
 	ivrs_hpet	[HW,X86_64]
 			Provide an override to the HPET-ID<->DEVICE-ID
 			mapping provided in the IVRS ACPI table. For
 			example, to map HPET-ID decimal 0 to
 			PCI device 00:14.0 write the parameter as:
 				ivrs_hpet[0]=00:14.0
 
 	ivrs_acpihid	[HW,X86_64]
 			Provide an override to the ACPI-HID:UID<->DEVICE-ID
 			mapping provided in the IVRS ACPI table. For
 			example, to map UART-HID:UID AMD0020:0 to
 			PCI device 00:14.5 write the parameter as:
 				ivrs_acpihid[00:14.5]=AMD0020:0
 
 	js=		[HW,JOY] Analog joystick
 			See Documentation/input/joystick.txt.
 
 	nokaslr		[KNL]
 			When CONFIG_RANDOMIZE_BASE is set, this disables
 			kernel and module base offset ASLR (Address Space
 			Layout Randomization).
 
 	keepinitrd	[HW,ARM]
 
 	kernelcore=	[KNL,X86,IA-64,PPC]
 			Format: nn[KMGTPE] | "mirror"
 			This parameter
 			specifies the amount of memory usable by the kernel
 			for non-movable allocations.  The requested amount is
 			spread evenly throughout all nodes in the system. The
 			remaining memory in each node is used for Movable
 			pages. In the event, a node is too small to have both
 			kernelcore and Movable pages, kernelcore pages will
 			take priority and other nodes will have a larger number
 			of Movable pages.  The Movable zone is used for the
 			allocation of pages that may be reclaimed or moved
 			by the page migration subsystem.  This means that
 			HugeTLB pages may not be allocated from this zone.
 			Note that allocations like PTEs-from-HighMem still
 			use the HighMem zone if it exists, and the Normal
 			zone if it does not.
 
 			Instead of specifying the amount of memory (nn[KMGTPE]),
 			you can specify "mirror" option. In case "mirror"
 			option is specified, mirrored (reliable) memory is used
 			for non-movable allocations and remaining memory is used
 			for Movable pages. nn[KMGTPE] and "mirror" are exclusive,
 			so you can NOT specify nn[KMGTPE] and "mirror" at the same
 			time.
 
 	kgdbdbgp=	[KGDB,HW] kgdb over EHCI usb debug port.
 			Format: <Controller#>[,poll interval]
 			The controller # is the number of the ehci usb debug
 			port as it is probed via PCI.  The poll interval is
 			optional and is the number seconds in between
 			each poll cycle to the debug port in case you need
 			the functionality for interrupting the kernel with
 			gdb or control-c on the dbgp connection.  When
 			not using this parameter you use sysrq-g to break into
 			the kernel debugger.
 
 	kgdboc=		[KGDB,HW] kgdb over consoles.
 			Requires a tty driver that supports console polling,
 			or a supported polling keyboard driver (non-usb).
 			 Serial only format: <serial_device>[,baud]
 			 keyboard only format: kbd
 			 keyboard and serial format: kbd,<serial_device>[,baud]
 			Optional Kernel mode setting:
 			 kms, kbd format: kms,kbd
 			 kms, kbd and serial format: kms,kbd,<ser_dev>[,baud]
 
 	kgdbwait	[KGDB] Stop kernel execution and enter the
 			kernel debugger at the earliest opportunity.
 
 	kmac=		[MIPS] korina ethernet MAC address.
 			Configure the RouterBoard 532 series on-chip
 			Ethernet adapter MAC address.
 
 	kmemleak=	[KNL] Boot-time kmemleak enable/disable
 			Valid arguments: on, off
 			Default: on
 			Built with CONFIG_DEBUG_KMEMLEAK_DEFAULT_OFF=y,
 			the default is off.
 
 	kmemcheck=	[X86] Boot-time kmemcheck enable/disable/one-shot mode
 			Valid arguments: 0, 1, 2
 			kmemcheck=0 (disabled)
 			kmemcheck=1 (enabled)
 			kmemcheck=2 (one-shot mode)
 			Default: 2 (one-shot mode)
 
 	kvm.ignore_msrs=[KVM] Ignore guest accesses to unhandled MSRs.
 			Default is 0 (don't ignore, but inject #GP)
 
 	kvm.mmu_audit=	[KVM] This is a R/W parameter which allows audit
 			KVM MMU at runtime.
 			Default is 0 (off)
 
 	kvm-amd.nested=	[KVM,AMD] Allow nested virtualization in KVM/SVM.
 			Default is 1 (enabled)
 
 	kvm-amd.npt=	[KVM,AMD] Disable nested paging (virtualized MMU)
 			for all guests.
 			Default is 1 (enabled) if in 64-bit or 32-bit PAE mode.
 
 	kvm-intel.ept=	[KVM,Intel] Disable extended page tables
 			(virtualized MMU) support on capable Intel chips.
 			Default is 1 (enabled)
 
 	kvm-intel.emulate_invalid_guest_state=
 			[KVM,Intel] Enable emulation of invalid guest states
 			Default is 0 (disabled)
 
 	kvm-intel.flexpriority=
 			[KVM,Intel] Disable FlexPriority feature (TPR shadow).
 			Default is 1 (enabled)
 
 	kvm-intel.nested=
 			[KVM,Intel] Enable VMX nesting (nVMX).
 			Default is 0 (disabled)
 
 	kvm-intel.unrestricted_guest=
 			[KVM,Intel] Disable unrestricted guest feature
 			(virtualized real and unpaged mode) on capable
 			Intel chips. Default is 1 (enabled)
 
 	kvm-intel.vpid=	[KVM,Intel] Disable Virtual Processor Identification
 			feature (tagged TLBs) on capable Intel chips.
 			Default is 1 (enabled)
 
 	l2cr=		[PPC]
 
 	l3cr=		[PPC]
 
 	lapic		[X86-32,APIC] Enable the local APIC even if BIOS
 			disabled it.
 
 	lapic=		[x86,APIC] "notscdeadline" Do not use TSC deadline
 			value for LAPIC timer one-shot implementation. Default
 			back to the programmable timer unit in the LAPIC.
 
 	lapic_timer_c2_ok	[X86,APIC] trust the local apic timer
 			in C2 power state.
 
 	libata.dma=	[LIBATA] DMA control
 			libata.dma=0	  Disable all PATA and SATA DMA
 			libata.dma=1	  PATA and SATA Disk DMA only
 			libata.dma=2	  ATAPI (CDROM) DMA only
 			libata.dma=4	  Compact Flash DMA only
 			Combinations also work, so libata.dma=3 enables DMA
 			for disks and CDROMs, but not CFs.
 
 	libata.ignore_hpa=	[LIBATA] Ignore HPA limit
 			libata.ignore_hpa=0	  keep BIOS limits (default)
 			libata.ignore_hpa=1	  ignore limits, using full disk
 
 	libata.noacpi	[LIBATA] Disables use of ACPI in libata suspend/resume
 			when set.
 			Format: <int>
 
 	libata.force=	[LIBATA] Force configurations.  The format is comma
 			separated list of "[ID:]VAL" where ID is
 			PORT[.DEVICE].  PORT and DEVICE are decimal numbers
 			matching port, link or device.  Basically, it matches
 			the ATA ID string printed on console by libata.  If
 			the whole ID part is omitted, the last PORT and DEVICE
 			values are used.  If ID hasn't been specified yet, the
 			configuration applies to all ports, links and devices.
 
 			If only DEVICE is omitted, the parameter applies to
 			the port and all links and devices behind it.  DEVICE
 			number of 0 either selects the first device or the
 			first fan-out link behind PMP device.  It does not
 			select the host link.  DEVICE number of 15 selects the
 			host link and device attached to it.
 
 			The VAL specifies the configuration to force.  As long
 			as there's no ambiguity shortcut notation is allowed.
 			For example, both 1.5 and 1.5G would work for 1.5Gbps.
 			The following configurations can be forced.
 
 			* Cable type: 40c, 80c, short40c, unk, ign or sata.
 			  Any ID with matching PORT is used.
 
 			* SATA link speed limit: 1.5Gbps or 3.0Gbps.
 
 			* Transfer mode: pio[0-7], mwdma[0-4] and udma[0-7].
 			  udma[/][16,25,33,44,66,100,133] notation is also
 			  allowed.
 
 			* [no]ncq: Turn on or off NCQ.
 
 			* [no]ncqtrim: Turn off queued DSM TRIM.
 
 			* nohrst, nosrst, norst: suppress hard, soft
                           and both resets.
 
 			* rstonce: only attempt one reset during
 			  hot-unplug link recovery
 
 			* dump_id: dump IDENTIFY data.
 
 			* atapi_dmadir: Enable ATAPI DMADIR bridge support
 
 			* disable: Disable this device.
 
 			If there are multiple matching configurations changing
 			the same attribute, the last one is used.
 
 	memblock=debug	[KNL] Enable memblock debug messages.
 
 	load_ramdisk=	[RAM] List of ramdisks to load from floppy
 			See Documentation/blockdev/ramdisk.txt.
 
 	lockd.nlm_grace_period=P  [NFS] Assign grace period.
 			Format: <integer>
 
 	lockd.nlm_tcpport=N	[NFS] Assign TCP port.
 			Format: <integer>
 
 	lockd.nlm_timeout=T	[NFS] Assign timeout value.
 			Format: <integer>
 
 	lockd.nlm_udpport=M	[NFS] Assign UDP port.
 			Format: <integer>
 
 	locktorture.nreaders_stress= [KNL]
 			Set the number of locking read-acquisition kthreads.
 			Defaults to being automatically set based on the
 			number of online CPUs.
 
 	locktorture.nwriters_stress= [KNL]
 			Set the number of locking write-acquisition kthreads.
 
 	locktorture.onoff_holdoff= [KNL]
 			Set time (s) after boot for CPU-hotplug testing.
 
 	locktorture.onoff_interval= [KNL]
 			Set time (s) between CPU-hotplug operations, or
 			zero to disable CPU-hotplug testing.
 
 	locktorture.shuffle_interval= [KNL]
 			Set task-shuffle interval (jiffies).  Shuffling
 			tasks allows some CPUs to go into dyntick-idle
 			mode during the locktorture test.
 
 	locktorture.shutdown_secs= [KNL]
 			Set time (s) after boot system shutdown.  This
 			is useful for hands-off automated testing.
 
 	locktorture.stat_interval= [KNL]
 			Time (s) between statistics printk()s.
 
 	locktorture.stutter= [KNL]
 			Time (s) to stutter testing, for example,
 			specifying five seconds causes the test to run for
 			five seconds, wait for five seconds, and so on.
 			This tests the locking primitive's ability to
 			transition abruptly to and from idle.
 
 	locktorture.torture_runnable= [BOOT]
 			Start locktorture running at boot time.
 
 	locktorture.torture_type= [KNL]
 			Specify the locking implementation to test.
 
 	locktorture.verbose= [KNL]
 			Enable additional printk() statements.
 
 	logibm.irq=	[HW,MOUSE] Logitech Bus Mouse Driver
 			Format: <irq>
 
 	loglevel=	All Kernel Messages with a loglevel smaller than the
 			console loglevel will be printed to the console. It can
 			also be changed with klogd or other programs. The
 			loglevels are defined as follows:
 
 			0 (KERN_EMERG)		system is unusable
 			1 (KERN_ALERT)		action must be taken immediately
 			2 (KERN_CRIT)		critical conditions
 			3 (KERN_ERR)		error conditions
 			4 (KERN_WARNING)	warning conditions
 			5 (KERN_NOTICE)		normal but significant condition
 			6 (KERN_INFO)		informational
 			7 (KERN_DEBUG)		debug-level messages
 
 	log_buf_len=n[KMG]	Sets the size of the printk ring buffer,
 			in bytes.  n must be a power of two and greater
 			than the minimal size. The minimal size is defined
 			by LOG_BUF_SHIFT kernel config parameter. There is
 			also CONFIG_LOG_CPU_MAX_BUF_SHIFT config parameter
 			that allows to increase the default size depending on
 			the number of CPUs. See init/Kconfig for more details.
 
 	logo.nologo	[FB] Disables display of the built-in Linux logo.
 			This may be used to provide more screen space for
 			kernel log messages and is useful when debugging
 			kernel boot problems.
 
 	lp=0		[LP]	Specify parallel ports to use, e.g,
 	lp=port[,port...]	lp=none,parport0 (lp0 not configured, lp1 uses
 	lp=reset		first parallel port). 'lp=0' disables the
 	lp=auto			printer driver. 'lp=reset' (which can be
 				specified in addition to the ports) causes
 				attached printers to be reset. Using
 				lp=port1,port2,... specifies the parallel ports
 				to associate lp devices with, starting with
 				lp0. A port specification may be 'none' to skip
 				that lp device, or a parport name such as
 				'parport0'. Specifying 'lp=auto' instead of a
 				port specification list means that device IDs
 				from each port should be examined, to see if
 				an IEEE 1284-compliant printer is attached; if
 				so, the driver will manage that printer.
 				See also header of drivers/char/lp.c.
 
 	lpj=n		[KNL]
 			Sets loops_per_jiffy to given constant, thus avoiding
 			time-consuming boot-time autodetection (up to 250 ms per
 			CPU). 0 enables autodetection (default). To determine
 			the correct value for your kernel, boot with normal
 			autodetection and see what value is printed. Note that
 			on SMP systems the preset will be applied to all CPUs,
 			which is likely to cause problems if your CPUs need
 			significantly divergent settings. An incorrect value
 			will cause delays in the kernel to be wrong, leading to
 			unpredictable I/O errors and other breakage. Although
 			unlikely, in the extreme case this might damage your
 			hardware.
 
 	ltpc=		[NET]
 			Format: <io>,<irq>,<dma>
 
 	machvec=	[IA-64] Force the use of a particular machine-vector
 			(machvec) in a generic kernel.
 			Example: machvec=hpzx1_swiotlb
 
 	machtype=	[Loongson] Share the same kernel image file between different
 			 yeeloong laptop.
 			Example: machtype=lemote-yeeloong-2f-7inch
 
 	max_addr=nn[KMG]	[KNL,BOOT,ia64] All physical memory greater
 			than or equal to this physical address is ignored.
 
 	maxcpus=	[SMP] Maximum number of processors that	an SMP kernel
 			will bring up during bootup.  maxcpus=n : n >= 0 limits
 			the kernel to bring up 'n' processors. Surely after
 			bootup you can bring up the other plugged cpu by executing
 			"echo 1 > /sys/devices/system/cpu/cpuX/online". So maxcpus
 			only takes effect during system bootup.
 			While n=0 is a special case, it is equivalent to "nosmp",
 			which also disables the IO APIC.
 
 	max_loop=	[LOOP] The number of loop block devices that get
 	(loop.max_loop)	unconditionally pre-created at init time. The default
 			number is configured by BLK_DEV_LOOP_MIN_COUNT. Instead
 			of statically allocating a predefined number, loop
 			devices can be requested on-demand with the
 			/dev/loop-control interface.
 
 	mce		[X86-32] Machine Check Exception
 
 	mce=option	[X86-64] See Documentation/x86/x86_64/boot-options.txt
 
 	md=		[HW] RAID subsystems devices and level
 			See Documentation/admin-guide/md.rst.
 
 	mdacon=		[MDA]
 			Format: <first>,<last>
 			Specifies range of consoles to be captured by the MDA.
 
 	mem=nn[KMG]	[KNL,BOOT] Force usage of a specific amount of memory
 			Amount of memory to be used when the kernel is not able
 			to see the whole system memory or for test.
 			[X86] Work as limiting max address. Use together
 			with memmap= to avoid physical address space collisions.
 			Without memmap= PCI devices could be placed at addresses
 			belonging to unused RAM.
 
 	mem=nopentium	[BUGS=X86-32] Disable usage of 4MB pages for kernel
 			memory.
 
 	memchunk=nn[KMG]
 			[KNL,SH] Allow user to override the default size for
 			per-device physically contiguous DMA buffers.
 
         memhp_default_state=online/offline
 			[KNL] Set the initial state for the memory hotplug
 			onlining policy. If not specified, the default value is
 			set according to the
 			CONFIG_MEMORY_HOTPLUG_DEFAULT_ONLINE kernel config
 			option.
 			See Documentation/memory-hotplug.txt.
 
 	memmap=exactmap	[KNL,X86] Enable setting of an exact
 			E820 memory map, as specified by the user.
 			Such memmap=exactmap lines can be constructed based on
 			BIOS output or other requirements. See the memmap=nn@ss
 			option description.
 
 	memmap=nn[KMG]@ss[KMG]
 			[KNL] Force usage of a specific region of memory.
 			Region of memory to be used is from ss to ss+nn.
 
 	memmap=nn[KMG]#ss[KMG]
 			[KNL,ACPI] Mark specific memory as ACPI data.
 			Region of memory to be marked is from ss to ss+nn.
 
 	memmap=nn[KMG]$ss[KMG]
 			[KNL,ACPI] Mark specific memory as reserved.
 			Region of memory to be reserved is from ss to ss+nn.
 			Example: Exclude memory from 0x18690000-0x1869ffff
 			         memmap=64K$0x18690000
 			         or
 			         memmap=0x10000$0x18690000
 
 	memmap=nn[KMG]!ss[KMG]
 			[KNL,X86] Mark specific memory as protected.
 			Region of memory to be used, from ss to ss+nn.
 			The memory region may be marked as e820 type 12 (0xc)
 			and is NVDIMM or ADR memory.
 
 	memory_corruption_check=0/1 [X86]
 			Some BIOSes seem to corrupt the first 64k of
 			memory when doing things like suspend/resume.
 			Setting this option will scan the memory
 			looking for corruption.  Enabling this will
 			both detect corruption and prevent the kernel
 			from using the memory being corrupted.
 			However, its intended as a diagnostic tool; if
 			repeatable BIOS-originated corruption always
 			affects the same memory, you can use memmap=
 			to prevent the kernel from using that memory.
 
 	memory_corruption_check_size=size [X86]
 			By default it checks for corruption in the low
 			64k, making this memory unavailable for normal
 			use.  Use this parameter to scan for
 			corruption in more or less memory.
 
 	memory_corruption_check_period=seconds [X86]
 			By default it checks for corruption every 60
 			seconds.  Use this parameter to check at some
 			other rate.  0 disables periodic checking.
 
 	memtest=	[KNL,X86,ARM] Enable memtest
 			Format: <integer>
 			default : 0 <disable>
 			Specifies the number of memtest passes to be
 			performed. Each pass selects another test
 			pattern from a given set of patterns. Memtest
 			fills the memory with this pattern, validates
 			memory contents and reserves bad memory
 			regions that are detected.
 
 	mem_sleep_default=	[SUSPEND] Default system suspend mode:
 			s2idle  - Suspend-To-Idle
 			shallow - Power-On Suspend or equivalent (if supported)
 			deep    - Suspend-To-RAM or equivalent (if supported)
 			See Documentation/power/states.txt.
 
 	meye.*=		[HW] Set MotionEye Camera parameters
 			See Documentation/video4linux/meye.txt.
 
 	mfgpt_irq=	[IA-32] Specify the IRQ to use for the
 			Multi-Function General Purpose Timers on AMD Geode
 			platforms.
 
 	mfgptfix	[X86-32] Fix MFGPT timers on AMD Geode platforms when
 			the BIOS has incorrectly applied a workaround. TinyBIOS
 			version 0.98 is known to be affected, 0.99 fixes the
 			problem by letting the user disable the workaround.
 
 	mga=		[HW,DRM]
 
 	min_addr=nn[KMG]	[KNL,BOOT,ia64] All physical memory below this
 			physical address is ignored.
 
 	mini2440=	[ARM,HW,KNL]
 			Format:[0..2][b][c][t]
 			Default: "0tb"
 			MINI2440 configuration specification:
 			0 - The attached screen is the 3.5" TFT
 			1 - The attached screen is the 7" TFT
 			2 - The VGA Shield is attached (1024x768)
 			Leaving out the screen size parameter will not load
 			the TFT driver, and the framebuffer will be left
 			unconfigured.
 			b - Enable backlight. The TFT backlight pin will be
 			linked to the kernel VESA blanking code and a GPIO
 			LED. This parameter is not necessary when using the
 			VGA shield.
 			c - Enable the s3c camera interface.
 			t - Reserved for enabling touchscreen support. The
 			touchscreen support is not enabled in the mainstream
 			kernel as of 2.6.30, a preliminary port can be found
 			in the "bleeding edge" mini2440 support kernel at
 			http://repo.or.cz/w/linux-2.6/mini2440.git
 
 	mminit_loglevel=
 			[KNL] When CONFIG_DEBUG_MEMORY_INIT is set, this
 			parameter allows control of the logging verbosity for
 			the additional memory initialisation checks. A value
 			of 0 disables mminit logging and a level of 4 will
 			log everything. Information is printed at KERN_DEBUG
 			so loglevel=8 may also need to be specified.
 
 	module.sig_enforce
 			[KNL] When CONFIG_MODULE_SIG is set, this means that
 			modules without (valid) signatures will fail to load.
 			Note that if CONFIG_MODULE_SIG_FORCE is set, that
 			is always true, so this option does nothing.
 
 	module_blacklist=  [KNL] Do not load a comma-separated list of
 			modules.  Useful for debugging problem modules.
 
 	mousedev.tap_time=
 			[MOUSE] Maximum time between finger touching and
 			leaving touchpad surface for touch to be considered
 			a tap and be reported as a left button click (for
 			touchpads working in absolute mode only).
 			Format: <msecs>
 	mousedev.xres=	[MOUSE] Horizontal screen resolution, used for devices
 			reporting absolute coordinates, such as tablets
 	mousedev.yres=	[MOUSE] Vertical screen resolution, used for devices
 			reporting absolute coordinates, such as tablets
 
 	movablecore=nn[KMG]	[KNL,X86,IA-64,PPC] This parameter
 			is similar to kernelcore except it specifies the
 			amount of memory used for migratable allocations.
 			If both kernelcore and movablecore is specified,
 			then kernelcore will be at *least* the specified
 			value but may be more. If movablecore on its own
 			is specified, the administrator must be careful
 			that the amount of memory usable for all allocations
 			is not too small.
 
 	movable_node	[KNL] Boot-time switch to enable the effects
 			of CONFIG_MOVABLE_NODE=y. See mm/Kconfig for details.
 
 	MTD_Partition=	[MTD]
 			Format: <name>,<region-number>,<size>,<offset>
 
 	MTD_Region=	[MTD] Format:
 			<name>,<region-number>[,<base>,<size>,<buswidth>,<altbuswidth>]
 
 	mtdparts=	[MTD]
 			See drivers/mtd/cmdlinepart.c.
 
 	multitce=off	[PPC]  This parameter disables the use of the pSeries
 			firmware feature for updating multiple TCE entries
 			at a time.
 
 	onenand.bdry=	[HW,MTD] Flex-OneNAND Boundary Configuration
 
 			Format: [die0_boundary][,die0_lock][,die1_boundary][,die1_lock]
 
 			boundary - index of last SLC block on Flex-OneNAND.
 				   The remaining blocks are configured as MLC blocks.
 			lock	 - Configure if Flex-OneNAND boundary should be locked.
 				   Once locked, the boundary cannot be changed.
 				   1 indicates lock status, 0 indicates unlock status.
 
 	mtdset=		[ARM]
 			ARM/S3C2412 JIVE boot control
 
 			See arch/arm/mach-s3c2412/mach-jive.c
 
 	mtouchusb.raw_coordinates=
 			[HW] Make the MicroTouch USB driver use raw coordinates
 			('y', default) or cooked coordinates ('n')
 
 	mtrr_chunk_size=nn[KMG] [X86]
 			used for mtrr cleanup. It is largest continuous chunk
 			that could hold holes aka. UC entries.
 
 	mtrr_gran_size=nn[KMG] [X86]
 			Used for mtrr cleanup. It is granularity of mtrr block.
 			Default is 1.
 			Large value could prevent small alignment from
 			using up MTRRs.
 
 	mtrr_spare_reg_nr=n [X86]
 			Format: <integer>
 			Range: 0,7 : spare reg number
 			Default : 1
 			Used for mtrr cleanup. It is spare mtrr entries number.
 			Set to 2 or more if your graphical card needs more.
 
 	n2=		[NET] SDL Inc. RISCom/N2 synchronous serial card
 
 	netdev=		[NET] Network devices parameters
 			Format: <irq>,<io>,<mem_start>,<mem_end>,<name>
 			Note that mem_start is often overloaded to mean
 			something different and driver-specific.
 			This usage is only documented in each driver source
 			file if at all.
 
 	nf_conntrack.acct=
 			[NETFILTER] Enable connection tracking flow accounting
 			0 to disable accounting
 			1 to enable accounting
 			Default value is 0.
 
 	nfsaddrs=	[NFS] Deprecated.  Use ip= instead.
 			See Documentation/filesystems/nfs/nfsroot.txt.
 
 	nfsroot=	[NFS] nfs root filesystem for disk-less boxes.
 			See Documentation/filesystems/nfs/nfsroot.txt.
 
 	nfsrootdebug	[NFS] enable nfsroot debugging messages.
 			See Documentation/filesystems/nfs/nfsroot.txt.
 
 	nfs.callback_nr_threads=
 			[NFSv4] set the total number of threads that the
 			NFS client will assign to service NFSv4 callback
 			requests.
 
 	nfs.callback_tcpport=
 			[NFS] set the TCP port on which the NFSv4 callback
 			channel should listen.
 
 	nfs.cache_getent=
 			[NFS] sets the pathname to the program which is used
 			to update the NFS client cache entries.
 
 	nfs.cache_getent_timeout=
 			[NFS] sets the timeout after which an attempt to
 			update a cache entry is deemed to have failed.
 
 	nfs.idmap_cache_timeout=
 			[NFS] set the maximum lifetime for idmapper cache
 			entries.
 
 	nfs.enable_ino64=
 			[NFS] enable 64-bit inode numbers.
 			If zero, the NFS client will fake up a 32-bit inode
 			number for the readdir() and stat() syscalls instead
 			of returning the full 64-bit number.
 			The default is to return 64-bit inode numbers.
 
 	nfs.max_session_cb_slots=
 			[NFSv4.1] Sets the maximum number of session
 			slots the client will assign to the callback
 			channel. This determines the maximum number of
 			callbacks the client will process in parallel for
 			a particular server.
 
 	nfs.max_session_slots=
 			[NFSv4.1] Sets the maximum number of session slots
 			the client will attempt to negotiate with the server.
 			This limits the number of simultaneous RPC requests
 			that the client can send to the NFSv4.1 server.
 			Note that there is little point in setting this
 			value higher than the max_tcp_slot_table_limit.
 
 	nfs.nfs4_disable_idmapping=
 			[NFSv4] When set to the default of '1', this option
 			ensures that both the RPC level authentication
 			scheme and the NFS level operations agree to use
 			numeric uids/gids if the mount is using the
 			'sec=sys' security flavour. In effect it is
 			disabling idmapping, which can make migration from
 			legacy NFSv2/v3 systems to NFSv4 easier.
 			Servers that do not support this mode of operation
 			will be autodetected by the client, and it will fall
 			back to using the idmapper.
 			To turn off this behaviour, set the value to '0'.
 	nfs.nfs4_unique_id=
 			[NFS4] Specify an additional fixed unique ident-
 			ification string that NFSv4 clients can insert into
 			their nfs_client_id4 string.  This is typically a
 			UUID that is generated at system install time.
 
 	nfs.send_implementation_id =
 			[NFSv4.1] Send client implementation identification
 			information in exchange_id requests.
 			If zero, no implementation identification information
 			will be sent.
 			The default is to send the implementation identification
 			information.
 
 	nfs.recover_lost_locks =
 			[NFSv4] Attempt to recover locks that were lost due
 			to a lease timeout on the server. Please note that
 			doing this risks data corruption, since there are
 			no guarantees that the file will remain unchanged
 			after the locks are lost.
 			If you want to enable the kernel legacy behaviour of
 			attempting to recover these locks, then set this
 			parameter to '1'.
 			The default parameter value of '0' causes the kernel
 			not to attempt recovery of lost locks.
 
 	nfs4.layoutstats_timer =
 			[NFSv4.2] Change the rate at which the kernel sends
 			layoutstats to the pNFS metadata server.
 
 			Setting this to value to 0 causes the kernel to use
 			whatever value is the default set by the layout
 			driver. A non-zero value sets the minimum interval
 			in seconds between layoutstats transmissions.
 
 	nfsd.nfs4_disable_idmapping=
 			[NFSv4] When set to the default of '1', the NFSv4
 			server will return only numeric uids and gids to
 			clients using auth_sys, and will accept numeric uids
 			and gids from such clients.  This is intended to ease
 			migration from NFSv2/v3.
 
 	objlayoutdriver.osd_login_prog=
 			[NFS] [OBJLAYOUT] sets the pathname to the program which
 			is used to automatically discover and login into new
 			osd-targets. Please see:
 			Documentation/filesystems/pnfs.txt for more explanations
 
 	nmi_debug=	[KNL,AVR32,SH] Specify one or more actions to take
 			when a NMI is triggered.
 			Format: [state][,regs][,debounce][,die]
 
 	nmi_watchdog=	[KNL,BUGS=X86] Debugging features for SMP kernels
 			Format: [panic,][nopanic,][num]
 			Valid num: 0 or 1
 			0 - turn hardlockup detector in nmi_watchdog off
 			1 - turn hardlockup detector in nmi_watchdog on
 			When panic is specified, panic when an NMI watchdog
 			timeout occurs (or 'nopanic' to override the opposite
 			default). To disable both hard and soft lockup detectors,
 			please see 'nowatchdog'.
 			This is useful when you use a panic=... timeout and
 			need the box quickly up again.
 
 	netpoll.carrier_timeout=
 			[NET] Specifies amount of time (in seconds) that
 			netpoll should wait for a carrier. By default netpoll
 			waits 4 seconds.
 
 	no387		[BUGS=X86-32] Tells the kernel to use the 387 maths
 			emulation library even if a 387 maths coprocessor
 			is present.
 
 	no_console_suspend
 			[HW] Never suspend the console
 			Disable suspending of consoles during suspend and
 			hibernate operations.  Once disabled, debugging
 			messages can reach various consoles while the rest
 			of the system is being put to sleep (ie, while
 			debugging driver suspend/resume hooks).  This may
 			not work reliably with all consoles, but is known
 			to work with serial and VGA consoles.
 			To facilitate more flexible debugging, we also add
 			console_suspend, a printk module parameter to control
 			it. Users could use console_suspend (usually
 			/sys/module/printk/parameters/console_suspend) to
 			turn on/off it dynamically.
 
 	noaliencache	[MM, NUMA, SLAB] Disables the allocation of alien
 			caches in the slab allocator.  Saves per-node memory,
 			but will impact performance.
 
 	noalign		[KNL,ARM]
 
 	noapic		[SMP,APIC] Tells the kernel to not make use of any
 			IOAPICs that may be present in the system.
 
 	noautogroup	Disable scheduler automatic task group creation.
 
 	nobats		[PPC] Do not use BATs for mapping kernel lowmem
 			on "Classic" PPC cores.
 
 	nocache		[ARM]
 
 	noclflush	[BUGS=X86] Don't use the CLFLUSH instruction
 
 	nodelayacct	[KNL] Disable per-task delay accounting
 
 	nodsp		[SH] Disable hardware DSP at boot time.
 
 	noefi		Disable EFI runtime services support.
 
 	noexec		[IA-64]
 
 	noexec		[X86]
 			On X86-32 available only on PAE configured kernels.
 			noexec=on: enable non-executable mappings (default)
 			noexec=off: disable non-executable mappings
 
 	nosmap		[X86]
 			Disable SMAP (Supervisor Mode Access Prevention)
 			even if it is supported by processor.
 
 	nosmep		[X86]
 			Disable SMEP (Supervisor Mode Execution Prevention)
 			even if it is supported by processor.
 
 	noexec32	[X86-64]
 			This affects only 32-bit executables.
 			noexec32=on: enable non-executable mappings (default)
 				read doesn't imply executable mappings
 			noexec32=off: disable non-executable mappings
 				read implies executable mappings
 
 	nofpu		[MIPS,SH] Disable hardware FPU at boot time.
 
 	nofxsr		[BUGS=X86-32] Disables x86 floating point extended
 			register save and restore. The kernel will only save
 			legacy floating-point registers on task switch.
 
 	nohugeiomap	[KNL,x86] Disable kernel huge I/O mappings.
 
 	nosmt		[KNL,S390] Disable symmetric multithreading (SMT).
 			Equivalent to smt=1.
 
 	noxsave		[BUGS=X86] Disables x86 extended register state save
 			and restore using xsave. The kernel will fallback to
 			enabling legacy floating-point and sse state.
 
 	noxsaveopt	[X86] Disables xsaveopt used in saving x86 extended
 			register states. The kernel will fall back to use
 			xsave to save the states. By using this parameter,
 			performance of saving the states is degraded because
 			xsave doesn't support modified optimization while
 			xsaveopt supports it on xsaveopt enabled systems.
 
 	noxsaves	[X86] Disables xsaves and xrstors used in saving and
 			restoring x86 extended register state in compacted
 			form of xsave area. The kernel will fall back to use
 			xsaveopt and xrstor to save and restore the states
 			in standard form of xsave area. By using this
 			parameter, xsave area per process might occupy more
 			memory on xsaves enabled systems.
 
 	nohlt		[BUGS=ARM,SH] Tells the kernel that the sleep(SH) or
 			wfi(ARM) instruction doesn't work correctly and not to
 			use it. This is also useful when using JTAG debugger.
 
 	no_file_caps	Tells the kernel not to honor file capabilities.  The
 			only way then for a file to be executed with privilege
 			is to be setuid root or executed by root.
 
 	nohalt		[IA-64] Tells the kernel not to use the power saving
 			function PAL_HALT_LIGHT when idle. This increases
 			power-consumption. On the positive side, it reduces
 			interrupt wake-up latency, which may improve performance
 			in certain environments such as networked servers or
 			real-time systems.
 
 	nohibernate	[HIBERNATION] Disable hibernation and resume.
 
 	nohz=		[KNL] Boottime enable/disable dynamic ticks
 			Valid arguments: on, off
 			Default: on
 
 	nohz_full=	[KNL,BOOT]
 			The argument is a cpu list, as described above.
 			In kernels built with CONFIG_NO_HZ_FULL=y, set
 			the specified list of CPUs whose tick will be stopped
 			whenever possible. The boot CPU will be forced outside
 			the range to maintain the timekeeping.
 			The CPUs in this range must also be included in the
 			rcu_nocbs= set.
 
 	noiotrap	[SH] Disables trapped I/O port accesses.
 
 	noirqdebug	[X86-32] Disables the code which attempts to detect and
 			disable unhandled interrupt sources.
 
 	no_timer_check	[X86,APIC] Disables the code which tests for
 			broken timer IRQ sources.
 
 	noisapnp	[ISAPNP] Disables ISA PnP code.
 
 	noinitrd	[RAM] Tells the kernel not to load any configured
 			initial RAM disk.
 
 	nointremap	[X86-64, Intel-IOMMU] Do not enable interrupt
 			remapping.
 			[Deprecated - use intremap=off]
 
 	nointroute	[IA-64]
 
 	noinvpcid	[X86] Disable the INVPCID cpu feature.
 
 	nojitter	[IA-64] Disables jitter checking for ITC timers.
 
 	no-kvmclock	[X86,KVM] Disable paravirtualized KVM clock driver
 
 	no-kvmapf	[X86,KVM] Disable paravirtualized asynchronous page
 			fault handling.
 
 	no-vmw-sched-clock
 			[X86,PV_OPS] Disable paravirtualized VMware scheduler
 			clock and use the default one.
 
 	no-steal-acc    [X86,KVM] Disable paravirtualized steal time accounting.
 			steal time is computed, but won't influence scheduler
 			behaviour
 
 	nolapic		[X86-32,APIC] Do not enable or use the local APIC.
 
 	nolapic_timer	[X86-32,APIC] Do not use the local APIC timer.
 
 	noltlbs		[PPC] Do not use large page/tlb entries for kernel
 			lowmem mapping on PPC40x and PPC8xx
 
 	nomca		[IA-64] Disable machine check abort handling
 
 	nomce		[X86-32] Disable Machine Check Exception
 
 	nomfgpt		[X86-32] Disable Multi-Function General Purpose
 			Timer usage (for AMD Geode machines).
 
 	nonmi_ipi	[X86] Disable using NMI IPIs during panic/reboot to
 			shutdown the other cpus.  Instead use the REBOOT_VECTOR
 			irq.
 
 	nomodule	Disable module load
 
 	nopat		[X86] Disable PAT (page attribute table extension of
 			pagetables) support.
 
 	norandmaps	Don't use address space randomization.  Equivalent to
 			echo 0 > /proc/sys/kernel/randomize_va_space
 
 	noreplace-paravirt	[X86,IA-64,PV_OPS] Don't patch paravirt_ops
 
 	noreplace-smp	[X86-32,SMP] Don't replace SMP instructions
 			with UP alternatives
 
 	nordrand	[X86] Disable kernel use of the RDRAND and
 			RDSEED instructions even if they are supported
 			by the processor.  RDRAND and RDSEED are still
 			available to user space applications.
 
 	noresume	[SWSUSP] Disables resume and restores original swap
 			space.
 
 	no-scroll	[VGA] Disables scrollback.
 			This is required for the Braillex ib80-piezo Braille
 			reader made by F.H. Papenmeier (Germany).
 
 	nosbagart	[IA-64]
 
 	nosep		[BUGS=X86-32] Disables x86 SYSENTER/SYSEXIT support.
 
 	nosmp		[SMP] Tells an SMP kernel to act as a UP kernel,
 			and disable the IO APIC.  legacy for "maxcpus=0".
 
 	nosoftlockup	[KNL] Disable the soft-lockup detector.
 
 	nosync		[HW,M68K] Disables sync negotiation for all devices.
 
 	notsc		[BUGS=X86-32] Disable Time Stamp Counter
 
 	nowatchdog	[KNL] Disable both lockup detectors, i.e.
                         soft-lockup and NMI watchdog (hard-lockup).
 
 	nowb		[ARM]
 
 	nox2apic	[X86-64,APIC] Do not enable x2APIC mode.
 
 	cpu0_hotplug	[X86] Turn on CPU0 hotplug feature when
 			CONFIG_BOOTPARAM_HOTPLUG_CPU0 is off.
 			Some features depend on CPU0. Known dependencies are:
 			1. Resume from suspend/hibernate depends on CPU0.
 			Suspend/hibernate will fail if CPU0 is offline and you
 			need to online CPU0 before suspend/hibernate.
 			2. PIC interrupts also depend on CPU0. CPU0 can't be
 			removed if a PIC interrupt is detected.
 			It's said poweroff/reboot may depend on CPU0 on some
 			machines although I haven't seen such issues so far
 			after CPU0 is offline on a few tested machines.
 			If the dependencies are under your control, you can
 			turn on cpu0_hotplug.
 
 	nptcg=		[IA-64] Override max number of concurrent global TLB
 			purges which is reported from either PAL_VM_SUMMARY or
 			SAL PALO.
 
 	nr_cpus=	[SMP] Maximum number of processors that	an SMP kernel
 			could support.  nr_cpus=n : n >= 1 limits the kernel to
 			support 'n' processors. It could be larger than the
 			number of already plugged CPU during bootup, later in
 			runtime you can physically add extra cpu until it reaches
 			n. So during boot up some boot time memory for per-cpu
 			variables need be pre-allocated for later physical cpu
 			hot plugging.
 
 	nr_uarts=	[SERIAL] maximum number of UARTs to be registered.
 
 	numa_balancing=	[KNL,X86] Enable or disable automatic NUMA balancing.
 			Allowed values are enable and disable
 
 	numa_zonelist_order= [KNL, BOOT] Select zonelist order for NUMA.
 			one of ['zone', 'node', 'default'] can be specified
 			This can be set from sysctl after boot.
 			See Documentation/sysctl/vm.txt for details.
 
 	ohci1394_dma=early	[HW] enable debugging via the ohci1394 driver.
 			See Documentation/debugging-via-ohci1394.txt for more
 			info.
 
 	olpc_ec_timeout= [OLPC] ms delay when issuing EC commands
 			Rather than timing out after 20 ms if an EC
 			command is not properly ACKed, override the length
 			of the timeout.  We have interrupts disabled while
 			waiting for the ACK, so if this is set too high
 			interrupts *may* be lost!
 
 	omap_mux=	[OMAP] Override bootloader pin multiplexing.
 			Format: <mux_mode0.mode_name=value>...
 			For example, to override I2C bus2:
 			omap_mux=i2c2_scl.i2c2_scl=0x100,i2c2_sda.i2c2_sda=0x100
 
 	oprofile.timer=	[HW]
 			Use timer interrupt instead of performance counters
 
 	oprofile.cpu_type=	Force an oprofile cpu type
 			This might be useful if you have an older oprofile
 			userland or if you want common events.
 			Format: { arch_perfmon }
 			arch_perfmon: [X86] Force use of architectural
 				perfmon on Intel CPUs instead of the
 				CPU specific event set.
 			timer: [X86] Force use of architectural NMI
 				timer mode (see also oprofile.timer
 				for generic hr timer mode)
 
 	oops=panic	Always panic on oopses. Default is to just kill the
 			process, but there is a small probability of
 			deadlocking the machine.
 			This will also cause panics on machine check exceptions.
 			Useful together with panic=30 to trigger a reboot.
 
 	OSS		[HW,OSS]
 			See Documentation/sound/oss/oss-parameters.txt
 
 	page_owner=	[KNL] Boot-time page_owner enabling option.
 			Storage of the information about who allocated
 			each page is disabled in default. With this switch,
 			we can turn it on.
 			on: enable the feature
 
 	page_poison=	[KNL] Boot-time parameter changing the state of
 			poisoning on the buddy allocator.
 			off: turn off poisoning
 			on: turn on poisoning
 
 	panic=		[KNL] Kernel behaviour on panic: delay <timeout>
 			timeout > 0: seconds before rebooting
 			timeout = 0: wait forever
 			timeout < 0: reboot immediately
 			Format: <timeout>
 
 	panic_on_warn	panic() instead of WARN().  Useful to cause kdump
 			on a WARN().
 
 	crash_kexec_post_notifiers
 			Run kdump after running panic-notifiers and dumping
 			kmsg. This only for the users who doubt kdump always
 			succeeds in any situation.
 			Note that this also increases risks of kdump failure,
 			because some panic notifiers can make the crashed
 			kernel more unstable.
 
 	parkbd.port=	[HW] Parallel port number the keyboard adapter is
 			connected to, default is 0.
 			Format: <parport#>
 	parkbd.mode=	[HW] Parallel port keyboard adapter mode of operation,
 			0 for XT, 1 for AT (default is AT).
 			Format: <mode>
 
 	parport=	[HW,PPT] Specify parallel ports. 0 disables.
 			Format: { 0 | auto | 0xBBB[,IRQ[,DMA]] }
 			Use 'auto' to force the driver to use any
 			IRQ/DMA settings detected (the default is to
 			ignore detected IRQ/DMA settings because of
 			possible conflicts). You can specify the base
 			address, IRQ, and DMA settings; IRQ and DMA
 			should be numbers, or 'auto' (for using detected
 			settings on that particular port), or 'nofifo'
 			(to avoid using a FIFO even if it is detected).
 			Parallel ports are assigned in the order they
 			are specified on the command line, starting
 			with parport0.
 
 	parport_init_mode=	[HW,PPT]
 			Configure VIA parallel port to operate in
 			a specific mode. This is necessary on Pegasos
 			computer where firmware has no options for setting
 			up parallel port mode and sets it to spp.
 			Currently this function knows 686a and 8231 chips.
 			Format: [spp|ps2|epp|ecp|ecpepp]
 
 	pause_on_oops=
 			Halt all CPUs after the first oops has been printed for
 			the specified number of seconds.  This is to be used if
 			your oopses keep scrolling off the screen.
 
 	pcbit=		[HW,ISDN]
 
 	pcd.		[PARIDE]
 			See header of drivers/block/paride/pcd.c.
 			See also Documentation/blockdev/paride.txt.
 
 	pci=option[,option...]	[PCI] various PCI subsystem options:
 		earlydump	[X86] dump PCI config space before the kernel
 			        changes anything
 		off		[X86] don't probe for the PCI bus
 		bios		[X86-32] force use of PCI BIOS, don't access
 				the hardware directly. Use this if your machine
 				has a non-standard PCI host bridge.
 		nobios		[X86-32] disallow use of PCI BIOS, only direct
 				hardware access methods are allowed. Use this
 				if you experience crashes upon bootup and you
 				suspect they are caused by the BIOS.
 		conf1		[X86] Force use of PCI Configuration Access
 				Mechanism 1 (config address in IO port 0xCF8,
 				data in IO port 0xCFC, both 32-bit).
 		conf2		[X86] Force use of PCI Configuration Access
 				Mechanism 2 (IO port 0xCF8 is an 8-bit port for
 				the function, IO port 0xCFA, also 8-bit, sets
 				bus number. The config space is then accessed
 				through ports 0xC000-0xCFFF).
 				See http://wiki.osdev.org/PCI for more info
 				on the configuration access mechanisms.
 		noaer		[PCIE] If the PCIEAER kernel config parameter is
 				enabled, this kernel boot option can be used to
 				disable the use of PCIE advanced error reporting.
 		nodomains	[PCI] Disable support for multiple PCI
 				root domains (aka PCI segments, in ACPI-speak).
 		nommconf	[X86] Disable use of MMCONFIG for PCI
 				Configuration
 		check_enable_amd_mmconf [X86] check for and enable
 				properly configured MMIO access to PCI
 				config space on AMD family 10h CPU
 		nomsi		[MSI] If the PCI_MSI kernel config parameter is
 				enabled, this kernel boot option can be used to
 				disable the use of MSI interrupts system-wide.
 		noioapicquirk	[APIC] Disable all boot interrupt quirks.
 				Safety option to keep boot IRQs enabled. This
 				should never be necessary.
 		ioapicreroute	[APIC] Enable rerouting of boot IRQs to the
 				primary IO-APIC for bridges that cannot disable
 				boot IRQs. This fixes a source of spurious IRQs
 				when the system masks IRQs.
 		noioapicreroute	[APIC] Disable workaround that uses the
 				boot IRQ equivalent of an IRQ that connects to
 				a chipset where boot IRQs cannot be disabled.
 				The opposite of ioapicreroute.
 		biosirq		[X86-32] Use PCI BIOS calls to get the interrupt
 				routing table. These calls are known to be buggy
 				on several machines and they hang the machine
 				when used, but on other computers it's the only
 				way to get the interrupt routing table. Try
 				this option if the kernel is unable to allocate
 				IRQs or discover secondary PCI buses on your
 				motherboard.
 		rom		[X86] Assign address space to expansion ROMs.
 				Use with caution as certain devices share
 				address decoders between ROMs and other
 				resources.
 		norom		[X86] Do not assign address space to
 				expansion ROMs that do not already have
 				BIOS assigned address ranges.
 		nobar		[X86] Do not assign address space to the
 				BARs that weren't assigned by the BIOS.
 		irqmask=0xMMMM	[X86] Set a bit mask of IRQs allowed to be
 				assigned automatically to PCI devices. You can
 				make the kernel exclude IRQs of your ISA cards
 				this way.
 		pirqaddr=0xAAAAA	[X86] Specify the physical address
 				of the PIRQ table (normally generated
 				by the BIOS) if it is outside the
 				F0000h-100000h range.
 		lastbus=N	[X86] Scan all buses thru bus #N. Can be
 				useful if the kernel is unable to find your
 				secondary buses and you want to tell it
 				explicitly which ones they are.
 		assign-busses	[X86] Always assign all PCI bus
 				numbers ourselves, overriding
 				whatever the firmware may have done.
 		usepirqmask	[X86] Honor the possible IRQ mask stored
 				in the BIOS $PIR table. This is needed on
 				some systems with broken BIOSes, notably
 				some HP Pavilion N5400 and Omnibook XE3
 				notebooks. This will have no effect if ACPI
 				IRQ routing is enabled.
 		noacpi		[X86] Do not use ACPI for IRQ routing
 				or for PCI scanning.
 		use_crs		[X86] Use PCI host bridge window information
 				from ACPI.  On BIOSes from 2008 or later, this
 				is enabled by default.  If you need to use this,
 				please report a bug.
 		nocrs		[X86] Ignore PCI host bridge windows from ACPI.
 			        If you need to use this, please report a bug.
 		routeirq	Do IRQ routing for all PCI devices.
 				This is normally done in pci_enable_device(),
 				so this option is a temporary workaround
 				for broken drivers that don't call it.
 		skip_isa_align	[X86] do not align io start addr, so can
 				handle more pci cards
 		noearly		[X86] Don't do any early type 1 scanning.
 				This might help on some broken boards which
 				machine check when some devices' config space
 				is read. But various workarounds are disabled
 				and some IOMMU drivers will not work.
 		bfsort		Sort PCI devices into breadth-first order.
 				This sorting is done to get a device
 				order compatible with older (<= 2.4) kernels.
 		nobfsort	Don't sort PCI devices into breadth-first order.
 		pcie_bus_tune_off	Disable PCIe MPS (Max Payload Size)
 				tuning and use the BIOS-configured MPS defaults.
 		pcie_bus_safe	Set every device's MPS to the largest value
 				supported by all devices below the root complex.
 		pcie_bus_perf	Set device MPS to the largest allowable MPS
 				based on its parent bus. Also set MRRS (Max
 				Read Request Size) to the largest supported
 				value (no larger than the MPS that the device
 				or bus can support) for best performance.
 		pcie_bus_peer2peer	Set every device's MPS to 128B, which
 				every device is guaranteed to support. This
 				configuration allows peer-to-peer DMA between
 				any pair of devices, possibly at the cost of
 				reduced performance.  This also guarantees
 				that hot-added devices will work.
 		cbiosize=nn[KMG]	The fixed amount of bus space which is
 				reserved for the CardBus bridge's IO window.
 				The default value is 256 bytes.
 		cbmemsize=nn[KMG]	The fixed amount of bus space which is
 				reserved for the CardBus bridge's memory
 				window. The default value is 64 megabytes.
 		resource_alignment=
 				Format:
 				[<order of align>@][<domain>:]<bus>:<slot>.<func>[; ...]
 				[<order of align>@]pci:<vendor>:<device>\
 						[:<subvendor>:<subdevice>][; ...]
 				Specifies alignment and device to reassign
 				aligned memory resources.
 				If <order of align> is not specified,
 				PAGE_SIZE is used as alignment.
 				PCI-PCI bridge can be specified, if resource
 				windows need to be expanded.
 				To specify the alignment for several
 				instances of a device, the PCI vendor,
 				device, subvendor, and subdevice may be
 				specified, e.g., 4096@pci:8086:9c22:103c:198f
 		ecrc=		Enable/disable PCIe ECRC (transaction layer
 				end-to-end CRC checking).
 				bios: Use BIOS/firmware settings. This is the
 				the default.
 				off: Turn ECRC off
 				on: Turn ECRC on.
 		hpiosize=nn[KMG]	The fixed amount of bus space which is
 				reserved for hotplug bridge's IO window.
 				Default size is 256 bytes.
 		hpmemsize=nn[KMG]	The fixed amount of bus space which is
 				reserved for hotplug bridge's memory window.
 				Default size is 2 megabytes.
 		hpbussize=nn	The minimum amount of additional bus numbers
 				reserved for buses below a hotplug bridge.
 				Default is 1.
 		realloc=	Enable/disable reallocating PCI bridge resources
 				if allocations done by BIOS are too small to
 				accommodate resources required by all child
 				devices.
 				off: Turn realloc off
 				on: Turn realloc on
 		realloc		same as realloc=on
 		noari		do not use PCIe ARI.
 		pcie_scan_all	Scan all possible PCIe devices.  Otherwise we
 				only look for one device below a PCIe downstream
 				port.
 
 	pcie_aspm=	[PCIE] Forcibly enable or disable PCIe Active State Power
 			Management.
 		off	Disable ASPM.
 		force	Enable ASPM even on devices that claim not to support it.
 			WARNING: Forcing ASPM on may cause system lockups.
 
 	pcie_hp=	[PCIE] PCI Express Hotplug driver options:
 		nomsi	Do not use MSI for PCI Express Native Hotplug (this
 			makes all PCIe ports use INTx for hotplug services).
 
 	pcie_ports=	[PCIE] PCIe ports handling:
 		auto	Ask the BIOS whether or not to use native PCIe services
 			associated with PCIe ports (PME, hot-plug, AER).  Use
 			them only if that is allowed by the BIOS.
 		native	Use native PCIe services associated with PCIe ports
 			unconditionally.
 		compat	Treat PCIe ports as PCI-to-PCI bridges, disable the PCIe
 			ports driver.
 
 	pcie_port_pm=	[PCIE] PCIe port power management handling:
 		off	Disable power management of all PCIe ports
 		force	Forcibly enable power management of all PCIe ports
 
 	pcie_pme=	[PCIE,PM] Native PCIe PME signaling options:
 		nomsi	Do not use MSI for native PCIe PME signaling (this makes
 			all PCIe root ports use INTx for all services).
 
 	pcmv=		[HW,PCMCIA] BadgePAD 4
 
 	pd_ignore_unused
 			[PM]
 			Keep all power-domains already enabled by bootloader on,
 			even if no driver has claimed them. This is useful
 			for debug and development, but should not be
 			needed on a platform with proper driver support.
 
 	pd.		[PARIDE]
 			See Documentation/blockdev/paride.txt.
 
 	pdcchassis=	[PARISC,HW] Disable/Enable PDC Chassis Status codes at
 			boot time.
 			Format: { 0 | 1 }
 			See arch/parisc/kernel/pdc_chassis.c
 
 	percpu_alloc=	Select which percpu first chunk allocator to use.
 			Currently supported values are "embed" and "page".
 			Archs may support subset or none of the	selections.
 			See comments in mm/percpu.c for details on each
 			allocator.  This parameter is primarily	for debugging
 			and performance comparison.
 
 	pf.		[PARIDE]
 			See Documentation/blockdev/paride.txt.
 
 	pg.		[PARIDE]
 			See Documentation/blockdev/paride.txt.
 
 	pirq=		[SMP,APIC] Manual mp-table setup
 			See Documentation/x86/i386/IO-APIC.txt.
 
 	plip=		[PPT,NET] Parallel port network link
 			Format: { parport<nr> | timid | 0 }
 			See also Documentation/parport.txt.
 
 	pmtmr=		[X86] Manual setup of pmtmr I/O Port.
 			Override pmtimer IOPort with a hex value.
 			e.g. pmtmr=0x508
 
 	pnp.debug=1	[PNP]
 			Enable PNP debug messages (depends on the
 			CONFIG_PNP_DEBUG_MESSAGES option).  Change at run-time
 			via /sys/module/pnp/parameters/debug.  We always show
 			current resource usage; turning this on also shows
 			possible settings and some assignment information.
 
 	pnpacpi=	[ACPI]
 			{ off }
 
 	pnpbios=	[ISAPNP]
 			{ on | off | curr | res | no-curr | no-res }
 
 	pnp_reserve_irq=
 			[ISAPNP] Exclude IRQs for the autoconfiguration
 
 	pnp_reserve_dma=
 			[ISAPNP] Exclude DMAs for the autoconfiguration
 
 	pnp_reserve_io=	[ISAPNP] Exclude I/O ports for the autoconfiguration
 			Ranges are in pairs (I/O port base and size).
 
 	pnp_reserve_mem=
 			[ISAPNP] Exclude memory regions for the
 			autoconfiguration.
 			Ranges are in pairs (memory base and size).
 
 	ports=		[IP_VS_FTP] IPVS ftp helper module
 			Default is 21.
 			Up to 8 (IP_VS_APP_MAX_PORTS) ports
 			may be specified.
 			Format: <port>,<port>....
 
 	powersave=off	[PPC] This option disables power saving features.
 			It specifically disables cpuidle and sets the
 			platform machine description specific power_save
 			function to NULL. On Idle the CPU just reduces
 			execution priority.
 
 	ppc_strict_facility_enable
 			[PPC] This option catches any kernel floating point,
 			Altivec, VSX and SPE outside of regions specifically
 			allowed (eg kernel_enable_fpu()/kernel_disable_fpu()).
 			There is some performance impact when enabling this.
 
 	print-fatal-signals=
 			[KNL] debug: print fatal signals
 
 			If enabled, warn about various signal handling
 			related application anomalies: too many signals,
 			too many POSIX.1 timers, fatal signals causing a
 			coredump - etc.
 
 			If you hit the warning due to signal overflow,
 			you might want to try "ulimit -i unlimited".
 
 			default: off.
 
 	printk.always_kmsg_dump=
 			Trigger kmsg_dump for cases other than kernel oops or
 			panics
 			Format: <bool>  (1/Y/y=enable, 0/N/n=disable)
 			default: disabled
 
 	printk.devkmsg={on,off,ratelimit}
 			Control writing to /dev/kmsg.
 			on - unlimited logging to /dev/kmsg from userspace
 			off - logging to /dev/kmsg disabled
 			ratelimit - ratelimit the logging
 			Default: ratelimit
 
 	printk.time=	Show timing data prefixed to each printk message line
 			Format: <bool>  (1/Y/y=enable, 0/N/n=disable)
 
 	processor.max_cstate=	[HW,ACPI]
 			Limit processor to maximum C-state
 			max_cstate=9 overrides any DMI blacklist limit.
 
 	processor.nocst	[HW,ACPI]
 			Ignore the _CST method to determine C-states,
 			instead using the legacy FADT method
 
 	profile=	[KNL] Enable kernel profiling via /proc/profile
 			Format: [schedule,]<number>
 			Param: "schedule" - profile schedule points.
 			Param: <number> - step/bucket size as a power of 2 for
 				statistical time based profiling.
 			Param: "sleep" - profile D-state sleeping (millisecs).
 				Requires CONFIG_SCHEDSTATS
 			Param: "kvm" - profile VM exits.
 
 	prompt_ramdisk=	[RAM] List of RAM disks to prompt for floppy disk
 			before loading.
 			See Documentation/blockdev/ramdisk.txt.
 
 	psmouse.proto=	[HW,MOUSE] Highest PS2 mouse protocol extension to
 			probe for; one of (bare|imps|exps|lifebook|any).
 	psmouse.rate=	[HW,MOUSE] Set desired mouse report rate, in reports
 			per second.
 	psmouse.resetafter=	[HW,MOUSE]
 			Try to reset the device after so many bad packets
 			(0 = never).
 	psmouse.resolution=
 			[HW,MOUSE] Set desired mouse resolution, in dpi.
 	psmouse.smartscroll=
 			[HW,MOUSE] Controls Logitech smartscroll autorepeat.
 			0 = disabled, 1 = enabled (default).
 
 	pstore.backend=	Specify the name of the pstore backend to use
 
 	pt.		[PARIDE]
 			See Documentation/blockdev/paride.txt.
 
 	pty.legacy_count=
 			[KNL] Number of legacy pty's. Overwrites compiled-in
 			default number.
 
 	quiet		[KNL] Disable most log messages
 
 	r128=		[HW,DRM]
 
 	raid=		[HW,RAID]
 			See Documentation/admin-guide/md.rst.
 
 	ramdisk_size=	[RAM] Sizes of RAM disks in kilobytes
 			See Documentation/blockdev/ramdisk.txt.
 
 	rcu_nocbs=	[KNL]
 			The argument is a cpu list, as described above.
 
 			In kernels built with CONFIG_RCU_NOCB_CPU=y, set
 			the specified list of CPUs to be no-callback CPUs.
 			Invocation of these CPUs' RCU callbacks will
 			be offloaded to "rcuox/N" kthreads created for
 			that purpose, where "x" is "b" for RCU-bh, "p"
 			for RCU-preempt, and "s" for RCU-sched, and "N"
 			is the CPU number.  This reduces OS jitter on the
 			offloaded CPUs, which can be useful for HPC and
 			real-time workloads.  It can also improve energy
 			efficiency for asymmetric multiprocessors.
 
 	rcu_nocb_poll	[KNL]
 			Rather than requiring that offloaded CPUs
 			(specified by rcu_nocbs= above) explicitly
 			awaken the corresponding "rcuoN" kthreads,
 			make these kthreads poll for callbacks.
 			This improves the real-time response for the
 			offloaded CPUs by relieving them of the need to
 			wake up the corresponding kthread, but degrades
 			energy efficiency by requiring that the kthreads
 			periodically wake up to do the polling.
 
 	rcutree.blimit=	[KNL]
 			Set maximum number of finished RCU callbacks to
 			process in one batch.
 
 	rcutree.dump_tree=	[KNL]
 			Dump the structure of the rcu_node combining tree
 			out at early boot.  This is used for diagnostic
 			purposes, to verify correct tree setup.
 
 	rcutree.gp_cleanup_delay=	[KNL]
 			Set the number of jiffies to delay each step of
 			RCU grace-period cleanup.  This only has effect
 			when CONFIG_RCU_TORTURE_TEST_SLOW_CLEANUP is set.
 
 	rcutree.gp_init_delay=	[KNL]
 			Set the number of jiffies to delay each step of
 			RCU grace-period initialization.  This only has
 			effect when CONFIG_RCU_TORTURE_TEST_SLOW_INIT
 			is set.
 
 	rcutree.gp_preinit_delay=	[KNL]
 			Set the number of jiffies to delay each step of
 			RCU grace-period pre-initialization, that is,
 			the propagation of recent CPU-hotplug changes up
 			the rcu_node combining tree.  This only has effect
 			when CONFIG_RCU_TORTURE_TEST_SLOW_PREINIT is set.
 
 	rcutree.rcu_fanout_exact= [KNL]
 			Disable autobalancing of the rcu_node combining
 			tree.  This is used by rcutorture, and might
 			possibly be useful for architectures having high
 			cache-to-cache transfer latencies.
 
 	rcutree.rcu_fanout_leaf= [KNL]
 			Change the number of CPUs assigned to each
 			leaf rcu_node structure.  Useful for very
 			large systems, which will choose the value 64,
 			and for NUMA systems with large remote-access
 			latencies, which will choose a value aligned
 			with the appropriate hardware boundaries.
 
 	rcutree.jiffies_till_sched_qs= [KNL]
 			Set required age in jiffies for a
 			given grace period before RCU starts
 			soliciting quiescent-state help from
 			rcu_note_context_switch().
 
 	rcutree.jiffies_till_first_fqs= [KNL]
 			Set delay from grace-period initialization to
 			first attempt to force quiescent states.
 			Units are jiffies, minimum value is zero,
 			and maximum value is HZ.
 
 	rcutree.jiffies_till_next_fqs= [KNL]
 			Set delay between subsequent attempts to force
 			quiescent states.  Units are jiffies, minimum
 			value is one, and maximum value is HZ.
 
 	rcutree.kthread_prio= 	 [KNL,BOOT]
 			Set the SCHED_FIFO priority of the RCU per-CPU
 			kthreads (rcuc/N). This value is also used for
 			the priority of the RCU boost threads (rcub/N)
 			and for the RCU grace-period kthreads (rcu_bh,
 			rcu_preempt, and rcu_sched). If RCU_BOOST is
 			set, valid values are 1-99 and the default is 1
 			(the least-favored priority).  Otherwise, when
 			RCU_BOOST is not set, valid values are 0-99 and
 			the default is zero (non-realtime operation).
 
 	rcutree.rcu_nocb_leader_stride= [KNL]
 			Set the number of NOCB kthread groups, which
 			defaults to the square root of the number of
 			CPUs.  Larger numbers reduces the wakeup overhead
 			on the per-CPU grace-period kthreads, but increases
 			that same overhead on each group's leader.
 
 	rcutree.qhimark= [KNL]
 			Set threshold of queued RCU callbacks beyond which
 			batch limiting is disabled.
 
 	rcutree.qlowmark= [KNL]
 			Set threshold of queued RCU callbacks below which
 			batch limiting is re-enabled.
 
 	rcutree.rcu_idle_gp_delay= [KNL]
 			Set wakeup interval for idle CPUs that have
 			RCU callbacks (RCU_FAST_NO_HZ=y).
 
 	rcutree.rcu_idle_lazy_gp_delay= [KNL]
 			Set wakeup interval for idle CPUs that have
 			only "lazy" RCU callbacks (RCU_FAST_NO_HZ=y).
 			Lazy RCU callbacks are those which RCU can
 			prove do nothing more than free memory.
 
 	rcutree.rcu_kick_kthreads= [KNL]
 			Cause the grace-period kthread to get an extra
 			wake_up() if it sleeps three times longer than
 			it should at force-quiescent-state time.
 			This wake_up() will be accompanied by a
 			WARN_ONCE() splat and an ftrace_dump().
 
 	rcuperf.gp_exp= [KNL]
 			Measure performance of expedited synchronous
 			grace-period primitives.
 
 	rcuperf.holdoff= [KNL]
 			Set test-start holdoff period.  The purpose of
 			this parameter is to delay the start of the
 			test until boot completes in order to avoid
 			interference.
 
 	rcuperf.nreaders= [KNL]
 			Set number of RCU readers.  The value -1 selects
 			N, where N is the number of CPUs.  A value
 			"n" less than -1 selects N-n+1, where N is again
 			the number of CPUs.  For example, -2 selects N
 			(the number of CPUs), -3 selects N+1, and so on.
 			A value of "n" less than or equal to -N selects
 			a single reader.
 
 	rcuperf.nwriters= [KNL]
 			Set number of RCU writers.  The values operate
 			the same as for rcuperf.nreaders.
 			N, where N is the number of CPUs
 
 	rcuperf.perf_runnable= [BOOT]
 			Start rcuperf running at boot time.
 
 	rcuperf.shutdown= [KNL]
 			Shut the system down after performance tests
 			complete.  This is useful for hands-off automated
 			testing.
 
 	rcuperf.perf_type= [KNL]
 			Specify the RCU implementation to test.
 
 	rcuperf.verbose= [KNL]
 			Enable additional printk() statements.
 
 	rcutorture.cbflood_inter_holdoff= [KNL]
 			Set holdoff time (jiffies) between successive
 			callback-flood tests.
 
 	rcutorture.cbflood_intra_holdoff= [KNL]
 			Set holdoff time (jiffies) between successive
 			bursts of callbacks within a given callback-flood
 			test.
 
 	rcutorture.cbflood_n_burst= [KNL]
 			Set the number of bursts making up a given
 			callback-flood test.  Set this to zero to
 			disable callback-flood testing.
 
 	rcutorture.cbflood_n_per_burst= [KNL]
 			Set the number of callbacks to be registered
 			in a given burst of a callback-flood test.
 
 	rcutorture.fqs_duration= [KNL]
 			Set duration of force_quiescent_state bursts
 			in microseconds.
 
 	rcutorture.fqs_holdoff= [KNL]
 			Set holdoff time within force_quiescent_state bursts
 			in microseconds.
 
 	rcutorture.fqs_stutter= [KNL]
 			Set wait time between force_quiescent_state bursts
 			in seconds.
 
 	rcutorture.gp_cond= [KNL]
 			Use conditional/asynchronous update-side
 			primitives, if available.
 
 	rcutorture.gp_exp= [KNL]
 			Use expedited update-side primitives, if available.
 
 	rcutorture.gp_normal= [KNL]
 			Use normal (non-expedited) asynchronous
 			update-side primitives, if available.
 
 	rcutorture.gp_sync= [KNL]
 			Use normal (non-expedited) synchronous
 			update-side primitives, if available.  If all
 			of rcutorture.gp_cond=, rcutorture.gp_exp=,
 			rcutorture.gp_normal=, and rcutorture.gp_sync=
 			are zero, rcutorture acts as if is interpreted
 			they are all non-zero.
 
 	rcutorture.n_barrier_cbs= [KNL]
 			Set callbacks/threads for rcu_barrier() testing.
 
 	rcutorture.nfakewriters= [KNL]
 			Set number of concurrent RCU writers.  These just
 			stress RCU, they don't participate in the actual
 			test, hence the "fake".
 
 	rcutorture.nreaders= [KNL]
 			Set number of RCU readers.  The value -1 selects
 			N-1, where N is the number of CPUs.  A value
 			"n" less than -1 selects N-n-2, where N is again
 			the number of CPUs.  For example, -2 selects N
 			(the number of CPUs), -3 selects N+1, and so on.
 
 	rcutorture.object_debug= [KNL]
 			Enable debug-object double-call_rcu() testing.
 
 	rcutorture.onoff_holdoff= [KNL]
 			Set time (s) after boot for CPU-hotplug testing.
 
 	rcutorture.onoff_interval= [KNL]
 			Set time (s) between CPU-hotplug operations, or
 			zero to disable CPU-hotplug testing.
 
 	rcutorture.shuffle_interval= [KNL]
 			Set task-shuffle interval (s).  Shuffling tasks
 			allows some CPUs to go into dyntick-idle mode
 			during the rcutorture test.
 
 	rcutorture.shutdown_secs= [KNL]
 			Set time (s) after boot system shutdown.  This
 			is useful for hands-off automated testing.
 
 	rcutorture.stall_cpu= [KNL]
 			Duration of CPU stall (s) to test RCU CPU stall
 			warnings, zero to disable.
 
 	rcutorture.stall_cpu_holdoff= [KNL]
 			Time to wait (s) after boot before inducing stall.
 
 	rcutorture.stat_interval= [KNL]
 			Time (s) between statistics printk()s.
 
 	rcutorture.stutter= [KNL]
 			Time (s) to stutter testing, for example, specifying
 			five seconds causes the test to run for five seconds,
 			wait for five seconds, and so on.  This tests RCU's
 			ability to transition abruptly to and from idle.
 
 	rcutorture.test_boost= [KNL]
 			Test RCU priority boosting?  0=no, 1=maybe, 2=yes.
 			"Maybe" means test if the RCU implementation
 			under test support RCU priority boosting.
 
 	rcutorture.test_boost_duration= [KNL]
 			Duration (s) of each individual boost test.
 
 	rcutorture.test_boost_interval= [KNL]
 			Interval (s) between each boost test.
 
 	rcutorture.test_no_idle_hz= [KNL]
 			Test RCU's dyntick-idle handling.  See also the
 			rcutorture.shuffle_interval parameter.
 
 	rcutorture.torture_runnable= [BOOT]
 			Start rcutorture running at boot time.
 
 	rcutorture.torture_type= [KNL]
 			Specify the RCU implementation to test.
 
 	rcutorture.verbose= [KNL]
 			Enable additional printk() statements.
 
 	rcupdate.rcu_cpu_stall_suppress= [KNL]
 			Suppress RCU CPU stall warning messages.
 
 	rcupdate.rcu_cpu_stall_timeout= [KNL]
 			Set timeout for RCU CPU stall warning messages.
 
 	rcupdate.rcu_expedited= [KNL]
 			Use expedited grace-period primitives, for
 			example, synchronize_rcu_expedited() instead
 			of synchronize_rcu().  This reduces latency,
 			but can increase CPU utilization, degrade
 			real-time latency, and degrade energy efficiency.
 			No effect on CONFIG_TINY_RCU kernels.
 
 	rcupdate.rcu_normal= [KNL]
 			Use only normal grace-period primitives,
 			for example, synchronize_rcu() instead of
 			synchronize_rcu_expedited().  This improves
 			real-time latency, CPU utilization, and
 			energy efficiency, but can expose users to
 			increased grace-period latency.  This parameter
 			overrides rcupdate.rcu_expedited.  No effect on
 			CONFIG_TINY_RCU kernels.
 
 	rcupdate.rcu_normal_after_boot= [KNL]
 			Once boot has completed (that is, after
 			rcu_end_inkernel_boot() has been invoked), use
 			only normal grace-period primitives.  No effect
 			on CONFIG_TINY_RCU kernels.
 
 	rcupdate.rcu_task_stall_timeout= [KNL]
 			Set timeout in jiffies for RCU task stall warning
 			messages.  Disable with a value less than or equal
 			to zero.
 
 	rcupdate.rcu_self_test= [KNL]
 			Run the RCU early boot self tests
 
 	rcupdate.rcu_self_test_bh= [KNL]
 			Run the RCU bh early boot self tests
 
 	rcupdate.rcu_self_test_sched= [KNL]
 			Run the RCU sched early boot self tests
 
 	rdinit=		[KNL]
 			Format: <full_path>
 			Run specified binary instead of /init from the ramdisk,
 			used for early userspace startup. See initrd.
 
 	reboot=		[KNL]
 			Format (x86 or x86_64):
 				[w[arm] | c[old] | h[ard] | s[oft] | g[pio]] \
 				[[,]s[mp]#### \
 				[[,]b[ios] | a[cpi] | k[bd] | t[riple] | e[fi] | p[ci]] \
 				[[,]f[orce]
 			Where reboot_mode is one of warm (soft) or cold (hard) or gpio,
 			      reboot_type is one of bios, acpi, kbd, triple, efi, or pci,
 			      reboot_force is either force or not specified,
 			      reboot_cpu is s[mp]#### with #### being the processor
 					to be used for rebooting.
 
 	relax_domain_level=
 			[KNL, SMP] Set scheduler's default relax_domain_level.
 			See Documentation/cgroup-v1/cpusets.txt.
 
 	reserve=	[KNL,BUGS] Force the kernel to ignore some iomem area
 
 	reservetop=	[X86-32]
 			Format: nn[KMG]
 			Reserves a hole at the top of the kernel virtual
 			address space.
 
 	reservelow=	[X86]
 			Format: nn[K]
 			Set the amount of memory to reserve for BIOS at
 			the bottom of the address space.
 
 	reset_devices	[KNL] Force drivers to reset the underlying device
 			during initialization.
 
 	resume=		[SWSUSP]
 			Specify the partition device for software suspend
 			Format:
 			{/dev/<dev> | PARTUUID=<uuid> | <int>:<int> | <hex>}
 
 	resume_offset=	[SWSUSP]
 			Specify the offset from the beginning of the partition
 			given by "resume=" at which the swap header is located,
 			in <PAGE_SIZE> units (needed only for swap files).
 			See  Documentation/power/swsusp-and-swap-files.txt
 
 	resumedelay=	[HIBERNATION] Delay (in seconds) to pause before attempting to
 			read the resume files
 
 	resumewait	[HIBERNATION] Wait (indefinitely) for resume device to show up.
 			Useful for devices that are detected asynchronously
 			(e.g. USB and MMC devices).
 
 	hibernate=	[HIBERNATION]
 		noresume	Don't check if there's a hibernation image
 				present during boot.
 		nocompress	Don't compress/decompress hibernation images.
 		no		Disable hibernation and resume.
 		protect_image	Turn on image protection during restoration
 				(that will set all pages holding image data
 				during restoration read-only).
 
 	retain_initrd	[RAM] Keep initrd memory after extraction
 
 	rfkill.default_state=
 		0	"airplane mode".  All wifi, bluetooth, wimax, gps, fm,
 			etc. communication is blocked by default.
 		1	Unblocked.
 
 	rfkill.master_switch_mode=
 		0	The "airplane mode" button does nothing.
 		1	The "airplane mode" button toggles between everything
 			blocked and the previous configuration.
 		2	The "airplane mode" button toggles between everything
 			blocked and everything unblocked.
 
 	rhash_entries=	[KNL,NET]
 			Set number of hash buckets for route cache
 
 	ring3mwait=disable
 			[KNL] Disable ring 3 MONITOR/MWAIT feature on supported
 			CPUs.
 
 	ro		[KNL] Mount root device read-only on boot
 
 	rodata=		[KNL]
 		on	Mark read-only kernel memory as read-only (default).
 		off	Leave read-only kernel memory writable for debugging.
 
 	rockchip.usb_uart
 			Enable the uart passthrough on the designated usb port
 			on Rockchip SoCs. When active, the signals of the
 			debug-uart get routed to the D+ and D- pins of the usb
 			port and the regular usb controller gets disabled.
 
 	root=		[KNL] Root filesystem
 			See name_to_dev_t comment in init/do_mounts.c.
 
 	rootdelay=	[KNL] Delay (in seconds) to pause before attempting to
 			mount the root filesystem
 
 	rootflags=	[KNL] Set root filesystem mount option string
 
 	rootfstype=	[KNL] Set root filesystem type
 
 	rootwait	[KNL] Wait (indefinitely) for root device to show up.
 			Useful for devices that are detected asynchronously
 			(e.g. USB and MMC devices).
 
 	rproc_mem=nn[KMG][@address]
 			[KNL,ARM,CMA] Remoteproc physical memory block.
 			Memory area to be used by remote processor image,
 			managed by CMA.
 
 	rw		[KNL] Mount root device read-write on boot
 
 	S		[KNL] Run init in single mode
 
 	s390_iommu=	[HW,S390]
 			Set s390 IOTLB flushing mode
 		strict
 			With strict flushing every unmap operation will result in
 			an IOTLB flush. Default is lazy flushing before reuse,
 			which is faster.
 
 	sa1100ir	[NET]
 			See drivers/net/irda/sa1100_ir.c.
 
 	sbni=		[NET] Granch SBNI12 leased line adapter
 
 	sched_debug	[KNL] Enables verbose scheduler debug messages.
 
 	schedstats=	[KNL,X86] Enable or disable scheduled statistics.
 			Allowed values are enable and disable. This feature
 			incurs a small amount of overhead in the scheduler
 			but is useful for debugging and performance tuning.
 
 	skew_tick=	[KNL] Offset the periodic timer tick per cpu to mitigate
 			xtime_lock contention on larger systems, and/or RCU lock
 			contention on all systems with CONFIG_MAXSMP set.
 			Format: { "0" | "1" }
 			0 -- disable. (may be 1 via CONFIG_CMDLINE="skew_tick=1"
 			1 -- enable.
 			Note: increases power consumption, thus should only be
 			enabled if running jitter sensitive (HPC/RT) workloads.
 
 	security=	[SECURITY] Choose a security module to enable at boot.
 			If this boot parameter is not specified, only the first
 			security module asking for security registration will be
 			loaded. An invalid security module name will be treated
 			as if no module has been chosen.
 
 	selinux=	[SELINUX] Disable or enable SELinux at boot time.
 			Format: { "0" | "1" }
 			See security/selinux/Kconfig help text.
 			0 -- disable.
 			1 -- enable.
 			Default value is set via kernel config option.
 			If enabled at boot time, /selinux/disable can be used
 			later to disable prior to initial policy load.
 
 	apparmor=	[APPARMOR] Disable or enable AppArmor at boot time
 			Format: { "0" | "1" }
 			See security/apparmor/Kconfig help text
 			0 -- disable.
 			1 -- enable.
 			Default value is set via kernel config option.
 
 	serialnumber	[BUGS=X86-32]
 
 	shapers=	[NET]
 			Maximal number of shapers.
 
 	simeth=		[IA-64]
 	simscsi=
 
 	slram=		[HW,MTD]
 
 	slab_nomerge	[MM]
 			Disable merging of slabs with similar size. May be
 			necessary if there is some reason to distinguish
 			allocs to different slabs. Debug options disable
 			merging on their own.
 			For more information see Documentation/vm/slub.txt.
 
 	slab_max_order=	[MM, SLAB]
 			Determines the maximum allowed order for slabs.
 			A high setting may cause OOMs due to memory
 			fragmentation.  Defaults to 1 for systems with
 			more than 32MB of RAM, 0 otherwise.
 
 	slub_debug[=options[,slabs]]	[MM, SLUB]
 			Enabling slub_debug allows one to determine the
 			culprit if slab objects become corrupted. Enabling
 			slub_debug can create guard zones around objects and
 			may poison objects when not in use. Also tracks the
 			last alloc / free. For more information see
 			Documentation/vm/slub.txt.
 
 	slub_max_order= [MM, SLUB]
 			Determines the maximum allowed order for slabs.
 			A high setting may cause OOMs due to memory
 			fragmentation. For more information see
 			Documentation/vm/slub.txt.
 
 	slub_min_objects=	[MM, SLUB]
 			The minimum number of objects per slab. SLUB will
 			increase the slab order up to slub_max_order to
 			generate a sufficiently large slab able to contain
 			the number of objects indicated. The higher the number
 			of objects the smaller the overhead of tracking slabs
 			and the less frequently locks need to be acquired.
 			For more information see Documentation/vm/slub.txt.
 
 	slub_min_order=	[MM, SLUB]
 			Determines the minimum page order for slabs. Must be
 			lower than slub_max_order.
 			For more information see Documentation/vm/slub.txt.
 
 	slub_nomerge	[MM, SLUB]
 			Same with slab_nomerge. This is supported for legacy.
 			See slab_nomerge for more information.
 
 	smart2=		[HW]
 			Format: <io1>[,<io2>[,...,<io8>]]
 
 	smsc-ircc2.nopnp	[HW] Don't use PNP to discover SMC devices
 	smsc-ircc2.ircc_cfg=	[HW] Device configuration I/O port
 	smsc-ircc2.ircc_sir=	[HW] SIR base I/O port
 	smsc-ircc2.ircc_fir=	[HW] FIR base I/O port
 	smsc-ircc2.ircc_irq=	[HW] IRQ line
 	smsc-ircc2.ircc_dma=	[HW] DMA channel
 	smsc-ircc2.ircc_transceiver= [HW] Transceiver type:
 				0: Toshiba Satellite 1800 (GP data pin select)
 				1: Fast pin select (default)
 				2: ATC IRMode
 
 	smt		[KNL,S390] Set the maximum number of threads (logical
 			CPUs) to use per physical CPU on systems capable of
 			symmetric multithreading (SMT). Will be capped to the
 			actual hardware limit.
 			Format: <integer>
 			Default: -1 (no limit)
 
 	softlockup_panic=
 			[KNL] Should the soft-lockup detector generate panics.
 			Format: <integer>
 
 	softlockup_all_cpu_backtrace=
 			[KNL] Should the soft-lockup detector generate
 			backtraces on all cpus.
 			Format: <integer>
 
 	sonypi.*=	[HW] Sony Programmable I/O Control Device driver
 			See Documentation/laptops/sonypi.txt
 
 	spia_io_base=	[HW,MTD]
 	spia_fio_base=
 	spia_pedr=
 	spia_peddr=
 
 	stacktrace	[FTRACE]
 			Enabled the stack tracer on boot up.
 
 	stacktrace_filter=[function-list]
 			[FTRACE] Limit the functions that the stack tracer
 			will trace at boot up. function-list is a comma separated
 			list of functions. This list can be changed at run
 			time by the stack_trace_filter file in the debugfs
 			tracing directory. Note, this enables stack tracing
 			and the stacktrace above is not needed.
 
 	sti=		[PARISC,HW]
 			Format: <num>
 			Set the STI (builtin display/keyboard on the HP-PARISC
 			machines) console (graphic card) which should be used
 			as the initial boot-console.
 			See also comment in drivers/video/console/sticore.c.
 
 	sti_font=	[HW]
 			See comment in drivers/video/console/sticore.c.
 
 	stifb=		[HW]
 			Format: bpp:<bpp1>[:<bpp2>[:<bpp3>...]]
 
 	sunrpc.min_resvport=
 	sunrpc.max_resvport=
 			[NFS,SUNRPC]
 			SunRPC servers often require that client requests
 			originate from a privileged port (i.e. a port in the
 			range 0 < portnr < 1024).
 			An administrator who wishes to reserve some of these
 			ports for other uses may adjust the range that the
 			kernel's sunrpc client considers to be privileged
 			using these two parameters to set the minimum and
 			maximum port values.
 
 	sunrpc.svc_rpc_per_connection_limit=
 			[NFS,SUNRPC]
 			Limit the number of requests that the server will
 			process in parallel from a single connection.
 			The default value is 0 (no limit).
 
 	sunrpc.pool_mode=
 			[NFS]
 			Control how the NFS server code allocates CPUs to
 			service thread pools.  Depending on how many NICs
 			you have and where their interrupts are bound, this
 			option will affect which CPUs will do NFS serving.
 			Note: this parameter cannot be changed while the
 			NFS server is running.
 
 			auto	    the server chooses an appropriate mode
 				    automatically using heuristics
 			global	    a single global pool contains all CPUs
 			percpu	    one pool for each CPU
 			pernode	    one pool for each NUMA node (equivalent
 				    to global on non-NUMA machines)
 
 	sunrpc.tcp_slot_table_entries=
 	sunrpc.udp_slot_table_entries=
 			[NFS,SUNRPC]
 			Sets the upper limit on the number of simultaneous
 			RPC calls that can be sent from the client to a
 			server. Increasing these values may allow you to
 			improve throughput, but will also increase the
 			amount of memory reserved for use by the client.
 
 	suspend.pm_test_delay=
 			[SUSPEND]
 			Sets the number of seconds to remain in a suspend test
 			mode before resuming the system (see
 			/sys/power/pm_test). Only available when CONFIG_PM_DEBUG
 			is set. Default value is 5.
 
 	swapaccount=[0|1]
 			[KNL] Enable accounting of swap in memory resource
 			controller if no parameter or 1 is given or disable
 			it if 0 is given (See Documentation/cgroup-v1/memory.txt)
 
 	swiotlb=	[ARM,IA-64,PPC,MIPS,X86]
 			Format: { <int> | force | noforce }
 			<int> -- Number of I/O TLB slabs
 			force -- force using of bounce buffers even if they
 			         wouldn't be automatically used by the kernel
 			noforce -- Never use bounce buffers (for debugging)
 
 	switches=	[HW,M68k]
 
 	sysfs.deprecated=0|1 [KNL]
 			Enable/disable old style sysfs layout for old udev
 			on older distributions. When this option is enabled
 			very new udev will not work anymore. When this option
 			is disabled (or CONFIG_SYSFS_DEPRECATED not compiled)
 			in older udev will not work anymore.
 			Default depends on CONFIG_SYSFS_DEPRECATED_V2 set in
 			the kernel configuration.
 
 	sysrq_always_enabled
 			[KNL]
 			Ignore sysrq setting - this boot parameter will
 			neutralize any effect of /proc/sys/kernel/sysrq.
 			Useful for debugging.
 
 	tcpmhash_entries= [KNL,NET]
 			Set the number of tcp_metrics_hash slots.
 			Default value is 8192 or 16384 depending on total
 			ram pages. This is used to specify the TCP metrics
 			cache size. See Documentation/networking/ip-sysctl.txt
 			"tcp_no_metrics_save" section for more details.
 
 	tdfx=		[HW,DRM]
 
 	test_suspend=	[SUSPEND][,N]
 			Specify "mem" (for Suspend-to-RAM) or "standby" (for
 			standby suspend) or "freeze" (for suspend type freeze)
 			as the system sleep state during system startup with
 			the optional capability to repeat N number of times.
 			The system is woken from this state using a
 			wakeup-capable RTC alarm.
 
 	thash_entries=	[KNL,NET]
 			Set number of hash buckets for TCP connection
 
 	thermal.act=	[HW,ACPI]
 			-1: disable all active trip points in all thermal zones
 			<degrees C>: override all lowest active trip points
 
 	thermal.crt=	[HW,ACPI]
 			-1: disable all critical trip points in all thermal zones
 			<degrees C>: override all critical trip points
 
 	thermal.nocrt=	[HW,ACPI]
 			Set to disable actions on ACPI thermal zone
 			critical and hot trip points.
 
 	thermal.off=	[HW,ACPI]
 			1: disable ACPI thermal control
 
 	thermal.psv=	[HW,ACPI]
 			-1: disable all passive trip points
 			<degrees C>: override all passive trip points to this
 			value
 
 	thermal.tzp=	[HW,ACPI]
 			Specify global default ACPI thermal zone polling rate
 			<deci-seconds>: poll all this frequency
 			0: no polling (default)
 
 	threadirqs	[KNL]
 			Force threading of all interrupt handlers except those
 			marked explicitly IRQF_NO_THREAD.
 
 	tmem		[KNL,XEN]
 			Enable the Transcendent memory driver if built-in.
 
 	tmem.cleancache=0|1 [KNL, XEN]
 			Default is on (1). Disable the usage of the cleancache
 			API to send anonymous pages to the hypervisor.
 
 	tmem.frontswap=0|1 [KNL, XEN]
 			Default is on (1). Disable the usage of the frontswap
 			API to send swap pages to the hypervisor. If disabled
 			the selfballooning and selfshrinking are force disabled.
 
 	tmem.selfballooning=0|1 [KNL, XEN]
 			Default is on (1). Disable the driving of swap pages
 			to the hypervisor.
 
 	tmem.selfshrinking=0|1 [KNL, XEN]
 			Default is on (1). Partial swapoff that immediately
 			transfers pages from Xen hypervisor back to the
 			kernel based on different criteria.
 
 	topology=	[S390]
 			Format: {off | on}
 			Specify if the kernel should make use of the cpu
 			topology information if the hardware supports this.
 			The scheduler will make use of this information and
 			e.g. base its process migration decisions on it.
 			Default is on.
 
 	topology_updates= [KNL, PPC, NUMA]
 			Format: {off}
 			Specify if the kernel should ignore (off)
 			topology updates sent by the hypervisor to this
 			LPAR.
 
 	tp720=		[HW,PS2]
 
 	tpm_suspend_pcr=[HW,TPM]
 			Format: integer pcr id
 			Specify that at suspend time, the tpm driver
 			should extend the specified pcr with zeros,
 			as a workaround for some chips which fail to
 			flush the last written pcr on TPM_SaveState.
 			This will guarantee that all the other pcrs
 			are saved.
 
 	trace_buf_size=nn[KMG]
 			[FTRACE] will set tracing buffer size on each cpu.
 
 	trace_event=[event-list]
 			[FTRACE] Set and start specified trace events in order
 			to facilitate early boot debugging. The event-list is a
 			comma separated list of trace events to enable. See
 			also Documentation/trace/events.txt
 
 	trace_options=[option-list]
 			[FTRACE] Enable or disable tracer options at boot.
 			The option-list is a comma delimited list of options
 			that can be enabled or disabled just as if you were
 			to echo the option name into
 
 			    /sys/kernel/debug/tracing/trace_options
 
 			For example, to enable stacktrace option (to dump the
 			stack trace of each event), add to the command line:
 
 			      trace_options=stacktrace
 
 			See also Documentation/trace/ftrace.txt "trace options"
 			section.
 
 	tp_printk[FTRACE]
 			Have the tracepoints sent to printk as well as the
 			tracing ring buffer. This is useful for early boot up
 			where the system hangs or reboots and does not give the
 			option for reading the tracing buffer or performing a
 			ftrace_dump_on_oops.
 
 			To turn off having tracepoints sent to printk,
 			 echo 0 > /proc/sys/kernel/tracepoint_printk
 			Note, echoing 1 into this file without the
 			tracepoint_printk kernel cmdline option has no effect.
 
 			** CAUTION **
 
 			Having tracepoints sent to printk() and activating high
 			frequency tracepoints such as irq or sched, can cause
 			the system to live lock.
 
 	traceoff_on_warning
 			[FTRACE] enable this option to disable tracing when a
 			warning is hit. This turns off "tracing_on". Tracing can
 			be enabled again by echoing '1' into the "tracing_on"
 			file located in /sys/kernel/debug/tracing/
 
 			This option is useful, as it disables the trace before
 			the WARNING dump is called, which prevents the trace to
 			be filled with content caused by the warning output.
 
 			This option can also be set at run time via the sysctl
 			option:  kernel/traceoff_on_warning
 
 	transparent_hugepage=
 			[KNL]
 			Format: [always|madvise|never]
 			Can be used to control the default behavior of the system
 			with respect to transparent hugepages.
 			See Documentation/vm/transhuge.txt for more details.
 
 	tsc=		Disable clocksource stability checks for TSC.
 			Format: <string>
 			[x86] reliable: mark tsc clocksource as reliable, this
 			disables clocksource verification at runtime, as well
 			as the stability checks done at bootup.	Used to enable
 			high-resolution timer mode on older hardware, and in
 			virtualized environment.
 			[x86] noirqtime: Do not use TSC to do irq accounting.
 			Used to run time disable IRQ_TIME_ACCOUNTING on any
 			platforms where RDTSC is slow and this accounting
 			can add overhead.
 
 	turbografx.map[2|3]=	[HW,JOY]
 			TurboGraFX parallel port interface
 			Format:
 			<port#>,<js1>,<js2>,<js3>,<js4>,<js5>,<js6>,<js7>
 			See also Documentation/input/joystick-parport.txt
 
 	udbg-immortal	[PPC] When debugging early kernel crashes that
 			happen after console_init() and before a proper
 			console driver takes over, this boot options might
 			help "seeing" what's going on.
 
 	uhash_entries=	[KNL,NET]
 			Set number of hash buckets for UDP/UDP-Lite connections
 
 	uhci-hcd.ignore_oc=
 			[USB] Ignore overcurrent events (default N).
 			Some badly-designed motherboards generate lots of
 			bogus events, for ports that aren't wired to
 			anything.  Set this parameter to avoid log spamming.
 			Note that genuine overcurrent events won't be
 			reported either.
 
 	unknown_nmi_panic
 			[X86] Cause panic on unknown NMI.
 
 	usbcore.authorized_default=
 			[USB] Default USB device authorization:
 			(default -1 = authorized except for wireless USB,
 			0 = not authorized, 1 = authorized)
 
 	usbcore.autosuspend=
 			[USB] The autosuspend time delay (in seconds) used
 			for newly-detected USB devices (default 2).  This
 			is the time required before an idle device will be
 			autosuspended.  Devices for which the delay is set
 			to a negative value won't be autosuspended at all.
 
 	usbcore.usbfs_snoop=
 			[USB] Set to log all usbfs traffic (default 0 = off).
 
 	usbcore.usbfs_snoop_max=
 			[USB] Maximum number of bytes to snoop in each URB
 			(default = 65536).
 
 	usbcore.blinkenlights=
 			[USB] Set to cycle leds on hubs (default 0 = off).
 
 	usbcore.old_scheme_first=
 			[USB] Start with the old device initialization
 			scheme (default 0 = off).
 
 	usbcore.usbfs_memory_mb=
 			[USB] Memory limit (in MB) for buffers allocated by
 			usbfs (default = 16, 0 = max = 2047).
 
 	usbcore.use_both_schemes=
 			[USB] Try the other device initialization scheme
 			if the first one fails (default 1 = enabled).
 
 	usbcore.initial_descriptor_timeout=
 			[USB] Specifies timeout for the initial 64-byte
                         USB_REQ_GET_DESCRIPTOR request in milliseconds
 			(default 5000 = 5.0 seconds).
 
 	usbcore.nousb	[USB] Disable the USB subsystem
 
 	usbhid.mousepoll=
 			[USBHID] The interval which mice are to be polled at.
 
 	usb-storage.delay_use=
 			[UMS] The delay in seconds before a new device is
 			scanned for Logical Units (default 1).
 
 	usb-storage.quirks=
 			[UMS] A list of quirks entries to supplement or
 			override the built-in unusual_devs list.  List
 			entries are separated by commas.  Each entry has
 			the form VID:PID:Flags where VID and PID are Vendor
 			and Product ID values (4-digit hex numbers) and
 			Flags is a set of characters, each corresponding
 			to a common usb-storage quirk flag as follows:
 				a = SANE_SENSE (collect more than 18 bytes
 					of sense data);
 				b = BAD_SENSE (don't collect more than 18
 					bytes of sense data);
 				c = FIX_CAPACITY (decrease the reported
 					device capacity by one sector);
 				d = NO_READ_DISC_INFO (don't use
 					READ_DISC_INFO command);
 				e = NO_READ_CAPACITY_16 (don't use
 					READ_CAPACITY_16 command);
 				f = NO_REPORT_OPCODES (don't use report opcodes
 					command, uas only);
 				g = MAX_SECTORS_240 (don't transfer more than
 					240 sectors at a time, uas only);
 				h = CAPACITY_HEURISTICS (decrease the
 					reported device capacity by one
 					sector if the number is odd);
 				i = IGNORE_DEVICE (don't bind to this
 					device);
 				j = NO_REPORT_LUNS (don't use report luns
 					command, uas only);
 				l = NOT_LOCKABLE (don't try to lock and
 					unlock ejectable media);
 				m = MAX_SECTORS_64 (don't transfer more
 					than 64 sectors = 32 KB at a time);
 				n = INITIAL_READ10 (force a retry of the
 					initial READ(10) command);
 				o = CAPACITY_OK (accept the capacity
 					reported by the device);
 				p = WRITE_CACHE (the device cache is ON
 					by default);
 				r = IGNORE_RESIDUE (the device reports
 					bogus residue values);
 				s = SINGLE_LUN (the device has only one
 					Logical Unit);
 				t = NO_ATA_1X (don't allow ATA(12) and ATA(16)
 					commands, uas only);
 				u = IGNORE_UAS (don't bind to the uas driver);
 				w = NO_WP_DETECT (don't test whether the
 					medium is write-protected).
 				y = ALWAYS_SYNC (issue a SYNCHRONIZE_CACHE
 					even if the device claims no cache)
 			Example: quirks=0419:aaf5:rl,0421:0433:rc
 
 	user_debug=	[KNL,ARM]
 			Format: <int>
 			See arch/arm/Kconfig.debug help text.
 				 1 - undefined instruction events
 				 2 - system calls
 				 4 - invalid data aborts
 				 8 - SIGSEGV faults
 				16 - SIGBUS faults
 			Example: user_debug=31
 
 	userpte=
 			[X86] Flags controlling user PTE allocations.
 
 				nohigh = do not allocate PTE pages in
 					HIGHMEM regardless of setting
 					of CONFIG_HIGHPTE.
 
 	vdso=		[X86,SH]
 			On X86_32, this is an alias for vdso32=.  Otherwise:
 
 			vdso=1: enable VDSO (the default)
 			vdso=0: disable VDSO mapping
 
 	vdso32=		[X86] Control the 32-bit vDSO
 			vdso32=1: enable 32-bit VDSO
 			vdso32=0 or vdso32=2: disable 32-bit VDSO
 
 			See the help text for CONFIG_COMPAT_VDSO for more
 			details.  If CONFIG_COMPAT_VDSO is set, the default is
 			vdso32=0; otherwise, the default is vdso32=1.
 
 			For compatibility with older kernels, vdso32=2 is an
 			alias for vdso32=0.
 
 			Try vdso32=0 if you encounter an error that says:
 			dl_main: Assertion `(void *) ph->p_vaddr == _rtld_local._dl_sysinfo_dso' failed!
 
 	vector=		[IA-64,SMP]
 			vector=percpu: enable percpu vector domain
 
 	video=		[FB] Frame buffer configuration
 			See Documentation/fb/modedb.txt.
 
 	video.brightness_switch_enabled= [0,1]
 			If set to 1, on receiving an ACPI notify event
 			generated by hotkey, video driver will adjust brightness
 			level and then send out the event to user space through
 			the allocated input device; If set to 0, video driver
 			will only send out the event without touching backlight
 			brightness level.
 			default: 1
 
 	virtio_mmio.device=
 			[VMMIO] Memory mapped virtio (platform) device.
 
 				<size>@<baseaddr>:<irq>[:<id>]
 			where:
 				<size>     := size (can use standard suffixes
 						like K, M and G)
 				<baseaddr> := physical base address
 				<irq>      := interrupt number (as passed to
 						request_irq())
 				<id>       := (optional) platform device id
 			example:
 				virtio_mmio.device=1K@0x100b0000:48:7
 
 			Can be used multiple times for multiple devices.
 
 	vga=		[BOOT,X86-32] Select a particular video mode
 			See Documentation/x86/boot.txt and
 			Documentation/svga.txt.
 			Use vga=ask for menu.
 			This is actually a boot loader parameter; the value is
 			passed to the kernel using a special protocol.
 
 	vmalloc=nn[KMG]	[KNL,BOOT] Forces the vmalloc area to have an exact
 			size of <nn>. This can be used to increase the
 			minimum size (128MB on x86). It can also be used to
 			decrease the size and leave more room for directly
 			mapped kernel RAM.
 
 	vmhalt=		[KNL,S390] Perform z/VM CP command after system halt.
 			Format: <command>
 
 	vmpanic=	[KNL,S390] Perform z/VM CP command after kernel panic.
 			Format: <command>
 
 	vmpoff=		[KNL,S390] Perform z/VM CP command after power off.
 			Format: <command>
 
 	vsyscall=	[X86-64]
 			Controls the behavior of vsyscalls (i.e. calls to
 			fixed addresses of 0xffffffffff600x00 from legacy
 			code).  Most statically-linked binaries and older
 			versions of glibc use these calls.  Because these
 			functions are at fixed addresses, they make nice
 			targets for exploits that can control RIP.
 
 			emulate     [default] Vsyscalls turn into traps and are
 			            emulated reasonably safely.
 
 			native      Vsyscalls are native syscall instructions.
 			            This is a little bit faster than trapping
 			            and makes a few dynamic recompilers work
 			            better than they would in emulation mode.
 			            It also makes exploits much easier to write.
 
 			none        Vsyscalls don't work at all.  This makes
 			            them quite hard to use for exploits but
 			            might break your system.
 
 	vt.color=	[VT] Default text color.
 			Format: 0xYX, X = foreground, Y = background.
 			Default: 0x07 = light gray on black.
 
 	vt.cur_default=	[VT] Default cursor shape.
 			Format: 0xCCBBAA, where AA, BB, and CC are the same as
 			the parameters of the <Esc>[?A;B;Cc escape sequence;
 			see VGA-softcursor.txt. Default: 2 = underline.
 
 	vt.default_blu=	[VT]
 			Format: <blue0>,<blue1>,<blue2>,...,<blue15>
 			Change the default blue palette of the console.
 			This is a 16-member array composed of values
 			ranging from 0-255.
 
 	vt.default_grn=	[VT]
 			Format: <green0>,<green1>,<green2>,...,<green15>
 			Change the default green palette of the console.
 			This is a 16-member array composed of values
 			ranging from 0-255.
 
 	vt.default_red=	[VT]
 			Format: <red0>,<red1>,<red2>,...,<red15>
 			Change the default red palette of the console.
 			This is a 16-member array composed of values
 			ranging from 0-255.
 
 	vt.default_utf8=
 			[VT]
 			Format=<0|1>
 			Set system-wide default UTF-8 mode for all tty's.
 			Default is 1, i.e. UTF-8 mode is enabled for all
 			newly opened terminals.
 
 	vt.global_cursor_default=
 			[VT]
 			Format=<-1|0|1>
 			Set system-wide default for whether a cursor
 			is shown on new VTs. Default is -1,
 			i.e. cursors will be created by default unless
 			overridden by individual drivers. 0 will hide
 			cursors, 1 will display them.
 
 	vt.italic=	[VT] Default color for italic text; 0-15.
 			Default: 2 = green.
 
 	vt.underline=	[VT] Default color for underlined text; 0-15.
 			Default: 3 = cyan.
 
 	watchdog timers	[HW,WDT] For information on watchdog timers,
 			see Documentation/watchdog/watchdog-parameters.txt
 			or other driver-specific files in the
 			Documentation/watchdog/ directory.
 
 	workqueue.watchdog_thresh=
 			If CONFIG_WQ_WATCHDOG is configured, workqueue can
 			warn stall conditions and dump internal state to
 			help debugging.  0 disables workqueue stall
 			detection; otherwise, it's the stall threshold
 			duration in seconds.  The default value is 30 and
 			it can be updated at runtime by writing to the
 			corresponding sysfs file.
 
 	workqueue.disable_numa
 			By default, all work items queued to unbound
 			workqueues are affine to the NUMA nodes they're
 			issued on, which results in better behavior in
 			general.  If NUMA affinity needs to be disabled for
 			whatever reason, this option can be used.  Note
 			that this also can be controlled per-workqueue for
 			workqueues visible under /sys/bus/workqueue/.
 
 	workqueue.power_efficient
 			Per-cpu workqueues are generally preferred because
 			they show better performance thanks to cache
 			locality; unfortunately, per-cpu workqueues tend to
 			be more power hungry than unbound workqueues.
 
 			Enabling this makes the per-cpu workqueues which
 			were observed to contribute significantly to power
 			consumption unbound, leading to measurably lower
 			power usage at the cost of small performance
 			overhead.
 
 			The default value of this parameter is determined by
 			the config option CONFIG_WQ_POWER_EFFICIENT_DEFAULT.
 
 	workqueue.debug_force_rr_cpu
 			Workqueue used to implicitly guarantee that work
 			items queued without explicit CPU specified are put
 			on the local CPU.  This guarantee is no longer true
 			and while local CPU is still preferred work items
 			may be put on foreign CPUs.  This debug option
 			forces round-robin CPU selection to flush out
 			usages which depend on the now broken guarantee.
 			When enabled, memory and cache locality will be
 			impacted.
 
 	x2apic_phys	[X86-64,APIC] Use x2apic physical mode instead of
 			default x2apic cluster mode on platforms
 			supporting x2apic.
 
 	x86_intel_mid_timer= [X86-32,APBT]
 			Choose timer option for x86 Intel MID platform.
 			Two valid options are apbt timer only and lapic timer
 			plus one apbt timer for broadcast timer.
 			x86_intel_mid_timer=apbt_only | lapic_and_apbt
 
 	xen_512gb_limit		[KNL,X86-64,XEN]
 			Restricts the kernel running paravirtualized under Xen
 			to use only up to 512 GB of RAM. The reason to do so is
 			crash analysis tools and Xen tools for doing domain
 			save/restore/migration must be enabled to handle larger
 			domains.
 
 	xen_emul_unplug=		[HW,X86,XEN]
 			Unplug Xen emulated devices
 			Format: [unplug0,][unplug1]
 			ide-disks -- unplug primary master IDE devices
 			aux-ide-disks -- unplug non-primary-master IDE devices
 			nics -- unplug network devices
 			all -- unplug all emulated devices (NICs and IDE disks)
 			unnecessary -- unplugging emulated devices is
 				unnecessary even if the host did not respond to
 				the unplug protocol
 			never -- do not unplug even if version check succeeds
 
 	xen_nopvspin	[X86,XEN]
 			Disables the ticketlock slowpath using Xen PV
 			optimizations.
 
 	xen_nopv	[X86]
 			Disables the PV optimizations forcing the HVM guest to
 			run as generic HVM guest with no PV drivers.
 
 	xirc2ps_cs=	[NET,PCMCIA]
 			Format:
 			<irq>,<irq_mask>,<io>,<full_duplex>,<do_sound>,<lockup_hack>[,<irq2>[,<irq3>[,<irq4>]]]
diff --git a/Documentation/devicetree/bindings/misc/idt_89hpesx.txt b/Documentation/devicetree/bindings/misc/idt_89hpesx.txt
new file mode 100644
index 000000000000..b9093b79ab7d
--- /dev/null
+++ b/Documentation/devicetree/bindings/misc/idt_89hpesx.txt
@@ -0,0 +1,44 @@
+EEPROM / CSR SMBus-slave interface of IDT 89HPESx devices
+
+Required properties:
+  - compatible : should be "<manufacturer>,<type>"
+		 Basically there is only one manufacturer: idt, but some
+		 compatible devices may be produced in future. Following devices
+		 are supported: 89hpes8nt2, 89hpes12nt3, 89hpes24nt6ag2,
+		 89hpes32nt8ag2, 89hpes32nt8bg2, 89hpes12nt12g2, 89hpes16nt16g2,
+		 89hpes24nt24g2, 89hpes32nt24ag2, 89hpes32nt24bg2;
+		 89hpes12n3, 89hpes12n3a, 89hpes24n3, 89hpes24n3a;
+		 89hpes32h8, 89hpes32h8g2, 89hpes48h12, 89hpes48h12g2,
+		 89hpes48h12ag2, 89hpes16h16, 89hpes22h16, 89hpes22h16g2,
+		 89hpes34h16, 89hpes34h16g2, 89hpes64h16, 89hpes64h16g2,
+		 89hpes64h16ag2;
+		 89hpes12t3g2, 89hpes24t3g2, 89hpes16t4, 89hpes4t4g2,
+		 89hpes10t4g2, 89hpes16t4g2, 89hpes16t4ag2, 89hpes5t5,
+		 89hpes6t5, 89hpes8t5, 89hpes8t5a, 89hpes24t6, 89hpes6t6g2,
+		 89hpes24t6g2, 89hpes16t7, 89hpes32t8, 89hpes32t8g2,
+		 89hpes48t12, 89hpes48t12g2.
+  - reg :	 I2C address of the IDT 89HPESx device.
+
+Optionally there can be EEPROM-compatible subnode:
+  - compatible:  There are five EEPROM devices supported: 24c32, 24c64, 24c128,
+		 24c256 and 24c512 differed by size.
+  - reg:         Custom address of EEPROM device (If not specified IDT 89HPESx
+    (optional)	 device will try to communicate with EEPROM sited by default
+		 address - 0x50)
+  - read-only :	 Parameterless property disables writes to the EEPROM
+    (optional)
+
+Example:
+	idt@60 {
+		compatible = "idt,89hpes32nt8ag2";
+		reg = <0x74>;
+		#address-cells = <1>;
+		#size-cells = <0>;
+
+		eeprom@50 {
+			compatible = "onsemi,24c64";
+			reg = <0x50>;
+			read-only;
+		};
+	};
+
diff --git a/Documentation/devicetree/bindings/nvmem/imx-ocotp.txt b/Documentation/devicetree/bindings/nvmem/imx-ocotp.txt
index 383d5889e95a..966a72ecc6bd 100644
--- a/Documentation/devicetree/bindings/nvmem/imx-ocotp.txt
+++ b/Documentation/devicetree/bindings/nvmem/imx-ocotp.txt
@@ -1,20 +1,22 @@
 Freescale i.MX6 On-Chip OTP Controller (OCOTP) device tree bindings
 
 This binding represents the on-chip eFuse OTP controller found on
-i.MX6Q/D, i.MX6DL/S, i.MX6SL, and i.MX6SX SoCs.
+i.MX6Q/D, i.MX6DL/S, i.MX6SL, i.MX6SX and i.MX6UL SoCs.
 
 Required properties:
 - compatible: should be one of
 	"fsl,imx6q-ocotp" (i.MX6Q/D/DL/S),
 	"fsl,imx6sl-ocotp" (i.MX6SL), or
-	"fsl,imx6sx-ocotp" (i.MX6SX), followed by "syscon".
+	"fsl,imx6sx-ocotp" (i.MX6SX),
+	"fsl,imx6ul-ocotp" (i.MX6UL),
+	followed by "syscon".
 - reg: Should contain the register base and length.
 - clocks: Should contain a phandle pointing to the gated peripheral clock.
 
 Example:
 
 	ocotp: ocotp@021bc000 {
 		compatible = "fsl,imx6q-ocotp", "syscon";
 		reg = <0x021bc000 0x4000>;
 		clocks = <&clks IMX6QDL_CLK_IIM>;
 	};
diff --git a/Documentation/devicetree/bindings/sram/sram.txt b/Documentation/devicetree/bindings/sram/sram.txt
index 068c2c03c38f..267da4410aef 100644
--- a/Documentation/devicetree/bindings/sram/sram.txt
+++ b/Documentation/devicetree/bindings/sram/sram.txt
@@ -1,72 +1,78 @@
 Generic on-chip SRAM
 
 Simple IO memory regions to be managed by the genalloc API.
 
 Required properties:
 
 - compatible : mmio-sram or atmel,sama5d2-securam
 
 - reg : SRAM iomem address range
 
 Reserving sram areas:
 ---------------------
 
 Each child of the sram node specifies a region of reserved memory. Each
 child node should use a 'reg' property to specify a specific range of
 reserved memory.
 
 Following the generic-names recommended practice, node names should
 reflect the purpose of the node. Unit address (@<address>) should be
 appended to the name.
 
 Required properties in the sram node:
 
 - #address-cells, #size-cells : should use the same values as the root node
 - ranges : standard definition, should translate from local addresses
            within the sram to bus addresses
 
 Optional properties in the sram node:
 
 - no-memory-wc : the flag indicating, that SRAM memory region has not to
                  be remapped as write combining. WC is used by default.
 
 Required properties in the area nodes:
 
 - reg : iomem address range, relative to the SRAM range
 
 Optional properties in the area nodes:
 
 - compatible : standard definition, should contain a vendor specific string
                in the form <vendor>,[<device>-]<usage>
 - pool : indicates that the particular reserved SRAM area is addressable
          and in use by another device or devices
 - export : indicates that the reserved SRAM area may be accessed outside
            of the kernel, e.g. by bootloader or userspace
+- protect-exec : Same as 'pool' above but with the additional
+		 constraint that code wil be run from the region and
+		 that the memory is maintained as read-only, executable
+		 during code execution. NOTE: This region must be page
+		 aligned on start and end in order to properly allow
+		 manipulation of the page attributes.
 - label : the name for the reserved partition, if omitted, the label
           is taken from the node name excluding the unit address.
 
 Example:
 
 sram: sram@5c000000 {
 	compatible = "mmio-sram";
 	reg = <0x5c000000 0x40000>; /* 256 KiB SRAM at address 0x5c000000 */
 
 	#address-cells = <1>;
 	#size-cells = <1>;
 	ranges = <0 0x5c000000 0x40000>;
 
 	smp-sram@100 {
 		compatible = "socvendor,smp-sram";
 		reg = <0x100 0x50>;
 	};
 
 	device-sram@1000 {
 		reg = <0x1000 0x1000>;
 		pool;
 	};
 
 	exported@20000 {
 		reg = <0x20000 0x20000>;
 		export;
 	};
 };
diff --git a/Documentation/driver-api/index.rst b/Documentation/driver-api/index.rst
index 5475a2807e7a..c5a1cd0a4ae7 100644
--- a/Documentation/driver-api/index.rst
+++ b/Documentation/driver-api/index.rst
@@ -1,39 +1,40 @@
 ========================================
 The Linux driver implementer's API guide
 ========================================
 
 The kernel offers a wide variety of interfaces to support the development
 of device drivers.  This document is an only somewhat organized collection
 of some of those interfaces â it will hopefully get better over time!  The
 available subsections can be seen below.
 
 .. class:: toc-title
 
 	   Table of contents
 
 .. toctree::
    :maxdepth: 2
 
    basics
    infrastructure
    dma-buf
    device_link
    message-based
    sound
    frame-buffer
    input
    usb
    spi
    i2c
    hsi
    edac
    miscellaneous
    vme
    80211/index
+   uio-howto
 
 .. only::  subproject and html
 
    Indices
    =======
 
    * :ref:`genindex`
diff --git a/Documentation/driver-api/uio-howto.rst b/Documentation/driver-api/uio-howto.rst
new file mode 100644
index 000000000000..f73d660b2956
--- /dev/null
+++ b/Documentation/driver-api/uio-howto.rst
@@ -0,0 +1,705 @@
+=======================
+The Userspace I/O HOWTO
+=======================
+
+:Author: Hans-JÃ¼rgen Koch Linux developer, Linutronix
+:Date:   2006-12-11
+
+About this document
+===================
+
+Translations
+------------
+
+If you know of any translations for this document, or you are interested
+in translating it, please email me hjk@hansjkoch.de.
+
+Preface
+-------
+
+For many types of devices, creating a Linux kernel driver is overkill.
+All that is really needed is some way to handle an interrupt and provide
+access to the memory space of the device. The logic of controlling the
+device does not necessarily have to be within the kernel, as the device
+does not need to take advantage of any of other resources that the
+kernel provides. One such common class of devices that are like this are
+for industrial I/O cards.
+
+To address this situation, the userspace I/O system (UIO) was designed.
+For typical industrial I/O cards, only a very small kernel module is
+needed. The main part of the driver will run in user space. This
+simplifies development and reduces the risk of serious bugs within a
+kernel module.
+
+Please note that UIO is not an universal driver interface. Devices that
+are already handled well by other kernel subsystems (like networking or
+serial or USB) are no candidates for an UIO driver. Hardware that is
+ideally suited for an UIO driver fulfills all of the following:
+
+-  The device has memory that can be mapped. The device can be
+   controlled completely by writing to this memory.
+
+-  The device usually generates interrupts.
+
+-  The device does not fit into one of the standard kernel subsystems.
+
+Acknowledgments
+---------------
+
+I'd like to thank Thomas Gleixner and Benedikt Spranger of Linutronix,
+who have not only written most of the UIO code, but also helped greatly
+writing this HOWTO by giving me all kinds of background information.
+
+Feedback
+--------
+
+Find something wrong with this document? (Or perhaps something right?) I
+would love to hear from you. Please email me at hjk@hansjkoch.de.
+
+About UIO
+=========
+
+If you use UIO for your card's driver, here's what you get:
+
+-  only one small kernel module to write and maintain.
+
+-  develop the main part of your driver in user space, with all the
+   tools and libraries you're used to.
+
+-  bugs in your driver won't crash the kernel.
+
+-  updates of your driver can take place without recompiling the kernel.
+
+How UIO works
+-------------
+
+Each UIO device is accessed through a device file and several sysfs
+attribute files. The device file will be called ``/dev/uio0`` for the
+first device, and ``/dev/uio1``, ``/dev/uio2`` and so on for subsequent
+devices.
+
+``/dev/uioX`` is used to access the address space of the card. Just use
+:c:func:`mmap()` to access registers or RAM locations of your card.
+
+Interrupts are handled by reading from ``/dev/uioX``. A blocking
+:c:func:`read()` from ``/dev/uioX`` will return as soon as an
+interrupt occurs. You can also use :c:func:`select()` on
+``/dev/uioX`` to wait for an interrupt. The integer value read from
+``/dev/uioX`` represents the total interrupt count. You can use this
+number to figure out if you missed some interrupts.
+
+For some hardware that has more than one interrupt source internally,
+but not separate IRQ mask and status registers, there might be
+situations where userspace cannot determine what the interrupt source
+was if the kernel handler disables them by writing to the chip's IRQ
+register. In such a case, the kernel has to disable the IRQ completely
+to leave the chip's register untouched. Now the userspace part can
+determine the cause of the interrupt, but it cannot re-enable
+interrupts. Another cornercase is chips where re-enabling interrupts is
+a read-modify-write operation to a combined IRQ status/acknowledge
+register. This would be racy if a new interrupt occurred simultaneously.
+
+To address these problems, UIO also implements a write() function. It is
+normally not used and can be ignored for hardware that has only a single
+interrupt source or has separate IRQ mask and status registers. If you
+need it, however, a write to ``/dev/uioX`` will call the
+:c:func:`irqcontrol()` function implemented by the driver. You have
+to write a 32-bit value that is usually either 0 or 1 to disable or
+enable interrupts. If a driver does not implement
+:c:func:`irqcontrol()`, :c:func:`write()` will return with
+``-ENOSYS``.
+
+To handle interrupts properly, your custom kernel module can provide its
+own interrupt handler. It will automatically be called by the built-in
+handler.
+
+For cards that don't generate interrupts but need to be polled, there is
+the possibility to set up a timer that triggers the interrupt handler at
+configurable time intervals. This interrupt simulation is done by
+calling :c:func:`uio_event_notify()` from the timer's event
+handler.
+
+Each driver provides attributes that are used to read or write
+variables. These attributes are accessible through sysfs files. A custom
+kernel driver module can add its own attributes to the device owned by
+the uio driver, but not added to the UIO device itself at this time.
+This might change in the future if it would be found to be useful.
+
+The following standard attributes are provided by the UIO framework:
+
+-  ``name``: The name of your device. It is recommended to use the name
+   of your kernel module for this.
+
+-  ``version``: A version string defined by your driver. This allows the
+   user space part of your driver to deal with different versions of the
+   kernel module.
+
+-  ``event``: The total number of interrupts handled by the driver since
+   the last time the device node was read.
+
+These attributes appear under the ``/sys/class/uio/uioX`` directory.
+Please note that this directory might be a symlink, and not a real
+directory. Any userspace code that accesses it must be able to handle
+this.
+
+Each UIO device can make one or more memory regions available for memory
+mapping. This is necessary because some industrial I/O cards require
+access to more than one PCI memory region in a driver.
+
+Each mapping has its own directory in sysfs, the first mapping appears
+as ``/sys/class/uio/uioX/maps/map0/``. Subsequent mappings create
+directories ``map1/``, ``map2/``, and so on. These directories will only
+appear if the size of the mapping is not 0.
+
+Each ``mapX/`` directory contains four read-only files that show
+attributes of the memory:
+
+-  ``name``: A string identifier for this mapping. This is optional, the
+   string can be empty. Drivers can set this to make it easier for
+   userspace to find the correct mapping.
+
+-  ``addr``: The address of memory that can be mapped.
+
+-  ``size``: The size, in bytes, of the memory pointed to by addr.
+
+-  ``offset``: The offset, in bytes, that has to be added to the pointer
+   returned by :c:func:`mmap()` to get to the actual device memory.
+   This is important if the device's memory is not page aligned.
+   Remember that pointers returned by :c:func:`mmap()` are always
+   page aligned, so it is good style to always add this offset.
+
+From userspace, the different mappings are distinguished by adjusting
+the ``offset`` parameter of the :c:func:`mmap()` call. To map the
+memory of mapping N, you have to use N times the page size as your
+offset::
+
+    offset = N * getpagesize();
+
+Sometimes there is hardware with memory-like regions that can not be
+mapped with the technique described here, but there are still ways to
+access them from userspace. The most common example are x86 ioports. On
+x86 systems, userspace can access these ioports using
+:c:func:`ioperm()`, :c:func:`iopl()`, :c:func:`inb()`,
+:c:func:`outb()`, and similar functions.
+
+Since these ioport regions can not be mapped, they will not appear under
+``/sys/class/uio/uioX/maps/`` like the normal memory described above.
+Without information about the port regions a hardware has to offer, it
+becomes difficult for the userspace part of the driver to find out which
+ports belong to which UIO device.
+
+To address this situation, the new directory
+``/sys/class/uio/uioX/portio/`` was added. It only exists if the driver
+wants to pass information about one or more port regions to userspace.
+If that is the case, subdirectories named ``port0``, ``port1``, and so
+on, will appear underneath ``/sys/class/uio/uioX/portio/``.
+
+Each ``portX/`` directory contains four read-only files that show name,
+start, size, and type of the port region:
+
+-  ``name``: A string identifier for this port region. The string is
+   optional and can be empty. Drivers can set it to make it easier for
+   userspace to find a certain port region.
+
+-  ``start``: The first port of this region.
+
+-  ``size``: The number of ports in this region.
+
+-  ``porttype``: A string describing the type of port.
+
+Writing your own kernel module
+==============================
+
+Please have a look at ``uio_cif.c`` as an example. The following
+paragraphs explain the different sections of this file.
+
+struct uio_info
+---------------
+
+This structure tells the framework the details of your driver, Some of
+the members are required, others are optional.
+
+-  ``const char *name``: Required. The name of your driver as it will
+   appear in sysfs. I recommend using the name of your module for this.
+
+-  ``const char *version``: Required. This string appears in
+   ``/sys/class/uio/uioX/version``.
+
+-  ``struct uio_mem mem[ MAX_UIO_MAPS ]``: Required if you have memory
+   that can be mapped with :c:func:`mmap()`. For each mapping you
+   need to fill one of the ``uio_mem`` structures. See the description
+   below for details.
+
+-  ``struct uio_port port[ MAX_UIO_PORTS_REGIONS ]``: Required if you
+   want to pass information about ioports to userspace. For each port
+   region you need to fill one of the ``uio_port`` structures. See the
+   description below for details.
+
+-  ``long irq``: Required. If your hardware generates an interrupt, it's
+   your modules task to determine the irq number during initialization.
+   If you don't have a hardware generated interrupt but want to trigger
+   the interrupt handler in some other way, set ``irq`` to
+   ``UIO_IRQ_CUSTOM``. If you had no interrupt at all, you could set
+   ``irq`` to ``UIO_IRQ_NONE``, though this rarely makes sense.
+
+-  ``unsigned long irq_flags``: Required if you've set ``irq`` to a
+   hardware interrupt number. The flags given here will be used in the
+   call to :c:func:`request_irq()`.
+
+-  ``int (*mmap)(struct uio_info *info, struct vm_area_struct *vma)``:
+   Optional. If you need a special :c:func:`mmap()`
+   function, you can set it here. If this pointer is not NULL, your
+   :c:func:`mmap()` will be called instead of the built-in one.
+
+-  ``int (*open)(struct uio_info *info, struct inode *inode)``:
+   Optional. You might want to have your own :c:func:`open()`,
+   e.g. to enable interrupts only when your device is actually used.
+
+-  ``int (*release)(struct uio_info *info, struct inode *inode)``:
+   Optional. If you define your own :c:func:`open()`, you will
+   probably also want a custom :c:func:`release()` function.
+
+-  ``int (*irqcontrol)(struct uio_info *info, s32 irq_on)``:
+   Optional. If you need to be able to enable or disable interrupts
+   from userspace by writing to ``/dev/uioX``, you can implement this
+   function. The parameter ``irq_on`` will be 0 to disable interrupts
+   and 1 to enable them.
+
+Usually, your device will have one or more memory regions that can be
+mapped to user space. For each region, you have to set up a
+``struct uio_mem`` in the ``mem[]`` array. Here's a description of the
+fields of ``struct uio_mem``:
+
+-  ``const char *name``: Optional. Set this to help identify the memory
+   region, it will show up in the corresponding sysfs node.
+
+-  ``int memtype``: Required if the mapping is used. Set this to
+   ``UIO_MEM_PHYS`` if you you have physical memory on your card to be
+   mapped. Use ``UIO_MEM_LOGICAL`` for logical memory (e.g. allocated
+   with :c:func:`kmalloc()`). There's also ``UIO_MEM_VIRTUAL`` for
+   virtual memory.
+
+-  ``phys_addr_t addr``: Required if the mapping is used. Fill in the
+   address of your memory block. This address is the one that appears in
+   sysfs.
+
+-  ``resource_size_t size``: Fill in the size of the memory block that
+   ``addr`` points to. If ``size`` is zero, the mapping is considered
+   unused. Note that you *must* initialize ``size`` with zero for all
+   unused mappings.
+
+-  ``void *internal_addr``: If you have to access this memory region
+   from within your kernel module, you will want to map it internally by
+   using something like :c:func:`ioremap()`. Addresses returned by
+   this function cannot be mapped to user space, so you must not store
+   it in ``addr``. Use ``internal_addr`` instead to remember such an
+   address.
+
+Please do not touch the ``map`` element of ``struct uio_mem``! It is
+used by the UIO framework to set up sysfs files for this mapping. Simply
+leave it alone.
+
+Sometimes, your device can have one or more port regions which can not
+be mapped to userspace. But if there are other possibilities for
+userspace to access these ports, it makes sense to make information
+about the ports available in sysfs. For each region, you have to set up
+a ``struct uio_port`` in the ``port[]`` array. Here's a description of
+the fields of ``struct uio_port``:
+
+-  ``char *porttype``: Required. Set this to one of the predefined
+   constants. Use ``UIO_PORT_X86`` for the ioports found in x86
+   architectures.
+
+-  ``unsigned long start``: Required if the port region is used. Fill in
+   the number of the first port of this region.
+
+-  ``unsigned long size``: Fill in the number of ports in this region.
+   If ``size`` is zero, the region is considered unused. Note that you
+   *must* initialize ``size`` with zero for all unused regions.
+
+Please do not touch the ``portio`` element of ``struct uio_port``! It is
+used internally by the UIO framework to set up sysfs files for this
+region. Simply leave it alone.
+
+Adding an interrupt handler
+---------------------------
+
+What you need to do in your interrupt handler depends on your hardware
+and on how you want to handle it. You should try to keep the amount of
+code in your kernel interrupt handler low. If your hardware requires no
+action that you *have* to perform after each interrupt, then your
+handler can be empty.
+
+If, on the other hand, your hardware *needs* some action to be performed
+after each interrupt, then you *must* do it in your kernel module. Note
+that you cannot rely on the userspace part of your driver. Your
+userspace program can terminate at any time, possibly leaving your
+hardware in a state where proper interrupt handling is still required.
+
+There might also be applications where you want to read data from your
+hardware at each interrupt and buffer it in a piece of kernel memory
+you've allocated for that purpose. With this technique you could avoid
+loss of data if your userspace program misses an interrupt.
+
+A note on shared interrupts: Your driver should support interrupt
+sharing whenever this is possible. It is possible if and only if your
+driver can detect whether your hardware has triggered the interrupt or
+not. This is usually done by looking at an interrupt status register. If
+your driver sees that the IRQ bit is actually set, it will perform its
+actions, and the handler returns IRQ_HANDLED. If the driver detects
+that it was not your hardware that caused the interrupt, it will do
+nothing and return IRQ_NONE, allowing the kernel to call the next
+possible interrupt handler.
+
+If you decide not to support shared interrupts, your card won't work in
+computers with no free interrupts. As this frequently happens on the PC
+platform, you can save yourself a lot of trouble by supporting interrupt
+sharing.
+
+Using uio_pdrv for platform devices
+-----------------------------------
+
+In many cases, UIO drivers for platform devices can be handled in a
+generic way. In the same place where you define your
+``struct platform_device``, you simply also implement your interrupt
+handler and fill your ``struct uio_info``. A pointer to this
+``struct uio_info`` is then used as ``platform_data`` for your platform
+device.
+
+You also need to set up an array of ``struct resource`` containing
+addresses and sizes of your memory mappings. This information is passed
+to the driver using the ``.resource`` and ``.num_resources`` elements of
+``struct platform_device``.
+
+You now have to set the ``.name`` element of ``struct platform_device``
+to ``"uio_pdrv"`` to use the generic UIO platform device driver. This
+driver will fill the ``mem[]`` array according to the resources given,
+and register the device.
+
+The advantage of this approach is that you only have to edit a file you
+need to edit anyway. You do not have to create an extra driver.
+
+Using uio_pdrv_genirq for platform devices
+------------------------------------------
+
+Especially in embedded devices, you frequently find chips where the irq
+pin is tied to its own dedicated interrupt line. In such cases, where
+you can be really sure the interrupt is not shared, we can take the
+concept of ``uio_pdrv`` one step further and use a generic interrupt
+handler. That's what ``uio_pdrv_genirq`` does.
+
+The setup for this driver is the same as described above for
+``uio_pdrv``, except that you do not implement an interrupt handler. The
+``.handler`` element of ``struct uio_info`` must remain ``NULL``. The
+``.irq_flags`` element must not contain ``IRQF_SHARED``.
+
+You will set the ``.name`` element of ``struct platform_device`` to
+``"uio_pdrv_genirq"`` to use this driver.
+
+The generic interrupt handler of ``uio_pdrv_genirq`` will simply disable
+the interrupt line using :c:func:`disable_irq_nosync()`. After
+doing its work, userspace can reenable the interrupt by writing
+0x00000001 to the UIO device file. The driver already implements an
+:c:func:`irq_control()` to make this possible, you must not
+implement your own.
+
+Using ``uio_pdrv_genirq`` not only saves a few lines of interrupt
+handler code. You also do not need to know anything about the chip's
+internal registers to create the kernel part of the driver. All you need
+to know is the irq number of the pin the chip is connected to.
+
+Using uio_dmem_genirq for platform devices
+------------------------------------------
+
+In addition to statically allocated memory ranges, they may also be a
+desire to use dynamically allocated regions in a user space driver. In
+particular, being able to access memory made available through the
+dma-mapping API, may be particularly useful. The ``uio_dmem_genirq``
+driver provides a way to accomplish this.
+
+This driver is used in a similar manner to the ``"uio_pdrv_genirq"``
+driver with respect to interrupt configuration and handling.
+
+Set the ``.name`` element of ``struct platform_device`` to
+``"uio_dmem_genirq"`` to use this driver.
+
+When using this driver, fill in the ``.platform_data`` element of
+``struct platform_device``, which is of type
+``struct uio_dmem_genirq_pdata`` and which contains the following
+elements:
+
+-  ``struct uio_info uioinfo``: The same structure used as the
+   ``uio_pdrv_genirq`` platform data
+
+-  ``unsigned int *dynamic_region_sizes``: Pointer to list of sizes of
+   dynamic memory regions to be mapped into user space.
+
+-  ``unsigned int num_dynamic_regions``: Number of elements in
+   ``dynamic_region_sizes`` array.
+
+The dynamic regions defined in the platform data will be appended to the
+`` mem[] `` array after the platform device resources, which implies
+that the total number of static and dynamic memory regions cannot exceed
+``MAX_UIO_MAPS``.
+
+The dynamic memory regions will be allocated when the UIO device file,
+``/dev/uioX`` is opened. Similar to static memory resources, the memory
+region information for dynamic regions is then visible via sysfs at
+``/sys/class/uio/uioX/maps/mapY/*``. The dynamic memory regions will be
+freed when the UIO device file is closed. When no processes are holding
+the device file open, the address returned to userspace is ~0.
+
+Writing a driver in userspace
+=============================
+
+Once you have a working kernel module for your hardware, you can write
+the userspace part of your driver. You don't need any special libraries,
+your driver can be written in any reasonable language, you can use
+floating point numbers and so on. In short, you can use all the tools
+and libraries you'd normally use for writing a userspace application.
+
+Getting information about your UIO device
+-----------------------------------------
+
+Information about all UIO devices is available in sysfs. The first thing
+you should do in your driver is check ``name`` and ``version`` to make
+sure your talking to the right device and that its kernel driver has the
+version you expect.
+
+You should also make sure that the memory mapping you need exists and
+has the size you expect.
+
+There is a tool called ``lsuio`` that lists UIO devices and their
+attributes. It is available here:
+
+http://www.osadl.org/projects/downloads/UIO/user/
+
+With ``lsuio`` you can quickly check if your kernel module is loaded and
+which attributes it exports. Have a look at the manpage for details.
+
+The source code of ``lsuio`` can serve as an example for getting
+information about an UIO device. The file ``uio_helper.c`` contains a
+lot of functions you could use in your userspace driver code.
+
+mmap() device memory
+--------------------
+
+After you made sure you've got the right device with the memory mappings
+you need, all you have to do is to call :c:func:`mmap()` to map the
+device's memory to userspace.
+
+The parameter ``offset`` of the :c:func:`mmap()` call has a special
+meaning for UIO devices: It is used to select which mapping of your
+device you want to map. To map the memory of mapping N, you have to use
+N times the page size as your offset::
+
+        offset = N * getpagesize();
+
+N starts from zero, so if you've got only one memory range to map, set
+``offset = 0``. A drawback of this technique is that memory is always
+mapped beginning with its start address.
+
+Waiting for interrupts
+----------------------
+
+After you successfully mapped your devices memory, you can access it
+like an ordinary array. Usually, you will perform some initialization.
+After that, your hardware starts working and will generate an interrupt
+as soon as it's finished, has some data available, or needs your
+attention because an error occurred.
+
+``/dev/uioX`` is a read-only file. A :c:func:`read()` will always
+block until an interrupt occurs. There is only one legal value for the
+``count`` parameter of :c:func:`read()`, and that is the size of a
+signed 32 bit integer (4). Any other value for ``count`` causes
+:c:func:`read()` to fail. The signed 32 bit integer read is the
+interrupt count of your device. If the value is one more than the value
+you read the last time, everything is OK. If the difference is greater
+than one, you missed interrupts.
+
+You can also use :c:func:`select()` on ``/dev/uioX``.
+
+Generic PCI UIO driver
+======================
+
+The generic driver is a kernel module named uio_pci_generic. It can
+work with any device compliant to PCI 2.3 (circa 2002) and any compliant
+PCI Express device. Using this, you only need to write the userspace
+driver, removing the need to write a hardware-specific kernel module.
+
+Making the driver recognize the device
+--------------------------------------
+
+Since the driver does not declare any device ids, it will not get loaded
+automatically and will not automatically bind to any devices, you must
+load it and allocate id to the driver yourself. For example::
+
+     modprobe uio_pci_generic
+     echo "8086 10f5" > /sys/bus/pci/drivers/uio_pci_generic/new_id
+
+If there already is a hardware specific kernel driver for your device,
+the generic driver still won't bind to it, in this case if you want to
+use the generic driver (why would you?) you'll have to manually unbind
+the hardware specific driver and bind the generic driver, like this::
+
+        echo -n 0000:00:19.0 > /sys/bus/pci/drivers/e1000e/unbind
+        echo -n 0000:00:19.0 > /sys/bus/pci/drivers/uio_pci_generic/bind
+
+You can verify that the device has been bound to the driver by looking
+for it in sysfs, for example like the following::
+
+        ls -l /sys/bus/pci/devices/0000:00:19.0/driver
+
+Which if successful should print::
+
+      .../0000:00:19.0/driver -> ../../../bus/pci/drivers/uio_pci_generic
+
+Note that the generic driver will not bind to old PCI 2.2 devices. If
+binding the device failed, run the following command::
+
+      dmesg
+
+and look in the output for failure reasons.
+
+Things to know about uio_pci_generic
+------------------------------------
+
+Interrupts are handled using the Interrupt Disable bit in the PCI
+command register and Interrupt Status bit in the PCI status register.
+All devices compliant to PCI 2.3 (circa 2002) and all compliant PCI
+Express devices should support these bits. uio_pci_generic detects
+this support, and won't bind to devices which do not support the
+Interrupt Disable Bit in the command register.
+
+On each interrupt, uio_pci_generic sets the Interrupt Disable bit.
+This prevents the device from generating further interrupts until the
+bit is cleared. The userspace driver should clear this bit before
+blocking and waiting for more interrupts.
+
+Writing userspace driver using uio_pci_generic
+------------------------------------------------
+
+Userspace driver can use pci sysfs interface, or the libpci library that
+wraps it, to talk to the device and to re-enable interrupts by writing
+to the command register.
+
+Example code using uio_pci_generic
+----------------------------------
+
+Here is some sample userspace driver code using uio_pci_generic::
+
+    #include <stdlib.h>
+    #include <stdio.h>
+    #include <unistd.h>
+    #include <sys/types.h>
+    #include <sys/stat.h>
+    #include <fcntl.h>
+    #include <errno.h>
+
+    int main()
+    {
+        int uiofd;
+        int configfd;
+        int err;
+        int i;
+        unsigned icount;
+        unsigned char command_high;
+
+        uiofd = open("/dev/uio0", O_RDONLY);
+        if (uiofd < 0) {
+            perror("uio open:");
+            return errno;
+        }
+        configfd = open("/sys/class/uio/uio0/device/config", O_RDWR);
+        if (configfd < 0) {
+            perror("config open:");
+            return errno;
+        }
+
+        /* Read and cache command value */
+        err = pread(configfd, &command_high, 1, 5);
+        if (err != 1) {
+            perror("command config read:");
+            return errno;
+        }
+        command_high &= ~0x4;
+
+        for(i = 0;; ++i) {
+            /* Print out a message, for debugging. */
+            if (i == 0)
+                fprintf(stderr, "Started uio test driver.\n");
+            else
+                fprintf(stderr, "Interrupts: %d\n", icount);
+
+            /****************************************/
+            /* Here we got an interrupt from the
+               device. Do something to it. */
+            /****************************************/
+
+            /* Re-enable interrupts. */
+            err = pwrite(configfd, &command_high, 1, 5);
+            if (err != 1) {
+                perror("config write:");
+                break;
+            }
+
+            /* Wait for next interrupt. */
+            err = read(uiofd, &icount, 4);
+            if (err != 4) {
+                perror("uio read:");
+                break;
+            }
+
+        }
+        return errno;
+    }
+
+Generic Hyper-V UIO driver
+==========================
+
+The generic driver is a kernel module named uio_hv_generic. It
+supports devices on the Hyper-V VMBus similar to uio_pci_generic on
+PCI bus.
+
+Making the driver recognize the device
+--------------------------------------
+
+Since the driver does not declare any device GUID's, it will not get
+loaded automatically and will not automatically bind to any devices, you
+must load it and allocate id to the driver yourself. For example, to use
+the network device GUID::
+
+     modprobe uio_hv_generic
+     echo "f8615163-df3e-46c5-913f-f2d2f965ed0e" > /sys/bus/vmbus/drivers/uio_hv_generic/new_id
+
+If there already is a hardware specific kernel driver for the device,
+the generic driver still won't bind to it, in this case if you want to
+use the generic driver (why would you?) you'll have to manually unbind
+the hardware specific driver and bind the generic driver, like this::
+
+          echo -n vmbus-ed963694-e847-4b2a-85af-bc9cfc11d6f3 > /sys/bus/vmbus/drivers/hv_netvsc/unbind
+          echo -n vmbus-ed963694-e847-4b2a-85af-bc9cfc11d6f3 > /sys/bus/vmbus/drivers/uio_hv_generic/bind
+
+You can verify that the device has been bound to the driver by looking
+for it in sysfs, for example like the following::
+
+        ls -l /sys/bus/vmbus/devices/vmbus-ed963694-e847-4b2a-85af-bc9cfc11d6f3/driver
+
+Which if successful should print::
+
+      .../vmbus-ed963694-e847-4b2a-85af-bc9cfc11d6f3/driver -> ../../../bus/vmbus/drivers/uio_hv_generic
+
+Things to know about uio_hv_generic
+-----------------------------------
+
+On each interrupt, uio_hv_generic sets the Interrupt Disable bit. This
+prevents the device from generating further interrupts until the bit is
+cleared. The userspace driver should clear this bit before blocking and
+waiting for more interrupts.
+
+Further information
+===================
+
+-  `OSADL homepage. <http://www.osadl.org>`_
+
+-  `Linutronix homepage. <http://www.linutronix.de>`_
diff --git a/Documentation/extcon/intel-int3496.txt b/Documentation/extcon/intel-int3496.txt
new file mode 100644
index 000000000000..af0b366c25b7
--- /dev/null
+++ b/Documentation/extcon/intel-int3496.txt
@@ -0,0 +1,22 @@
+Intel INT3496 ACPI device extcon driver documentation
+-----------------------------------------------------
+
+The Intel INT3496 ACPI device extcon driver is a driver for ACPI
+devices with an acpi-id of INT3496, such as found for example on
+Intel Baytrail and Cherrytrail tablets.
+
+This ACPI device describes how the OS can read the id-pin of the devices'
+USB-otg port, as well as how it optionally can enable Vbus output on the
+otg port and how it can optionally control the muxing of the data pins
+between an USB host and an USB peripheral controller.
+
+The ACPI devices exposes this functionality by returning an array with up
+to 3 gpio descriptors from its ACPI _CRS (Current Resource Settings) call:
+
+Index 0: The input gpio for the id-pin, this is always present and valid
+Index 1: The output gpio for enabling Vbus output from the device to the otg
+         port, write 1 to enable the Vbus output (this gpio descriptor may
+         be absent or invalid)
+Index 2: The output gpio for muxing of the data pins between the USB host and
+         the USB peripheral controller, write 1 to mux to the peripheral
+         controller
diff --git a/Documentation/fpga/fpga-mgr.txt b/Documentation/fpga/fpga-mgr.txt
index 86ee5078fd03..78f197fadfd1 100644
--- a/Documentation/fpga/fpga-mgr.txt
+++ b/Documentation/fpga/fpga-mgr.txt
@@ -1,186 +1,199 @@
 FPGA Manager Core
 
 Alan Tull 2015
 
 Overview
 ========
 
 The FPGA manager core exports a set of functions for programming an FPGA with
 an image.  The API is manufacturer agnostic.  All manufacturer specifics are
 hidden away in a low level driver which registers a set of ops with the core.
 The FPGA image data itself is very manufacturer specific, but for our purposes
 it's just binary data.  The FPGA manager core won't parse it.
 
 
 API Functions:
 ==============
 
 To program the FPGA from a file or from a buffer:
 -------------------------------------------------
 
 	int fpga_mgr_buf_load(struct fpga_manager *mgr,
 			      struct fpga_image_info *info,
 		              const char *buf, size_t count);
 
-Load the FPGA from an image which exists as a buffer in memory.
+Load the FPGA from an image which exists as a contiguous buffer in
+memory. Allocating contiguous kernel memory for the buffer should be avoided,
+users are encouraged to use the _sg interface instead of this.
+
+        int fpga_mgr_buf_load_sg(struct fpga_manager *mgr,
+				 struct fpga_image_info *info,
+				 struct sg_table *sgt);
+
+Load the FPGA from an image from non-contiguous in memory. Callers can
+construct a sg_table using alloc_page backed memory.
 
 	int fpga_mgr_firmware_load(struct fpga_manager *mgr,
 				   struct fpga_image_info *info,
 		                   const char *image_name);
 
 Load the FPGA from an image which exists as a file.  The image file must be on
 the firmware search path (see the firmware class documentation).  If successful,
 the FPGA ends up in operating mode.  Return 0 on success or a negative error
 code.
 
 A FPGA design contained in a FPGA image file will likely have particulars that
 affect how the image is programmed to the FPGA.  These are contained in struct
 fpga_image_info.  Currently the only such particular is a single flag bit
 indicating whether the image is for full or partial reconfiguration.
 
 To get/put a reference to a FPGA manager:
 -----------------------------------------
 
 	struct fpga_manager *of_fpga_mgr_get(struct device_node *node);
 	struct fpga_manager *fpga_mgr_get(struct device *dev);
 
 Given a DT node or device, get an exclusive reference to a FPGA manager.
 
 	void fpga_mgr_put(struct fpga_manager *mgr);
 
 Release the reference.
 
 
 To register or unregister the low level FPGA-specific driver:
 -------------------------------------------------------------
 
 	int fpga_mgr_register(struct device *dev, const char *name,
 		              const struct fpga_manager_ops *mops,
 		              void *priv);
 
 	void fpga_mgr_unregister(struct device *dev);
 
 Use of these two functions is described below in "How To Support a new FPGA
 device."
 
 
 How to write an image buffer to a supported FPGA
 ================================================
 /* Include to get the API */
 #include <linux/fpga/fpga-mgr.h>
 
 /* device node that specifies the FPGA manager to use */
 struct device_node *mgr_node = ...
 
 /* FPGA image is in this buffer.  count is size of the buffer. */
 char *buf = ...
 int count = ...
 
 /* struct with information about the FPGA image to program. */
 struct fpga_image_info info;
 
 /* flags indicates whether to do full or partial reconfiguration */
 info.flags = 0;
 
 int ret;
 
 /* Get exclusive control of FPGA manager */
 struct fpga_manager *mgr = of_fpga_mgr_get(mgr_node);
 
 /* Load the buffer to the FPGA */
 ret = fpga_mgr_buf_load(mgr, &info, buf, count);
 
 /* Release the FPGA manager */
 fpga_mgr_put(mgr);
 
 
 How to write an image file to a supported FPGA
 ==============================================
 /* Include to get the API */
 #include <linux/fpga/fpga-mgr.h>
 
 /* device node that specifies the FPGA manager to use */
 struct device_node *mgr_node = ...
 
 /* FPGA image is in this file which is in the firmware search path */
 const char *path = "fpga-image-9.rbf"
 
 /* struct with information about the FPGA image to program. */
 struct fpga_image_info info;
 
 /* flags indicates whether to do full or partial reconfiguration */
 info.flags = 0;
 
 int ret;
 
 /* Get exclusive control of FPGA manager */
 struct fpga_manager *mgr = of_fpga_mgr_get(mgr_node);
 
 /* Get the firmware image (path) and load it to the FPGA */
 ret = fpga_mgr_firmware_load(mgr, &info, path);
 
 /* Release the FPGA manager */
 fpga_mgr_put(mgr);
 
 
 How to support a new FPGA device
 ================================
 To add another FPGA manager, write a driver that implements a set of ops.  The
 probe function calls fpga_mgr_register(), such as:
 
 static const struct fpga_manager_ops socfpga_fpga_ops = {
        .write_init = socfpga_fpga_ops_configure_init,
        .write = socfpga_fpga_ops_configure_write,
        .write_complete = socfpga_fpga_ops_configure_complete,
        .state = socfpga_fpga_ops_state,
 };
 
 static int socfpga_fpga_probe(struct platform_device *pdev)
 {
 	struct device *dev = &pdev->dev;
 	struct socfpga_fpga_priv *priv;
 	int ret;
 
 	priv = devm_kzalloc(dev, sizeof(*priv), GFP_KERNEL);
 	if (!priv)
 		return -ENOMEM;
 
 	/* ... do ioremaps, get interrupts, etc. and save
 	   them in priv... */
 
 	return fpga_mgr_register(dev, "Altera SOCFPGA FPGA Manager",
 				 &socfpga_fpga_ops, priv);
 }
 
 static int socfpga_fpga_remove(struct platform_device *pdev)
 {
 	fpga_mgr_unregister(&pdev->dev);
 
 	return 0;
 }
 
 
 The ops will implement whatever device specific register writes are needed to
 do the programming sequence for this particular FPGA.  These ops return 0 for
 success or negative error codes otherwise.
 
 The programming sequence is:
  1. .write_init
- 2. .write (may be called once or multiple times)
+ 2. .write or .write_sg (may be called once or multiple times)
  3. .write_complete
 
 The .write_init function will prepare the FPGA to receive the image data.  The
 buffer passed into .write_init will be atmost .initial_header_size bytes long,
 if the whole bitstream is not immediately available then the core code will
 buffer up at least this much before starting.
 
 The .write function writes a buffer to the FPGA. The buffer may be contain the
 whole FPGA image or may be a smaller chunk of an FPGA image.  In the latter
-case, this function is called multiple times for successive chunks.
+case, this function is called multiple times for successive chunks. This interface
+is suitable for drivers which use PIO.
+
+The .write_sg version behaves the same as .write except the input is a sg_table
+scatter list. This interface is suitable for drivers which use DMA.
 
 The .write_complete function is called after all the image has been written
 to put the FPGA into operating mode.
 
 The ops include a .state function which will read the hardware FPGA manager and
 return a code of type enum fpga_mgr_states.  It doesn't result in a change in
 hardware state.
diff --git a/MAINTAINERS b/MAINTAINERS
index d6e91e96f4e5..427c97e429bf 100644
--- a/MAINTAINERS
+++ b/MAINTAINERS
@@ -1,13802 +1,13803 @@
 
 
 	List of maintainers and how to submit kernel changes
 
 Please try to follow the guidelines below.  This will make things
 easier on the maintainers.  Not all of these guidelines matter for every
 trivial patch so apply some common sense.
 
 1.	Always _test_ your changes, however small, on at least 4 or
 	5 people, preferably many more.
 
 2.	Try to release a few ALPHA test versions to the net. Announce
 	them onto the kernel channel and await results. This is especially
 	important for device drivers, because often that's the only way
 	you will find things like the fact version 3 firmware needs
 	a magic fix you didn't know about, or some clown changed the
 	chips on a board and not its name.  (Don't laugh!  Look at the
 	SMC etherpower for that.)
 
 3.	Make sure your changes compile correctly in multiple
 	configurations. In particular check that changes work both as a
 	module and built into the kernel.
 
 4.	When you are happy with a change make it generally available for
 	testing and await feedback.
 
 5.	Make a patch available to the relevant maintainer in the list. Use
 	'diff -u' to make the patch easy to merge. Be prepared to get your
 	changes sent back with seemingly silly requests about formatting
 	and variable names.  These aren't as silly as they seem. One
 	job the maintainers (and especially Linus) do is to keep things
 	looking the same. Sometimes this means that the clever hack in
 	your driver to get around a problem actually needs to become a
 	generalized kernel feature ready for next time.
 
 	PLEASE check your patch with the automated style checker
 	(scripts/checkpatch.pl) to catch trivial style violations.
 	See Documentation/process/coding-style.rst for guidance here.
 
 	PLEASE CC: the maintainers and mailing lists that are generated
 	by scripts/get_maintainer.pl.  The results returned by the
 	script will be best if you have git installed and are making
 	your changes in a branch derived from Linus' latest git tree.
 	See Documentation/process/submitting-patches.rst for details.
 
 	PLEASE try to include any credit lines you want added with the
 	patch. It avoids people being missed off by mistake and makes
 	it easier to know who wants adding and who doesn't.
 
 	PLEASE document known bugs. If it doesn't work for everything
 	or does something very odd once a month document it.
 
 	PLEASE remember that submissions must be made under the terms
 	of the Linux Foundation certificate of contribution and should
 	include a Signed-off-by: line.  The current version of this
 	"Developer's Certificate of Origin" (DCO) is listed in the file
 	Documentation/process/submitting-patches.rst.
 
 6.	Make sure you have the right to send any changes you make. If you
 	do changes at work you may find your employer owns the patch
 	not you.
 
 7.	When sending security related changes or reports to a maintainer
 	please Cc: security@kernel.org, especially if the maintainer
 	does not respond.
 
 8.	Happy hacking.
 
 Descriptions of section entries:
 
 	P: Person (obsolete)
 	M: Mail patches to: FullName <address@domain>
 	R: Designated reviewer: FullName <address@domain>
 	   These reviewers should be CCed on patches.
 	L: Mailing list that is relevant to this area
 	W: Web-page with status/info
 	B: URI for where to file bugs. A web-page with detailed bug
 	   filing info, a direct bug tracker link, or a mailto: URI.
 	C: URI for chat protocol, server and channel where developers
 	   usually hang out, for example irc://server/channel.
 	Q: Patchwork web based patch tracking system site
 	T: SCM tree type and location.
 	   Type is one of: git, hg, quilt, stgit, topgit
 	S: Status, one of the following:
 	   Supported:	Someone is actually paid to look after this.
 	   Maintained:	Someone actually looks after it.
 	   Odd Fixes:	It has a maintainer but they don't have time to do
 			much other than throw the odd patch in. See below..
 	   Orphan:	No current maintainer [but maybe you could take the
 			role as you write your new code].
 	   Obsolete:	Old code. Something tagged obsolete generally means
 			it has been replaced by a better system and you
 			should be using that.
 	F: Files and directories with wildcard patterns.
 	   A trailing slash includes all files and subdirectory files.
 	   F:	drivers/net/	all files in and below drivers/net
 	   F:	drivers/net/*	all files in drivers/net, but not below
 	   F:	*/net/*		all files in "any top level directory"/net
 	   One pattern per line.  Multiple F: lines acceptable.
 	N: Files and directories with regex patterns.
 	   N:	[^a-z]tegra	all files whose path contains the word tegra
 	   One pattern per line.  Multiple N: lines acceptable.
 	   scripts/get_maintainer.pl has different behavior for files that
 	   match F: pattern and matches of N: patterns.  By default,
 	   get_maintainer will not look at git log history when an F: pattern
 	   match occurs.  When an N: match occurs, git log history is used
 	   to also notify the people that have git commit signatures.
 	X: Files and directories that are NOT maintained, same rules as F:
 	   Files exclusions are tested before file matches.
 	   Can be useful for excluding a specific subdirectory, for instance:
 	   F:	net/
 	   X:	net/ipv6/
 	   matches all files in and below net excluding net/ipv6/
 	K: Keyword perl extended regex pattern to match content in a
 	   patch or file.  For instance:
 	   K: of_get_profile
 	      matches patches or files that contain "of_get_profile"
 	   K: \b(printk|pr_(info|err))\b
 	      matches patches or files that contain one or more of the words
 	      printk, pr_info or pr_err
 	   One regex pattern per line.  Multiple K: lines acceptable.
 
 Note: For the hard of thinking, this list is meant to remain in alphabetical
 order. If you could add yourselves to it in alphabetical order that would be
 so much easier [Ed]
 
 Maintainers List (try to look for most precise areas first)
 
 		-----------------------------------
 
 3C59X NETWORK DRIVER
 M:	Steffen Klassert <klassert@mathematik.tu-chemnitz.de>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	Documentation/networking/vortex.txt
 F:	drivers/net/ethernet/3com/3c59x.c
 
 3CR990 NETWORK DRIVER
 M:	David Dillow <dave@thedillows.org>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/ethernet/3com/typhoon*
 
 3WARE SAS/SATA-RAID SCSI DRIVERS (3W-XXXX, 3W-9XXX, 3W-SAS)
 M:	Adam Radford <aradford@gmail.com>
 L:	linux-scsi@vger.kernel.org
 W:	http://www.lsi.com
 S:	Supported
 F:	drivers/scsi/3w-*
 
 53C700 AND 53C700-66 SCSI DRIVER
 M:	"James E.J. Bottomley" <James.Bottomley@HansenPartnership.com>
 L:	linux-scsi@vger.kernel.org
 S:	Maintained
 F:	drivers/scsi/53c700*
 
 6LOWPAN GENERIC (BTLE/IEEE 802.15.4)
 M:	Alexander Aring <aar@pengutronix.de>
 M:	Jukka Rissanen <jukka.rissanen@linux.intel.com>
 L:	linux-bluetooth@vger.kernel.org
 L:	linux-wpan@vger.kernel.org
 S:	Maintained
 F:	net/6lowpan/
 F:	include/net/6lowpan.h
 F:	Documentation/networking/6lowpan.txt
 
 6PACK NETWORK DRIVER FOR AX.25
 M:	Andreas Koensgen <ajk@comnets.uni-bremen.de>
 L:	linux-hams@vger.kernel.org
 S:	Maintained
 F:	drivers/net/hamradio/6pack.c
 
 8169 10/100/1000 GIGABIT ETHERNET DRIVER
 M:	Realtek linux nic maintainers <nic_swsd@realtek.com>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/ethernet/realtek/r8169.c
 
 8250/16?50 (AND CLONE UARTS) SERIAL DRIVER
 M:	Greg Kroah-Hartman <gregkh@linuxfoundation.org>
 L:	linux-serial@vger.kernel.org
 S:	Maintained
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/tty.git
 F:	drivers/tty/serial/8250*
 F:	include/linux/serial_8250.h
 
 8390 NETWORK DRIVERS [WD80x3/SMC-ELITE, SMC-ULTRA, NE2000, 3C503, etc.]
 L:	netdev@vger.kernel.org
 S:	Orphan / Obsolete
 F:	drivers/net/ethernet/8390/
 
 9P FILE SYSTEM
 M:	Eric Van Hensbergen <ericvh@gmail.com>
 M:	Ron Minnich <rminnich@sandia.gov>
 M:	Latchesar Ionkov <lucho@ionkov.net>
 L:	v9fs-developer@lists.sourceforge.net
 W:	http://swik.net/v9fs
 Q:	http://patchwork.kernel.org/project/v9fs-devel/list/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/ericvh/v9fs.git
 S:	Maintained
 F:	Documentation/filesystems/9p.txt
 F:	fs/9p/
 F:	net/9p/
 F:	include/net/9p/
 F:	include/uapi/linux/virtio_9p.h
 F:	include/trace/events/9p.h
 
 
 A8293 MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://palosaari.fi/linux/
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/anttip/media_tree.git
 S:	Maintained
 F:	drivers/media/dvb-frontends/a8293*
 
 AACRAID SCSI RAID DRIVER
 M:	Adaptec OEM Raid Solutions <aacraid@microsemi.com>
 L:	linux-scsi@vger.kernel.org
 W:	http://www.adaptec.com/
 S:	Supported
 F:	Documentation/scsi/aacraid.txt
 F:	drivers/scsi/aacraid/
 
 ABI/API
 L:	linux-api@vger.kernel.org
 F:	include/linux/syscalls.h
 F:	kernel/sys_ni.c
 
 ABIT UGURU 1,2 HARDWARE MONITOR DRIVER
 M:	Hans de Goede <hdegoede@redhat.com>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	drivers/hwmon/abituguru.c
 
 ABIT UGURU 3 HARDWARE MONITOR DRIVER
 M:	Alistair John Strachan <alistair@devzero.co.uk>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	drivers/hwmon/abituguru3.c
 
 ACCES 104-DIO-48E GPIO DRIVER
 M:	William Breathitt Gray <vilhelm.gray@gmail.com>
 L:	linux-gpio@vger.kernel.org
 S:	Maintained
 F:	drivers/gpio/gpio-104-dio-48e.c
 
 ACCES 104-IDI-48 GPIO DRIVER
 M:	"William Breathitt Gray" <vilhelm.gray@gmail.com>
 L:	linux-gpio@vger.kernel.org
 S:	Maintained
 F:	drivers/gpio/gpio-104-idi-48.c
 
 ACCES 104-IDIO-16 GPIO DRIVER
 M:	"William Breathitt Gray" <vilhelm.gray@gmail.com>
 L:	linux-gpio@vger.kernel.org
 S:	Maintained
 F:	drivers/gpio/gpio-104-idio-16.c
 
 ACCES 104-QUAD-8 IIO DRIVER
 M:	William Breathitt Gray <vilhelm.gray@gmail.com>
 L:	linux-iio@vger.kernel.org
 S:	Maintained
 F:	drivers/iio/counter/104-quad-8.c
 
 ACENIC DRIVER
 M:	Jes Sorensen <jes@trained-monkey.org>
 L:	linux-acenic@sunsite.dk
 S:	Maintained
 F:	drivers/net/ethernet/alteon/acenic*
 
 ACER ASPIRE ONE TEMPERATURE AND FAN DRIVER
 M:	Peter Feuerer <peter@piie.net>
 L:	platform-driver-x86@vger.kernel.org
 W:	http://piie.net/?section=acerhdf
 S:	Maintained
 F:	drivers/platform/x86/acerhdf.c
 
 ACER WMI LAPTOP EXTRAS
 M:	"Lee, Chun-Yi" <jlee@suse.com>
 L:	platform-driver-x86@vger.kernel.org
 S:	Maintained
 F:	drivers/platform/x86/acer-wmi.c
 
 ACPI
 M:	"Rafael J. Wysocki" <rjw@rjwysocki.net>
 M:	Len Brown <lenb@kernel.org>
 L:	linux-acpi@vger.kernel.org
 W:	https://01.org/linux-acpi
 Q:	https://patchwork.kernel.org/project/linux-acpi/list/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm
 B:	https://bugzilla.kernel.org
 S:	Supported
 F:	drivers/acpi/
 F:	drivers/pnp/pnpacpi/
 F:	include/linux/acpi.h
 F:	include/acpi/
 F:	Documentation/acpi/
 F:	Documentation/ABI/testing/sysfs-bus-acpi
 F:	Documentation/ABI/testing/configfs-acpi
 F:	drivers/pci/*acpi*
 F:	drivers/pci/*/*acpi*
 F:	drivers/pci/*/*/*acpi*
 F:	tools/power/acpi/
 
 ACPI COMPONENT ARCHITECTURE (ACPICA)
 M:	Robert Moore <robert.moore@intel.com>
 M:	Lv Zheng <lv.zheng@intel.com>
 M:	"Rafael J. Wysocki" <rafael.j.wysocki@intel.com>
 L:	linux-acpi@vger.kernel.org
 L:	devel@acpica.org
 W:	https://acpica.org/
 W:	https://github.com/acpica/acpica/
 Q:	https://patchwork.kernel.org/project/linux-acpi/list/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm
 B:	https://bugzilla.kernel.org
 B:	https://bugs.acpica.org
 S:	Supported
 F:	drivers/acpi/acpica/
 F:	include/acpi/
 F:	tools/power/acpi/
 
 ACPI FAN DRIVER
 M:	Zhang Rui <rui.zhang@intel.com>
 L:	linux-acpi@vger.kernel.org
 W:	https://01.org/linux-acpi
 B:	https://bugzilla.kernel.org
 S:	Supported
 F:	drivers/acpi/fan.c
 
 ACPI FOR ARM64 (ACPI/arm64)
 M:	Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
 M:	Hanjun Guo <hanjun.guo@linaro.org>
 M:	Sudeep Holla <sudeep.holla@arm.com>
 L:	linux-acpi@vger.kernel.org
 S:	Maintained
 F:	drivers/acpi/arm64
 
 ACPI THERMAL DRIVER
 M:	Zhang Rui <rui.zhang@intel.com>
 L:	linux-acpi@vger.kernel.org
 W:	https://01.org/linux-acpi
 B:	https://bugzilla.kernel.org
 S:	Supported
 F:	drivers/acpi/*thermal*
 
 ACPI VIDEO DRIVER
 M:	Zhang Rui <rui.zhang@intel.com>
 L:	linux-acpi@vger.kernel.org
 W:	https://01.org/linux-acpi
 B:	https://bugzilla.kernel.org
 S:	Supported
 F:	drivers/acpi/acpi_video.c
 
 ACPI WMI DRIVER
 L:	platform-driver-x86@vger.kernel.org
 S:	Orphan
 F:	drivers/platform/x86/wmi.c
 
 AD1889 ALSA SOUND DRIVER
 M:	Thibaut Varene <T-Bone@parisc-linux.org>
 W:	http://wiki.parisc-linux.org/AD1889
 L:	linux-parisc@vger.kernel.org
 S:	Maintained
 F:	sound/pci/ad1889.*
 
 AD525X ANALOG DEVICES DIGITAL POTENTIOMETERS DRIVER
 M:	Michael Hennerich <michael.hennerich@analog.com>
 W:	http://wiki.analog.com/AD5254
 W:	http://ez.analog.com/community/linux-device-drivers
 S:	Supported
 F:	drivers/misc/ad525x_dpot.c
 
 AD5398 CURRENT REGULATOR DRIVER (AD5398/AD5821)
 M:	Michael Hennerich <michael.hennerich@analog.com>
 W:	http://wiki.analog.com/AD5398
 W:	http://ez.analog.com/community/linux-device-drivers
 S:	Supported
 F:	drivers/regulator/ad5398.c
 
 AD714X CAPACITANCE TOUCH SENSOR DRIVER (AD7142/3/7/8/7A)
 M:	Michael Hennerich <michael.hennerich@analog.com>
 W:	http://wiki.analog.com/AD7142
 W:	http://ez.analog.com/community/linux-device-drivers
 S:	Supported
 F:	drivers/input/misc/ad714x.c
 
 AD7877 TOUCHSCREEN DRIVER
 M:	Michael Hennerich <michael.hennerich@analog.com>
 W:	http://wiki.analog.com/AD7877
 W:	http://ez.analog.com/community/linux-device-drivers
 S:	Supported
 F:	drivers/input/touchscreen/ad7877.c
 
 AD7879 TOUCHSCREEN DRIVER (AD7879/AD7889)
 M:	Michael Hennerich <michael.hennerich@analog.com>
 W:	http://wiki.analog.com/AD7879
 W:	http://ez.analog.com/community/linux-device-drivers
 S:	Supported
 F:	drivers/input/touchscreen/ad7879.c
 
 ADDRESS SPACE LAYOUT RANDOMIZATION (ASLR)
 M:	Jiri Kosina <jikos@kernel.org>
 S:	Maintained
 
 ADF7242 IEEE 802.15.4 RADIO DRIVER
 M:	Michael Hennerich <michael.hennerich@analog.com>
 W:	https://wiki.analog.com/ADF7242
 W:	http://ez.analog.com/community/linux-device-drivers
 L:	linux-wpan@vger.kernel.org
 S:	Supported
 F:	drivers/net/ieee802154/adf7242.c
 F:	Documentation/devicetree/bindings/net/ieee802154/adf7242.txt
 
 ADM1025 HARDWARE MONITOR DRIVER
 M:	Jean Delvare <jdelvare@suse.com>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	Documentation/hwmon/adm1025
 F:	drivers/hwmon/adm1025.c
 
 ADM1029 HARDWARE MONITOR DRIVER
 M:	Corentin Labbe <clabbe.montjoie@gmail.com>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	drivers/hwmon/adm1029.c
 
 ADM8211 WIRELESS DRIVER
 L:	linux-wireless@vger.kernel.org
 W:	http://wireless.kernel.org/
 S:	Orphan
 F:	drivers/net/wireless/admtek/adm8211.*
 
 ADP1653 FLASH CONTROLLER DRIVER
 M:	Sakari Ailus <sakari.ailus@iki.fi>
 L:	linux-media@vger.kernel.org
 S:	Maintained
 F:	drivers/media/i2c/adp1653.c
 F:	include/media/i2c/adp1653.h
 
 ADP5520 BACKLIGHT DRIVER WITH IO EXPANDER (ADP5520/ADP5501)
 M:	Michael Hennerich <michael.hennerich@analog.com>
 W:	http://wiki.analog.com/ADP5520
 W:	http://ez.analog.com/community/linux-device-drivers
 S:	Supported
 F:	drivers/mfd/adp5520.c
 F:	drivers/video/backlight/adp5520_bl.c
 F:	drivers/leds/leds-adp5520.c
 F:	drivers/gpio/gpio-adp5520.c
 F:	drivers/input/keyboard/adp5520-keys.c
 
 ADP5588 QWERTY KEYPAD AND IO EXPANDER DRIVER (ADP5588/ADP5587)
 M:	Michael Hennerich <michael.hennerich@analog.com>
 W:	http://wiki.analog.com/ADP5588
 W:	http://ez.analog.com/community/linux-device-drivers
 S:	Supported
 F:	drivers/input/keyboard/adp5588-keys.c
 F:	drivers/gpio/gpio-adp5588.c
 
 ADP8860 BACKLIGHT DRIVER (ADP8860/ADP8861/ADP8863)
 M:	Michael Hennerich <michael.hennerich@analog.com>
 W:	http://wiki.analog.com/ADP8860
 W:	http://ez.analog.com/community/linux-device-drivers
 S:	Supported
 F:	drivers/video/backlight/adp8860_bl.c
 
 ADS1015 HARDWARE MONITOR DRIVER
 M:	Dirk Eibach <eibach@gdsys.de>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	Documentation/hwmon/ads1015
 F:	drivers/hwmon/ads1015.c
 F:	include/linux/i2c/ads1015.h
 
 ADT746X FAN DRIVER
 M:	Colin Leroy <colin@colino.net>
 S:	Maintained
 F:	drivers/macintosh/therm_adt746x.c
 
 ADT7475 HARDWARE MONITOR DRIVER
 M:	Jean Delvare <jdelvare@suse.com>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	Documentation/hwmon/adt7475
 F:	drivers/hwmon/adt7475.c
 
 ADXL34X THREE-AXIS DIGITAL ACCELEROMETER DRIVER (ADXL345/ADXL346)
 M:	Michael Hennerich <michael.hennerich@analog.com>
 W:	http://wiki.analog.com/ADXL345
 W:	http://ez.analog.com/community/linux-device-drivers
 S:	Supported
 F:	drivers/input/misc/adxl34x.c
 
 ADVANSYS SCSI DRIVER
 M:	Matthew Wilcox <matthew@wil.cx>
 M:	Hannes Reinecke <hare@suse.com>
 L:	linux-scsi@vger.kernel.org
 S:	Maintained
 F:	Documentation/scsi/advansys.txt
 F:	drivers/scsi/advansys.c
 
 AEDSP16 DRIVER
 M:	Riccardo Facchetti <fizban@tin.it>
 S:	Maintained
 F:	sound/oss/aedsp16.c
 
 AF9013 MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://palosaari.fi/linux/
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/anttip/media_tree.git
 S:	Maintained
 F:	drivers/media/dvb-frontends/af9013*
 
 AF9033 MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://palosaari.fi/linux/
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/anttip/media_tree.git
 S:	Maintained
 F:	drivers/media/dvb-frontends/af9033*
 
 AFFS FILE SYSTEM
 L:	linux-fsdevel@vger.kernel.org
 S:	Orphan
 F:	Documentation/filesystems/affs.txt
 F:	fs/affs/
 
 AFS FILESYSTEM & AF_RXRPC SOCKET DOMAIN
 M:	David Howells <dhowells@redhat.com>
 L:	linux-afs@lists.infradead.org
 S:	Supported
 F:	fs/afs/
 F:	include/net/af_rxrpc.h
 F:	net/rxrpc/af_rxrpc.c
 W:	https://www.infradead.org/~dhowells/kafs/
 
 AGPGART DRIVER
 M:	David Airlie <airlied@linux.ie>
 T:	git git://people.freedesktop.org/~airlied/linux (part of drm maint)
 S:	Maintained
 F:	drivers/char/agp/
 F:	include/linux/agp*
 F:	include/uapi/linux/agp*
 
 AHA152X SCSI DRIVER
 M:	"Juergen E. Fischer" <fischer@norbit.de>
 L:	linux-scsi@vger.kernel.org
 S:	Maintained
 F:	drivers/scsi/aha152x*
 F:	drivers/scsi/pcmcia/aha152x*
 
 AIC7XXX / AIC79XX SCSI DRIVER
 M:	Hannes Reinecke <hare@suse.com>
 L:	linux-scsi@vger.kernel.org
 S:	Maintained
 F:	drivers/scsi/aic7xxx/
 
 AIMSLAB FM RADIO RECEIVER DRIVER
 M:	Hans Verkuil <hverkuil@xs4all.nl>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 W:	https://linuxtv.org
 S:	Maintained
 F:	drivers/media/radio/radio-aimslab*
 
 AIO
 M:	Benjamin LaHaise <bcrl@kvack.org>
 L:	linux-aio@kvack.org
 S:	Supported
 F:	fs/aio.c
 F:	include/linux/*aio*.h
 
 AIRSPY MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://palosaari.fi/linux/
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/anttip/media_tree.git
 S:	Maintained
 F:	drivers/media/usb/airspy/
 
 ALACRITECH GIGABIT ETHERNET DRIVER
 M:	Lino Sanfilippo <LinoSanfilippo@gmx.de>
 S:	Maintained
 F:	drivers/net/ethernet/alacritech/*
 
 ALCATEL SPEEDTOUCH USB DRIVER
 M:	Duncan Sands <duncan.sands@free.fr>
 L:	linux-usb@vger.kernel.org
 W:	http://www.linux-usb.org/SpeedTouch/
 S:	Maintained
 F:	drivers/usb/atm/speedtch.c
 F:	drivers/usb/atm/usbatm.c
 
 ALCHEMY AU1XX0 MMC DRIVER
 M:	Manuel Lauss <manuel.lauss@gmail.com>
 S:	Maintained
 F:	drivers/mmc/host/au1xmmc.c
 
 ALI1563 I2C DRIVER
 M:	Rudolf Marek <r.marek@assembler.cz>
 L:	linux-i2c@vger.kernel.org
 S:	Maintained
 F:	Documentation/i2c/busses/i2c-ali1563
 F:	drivers/i2c/busses/i2c-ali1563.c
 
 ALLWINNER SECURITY SYSTEM
 M:	Corentin Labbe <clabbe.montjoie@gmail.com>
 L:	linux-crypto@vger.kernel.org
 S:	Maintained
 F:	drivers/crypto/sunxi-ss/
 
 ALPHA PORT
 M:	Richard Henderson <rth@twiddle.net>
 M:	Ivan Kokshaysky <ink@jurassic.park.msu.ru>
 M:	Matt Turner <mattst88@gmail.com>
 S:	Odd Fixes
 L:	linux-alpha@vger.kernel.org
 F:	arch/alpha/
 
 ALPS PS/2 TOUCHPAD DRIVER
 R:	Pali RohÃ¡r <pali.rohar@gmail.com>
 F:	drivers/input/mouse/alps.*
 
 ALTERA MAILBOX DRIVER
 M:	Ley Foon Tan <lftan@altera.com>
 L:	nios2-dev@lists.rocketboards.org (moderated for non-subscribers)
 S:	Maintained
 F:	drivers/mailbox/mailbox-altera.c
 
 ALTERA PIO DRIVER
 M:	Tien Hock Loh <thloh@altera.com>
 L:	linux-gpio@vger.kernel.org
 S:	Maintained
 F:	drivers/gpio/gpio-altera.c
 
 ALTERA SYSTEM RESOURCE DRIVER FOR ARRIA10 DEVKIT
 M:	Thor Thayer <thor.thayer@linux.intel.com>
 S:	Maintained
 F:	drivers/gpio/gpio-altera-a10sr.c
 F:	drivers/mfd/altera-a10sr.c
 F:	include/linux/mfd/altera-a10sr.h
 
 ALTERA TRIPLE SPEED ETHERNET DRIVER
 M:	Vince Bridgers <vbridger@opensource.altera.com>
 L:	netdev@vger.kernel.org
 L:	nios2-dev@lists.rocketboards.org (moderated for non-subscribers)
 S:	Maintained
 F:	drivers/net/ethernet/altera/
 
 ALTERA UART/JTAG UART SERIAL DRIVERS
 M:	Tobias Klauser <tklauser@distanz.ch>
 L:	linux-serial@vger.kernel.org
 L:	nios2-dev@lists.rocketboards.org (moderated for non-subscribers)
 S:	Maintained
 F:	drivers/tty/serial/altera_uart.c
 F:	drivers/tty/serial/altera_jtaguart.c
 F:	include/linux/altera_uart.h
 F:	include/linux/altera_jtaguart.h
 
 AMAZON ETHERNET DRIVERS
 M:	Netanel Belgazal <netanel@annapurnalabs.com>
 R:	Saeed Bishara <saeed@annapurnalabs.com>
 R:	Zorik Machulsky <zorik@annapurnalabs.com>
 L:	netdev@vger.kernel.org
 S:	Supported
 F:	Documentation/networking/ena.txt
 F:	drivers/net/ethernet/amazon/
 
 AMD CRYPTOGRAPHIC COPROCESSOR (CCP) DRIVER
 M:	Tom Lendacky <thomas.lendacky@amd.com>
 M:	Gary Hook <gary.hook@amd.com>
 L:	linux-crypto@vger.kernel.org
 S:	Supported
 F:	drivers/crypto/ccp/
 F:	include/linux/ccp.h
 
 AMD FAM15H PROCESSOR POWER MONITORING DRIVER
 M:	Huang Rui <ray.huang@amd.com>
 L:	linux-hwmon@vger.kernel.org
 S:	Supported
 F:	Documentation/hwmon/fam15h_power
 F:	drivers/hwmon/fam15h_power.c
 
 AMD GEODE CS5536 USB DEVICE CONTROLLER DRIVER
 L:	linux-geode@lists.infradead.org (moderated for non-subscribers)
 S:	Orphan
 F:	drivers/usb/gadget/udc/amd5536udc.*
 
 AMD GEODE PROCESSOR/CHIPSET SUPPORT
 P:	Andres Salomon <dilinger@queued.net>
 L:	linux-geode@lists.infradead.org (moderated for non-subscribers)
 W:	http://www.amd.com/us-en/ConnectivitySolutions/TechnicalResources/0,,50_2334_2452_11363,00.html
 S:	Supported
 F:	drivers/char/hw_random/geode-rng.c
 F:	drivers/crypto/geode*
 F:	drivers/video/fbdev/geode/
 F:	arch/x86/include/asm/geode.h
 
 AMD IOMMU (AMD-VI)
 M:	Joerg Roedel <joro@8bytes.org>
 L:	iommu@lists.linux-foundation.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/joro/iommu.git
 S:	Maintained
 F:	drivers/iommu/amd_iommu*.[ch]
 F:	include/linux/amd-iommu.h
 
 AMD KFD
 M:	Oded Gabbay <oded.gabbay@gmail.com>
 L:	dri-devel@lists.freedesktop.org
 T:	git git://people.freedesktop.org/~gabbayo/linux.git
 S:	Supported
 F:	drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd.c
 F:	drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd.h
 F:	drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd_gfx_v7.c
 F:	drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd_gfx_v8.c
 F:	drivers/gpu/drm/amd/amdkfd/
 F:	drivers/gpu/drm/amd/include/cik_structs.h
 F:	drivers/gpu/drm/amd/include/kgd_kfd_interface.h
 F:	drivers/gpu/drm/amd/include/vi_structs.h
 F:	drivers/gpu/drm/radeon/radeon_kfd.c
 F:	drivers/gpu/drm/radeon/radeon_kfd.h
 F:	include/uapi/linux/kfd_ioctl.h
 
 AMD SEATTLE DEVICE TREE SUPPORT
 M:	Brijesh Singh <brijeshkumar.singh@amd.com>
 M:	Suravee Suthikulpanit <suravee.suthikulpanit@amd.com>
 M:	Tom Lendacky <thomas.lendacky@amd.com>
 S:	Supported
 F:	arch/arm64/boot/dts/amd/
 
 AMD XGBE DRIVER
 M:	Tom Lendacky <thomas.lendacky@amd.com>
 L:	netdev@vger.kernel.org
 S:	Supported
 F:	drivers/net/ethernet/amd/xgbe/
 F:	arch/arm64/boot/dts/amd/amd-seattle-xgbe*.dtsi
 
 AMS (Apple Motion Sensor) DRIVER
 M:	Michael Hanselmann <linux-kernel@hansmi.ch>
 S:	Supported
 F:	drivers/macintosh/ams/
 
 ANALOG DEVICES INC AD9389B DRIVER
 M:	Hans Verkuil <hans.verkuil@cisco.com>
 L:	linux-media@vger.kernel.org
 S:	Maintained
 F:	drivers/media/i2c/ad9389b*
 
 ANALOG DEVICES INC ADV7180 DRIVER
 M:	Lars-Peter Clausen <lars@metafoo.de>
 L:	linux-media@vger.kernel.org
 W:	http://ez.analog.com/community/linux-device-drivers
 S:	Supported
 F:	drivers/media/i2c/adv7180.c
 
 ANALOG DEVICES INC ADV7511 DRIVER
 M:	Hans Verkuil <hans.verkuil@cisco.com>
 L:	linux-media@vger.kernel.org
 S:	Maintained
 F:	drivers/media/i2c/adv7511*
 
 ANALOG DEVICES INC ADV7604 DRIVER
 M:	Hans Verkuil <hans.verkuil@cisco.com>
 L:	linux-media@vger.kernel.org
 S:	Maintained
 F:	drivers/media/i2c/adv7604*
 
 ANALOG DEVICES INC ADV7842 DRIVER
 M:	Hans Verkuil <hans.verkuil@cisco.com>
 L:	linux-media@vger.kernel.org
 S:	Maintained
 F:	drivers/media/i2c/adv7842*
 
 ANALOG DEVICES INC ASOC CODEC DRIVERS
 M:	Lars-Peter Clausen <lars@metafoo.de>
 L:	alsa-devel@alsa-project.org (moderated for non-subscribers)
 W:	http://wiki.analog.com/
 W:	http://ez.analog.com/community/linux-device-drivers
 S:	Supported
 F:	sound/soc/codecs/adau*
 F:	sound/soc/codecs/adav*
 F:	sound/soc/codecs/ad1*
 F:	sound/soc/codecs/ad7*
 F:	sound/soc/codecs/ssm*
 F:	sound/soc/codecs/sigmadsp.*
 
 ANALOG DEVICES INC ASOC DRIVERS
 L:	adi-buildroot-devel@lists.sourceforge.net (moderated for non-subscribers)
 L:	alsa-devel@alsa-project.org (moderated for non-subscribers)
 W:	http://blackfin.uclinux.org/
 S:	Supported
 F:	sound/soc/blackfin/*
 
 ANALOG DEVICES INC IIO DRIVERS
 M:	Lars-Peter Clausen <lars@metafoo.de>
 M:	Michael Hennerich <Michael.Hennerich@analog.com>
 W:	http://wiki.analog.com/
 W:	http://ez.analog.com/community/linux-device-drivers
 S:	Supported
 F:	drivers/iio/*/ad*
 X:	drivers/iio/*/adjd*
 F:	drivers/staging/iio/*/ad*
 F:	drivers/staging/iio/trigger/iio-trig-bfin-timer.c
 
 ANALOG DEVICES INC DMA DRIVERS
 M:	Lars-Peter Clausen <lars@metafoo.de>
 W:	http://ez.analog.com/community/linux-device-drivers
 S:	Supported
 F:	drivers/dma/dma-axi-dmac.c
 
 ANDROID CONFIG FRAGMENTS
 M:	Rob Herring <robh@kernel.org>
 S:	Supported
 F:	kernel/configs/android*
 
 ANDROID DRIVERS
 M:	Greg Kroah-Hartman <gregkh@linuxfoundation.org>
 M:	Arve HjÃ¸nnevÃ¥g <arve@android.com>
 M:	Riley Andrews <riandrews@android.com>
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/staging.git
 L:	devel@driverdev.osuosl.org
 S:	Supported
 F:	drivers/android/
 F:	drivers/staging/android/
 
 ANDROID ION DRIVER
 M:	Laura Abbott <labbott@redhat.com>
 M:	Sumit Semwal <sumit.semwal@linaro.org>
 L:	devel@driverdev.osuosl.org
 S:	Supported
 F:	Documentation/devicetree/bindings/staging/ion/
 F:	drivers/staging/android/ion
 F:	drivers/staging/android/uapi/ion.h
 F:	drivers/staging/android/uapi/ion_test.h
 
 AOA (Apple Onboard Audio) ALSA DRIVER
 M:	Johannes Berg <johannes@sipsolutions.net>
 L:	linuxppc-dev@lists.ozlabs.org
 L:	alsa-devel@alsa-project.org (moderated for non-subscribers)
 S:	Maintained
 F:	sound/aoa/
 
 APEX EMBEDDED SYSTEMS STX104 IIO DRIVER
 M:	William Breathitt Gray <vilhelm.gray@gmail.com>
 L:	linux-iio@vger.kernel.org
 S:	Maintained
 F:	drivers/iio/adc/stx104.c
 
 APM DRIVER
 M:	Jiri Kosina <jikos@kernel.org>
 S:	Odd fixes
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/jikos/apm.git
 F:	arch/x86/kernel/apm_32.c
 F:	include/linux/apm_bios.h
 F:	include/uapi/linux/apm_bios.h
 F:	drivers/char/apm-emulation.c
 
 APPLE BCM5974 MULTITOUCH DRIVER
 M:	Henrik Rydberg <rydberg@bitmath.org>
 L:	linux-input@vger.kernel.org
 S:	Odd fixes
 F:	drivers/input/mouse/bcm5974.c
 
 APPLE SMC DRIVER
 M:	Henrik Rydberg <rydberg@bitmath.org>
 L:	linux-hwmon@vger.kernel.org
 S:	Odd fixes
 F:	drivers/hwmon/applesmc.c
 
 APPLETALK NETWORK LAYER
 L:	netdev@vger.kernel.org
 S:	Odd fixes
 F:	drivers/net/appletalk/
 F:	net/appletalk/
 
 APPLIED MICRO (APM) X-GENE DEVICE TREE SUPPORT
 M:	Duc Dang <dhdang@apm.com>
 S:	Supported
 F:	arch/arm64/boot/dts/apm/
 
 APPLIED MICRO (APM) X-GENE SOC ETHERNET DRIVER
 M:	Iyappan Subramanian <isubramanian@apm.com>
 M:	Keyur Chudgar <kchudgar@apm.com>
 S:	Supported
 F:	drivers/net/ethernet/apm/xgene/
 F:	drivers/net/phy/mdio-xgene.c
 F:	Documentation/devicetree/bindings/net/apm-xgene-enet.txt
 F:	Documentation/devicetree/bindings/net/apm-xgene-mdio.txt
 
 APPLIED MICRO (APM) X-GENE SOC PMU
 M:	Tai Nguyen <ttnguyen@apm.com>
 S:	Supported
 F:	drivers/perf/xgene_pmu.c
 F:	Documentation/perf/xgene-pmu.txt
 F:	Documentation/devicetree/bindings/perf/apm-xgene-pmu.txt
 
 APTINA CAMERA SENSOR PLL
 M:	Laurent Pinchart <Laurent.pinchart@ideasonboard.com>
 L:	linux-media@vger.kernel.org
 S:	Maintained
 F:	drivers/media/i2c/aptina-pll.*
 
 ARC FRAMEBUFFER DRIVER
 M:	Jaya Kumar <jayalk@intworks.biz>
 S:	Maintained
 F:	drivers/video/fbdev/arcfb.c
 F:	drivers/video/fbdev/core/fb_defio.c
 
 ARCNET NETWORK LAYER
 M:	Michael Grzeschik <m.grzeschik@pengutronix.de>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/arcnet/
 F:	include/uapi/linux/if_arcnet.h
 
 ARC PGU DRM DRIVER
 M:	Alexey Brodkin <abrodkin@synopsys.com>
 S:	Supported
 F:	drivers/gpu/drm/arc/
 F:	Documentation/devicetree/bindings/display/snps,arcpgu.txt
 
 ARM ARCHITECTED TIMER DRIVER
 M:	Mark Rutland <mark.rutland@arm.com>
 M:	Marc Zyngier <marc.zyngier@arm.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	arch/arm/include/asm/arch_timer.h
 F:	arch/arm64/include/asm/arch_timer.h
 F:	drivers/clocksource/arm_arch_timer.c
 
 ARM HDLCD DRM DRIVER
 M:	Liviu Dudau <liviu.dudau@arm.com>
 S:	Supported
 F:	drivers/gpu/drm/arm/hdlcd_*
 F:	Documentation/devicetree/bindings/display/arm,hdlcd.txt
 
 ARM MALI-DP DRM DRIVER
 M:	Liviu Dudau <liviu.dudau@arm.com>
 M:	Brian Starkey <brian.starkey@arm.com>
 M:	Mali DP Maintainers <malidp@foss.arm.com>
 S:	Supported
 F:	drivers/gpu/drm/arm/
 F:	Documentation/devicetree/bindings/display/arm,malidp.txt
 
 ARM MFM AND FLOPPY DRIVERS
 M:	Ian Molton <spyro@f2s.com>
 S:	Maintained
 F:	arch/arm/lib/floppydma.S
 F:	arch/arm/include/asm/floppy.h
 
 ARM PMU PROFILING AND DEBUGGING
 M:	Will Deacon <will.deacon@arm.com>
 M:	Mark Rutland <mark.rutland@arm.com>
 S:	Maintained
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 F:	arch/arm*/kernel/perf_*
 F:	arch/arm/oprofile/common.c
 F:	arch/arm*/kernel/hw_breakpoint.c
 F:	arch/arm*/include/asm/hw_breakpoint.h
 F:	arch/arm*/include/asm/perf_event.h
 F:	drivers/perf/*
 F:	include/linux/perf/arm_pmu.h
 F:	Documentation/devicetree/bindings/arm/pmu.txt
 
 ARM PORT
 M:	Russell King <linux@armlinux.org.uk>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 W:	http://www.armlinux.org.uk/
 S:	Maintained
 T:	git git://git.armlinux.org.uk/~rmk/linux-arm.git
 F:	arch/arm/
 
 ARM SUB-ARCHITECTURES
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	arch/arm/mach-*/
 F:	arch/arm/plat-*/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/arm/arm-soc.git
 
 ARM PRIMECELL AACI PL041 DRIVER
 M:	Russell King <linux@armlinux.org.uk>
 S:	Maintained
 F:	sound/arm/aaci.*
 
 ARM PRIMECELL CLCD PL110 DRIVER
 M:	Russell King <linux@armlinux.org.uk>
 S:	Maintained
 F:	drivers/video/fbdev/amba-clcd.*
 
 ARM PRIMECELL KMI PL050 DRIVER
 M:	Russell King <linux@armlinux.org.uk>
 S:	Maintained
 F:	drivers/input/serio/ambakmi.*
 F:	include/linux/amba/kmi.h
 
 ARM PRIMECELL MMCI PL180/1 DRIVER
 M:	Russell King <linux@armlinux.org.uk>
 S:	Maintained
 F:	drivers/mmc/host/mmci.*
 F:	include/linux/amba/mmci.h
 
 ARM PRIMECELL UART PL010 AND PL011 DRIVERS
 M:	Russell King <linux@armlinux.org.uk>
 S:	Maintained
 F:	drivers/tty/serial/amba-pl01*.c
 F:	include/linux/amba/serial.h
 
 ARM PRIMECELL BUS SUPPORT
 M:	Russell King <linux@armlinux.org.uk>
 S:	Maintained
 F:	drivers/amba/
 F:	include/linux/amba/bus.h
 
 ARM/ADS SPHERE MACHINE SUPPORT
 M:	Lennert Buytenhek <kernel@wantstofly.org>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 
 ARM/AFEB9260 MACHINE SUPPORT
 M:	Sergey Lapin <slapin@ossfans.org>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 
 ARM/AJECO 1ARM MACHINE SUPPORT
 M:	Lennert Buytenhek <kernel@wantstofly.org>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 
 ARM/Allwinner sunXi SoC support
 M:	Maxime Ripard <maxime.ripard@free-electrons.com>
 M:	Chen-Yu Tsai <wens@csie.org>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 N:	sun[x456789]i
 F:	arch/arm/boot/dts/ntc-gr8*
 F:	arch/arm64/boot/dts/allwinner/
 
 ARM/Allwinner SoC Clock Support
 M:	Emilio LÃ³pez <emilio@elopez.com.ar>
 S:	Maintained
 F:	drivers/clk/sunxi/
 
 ARM/Amlogic Meson SoC support
 M:	Carlo Caione <carlo@caione.org>
 M:	Kevin Hilman <khilman@baylibre.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 L:	linux-amlogic@lists.infradead.org
 W:	http://linux-meson.com/
 S:	Maintained
 F:	arch/arm/mach-meson/
 F:	arch/arm/boot/dts/meson*
 F:	arch/arm64/boot/dts/amlogic/
 F: 	drivers/pinctrl/meson/
 F:	drivers/mmc/host/meson*
 N:	meson
 
 ARM/Annapurna Labs ALPINE ARCHITECTURE
 M:	Tsahee Zidenberg <tsahee@annapurnalabs.com>
 M:	Antoine Tenart <antoine.tenart@free-electrons.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	arch/arm/mach-alpine/
 F:	arch/arm/boot/dts/alpine*
 F:	arch/arm64/boot/dts/al/
 F:	drivers/*/*alpine*
 
 ARM/ARTPEC MACHINE SUPPORT
 M:	Jesper Nilsson <jesper.nilsson@axis.com>
 M:	Lars Persson <lars.persson@axis.com>
 M:	Niklas Cassel <niklas.cassel@axis.com>
 S:	Maintained
 L:	linux-arm-kernel@axis.com
 F:	arch/arm/mach-artpec
 F:	arch/arm/boot/dts/artpec6*
 F:	drivers/clk/axis
 
 ARM/ASPEED MACHINE SUPPORT
 M:	Joel Stanley <joel@jms.id.au>
 S:	Maintained
 F:	arch/arm/mach-aspeed/
 F:	arch/arm/boot/dts/aspeed-*
 F:	drivers/*/*aspeed*
 
 ARM/ATMEL AT91RM9200, AT91SAM9 AND SAMA5 SOC SUPPORT
 M:	Nicolas Ferre <nicolas.ferre@microchip.com>
 M:	Alexandre Belloni <alexandre.belloni@free-electrons.com>
 M:	Jean-Christophe Plagniol-Villard <plagnioj@jcrosoft.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 W:	http://www.linux4sam.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/nferre/linux-at91.git
 S:	Supported
 F:	arch/arm/mach-at91/
 F:	include/soc/at91/
 F:	arch/arm/boot/dts/at91*.dts
 F:	arch/arm/boot/dts/at91*.dtsi
 F:	arch/arm/boot/dts/sama*.dts
 F:	arch/arm/boot/dts/sama*.dtsi
 F:	arch/arm/include/debug/at91.S
 
 ARM/ATMEL AT91 Clock Support
 M:	Boris Brezillon <boris.brezillon@free-electrons.com>
 S:	Maintained
 F:	drivers/clk/at91
 
 ARM/CALXEDA HIGHBANK ARCHITECTURE
 M:	Rob Herring <robh@kernel.org>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	arch/arm/mach-highbank/
 F:	arch/arm/boot/dts/highbank.dts
 F:	arch/arm/boot/dts/ecx-*.dts*
 
 ARM/CAVIUM NETWORKS CNS3XXX MACHINE SUPPORT
 M:	Krzysztof Halasa <khalasa@piap.pl>
 S:	Maintained
 F:	arch/arm/mach-cns3xxx/
 
 ARM/CAVIUM THUNDER NETWORK DRIVER
 M:	Sunil Goutham <sgoutham@cavium.com>
 M:	Robert Richter <rric@kernel.org>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Supported
 F:	drivers/net/ethernet/cavium/thunder/
 
 ARM/CIRRUS LOGIC CLPS711X ARM ARCHITECTURE
 M:	Alexander Shiyan <shc_work@mail.ru>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Odd Fixes
 N:	clps711x
 
 ARM/CIRRUS LOGIC EP93XX ARM ARCHITECTURE
 M:	Hartley Sweeten <hsweeten@visionengravers.com>
 M:	Ryan Mallon <rmallon@gmail.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	arch/arm/mach-ep93xx/
 F:	arch/arm/mach-ep93xx/include/mach/
 
 ARM/CIRRUS LOGIC EDB9315A MACHINE SUPPORT
 M:	Lennert Buytenhek <kernel@wantstofly.org>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 
 ARM/CLKDEV SUPPORT
 M:	Russell King <linux@armlinux.org.uk>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 T:	git git://git.armlinux.org.uk/~rmk/linux-arm.git clkdev
 F:	arch/arm/include/asm/clkdev.h
 F:	drivers/clk/clkdev.c
 
 ARM/COMPULAB CM-X270/EM-X270 and CM-X300 MACHINE SUPPORT
 M:	Mike Rapoport <mike@compulab.co.il>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 
 ARM/CONTEC MICRO9 MACHINE SUPPORT
 M:	Hubert Feurstein <hubert.feurstein@contec.at>
 S:	Maintained
 F:	arch/arm/mach-ep93xx/micro9.c
 
 ARM/CORESIGHT FRAMEWORK AND DRIVERS
 M:	Mathieu Poirier <mathieu.poirier@linaro.org>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	drivers/hwtracing/coresight/*
 F:	Documentation/trace/coresight.txt
 F:	Documentation/devicetree/bindings/arm/coresight.txt
 F:	Documentation/ABI/testing/sysfs-bus-coresight-devices-*
 F:	tools/perf/arch/arm/util/pmu.c
 F:	tools/perf/arch/arm/util/auxtrace.c
 F:	tools/perf/arch/arm/util/cs-etm.c
 F:	tools/perf/arch/arm/util/cs-etm.h
 F:	tools/perf/util/cs-etm.h
 
 ARM/CORGI MACHINE SUPPORT
 M:	Richard Purdie <rpurdie@rpsys.net>
 S:	Maintained
 
 ARM/CORTINA SYSTEMS GEMINI ARM ARCHITECTURE
 M:	Hans Ulli Kroll <ulli.kroll@googlemail.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 T:	git git://github.com/ulli-kroll/linux.git
 S:	Maintained
 F:	arch/arm/mach-gemini/
 F:	drivers/rtc/rtc-gemini.c
 
 ARM/CSR SIRFPRIMA2 MACHINE SUPPORT
 M:	Barry Song <baohua@kernel.org>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/baohua/linux.git
 S:	Maintained
 F:	arch/arm/boot/dts/prima2*
 F:	arch/arm/mach-prima2/
 F:	drivers/clk/sirf/
 F:	drivers/clocksource/timer-prima2.c
 F:	drivers/clocksource/timer-atlas7.c
 N:	[^a-z]sirf
 
 ARM/CONEXANT DIGICOLOR MACHINE SUPPORT
 M:	Baruch Siach <baruch@tkos.co.il>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	arch/arm/boot/dts/cx92755*
 N:	digicolor
 
 ARM/EBSA110 MACHINE SUPPORT
 M:	Russell King <linux@armlinux.org.uk>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 W:	http://www.armlinux.org.uk/
 S:	Maintained
 F:	arch/arm/mach-ebsa110/
 F:	drivers/net/ethernet/amd/am79c961a.*
 
 ARM/ENERGY MICRO (SILICON LABS) EFM32 SUPPORT
 M:	Uwe Kleine-KÃ¶nig <kernel@pengutronix.de>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 N:	efm32
 
 ARM/EZX SMARTPHONES (A780, A910, A1200, E680, ROKR E2 and ROKR E6)
 M:	Daniel Ribeiro <drwyrm@gmail.com>
 M:	Stefan Schmidt <stefan@openezx.org>
 M:	Harald Welte <laforge@openezx.org>
 L:	openezx-devel@lists.openezx.org (moderated for non-subscribers)
 W:	http://www.openezx.org/
 S:	Maintained
 T:	topgit git://git.openezx.org/openezx.git
 F:	arch/arm/mach-pxa/ezx.c
 
 ARM/FARADAY FA526 PORT
 M:	Hans Ulli Kroll <ulli.kroll@googlemail.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 T:	git git://git.berlios.de/gemini-board
 F:	arch/arm/mm/*-fa*
 
 ARM/FOOTBRIDGE ARCHITECTURE
 M:	Russell King <linux@armlinux.org.uk>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 W:	http://www.armlinux.org.uk/
 S:	Maintained
 F:	arch/arm/include/asm/hardware/dec21285.h
 F:	arch/arm/mach-footbridge/
 
 ARM/FREESCALE IMX / MXC ARM ARCHITECTURE
 M:	Shawn Guo <shawnguo@kernel.org>
 M:	Sascha Hauer <kernel@pengutronix.de>
 R:	Fabio Estevam <fabio.estevam@nxp.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/shawnguo/linux.git
 F:	arch/arm/mach-imx/
 F:	arch/arm/mach-mxs/
 F:	arch/arm/boot/dts/imx*
 F:	arch/arm/configs/imx*_defconfig
 F:	drivers/clk/imx/
 F:	include/soc/imx/
 
 ARM/FREESCALE VYBRID ARM ARCHITECTURE
 M:	Shawn Guo <shawnguo@kernel.org>
 M:	Sascha Hauer <kernel@pengutronix.de>
 R:	Stefan Agner <stefan@agner.ch>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/shawnguo/linux.git
 F:	arch/arm/mach-imx/*vf610*
 F:	arch/arm/boot/dts/vf*
 
 ARM/GLOMATION GESBC9312SX MACHINE SUPPORT
 M:	Lennert Buytenhek <kernel@wantstofly.org>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 
 ARM/GUMSTIX MACHINE SUPPORT
 M:	Steve Sakoman <sakoman@gmail.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 
 ARM/H4700 (HP IPAQ HX4700) MACHINE SUPPORT
 M:	Philipp Zabel <philipp.zabel@gmail.com>
 M:	Paul Parsons <lost.distance@yahoo.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	arch/arm/mach-pxa/hx4700.c
 F:	arch/arm/mach-pxa/include/mach/hx4700.h
 F:	sound/soc/pxa/hx4700.c
 
 ARM/HISILICON SOC SUPPORT
 M:	Wei Xu <xuwei5@hisilicon.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 W:	http://www.hisilicon.com
 S:	Supported
 T:	git git://github.com/hisilicon/linux-hisi.git
 F:	arch/arm/mach-hisi/
 F:	arch/arm/boot/dts/hi3*
 F:	arch/arm/boot/dts/hip*
 F:	arch/arm/boot/dts/hisi*
 F:	arch/arm64/boot/dts/hisilicon/
 
 ARM/HP JORNADA 7XX MACHINE SUPPORT
 M:	Kristoffer Ericson <kristoffer.ericson@gmail.com>
 W:	www.jlime.com
 S:	Maintained
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/kristoffer/linux-hpc.git
 F:	arch/arm/mach-sa1100/jornada720.c
 F:	arch/arm/mach-sa1100/include/mach/jornada720.h
 
 ARM/IGEP MACHINE SUPPORT
 M:	Enric Balletbo i Serra <eballetbo@gmail.com>
 M:	Javier Martinez Canillas <javier@dowhile0.org>
 L:	linux-omap@vger.kernel.org
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	arch/arm/boot/dts/omap3-igep*
 
 ARM/INCOME PXA270 SUPPORT
 M:	Marek Vasut <marek.vasut@gmail.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	arch/arm/mach-pxa/colibri-pxa270-income.c
 
 ARM/INTEL IOP32X ARM ARCHITECTURE
 M:	Lennert Buytenhek <kernel@wantstofly.org>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 
 ARM/INTEL IOP33X ARM ARCHITECTURE
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Orphan
 
 ARM/INTEL IOP13XX ARM ARCHITECTURE
 M:	Lennert Buytenhek <kernel@wantstofly.org>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 
 ARM/INTEL IQ81342EX MACHINE SUPPORT
 M:	Lennert Buytenhek <kernel@wantstofly.org>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 
 ARM/INTEL IXDP2850 MACHINE SUPPORT
 M:	Lennert Buytenhek <kernel@wantstofly.org>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 
 ARM/INTEL IXP4XX ARM ARCHITECTURE
 M:	Imre Kaloz <kaloz@openwrt.org>
 M:	Krzysztof Halasa <khalasa@piap.pl>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	arch/arm/mach-ixp4xx/
 
 ARM/INTEL RESEARCH IMOTE/STARGATE 2 MACHINE SUPPORT
 M:	Jonathan Cameron <jic23@cam.ac.uk>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	arch/arm/mach-pxa/stargate2.c
 F:	drivers/pcmcia/pxa2xx_stargate2.c
 
 ARM/INTEL XSC3 (MANZANO) ARM CORE
 M:	Lennert Buytenhek <kernel@wantstofly.org>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 
 ARM/IP FABRICS DOUBLE ESPRESSO MACHINE SUPPORT
 M:	Lennert Buytenhek <kernel@wantstofly.org>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 
 ARM/TEXAS INSTRUMENT KEYSTONE ARCHITECTURE
 M:	Santosh Shilimkar <ssantosh@kernel.org>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	arch/arm/mach-keystone/
 F:	arch/arm/boot/dts/keystone-*
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/ssantosh/linux-keystone.git
 
 ARM/TEXAS INSTRUMENT KEYSTONE CLOCK FRAMEWORK
 M:	Santosh Shilimkar <ssantosh@kernel.org>
 L:	linux-kernel@vger.kernel.org
 S:	Maintained
 F:	drivers/clk/keystone/
 
 ARM/TEXAS INSTRUMENT KEYSTONE ClOCKSOURCE
 M:	Santosh Shilimkar <ssantosh@kernel.org>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 L:	linux-kernel@vger.kernel.org
 S:	Maintained
 F:	drivers/clocksource/timer-keystone.c
 
 ARM/TEXAS INSTRUMENT KEYSTONE RESET DRIVER
 M:	Santosh Shilimkar <ssantosh@kernel.org>
 L:	linux-kernel@vger.kernel.org
 S:	Maintained
 F:	drivers/power/reset/keystone-reset.c
 
 ARM/TEXAS INSTRUMENT AEMIF/EMIF DRIVERS
 M:	Santosh Shilimkar <ssantosh@kernel.org>
 L:	linux-kernel@vger.kernel.org
 S:	Maintained
 F:	drivers/memory/*emif*
 
 ARM/LG1K ARCHITECTURE
 M:	Chanho Min <chanho.min@lge.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	arch/arm64/boot/dts/lg/
 
 ARM/LOGICPD PXA270 MACHINE SUPPORT
 M:	Lennert Buytenhek <kernel@wantstofly.org>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 
 ARM/LPC18XX ARCHITECTURE
 M:	Joachim Eastwood <manabian@gmail.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	arch/arm/boot/dts/lpc43*
 F:	drivers/clk/nxp/clk-lpc18xx*
 F:	drivers/clocksource/time-lpc32xx.c
 F:	drivers/i2c/busses/i2c-lpc2k.c
 F:	drivers/memory/pl172.c
 F:	drivers/mtd/spi-nor/nxp-spifi.c
 F:	drivers/rtc/rtc-lpc24xx.c
 N:	lpc18xx
 
 ARM/LPC32XX SOC SUPPORT
 M:	Vladimir Zapolskiy <vz@mleia.com>
 M:	Sylvain Lemieux <slemieux.tyco@gmail.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 T:	git git://github.com/vzapolskiy/linux-lpc32xx.git
 S:	Maintained
 F:	arch/arm/boot/dts/lpc32*
 F:	arch/arm/mach-lpc32xx/
 F:	drivers/i2c/busses/i2c-pnx.c
 F:	drivers/net/ethernet/nxp/lpc_eth.c
 F:	drivers/usb/host/ohci-nxp.c
 F:	drivers/watchdog/pnx4008_wdt.c
 N:	lpc32xx
 
 ARM/MAGICIAN MACHINE SUPPORT
 M:	Philipp Zabel <philipp.zabel@gmail.com>
 S:	Maintained
 
 ARM/Marvell Kirkwood and Armada 370, 375, 38x, 39x, XP, 3700, 7K/8K SOC support
 M:	Jason Cooper <jason@lakedaemon.net>
 M:	Andrew Lunn <andrew@lunn.ch>
 M:	Gregory Clement <gregory.clement@free-electrons.com>
 M:	Sebastian Hesselbarth <sebastian.hesselbarth@gmail.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	arch/arm/mach-mvebu/
 F:	drivers/rtc/rtc-armada38x.c
 F:	arch/arm/boot/dts/armada*
 F:	arch/arm/boot/dts/kirkwood*
 F:	arch/arm64/boot/dts/marvell/armada*
 F:	drivers/cpufreq/mvebu-cpufreq.c
 F:	arch/arm/configs/mvebu_*_defconfig
 
 ARM/Marvell Berlin SoC support
 M:	Jisheng Zhang <jszhang@marvell.com>
 M:	Sebastian Hesselbarth <sebastian.hesselbarth@gmail.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	arch/arm/mach-berlin/
 F:	arch/arm/boot/dts/berlin*
 F:	arch/arm64/boot/dts/marvell/berlin*
 
 
 ARM/Marvell Dove/MV78xx0/Orion SOC support
 M:	Jason Cooper <jason@lakedaemon.net>
 M:	Andrew Lunn <andrew@lunn.ch>
 M:	Sebastian Hesselbarth <sebastian.hesselbarth@gmail.com>
 M:	Gregory Clement <gregory.clement@free-electrons.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	arch/arm/mach-dove/
 F:	arch/arm/mach-mv78xx0/
 F:	arch/arm/mach-orion5x/
 F:	arch/arm/plat-orion/
 F:	arch/arm/boot/dts/dove*
 F:	arch/arm/boot/dts/orion5x*
 
 
 ARM/Orion SoC/Technologic Systems TS-78xx platform support
 M:	Alexander Clouter <alex@digriz.org.uk>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 W:	http://www.digriz.org.uk/ts78xx/kernel
 S:	Maintained
 F:	arch/arm/mach-orion5x/ts78xx-*
 
 ARM/OXNAS platform support
 M:	Neil Armstrong <narmstrong@baylibre.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 L:	linux-oxnas@lists.tuxfamily.org (moderated for non-subscribers)
 S:	Maintained
 F:	arch/arm/mach-oxnas/
 F:	arch/arm/boot/dts/ox8*.dtsi
 F:	arch/arm/boot/dts/wd-mbwe.dts
 F:	arch/arm/boot/dts/cloudengines-pogoplug-series-3.dts
 N:	oxnas
 
 ARM/Mediatek RTC DRIVER
 M:	Eddie Huang <eddie.huang@mediatek.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 L:	linux-mediatek@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	drivers/rtc/rtc-mt6397.c
 
 ARM/Mediatek SoC support
 M:	Matthias Brugger <matthias.bgg@gmail.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 L:	linux-mediatek@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	arch/arm/boot/dts/mt6*
 F:	arch/arm/boot/dts/mt8*
 F:	arch/arm/mach-mediatek/
 N:	mtk
 K:	mediatek
 
 ARM/Mediatek USB3 PHY DRIVER
 M:	Chunfeng Yun <chunfeng.yun@mediatek.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 L:	linux-mediatek@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	drivers/phy/phy-mt65xx-usb3.c
 
 ARM/MICREL KS8695 ARCHITECTURE
 M:	Greg Ungerer <gerg@uclinux.org>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 F:	arch/arm/mach-ks8695/
 S:	Odd Fixes
 
 ARM/MIOA701 MACHINE SUPPORT
 M:	Robert Jarzmik <robert.jarzmik@free.fr>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 F:	arch/arm/mach-pxa/mioa701.c
 S:	Maintained
 
 ARM/NEC MOBILEPRO 900/c MACHINE SUPPORT
 M:	Michael Petchkovsky <mkpetch@internode.on.net>
 S:	Maintained
 
 ARM/NOMADIK ARCHITECTURE
 M:	Alessandro Rubini <rubini@unipv.it>
 M:	Linus Walleij <linus.walleij@linaro.org>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	arch/arm/mach-nomadik/
 F:	drivers/pinctrl/nomadik/
 F:	drivers/i2c/busses/i2c-nomadik.c
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/linusw/linux-nomadik.git
 
 ARM/OPENMOKO NEO FREERUNNER (GTA02) MACHINE SUPPORT
 M:	Nelson Castillo <arhuaco@freaks-unidos.net>
 L:	openmoko-kernel@lists.openmoko.org (subscribers-only)
 W:	http://wiki.openmoko.org/wiki/Neo_FreeRunner
 S:	Supported
 
 ARM/TOSA MACHINE SUPPORT
 M:	Dmitry Eremin-Solenikov <dbaryshkov@gmail.com>
 M:	Dirk Opfer <dirk@opfer-online.de>
 S:	Maintained
 
 ARM/PALMTX,PALMT5,PALMLD,PALMTE2,PALMTC SUPPORT
 M:	Marek Vasut <marek.vasut@gmail.com>
 L:	linux-arm-kernel@lists.infradead.org
 W:	http://hackndev.com
 S:	Maintained
 F:	arch/arm/mach-pxa/include/mach/palmtx.h
 F:	arch/arm/mach-pxa/palmtx.c
 F:	arch/arm/mach-pxa/include/mach/palmt5.h
 F:	arch/arm/mach-pxa/palmt5.c
 F:	arch/arm/mach-pxa/include/mach/palmld.h
 F:	arch/arm/mach-pxa/palmld.c
 F:	arch/arm/mach-pxa/include/mach/palmte2.h
 F:	arch/arm/mach-pxa/palmte2.c
 F:	arch/arm/mach-pxa/include/mach/palmtc.h
 F:	arch/arm/mach-pxa/palmtc.c
 
 ARM/PALM TREO SUPPORT
 M:	Tomas Cech <sleep_walker@suse.com>
 L:	linux-arm-kernel@lists.infradead.org
 W:	http://hackndev.com
 S:	Maintained
 F:	arch/arm/mach-pxa/include/mach/palmtreo.h
 F:	arch/arm/mach-pxa/palmtreo.c
 
 ARM/PALMZ72 SUPPORT
 M:	Sergey Lapin <slapin@ossfans.org>
 L:	linux-arm-kernel@lists.infradead.org
 W:	http://hackndev.com
 S:	Maintained
 F:	arch/arm/mach-pxa/include/mach/palmz72.h
 F:	arch/arm/mach-pxa/palmz72.c
 
 ARM/PLEB SUPPORT
 M:	Peter Chubb <pleb@gelato.unsw.edu.au>
 W:	http://www.disy.cse.unsw.edu.au/Hardware/PLEB
 S:	Maintained
 
 ARM/PT DIGITAL BOARD PORT
 M:	Stefan Eletzhofer <stefan.eletzhofer@eletztrick.de>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 W:	http://www.armlinux.org.uk/
 S:	Maintained
 
 ARM/QUALCOMM SUPPORT
 M:	Andy Gross <andy.gross@linaro.org>
 M:	David Brown <david.brown@linaro.org>
 L:	linux-arm-msm@vger.kernel.org
 L:	linux-soc@vger.kernel.org
 S:	Maintained
 F:	Documentation/devicetree/bindings/soc/qcom/
 F:	arch/arm/boot/dts/qcom-*.dts
 F:	arch/arm/boot/dts/qcom-*.dtsi
 F:	arch/arm/mach-qcom/
 F:	arch/arm64/boot/dts/qcom/*
 F:	drivers/i2c/busses/i2c-qup.c
 F:	drivers/clk/qcom/
 F:	drivers/pinctrl/qcom/
 F:	drivers/soc/qcom/
 F:	drivers/spi/spi-qup.c
 F:	drivers/tty/serial/msm_serial.h
 F:	drivers/tty/serial/msm_serial.c
 F:	drivers/*/pm8???-*
 F:	drivers/mfd/ssbi.c
 F:	drivers/firmware/qcom_scm.c
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/agross/linux.git
 
 ARM/RADISYS ENP2611 MACHINE SUPPORT
 M:	Lennert Buytenhek <kernel@wantstofly.org>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 
 ARM/RENESAS ARM64 ARCHITECTURE
 M:	Simon Horman <horms@verge.net.au>
 M:	Magnus Damm <magnus.damm@gmail.com>
 L:	linux-renesas-soc@vger.kernel.org
 Q:	http://patchwork.kernel.org/project/linux-renesas-soc/list/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/horms/renesas.git next
 S:	Supported
 F:	arch/arm64/boot/dts/renesas/
 F:	drivers/soc/renesas/
 F:	include/linux/soc/renesas/
 
 ARM/RISCPC ARCHITECTURE
 M:	Russell King <linux@armlinux.org.uk>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 W:	http://www.armlinux.org.uk/
 S:	Maintained
 F:	arch/arm/include/asm/hardware/entry-macro-iomd.S
 F:	arch/arm/include/asm/hardware/ioc.h
 F:	arch/arm/include/asm/hardware/iomd.h
 F:	arch/arm/include/asm/hardware/memc.h
 F:	arch/arm/mach-rpc/
 F:	drivers/net/ethernet/8390/etherh.c
 F:	drivers/net/ethernet/i825xx/ether1*
 F:	drivers/net/ethernet/seeq/ether3*
 F:	drivers/scsi/arm/
 
 ARM/Rockchip SoC support
 M:	Heiko Stuebner <heiko@sntech.de>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 L:	linux-rockchip@lists.infradead.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/mmind/linux-rockchip.git
 S:	Maintained
 F:	arch/arm/boot/dts/rk3*
 F:	arch/arm/mach-rockchip/
 F:	drivers/clk/rockchip/
 F:	drivers/i2c/busses/i2c-rk3x.c
 F:	drivers/*/*rockchip*
 F:	drivers/*/*/*rockchip*
 F:	sound/soc/rockchip/
 N:	rockchip
 
 ARM/SAMSUNG EXYNOS ARM ARCHITECTURES
 M:	Kukjin Kim <kgene@kernel.org>
 M:	Krzysztof Kozlowski <krzk@kernel.org>
 R:	Javier Martinez Canillas <javier@osg.samsung.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 L:	linux-samsung-soc@vger.kernel.org (moderated for non-subscribers)
 Q:	https://patchwork.kernel.org/project/linux-samsung-soc/list/
 S:	Maintained
 F:	arch/arm/boot/dts/s3c*
 F:	arch/arm/boot/dts/s5p*
 F:	arch/arm/boot/dts/samsung*
 F:	arch/arm/boot/dts/exynos*
 F:	arch/arm64/boot/dts/exynos/
 F:	arch/arm/plat-samsung/
 F:	arch/arm/mach-s3c24*/
 F:	arch/arm/mach-s3c64xx/
 F:	arch/arm/mach-s5p*/
 F:	arch/arm/mach-exynos*/
 F:	drivers/*/*s3c24*
 F:	drivers/*/*/*s3c24*
 F:	drivers/*/*s3c64xx*
 F:	drivers/*/*s5pv210*
 F:	drivers/memory/samsung/*
 F:	drivers/soc/samsung/*
 F:	Documentation/arm/Samsung/
 F:	Documentation/devicetree/bindings/arm/samsung/
 F:	Documentation/devicetree/bindings/sram/samsung-sram.txt
 F:	Documentation/devicetree/bindings/power/pd-samsung.txt
 N:	exynos
 
 ARM/SAMSUNG MOBILE MACHINE SUPPORT
 M:	Kyungmin Park <kyungmin.park@samsung.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	arch/arm/mach-s5pv210/
 
 ARM/SAMSUNG S5P SERIES 2D GRAPHICS ACCELERATION (G2D) SUPPORT
 M:	Kyungmin Park <kyungmin.park@samsung.com>
 M:	Kamil Debski <kamil@wypas.org>
 M:	Andrzej Hajda <a.hajda@samsung.com>
 L:	linux-arm-kernel@lists.infradead.org
 L:	linux-media@vger.kernel.org
 S:	Maintained
 F:	drivers/media/platform/s5p-g2d/
 
 ARM/SAMSUNG S5P SERIES Multi Format Codec (MFC) SUPPORT
 M:	Kyungmin Park <kyungmin.park@samsung.com>
 M:	Kamil Debski <kamil@wypas.org>
 M:	Jeongtae Park <jtp.park@samsung.com>
 M:	Andrzej Hajda <a.hajda@samsung.com>
 L:	linux-arm-kernel@lists.infradead.org
 L:	linux-media@vger.kernel.org
 S:	Maintained
 F:	arch/arm/plat-samsung/s5p-dev-mfc.c
 F:	drivers/media/platform/s5p-mfc/
 
 ARM/SAMSUNG S5P SERIES HDMI CEC SUBSYSTEM SUPPORT
 M:	Kyungmin Park <kyungmin.park@samsung.com>
 L:	linux-arm-kernel@lists.infradead.org
 L:	linux-media@vger.kernel.org
 S:	Maintained
 F:	drivers/staging/media/platform/s5p-cec/
 
 ARM/SAMSUNG S5P SERIES JPEG CODEC SUPPORT
 M:	Andrzej Pietrasiewicz <andrzej.p@samsung.com>
 M:	Jacek Anaszewski <jacek.anaszewski@gmail.com>
 L:	linux-arm-kernel@lists.infradead.org
 L:	linux-media@vger.kernel.org
 S:	Maintained
 F:	drivers/media/platform/s5p-jpeg/
 
 ARM/SHMOBILE ARM ARCHITECTURE
 M:	Simon Horman <horms@verge.net.au>
 M:	Magnus Damm <magnus.damm@gmail.com>
 L:	linux-renesas-soc@vger.kernel.org
 Q:	http://patchwork.kernel.org/project/linux-renesas-soc/list/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/horms/renesas.git next
 S:	Supported
 F:	arch/arm/boot/dts/emev2*
 F:	arch/arm/boot/dts/r7s*
 F:	arch/arm/boot/dts/r8a*
 F:	arch/arm/boot/dts/sh*
 F:	arch/arm/configs/shmobile_defconfig
 F:	arch/arm/include/debug/renesas-scif.S
 F:	arch/arm/mach-shmobile/
 F:	drivers/soc/renesas/
 F:	include/linux/soc/renesas/
 
 ARM/SOCFPGA ARCHITECTURE
 M:	Dinh Nguyen <dinguyen@kernel.org>
 S:	Maintained
 F:	arch/arm/mach-socfpga/
 F:	arch/arm/boot/dts/socfpga*
 F:	arch/arm/configs/socfpga_defconfig
 F:	arch/arm64/boot/dts/altera/
 W:	http://www.rocketboards.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/dinguyen/linux.git
 
 ARM/SOCFPGA CLOCK FRAMEWORK SUPPORT
 M:	Dinh Nguyen <dinguyen@kernel.org>
 S:	Maintained
 F:	drivers/clk/socfpga/
 
 ARM/SOCFPGA EDAC SUPPORT
 M:	Thor Thayer <thor.thayer@linux.intel.com>
 S:	Maintained
 F:	drivers/edac/altera_edac.
 
 ARM/STI ARCHITECTURE
 M:	Patrice Chotard <patrice.chotard@st.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 L:	kernel@stlinux.com
 W:	http://www.stlinux.com
 S:	Maintained
 F:	arch/arm/mach-sti/
 F:	arch/arm/boot/dts/sti*
 F:	drivers/char/hw_random/st-rng.c
 F:	drivers/clocksource/arm_global_timer.c
 F:	drivers/clocksource/clksrc_st_lpc.c
 F:	drivers/cpufreq/sti-cpufreq.c
 F:	drivers/dma/st_fdma*
 F:	drivers/i2c/busses/i2c-st.c
 F:	drivers/media/rc/st_rc.c
 F:	drivers/media/platform/sti/c8sectpfe/
 F:	drivers/mmc/host/sdhci-st.c
 F:	drivers/phy/phy-miphy28lp.c
 F:	drivers/phy/phy-stih407-usb.c
 F:	drivers/pinctrl/pinctrl-st.c
 F:	drivers/remoteproc/st_remoteproc.c
 F:	drivers/remoteproc/st_slim_rproc.c
 F:	drivers/reset/sti/
 F:	drivers/rtc/rtc-st-lpc.c
 F:	drivers/tty/serial/st-asc.c
 F:	drivers/usb/dwc3/dwc3-st.c
 F:	drivers/usb/host/ehci-st.c
 F:	drivers/usb/host/ohci-st.c
 F:	drivers/watchdog/st_lpc_wdt.c
 F:	drivers/ata/ahci_st.c
 F:	include/linux/remoteproc/st_slim_rproc.h
 
 ARM/STM32 ARCHITECTURE
 M:	Maxime Coquelin <mcoquelin.stm32@gmail.com>
 M:	Alexandre Torgue <alexandre.torgue@st.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/mcoquelin/stm32.git
 N:	stm32
 F:	drivers/clocksource/armv7m_systick.c
 
 ARM/TANGO ARCHITECTURE
 M:	Marc Gonzalez <marc_gonzalez@sigmadesigns.com>
 L:	linux-arm-kernel@lists.infradead.org
 S:	Maintained
 N:	tango
 
 ARM/TECHNOLOGIC SYSTEMS TS7250 MACHINE SUPPORT
 M:	Lennert Buytenhek <kernel@wantstofly.org>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 
 ARM/TETON BGA MACHINE SUPPORT
 M:	"Mark F. Brown" <mark.brown314@gmail.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 
 ARM/THECUS N2100 MACHINE SUPPORT
 M:	Lennert Buytenhek <kernel@wantstofly.org>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 
 ARM/NUVOTON W90X900 ARM ARCHITECTURE
 M:	Wan ZongShun <mcuos.com@gmail.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 W:	http://www.mcuos.com
 S:	Maintained
 F:	arch/arm/mach-w90x900/
 F:	drivers/input/keyboard/w90p910_keypad.c
 F:	drivers/input/touchscreen/w90p910_ts.c
 F:	drivers/watchdog/nuc900_wdt.c
 F:	drivers/net/ethernet/nuvoton/w90p910_ether.c
 F:	drivers/mtd/nand/nuc900_nand.c
 F:	drivers/rtc/rtc-nuc900.c
 F:	drivers/spi/spi-nuc900.c
 F:	drivers/usb/host/ehci-w90x900.c
 F:	drivers/video/fbdev/nuc900fb.c
 
 ARM/U300 MACHINE SUPPORT
 M:	Linus Walleij <linus.walleij@linaro.org>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Supported
 F:	arch/arm/mach-u300/
 F:	drivers/clocksource/timer-u300.c
 F:	drivers/i2c/busses/i2c-stu300.c
 F:	drivers/rtc/rtc-coh901331.c
 F:	drivers/watchdog/coh901327_wdt.c
 F:	drivers/dma/coh901318*
 F:	drivers/mfd/ab3100*
 F:	drivers/rtc/rtc-ab3100.c
 F:	drivers/rtc/rtc-coh901331.c
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/linusw/linux-stericsson.git
 
 ARM/UNIPHIER ARCHITECTURE
 M:	Masahiro Yamada <yamada.masahiro@socionext.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/masahiroy/linux-uniphier.git
 S:	Maintained
 F:	arch/arm/boot/dts/uniphier*
 F:	arch/arm/include/asm/hardware/cache-uniphier.h
 F:	arch/arm/mach-uniphier/
 F:	arch/arm/mm/cache-uniphier.c
 F:	arch/arm64/boot/dts/socionext/
 F:	drivers/bus/uniphier-system-bus.c
 F:	drivers/clk/uniphier/
 F:	drivers/i2c/busses/i2c-uniphier*
 F:	drivers/pinctrl/uniphier/
 F:	drivers/reset/reset-uniphier.c
 F:	drivers/tty/serial/8250/8250_uniphier.c
 N:	uniphier
 
 ARM/Ux500 ARM ARCHITECTURE
 M:	Linus Walleij <linus.walleij@linaro.org>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	arch/arm/mach-ux500/
 F:	drivers/clocksource/clksrc-dbx500-prcmu.c
 F:	drivers/dma/ste_dma40*
 F:	drivers/hwspinlock/u8500_hsem.c
 F:	drivers/mfd/abx500*
 F:	drivers/mfd/ab8500*
 F:	drivers/mfd/dbx500*
 F:	drivers/mfd/db8500*
 F:	drivers/pinctrl/nomadik/pinctrl-ab*
 F:	drivers/pinctrl/nomadik/pinctrl-nomadik*
 F:	drivers/rtc/rtc-ab8500.c
 F:	drivers/rtc/rtc-pl031.c
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/linusw/linux-stericsson.git
 
 ARM/Ux500 CLOCK FRAMEWORK SUPPORT
 M:	Ulf Hansson <ulf.hansson@linaro.org>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 T:	git git://git.linaro.org/people/ulfh/clk.git
 S:	Maintained
 F:	drivers/clk/ux500/
 
 ARM/VERSATILE EXPRESS PLATFORM
 M:	Liviu Dudau <liviu.dudau@arm.com>
 M:	Sudeep Holla <sudeep.holla@arm.com>
 M:	Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	arch/arm/boot/dts/vexpress*
 F:	arch/arm64/boot/dts/arm/
 F:	arch/arm/mach-vexpress/
 F:	*/*/vexpress*
 F:	*/*/*/vexpress*
 F:	drivers/clk/versatile/clk-vexpress-osc.c
 F:	drivers/clocksource/versatile.c
 N:	mps2
 
 ARM/VFP SUPPORT
 M:	Russell King <linux@armlinux.org.uk>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 W:	http://www.armlinux.org.uk/
 S:	Maintained
 F:	arch/arm/vfp/
 
 ARM/VOIPAC PXA270 SUPPORT
 M:	Marek Vasut <marek.vasut@gmail.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	arch/arm/mach-pxa/vpac270.c
 F:	arch/arm/mach-pxa/include/mach/vpac270.h
 
 ARM/VT8500 ARM ARCHITECTURE
 M:	Tony Prisk <linux@prisktech.co.nz>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	arch/arm/mach-vt8500/
 F:	drivers/clocksource/vt8500_timer.c
 F:	drivers/i2c/busses/i2c-wmt.c
 F:	drivers/mmc/host/wmt-sdmmc.c
 F:	drivers/pwm/pwm-vt8500.c
 F:	drivers/rtc/rtc-vt8500.c
 F:	drivers/tty/serial/vt8500_serial.c
 F:	drivers/usb/host/ehci-platform.c
 F:	drivers/usb/host/uhci-platform.c
 F:	drivers/video/fbdev/vt8500lcdfb.*
 F:	drivers/video/fbdev/wm8505fb*
 F:	drivers/video/fbdev/wmt_ge_rops.*
 
 ARM/ZIPIT Z2 SUPPORT
 M:	Marek Vasut <marek.vasut@gmail.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	arch/arm/mach-pxa/z2.c
 F:	arch/arm/mach-pxa/include/mach/z2.h
 
 ARM/ZTE ARCHITECTURE
 M:	Jun Nie <jun.nie@linaro.org>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	arch/arm/mach-zx/
 F:	drivers/clk/zte/
 F:	Documentation/devicetree/bindings/arm/zte.txt
 F:	Documentation/devicetree/bindings/clock/zx296702-clk.txt
 
 ARM/ZYNQ ARCHITECTURE
 M:	Michal Simek <michal.simek@xilinx.com>
 R:	SÃ¶ren Brinkmann <soren.brinkmann@xilinx.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 W:	http://wiki.xilinx.com
 T:	git https://github.com/Xilinx/linux-xlnx.git
 S:	Supported
 F:	arch/arm/mach-zynq/
 F:	drivers/cpuidle/cpuidle-zynq.c
 F:	drivers/block/xsysace.c
 N:	zynq
 N:	xilinx
 F:	drivers/clocksource/cadence_ttc_timer.c
 F:	drivers/i2c/busses/i2c-cadence.c
 F:	drivers/mmc/host/sdhci-of-arasan.c
 F:	drivers/edac/synopsys_edac.c
 
 ARM SMMU DRIVERS
 M:	Will Deacon <will.deacon@arm.com>
 R:	Robin Murphy <robin.murphy@arm.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	drivers/iommu/arm-smmu.c
 F:	drivers/iommu/arm-smmu-v3.c
 F:	drivers/iommu/io-pgtable-arm.c
 F:	drivers/iommu/io-pgtable-arm-v7s.c
 
 ARM64 PORT (AARCH64 ARCHITECTURE)
 M:	Catalin Marinas <catalin.marinas@arm.com>
 M:	Will Deacon <will.deacon@arm.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux.git
 S:	Maintained
 F:	arch/arm64/
 F:	Documentation/arm64/
 
 AS3645A LED FLASH CONTROLLER DRIVER
 M:	Laurent Pinchart <laurent.pinchart@ideasonboard.com>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Maintained
 F:	drivers/media/i2c/as3645a.c
 F:	include/media/i2c/as3645a.h
 
 ASAHI KASEI AK8974 DRIVER
 M:	Linus Walleij <linus.walleij@linaro.org>
 L:	linux-iio@vger.kernel.org
 W:	http://www.akm.com/
 S:	Supported
 F:	drivers/iio/magnetometer/ak8974.c
 
 ASC7621 HARDWARE MONITOR DRIVER
 M:	George Joseph <george.joseph@fairview5.com>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	Documentation/hwmon/asc7621
 F:	drivers/hwmon/asc7621.c
 
 ASUS NOTEBOOKS AND EEEPC ACPI/WMI EXTRAS DRIVERS
 M:	Corentin Chary <corentin.chary@gmail.com>
 L:	acpi4asus-user@lists.sourceforge.net
 L:	platform-driver-x86@vger.kernel.org
 W:	http://acpi4asus.sf.net
 S:	Maintained
 F:	drivers/platform/x86/asus*.c
 F:	drivers/platform/x86/eeepc*.c
 
 ASUS WIRELESS RADIO CONTROL DRIVER
 M:	JoÃ£o Paulo Rechi Vita <jprvita@gmail.com>
 L:	platform-driver-x86@vger.kernel.org
 S:	Maintained
 F:	drivers/platform/x86/asus-wireless.c
 
 ASYMMETRIC KEYS
 M:	David Howells <dhowells@redhat.com>
 L:	keyrings@vger.kernel.org
 S:	Maintained
 F:	Documentation/crypto/asymmetric-keys.txt
 F:	include/linux/verification.h
 F:	include/crypto/public_key.h
 F:	include/crypto/pkcs7.h
 F:	crypto/asymmetric_keys/
 
 ASYNCHRONOUS TRANSFERS/TRANSFORMS (IOAT) API
 R:	Dan Williams <dan.j.williams@intel.com>
 W:	http://sourceforge.net/projects/xscaleiop
 S:	Odd fixes
 F:	Documentation/crypto/async-tx-api.txt
 F:	crypto/async_tx/
 F:	drivers/dma/
 F:	include/linux/dmaengine.h
 F:	include/linux/async_tx.h
 
 AT24 EEPROM DRIVER
 M:	Wolfram Sang <wsa@the-dreams.de>
 L:	linux-i2c@vger.kernel.org
 S:	Maintained
 F:	drivers/misc/eeprom/at24.c
 F:	include/linux/platform_data/at24.h
 
 ATA OVER ETHERNET (AOE) DRIVER
 M:	"Ed L. Cashin" <ed.cashin@acm.org>
 W:	http://www.openaoe.org/
 S:	Supported
 F:	Documentation/aoe/
 F:	drivers/block/aoe/
 
 ATHEROS 71XX/9XXX GPIO DRIVER
 M:	Alban Bedel <albeu@free.fr>
 W:	https://github.com/AlbanBedel/linux
 T:	git git://github.com/AlbanBedel/linux
 S:	Maintained
 F:	drivers/gpio/gpio-ath79.c
 F:	Documentation/devicetree/bindings/gpio/gpio-ath79.txt
 
 ATHEROS ATH GENERIC UTILITIES
 M:	"Luis R. Rodriguez" <mcgrof@do-not-panic.com>
 L:	linux-wireless@vger.kernel.org
 S:	Supported
 F:	drivers/net/wireless/ath/*
 
 ATHEROS ATH5K WIRELESS DRIVER
 M:	Jiri Slaby <jirislaby@gmail.com>
 M:	Nick Kossifidis <mickflemm@gmail.com>
 M:	"Luis R. Rodriguez" <mcgrof@do-not-panic.com>
 L:	linux-wireless@vger.kernel.org
 W:	http://wireless.kernel.org/en/users/Drivers/ath5k
 S:	Maintained
 F:	drivers/net/wireless/ath/ath5k/
 
 ATHEROS ATH6KL WIRELESS DRIVER
 M:	Kalle Valo <kvalo@qca.qualcomm.com>
 L:	linux-wireless@vger.kernel.org
 W:	http://wireless.kernel.org/en/users/Drivers/ath6kl
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/kvalo/ath.git
 S:	Supported
 F:	drivers/net/wireless/ath/ath6kl/
 
 WILOCITY WIL6210 WIRELESS DRIVER
 M:	Maya Erez <qca_merez@qca.qualcomm.com>
 L:	linux-wireless@vger.kernel.org
 L:	wil6210@qca.qualcomm.com
 S:	Supported
 W:	http://wireless.kernel.org/en/users/Drivers/wil6210
 F:	drivers/net/wireless/ath/wil6210/
 F:	include/uapi/linux/wil6210_uapi.h
 
 CARL9170 LINUX COMMUNITY WIRELESS DRIVER
 M:	Christian Lamparter <chunkeey@googlemail.com>
 L:	linux-wireless@vger.kernel.org
 W:	http://wireless.kernel.org/en/users/Drivers/carl9170
 S:	Maintained
 F:	drivers/net/wireless/ath/carl9170/
 
 ATK0110 HWMON DRIVER
 M:	Luca Tettamanti <kronos.it@gmail.com>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	drivers/hwmon/asus_atk0110.c
 
 ATI_REMOTE2 DRIVER
 M:	Ville Syrjala <syrjala@sci.fi>
 S:	Maintained
 F:	drivers/input/misc/ati_remote2.c
 
 ATLX ETHERNET DRIVERS
 M:	Jay Cliburn <jcliburn@gmail.com>
 M:	Chris Snook <chris.snook@gmail.com>
 L:	netdev@vger.kernel.org
 W:	http://sourceforge.net/projects/atl1
 W:	http://atl1.sourceforge.net
 S:	Maintained
 F:	drivers/net/ethernet/atheros/
 
 ATM
 M:	Chas Williams <3chas3@gmail.com>
 L:	linux-atm-general@lists.sourceforge.net (moderated for non-subscribers)
 L:	netdev@vger.kernel.org
 W:	http://linux-atm.sourceforge.net
 S:	Maintained
 F:	drivers/atm/
 F:	include/linux/atm*
 F:	include/uapi/linux/atm*
 
 ATMEL AT91 / AT32 MCI DRIVER
 M:	Ludovic Desroches <ludovic.desroches@microchip.com>
 S:	Maintained
 F:	drivers/mmc/host/atmel-mci.c
 
 ATMEL AT91 SAMA5D2-Compatible Shutdown Controller
 M:	Nicolas Ferre <nicolas.ferre@microchip.com>
 S:	Supported
 F:	drivers/power/reset/at91-sama5d2_shdwc.c
 
 ATMEL SAMA5D2 ADC DRIVER
 M:	Ludovic Desroches <ludovic.desroches@microchip.com>
 L:	linux-iio@vger.kernel.org
 S:	Supported
 F:	drivers/iio/adc/at91-sama5d2_adc.c
 
 ATMEL Audio ALSA driver
 M:	Nicolas Ferre <nicolas.ferre@microchip.com>
 L:	alsa-devel@alsa-project.org (moderated for non-subscribers)
 S:	Supported
 F:	sound/soc/atmel
 
 ATMEL XDMA DRIVER
 M:	Ludovic Desroches <ludovic.desroches@microchip.com>
 L:	linux-arm-kernel@lists.infradead.org
 L:	dmaengine@vger.kernel.org
 S:	Supported
 F:	drivers/dma/at_xdmac.c
 
 ATMEL I2C DRIVER
 M:	Ludovic Desroches <ludovic.desroches@microchip.com>
 L:	linux-i2c@vger.kernel.org
 S:	Supported
 F:	drivers/i2c/busses/i2c-at91.c
 
 ATMEL ISI DRIVER
 M:	Ludovic Desroches <ludovic.desroches@microchip.com>
 L:	linux-media@vger.kernel.org
 S:	Supported
 F:	drivers/media/platform/soc_camera/atmel-isi.c
 F:	include/media/atmel-isi.h
 
 ATMEL LCDFB DRIVER
 M:	Nicolas Ferre <nicolas.ferre@microchip.com>
 L:	linux-fbdev@vger.kernel.org
 S:	Maintained
 F:	drivers/video/fbdev/atmel_lcdfb.c
 F:	include/video/atmel_lcdc.h
 
 ATMEL MACB ETHERNET DRIVER
 M:	Nicolas Ferre <nicolas.ferre@microchip.com>
 S:	Supported
 F:	drivers/net/ethernet/cadence/
 
 ATMEL NAND DRIVER
 M:	Wenyou Yang <wenyou.yang@atmel.com>
 M:	Josh Wu <rainyfeeling@outlook.com>
 L:	linux-mtd@lists.infradead.org
 S:	Supported
 F:	drivers/mtd/nand/atmel_nand*
 
 ATMEL SDMMC DRIVER
 M:	Ludovic Desroches <ludovic.desroches@microchip.com>
 L:	linux-mmc@vger.kernel.org
 S:	Supported
 F:	drivers/mmc/host/sdhci-of-at91.c
 
 ATMEL SPI DRIVER
 M:	Nicolas Ferre <nicolas.ferre@microchip.com>
 S:	Supported
 F:	drivers/spi/spi-atmel.*
 
 ATMEL SSC DRIVER
 M:	Nicolas Ferre <nicolas.ferre@microchip.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Supported
 F:	drivers/misc/atmel-ssc.c
 F:	include/linux/atmel-ssc.h
 
 ATMEL Timer Counter (TC) AND CLOCKSOURCE DRIVERS
 M:	Nicolas Ferre <nicolas.ferre@microchip.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Supported
 F:	drivers/misc/atmel_tclib.c
 F:	drivers/clocksource/tcb_clksrc.c
 
 ATMEL USBA UDC DRIVER
 M:	Nicolas Ferre <nicolas.ferre@microchip.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Supported
 F:	drivers/usb/gadget/udc/atmel_usba_udc.*
 
 ATMEL WIRELESS DRIVER
 M:	Simon Kelley <simon@thekelleys.org.uk>
 L:	linux-wireless@vger.kernel.org
 W:	http://www.thekelleys.org.uk/atmel
 W:	http://atmelwlandriver.sourceforge.net/
 S:	Maintained
 F:	drivers/net/wireless/atmel/atmel*
 
 ATMEL MAXTOUCH DRIVER
 M:	Nick Dyer <nick@shmanahar.org>
 T:	git git://github.com/ndyer/linux.git
 S:	Maintained
 F:	Documentation/devicetree/bindings/input/atmel,maxtouch.txt
 F:	drivers/input/touchscreen/atmel_mxt_ts.c
 F:	include/linux/platform_data/atmel_mxt_ts.h
 
 ATTO EXPRESSSAS SAS/SATA RAID SCSI DRIVER
 M:	Bradley Grove <linuxdrivers@attotech.com>
 L:	linux-scsi@vger.kernel.org
 W:	http://www.attotech.com
 S:	Supported
 F:	drivers/scsi/esas2r
 
 ATUSB IEEE 802.15.4 RADIO DRIVER
 M:	Stefan Schmidt <stefan@osg.samsung.com>
 L:	linux-wpan@vger.kernel.org
 S:	Maintained
 F:	drivers/net/ieee802154/atusb.c
 F:	drivers/net/ieee802154/atusb.h
 F:	drivers/net/ieee802154/at86rf230.h
 
 AUDIT SUBSYSTEM
 M:	Paul Moore <paul@paul-moore.com>
 M:	Eric Paris <eparis@redhat.com>
 L:	linux-audit@redhat.com (moderated for non-subscribers)
 W:	http://people.redhat.com/sgrubb/audit/
 T:	git git://git.infradead.org/users/pcmoore/audit
 S:	Maintained
 F:	include/linux/audit.h
 F:	include/uapi/linux/audit.h
 F:	kernel/audit*
 
 AUXILIARY DISPLAY DRIVERS
 M:	Miguel Ojeda Sandonis <miguel.ojeda.sandonis@gmail.com>
 W:	http://miguelojeda.es/auxdisplay.htm
 W:	http://jair.lab.fi.uva.es/~migojed/auxdisplay.htm
 S:	Maintained
 F:	drivers/auxdisplay/
 F:	include/linux/cfag12864b.h
 
 AVR32 ARCHITECTURE
 M:	Haavard Skinnemoen <hskinnemoen@gmail.com>
 M:	Hans-Christian Egtvedt <egtvedt@samfundet.no>
 W:	http://www.atmel.com/products/AVR32/
 W:	http://mirror.egtvedt.no/avr32linux.org/
 W:	http://avrfreaks.net/
 S:	Maintained
 F:	arch/avr32/
 
 AVR32/AT32AP MACHINE SUPPORT
 M:	Haavard Skinnemoen <hskinnemoen@gmail.com>
 M:	Hans-Christian Egtvedt <egtvedt@samfundet.no>
 S:	Maintained
 F:	arch/avr32/mach-at32ap/
 
 AX.25 NETWORK LAYER
 M:	Ralf Baechle <ralf@linux-mips.org>
 L:	linux-hams@vger.kernel.org
 W:	http://www.linux-ax25.org/
 S:	Maintained
 F:	include/uapi/linux/ax25.h
 F:	include/net/ax25.h
 F:	net/ax25/
 
 AXENTIA ASOC DRIVERS
 M:	Peter Rosin <peda@axentia.se>
 L:	alsa-devel@alsa-project.org (moderated for non-subscribers)
 S:	Maintained
 F:	Documentation/devicetree/bindings/sound/axentia,*
 F:	sound/soc/atmel/tse850-pcm5142.c
 
 AZ6007 DVB DRIVER
 M:	Mauro Carvalho Chehab <mchehab@s-opensource.com>
 M:	Mauro Carvalho Chehab <mchehab@kernel.org>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Maintained
 F:	drivers/media/usb/dvb-usb-v2/az6007.c
 
 AZTECH FM RADIO RECEIVER DRIVER
 M:	Hans Verkuil <hverkuil@xs4all.nl>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 W:	https://linuxtv.org
 S:	Maintained
 F:	drivers/media/radio/radio-aztech*
 
 B43 WIRELESS DRIVER
 L:	linux-wireless@vger.kernel.org
 L:	b43-dev@lists.infradead.org
 W:	http://wireless.kernel.org/en/users/Drivers/b43
 S:	Odd Fixes
 F:	drivers/net/wireless/broadcom/b43/
 
 B43LEGACY WIRELESS DRIVER
 M:	Larry Finger <Larry.Finger@lwfinger.net>
 L:	linux-wireless@vger.kernel.org
 L:	b43-dev@lists.infradead.org
 W:	http://wireless.kernel.org/en/users/Drivers/b43
 S:	Maintained
 F:	drivers/net/wireless/broadcom/b43legacy/
 
 BACKLIGHT CLASS/SUBSYSTEM
 M:	Jingoo Han <jingoohan1@gmail.com>
 M:	Lee Jones <lee.jones@linaro.org>
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/lee/backlight.git
 S:	Maintained
 F:	drivers/video/backlight/
 F:	include/linux/backlight.h
 
 BATMAN ADVANCED
 M:	Marek Lindner <mareklindner@neomailbox.ch>
 M:	Simon Wunderlich <sw@simonwunderlich.de>
 M:	Antonio Quartulli <a@unstable.cc>
 L:	b.a.t.m.a.n@lists.open-mesh.org (moderated for non-subscribers)
 W:	https://www.open-mesh.org/
 Q:	https://patchwork.open-mesh.org/project/batman/list/
 S:	Maintained
 F:	Documentation/ABI/testing/sysfs-class-net-batman-adv
 F:	Documentation/ABI/testing/sysfs-class-net-mesh
 F:	Documentation/networking/batman-adv.txt
 F:	include/uapi/linux/batman_adv.h
 F:	net/batman-adv/
 
 BAYCOM/HDLCDRV DRIVERS FOR AX.25
 M:	Thomas Sailer <t.sailer@alumni.ethz.ch>
 L:	linux-hams@vger.kernel.org
 W:	http://www.baycom.org/~tom/ham/ham.html
 S:	Maintained
 F:	drivers/net/hamradio/baycom*
 
 BCACHE (BLOCK LAYER CACHE)
 M:	Kent Overstreet <kent.overstreet@gmail.com>
 L:	linux-bcache@vger.kernel.org
 W:	http://bcache.evilpiepirate.org
 S:	Orphan
 F:	drivers/md/bcache/
 
 BDISP ST MEDIA DRIVER
 M:	Fabien Dessenne <fabien.dessenne@st.com>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 W:	https://linuxtv.org
 S:	Supported
 F:	drivers/media/platform/sti/bdisp
 
 DELTA ST MEDIA DRIVER
 M:	Hugues Fruchet <hugues.fruchet@st.com>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 W:	https://linuxtv.org
 S:	Supported
 F:	drivers/media/platform/sti/delta
 
 BEFS FILE SYSTEM
 M:	Luis de Bethencourt <luisbg@osg.samsung.com>
 M:	Salah Triki <salah.triki@gmail.com>
 S:	Maintained
 T:	git git://github.com/luisbg/linux-befs.git
 F:	Documentation/filesystems/befs.txt
 F:	fs/befs/
 
 BECKHOFF CX5020 ETHERCAT MASTER DRIVER
 M:	Dariusz Marcinkiewicz <reksio@newterm.pl>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/ethernet/ec_bhf.c
 
 BFS FILE SYSTEM
 M:	"Tigran A. Aivazian" <tigran@aivazian.fsnet.co.uk>
 S:	Maintained
 F:	Documentation/filesystems/bfs.txt
 F:	fs/bfs/
 F:	include/uapi/linux/bfs_fs.h
 
 BLACKFIN ARCHITECTURE
 M:	Steven Miao <realmz6@gmail.com>
 L:	adi-buildroot-devel@lists.sourceforge.net (moderated for non-subscribers)
 T:	git git://git.code.sf.net/p/adi-linux/code
 W:	http://blackfin.uclinux.org
 S:	Supported
 F:	arch/blackfin/
 
 BLACKFIN EMAC DRIVER
 L:	adi-buildroot-devel@lists.sourceforge.net (moderated for non-subscribers)
 W:	http://blackfin.uclinux.org
 S:	Supported
 F:	drivers/net/ethernet/adi/
 
 BLACKFIN RTC DRIVER
 L:	adi-buildroot-devel@lists.sourceforge.net (moderated for non-subscribers)
 W:	http://blackfin.uclinux.org
 S:	Supported
 F:	drivers/rtc/rtc-bfin.c
 
 BLACKFIN SDH DRIVER
 M:	Sonic Zhang <sonic.zhang@analog.com>
 L:	adi-buildroot-devel@lists.sourceforge.net (moderated for non-subscribers)
 W:	http://blackfin.uclinux.org
 S:	Supported
 F:	drivers/mmc/host/bfin_sdh.c
 
 BLACKFIN SERIAL DRIVER
 M:	Sonic Zhang <sonic.zhang@analog.com>
 L:	adi-buildroot-devel@lists.sourceforge.net (moderated for non-subscribers)
 W:	http://blackfin.uclinux.org
 S:	Supported
 F:	drivers/tty/serial/bfin_uart.c
 
 BLACKFIN WATCHDOG DRIVER
 L:	adi-buildroot-devel@lists.sourceforge.net (moderated for non-subscribers)
 W:	http://blackfin.uclinux.org
 S:	Supported
 F:	drivers/watchdog/bfin_wdt.c
 
 BLACKFIN I2C TWI DRIVER
 M:	Sonic Zhang <sonic.zhang@analog.com>
 L:	adi-buildroot-devel@lists.sourceforge.net (moderated for non-subscribers)
 W:	http://blackfin.uclinux.org/
 S:	Supported
 F:	drivers/i2c/busses/i2c-bfin-twi.c
 
 BLACKFIN MEDIA DRIVER
 M:	Scott Jiang <scott.jiang.linux@gmail.com>
 L:	adi-buildroot-devel@lists.sourceforge.net (moderated for non-subscribers)
 W:	http://blackfin.uclinux.org/
 S:	Supported
 F:	drivers/media/platform/blackfin/
 F:	drivers/media/i2c/adv7183*
 F:	drivers/media/i2c/vs6624*
 
 BLINKM RGB LED DRIVER
 M:	Jan-Simon Moeller <jansimon.moeller@gmx.de>
 S:	Maintained
 F:	drivers/leds/leds-blinkm.c
 
 BLOCK LAYER
 M:	Jens Axboe <axboe@kernel.dk>
 L:	linux-block@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/axboe/linux-block.git
 S:	Maintained
 F:	block/
 F:	kernel/trace/blktrace.c
 F:	lib/sbitmap.c
 
 BLOCK2MTD DRIVER
 M:	Joern Engel <joern@lazybastard.org>
 L:	linux-mtd@lists.infradead.org
 S:	Maintained
 F:	drivers/mtd/devices/block2mtd.c
 
 BLUETOOTH DRIVERS
 M:	Marcel Holtmann <marcel@holtmann.org>
 M:	Gustavo Padovan <gustavo@padovan.org>
 M:	Johan Hedberg <johan.hedberg@gmail.com>
 L:	linux-bluetooth@vger.kernel.org
 W:	http://www.bluez.org/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/bluetooth/bluetooth.git
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/bluetooth/bluetooth-next.git
 S:	Maintained
 F:	drivers/bluetooth/
 
 BLUETOOTH SUBSYSTEM
 M:	Marcel Holtmann <marcel@holtmann.org>
 M:	Gustavo Padovan <gustavo@padovan.org>
 M:	Johan Hedberg <johan.hedberg@gmail.com>
 L:	linux-bluetooth@vger.kernel.org
 W:	http://www.bluez.org/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/bluetooth/bluetooth.git
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/bluetooth/bluetooth-next.git
 S:	Maintained
 F:	net/bluetooth/
 F:	include/net/bluetooth/
 
 BONDING DRIVER
 M:	Jay Vosburgh <j.vosburgh@gmail.com>
 M:	Veaceslav Falico <vfalico@gmail.com>
 M:	Andy Gospodarek <andy@greyhouse.net>
 L:	netdev@vger.kernel.org
 W:	http://sourceforge.net/projects/bonding/
 S:	Supported
 F:	drivers/net/bonding/
 F:	include/uapi/linux/if_bonding.h
 
 BPF (Safe dynamic programs and tools)
 M:	Alexei Starovoitov <ast@kernel.org>
 L:	netdev@vger.kernel.org
 L:	linux-kernel@vger.kernel.org
 S:	Supported
 F:	kernel/bpf/
 F:	tools/testing/selftests/bpf/
 F:	lib/test_bpf.c
 
 BROADCOM B44 10/100 ETHERNET DRIVER
 M:	Michael Chan <michael.chan@broadcom.com>
 L:	netdev@vger.kernel.org
 S:	Supported
 F:	drivers/net/ethernet/broadcom/b44.*
 
 BROADCOM B53 ETHERNET SWITCH DRIVER
 M:	Florian Fainelli <f.fainelli@gmail.com>
 L:	netdev@vger.kernel.org
 L:	openwrt-devel@lists.openwrt.org (subscribers-only)
 S:	Supported
 F:	drivers/net/dsa/b53/*
 F:	include/linux/platform_data/b53.h
 
 BROADCOM GENET ETHERNET DRIVER
 M:	Florian Fainelli <f.fainelli@gmail.com>
 L:	netdev@vger.kernel.org
 S:	Supported
 F:	drivers/net/ethernet/broadcom/genet/
 
 BROADCOM BNX2 GIGABIT ETHERNET DRIVER
 M:	Rasesh Mody <rasesh.mody@cavium.com>
 M:	Harish Patil <harish.patil@cavium.com>
 M:	Dept-GELinuxNICDev@cavium.com
 L:	netdev@vger.kernel.org
 S:	Supported
 F:	drivers/net/ethernet/broadcom/bnx2.*
 F:	drivers/net/ethernet/broadcom/bnx2_*
 
 BROADCOM BNX2X 10 GIGABIT ETHERNET DRIVER
 M:	Yuval Mintz <Yuval.Mintz@cavium.com>
 M:	Ariel Elior <ariel.elior@cavium.com>
 M:	everest-linux-l2@cavium.com
 L:	netdev@vger.kernel.org
 S:	Supported
 F:	drivers/net/ethernet/broadcom/bnx2x/
 
 BROADCOM BNXT_EN 50 GIGABIT ETHERNET DRIVER
 M:	Michael Chan <michael.chan@broadcom.com>
 L:	netdev@vger.kernel.org
 S:	Supported
 F:	drivers/net/ethernet/broadcom/bnxt/
 
 BROADCOM BCM281XX/BCM11XXX/BCM216XX ARM ARCHITECTURE
 M:	Florian Fainelli <f.fainelli@gmail.com>
 M:	Ray Jui <rjui@broadcom.com>
 M:	Scott Branden <sbranden@broadcom.com>
 M:	bcm-kernel-feedback-list@broadcom.com
 T:	git git://github.com/broadcom/mach-bcm
 S:	Maintained
 N:	bcm281*
 N:	bcm113*
 N:	bcm216*
 N:	kona
 F:	arch/arm/mach-bcm/
 
 BROADCOM BCM2835 ARM ARCHITECTURE
 M:	Stephen Warren <swarren@wwwdotorg.org>
 M:	Lee Jones <lee@kernel.org>
 M:	Eric Anholt <eric@anholt.net>
 L:	linux-rpi-kernel@lists.infradead.org (moderated for non-subscribers)
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/rpi/linux-rpi.git
 S:	Maintained
 N:	bcm2835
 F:	drivers/staging/vc04_services
 
 BROADCOM BCM47XX MIPS ARCHITECTURE
 M:	Hauke Mehrtens <hauke@hauke-m.de>
 M:	RafaÅ MiÅecki <zajec5@gmail.com>
 L:	linux-mips@linux-mips.org
 S:	Maintained
 F:	Documentation/devicetree/bindings/mips/brcm/
 F:	arch/mips/bcm47xx/*
 F:	arch/mips/include/asm/mach-bcm47xx/*
 
 BROADCOM BCM5301X ARM ARCHITECTURE
 M:	Hauke Mehrtens <hauke@hauke-m.de>
 M:	RafaÅ MiÅecki <zajec5@gmail.com>
 M:	bcm-kernel-feedback-list@broadcom.com
 L:	linux-arm-kernel@lists.infradead.org
 S:	Maintained
 F:	arch/arm/mach-bcm/bcm_5301x.c
 F:	arch/arm/boot/dts/bcm5301x*.dtsi
 F:	arch/arm/boot/dts/bcm470*
 
 BROADCOM BCM53573 ARM ARCHITECTURE
 M:	RafaÅ MiÅecki <rafal@milecki.pl>
 L:	linux-arm-kernel@lists.infradead.org
 S:	Maintained
 F:	arch/arm/boot/dts/bcm53573*
 F:	arch/arm/boot/dts/bcm47189*
 
 BROADCOM BCM63XX ARM ARCHITECTURE
 M:	Florian Fainelli <f.fainelli@gmail.com>
 M:	bcm-kernel-feedback-list@broadcom.com
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 T:	git git://github.com/broadcom/stblinux.git
 S:	Maintained
 N:	bcm63xx
 
 BROADCOM BCM63XX/BCM33XX UDC DRIVER
 M:	Kevin Cernekee <cernekee@gmail.com>
 L:	linux-usb@vger.kernel.org
 S:	Maintained
 F:	drivers/usb/gadget/udc/bcm63xx_udc.*
 
 BROADCOM BCM7XXX ARM ARCHITECTURE
 M:	Brian Norris <computersforpeace@gmail.com>
 M:	Gregory Fong <gregory.0xf0@gmail.com>
 M:	Florian Fainelli <f.fainelli@gmail.com>
 M:	bcm-kernel-feedback-list@broadcom.com
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 T:	git git://github.com/broadcom/stblinux.git
 S:	Maintained
 F:	arch/arm/mach-bcm/*brcmstb*
 F:	arch/arm/boot/dts/bcm7*.dts*
 F:	drivers/bus/brcmstb_gisb.c
 N:	brcmstb
 
 BROADCOM BMIPS MIPS ARCHITECTURE
 M:	Kevin Cernekee <cernekee@gmail.com>
 M:	Florian Fainelli <f.fainelli@gmail.com>
 L:	linux-mips@linux-mips.org
 T:	git git://github.com/broadcom/stblinux.git
 S:	Maintained
 F:	arch/mips/bmips/*
 F:	arch/mips/include/asm/mach-bmips/*
 F:	arch/mips/kernel/*bmips*
 F:	arch/mips/boot/dts/brcm/bcm*.dts*
 F:	drivers/irqchip/irq-bcm63*
 F:	drivers/irqchip/irq-bcm7*
 F:	drivers/irqchip/irq-brcmstb*
 F:	include/linux/bcm963xx_nvram.h
 F:	include/linux/bcm963xx_tag.h
 
 BROADCOM BMIPS CPUFREQ DRIVER
 M:	Markus Mayer <mmayer@broadcom.com>
 M:	bcm-kernel-feedback-list@broadcom.com
 L:	linux-pm@vger.kernel.org
 S:	Maintained
 F:	drivers/cpufreq/bmips-cpufreq.c
 
 BROADCOM TG3 GIGABIT ETHERNET DRIVER
 M:	Siva Reddy Kallam <siva.kallam@broadcom.com>
 M:	Prashant Sreedharan <prashant@broadcom.com>
 M:	Michael Chan <mchan@broadcom.com>
 L:	netdev@vger.kernel.org
 S:	Supported
 F:	drivers/net/ethernet/broadcom/tg3.*
 
 BROADCOM BRCM80211 IEEE802.11n WIRELESS DRIVER
 M:	Arend van Spriel <arend.vanspriel@broadcom.com>
 M:	Franky Lin <franky.lin@broadcom.com>
 M:	Hante Meuleman <hante.meuleman@broadcom.com>
 L:	linux-wireless@vger.kernel.org
 L:	brcm80211-dev-list.pdl@broadcom.com
 S:	Supported
 F:	drivers/net/wireless/broadcom/brcm80211/
 
 BROADCOM BNX2FC 10 GIGABIT FCOE DRIVER
 M:	QLogic-Storage-Upstream@qlogic.com
 L:	linux-scsi@vger.kernel.org
 S:	Supported
 F:	drivers/scsi/bnx2fc/
 
 BROADCOM BNX2I 1/10 GIGABIT iSCSI DRIVER
 M:	QLogic-Storage-Upstream@qlogic.com
 L:	linux-scsi@vger.kernel.org
 S:	Supported
 F:	drivers/scsi/bnx2i/
 
 BROADCOM IPROC ARM ARCHITECTURE
 M:	Ray Jui <rjui@broadcom.com>
 M:	Scott Branden <sbranden@broadcom.com>
 M:	Jon Mason <jonmason@broadcom.com>
 M:	bcm-kernel-feedback-list@broadcom.com
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 T:	git git://github.com/broadcom/cygnus-linux.git
 S:	Maintained
 N:	iproc
 N:	cygnus
 N:	bcm[-_]nsp
 N:	bcm9113*
 N:	bcm9583*
 N:	bcm9585*
 N:	bcm9586*
 N:	bcm988312
 N:	bcm113*
 N:	bcm583*
 N:	bcm585*
 N:	bcm586*
 N:	bcm88312
 F:	arch/arm64/boot/dts/broadcom/ns2*
 F:	drivers/clk/bcm/clk-ns*
 F:	drivers/pinctrl/bcm/pinctrl-ns*
 
 BROADCOM BRCMSTB GPIO DRIVER
 M:	Gregory Fong <gregory.0xf0@gmail.com>
 L:	bcm-kernel-feedback-list@broadcom.com
 S:	Supported
 F:	drivers/gpio/gpio-brcmstb.c
 F:	Documentation/devicetree/bindings/gpio/brcm,brcmstb-gpio.txt
 
 BROADCOM KONA GPIO DRIVER
 M:	Ray Jui <rjui@broadcom.com>
 L:	bcm-kernel-feedback-list@broadcom.com
 S:	Supported
 F:	drivers/gpio/gpio-bcm-kona.c
 F:	Documentation/devicetree/bindings/gpio/brcm,kona-gpio.txt
 
 BROADCOM NVRAM DRIVER
 M:	RafaÅ MiÅecki <zajec5@gmail.com>
 L:	linux-mips@linux-mips.org
 S:	Maintained
 F:	drivers/firmware/broadcom/*
 
 BROADCOM STB NAND FLASH DRIVER
 M:	Brian Norris <computersforpeace@gmail.com>
 M:	Kamal Dasu <kdasu.kdev@gmail.com>
 L:	linux-mtd@lists.infradead.org
 L:	bcm-kernel-feedback-list@broadcom.com
 S:	Maintained
 F:	drivers/mtd/nand/brcmnand/
 
 BROADCOM STB AVS CPUFREQ DRIVER
 M:	Markus Mayer <mmayer@broadcom.com>
 M:	bcm-kernel-feedback-list@broadcom.com
 L:	linux-pm@vger.kernel.org
 S:	Maintained
 F:	Documentation/devicetree/bindings/cpufreq/brcm,stb-avs-cpu-freq.txt
 F:	drivers/cpufreq/brcmstb*
 
 BROADCOM SPECIFIC AMBA DRIVER (BCMA)
 M:	RafaÅ MiÅecki <zajec5@gmail.com>
 L:	linux-wireless@vger.kernel.org
 S:	Maintained
 F:	drivers/bcma/
 F:	include/linux/bcma/
 
 BROADCOM SYSTEMPORT ETHERNET DRIVER
 M:	Florian Fainelli <f.fainelli@gmail.com>
 L:	netdev@vger.kernel.org
 S:	Supported
 F:	drivers/net/ethernet/broadcom/bcmsysport.*
 
 BROADCOM VULCAN ARM64 SOC
 M:	Jayachandran C. <c.jayachandran@gmail.com>
 M:	bcm-kernel-feedback-list@broadcom.com
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	arch/arm64/boot/dts/broadcom/vulcan*
 
 BROCADE BFA FC SCSI DRIVER
 M:	Anil Gurumurthy <anil.gurumurthy@qlogic.com>
 M:	Sudarsana Kalluru <sudarsana.kalluru@qlogic.com>
 L:	linux-scsi@vger.kernel.org
 S:	Supported
 F:	drivers/scsi/bfa/
 
 BROCADE BNA 10 GIGABIT ETHERNET DRIVER
 M:	Rasesh Mody <rasesh.mody@cavium.com>
 M:	Sudarsana Kalluru <sudarsana.kalluru@cavium.com>
 M:	Dept-GELinuxNICDev@cavium.com
 L:	netdev@vger.kernel.org
 S:	Supported
 F:	drivers/net/ethernet/brocade/bna/
 
 BSG (block layer generic sg v4 driver)
 M:	FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
 L:	linux-scsi@vger.kernel.org
 S:	Supported
 F:	block/bsg.c
 F:	include/linux/bsg.h
 F:	include/uapi/linux/bsg.h
 
 BT87X AUDIO DRIVER
 M:	Clemens Ladisch <clemens@ladisch.de>
 L:	alsa-devel@alsa-project.org (moderated for non-subscribers)
 T:	git git://git.alsa-project.org/alsa-kernel.git
 S:	Maintained
 F:	Documentation/sound/alsa/Bt87x.txt
 F:	sound/pci/bt87x.c
 
 BT8XXGPIO DRIVER
 M:	Michael Buesch <m@bues.ch>
 W:	http://bu3sch.de/btgpio.php
 S:	Maintained
 F:	drivers/gpio/gpio-bt8xx.c
 
 BTRFS FILE SYSTEM
 M:	Chris Mason <clm@fb.com>
 M:	Josef Bacik <jbacik@fb.com>
 M:	David Sterba <dsterba@suse.com>
 L:	linux-btrfs@vger.kernel.org
 W:	http://btrfs.wiki.kernel.org/
 Q:	http://patchwork.kernel.org/project/linux-btrfs/list/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/mason/linux-btrfs.git
 S:	Maintained
 F:	Documentation/filesystems/btrfs.txt
 F:	fs/btrfs/
 
 BTTV VIDEO4LINUX DRIVER
 M:	Mauro Carvalho Chehab <mchehab@s-opensource.com>
 M:	Mauro Carvalho Chehab <mchehab@kernel.org>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Odd fixes
 F:	Documentation/media/v4l-drivers/bttv*
 F:	drivers/media/pci/bt8xx/bttv*
 
 BUSLOGIC SCSI DRIVER
 M:	Khalid Aziz <khalid@gonehiking.org>
 L:	linux-scsi@vger.kernel.org
 S:	Maintained
 F:	drivers/scsi/BusLogic.*
 F:	drivers/scsi/FlashPoint.*
 
 C-MEDIA CMI8788 DRIVER
 M:	Clemens Ladisch <clemens@ladisch.de>
 L:	alsa-devel@alsa-project.org (moderated for non-subscribers)
 T:	git git://git.alsa-project.org/alsa-kernel.git
 S:	Maintained
 F:	sound/pci/oxygen/
 
 C6X ARCHITECTURE
 M:	Mark Salter <msalter@redhat.com>
 M:	Aurelien Jacquiot <a-jacquiot@ti.com>
 L:	linux-c6x-dev@linux-c6x.org
 W:	http://www.linux-c6x.org/wiki/index.php/Main_Page
 S:	Maintained
 F:	arch/c6x/
 
 CACHEFILES: FS-CACHE BACKEND FOR CACHING ON MOUNTED FILESYSTEMS
 M:	David Howells <dhowells@redhat.com>
 L:	linux-cachefs@redhat.com (moderated for non-subscribers)
 S:	Supported
 F:	Documentation/filesystems/caching/cachefiles.txt
 F:	fs/cachefiles/
 
 CADET FM/AM RADIO RECEIVER DRIVER
 M:	Hans Verkuil <hverkuil@xs4all.nl>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 W:	https://linuxtv.org
 S:	Maintained
 F:	drivers/media/radio/radio-cadet*
 
 CAFE CMOS INTEGRATED CAMERA CONTROLLER DRIVER
 M:	Jonathan Corbet <corbet@lwn.net>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Maintained
 F:	Documentation/media/v4l-drivers/cafe_ccic*
 F:	drivers/media/platform/marvell-ccic/
 
 CAIF NETWORK LAYER
 M:	Dmitry Tarnyagin <dmitry.tarnyagin@lockless.no>
 L:	netdev@vger.kernel.org
 S:	Supported
 F:	Documentation/networking/caif/
 F:	drivers/net/caif/
 F:	include/uapi/linux/caif/
 F:	include/net/caif/
 F:	net/caif/
 
 CALGARY x86-64 IOMMU
 M:	Muli Ben-Yehuda <mulix@mulix.org>
 M:	Jon Mason <jdmason@kudzu.us>
 L:	iommu@lists.linux-foundation.org
 S:	Maintained
 F:	arch/x86/kernel/pci-calgary_64.c
 F:	arch/x86/kernel/tce_64.c
 F:	arch/x86/include/asm/calgary.h
 F:	arch/x86/include/asm/tce.h
 
 CAN NETWORK LAYER
 M:	Oliver Hartkopp <socketcan@hartkopp.net>
 M:	Marc Kleine-Budde <mkl@pengutronix.de>
 L:	linux-can@vger.kernel.org
 W:	https://github.com/linux-can
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/mkl/linux-can.git
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/mkl/linux-can-next.git
 S:	Maintained
 F:	Documentation/networking/can.txt
 F:	net/can/
 F:	include/linux/can/core.h
 F:	include/uapi/linux/can.h
 F:	include/uapi/linux/can/bcm.h
 F:	include/uapi/linux/can/raw.h
 F:	include/uapi/linux/can/gw.h
 
 CAN NETWORK DRIVERS
 M:	Wolfgang Grandegger <wg@grandegger.com>
 M:	Marc Kleine-Budde <mkl@pengutronix.de>
 L:	linux-can@vger.kernel.org
 W:	https://github.com/linux-can
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/mkl/linux-can.git
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/mkl/linux-can-next.git
 S:	Maintained
 F:	Documentation/devicetree/bindings/net/can/
 F:	drivers/net/can/
 F:	include/linux/can/dev.h
 F:	include/linux/can/platform/
 F:	include/uapi/linux/can/error.h
 F:	include/uapi/linux/can/netlink.h
 
 CAPABILITIES
 M:	Serge Hallyn <serge@hallyn.com>
 L:	linux-security-module@vger.kernel.org
 S:	Supported
 F:	include/linux/capability.h
 F:	include/uapi/linux/capability.h
 F:	security/commoncap.c
 F:	kernel/capability.c
 
 CAPELLA MICROSYSTEMS LIGHT SENSOR DRIVER
 M:	Kevin Tsai <ktsai@capellamicro.com>
 S:	Maintained
 F:	drivers/iio/light/cm*
 F:	Documentation/devicetree/bindings/i2c/trivial-admin-guide/devices.rst
 
 CAVIUM I2C DRIVER
 M:	Jan Glauber <jglauber@cavium.com>
 M:	David Daney <david.daney@cavium.com>
 W:	http://www.cavium.com
 S:	Supported
 F:	drivers/i2c/busses/i2c-octeon*
 F:	drivers/i2c/busses/i2c-thunderx*
 
 CAVIUM LIQUIDIO NETWORK DRIVER
 M:     Derek Chickles <derek.chickles@caviumnetworks.com>
 M:     Satanand Burla <satananda.burla@caviumnetworks.com>
 M:     Felix Manlunas <felix.manlunas@caviumnetworks.com>
 M:     Raghu Vatsavayi <raghu.vatsavayi@caviumnetworks.com>
 L:     netdev@vger.kernel.org
 W:     http://www.cavium.com
 S:     Supported
 F:     drivers/net/ethernet/cavium/liquidio/
 
 CC2520 IEEE-802.15.4 RADIO DRIVER
 M:	Varka Bhadram <varkabhadram@gmail.com>
 L:	linux-wpan@vger.kernel.org
 S:	Maintained
 F:	drivers/net/ieee802154/cc2520.c
 F:	include/linux/spi/cc2520.h
 F:	Documentation/devicetree/bindings/net/ieee802154/cc2520.txt
 
 CEC DRIVER
 M:	Hans Verkuil <hans.verkuil@cisco.com>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 W:	http://linuxtv.org
 S:	Supported
 F:	Documentation/media/kapi/cec-core.rst
 F:	Documentation/media/uapi/cec
 F:	drivers/media/cec/
 F:	drivers/media/cec-edid.c
 F:	drivers/media/rc/keymaps/rc-cec.c
 F:	include/media/cec.h
 F:	include/media/cec-edid.h
 F:	include/uapi/linux/cec.h
 F:	include/uapi/linux/cec-funcs.h
 
 CELL BROADBAND ENGINE ARCHITECTURE
 M:	Arnd Bergmann <arnd@arndb.de>
 L:	linuxppc-dev@lists.ozlabs.org
 W:	http://www.ibm.com/developerworks/power/cell/
 S:	Supported
 F:	arch/powerpc/include/asm/cell*.h
 F:	arch/powerpc/include/asm/spu*.h
 F:	arch/powerpc/include/uapi/asm/spu*.h
 F:	arch/powerpc/oprofile/*cell*
 F:	arch/powerpc/platforms/cell/
 
 CEPH COMMON CODE (LIBCEPH)
 M:	Ilya Dryomov <idryomov@gmail.com>
 M:	"Yan, Zheng" <zyan@redhat.com>
 M:	Sage Weil <sage@redhat.com>
 L:	ceph-devel@vger.kernel.org
 W:	http://ceph.com/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/sage/ceph-client.git
 T:	git git://github.com/ceph/ceph-client.git
 S:	Supported
 F:	net/ceph/
 F:	include/linux/ceph/
 F:	include/linux/crush/
 
 CEPH DISTRIBUTED FILE SYSTEM CLIENT (CEPH)
 M:	"Yan, Zheng" <zyan@redhat.com>
 M:	Sage Weil <sage@redhat.com>
 M:	Ilya Dryomov <idryomov@gmail.com>
 L:	ceph-devel@vger.kernel.org
 W:	http://ceph.com/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/sage/ceph-client.git
 T:	git git://github.com/ceph/ceph-client.git
 S:	Supported
 F:	Documentation/filesystems/ceph.txt
 F:	fs/ceph/
 
 CERTIFICATE HANDLING:
 M:	David Howells <dhowells@redhat.com>
 M:	David Woodhouse <dwmw2@infradead.org>
 L:	keyrings@vger.kernel.org
 S:	Maintained
 F:	Documentation/module-signing.txt
 F:	certs/
 F:	scripts/sign-file.c
 F:	scripts/extract-cert.c
 
 CERTIFIED WIRELESS USB (WUSB) SUBSYSTEM:
 L:	linux-usb@vger.kernel.org
 S:	Orphan
 F:	Documentation/usb/WUSB-Design-overview.txt
 F:	Documentation/usb/wusb-cbaf
 F:	drivers/usb/host/hwa-hc.c
 F:	drivers/usb/host/whci/
 F:	drivers/usb/wusbcore/
 F:	include/linux/usb/wusb*
 
 HT16K33 LED CONTROLLER DRIVER
 M:	Robin van der Gracht <robin@protonic.nl>
 S:	Maintained
 F:	drivers/auxdisplay/ht16k33.c
 F:	Documentation/devicetree/bindings/display/ht16k33.txt
 
 CFAG12864B LCD DRIVER
 M:	Miguel Ojeda Sandonis <miguel.ojeda.sandonis@gmail.com>
 W:	http://miguelojeda.es/auxdisplay.htm
 W:	http://jair.lab.fi.uva.es/~migojed/auxdisplay.htm
 S:	Maintained
 F:	drivers/auxdisplay/cfag12864b.c
 F:	include/linux/cfag12864b.h
 
 CFAG12864BFB LCD FRAMEBUFFER DRIVER
 M:	Miguel Ojeda Sandonis <miguel.ojeda.sandonis@gmail.com>
 W:	http://miguelojeda.es/auxdisplay.htm
 W:	http://jair.lab.fi.uva.es/~migojed/auxdisplay.htm
 S:	Maintained
 F:	drivers/auxdisplay/cfag12864bfb.c
 F:	include/linux/cfag12864b.h
 
 CFG80211 and NL80211
 M:	Johannes Berg <johannes@sipsolutions.net>
 L:	linux-wireless@vger.kernel.org
 W:	http://wireless.kernel.org/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/jberg/mac80211.git
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/jberg/mac80211-next.git
 S:	Maintained
 F:	include/uapi/linux/nl80211.h
 F:	include/net/cfg80211.h
 F:	net/wireless/*
 X:	net/wireless/wext*
 
 CHAR and MISC DRIVERS
 M:	Arnd Bergmann <arnd@arndb.de>
 M:	Greg Kroah-Hartman <gregkh@linuxfoundation.org>
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/char-misc.git
 S:	Supported
 F:	drivers/char/*
 F:	drivers/misc/*
 F:	include/linux/miscdevice.h
 
 CHECKPATCH
 M:	Andy Whitcroft <apw@canonical.com>
 M:	Joe Perches <joe@perches.com>
 S:	Maintained
 F:	scripts/checkpatch.pl
 
 CHINESE DOCUMENTATION
 M:	Harry Wei <harryxiyou@gmail.com>
 L:	xiyoulinuxkernelgroup@googlegroups.com (subscribers-only)
 L:	linux-kernel@zh-kernel.org (moderated for non-subscribers)
 S:	Maintained
 F:	Documentation/translations/zh_CN/
 
 CHIPIDEA USB HIGH SPEED DUAL ROLE CONTROLLER
 M:	Peter Chen <Peter.Chen@nxp.com>
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/peter.chen/usb.git
 L:	linux-usb@vger.kernel.org
 S:	Maintained
 F:	drivers/usb/chipidea/
 
 CHIPONE ICN8318 I2C TOUCHSCREEN DRIVER
 M:	Hans de Goede <hdegoede@redhat.com>
 L:	linux-input@vger.kernel.org
 S:	Maintained
 F:	Documentation/devicetree/bindings/input/touchscreen/chipone_icn8318.txt
 F:	drivers/input/touchscreen/chipone_icn8318.c
 
 CHROME HARDWARE PLATFORM SUPPORT
 M:	Olof Johansson <olof@lixom.net>
 S:	Maintained
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/olof/chrome-platform.git
 F:	drivers/platform/chrome/
 
 CISCO VIC ETHERNET NIC DRIVER
 M:	Christian Benvenuti <benve@cisco.com>
 M:	Sujith Sankar <ssujith@cisco.com>
 M:	Govindarajulu Varadarajan <_govind@gmx.com>
 M:	Neel Patel <neepatel@cisco.com>
 S:	Supported
 F:	drivers/net/ethernet/cisco/enic/
 
 CISCO VIC LOW LATENCY NIC DRIVER
 M:	Christian Benvenuti <benve@cisco.com>
 M:	Dave Goodell <dgoodell@cisco.com>
 S:	Supported
 F:	drivers/infiniband/hw/usnic/
 
 CIRRUS LOGIC EP93XX ETHERNET DRIVER
 M:	Hartley Sweeten <hsweeten@visionengravers.com>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/ethernet/cirrus/ep93xx_eth.c
 
 CIRRUS LOGIC AUDIO CODEC DRIVERS
 M:	Brian Austin <brian.austin@cirrus.com>
 M:	Paul Handrigan <Paul.Handrigan@cirrus.com>
 L:	alsa-devel@alsa-project.org (moderated for non-subscribers)
 S:	Maintained
 F:	sound/soc/codecs/cs*
 
 CLEANCACHE API
 M:	Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
 L:	linux-kernel@vger.kernel.org
 S:	Maintained
 F:	mm/cleancache.c
 F:	include/linux/cleancache.h
 
 CLK API
 M:	Russell King <linux@armlinux.org.uk>
 L:	linux-clk@vger.kernel.org
 S:	Maintained
 F:	include/linux/clk.h
 
 CLOCKSOURCE, CLOCKEVENT DRIVERS
 M:	Daniel Lezcano <daniel.lezcano@linaro.org>
 M:	Thomas Gleixner <tglx@linutronix.de>
 L:	linux-kernel@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip.git timers/core
 S:	Supported
 F:	drivers/clocksource
 
 CISCO FCOE HBA DRIVER
 M:	Satish Kharat <satishkh@cisco.com>
 M:	Sesidhar Baddela <sebaddel@cisco.com>
 M:	Karan Tilak Kumar <kartilak@cisco.com>
 L:	linux-scsi@vger.kernel.org
 S:	Supported
 F:	drivers/scsi/fnic/
 
 CISCO SCSI HBA DRIVER
 M:	Karan Tilak Kumar <kartilak@cisco.com>
 M:	Sesidhar Baddela <sebaddel@cisco.com>
 L:	linux-scsi@vger.kernel.org
 S:	Supported
 F:	drivers/scsi/snic/
 
 CMPC ACPI DRIVER
 M:	Thadeu Lima de Souza Cascardo <cascardo@holoscopio.com>
 M:	Daniel Oliveira Nascimento <don@syst.com.br>
 L:	platform-driver-x86@vger.kernel.org
 S:	Supported
 F:	drivers/platform/x86/classmate-laptop.c
 
 COBALT MEDIA DRIVER
 M:	Hans Verkuil <hans.verkuil@cisco.com>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 W:	https://linuxtv.org
 S:	Supported
 F:	drivers/media/pci/cobalt/
 
 COCCINELLE/Semantic Patches (SmPL)
 M:	Julia Lawall <Julia.Lawall@lip6.fr>
 M:	Gilles Muller <Gilles.Muller@lip6.fr>
 M:	Nicolas Palix <nicolas.palix@imag.fr>
 M:	Michal Marek <mmarek@suse.com>
 L:	cocci@systeme.lip6.fr (moderated for non-subscribers)
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/mmarek/kbuild.git misc
 W:	http://coccinelle.lip6.fr/
 S:	Supported
 F:	Documentation/dev-tools/coccinelle.rst
 F:	scripts/coccinelle/
 F:	scripts/coccicheck
 
 CODA FILE SYSTEM
 M:	Jan Harkes <jaharkes@cs.cmu.edu>
 M:	coda@cs.cmu.edu
 L:	codalist@coda.cs.cmu.edu
 W:	http://www.coda.cs.cmu.edu/
 S:	Maintained
 F:	Documentation/filesystems/coda.txt
 F:	fs/coda/
 F:	include/linux/coda*.h
 F:	include/uapi/linux/coda*.h
 
 CODA V4L2 MEM2MEM DRIVER
 M:	Philipp Zabel <p.zabel@pengutronix.de>
 L:	linux-media@vger.kernel.org
 S:	Maintained
 F:	Documentation/devicetree/bindings/media/coda.txt
 F:	drivers/media/platform/coda/
 
 COMMON CLK FRAMEWORK
 M:	Michael Turquette <mturquette@baylibre.com>
 M:	Stephen Boyd <sboyd@codeaurora.org>
 L:	linux-clk@vger.kernel.org
 Q:	http://patchwork.kernel.org/project/linux-clk/list/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/clk/linux.git
 S:	Maintained
 F:	Documentation/devicetree/bindings/clock/
 F:	drivers/clk/
 X:	drivers/clk/clkdev.c
 F:	include/linux/clk-pr*
 F:	include/linux/clk/
 
 COMMON INTERNET FILE SYSTEM (CIFS)
 M:	Steve French <sfrench@samba.org>
 L:	linux-cifs@vger.kernel.org
 L:	samba-technical@lists.samba.org (moderated for non-subscribers)
 W:	http://linux-cifs.samba.org/
 T:	git git://git.samba.org/sfrench/cifs-2.6.git
 S:	Supported
 F:	Documentation/filesystems/cifs/
 F:	fs/cifs/
 
 COMPACTPCI HOTPLUG CORE
 M:	Scott Murray <scott@spiteful.org>
 L:	linux-pci@vger.kernel.org
 S:	Maintained
 F:	drivers/pci/hotplug/cpci_hotplug*
 
 COMPACTPCI HOTPLUG ZIATECH ZT5550 DRIVER
 M:	Scott Murray <scott@spiteful.org>
 L:	linux-pci@vger.kernel.org
 S:	Maintained
 F:	drivers/pci/hotplug/cpcihp_zt5550.*
 
 COMPACTPCI HOTPLUG GENERIC DRIVER
 M:	Scott Murray <scott@spiteful.org>
 L:	linux-pci@vger.kernel.org
 S:	Maintained
 F:	drivers/pci/hotplug/cpcihp_generic.c
 
 COMPAL LAPTOP SUPPORT
 M:	Cezary Jackiewicz <cezary.jackiewicz@gmail.com>
 L:	platform-driver-x86@vger.kernel.org
 S:	Maintained
 F:	drivers/platform/x86/compal-laptop.c
 
 CONEXANT ACCESSRUNNER USB DRIVER
 L:	accessrunner-general@lists.sourceforge.net
 W:	http://accessrunner.sourceforge.net/
 S:	Orphan
 F:	drivers/usb/atm/cxacru.c
 
 CONFIGFS
 M:	Joel Becker <jlbec@evilplan.org>
 M:	Christoph Hellwig <hch@lst.de>
 T:	git git://git.infradead.org/users/hch/configfs.git
 S:	Supported
 F:	fs/configfs/
 F:	include/linux/configfs.h
 
 CONNECTOR
 M:	Evgeniy Polyakov <zbr@ioremap.net>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/connector/
 
 CONTROL GROUP (CGROUP)
 M:	Tejun Heo <tj@kernel.org>
 M:	Li Zefan <lizefan@huawei.com>
 M:	Johannes Weiner <hannes@cmpxchg.org>
 L:	cgroups@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/tj/cgroup.git
 S:	Maintained
 F:	Documentation/cgroup*
 F:	include/linux/cgroup*
 F:	kernel/cgroup*
 
 CONTROL GROUP - CPUSET
 M:	Li Zefan <lizefan@huawei.com>
 L:	cgroups@vger.kernel.org
 W:	http://www.bullopensource.org/cpuset/
 W:	http://oss.sgi.com/projects/cpusets/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/tj/cgroup.git
 S:	Maintained
 F:	Documentation/cgroup-v1/cpusets.txt
 F:	include/linux/cpuset.h
 F:	kernel/cpuset.c
 
 CONTROL GROUP - MEMORY RESOURCE CONTROLLER (MEMCG)
 M:	Johannes Weiner <hannes@cmpxchg.org>
 M:	Michal Hocko <mhocko@kernel.org>
 M:	Vladimir Davydov <vdavydov.dev@gmail.com>
 L:	cgroups@vger.kernel.org
 L:	linux-mm@kvack.org
 S:	Maintained
 F:	mm/memcontrol.c
 F:	mm/swap_cgroup.c
 
 CORETEMP HARDWARE MONITORING DRIVER
 M:	Fenghua Yu <fenghua.yu@intel.com>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	Documentation/hwmon/coretemp
 F:	drivers/hwmon/coretemp.c
 
 COSA/SRP SYNC SERIAL DRIVER
 M:	Jan "Yenya" Kasprzak <kas@fi.muni.cz>
 W:	http://www.fi.muni.cz/~kas/cosa/
 S:	Maintained
 F:	drivers/net/wan/cosa*
 
 CPMAC ETHERNET DRIVER
 M:	Florian Fainelli <f.fainelli@gmail.com>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/ethernet/ti/cpmac.c
 
 CPU FREQUENCY DRIVERS
 M:	"Rafael J. Wysocki" <rjw@rjwysocki.net>
 M:	Viresh Kumar <viresh.kumar@linaro.org>
 L:	linux-pm@vger.kernel.org
 S:	Maintained
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm.git
 T:	git git://git.linaro.org/people/vireshk/linux.git (For ARM Updates)
 B:	https://bugzilla.kernel.org
 F:	Documentation/cpu-freq/
 F:	drivers/cpufreq/
 F:	include/linux/cpufreq.h
 
 CPU FREQUENCY DRIVERS - ARM BIG LITTLE
 M:	Viresh Kumar <viresh.kumar@linaro.org>
 M:	Sudeep Holla <sudeep.holla@arm.com>
 L:	linux-pm@vger.kernel.org
 W:	http://www.arm.com/products/processors/technologies/biglittleprocessing.php
 S:	Maintained
 F:	drivers/cpufreq/arm_big_little.h
 F:	drivers/cpufreq/arm_big_little.c
 F:	drivers/cpufreq/arm_big_little_dt.c
 
 CPUIDLE DRIVER - ARM BIG LITTLE
 M:	Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
 M:	Daniel Lezcano <daniel.lezcano@linaro.org>
 L:	linux-pm@vger.kernel.org
 L:	linux-arm-kernel@lists.infradead.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm.git
 S:	Maintained
 F:	drivers/cpuidle/cpuidle-big_little.c
 
 CPUIDLE DRIVER - ARM EXYNOS
 M:	Bartlomiej Zolnierkiewicz <b.zolnierkie@samsung.com>
 M:	Daniel Lezcano <daniel.lezcano@linaro.org>
 M:	Kukjin Kim <kgene@kernel.org>
 L:	linux-pm@vger.kernel.org
 L:	linux-samsung-soc@vger.kernel.org
 S:	Supported
 F:	drivers/cpuidle/cpuidle-exynos.c
 F:	arch/arm/mach-exynos/pm.c
 
 CPUIDLE DRIVERS
 M:	"Rafael J. Wysocki" <rjw@rjwysocki.net>
 M:	Daniel Lezcano <daniel.lezcano@linaro.org>
 L:	linux-pm@vger.kernel.org
 S:	Maintained
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm.git
 B:	https://bugzilla.kernel.org
 F:	drivers/cpuidle/*
 F:	include/linux/cpuidle.h
 
 CPUID/MSR DRIVER
 M:	"H. Peter Anvin" <hpa@zytor.com>
 S:	Maintained
 F:	arch/x86/kernel/cpuid.c
 F:	arch/x86/kernel/msr.c
 
 CPU POWER MONITORING SUBSYSTEM
 M:	Thomas Renninger <trenn@suse.com>
 L:	linux-pm@vger.kernel.org
 S:	Maintained
 F:	tools/power/cpupower/
 
 CRAMFS FILESYSTEM
 W:	http://sourceforge.net/projects/cramfs/
 S:	Orphan / Obsolete
 F:	Documentation/filesystems/cramfs.txt
 F:	fs/cramfs/
 
 CRIS PORT
 M:	Mikael Starvik <starvik@axis.com>
 M:	Jesper Nilsson <jesper.nilsson@axis.com>
 L:	linux-cris-kernel@axis.com
 W:	http://developer.axis.com
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/jesper/cris.git
 S:	Maintained
 F:	arch/cris/
 F:	drivers/tty/serial/crisv10.*
 
 CRYPTO API
 M:	Herbert Xu <herbert@gondor.apana.org.au>
 M:	"David S. Miller" <davem@davemloft.net>
 L:	linux-crypto@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/herbert/cryptodev-2.6.git
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/herbert/crypto-2.6.git
 S:	Maintained
 F:	Documentation/crypto/
 F:	Documentation/devicetree/bindings/crypto/
 F:	Documentation/DocBook/crypto-API.tmpl
 F:	arch/*/crypto/
 F:	crypto/
 F:	drivers/crypto/
 F:	include/crypto/
 F:	include/linux/crypto*
 
 CRYPTOGRAPHIC RANDOM NUMBER GENERATOR
 M:	Neil Horman <nhorman@tuxdriver.com>
 L:	linux-crypto@vger.kernel.org
 S:	Maintained
 F:	crypto/ansi_cprng.c
 F:	crypto/rng.c
 
 CS3308 MEDIA DRIVER
 M:	Hans Verkuil <hverkuil@xs4all.nl>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 W:	http://linuxtv.org
 S:	Odd Fixes
 F:	drivers/media/i2c/cs3308.c
 F:	drivers/media/i2c/cs3308.h
 
 CS5535 Audio ALSA driver
 M:	Jaya Kumar <jayakumar.alsa@gmail.com>
 S:	Maintained
 F:	sound/pci/cs5535audio/
 
 CW1200 WLAN driver
 M:	Solomon Peachy <pizza@shaftnet.org>
 S:	Maintained
 F:	drivers/net/wireless/st/cw1200/
 
 CX18 VIDEO4LINUX DRIVER
 M:	Andy Walls <awalls@md.metrocast.net>
 L:	ivtv-devel@ivtvdriver.org (subscribers-only)
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 W:	https://linuxtv.org
 W:	http://www.ivtvdriver.org/index.php/Cx18
 S:	Maintained
 F:	Documentation/media/v4l-drivers/cx18*
 F:	drivers/media/pci/cx18/
 F:	include/uapi/linux/ivtv*
 
 CX2341X MPEG ENCODER HELPER MODULE
 M:	Hans Verkuil <hverkuil@xs4all.nl>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 W:	https://linuxtv.org
 S:	Maintained
 F:	drivers/media/common/cx2341x*
 F:	include/media/cx2341x*
 
 CX24120 MEDIA DRIVER
 M:	Jemma Denson <jdenson@gmail.com>
 M:	Patrick Boettcher <patrick.boettcher@posteo.de>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 S:	Maintained
 F:	drivers/media/dvb-frontends/cx24120*
 
 CX88 VIDEO4LINUX DRIVER
 M:	Mauro Carvalho Chehab <mchehab@s-opensource.com>
 M:	Mauro Carvalho Chehab <mchehab@kernel.org>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Odd fixes
 F:	Documentation/media/v4l-drivers/cx88*
 F:	drivers/media/pci/cx88/
 
 CXD2820R MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://palosaari.fi/linux/
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/anttip/media_tree.git
 S:	Maintained
 F:	drivers/media/dvb-frontends/cxd2820r*
 
 CXGB3 ETHERNET DRIVER (CXGB3)
 M:	Santosh Raspatur <santosh@chelsio.com>
 L:	netdev@vger.kernel.org
 W:	http://www.chelsio.com
 S:	Supported
 F:	drivers/net/ethernet/chelsio/cxgb3/
 
 CXGB3 ISCSI DRIVER (CXGB3I)
 M:	Karen Xie <kxie@chelsio.com>
 L:	linux-scsi@vger.kernel.org
 W:	http://www.chelsio.com
 S:	Supported
 F:	drivers/scsi/cxgbi/cxgb3i
 
 CXGB3 IWARP RNIC DRIVER (IW_CXGB3)
 M:	Steve Wise <swise@chelsio.com>
 L:	linux-rdma@vger.kernel.org
 W:	http://www.openfabrics.org
 S:	Supported
 F:	drivers/infiniband/hw/cxgb3/
 F:	include/uapi/rdma/cxgb3-abi.h
 
 CXGB4 ETHERNET DRIVER (CXGB4)
 M:	Ganesh Goudar <ganeshgr@chelsio.com>
 L:	netdev@vger.kernel.org
 W:	http://www.chelsio.com
 S:	Supported
 F:	drivers/net/ethernet/chelsio/cxgb4/
 
 CXGB4 ISCSI DRIVER (CXGB4I)
 M:	Karen Xie <kxie@chelsio.com>
 L:	linux-scsi@vger.kernel.org
 W:	http://www.chelsio.com
 S:	Supported
 F:	drivers/scsi/cxgbi/cxgb4i
 
 CXGB4 IWARP RNIC DRIVER (IW_CXGB4)
 M:	Steve Wise <swise@chelsio.com>
 L:	linux-rdma@vger.kernel.org
 W:	http://www.openfabrics.org
 S:	Supported
 F:	drivers/infiniband/hw/cxgb4/
 F:	include/uapi/rdma/cxgb4-abi.h
 
 CXGB4VF ETHERNET DRIVER (CXGB4VF)
 M:	Casey Leedom <leedom@chelsio.com>
 L:	netdev@vger.kernel.org
 W:	http://www.chelsio.com
 S:	Supported
 F:	drivers/net/ethernet/chelsio/cxgb4vf/
 
 CXL (IBM Coherent Accelerator Processor Interface CAPI) DRIVER
 M:	Ian Munsie <imunsie@au1.ibm.com>
 M:	Frederic Barrat <fbarrat@linux.vnet.ibm.com>
 L:	linuxppc-dev@lists.ozlabs.org
 S:	Supported
 F:	arch/powerpc/platforms/powernv/pci-cxl.c
 F:	drivers/misc/cxl/
 F:	include/misc/cxl*
 F:	include/uapi/misc/cxl.h
 F:	Documentation/powerpc/cxl.txt
 F:	Documentation/ABI/testing/sysfs-class-cxl
 
 CXLFLASH (IBM Coherent Accelerator Processor Interface CAPI Flash) SCSI DRIVER
 M:	Manoj N. Kumar <manoj@linux.vnet.ibm.com>
 M:	Matthew R. Ochs <mrochs@linux.vnet.ibm.com>
 M:	Uma Krishnan <ukrishn@linux.vnet.ibm.com>
 L:	linux-scsi@vger.kernel.org
 S:	Supported
 F:	drivers/scsi/cxlflash/
 F:	include/uapi/scsi/cxlflash_ioctls.h
 F:	Documentation/powerpc/cxlflash.txt
 
 STMMAC ETHERNET DRIVER
 M:	Giuseppe Cavallaro <peppe.cavallaro@st.com>
 M:	Alexandre Torgue <alexandre.torgue@st.com>
 L:	netdev@vger.kernel.org
 W:	http://www.stlinux.com
 S:	Supported
 F:	drivers/net/ethernet/stmicro/stmmac/
 
 CYBERPRO FB DRIVER
 M:	Russell King <linux@armlinux.org.uk>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 W:	http://www.armlinux.org.uk/
 S:	Maintained
 F:	drivers/video/fbdev/cyber2000fb.*
 
 CYCLADES ASYNC MUX DRIVER
 W:	http://www.cyclades.com/
 S:	Orphan
 F:	drivers/tty/cyclades.c
 F:	include/linux/cyclades.h
 F:	include/uapi/linux/cyclades.h
 
 CYCLADES PC300 DRIVER
 W:	http://www.cyclades.com/
 S:	Orphan
 F:	drivers/net/wan/pc300*
 
 CYPRESS_FIRMWARE MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://palosaari.fi/linux/
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/anttip/media_tree.git
 S:	Maintained
 F:	drivers/media/common/cypress_firmware*
 
 CYTTSP TOUCHSCREEN DRIVER
 M:	Ferruh Yigit <fery@cypress.com>
 L:	linux-input@vger.kernel.org
 S:	Supported
 F:	drivers/input/touchscreen/cyttsp*
 F:	include/linux/input/cyttsp.h
 
 DALLAS/MAXIM DS1685-FAMILY REAL TIME CLOCK
 M:	Joshua Kinard <kumba@gentoo.org>
 S:	Maintained
 F:	drivers/rtc/rtc-ds1685.c
 F:	include/linux/rtc/ds1685.h
 
 DAMA SLAVE for AX.25
 M:	Joerg Reuter <jreuter@yaina.de>
 W:	http://yaina.de/jreuter/
 W:	http://www.qsl.net/dl1bke/
 L:	linux-hams@vger.kernel.org
 S:	Maintained
 F:	net/ax25/af_ax25.c
 F:	net/ax25/ax25_dev.c
 F:	net/ax25/ax25_ds_*
 F:	net/ax25/ax25_in.c
 F:	net/ax25/ax25_out.c
 F:	net/ax25/ax25_timer.c
 F:	net/ax25/sysctl_net_ax25.c
 
 DAVICOM FAST ETHERNET (DMFE) NETWORK DRIVER
 L:	netdev@vger.kernel.org
 S:	Orphan
 F:	Documentation/networking/dmfe.txt
 F:	drivers/net/ethernet/dec/tulip/dmfe.c
 
 DC390/AM53C974 SCSI driver
 M:	Hannes Reinecke <hare@suse.com>
 L:	linux-scsi@vger.kernel.org
 S:	Maintained
 F:	drivers/scsi/am53c974.c
 
 DC395x SCSI driver
 M:	Oliver Neukum <oliver@neukum.org>
 M:	Ali Akcaagac <aliakc@web.de>
 M:	Jamie Lenehan <lenehan@twibble.org>
 L:	dc395x@twibble.org
 W:	http://twibble.org/dist/dc395x/
 W:	http://lists.twibble.org/mailman/listinfo/dc395x/
 S:	Maintained
 F:	Documentation/scsi/dc395x.txt
 F:	drivers/scsi/dc395x.*
 
 DCCP PROTOCOL
 M:	Gerrit Renker <gerrit@erg.abdn.ac.uk>
 L:	dccp@vger.kernel.org
 W:	http://www.linuxfoundation.org/collaborate/workgroups/networking/dccp
 S:	Maintained
 F:	include/linux/dccp.h
 F:	include/uapi/linux/dccp.h
 F:	include/linux/tfrc.h
 F:	net/dccp/
 
 DECnet NETWORK LAYER
 W:	http://linux-decnet.sourceforge.net
 L:	linux-decnet-user@lists.sourceforge.net
 S:	Orphan
 F:	Documentation/networking/decnet.txt
 F:	net/decnet/
 
 DECSTATION PLATFORM SUPPORT
 M:	"Maciej W. Rozycki" <macro@linux-mips.org>
 L:	linux-mips@linux-mips.org
 W:	http://www.linux-mips.org/wiki/DECstation
 S:	Maintained
 F:	arch/mips/dec/
 F:	arch/mips/include/asm/dec/
 F:	arch/mips/include/asm/mach-dec/
 
 DEFXX FDDI NETWORK DRIVER
 M:	"Maciej W. Rozycki" <macro@linux-mips.org>
 S:	Maintained
 F:	drivers/net/fddi/defxx.*
 
 DELL LAPTOP DRIVER
 M:	Matthew Garrett <mjg59@srcf.ucam.org>
 M:	Pali RohÃ¡r <pali.rohar@gmail.com>
 L:	platform-driver-x86@vger.kernel.org
 S:	Maintained
 F:	drivers/platform/x86/dell-laptop.c
 
 DELL LAPTOP RBTN DRIVER
 M:	Pali RohÃ¡r <pali.rohar@gmail.com>
 S:	Maintained
 F:	drivers/platform/x86/dell-rbtn.*
 
 DELL LAPTOP FREEFALL DRIVER
 M:	Pali RohÃ¡r <pali.rohar@gmail.com>
 S:	Maintained
 F:	drivers/platform/x86/dell-smo8800.c
 
 DELL LAPTOP SMM DRIVER
 M:	Pali RohÃ¡r <pali.rohar@gmail.com>
 S:	Maintained
 F:	drivers/hwmon/dell-smm-hwmon.c
 F:	include/uapi/linux/i8k.h
 
 DELL SYSTEMS MANAGEMENT BASE DRIVER (dcdbas)
 M:	Doug Warzecha <Douglas_Warzecha@dell.com>
 S:	Maintained
 F:	Documentation/dcdbas.txt
 F:	drivers/firmware/dcdbas.*
 
 DELL WMI EXTRAS DRIVER
 M:	Matthew Garrett <mjg59@srcf.ucam.org>
 M:	Pali RohÃ¡r <pali.rohar@gmail.com>
 S:	Maintained
 F:	drivers/platform/x86/dell-wmi.c
 
 DESIGNWARE USB2 DRD IP DRIVER
 M:	John Youn <johnyoun@synopsys.com>
 L:	linux-usb@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/balbi/usb.git
 S:	Maintained
 F:	drivers/usb/dwc2/
 
 DESIGNWARE USB3 DRD IP DRIVER
 M:	Felipe Balbi <balbi@kernel.org>
 L:	linux-usb@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/balbi/usb.git
 S:	Maintained
 F:	drivers/usb/dwc3/
 
 DEVICE COREDUMP (DEV_COREDUMP)
 M:	Johannes Berg <johannes@sipsolutions.net>
 L:	linux-kernel@vger.kernel.org
 S:	Maintained
 F:	drivers/base/devcoredump.c
 F:	include/linux/devcoredump.h
 
 DEVICE FREQUENCY (DEVFREQ)
 M:	MyungJoo Ham <myungjoo.ham@samsung.com>
 M:	Kyungmin Park <kyungmin.park@samsung.com>
 R:	Chanwoo Choi <cw00.choi@samsung.com>
 L:	linux-pm@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/mzx/devfreq.git
 S:	Maintained
 F:	drivers/devfreq/
 F:	include/linux/devfreq.h
 F:	Documentation/devicetree/bindings/devfreq/
 
 DEVICE FREQUENCY EVENT (DEVFREQ-EVENT)
 M:	Chanwoo Choi <cw00.choi@samsung.com>
 L:	linux-pm@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/mzx/devfreq.git
 S:	Supported
 F:	drivers/devfreq/event/
 F:	drivers/devfreq/devfreq-event.c
 F:	include/linux/devfreq-event.h
 F:	Documentation/devicetree/bindings/devfreq/event/
 
 BUS FREQUENCY DRIVER FOR SAMSUNG EXYNOS
 M:	Chanwoo Choi <cw00.choi@samsung.com>
 L:	linux-pm@vger.kernel.org
 L:	linux-samsung-soc@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/mzx/devfreq.git
 S:	Maintained
 F:	drivers/devfreq/exynos-bus.c
 F:	Documentation/devicetree/bindings/devfreq/exynos-bus.txt
 
 DEVICE NUMBER REGISTRY
 M:	Torben Mathiasen <device@lanana.org>
 W:	http://lanana.org/docs/device-list/index.html
 S:	Maintained
 
 DEVICE-MAPPER  (LVM)
 M:	Alasdair Kergon <agk@redhat.com>
 M:	Mike Snitzer <snitzer@redhat.com>
 M:	dm-devel@redhat.com
 L:	dm-devel@redhat.com
 W:	http://sources.redhat.com/dm
 Q:	http://patchwork.kernel.org/project/dm-devel/list/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/device-mapper/linux-dm.git
 T:	quilt http://people.redhat.com/agk/patches/linux/editing/
 S:	Maintained
 F:	Documentation/device-mapper/
 F:	drivers/md/dm*
 F:	drivers/md/persistent-data/
 F:	include/linux/device-mapper.h
 F:	include/linux/dm-*.h
 F:	include/uapi/linux/dm-*.h
 
 DEVLINK
 M:	Jiri Pirko <jiri@mellanox.com>
 L:	netdev@vger.kernel.org
 S:	Supported
 F:	net/core/devlink.c
 F:	include/net/devlink.h
 F:	include/uapi/linux/devlink.h
 
 DIALOG SEMICONDUCTOR DRIVERS
 M:	Support Opensource <support.opensource@diasemi.com>
 W:	http://www.dialog-semiconductor.com/products
 S:	Supported
 F:	Documentation/hwmon/da90??
 F:	Documentation/devicetree/bindings/mfd/da90*.txt
 F:	Documentation/devicetree/bindings/regulator/da92*.txt
 F:	Documentation/devicetree/bindings/sound/da[79]*.txt
 F:	drivers/gpio/gpio-da90??.c
 F:	drivers/hwmon/da90??-hwmon.c
 F:	drivers/iio/adc/da91??-*.c
 F:	drivers/input/misc/da90??_onkey.c
 F:	drivers/input/touchscreen/da9052_tsi.c
 F:	drivers/leds/leds-da90??.c
 F:	drivers/mfd/da903x.c
 F:	drivers/mfd/da90??-*.c
 F:	drivers/mfd/da91??-*.c
 F:	drivers/power/supply/da9052-battery.c
 F:	drivers/power/supply/da91??-*.c
 F:	drivers/regulator/da903x.c
 F:	drivers/regulator/da9???-regulator.[ch]
 F:	drivers/rtc/rtc-da90??.c
 F:	drivers/video/backlight/da90??_bl.c
 F:	drivers/watchdog/da90??_wdt.c
 F:	include/linux/mfd/da903x.h
 F:	include/linux/mfd/da9052/
 F:	include/linux/mfd/da9055/
 F:	include/linux/mfd/da9062/
 F:	include/linux/mfd/da9063/
 F:	include/linux/mfd/da9150/
 F:	include/linux/regulator/da9211.h
 F:	include/sound/da[79]*.h
 F:	sound/soc/codecs/da[79]*.[ch]
 
 DIAMOND SYSTEMS GPIO-MM GPIO DRIVER
 M:	William Breathitt Gray <vilhelm.gray@gmail.com>
 L:	linux-gpio@vger.kernel.org
 S:	Maintained
 F:	drivers/gpio/gpio-gpio-mm.c
 
 DIGI NEO AND CLASSIC PCI PRODUCTS
 M:	Lidza Louina <lidza.louina@gmail.com>
 M:	Mark Hounschell <markh@compro.net>
 L:	driverdev-devel@linuxdriverproject.org
 S:	Maintained
 F:	drivers/staging/dgnc/
 
 DIOLAN U2C-12 I2C DRIVER
 M:	Guenter Roeck <linux@roeck-us.net>
 L:	linux-i2c@vger.kernel.org
 S:	Maintained
 F:	drivers/i2c/busses/i2c-diolan-u2c.c
 
 DIRECT ACCESS (DAX)
 M:	Matthew Wilcox <willy@linux.intel.com>
 L:	linux-fsdevel@vger.kernel.org
 S:	Supported
 F:	fs/dax.c
 
 DIRECTORY NOTIFICATION (DNOTIFY)
 M:	Eric Paris <eparis@parisplace.org>
 S:	Maintained
 F:	Documentation/filesystems/dnotify.txt
 F:	fs/notify/dnotify/
 F:	include/linux/dnotify.h
 
 DISK GEOMETRY AND PARTITION HANDLING
 M:	Andries Brouwer <aeb@cwi.nl>
 W:	http://www.win.tue.nl/~aeb/linux/Large-Disk.html
 W:	http://www.win.tue.nl/~aeb/linux/zip/zip-1.html
 W:	http://www.win.tue.nl/~aeb/partitions/partition_types-1.html
 S:	Maintained
 
 DISKQUOTA
 M:	Jan Kara <jack@suse.com>
 S:	Maintained
 F:	Documentation/filesystems/quota.txt
 F:	fs/quota/
 F:	include/linux/quota*.h
 F:	include/uapi/linux/quota*.h
 
 DISPLAYLINK USB 2.0 FRAMEBUFFER DRIVER (UDLFB)
 M:	Bernie Thompson <bernie@plugable.com>
 L:	linux-fbdev@vger.kernel.org
 S:	Maintained
 W:	http://plugable.com/category/projects/udlfb/
 F:	drivers/video/fbdev/udlfb.c
 F:	include/video/udlfb.h
 F:	Documentation/fb/udlfb.txt
 
 DISTRIBUTED LOCK MANAGER (DLM)
 M:	Christine Caulfield <ccaulfie@redhat.com>
 M:	David Teigland <teigland@redhat.com>
 L:	cluster-devel@redhat.com
 W:	http://sources.redhat.com/cluster/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/teigland/linux-dlm.git
 S:	Supported
 F:	fs/dlm/
 
 DMA BUFFER SHARING FRAMEWORK
 M:	Sumit Semwal <sumit.semwal@linaro.org>
 S:	Maintained
 L:	linux-media@vger.kernel.org
 L:	dri-devel@lists.freedesktop.org
 L:	linaro-mm-sig@lists.linaro.org (moderated for non-subscribers)
 F:	drivers/dma-buf/
 F:	include/linux/dma-buf*
 F:	include/linux/reservation.h
 F:	include/linux/*fence.h
 F:	Documentation/dma-buf-sharing.txt
 T:	git git://anongit.freedesktop.org/drm/drm-misc
 
 SYNC FILE FRAMEWORK
 M:	Sumit Semwal <sumit.semwal@linaro.org>
 R:	Gustavo Padovan <gustavo@padovan.org>
 S:	Maintained
 L:	linux-media@vger.kernel.org
 L:	dri-devel@lists.freedesktop.org
 F:	drivers/dma-buf/sync_*
 F:	drivers/dma-buf/sw_sync.c
 F:	include/linux/sync_file.h
 F:	include/uapi/linux/sync_file.h
 F:	Documentation/sync_file.txt
 T:	git git://anongit.freedesktop.org/drm/drm-misc
 
 DMA GENERIC OFFLOAD ENGINE SUBSYSTEM
 M:	Vinod Koul <vinod.koul@intel.com>
 L:	dmaengine@vger.kernel.org
 Q:	https://patchwork.kernel.org/project/linux-dmaengine/list/
 S:	Maintained
 F:	drivers/dma/
 F:	include/linux/dmaengine.h
 F:	Documentation/devicetree/bindings/dma/
 F:	Documentation/dmaengine/
 T:	git git://git.infradead.org/users/vkoul/slave-dma.git
 
 DME1737 HARDWARE MONITOR DRIVER
 M:	Juerg Haefliger <juergh@gmail.com>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	Documentation/hwmon/dme1737
 F:	drivers/hwmon/dme1737.c
 
 DMI/SMBIOS SUPPORT
 M:	Jean Delvare <jdelvare@suse.com>
 S:	Maintained
 T:	quilt http://jdelvare.nerim.net/devel/linux/jdelvare-dmi/
 F:	Documentation/ABI/testing/sysfs-firmware-dmi-tables
 F:	drivers/firmware/dmi-id.c
 F:	drivers/firmware/dmi_scan.c
 F:	include/linux/dmi.h
 
 DOCUMENTATION
 M:	Jonathan Corbet <corbet@lwn.net>
 L:	linux-doc@vger.kernel.org
 S:	Maintained
 F:	Documentation/
 F:	scripts/docproc.c
 F:	scripts/kernel-doc*
 X:	Documentation/ABI/
 X:	Documentation/devicetree/
 X:	Documentation/acpi
 X:	Documentation/power
 X:	Documentation/spi
 X:	Documentation/media
 T:	git git://git.lwn.net/linux.git docs-next
 
 DOUBLETALK DRIVER
 M:	"James R. Van Zandt" <jrv@vanzandt.mv.com>
 L:	blinux-list@redhat.com
 S:	Maintained
 F:	drivers/char/dtlk.c
 F:	include/linux/dtlk.h
 
 DPT_I2O SCSI RAID DRIVER
 M:	Adaptec OEM Raid Solutions <aacraid@adaptec.com>
 L:	linux-scsi@vger.kernel.org
 W:	http://www.adaptec.com/
 S:	Maintained
 F:	drivers/scsi/dpt*
 F:	drivers/scsi/dpt/
 
 DRBD DRIVER
 M:	Philipp Reisner <philipp.reisner@linbit.com>
 M:	Lars Ellenberg <lars.ellenberg@linbit.com>
 L:	drbd-dev@lists.linbit.com
 W:	http://www.drbd.org
 T:	git git://git.linbit.com/linux-drbd.git
 T:	git git://git.linbit.com/drbd-8.4.git
 S:	Supported
 F:	drivers/block/drbd/
 F:	lib/lru_cache.c
 F:	Documentation/blockdev/drbd/
 
 DRIVER CORE, KOBJECTS, DEBUGFS, KERNFS AND SYSFS
 M:	Greg Kroah-Hartman <gregkh@linuxfoundation.org>
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/driver-core.git
 S:	Supported
 F:	Documentation/kobject.txt
 F:	drivers/base/
 F:	fs/debugfs/
 F:	fs/kernfs/
 F:	fs/sysfs/
 F:	include/linux/debugfs.h
 F:	include/linux/kobj*
 F:	lib/kobj*
 
 DRM DRIVERS
 M:	David Airlie <airlied@linux.ie>
 L:	dri-devel@lists.freedesktop.org
 T:	git git://people.freedesktop.org/~airlied/linux
 B:	https://bugs.freedesktop.org/
 C:	irc://chat.freenode.net/dri-devel
 S:	Maintained
 F:	drivers/gpu/drm/
 F:	drivers/gpu/vga/
 F:	Documentation/devicetree/bindings/display/
 F:	Documentation/devicetree/bindings/gpu/
 F:	Documentation/devicetree/bindings/video/
 F:	Documentation/gpu/
 F:	include/drm/
 F:	include/uapi/drm/
 
 DRM DRIVERS AND MISC GPU PATCHES
 M:	Daniel Vetter <daniel.vetter@intel.com>
 M:	Jani Nikula <jani.nikula@linux.intel.com>
 M:	Sean Paul <seanpaul@chromium.org>
 W:	https://01.org/linuxgraphics/gfx-docs/maintainer-tools/drm-misc.html
 S:	Maintained
 T:	git git://anongit.freedesktop.org/drm/drm-misc
 F:	Documentation/gpu/
 F:	drivers/gpu/vga/
 F:	drivers/gpu/drm/*
 F:	include/drm/drm*
 F:	include/uapi/drm/drm*
 
 DRM DRIVER FOR AST SERVER GRAPHICS CHIPS
 M:	Dave Airlie <airlied@redhat.com>
 S:	Odd Fixes
 F:	drivers/gpu/drm/ast/
 
 DRM DRIVERS FOR BRIDGE CHIPS
 M:	Archit Taneja <architt@codeaurora.org>
 S:	Maintained
 T:	git git://anongit.freedesktop.org/drm/drm-misc
 F:	drivers/gpu/drm/bridge/
 
 DRM DRIVER FOR BOCHS VIRTUAL GPU
 M:	Gerd Hoffmann <kraxel@redhat.com>
 L:	virtualization@lists.linux-foundation.org
 T:	git git://git.kraxel.org/linux drm-qemu
 S:	Maintained
 F:	drivers/gpu/drm/bochs/
 
 DRM DRIVER FOR QEMU'S CIRRUS DEVICE
 M:	Dave Airlie <airlied@redhat.com>
 M:	Gerd Hoffmann <kraxel@redhat.com>
 L:	virtualization@lists.linux-foundation.org
 T:	git git://git.kraxel.org/linux drm-qemu
 S:	Obsolete
 W:	https://www.kraxel.org/blog/2014/10/qemu-using-cirrus-considered-harmful/
 F:	drivers/gpu/drm/cirrus/
 
 RADEON and AMDGPU DRM DRIVERS
 M:	Alex Deucher <alexander.deucher@amd.com>
 M:	Christian KÃ¶nig <christian.koenig@amd.com>
 L:	amd-gfx@lists.freedesktop.org
 T:	git git://people.freedesktop.org/~agd5f/linux
 S:	Supported
 F:	drivers/gpu/drm/radeon/
 F:	include/uapi/drm/radeon_drm.h
 F:	drivers/gpu/drm/amd/
 F:	include/uapi/drm/amdgpu_drm.h
 
 DRM PANEL DRIVERS
 M:	Thierry Reding <thierry.reding@gmail.com>
 L:	dri-devel@lists.freedesktop.org
 T:	git git://anongit.freedesktop.org/tegra/linux.git
 S:	Maintained
 F:	drivers/gpu/drm/drm_panel.c
 F:	drivers/gpu/drm/panel/
 F:	include/drm/drm_panel.h
 F:	Documentation/devicetree/bindings/display/panel/
 
 INTEL DRM DRIVERS (excluding Poulsbo, Moorestown and derivative chipsets)
 M:	Daniel Vetter <daniel.vetter@intel.com>
 M:	Jani Nikula <jani.nikula@linux.intel.com>
 L:	intel-gfx@lists.freedesktop.org
 W:	https://01.org/linuxgraphics/
 B:	https://01.org/linuxgraphics/documentation/how-report-bugs
 C:	irc://chat.freenode.net/intel-gfx
 Q:	http://patchwork.freedesktop.org/project/intel-gfx/
 T:	git git://anongit.freedesktop.org/drm-intel
 S:	Supported
 F:	drivers/gpu/drm/i915/
 F:	include/drm/i915*
 F:	include/uapi/drm/i915_drm.h
 F:	Documentation/gpu/i915.rst
 
 INTEL GVT-g DRIVERS (Intel GPU Virtualization)
 M:      Zhenyu Wang <zhenyuw@linux.intel.com>
 M:      Zhi Wang <zhi.a.wang@intel.com>
 L:      intel-gvt-dev@lists.freedesktop.org
 L:      intel-gfx@lists.freedesktop.org
 W:      https://01.org/igvt-g
 T:      git https://github.com/01org/gvt-linux.git
 S:      Supported
 F:      drivers/gpu/drm/i915/gvt/
 
 DRM DRIVERS FOR ATMEL HLCDC
 M:	Boris Brezillon <boris.brezillon@free-electrons.com>
 L:	dri-devel@lists.freedesktop.org
 S:	Supported
 F:	drivers/gpu/drm/atmel-hlcdc/
 F:	Documentation/devicetree/bindings/drm/atmel/
 
 DRM DRIVERS FOR ALLWINNER A10
 M:	Maxime Ripard  <maxime.ripard@free-electrons.com>
 L:	dri-devel@lists.freedesktop.org
 S:	Supported
 F:	drivers/gpu/drm/sun4i/
 F:	Documentation/devicetree/bindings/display/sunxi/sun4i-drm.txt
 
 DRM DRIVERS FOR AMLOGIC SOCS
 M:	Neil Armstrong <narmstrong@baylibre.com>
 L:	dri-devel@lists.freedesktop.org
 L:	linux-amlogic@lists.infradead.org
 W:	http://linux-meson.com/
 S:	Supported
 F:	drivers/gpu/drm/meson/
 F:	Documentation/devicetree/bindings/display/amlogic,meson-vpu.txt
 
 DRM DRIVERS FOR EXYNOS
 M:	Inki Dae <inki.dae@samsung.com>
 M:	Joonyoung Shim <jy0922.shim@samsung.com>
 M:	Seung-Woo Kim <sw0312.kim@samsung.com>
 M:	Kyungmin Park <kyungmin.park@samsung.com>
 L:	dri-devel@lists.freedesktop.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/daeinki/drm-exynos.git
 S:	Supported
 F:	drivers/gpu/drm/exynos/
 F:	include/uapi/drm/exynos_drm.h
 F:	Documentation/devicetree/bindings/display/exynos/
 
 DRM DRIVERS FOR FREESCALE DCU
 M:	Stefan Agner <stefan@agner.ch>
 M:	Alison Wang <alison.wang@freescale.com>
 L:	dri-devel@lists.freedesktop.org
 S:	Supported
 F:	drivers/gpu/drm/fsl-dcu/
 F:	Documentation/devicetree/bindings/display/fsl,dcu.txt
 F:	Documentation/devicetree/bindings/display/fsl,tcon.txt
 F:	Documentation/devicetree/bindings/display/panel/nec,nl4827hc19_05b.txt
 
 DRM DRIVERS FOR FREESCALE IMX
 M:	Philipp Zabel <p.zabel@pengutronix.de>
 L:	dri-devel@lists.freedesktop.org
 S:	Maintained
 F:	drivers/gpu/drm/imx/
 F:	drivers/gpu/ipu-v3/
 F:	Documentation/devicetree/bindings/display/imx/
 
 DRM DRIVERS FOR GMA500 (Poulsbo, Moorestown and derivative chipsets)
 M:	Patrik Jakobsson <patrik.r.jakobsson@gmail.com>
 L:	dri-devel@lists.freedesktop.org
 T:	git git://github.com/patjak/drm-gma500
 S:	Maintained
 F:	drivers/gpu/drm/gma500/
 
 DRM DRIVERS FOR HISILICON
 M:	Xinliang Liu <z.liuxinliang@hisilicon.com>
 M:	Rongrong Zou <zourongrong@gmail.com>
 R:	Xinwei Kong <kong.kongxinwei@hisilicon.com>
 R:	Chen Feng <puck.chen@hisilicon.com>
 L:	dri-devel@lists.freedesktop.org
 T:	git git://github.com/xin3liang/linux.git
 S:	Maintained
 F:	drivers/gpu/drm/hisilicon/
 F:	Documentation/devicetree/bindings/display/hisilicon/
 
 DRM DRIVER FOR INTEL I810 VIDEO CARDS
 S:	Orphan / Obsolete
 F:	drivers/gpu/drm/i810/
 F:	include/uapi/drm/i810_drm.h
 
 DRM DRIVERS FOR MEDIATEK
 M:	CK Hu <ck.hu@mediatek.com>
 M:	Philipp Zabel <p.zabel@pengutronix.de>
 L:	dri-devel@lists.freedesktop.org
 S:	Supported
 F:	drivers/gpu/drm/mediatek/
 F:	Documentation/devicetree/bindings/display/mediatek/
 
 DRM DRIVER FOR MSM ADRENO GPU
 M:	Rob Clark <robdclark@gmail.com>
 L:	linux-arm-msm@vger.kernel.org
 L:	dri-devel@lists.freedesktop.org
 L:	freedreno@lists.freedesktop.org
 T:	git git://people.freedesktop.org/~robclark/linux
 S:	Maintained
 F:	drivers/gpu/drm/msm/
 F:	include/uapi/drm/msm_drm.h
 F:	Documentation/devicetree/bindings/display/msm/
 
 DRM DRIVER FOR NVIDIA GEFORCE/QUADRO GPUS
 M:	Ben Skeggs <bskeggs@redhat.com>
 L:	dri-devel@lists.freedesktop.org
 L:	nouveau@lists.freedesktop.org
 T:	git git://github.com/skeggsb/linux
 S:	Supported
 F:	drivers/gpu/drm/nouveau/
 F:	include/uapi/drm/nouveau_drm.h
 
 DRM DRIVERS FOR NVIDIA TEGRA
 M:	Thierry Reding <thierry.reding@gmail.com>
 L:	dri-devel@lists.freedesktop.org
 L:	linux-tegra@vger.kernel.org
 T:	git git://anongit.freedesktop.org/tegra/linux.git
 S:	Supported
 F:	drivers/gpu/drm/tegra/
 F:	drivers/gpu/host1x/
 F:	include/linux/host1x.h
 F:	include/uapi/drm/tegra_drm.h
 F:	Documentation/devicetree/bindings/display/tegra/nvidia,tegra20-host1x.txt
 
 DRM DRIVER FOR MATROX G200/G400 GRAPHICS CARDS
 S:	Orphan / Obsolete
 F:	drivers/gpu/drm/mga/
 F:	include/uapi/drm/mga_drm.h
 
 DRM DRIVER FOR MGA G200 SERVER GRAPHICS CHIPS
 M:	Dave Airlie <airlied@redhat.com>
 S:	Odd Fixes
 F:	drivers/gpu/drm/mgag200/
 
 DRM DRIVER FOR RAGE 128 VIDEO CARDS
 S:	Orphan / Obsolete
 F:	drivers/gpu/drm/r128/
 F:	include/uapi/drm/r128_drm.h
 
 DRM DRIVERS FOR RENESAS
 M:	Laurent Pinchart <laurent.pinchart@ideasonboard.com>
 L:	dri-devel@lists.freedesktop.org
 L:	linux-renesas-soc@vger.kernel.org
 T:	git git://linuxtv.org/pinchartl/fbdev
 S:	Supported
 F:	drivers/gpu/drm/rcar-du/
 F:	drivers/gpu/drm/shmobile/
 F:	include/linux/platform_data/shmob_drm.h
 F:	Documentation/devicetree/bindings/display/renesas,du.txt
 
 DRM DRIVER FOR QXL VIRTUAL GPU
 M:	Dave Airlie <airlied@redhat.com>
 M:	Gerd Hoffmann <kraxel@redhat.com>
 L:	virtualization@lists.linux-foundation.org
 T:	git git://git.kraxel.org/linux drm-qemu
 S:	Maintained
 F:	drivers/gpu/drm/qxl/
 F:	include/uapi/drm/qxl_drm.h
 
 DRM DRIVERS FOR ROCKCHIP
 M:	Mark Yao <mark.yao@rock-chips.com>
 L:	dri-devel@lists.freedesktop.org
 S:	Maintained
 F:	drivers/gpu/drm/rockchip/
 F:	Documentation/devicetree/bindings/display/rockchip/
 
 DRM DRIVER FOR SAVAGE VIDEO CARDS
 S:	Orphan / Obsolete
 F:	drivers/gpu/drm/savage/
 F:	include/uapi/drm/savage_drm.h
 
 DRM DRIVER FOR SIS VIDEO CARDS
 S:	Orphan / Obsolete
 F:	drivers/gpu/drm/sis/
 F:	include/uapi/drm/sis_drm.h
 
 DRM DRIVERS FOR STI
 M:	Benjamin Gaignard <benjamin.gaignard@linaro.org>
 M:	Vincent Abriou <vincent.abriou@st.com>
 L:	dri-devel@lists.freedesktop.org
 T:	git http://git.linaro.org/people/benjamin.gaignard/kernel.git
 S:	Maintained
 F:	drivers/gpu/drm/sti
 F:	Documentation/devicetree/bindings/display/st,stih4xx.txt
 
 DRM DRIVER FOR TDFX VIDEO CARDS
 S:	Orphan / Obsolete
 F:	drivers/gpu/drm/tdfx/
 
 DRM DRIVER FOR USB DISPLAYLINK VIDEO ADAPTERS
 M:	Dave Airlie <airlied@redhat.com>
 S:	Odd Fixes
 F:	drivers/gpu/drm/udl/
 
 DRM DRIVERS FOR VIVANTE GPU IP
 M:	Lucas Stach <l.stach@pengutronix.de>
 R:	Russell King <linux+etnaviv@armlinux.org.uk>
 R:	Christian Gmeiner <christian.gmeiner@gmail.com>
 L:	etnaviv@lists.freedesktop.org
 L:	dri-devel@lists.freedesktop.org
 S:	Maintained
 F:	drivers/gpu/drm/etnaviv/
 F:	include/uapi/drm/etnaviv_drm.h
 F:	Documentation/devicetree/bindings/display/etnaviv/
 
 DRM DRIVER FOR VMWARE VIRTUAL GPU
 M:	"VMware Graphics" <linux-graphics-maintainer@vmware.com>
 M:	Sinclair Yeh <syeh@vmware.com>
 M:	Thomas Hellstrom <thellstrom@vmware.com>
 L:	dri-devel@lists.freedesktop.org
 T:	git git://people.freedesktop.org/~syeh/repos_linux
 T:	git git://people.freedesktop.org/~thomash/linux
 S:	Supported
 F:	drivers/gpu/drm/vmwgfx/
 F:	include/uapi/drm/vmwgfx_drm.h
 
 DRM DRIVERS FOR VC4
 M:	Eric Anholt <eric@anholt.net>
 T:	git git://github.com/anholt/linux
 S:	Supported
 F:	drivers/gpu/drm/vc4/
 F:	include/uapi/drm/vc4_drm.h
 F:	Documentation/devicetree/bindings/display/brcm,bcm-vc4.txt
 
 DRM DRIVERS FOR TI OMAP
 M:	Tomi Valkeinen <tomi.valkeinen@ti.com>
 L:	dri-devel@lists.freedesktop.org
 S:	Maintained
 F:	drivers/gpu/drm/omapdrm/
 F:	Documentation/devicetree/bindings/display/ti/
 
 DRM DRIVERS FOR TI LCDC
 M:	Jyri Sarha <jsarha@ti.com>
 R:	Tomi Valkeinen <tomi.valkeinen@ti.com>
 L:	dri-devel@lists.freedesktop.org
 S:	Maintained
 F:	drivers/gpu/drm/tilcdc/
 F:	Documentation/devicetree/bindings/display/tilcdc/
 
 DRM DRIVERS FOR ZTE ZX
 M:	Shawn Guo <shawnguo@kernel.org>
 L:	dri-devel@lists.freedesktop.org
 S:	Maintained
 F:	drivers/gpu/drm/zte/
 F:	Documentation/devicetree/bindings/display/zte,vou.txt
 
 DSBR100 USB FM RADIO DRIVER
 M:	Alexey Klimov <klimov.linux@gmail.com>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Maintained
 F:	drivers/media/radio/dsbr100.c
 
 DSCC4 DRIVER
 M:	Francois Romieu <romieu@fr.zoreil.com>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/wan/dscc4.c
 
 DT3155 MEDIA DRIVER
 M:	Hans Verkuil <hverkuil@xs4all.nl>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 W:	https://linuxtv.org
 S:	Odd Fixes
 F:	drivers/media/pci/dt3155/
 
 DVB_USB_AF9015 MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://palosaari.fi/linux/
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/anttip/media_tree.git
 S:	Maintained
 F:	drivers/media/usb/dvb-usb-v2/af9015*
 
 DVB_USB_AF9035 MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://palosaari.fi/linux/
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/anttip/media_tree.git
 S:	Maintained
 F:	drivers/media/usb/dvb-usb-v2/af9035*
 
 DVB_USB_ANYSEE MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://palosaari.fi/linux/
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/anttip/media_tree.git
 S:	Maintained
 F:	drivers/media/usb/dvb-usb-v2/anysee*
 
 DVB_USB_AU6610 MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://palosaari.fi/linux/
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/anttip/media_tree.git
 S:	Maintained
 F:	drivers/media/usb/dvb-usb-v2/au6610*
 
 DVB_USB_CE6230 MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://palosaari.fi/linux/
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/anttip/media_tree.git
 S:	Maintained
 F:	drivers/media/usb/dvb-usb-v2/ce6230*
 
 DVB_USB_CXUSB MEDIA DRIVER
 M:	Michael Krufky <mkrufky@linuxtv.org>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://github.com/mkrufky
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/media_tree.git
 S:	Maintained
 F:	drivers/media/usb/dvb-usb/cxusb*
 
 DVB_USB_EC168 MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://palosaari.fi/linux/
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/anttip/media_tree.git
 S:	Maintained
 F:	drivers/media/usb/dvb-usb-v2/ec168*
 
 DVB_USB_GL861 MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/anttip/media_tree.git
 S:	Maintained
 F:	drivers/media/usb/dvb-usb-v2/gl861*
 
 DVB_USB_MXL111SF MEDIA DRIVER
 M:	Michael Krufky <mkrufky@linuxtv.org>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://github.com/mkrufky
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/mkrufky/mxl111sf.git
 S:	Maintained
 F:	drivers/media/usb/dvb-usb-v2/mxl111sf*
 
 DVB_USB_RTL28XXU MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://palosaari.fi/linux/
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/anttip/media_tree.git
 S:	Maintained
 F:	drivers/media/usb/dvb-usb-v2/rtl28xxu*
 
 DVB_USB_V2 MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://palosaari.fi/linux/
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/anttip/media_tree.git
 S:	Maintained
 F:	drivers/media/usb/dvb-usb-v2/dvb_usb*
 F:	drivers/media/usb/dvb-usb-v2/usb_urb.c
 
 DYNAMIC DEBUG
 M:	Jason Baron <jbaron@akamai.com>
 S:	Maintained
 F:	lib/dynamic_debug.c
 F:	include/linux/dynamic_debug.h
 
 DZ DECSTATION DZ11 SERIAL DRIVER
 M:	"Maciej W. Rozycki" <macro@linux-mips.org>
 S:	Maintained
 F:	drivers/tty/serial/dz.*
 
 E3X0 POWER BUTTON DRIVER
 M:	Moritz Fischer <moritz.fischer@ettus.com>
 L:	usrp-users@lists.ettus.com
 W:	http://www.ettus.com
 S:	Supported
 F:	drivers/input/misc/e3x0-button.c
 F:	Documentation/devicetree/bindings/input/e3x0-button.txt
 
 E4000 MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://palosaari.fi/linux/
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/anttip/media_tree.git
 S:	Maintained
 F:	drivers/media/tuners/e4000*
 
 EATA ISA/EISA/PCI SCSI DRIVER
 M:	Dario Ballabio <ballabio_dario@emc.com>
 L:	linux-scsi@vger.kernel.org
 S:	Maintained
 F:	drivers/scsi/eata.c
 
 EC100 MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://palosaari.fi/linux/
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/anttip/media_tree.git
 S:	Maintained
 F:	drivers/media/dvb-frontends/ec100*
 
 ECRYPT FILE SYSTEM
 M:	Tyler Hicks <tyhicks@canonical.com>
 L:	ecryptfs@vger.kernel.org
 W:	http://ecryptfs.org
 W:	https://launchpad.net/ecryptfs
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/tyhicks/ecryptfs.git
 S:	Supported
 F:	Documentation/filesystems/ecryptfs.txt
 F:	fs/ecryptfs/
 
 EDAC-CORE
 M:	Borislav Petkov <bp@alien8.de>
 M:	Mauro Carvalho Chehab <mchehab@s-opensource.com>
 M:	Mauro Carvalho Chehab <mchehab@kernel.org>
 L:	linux-edac@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/bp/bp.git for-next
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/mchehab/linux-edac.git linux_next
 S:	Supported
 F:	Documentation/admin-guide/ras.rst
 F:	Documentation/driver-api/edac.rst
 F:	drivers/edac/
 F:	include/linux/edac.h
 
 EDAC-AMD64
 M:	Borislav Petkov <bp@alien8.de>
 L:	linux-edac@vger.kernel.org
 S:	Maintained
 F:	drivers/edac/amd64_edac*
 
 EDAC-CALXEDA
 M:	Robert Richter <rric@kernel.org>
 L:	linux-edac@vger.kernel.org
 S:	Maintained
 F:	drivers/edac/highbank*
 
 EDAC-CAVIUM
 M:	Ralf Baechle <ralf@linux-mips.org>
 M:	David Daney <david.daney@cavium.com>
 L:	linux-edac@vger.kernel.org
 L:	linux-mips@linux-mips.org
 S:	Supported
 F:	drivers/edac/octeon_edac*
 
 EDAC-E752X
 M:	Mark Gross <mark.gross@intel.com>
 L:	linux-edac@vger.kernel.org
 S:	Maintained
 F:	drivers/edac/e752x_edac.c
 
 EDAC-E7XXX
 L:	linux-edac@vger.kernel.org
 S:	Maintained
 F:	drivers/edac/e7xxx_edac.c
 
 EDAC-FSL_DDR
 M:	York Sun <york.sun@nxp.com>
 L:	linux-edac@vger.kernel.org
 S:	Maintained
 F:	drivers/edac/fsl_ddr_edac.*
 
 EDAC-GHES
 M:	Mauro Carvalho Chehab <mchehab@s-opensource.com>
 M:	Mauro Carvalho Chehab <mchehab@kernel.org>
 L:	linux-edac@vger.kernel.org
 S:	Maintained
 F:	drivers/edac/ghes_edac.c
 
 EDAC-I82443BXGX
 M:	Tim Small <tim@buttersideup.com>
 L:	linux-edac@vger.kernel.org
 S:	Maintained
 F:	drivers/edac/i82443bxgx_edac.c
 
 EDAC-I3000
 L:	linux-edac@vger.kernel.org
 S:	Orphan
 F:	drivers/edac/i3000_edac.c
 
 EDAC-I5000
 L:	linux-edac@vger.kernel.org
 S:	Maintained
 F:	drivers/edac/i5000_edac.c
 
 EDAC-I5400
 M:	Mauro Carvalho Chehab <mchehab@s-opensource.com>
 M:	Mauro Carvalho Chehab <mchehab@kernel.org>
 L:	linux-edac@vger.kernel.org
 S:	Maintained
 F:	drivers/edac/i5400_edac.c
 
 EDAC-I7300
 M:	Mauro Carvalho Chehab <mchehab@s-opensource.com>
 M:	Mauro Carvalho Chehab <mchehab@kernel.org>
 L:	linux-edac@vger.kernel.org
 S:	Maintained
 F:	drivers/edac/i7300_edac.c
 
 EDAC-I7CORE
 M:	Mauro Carvalho Chehab <mchehab@s-opensource.com>
 M:	Mauro Carvalho Chehab <mchehab@kernel.org>
 L:	linux-edac@vger.kernel.org
 S:	Maintained
 F:	drivers/edac/i7core_edac.c
 
 EDAC-I82975X
 M:	Ranganathan Desikan <ravi@jetztechnologies.com>
 M:	"Arvind R." <arvino55@gmail.com>
 L:	linux-edac@vger.kernel.org
 S:	Maintained
 F:	drivers/edac/i82975x_edac.c
 
 EDAC-IE31200
 M:	Jason Baron <jbaron@akamai.com>
 L:	linux-edac@vger.kernel.org
 S:	Maintained
 F:	drivers/edac/ie31200_edac.c
 
 EDAC-MPC85XX
 M:	Johannes Thumshirn <morbidrsa@gmail.com>
 L:	linux-edac@vger.kernel.org
 S:	Maintained
 F:	drivers/edac/mpc85xx_edac.[ch]
 
 EDAC-PASEMI
 M:	Egor Martovetsky <egor@pasemi.com>
 L:	linux-edac@vger.kernel.org
 S:	Maintained
 F:	drivers/edac/pasemi_edac.c
 
 EDAC-R82600
 M:	Tim Small <tim@buttersideup.com>
 L:	linux-edac@vger.kernel.org
 S:	Maintained
 F:	drivers/edac/r82600_edac.c
 
 EDAC-SBRIDGE
 M:	Mauro Carvalho Chehab <mchehab@s-opensource.com>
 M:	Mauro Carvalho Chehab <mchehab@kernel.org>
 L:	linux-edac@vger.kernel.org
 S:	Maintained
 F:	drivers/edac/sb_edac.c
 
 EDAC-SKYLAKE
 M:	Tony Luck <tony.luck@intel.com>
 L:	linux-edac@vger.kernel.org
 S:	Maintained
 F:	drivers/edac/skx_edac.c
 
 EDAC-XGENE
 APPLIED MICRO (APM) X-GENE SOC EDAC
 M:     Loc Ho <lho@apm.com>
 S:     Supported
 F:     drivers/edac/xgene_edac.c
 F:     Documentation/devicetree/bindings/edac/apm-xgene-edac.txt
 
 EDIROL UA-101/UA-1000 DRIVER
 M:	Clemens Ladisch <clemens@ladisch.de>
 L:	alsa-devel@alsa-project.org (moderated for non-subscribers)
 T:	git git://git.alsa-project.org/alsa-kernel.git
 S:	Maintained
 F:	sound/usb/misc/ua101.c
 
 EXTENSIBLE FIRMWARE INTERFACE (EFI)
 M:	Matt Fleming <matt@codeblueprint.co.uk>
 M:	Ard Biesheuvel <ard.biesheuvel@linaro.org>
 L:	linux-efi@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/efi/efi.git
 S:	Maintained
 F:	Documentation/efi-stub.txt
 F:	arch/*/kernel/efi.c
 F:	arch/x86/boot/compressed/eboot.[ch]
 F:	arch/*/include/asm/efi.h
 F:	arch/x86/platform/efi/
 F:	drivers/firmware/efi/
 F:	include/linux/efi*.h
 F:	arch/arm/boot/compressed/efi-header.S
 F:	arch/arm64/kernel/efi-entry.S
 
 EFI VARIABLE FILESYSTEM
 M:	Matthew Garrett <matthew.garrett@nebula.com>
 M:	Jeremy Kerr <jk@ozlabs.org>
 M:	Matt Fleming <matt@codeblueprint.co.uk>
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/mfleming/efi.git
 L:	linux-efi@vger.kernel.org
 S:	Maintained
 F:	fs/efivarfs/
 
 EFIFB FRAMEBUFFER DRIVER
 L:	linux-fbdev@vger.kernel.org
 M:	Peter Jones <pjones@redhat.com>
 S:	Maintained
 F:	drivers/video/fbdev/efifb.c
 
 EFI TEST DRIVER
 L:	linux-efi@vger.kernel.org
 M:	Ivan Hu <ivan.hu@canonical.com>
 M:	Matt Fleming <matt@codeblueprint.co.uk>
 S:	Maintained
 F:	drivers/firmware/efi/test/
 
 EFS FILESYSTEM
 W:	http://aeschi.ch.eu.org/efs/
 S:	Orphan
 F:	fs/efs/
 
 EHEA (IBM pSeries eHEA 10Gb ethernet adapter) DRIVER
 M:	Douglas Miller <dougmill@linux.vnet.ibm.com>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/ethernet/ibm/ehea/
 
 EM28XX VIDEO4LINUX DRIVER
 M:	Mauro Carvalho Chehab <mchehab@s-opensource.com>
 M:	Mauro Carvalho Chehab <mchehab@kernel.org>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Maintained
 F:	drivers/media/usb/em28xx/
 F:	Documentation/media/v4l-drivers/em28xx*
 
 EMBEDDED LINUX
 M:	Paul Gortmaker <paul.gortmaker@windriver.com>
 M:	Matt Mackall <mpm@selenic.com>
 M:	David Woodhouse <dwmw2@infradead.org>
 L:	linux-embedded@vger.kernel.org
 S:	Maintained
 
 EMULEX/BROADCOM LPFC FC/FCOE SCSI DRIVER
 M:	James Smart <james.smart@broadcom.com>
 M:	Dick Kennedy <dick.kennedy@broadcom.com>
 L:	linux-scsi@vger.kernel.org
 W:	http://www.broadcom.com
 S:	Supported
 F:	drivers/scsi/lpfc/
 
 ENE CB710 FLASH CARD READER DRIVER
 M:	MichaÅ MirosÅaw <mirq-linux@rere.qmqm.pl>
 S:	Maintained
 F:	drivers/misc/cb710/
 F:	drivers/mmc/host/cb710-mmc.*
 F:	include/linux/cb710.h
 
 ENE KB2426 (ENE0100/ENE020XX) INFRARED RECEIVER
 M:	Maxim Levitsky <maximlevitsky@gmail.com>
 S:	Maintained
 F:	drivers/media/rc/ene_ir.*
 
 EPSON S1D13XXX FRAMEBUFFER DRIVER
 M:	Kristoffer Ericson <kristoffer.ericson@gmail.com>
 S:	Maintained
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/kristoffer/linux-hpc.git
 F:	drivers/video/fbdev/s1d13xxxfb.c
 F:	include/video/s1d13xxxfb.h
 
 ET131X NETWORK DRIVER
 M:	Mark Einon <mark.einon@gmail.com>
 S:	Odd Fixes
 F:	drivers/net/ethernet/agere/
 
 ETHERNET BRIDGE
 M:	Stephen Hemminger <stephen@networkplumber.org>
 L:	bridge@lists.linux-foundation.org (moderated for non-subscribers)
 L:	netdev@vger.kernel.org
 W:	http://www.linuxfoundation.org/en/Net:Bridge
 S:	Maintained
 F:	include/linux/netfilter_bridge/
 F:	net/bridge/
 
 ETHERNET PHY LIBRARY
 M:	Florian Fainelli <f.fainelli@gmail.com>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	include/linux/phy.h
 F:	include/linux/phy_fixed.h
 F:	drivers/net/phy/
 F:	Documentation/networking/phy.txt
 F:	drivers/of/of_mdio.c
 F:	drivers/of/of_net.c
 
 EXT2 FILE SYSTEM
 M:	Jan Kara <jack@suse.com>
 L:	linux-ext4@vger.kernel.org
 S:	Maintained
 F:	Documentation/filesystems/ext2.txt
 F:	fs/ext2/
 F:	include/linux/ext2*
 
 EXT4 FILE SYSTEM
 M:	"Theodore Ts'o" <tytso@mit.edu>
 M:	Andreas Dilger <adilger.kernel@dilger.ca>
 L:	linux-ext4@vger.kernel.org
 W:	http://ext4.wiki.kernel.org
 Q:	http://patchwork.ozlabs.org/project/linux-ext4/list/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/tytso/ext4.git
 S:	Maintained
 F:	Documentation/filesystems/ext4.txt
 F:	fs/ext4/
 
 Extended Verification Module (EVM)
 M:	Mimi Zohar <zohar@linux.vnet.ibm.com>
 L:	linux-ima-devel@lists.sourceforge.net
 L:	linux-security-module@vger.kernel.org
 S:	Supported
 F:	security/integrity/evm/
 
 EXTERNAL CONNECTOR SUBSYSTEM (EXTCON)
 M:	MyungJoo Ham <myungjoo.ham@samsung.com>
 M:	Chanwoo Choi <cw00.choi@samsung.com>
 L:	linux-kernel@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/chanwoo/extcon.git
 S:	Maintained
 F:	drivers/extcon/
 F:	include/linux/extcon/
 F:	include/linux/extcon.h
 F:	Documentation/extcon/
 F:	Documentation/devicetree/bindings/extcon/
 
 EXYNOS DP DRIVER
 M:	Jingoo Han <jingoohan1@gmail.com>
 L:	dri-devel@lists.freedesktop.org
 S:	Maintained
 F:	drivers/gpu/drm/exynos/exynos_dp*
 
 EXYNOS SYSMMU (IOMMU) driver
 M:	Marek Szyprowski <m.szyprowski@samsung.com>
 L:	iommu@lists.linux-foundation.org
 S:	Maintained
 F:	drivers/iommu/exynos-iommu.c
 
 EZchip NPS platform support
 M:	Noam Camus <noamc@ezchip.com>
 S:	Supported
 F:	arch/arc/plat-eznps
 F:	arch/arc/boot/dts/eznps.dts
 
 F71805F HARDWARE MONITORING DRIVER
 M:	Jean Delvare <jdelvare@suse.com>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	Documentation/hwmon/f71805f
 F:	drivers/hwmon/f71805f.c
 
 FC0011 TUNER DRIVER
 M:	Michael Buesch <m@bues.ch>
 L:	linux-media@vger.kernel.org
 S:	Maintained
 F:	drivers/media/tuners/fc0011.h
 F:	drivers/media/tuners/fc0011.c
 
 FC2580 MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://palosaari.fi/linux/
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/anttip/media_tree.git
 S:	Maintained
 F:	drivers/media/tuners/fc2580*
 
 FANOTIFY
 M:	Eric Paris <eparis@redhat.com>
 S:	Maintained
 F:	fs/notify/fanotify/
 F:	include/linux/fanotify.h
 F:	include/uapi/linux/fanotify.h
 
 FARSYNC SYNCHRONOUS DRIVER
 M:	Kevin Curtis <kevin.curtis@farsite.co.uk>
 W:	http://www.farsite.co.uk/
 S:	Supported
 F:	drivers/net/wan/farsync.*
 
 FAULT INJECTION SUPPORT
 M:	Akinobu Mita <akinobu.mita@gmail.com>
 S:	Supported
 F:	Documentation/fault-injection/
 F:	lib/fault-inject.c
 
 FBTFT Framebuffer drivers
 M:	Thomas Petazzoni <thomas.petazzoni@free-electrons.com>
 M:	Noralf TrÃ¸nnes <noralf@tronnes.org>
 S:	Maintained
 F:	drivers/staging/fbtft/
 
 FCOE SUBSYSTEM (libfc, libfcoe, fcoe)
 M:	Johannes Thumshirn <jth@kernel.org>
 L:	fcoe-devel@open-fcoe.org
 W:	www.Open-FCoE.org
 S:	Supported
 F:	drivers/scsi/libfc/
 F:	drivers/scsi/fcoe/
 F:	include/scsi/fc/
 F:	include/scsi/libfc.h
 F:	include/scsi/libfcoe.h
 F:	include/uapi/scsi/fc/
 
 FILE LOCKING (flock() and fcntl()/lockf())
 M:	Jeff Layton <jlayton@poochiereds.net>
 M:	"J. Bruce Fields" <bfields@fieldses.org>
 L:	linux-fsdevel@vger.kernel.org
 S:	Maintained
 F:	include/linux/fcntl.h
 F:	include/linux/fs.h
 F:	include/uapi/linux/fcntl.h
 F:	include/uapi/linux/fs.h
 F:	fs/fcntl.c
 F:	fs/locks.c
 
 FILESYSTEMS (VFS and infrastructure)
 M:	Alexander Viro <viro@zeniv.linux.org.uk>
 L:	linux-fsdevel@vger.kernel.org
 S:	Maintained
 F:	fs/*
 
 FINTEK F75375S HARDWARE MONITOR AND FAN CONTROLLER DRIVER
 M:	Riku Voipio <riku.voipio@iki.fi>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	drivers/hwmon/f75375s.c
 F:	include/linux/f75375s.h
 
 FIREWIRE AUDIO DRIVERS
 M:	Clemens Ladisch <clemens@ladisch.de>
 L:	alsa-devel@alsa-project.org (moderated for non-subscribers)
 T:	git git://git.alsa-project.org/alsa-kernel.git
 S:	Maintained
 F:	sound/firewire/
 
 FIREWIRE MEDIA DRIVERS (firedtv)
 M:	Stefan Richter <stefanr@s5r6.in-berlin.de>
 L:	linux-media@vger.kernel.org
 L:	linux1394-devel@lists.sourceforge.net
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/mchehab/linux-media.git
 S:	Maintained
 F:	drivers/media/firewire/
 
 FIREWIRE SBP-2 TARGET
 M:	Chris Boot <bootc@bootc.net>
 L:	linux-scsi@vger.kernel.org
 L:	target-devel@vger.kernel.org
 L:	linux1394-devel@lists.sourceforge.net
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/nab/lio-core-2.6.git master
 S:	Maintained
 F:	drivers/target/sbp/
 
 FIREWIRE SUBSYSTEM
 M:	Stefan Richter <stefanr@s5r6.in-berlin.de>
 L:	linux1394-devel@lists.sourceforge.net
 W:	http://ieee1394.wiki.kernel.org/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/ieee1394/linux1394.git
 S:	Maintained
 F:	drivers/firewire/
 F:	include/linux/firewire.h
 F:	include/uapi/linux/firewire*.h
 F:	tools/firewire/
 
 FIRMWARE LOADER (request_firmware)
 M:	Ming Lei <ming.lei@canonical.com>
 M:	Luis R. Rodriguez <mcgrof@kernel.org>
 L:	linux-kernel@vger.kernel.org
 S:	Maintained
 F:	Documentation/firmware_class/
 F:	drivers/base/firmware*.c
 F:	include/linux/firmware.h
 
 FLASH ADAPTER DRIVER (IBM Flash Adapter 900GB Full Height PCI Flash Card)
 M:	Joshua Morris <josh.h.morris@us.ibm.com>
 M:	Philip Kelleher <pjk1939@linux.vnet.ibm.com>
 S:	Maintained
 F:	drivers/block/rsxx/
 
 FLOPPY DRIVER
 M:	Jiri Kosina <jikos@kernel.org>
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/jikos/floppy.git
 S:	Odd fixes
 F:	drivers/block/floppy.c
 
 FMC SUBSYSTEM
 M:	Alessandro Rubini <rubini@gnudd.com>
 W:	http://www.ohwr.org/projects/fmc-bus
 S:	Supported
 F:	drivers/fmc/
 F:	include/linux/fmc*.h
 F:	include/linux/ipmi-fru.h
 K:	fmc_d.*register
 
 FPGA MANAGER FRAMEWORK
 M:	Alan Tull <atull@opensource.altera.com>
 R:	Moritz Fischer <moritz.fischer@ettus.com>
 L:	linux-fpga@vger.kernel.org
 S:	Maintained
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/atull/linux-fpga.git
 F:	drivers/fpga/
 F:	include/linux/fpga/fpga-mgr.h
 W:	http://www.rocketboards.org
 
 FPU EMULATOR
 M:	Bill Metzenthen <billm@melbpc.org.au>
 W:	http://floatingpoint.sourceforge.net/emulator/index.html
 S:	Maintained
 F:	arch/x86/math-emu/
 
 FRAME RELAY DLCI/FRAD (Sangoma drivers too)
 L:	netdev@vger.kernel.org
 S:	Orphan
 F:	drivers/net/wan/dlci.c
 F:	drivers/net/wan/sdla.c
 
 FRAMEBUFFER LAYER
 M:	Bartlomiej Zolnierkiewicz <b.zolnierkie@samsung.com>
 L:	linux-fbdev@vger.kernel.org
 T:	git git://github.com/bzolnier/linux.git
 Q:	http://patchwork.kernel.org/project/linux-fbdev/list/
 S:	Maintained
 F:	Documentation/fb/
 F:	drivers/video/
 F:	include/video/
 F:	include/linux/fb.h
 F:	include/uapi/video/
 F:	include/uapi/linux/fb.h
 
 FREESCALE CAAM (Cryptographic Acceleration and Assurance Module) DRIVER
 M:	Horia GeantÄ <horia.geanta@nxp.com>
 M:	Dan Douglass <dan.douglass@nxp.com>
 L:	linux-crypto@vger.kernel.org
 S:	Maintained
 F:	drivers/crypto/caam/
 F:	Documentation/devicetree/bindings/crypto/fsl-sec4.txt
 
 FREESCALE DIU FRAMEBUFFER DRIVER
 M:	Timur Tabi <timur@tabi.org>
 L:	linux-fbdev@vger.kernel.org
 S:	Maintained
 F:	drivers/video/fbdev/fsl-diu-fb.*
 
 FREESCALE DMA DRIVER
 M:	Li Yang <leoli@freescale.com>
 M:	Zhang Wei <zw@zh-kernel.org>
 L:	linuxppc-dev@lists.ozlabs.org
 S:	Maintained
 F:	drivers/dma/fsldma.*
 
 FREESCALE GPMI NAND DRIVER
 M:	Han Xu <han.xu@nxp.com>
 L:	linux-mtd@lists.infradead.org
 S:	Maintained
 F:	drivers/mtd/nand/gpmi-nand/*
 
 FREESCALE I2C CPM DRIVER
 M:	Jochen Friedrich <jochen@scram.de>
 L:	linuxppc-dev@lists.ozlabs.org
 L:	linux-i2c@vger.kernel.org
 S:	Maintained
 F:	drivers/i2c/busses/i2c-cpm.c
 
 FREESCALE IMX / MXC FRAMEBUFFER DRIVER
 M:	Sascha Hauer <kernel@pengutronix.de>
 L:	linux-fbdev@vger.kernel.org
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	include/linux/platform_data/video-imxfb.h
 F:	drivers/video/fbdev/imxfb.c
 
 FREESCALE QUAD SPI DRIVER
 M:	Han Xu <han.xu@nxp.com>
 L:	linux-mtd@lists.infradead.org
 S:	Maintained
 F:	drivers/mtd/spi-nor/fsl-quadspi.c
 
 FREESCALE SOC FS_ENET DRIVER
 M:	Pantelis Antoniou <pantelis.antoniou@gmail.com>
 M:	Vitaly Bordug <vbordug@ru.mvista.com>
 L:	linuxppc-dev@lists.ozlabs.org
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/ethernet/freescale/fs_enet/
 F:	include/linux/fs_enet_pd.h
 
 FREESCALE IMX / MXC FEC DRIVER
 M:	Fugang Duan <fugang.duan@nxp.com>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/ethernet/freescale/fec_main.c
 F:	drivers/net/ethernet/freescale/fec_ptp.c
 F:	drivers/net/ethernet/freescale/fec.h
 F:	Documentation/devicetree/bindings/net/fsl-fec.txt
 
 FREESCALE QORIQ DPAA FMAN DRIVER
 M:	Madalin Bucur <madalin.bucur@nxp.com>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/ethernet/freescale/fman
 F:	Documentation/devicetree/bindings/powerpc/fsl/fman.txt
 
 FREESCALE QORIQ DPAA ETHERNET DRIVER
 M:	Madalin Bucur <madalin.bucur@nxp.com>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/ethernet/freescale/dpaa
 
 FREESCALE SOC DRIVERS
 M:	Scott Wood <oss@buserror.net>
 L:	linuxppc-dev@lists.ozlabs.org
 L:	linux-arm-kernel@lists.infradead.org
 S:	Maintained
 F:	drivers/soc/fsl/
 F:	include/linux/fsl/
 
 FREESCALE QUICC ENGINE LIBRARY
 M:	Qiang Zhao <qiang.zhao@nxp.com>
 L:	linuxppc-dev@lists.ozlabs.org
 S:	Maintained
 F:	drivers/soc/fsl/qe/
 F:	include/soc/fsl/*qe*.h
 F:	include/soc/fsl/*ucc*.h
 
 FREESCALE USB PERIPHERAL DRIVERS
 M:	Li Yang <leoli@freescale.com>
 L:	linux-usb@vger.kernel.org
 L:	linuxppc-dev@lists.ozlabs.org
 S:	Maintained
 F:	drivers/usb/gadget/udc/fsl*
 
 FREESCALE QUICC ENGINE UCC ETHERNET DRIVER
 M:	Li Yang <leoli@freescale.com>
 L:	netdev@vger.kernel.org
 L:	linuxppc-dev@lists.ozlabs.org
 S:	Maintained
 F:	drivers/net/ethernet/freescale/ucc_geth*
 
 FREESCALE eTSEC ETHERNET DRIVER (GIANFAR)
 M:	Claudiu Manoil <claudiu.manoil@freescale.com>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/ethernet/freescale/gianfar*
 X:	drivers/net/ethernet/freescale/gianfar_ptp.c
 F:	Documentation/devicetree/bindings/net/fsl-tsec-phy.txt
 
 FREESCALE QUICC ENGINE UCC HDLC DRIVER
 M:	Zhao Qiang <qiang.zhao@nxp.com>
 L:	netdev@vger.kernel.org
 L:	linuxppc-dev@lists.ozlabs.org
 S:	Maintained
 F:	drivers/net/wan/fsl_ucc_hdlc*
 
 FREESCALE QUICC ENGINE UCC UART DRIVER
 M:	Timur Tabi <timur@tabi.org>
 L:	linuxppc-dev@lists.ozlabs.org
 S:	Maintained
 F:	drivers/tty/serial/ucc_uart.c
 
 FREESCALE SOC SOUND DRIVERS
 M:	Timur Tabi <timur@tabi.org>
 M:	Nicolin Chen <nicoleotsuka@gmail.com>
 M:	Xiubo Li <Xiubo.Lee@gmail.com>
 R:	Fabio Estevam <fabio.estevam@nxp.com>
 L:	alsa-devel@alsa-project.org (moderated for non-subscribers)
 L:	linuxppc-dev@lists.ozlabs.org
 S:	Maintained
 F:	sound/soc/fsl/fsl*
 F:	sound/soc/fsl/imx*
 F:	sound/soc/fsl/mpc8610_hpcd.c
 
 FREEVXFS FILESYSTEM
 M:	Christoph Hellwig <hch@infradead.org>
 W:	ftp://ftp.openlinux.org/pub/people/hch/vxfs
 S:	Maintained
 F:	fs/freevxfs/
 
 FREEZER
 M:	"Rafael J. Wysocki" <rjw@rjwysocki.net>
 M:	Pavel Machek <pavel@ucw.cz>
 L:	linux-pm@vger.kernel.org
 S:	Supported
 F:	Documentation/power/freezing-of-tasks.txt
 F:	include/linux/freezer.h
 F:	kernel/freezer.c
 
 FRONTSWAP API
 M:	Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
 L:	linux-kernel@vger.kernel.org
 S:	Maintained
 F:	mm/frontswap.c
 F:	include/linux/frontswap.h
 
 FS-CACHE: LOCAL CACHING FOR NETWORK FILESYSTEMS
 M:	David Howells <dhowells@redhat.com>
 L:	linux-cachefs@redhat.com (moderated for non-subscribers)
 S:	Supported
 F:	Documentation/filesystems/caching/
 F:	fs/fscache/
 F:	include/linux/fscache*.h
 
 FS-CRYPTO: FILE SYSTEM LEVEL ENCRYPTION SUPPORT
 M:	Theodore Y. Ts'o <tytso@mit.edu>
 M:	Jaegeuk Kim <jaegeuk@kernel.org>
 L:	linux-fsdevel@vger.kernel.org
 S:	Supported
 F:	fs/crypto/
 F:	include/linux/fscrypt*.h
 
 F2FS FILE SYSTEM
 M:	Jaegeuk Kim <jaegeuk@kernel.org>
 M:	Chao Yu <yuchao0@huawei.com>
 L:	linux-f2fs-devel@lists.sourceforge.net
 W:	https://f2fs.wiki.kernel.org/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/jaegeuk/f2fs.git
 S:	Maintained
 F:	Documentation/filesystems/f2fs.txt
 F:	Documentation/ABI/testing/sysfs-fs-f2fs
 F:	fs/f2fs/
 F:	include/linux/f2fs_fs.h
 F:	include/trace/events/f2fs.h
 
 FUJITSU FR-V (FRV) PORT
 S:	Orphan
 F:	arch/frv/
 
 FUJITSU LAPTOP EXTRAS
 M:	Jonathan Woithe <jwoithe@just42.net>
 L:	platform-driver-x86@vger.kernel.org
 S:	Maintained
 F:	drivers/platform/x86/fujitsu-laptop.c
 
 FUJITSU M-5MO LS CAMERA ISP DRIVER
 M:	Kyungmin Park <kyungmin.park@samsung.com>
 M:	Heungjun Kim <riverful.kim@samsung.com>
 L:	linux-media@vger.kernel.org
 S:	Maintained
 F:	drivers/media/i2c/m5mols/
 F:	include/media/i2c/m5mols.h
 
 FUJITSU TABLET EXTRAS
 M:	Robert Gerlach <khnz@gmx.de>
 L:	platform-driver-x86@vger.kernel.org
 S:	Maintained
 F:	drivers/platform/x86/fujitsu-tablet.c
 
 FUSE: FILESYSTEM IN USERSPACE
 M:	Miklos Szeredi <miklos@szeredi.hu>
 L:	linux-fsdevel@vger.kernel.org
 W:	http://fuse.sourceforge.net/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/mszeredi/fuse.git
 S:	Maintained
 F:	fs/fuse/
 F:	include/uapi/linux/fuse.h
 F:	Documentation/filesystems/fuse.txt
 
 FUTURE DOMAIN TMC-16x0 SCSI DRIVER (16-bit)
 M:	Rik Faith <faith@cs.unc.edu>
 L:	linux-scsi@vger.kernel.org
 S:	Odd Fixes (e.g., new signatures)
 F:	drivers/scsi/fdomain.*
 
 GCC PLUGINS
 M:	Kees Cook <keescook@chromium.org>
 R:	Emese Revfy <re.emese@gmail.com>
 L:	kernel-hardening@lists.openwall.com
 S:	Maintained
 F:	scripts/gcc-plugins/
 F:	scripts/gcc-plugin.sh
 F:	scripts/Makefile.gcc-plugins
 F:	Documentation/gcc-plugins.txt
 
 GCOV BASED KERNEL PROFILING
 M:	Peter Oberparleiter <oberpar@linux.vnet.ibm.com>
 S:	Maintained
 F:	kernel/gcov/
 F:	Documentation/dev-tools/gcov.rst
 
 GDT SCSI DISK ARRAY CONTROLLER DRIVER
 M:	Achim Leubner <achim_leubner@adaptec.com>
 L:	linux-scsi@vger.kernel.org
 W:	http://www.icp-vortex.com/
 S:	Supported
 F:	drivers/scsi/gdt*
 
 GDB KERNEL DEBUGGING HELPER SCRIPTS
 M:	Jan Kiszka <jan.kiszka@siemens.com>
 M:	Kieran Bingham <kieran@bingham.xyz>
 S:	Supported
 F:	scripts/gdb/
 
 GEMTEK FM RADIO RECEIVER DRIVER
 M:	Hans Verkuil <hverkuil@xs4all.nl>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 W:	https://linuxtv.org
 S:	Maintained
 F:	drivers/media/radio/radio-gemtek*
 
 GENERIC GPIO I2C DRIVER
 M:	Haavard Skinnemoen <hskinnemoen@gmail.com>
 S:	Supported
 F:	drivers/i2c/busses/i2c-gpio.c
 F:	include/linux/i2c-gpio.h
 
 GENERIC GPIO I2C MULTIPLEXER DRIVER
 M:	Peter Korsgaard <peter.korsgaard@barco.com>
 L:	linux-i2c@vger.kernel.org
 S:	Supported
 F:	drivers/i2c/muxes/i2c-mux-gpio.c
 F:	include/linux/i2c-mux-gpio.h
 F:	Documentation/i2c/muxes/i2c-mux-gpio
 
 GENERIC HDLC (WAN) DRIVERS
 M:	Krzysztof Halasa <khc@pm.waw.pl>
 W:	http://www.kernel.org/pub/linux/utils/net/hdlc/
 S:	Maintained
 F:	drivers/net/wan/c101.c
 F:	drivers/net/wan/hd6457*
 F:	drivers/net/wan/hdlc*
 F:	drivers/net/wan/n2.c
 F:	drivers/net/wan/pc300too.c
 F:	drivers/net/wan/pci200syn.c
 F:	drivers/net/wan/wanxl*
 
 GENERIC INCLUDE/ASM HEADER FILES
 M:	Arnd Bergmann <arnd@arndb.de>
 L:	linux-arch@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/arnd/asm-generic.git
 S:	Maintained
 F:	include/asm-generic/
 F:	include/uapi/asm-generic/
 
 GENERIC PHY FRAMEWORK
 M:	Kishon Vijay Abraham I <kishon@ti.com>
 L:	linux-kernel@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/kishon/linux-phy.git
 S:	Supported
 F:	drivers/phy/
 F:	include/linux/phy/
 
 GENERIC PM DOMAINS
 M:	"Rafael J. Wysocki" <rjw@rjwysocki.net>
 M:	Kevin Hilman <khilman@kernel.org>
 M:	Ulf Hansson <ulf.hansson@linaro.org>
 L:	linux-pm@vger.kernel.org
 S:	Supported
 F:	drivers/base/power/domain*.c
 F:	include/linux/pm_domain.h
 
 GENERIC UIO DRIVER FOR PCI DEVICES
 M:	"Michael S. Tsirkin" <mst@redhat.com>
 L:	kvm@vger.kernel.org
 S:	Supported
 F:	drivers/uio/uio_pci_generic.c
 
 GET_MAINTAINER SCRIPT
 M:	Joe Perches <joe@perches.com>
 S:	Maintained
 F:	scripts/get_maintainer.pl
 
 GENWQE (IBM Generic Workqueue Card)
 M:	Frank Haverkamp <haver@linux.vnet.ibm.com>
 M:	Gabriel Krisman Bertazi <krisman@linux.vnet.ibm.com>
 S:	Supported
 F:	drivers/misc/genwqe/
 
 GFS2 FILE SYSTEM
 M:	Steven Whitehouse <swhiteho@redhat.com>
 M:	Bob Peterson <rpeterso@redhat.com>
 L:	cluster-devel@redhat.com
 W:	http://sources.redhat.com/cluster/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/gfs2/linux-gfs2.git
 S:	Supported
 F:	Documentation/filesystems/gfs2*.txt
 F:	fs/gfs2/
 F:	include/uapi/linux/gfs2_ondisk.h
 
 GIGASET ISDN DRIVERS
 M:	Paul Bolle <pebolle@tiscali.nl>
 L:	gigaset307x-common@lists.sourceforge.net
 W:	http://gigaset307x.sourceforge.net/
 S:	Odd Fixes
 F:	Documentation/isdn/README.gigaset
 F:	drivers/isdn/gigaset/
 F:	include/uapi/linux/gigaset_dev.h
 
 GO7007 MPEG CODEC
 M:	Hans Verkuil <hans.verkuil@cisco.com>
 L:	linux-media@vger.kernel.org
 S:	Maintained
 F:	drivers/media/usb/go7007/
 
 GOODIX TOUCHSCREEN
 M:	Bastien Nocera <hadess@hadess.net>
 L:	linux-input@vger.kernel.org
 S:	Maintained
 F:	drivers/input/touchscreen/goodix.c
 
 GPIO MOCKUP DRIVER
 M:	Bamvor Jian Zhang <bamvor.zhangjian@linaro.org>
 L:	linux-gpio@vger.kernel.org
 S:	Maintained
 F:	drivers/gpio/gpio-mockup.c
 F:	tools/testing/selftests/gpio/
 
 GPIO SUBSYSTEM
 M:	Linus Walleij <linus.walleij@linaro.org>
 M:	Alexandre Courbot <gnurou@gmail.com>
 L:	linux-gpio@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/linusw/linux-gpio.git
 S:	Maintained
 F:	Documentation/devicetree/bindings/gpio/
 F:	Documentation/gpio/
 F:	Documentation/ABI/testing/gpio-cdev
 F:	Documentation/ABI/obsolete/sysfs-gpio
 F:	drivers/gpio/
 F:	include/linux/gpio/
 F:	include/linux/gpio.h
 F:	include/asm-generic/gpio.h
 F:	include/uapi/linux/gpio.h
 F:	tools/gpio/
 
 GRE DEMULTIPLEXER DRIVER
 M:	Dmitry Kozlov <xeb@mail.ru>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	net/ipv4/gre_demux.c
 F:	net/ipv4/gre_offload.c
 F:	include/net/gre.h
 
 GRETH 10/100/1G Ethernet MAC device driver
 M:	Andreas Larsson <andreas@gaisler.com>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/ethernet/aeroflex/
 
 GREYBUS SUBSYSTEM
 M:	Johan Hovold <johan@kernel.org>
 M:	Alex Elder <elder@kernel.org>
 M:	Greg Kroah-Hartman <gregkh@linuxfoundation.org>
 S:	Maintained
 F:	drivers/staging/greybus/
 L:	greybus-dev@lists.linaro.org
 
 GREYBUS AUDIO PROTOCOLS DRIVERS
 M:	Vaibhav Agarwal <vaibhav.sr@gmail.com>
 M:	Mark Greer <mgreer@animalcreek.com>
 S:	Maintained
 F:	drivers/staging/greybus/audio_apbridgea.c
 F:	drivers/staging/greybus/audio_apbridgea.h
 F:	drivers/staging/greybus/audio_codec.c
 F:	drivers/staging/greybus/audio_codec.h
 F:	drivers/staging/greybus/audio_gb.c
 F:	drivers/staging/greybus/audio_manager.c
 F:	drivers/staging/greybus/audio_manager.h
 F:	drivers/staging/greybus/audio_manager_module.c
 F:	drivers/staging/greybus/audio_manager_private.h
 F:	drivers/staging/greybus/audio_manager_sysfs.c
 F:	drivers/staging/greybus/audio_module.c
 F:	drivers/staging/greybus/audio_topology.c
 
 GREYBUS PROTOCOLS DRIVERS
 M:	Rui Miguel Silva <rmfrfs@gmail.com>
 S:	Maintained
 F:	drivers/staging/greybus/sdio.c
 F:	drivers/staging/greybus/light.c
 F:	drivers/staging/greybus/gpio.c
 F:	drivers/staging/greybus/power_supply.c
 F:	drivers/staging/greybus/spi.c
 F:	drivers/staging/greybus/spilib.c
 
 GREYBUS PROTOCOLS DRIVERS
 M:	Bryan O'Donoghue <pure.logic@nexus-software.ie>
 S:	Maintained
 F:	drivers/staging/greybus/loopback.c
 F:	drivers/staging/greybus/timesync.c
 F:	drivers/staging/greybus/timesync_platform.c
 
 GREYBUS PROTOCOLS DRIVERS
 M:	Viresh Kumar <vireshk@kernel.org>
 S:	Maintained
 F:	drivers/staging/greybus/authentication.c
 F:	drivers/staging/greybus/bootrom.c
 F:	drivers/staging/greybus/firmware.h
 F:	drivers/staging/greybus/fw-core.c
 F:	drivers/staging/greybus/fw-download.c
 F:	drivers/staging/greybus/fw-managament.c
 F:	drivers/staging/greybus/greybus_authentication.h
 F:	drivers/staging/greybus/greybus_firmware.h
 F:	drivers/staging/greybus/hid.c
 F:	drivers/staging/greybus/i2c.c
 F:	drivers/staging/greybus/spi.c
 F:	drivers/staging/greybus/spilib.c
 F:	drivers/staging/greybus/spilib.h
 
 GREYBUS PROTOCOLS DRIVERS
 M:	David Lin <dtwlin@gmail.com>
 S:	Maintained
 F:	drivers/staging/greybus/uart.c
 F:	drivers/staging/greybus/log.c
 
 GREYBUS PLATFORM DRIVERS
 M:	Vaibhav Hiremath <hvaibhav.linux@gmail.com>
 S:	Maintained
 F:	drivers/staging/greybus/arche-platform.c
 F:	drivers/staging/greybus/arche-apb-ctrl.c
 F:	drivers/staging/greybus/arche_platform.h
 
 GS1662 VIDEO SERIALIZER
 M:	Charles-Antoine Couret <charles-antoine.couret@nexvision.fr>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Maintained
 F:	drivers/media/spi/gs1662.c
 
 GSPCA FINEPIX SUBDRIVER
 M:	Frank Zago <frank@zago.net>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Maintained
 F:	drivers/media/usb/gspca/finepix.c
 
 GSPCA GL860 SUBDRIVER
 M:	Olivier Lorin <o.lorin@laposte.net>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Maintained
 F:	drivers/media/usb/gspca/gl860/
 
 GSPCA M5602 SUBDRIVER
 M:	Erik Andren <erik.andren@gmail.com>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Maintained
 F:	drivers/media/usb/gspca/m5602/
 
 GSPCA PAC207 SONIXB SUBDRIVER
 M:	Hans Verkuil <hverkuil@xs4all.nl>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Odd Fixes
 F:	drivers/media/usb/gspca/pac207.c
 
 GSPCA SN9C20X SUBDRIVER
 M:	Brian Johnson <brijohn@gmail.com>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Maintained
 F:	drivers/media/usb/gspca/sn9c20x.c
 
 GSPCA T613 SUBDRIVER
 M:	Leandro Costantino <lcostantino@gmail.com>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Maintained
 F:	drivers/media/usb/gspca/t613.c
 
 GSPCA USB WEBCAM DRIVER
 M:	Hans Verkuil <hverkuil@xs4all.nl>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Odd Fixes
 F:	drivers/media/usb/gspca/
 
 GTP (GPRS Tunneling Protocol)
 M:	Pablo Neira Ayuso <pablo@netfilter.org>
 M:	Harald Welte <laforge@gnumonks.org>
 L:	osmocom-net-gprs@lists.osmocom.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/pablo/gtp.git
 S:	Maintained
 F:	drivers/net/gtp.c
 
 GUID PARTITION TABLE (GPT)
 M:	Davidlohr Bueso <dave@stgolabs.net>
 L:	linux-efi@vger.kernel.org
 S:	Maintained
 F:	block/partitions/efi.*
 
 STK1160 USB VIDEO CAPTURE DRIVER
 M:	Ezequiel Garcia <ezequiel@vanguardiasur.com.ar>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Maintained
 F:	drivers/media/usb/stk1160/
 
 H8/300 ARCHITECTURE
 M:	Yoshinori Sato <ysato@users.sourceforge.jp>
 L:	uclinux-h8-devel@lists.sourceforge.jp (moderated for non-subscribers)
 W:	http://uclinux-h8.sourceforge.jp
 T:	git git://git.sourceforge.jp/gitroot/uclinux-h8/linux.git
 S:	Maintained
 F:	arch/h8300/
 F:	drivers/clocksource/h8300_*.c
 F:	drivers/clk/h8300/
 F:	drivers/irqchip/irq-renesas-h8*.c
 
 HARD DRIVE ACTIVE PROTECTION SYSTEM (HDAPS) DRIVER
 M:	Frank Seidel <frank@f-seidel.de>
 L:	platform-driver-x86@vger.kernel.org
 W:	http://www.kernel.org/pub/linux/kernel/people/fseidel/hdaps/
 S:	Maintained
 F:	drivers/platform/x86/hdaps.c
 
 HDPVR USB VIDEO ENCODER DRIVER
 M:	Hans Verkuil <hverkuil@xs4all.nl>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 W:	https://linuxtv.org
 S:	Odd Fixes
 F:	drivers/media/usb/hdpvr/
 
 HWPOISON MEMORY FAILURE HANDLING
 M:	Naoya Horiguchi <n-horiguchi@ah.jp.nec.com>
 L:	linux-mm@kvack.org
 S:	Maintained
 F:	mm/memory-failure.c
 F:	mm/hwpoison-inject.c
 
 HYPERVISOR VIRTUAL CONSOLE DRIVER
 L:	linuxppc-dev@lists.ozlabs.org
 S:	Odd Fixes
 F:	drivers/tty/hvc/
 
 HACKRF MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://palosaari.fi/linux/
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/anttip/media_tree.git
 S:	Maintained
 F:	drivers/media/usb/hackrf/
 
 HARDWARE MONITORING
 M:	Jean Delvare <jdelvare@suse.com>
 M:	Guenter Roeck <linux@roeck-us.net>
 L:	linux-hwmon@vger.kernel.org
 W:	http://hwmon.wiki.kernel.org/
 T:	quilt http://jdelvare.nerim.net/devel/linux/jdelvare-hwmon/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/groeck/linux-staging.git
 S:	Maintained
 F:	Documentation/hwmon/
 F:	drivers/hwmon/
 F:	include/linux/hwmon*.h
 
 HARDWARE RANDOM NUMBER GENERATOR CORE
 M:	Matt Mackall <mpm@selenic.com>
 M:	Herbert Xu <herbert@gondor.apana.org.au>
 L:	linux-crypto@vger.kernel.org
 S:	Odd fixes
 F:	Documentation/devicetree/bindings/rng/
 F:	Documentation/hw_random.txt
 F:	drivers/char/hw_random/
 F:	include/linux/hw_random.h
 
 HARDWARE SPINLOCK CORE
 M:	Ohad Ben-Cohen <ohad@wizery.com>
 M:	Bjorn Andersson <bjorn.andersson@linaro.org>
 L:	linux-remoteproc@vger.kernel.org
 S:	Maintained
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/ohad/hwspinlock.git
 F:	Documentation/devicetree/bindings/hwlock/
 F:	Documentation/hwspinlock.txt
 F:	drivers/hwspinlock/
 F:	include/linux/hwspinlock.h
 
 HARMONY SOUND DRIVER
 L:	linux-parisc@vger.kernel.org
 S:	Maintained
 F:	sound/parisc/harmony.*
 
 HEWLETT PACKARD ENTERPRISE ILO NMI WATCHDOG DRIVER
 M:	Jimmy Vance <jimmy.vance@hpe.com>
 S:	Supported
 F:	Documentation/watchdog/hpwdt.txt
 F:	drivers/watchdog/hpwdt.c
 
 HEWLETT-PACKARD SMART ARRAY RAID DRIVER (hpsa)
 M:	Don Brace <don.brace@microsemi.com>
 L:	esc.storagedev@microsemi.com
 L:	linux-scsi@vger.kernel.org
 S:	Supported
 F:	Documentation/scsi/hpsa.txt
 F:	drivers/scsi/hpsa*.[ch]
 F:	include/linux/cciss*.h
 F:	include/uapi/linux/cciss*.h
 
 HEWLETT-PACKARD SMART CISS RAID DRIVER (cciss)
 M:	Don Brace <don.brace@microsemi.com>
 L:	esc.storagedev@microsemi.com
 L:	linux-scsi@vger.kernel.org
 S:	Supported
 F:	Documentation/blockdev/cciss.txt
 F:	drivers/block/cciss*
 F:	include/linux/cciss_ioctl.h
 F:	include/uapi/linux/cciss_ioctl.h
 
 HFI1 DRIVER
 M:	Mike Marciniszyn <mike.marciniszyn@intel.com>
 M:	Dennis Dalessandro <dennis.dalessandro@intel.com>
 L:	linux-rdma@vger.kernel.org
 S:	Supported
 F:	drivers/infiniband/hw/hfi1
 
 HFS FILESYSTEM
 L:	linux-fsdevel@vger.kernel.org
 S:	Orphan
 F:	Documentation/filesystems/hfs.txt
 F:	fs/hfs/
 
 HFSPLUS FILESYSTEM
 L:	linux-fsdevel@vger.kernel.org
 S:	Orphan
 F:	Documentation/filesystems/hfsplus.txt
 F:	fs/hfsplus/
 
 HGA FRAMEBUFFER DRIVER
 M:	Ferenc Bakonyi <fero@drama.obuda.kando.hu>
 L:	linux-nvidia@lists.surfsouth.com
 W:	http://drama.obuda.kando.hu/~fero/cgi-bin/hgafb.shtml
 S:	Maintained
 F:	drivers/video/fbdev/hgafb.c
 
 HIBERNATION (aka Software Suspend, aka swsusp)
 M:	"Rafael J. Wysocki" <rjw@rjwysocki.net>
 M:	Pavel Machek <pavel@ucw.cz>
 L:	linux-pm@vger.kernel.org
 B:	https://bugzilla.kernel.org
 S:	Supported
 F:	arch/x86/power/
 F:	drivers/base/power/
 F:	kernel/power/
 F:	include/linux/suspend.h
 F:	include/linux/freezer.h
 F:	include/linux/pm.h
 F:	arch/*/include/asm/suspend*.h
 
 HID CORE LAYER
 M:	Jiri Kosina <jikos@kernel.org>
 R:	Benjamin Tissoires <benjamin.tissoires@redhat.com>
 L:	linux-input@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/jikos/hid.git
 S:	Maintained
 F:	drivers/hid/
 F:	include/linux/hid*
 F:	include/uapi/linux/hid*
 
 HID SENSOR HUB DRIVERS
 M:	Jiri Kosina <jikos@kernel.org>
 M:	Jonathan Cameron <jic23@kernel.org>
 M:	Srinivas Pandruvada <srinivas.pandruvada@linux.intel.com>
 L:	linux-input@vger.kernel.org
 L:	linux-iio@vger.kernel.org
 S:	Maintained
 F:	Documentation/hid/hid-sensor*
 F:	drivers/hid/hid-sensor-*
 F:	drivers/iio/*/hid-*
 F:	include/linux/hid-sensor-*
 
 HIGH-RESOLUTION TIMERS, CLOCKEVENTS, DYNTICKS
 M:	Thomas Gleixner <tglx@linutronix.de>
 L:	linux-kernel@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip.git timers/core
 S:	Maintained
 F:	Documentation/timers/
 F:	kernel/time/hrtimer.c
 F:	kernel/time/clockevents.c
 F:	kernel/time/tick*.*
 F:	kernel/time/timer_*.c
 F:	include/linux/clockchips.h
 F:	include/linux/hrtimer.h
 
 HIGH-SPEED SCC DRIVER FOR AX.25
 L:	linux-hams@vger.kernel.org
 S:	Orphan
 F:	drivers/net/hamradio/dmascc.c
 F:	drivers/net/hamradio/scc.c
 
 HIGHPOINT ROCKETRAID 3xxx RAID DRIVER
 M:	HighPoint Linux Team <linux@highpoint-tech.com>
 W:	http://www.highpoint-tech.com
 S:	Supported
 F:	Documentation/scsi/hptiop.txt
 F:	drivers/scsi/hptiop.c
 
 HIPPI
 M:	Jes Sorensen <jes@trained-monkey.org>
 L:	linux-hippi@sunsite.dk
 S:	Maintained
 F:	include/linux/hippidevice.h
 F:	include/uapi/linux/if_hippi.h
 F:	net/802/hippi.c
 F:	drivers/net/hippi/
 
 HISILICON NETWORK SUBSYSTEM DRIVER
 M:	Yisen Zhuang <yisen.zhuang@huawei.com>
 M:	Salil Mehta <salil.mehta@huawei.com>
 L:	netdev@vger.kernel.org
 W:	http://www.hisilicon.com
 S:	Maintained
 F:	drivers/net/ethernet/hisilicon/
 F:	Documentation/devicetree/bindings/net/hisilicon*.txt
 
 HISILICON ROCE DRIVER
 M:	Lijun Ou <oulijun@huawei.com>
 M:	Wei Hu(Xavier) <xavier.huwei@huawei.com>
 L:	linux-rdma@vger.kernel.org
 S:	Maintained
 F:	drivers/infiniband/hw/hns/
 F:	Documentation/devicetree/bindings/infiniband/hisilicon-hns-roce.txt
 
 HISILICON SAS Controller
 M:	John Garry <john.garry@huawei.com>
 W:	http://www.hisilicon.com
 S:	Supported
 F:	drivers/scsi/hisi_sas/
 F:	Documentation/devicetree/bindings/scsi/hisilicon-sas.txt
 
 HOST AP DRIVER
 M:	Jouni Malinen <j@w1.fi>
 L:	linux-wireless@vger.kernel.org
 W:	http://w1.fi/hostap-driver.html
 S:	Obsolete
 F:	drivers/net/wireless/intersil/hostap/
 
 HP COMPAQ TC1100 TABLET WMI EXTRAS DRIVER
 L:	platform-driver-x86@vger.kernel.org
 S:	Orphan
 F:	drivers/platform/x86/tc1100-wmi.c
 
 HP100:	Driver for HP 10/100 Mbit/s Voice Grade Network Adapter Series
 M:	Jaroslav Kysela <perex@perex.cz>
 S:	Maintained
 F:	drivers/net/ethernet/hp/hp100.*
 
 HPET:	High Precision Event Timers driver
 M:	Clemens Ladisch <clemens@ladisch.de>
 S:	Maintained
 F:	Documentation/timers/hpet.txt
 F:	drivers/char/hpet.c
 F:	include/linux/hpet.h
 F:	include/uapi/linux/hpet.h
 
 HPET:	x86
 S:	Orphan
 F:	arch/x86/kernel/hpet.c
 F:	arch/x86/include/asm/hpet.h
 
 HPFS FILESYSTEM
 M:	Mikulas Patocka <mikulas@artax.karlin.mff.cuni.cz>
 W:	http://artax.karlin.mff.cuni.cz/~mikulas/vyplody/hpfs/index-e.cgi
 S:	Maintained
 F:	fs/hpfs/
 
 HSI SUBSYSTEM
 M:	Sebastian Reichel <sre@kernel.org>
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/sre/linux-hsi.git
 S:	Maintained
 F:	Documentation/ABI/testing/sysfs-bus-hsi
 F:	Documentation/device-drivers/serial-interfaces.rst
 F:	drivers/hsi/
 F:	include/linux/hsi/
 F:	include/uapi/linux/hsi/
 
 HSO 3G MODEM DRIVER
 M:	Jan Dumon <j.dumon@option.com>
 W:	http://www.pharscape.org
 S:	Maintained
 F:	drivers/net/usb/hso.c
 
 HSR NETWORK PROTOCOL
 M:	Arvid Brodin <arvid.brodin@alten.se>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	net/hsr/
 
 HTCPEN TOUCHSCREEN DRIVER
 M:	Pau Oliva Fora <pof@eslack.org>
 L:	linux-input@vger.kernel.org
 S:	Maintained
 F:	drivers/input/touchscreen/htcpen.c
 
 HUGETLB FILESYSTEM
 M:	Nadia Yvette Chambers <nyc@holomorphy.com>
 S:	Maintained
 F:	fs/hugetlbfs/
 
 HVA ST MEDIA DRIVER
 M:	Jean-Christophe Trotin <jean-christophe.trotin@st.com>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 W:	https://linuxtv.org
 S:	Supported
 F:	drivers/media/platform/sti/hva
 
 Hyper-V CORE AND DRIVERS
 M:	"K. Y. Srinivasan" <kys@microsoft.com>
 M:	Haiyang Zhang <haiyangz@microsoft.com>
 M:	Stephen Hemminger <sthemmin@microsoft.com>
 L:	devel@linuxdriverproject.org
 S:	Maintained
 F:	arch/x86/include/asm/mshyperv.h
 F:	arch/x86/include/uapi/asm/hyperv.h
 F:	arch/x86/kernel/cpu/mshyperv.c
+F:	arch/x86/hyperv
 F:	drivers/hid/hid-hyperv.c
 F:	drivers/hv/
 F:	drivers/input/serio/hyperv-keyboard.c
 F:	drivers/pci/host/pci-hyperv.c
 F:	drivers/net/hyperv/
 F:	drivers/scsi/storvsc_drv.c
 F:	drivers/uio/uio_hv_generic.c
 F:	drivers/video/fbdev/hyperv_fb.c
 F:	include/linux/hyperv.h
 F:	tools/hv/
 F:	Documentation/ABI/stable/sysfs-bus-vmbus
 
 I2C MUXES
 M:	Peter Rosin <peda@axentia.se>
 L:	linux-i2c@vger.kernel.org
 S:	Maintained
 F:	Documentation/i2c/i2c-topology
 F:	Documentation/i2c/muxes/
 F:	Documentation/devicetree/bindings/i2c/i2c-mux*
 F:	Documentation/devicetree/bindings/i2c/i2c-arb*
 F:	Documentation/devicetree/bindings/i2c/i2c-gate*
 F:	drivers/i2c/i2c-mux.c
 F:	drivers/i2c/muxes/
 F:	include/linux/i2c-mux.h
 
 I2C OVER PARALLEL PORT
 M:	Jean Delvare <jdelvare@suse.com>
 L:	linux-i2c@vger.kernel.org
 S:	Maintained
 F:	Documentation/i2c/busses/i2c-parport
 F:	Documentation/i2c/busses/i2c-parport-light
 F:	drivers/i2c/busses/i2c-parport.c
 F:	drivers/i2c/busses/i2c-parport-light.c
 
 I2C/SMBUS CONTROLLER DRIVERS FOR PC
 M:	Jean Delvare <jdelvare@suse.com>
 L:	linux-i2c@vger.kernel.org
 S:	Maintained
 F:	Documentation/i2c/busses/i2c-ali1535
 F:	Documentation/i2c/busses/i2c-ali1563
 F:	Documentation/i2c/busses/i2c-ali15x3
 F:	Documentation/i2c/busses/i2c-amd756
 F:	Documentation/i2c/busses/i2c-amd8111
 F:	Documentation/i2c/busses/i2c-i801
 F:	Documentation/i2c/busses/i2c-nforce2
 F:	Documentation/i2c/busses/i2c-piix4
 F:	Documentation/i2c/busses/i2c-sis5595
 F:	Documentation/i2c/busses/i2c-sis630
 F:	Documentation/i2c/busses/i2c-sis96x
 F:	Documentation/i2c/busses/i2c-via
 F:	Documentation/i2c/busses/i2c-viapro
 F:	drivers/i2c/busses/i2c-ali1535.c
 F:	drivers/i2c/busses/i2c-ali1563.c
 F:	drivers/i2c/busses/i2c-ali15x3.c
 F:	drivers/i2c/busses/i2c-amd756.c
 F:	drivers/i2c/busses/i2c-amd756-s4882.c
 F:	drivers/i2c/busses/i2c-amd8111.c
 F:	drivers/i2c/busses/i2c-i801.c
 F:	drivers/i2c/busses/i2c-isch.c
 F:	drivers/i2c/busses/i2c-nforce2.c
 F:	drivers/i2c/busses/i2c-nforce2-s4985.c
 F:	drivers/i2c/busses/i2c-piix4.c
 F:	drivers/i2c/busses/i2c-sis5595.c
 F:	drivers/i2c/busses/i2c-sis630.c
 F:	drivers/i2c/busses/i2c-sis96x.c
 F:	drivers/i2c/busses/i2c-via.c
 F:	drivers/i2c/busses/i2c-viapro.c
 
 I2C/SMBUS ISMT DRIVER
 M:	Seth Heasley <seth.heasley@intel.com>
 M:	Neil Horman <nhorman@tuxdriver.com>
 L:	linux-i2c@vger.kernel.org
 F:	drivers/i2c/busses/i2c-ismt.c
 F:	Documentation/i2c/busses/i2c-ismt
 
 I2C/SMBUS STUB DRIVER
 M:	Jean Delvare <jdelvare@suse.com>
 L:	linux-i2c@vger.kernel.org
 S:	Maintained
 F:	drivers/i2c/i2c-stub.c
 
 I2C SUBSYSTEM
 M:	Wolfram Sang <wsa@the-dreams.de>
 L:	linux-i2c@vger.kernel.org
 W:	https://i2c.wiki.kernel.org/
 Q:	https://patchwork.ozlabs.org/project/linux-i2c/list/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/wsa/linux.git
 S:	Maintained
 F:	Documentation/devicetree/bindings/i2c/
 F:	Documentation/i2c/
 F:	drivers/i2c/
 F:	drivers/i2c/*/
 F:	include/linux/i2c.h
 F:	include/linux/i2c-*.h
 F:	include/uapi/linux/i2c.h
 F:	include/uapi/linux/i2c-*.h
 
 I2C ACPI SUPPORT
 M:	Mika Westerberg <mika.westerberg@linux.intel.com>
 L:	linux-i2c@vger.kernel.org
 L:	linux-acpi@vger.kernel.org
 S:	Maintained
 
 I2C-TAOS-EVM DRIVER
 M:	Jean Delvare <jdelvare@suse.com>
 L:	linux-i2c@vger.kernel.org
 S:	Maintained
 F:	Documentation/i2c/busses/i2c-taos-evm
 F:	drivers/i2c/busses/i2c-taos-evm.c
 
 I2C-TINY-USB DRIVER
 M:	Till Harbaum <till@harbaum.org>
 L:	linux-i2c@vger.kernel.org
 W:	http://www.harbaum.org/till/i2c_tiny_usb
 S:	Maintained
 F:	drivers/i2c/busses/i2c-tiny-usb.c
 
 i386 BOOT CODE
 M:	"H. Peter Anvin" <hpa@zytor.com>
 S:	Maintained
 F:	arch/x86/boot/
 
 i386 SETUP CODE / CPU ERRATA WORKAROUNDS
 M:	"H. Peter Anvin" <hpa@zytor.com>
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/hpa/linux-2.6-x86setup.git
 S:	Maintained
 
 IA64 (Itanium) PLATFORM
 M:	Tony Luck <tony.luck@intel.com>
 M:	Fenghua Yu <fenghua.yu@intel.com>
 L:	linux-ia64@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/aegl/linux.git
 S:	Maintained
 F:	arch/ia64/
 
 IBM Power VMX Cryptographic instructions
 M:	Leonidas S. Barbosa <leosilva@linux.vnet.ibm.com>
 M:	Paulo Flabiano Smorigo <pfsmorigo@linux.vnet.ibm.com>
 L:	linux-crypto@vger.kernel.org
 S:	Supported
 F:	drivers/crypto/vmx/Makefile
 F:	drivers/crypto/vmx/Kconfig
 F:	drivers/crypto/vmx/vmx.c
 F:	drivers/crypto/vmx/aes*
 F:	drivers/crypto/vmx/ghash*
 F:	drivers/crypto/vmx/ppc-xlate.pl
 
 IBM Power in-Nest Crypto Acceleration
 M:	Leonidas S. Barbosa <leosilva@linux.vnet.ibm.com>
 M:	Paulo Flabiano Smorigo <pfsmorigo@linux.vnet.ibm.com>
 L:	linux-crypto@vger.kernel.org
 S:	Supported
 F:	drivers/crypto/nx/Makefile
 F:	drivers/crypto/nx/Kconfig
 F:	drivers/crypto/nx/nx-aes*
 F:	drivers/crypto/nx/nx-sha*
 F:	drivers/crypto/nx/nx.*
 F:	drivers/crypto/nx/nx_csbcpb.h
 F:	drivers/crypto/nx/nx_debugfs.h
 
 IBM Power 842 compression accelerator
 M:	Dan Streetman <ddstreet@ieee.org>
 S:	Supported
 F:	drivers/crypto/nx/Makefile
 F:	drivers/crypto/nx/Kconfig
 F:	drivers/crypto/nx/nx-842*
 F:	include/linux/sw842.h
 F:	crypto/842.c
 F:	lib/842/
 
 IBM Power Linux RAID adapter
 M:	Brian King <brking@us.ibm.com>
 S:	Supported
 F:	drivers/scsi/ipr.*
 
 IBM Power Virtual Ethernet Device Driver
 M:	Thomas Falcon <tlfalcon@linux.vnet.ibm.com>
 L:	netdev@vger.kernel.org
 S:	Supported
 F:	drivers/net/ethernet/ibm/ibmveth.*
 
 IBM Power SRIOV Virtual NIC Device Driver
 M:	Thomas Falcon <tlfalcon@linux.vnet.ibm.com>
 M:	John Allen <jallen@linux.vnet.ibm.com>
 L:	netdev@vger.kernel.org
 S:	Supported
 F:	drivers/net/ethernet/ibm/ibmvnic.*
 
 IBM Power Virtual SCSI Device Drivers
 M:	Tyrel Datwyler <tyreld@linux.vnet.ibm.com>
 L:	linux-scsi@vger.kernel.org
 S:	Supported
 F:	drivers/scsi/ibmvscsi/ibmvscsi*
 F:	include/scsi/viosrp.h
 
 IBM Power Virtual SCSI Device Target Driver
 M:	Bryant G. Ly <bryantly@linux.vnet.ibm.com>
 M:	Michael Cyr <mikecyr@linux.vnet.ibm.com>
 L:	linux-scsi@vger.kernel.org
 L:	target-devel@vger.kernel.org
 S:	Supported
 F:	drivers/scsi/ibmvscsi_tgt/
 
 IBM Power Virtual FC Device Drivers
 M:	Tyrel Datwyler <tyreld@linux.vnet.ibm.com>
 L:	linux-scsi@vger.kernel.org
 S:	Supported
 F:	drivers/scsi/ibmvscsi/ibmvfc*
 
 IBM ServeRAID RAID DRIVER
 S:	Orphan
 F:	drivers/scsi/ips.*
 
 ICH LPC AND GPIO DRIVER
 M:	Peter Tyser <ptyser@xes-inc.com>
 S:	Maintained
 F:	drivers/mfd/lpc_ich.c
 F:	drivers/gpio/gpio-ich.c
 
 IDE SUBSYSTEM
 M:	"David S. Miller" <davem@davemloft.net>
 L:	linux-ide@vger.kernel.org
 Q:	http://patchwork.ozlabs.org/project/linux-ide/list/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/davem/ide.git
 S:	Maintained
 F:	Documentation/ide/
 F:	drivers/ide/
 F:	include/linux/ide.h
 
 IDEAPAD LAPTOP EXTRAS DRIVER
 M:	Ike Panhc <ike.pan@canonical.com>
 L:	platform-driver-x86@vger.kernel.org
 W:	http://launchpad.net/ideapad-laptop
 S:	Maintained
 F:	drivers/platform/x86/ideapad-laptop.c
 
 IDEAPAD LAPTOP SLIDEBAR DRIVER
 M:	Andrey Moiseev <o2g.org.ru@gmail.com>
 L:	linux-input@vger.kernel.org
 W:	https://github.com/o2genum/ideapad-slidebar
 S:	Maintained
 F:	drivers/input/misc/ideapad_slidebar.c
 
 IDE/ATAPI DRIVERS
 M:	Borislav Petkov <bp@alien8.de>
 L:	linux-ide@vger.kernel.org
 S:	Maintained
 F:	Documentation/cdrom/ide-cd
 F:	drivers/ide/ide-cd*
 
 IEEE 802.15.4 SUBSYSTEM
 M:	Alexander Aring <aar@pengutronix.de>
 M:	Stefan Schmidt <stefan@osg.samsung.com>
 L:	linux-wpan@vger.kernel.org
 W:	http://wpan.cakelab.org/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/bluetooth/bluetooth.git
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/bluetooth/bluetooth-next.git
 S:	Maintained
 F:	net/ieee802154/
 F:	net/mac802154/
 F:	drivers/net/ieee802154/
 F:	include/linux/nl802154.h
 F:	include/linux/ieee802154.h
 F:	include/net/nl802154.h
 F:	include/net/mac802154.h
 F:	include/net/af_ieee802154.h
 F:	include/net/cfg802154.h
 F:	include/net/ieee802154_netdev.h
 F:	Documentation/networking/ieee802154.txt
 
 IFE PROTOCOL
 M:	Yotam Gigi <yotamg@mellanox.com>
 M:	Jamal Hadi Salim <jhs@mojatatu.com>
 F:	net/ife
 F:	include/net/ife.h
 F:	include/uapi/linux/ife.h
 
 IGORPLUG-USB IR RECEIVER
 M:	Sean Young <sean@mess.org>
 L:	linux-media@vger.kernel.org
 S:	Maintained
 F:	drivers/media/rc/igorplugusb.c
 
 IGUANAWORKS USB IR TRANSCEIVER
 M:	Sean Young <sean@mess.org>
 L:	linux-media@vger.kernel.org
 S:	Maintained
 F:	drivers/media/rc/iguanair.c
 
 IIO DIGITAL POTENTIOMETER DAC
 M:	Peter Rosin <peda@axentia.se>
 L:	linux-iio@vger.kernel.org
 S:	Maintained
 F:	Documentation/ABI/testing/sysfs-bus-iio-dac-dpot-dac
 F:	Documentation/devicetree/bindings/iio/dac/dpot-dac.txt
 F:	drivers/iio/dac/dpot-dac.c
 
 IIO ENVELOPE DETECTOR
 M:	Peter Rosin <peda@axentia.se>
 L:	linux-iio@vger.kernel.org
 S:	Maintained
 F:	Documentation/ABI/testing/sysfs-bus-iio-adc-envelope-detector
 F:	Documentation/devicetree/bindings/iio/adc/envelope-detector.txt
 F:	drivers/iio/adc/envelope-detector.c
 
 IIO SUBSYSTEM AND DRIVERS
 M:	Jonathan Cameron <jic23@kernel.org>
 R:	Hartmut Knaack <knaack.h@gmx.de>
 R:	Lars-Peter Clausen <lars@metafoo.de>
 R:	Peter Meerwald-Stadler <pmeerw@pmeerw.net>
 L:	linux-iio@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/jic23/iio.git
 S:	Maintained
 F:	Documentation/devicetree/bindings/iio/
 F:	drivers/iio/
 F:	drivers/staging/iio/
 F:	include/linux/iio/
 F:	tools/iio/
 
 IKANOS/ADI EAGLE ADSL USB DRIVER
 M:	Matthieu Castet <castet.matthieu@free.fr>
 M:	Stanislaw Gruszka <stf_xl@wp.pl>
 S:	Maintained
 F:	drivers/usb/atm/ueagle-atm.c
 
 IMGTEC ASCII LCD DRIVER
 M:	Paul Burton <paul.burton@imgtec.com>
 S:	Maintained
 F:	Documentation/devicetree/bindings/auxdisplay/img-ascii-lcd.txt
 F:	drivers/auxdisplay/img-ascii-lcd.c
 
 INA209 HARDWARE MONITOR DRIVER
 M:	Guenter Roeck <linux@roeck-us.net>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	Documentation/hwmon/ina209
 F:	Documentation/devicetree/bindings/i2c/ina209.txt
 F:	drivers/hwmon/ina209.c
 
 INA2XX HARDWARE MONITOR DRIVER
 M:	Guenter Roeck <linux@roeck-us.net>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	Documentation/hwmon/ina2xx
 F:	drivers/hwmon/ina2xx.c
 F:	include/linux/platform_data/ina2xx.h
 
 INDUSTRY PACK SUBSYSTEM (IPACK)
 M:	Samuel Iglesias Gonsalvez <siglesias@igalia.com>
 M:	Jens Taprogge <jens.taprogge@taprogge.org>
 M:	Greg Kroah-Hartman <gregkh@linuxfoundation.org>
 L:	industrypack-devel@lists.sourceforge.net
 W:	http://industrypack.sourceforge.net
 S:	Maintained
 F:	drivers/ipack/
 
 INGENIC JZ4780 DMA Driver
 M:	Zubair Lutfullah Kakakhel <Zubair.Kakakhel@imgtec.com>
 S:	Maintained
 F:	drivers/dma/dma-jz4780.c
 
 INGENIC JZ4780 NAND DRIVER
 M:	Harvey Hunt <harveyhuntnexus@gmail.com>
 L:	linux-mtd@lists.infradead.org
 S:	Maintained
 F:	drivers/mtd/nand/jz4780_*
 
 INTEGRITY MEASUREMENT ARCHITECTURE (IMA)
 M:	Mimi Zohar <zohar@linux.vnet.ibm.com>
 M:	Dmitry Kasatkin <dmitry.kasatkin@gmail.com>
 L:	linux-ima-devel@lists.sourceforge.net
 L:	linux-ima-user@lists.sourceforge.net
 L:	linux-security-module@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/zohar/linux-integrity.git
 S:	Supported
 F:	security/integrity/ima/
 
 IMGTEC IR DECODER DRIVER
 M:	James Hogan <james.hogan@imgtec.com>
 S:	Maintained
 F:	drivers/media/rc/img-ir/
 
 IMS TWINTURBO FRAMEBUFFER DRIVER
 L:	linux-fbdev@vger.kernel.org
 S:	Orphan
 F:	drivers/video/fbdev/imsttfb.c
 
 INFINIBAND SUBSYSTEM
 M:	Doug Ledford <dledford@redhat.com>
 M:	Sean Hefty <sean.hefty@intel.com>
 M:	Hal Rosenstock <hal.rosenstock@gmail.com>
 L:	linux-rdma@vger.kernel.org
 W:	http://www.openfabrics.org/
 Q:	http://patchwork.kernel.org/project/linux-rdma/list/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/dledford/rdma.git
 S:	Supported
 F:	Documentation/infiniband/
 F:	drivers/infiniband/
 F:	include/uapi/linux/if_infiniband.h
 F:	include/uapi/rdma/
 F:	include/rdma/
 
 INOTIFY
 M:	John McCutchan <john@johnmccutchan.com>
 M:	Robert Love <rlove@rlove.org>
 M:	Eric Paris <eparis@parisplace.org>
 S:	Maintained
 F:	Documentation/filesystems/inotify.txt
 F:	fs/notify/inotify/
 F:	include/linux/inotify.h
 F:	include/uapi/linux/inotify.h
 
 INPUT (KEYBOARD, MOUSE, JOYSTICK, TOUCHSCREEN) DRIVERS
 M:	Dmitry Torokhov <dmitry.torokhov@gmail.com>
 L:	linux-input@vger.kernel.org
 Q:	http://patchwork.kernel.org/project/linux-input/list/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/dtor/input.git
 S:	Maintained
 F:	drivers/input/
 F:	include/linux/input.h
 F:	include/uapi/linux/input.h
 F:	include/linux/input/
 F:	Documentation/devicetree/bindings/input/
 
 INPUT MULTITOUCH (MT) PROTOCOL
 M:	Henrik Rydberg <rydberg@bitmath.org>
 L:	linux-input@vger.kernel.org
 S:	Odd fixes
 F:	Documentation/input/multi-touch-protocol.txt
 F:	drivers/input/input-mt.c
 K:	\b(ABS|SYN)_MT_
 
 INTEL ASoC BDW/HSW DRIVERS
 M:	Jie Yang <yang.jie@linux.intel.com>
 L:	alsa-devel@alsa-project.org (moderated for non-subscribers)
 S:	Supported
 F:	sound/soc/intel/common/sst-dsp*
 F:	sound/soc/intel/common/sst-firmware.c
 F:	sound/soc/intel/boards/broadwell.c
 F:	sound/soc/intel/haswell/
 
 INTEL C600 SERIES SAS CONTROLLER DRIVER
 M:	Intel SCU Linux support <intel-linux-scu@intel.com>
 M:	Artur Paszkiewicz <artur.paszkiewicz@intel.com>
 L:	linux-scsi@vger.kernel.org
 T:	git git://git.code.sf.net/p/intel-sas/isci
 S:	Supported
 F:	drivers/scsi/isci/
 
 INTEL HID EVENT DRIVER
 M:	Alex Hung <alex.hung@canonical.com>
 L:	platform-driver-x86@vger.kernel.org
 S:	Maintained
 F:	drivers/platform/x86/intel-hid.c
 
 INTEL VIRTUAL BUTTON DRIVER
 M:	AceLan Kao <acelan.kao@canonical.com>
 L:	platform-driver-x86@vger.kernel.org
 S:	Maintained
 F:	drivers/platform/x86/intel-vbtn.c
 
 INTEL IDLE DRIVER
 M:	Jacob Pan <jacob.jun.pan@linux.intel.com>
 M:	Len Brown <lenb@kernel.org>
 L:	linux-pm@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux.git
 B:	https://bugzilla.kernel.org
 S:	Supported
 F:	drivers/idle/intel_idle.c
 
 INTEL INTEGRATED SENSOR HUB DRIVER
 M:	Srinivas Pandruvada <srinivas.pandruvada@linux.intel.com>
 M:	Jiri Kosina <jikos@kernel.org>
 L:	linux-input@vger.kernel.org
 S:	Maintained
 F:	drivers/hid/intel-ish-hid/
 
 INTEL PSTATE DRIVER
 M:	Srinivas Pandruvada <srinivas.pandruvada@linux.intel.com>
 M:	Len Brown <lenb@kernel.org>
 L:	linux-pm@vger.kernel.org
 S:	Supported
 F:	drivers/cpufreq/intel_pstate.c
 
 INTEL FRAMEBUFFER DRIVER (excluding 810 and 815)
 M:	Maik Broemme <mbroemme@libmpq.org>
 L:	linux-fbdev@vger.kernel.org
 S:	Maintained
 F:	Documentation/fb/intelfb.txt
 F:	drivers/video/fbdev/intelfb/
 
 INTEL 810/815 FRAMEBUFFER DRIVER
 M:	Antonino Daplas <adaplas@gmail.com>
 L:	linux-fbdev@vger.kernel.org
 S:	Maintained
 F:	drivers/video/fbdev/i810/
 
 INTEL MENLOW THERMAL DRIVER
 M:	Sujith Thomas <sujith.thomas@intel.com>
 L:	platform-driver-x86@vger.kernel.org
 W:	https://01.org/linux-acpi
 S:	Supported
 F:	drivers/platform/x86/intel_menlow.c
 
 INTEL I/OAT DMA DRIVER
 M:	Dave Jiang <dave.jiang@intel.com>
 R:	Dan Williams <dan.j.williams@intel.com>
 L:	dmaengine@vger.kernel.org
 Q:	https://patchwork.kernel.org/project/linux-dmaengine/list/
 S:	Supported
 F:	drivers/dma/ioat*
 
 INTEL IOMMU (VT-d)
 M:	David Woodhouse <dwmw2@infradead.org>
 L:	iommu@lists.linux-foundation.org
 T:	git git://git.infradead.org/iommu-2.6.git
 S:	Supported
 F:	drivers/iommu/intel-iommu.c
 F:	include/linux/intel-iommu.h
 
 INTEL IOP-ADMA DMA DRIVER
 R:	Dan Williams <dan.j.williams@intel.com>
 S:	Odd fixes
 F:	drivers/dma/iop-adma.c
 
 INTEL IXP4XX QMGR, NPE, ETHERNET and HSS SUPPORT
 M:	Krzysztof Halasa <khalasa@piap.pl>
 S:	Maintained
 F:	arch/arm/mach-ixp4xx/include/mach/qmgr.h
 F:	arch/arm/mach-ixp4xx/include/mach/npe.h
 F:	arch/arm/mach-ixp4xx/ixp4xx_qmgr.c
 F:	arch/arm/mach-ixp4xx/ixp4xx_npe.c
 F:	drivers/net/ethernet/xscale/ixp4xx_eth.c
 F:	drivers/net/wan/ixp4xx_hss.c
 
 INTEL IXP4XX RANDOM NUMBER GENERATOR SUPPORT
 M:	Deepak Saxena <dsaxena@plexity.net>
 S:	Maintained
 F:	drivers/char/hw_random/ixp4xx-rng.c
 
 INTEL ETHERNET DRIVERS
 M:	Jeff Kirsher <jeffrey.t.kirsher@intel.com>
 L:	intel-wired-lan@lists.osuosl.org (moderated for non-subscribers)
 W:	http://www.intel.com/support/feedback.htm
 W:	http://e1000.sourceforge.net/
 Q:	http://patchwork.ozlabs.org/project/intel-wired-lan/list/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/jkirsher/net-queue.git
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/jkirsher/next-queue.git
 S:	Supported
 F:	Documentation/networking/e100.txt
 F:	Documentation/networking/e1000.txt
 F:	Documentation/networking/e1000e.txt
 F:	Documentation/networking/igb.txt
 F:	Documentation/networking/igbvf.txt
 F:	Documentation/networking/ixgb.txt
 F:	Documentation/networking/ixgbe.txt
 F:	Documentation/networking/ixgbevf.txt
 F:	Documentation/networking/i40e.txt
 F:	Documentation/networking/i40evf.txt
 F:	drivers/net/ethernet/intel/
 F:	drivers/net/ethernet/intel/*/
 
 INTEL RDMA RNIC DRIVER
 M:     Faisal Latif <faisal.latif@intel.com>
 M:     Shiraz Saleem <shiraz.saleem@intel.com>
 L:     linux-rdma@vger.kernel.org
 S:     Supported
 F:     drivers/infiniband/hw/i40iw/
 
 INTEL MERRIFIELD GPIO DRIVER
 M:	Andy Shevchenko <andriy.shevchenko@linux.intel.com>
 L:	linux-gpio@vger.kernel.org
 S:	Maintained
 F:	drivers/gpio/gpio-merrifield.c
 
 INTEL-MID GPIO DRIVER
 M:	David Cohen <david.a.cohen@linux.intel.com>
 L:	linux-gpio@vger.kernel.org
 S:	Maintained
 F:	drivers/gpio/gpio-intel-mid.c
 
 INTEL PRO/WIRELESS 2100, 2200BG, 2915ABG NETWORK CONNECTION SUPPORT
 M:	Stanislav Yakovlev <stas.yakovlev@gmail.com>
 L:	linux-wireless@vger.kernel.org
 S:	Maintained
 F:	Documentation/networking/README.ipw2100
 F:	Documentation/networking/README.ipw2200
 F:	drivers/net/wireless/intel/ipw2x00/
 
 INTEL(R) TRACE HUB
 M:	Alexander Shishkin <alexander.shishkin@linux.intel.com>
 S:	Supported
 F:	Documentation/trace/intel_th.txt
 F:	drivers/hwtracing/intel_th/
 
 INTEL(R) TRUSTED EXECUTION TECHNOLOGY (TXT)
 M:	Ning Sun <ning.sun@intel.com>
 L:	tboot-devel@lists.sourceforge.net
 W:	http://tboot.sourceforge.net
 T:	hg http://tboot.hg.sourceforge.net:8000/hgroot/tboot/tboot
 S:	Supported
 F:	Documentation/intel_txt.txt
 F:	include/linux/tboot.h
 F:	arch/x86/kernel/tboot.c
 
 INTEL WIRELESS WIMAX CONNECTION 2400
 M:	Inaky Perez-Gonzalez <inaky.perez-gonzalez@intel.com>
 M:	linux-wimax@intel.com
 L:	wimax@linuxwimax.org (subscribers-only)
 S:	Supported
 W:	http://linuxwimax.org
 F:	Documentation/wimax/README.i2400m
 F:	drivers/net/wimax/i2400m/
 F:	include/uapi/linux/wimax/i2400m.h
 
 INTEL WIRELESS 3945ABG/BG, 4965AGN (iwlegacy)
 M:	Stanislaw Gruszka <sgruszka@redhat.com>
 L:	linux-wireless@vger.kernel.org
 S:	Supported
 F:	drivers/net/wireless/intel/iwlegacy/
 
 INTEL WIRELESS WIFI LINK (iwlwifi)
 M:	Johannes Berg <johannes.berg@intel.com>
 M:	Emmanuel Grumbach <emmanuel.grumbach@intel.com>
 M:	Luca Coelho <luciano.coelho@intel.com>
 M:	Intel Linux Wireless <linuxwifi@intel.com>
 L:	linux-wireless@vger.kernel.org
 W:	http://intellinuxwireless.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/iwlwifi/iwlwifi.git
 S:	Supported
 F:	drivers/net/wireless/intel/iwlwifi/
 
 INTEL MANAGEMENT ENGINE (mei)
 M:	Tomas Winkler <tomas.winkler@intel.com>
 L:	linux-kernel@vger.kernel.org
 S:	Supported
 F:	include/uapi/linux/mei.h
 F:	include/linux/mei_cl_bus.h
 F:	drivers/misc/mei/*
 F:	drivers/watchdog/mei_wdt.c
 F:	Documentation/misc-devices/mei/*
 F:	samples/mei/*
 
 INTEL MIC DRIVERS (mic)
 M:	Sudeep Dutt <sudeep.dutt@intel.com>
 M:	Ashutosh Dixit <ashutosh.dixit@intel.com>
 S:	Supported
 W:	https://github.com/sudeepdutt/mic
 W:	http://software.intel.com/en-us/mic-developer
 F:	include/linux/mic_bus.h
 F:	include/linux/scif.h
 F:	include/uapi/linux/mic_common.h
 F: 	include/uapi/linux/mic_ioctl.h
 F:	include/uapi/linux/scif_ioctl.h
 F:	drivers/misc/mic/
 F:	drivers/dma/mic_x100_dma.c
 F:	drivers/dma/mic_x100_dma.h
 F:	Documentation/mic/
 
 INTEL PMC/P-Unit IPC DRIVER
 M:	Zha Qipeng<qipeng.zha@intel.com>
 L:	platform-driver-x86@vger.kernel.org
 S:	Maintained
 F:	drivers/platform/x86/intel_pmc_ipc.c
 F:	drivers/platform/x86/intel_punit_ipc.c
 F:	arch/x86/include/asm/intel_pmc_ipc.h
 F:	arch/x86/include/asm/intel_punit_ipc.h
 
 INTEL TELEMETRY DRIVER
 M:	Souvik Kumar Chakravarty <souvik.k.chakravarty@intel.com>
 L:	platform-driver-x86@vger.kernel.org
 S:	Maintained
 F:	arch/x86/include/asm/intel_telemetry.h
 F:	drivers/platform/x86/intel_telemetry*
 
 INTEL PMC CORE DRIVER
 M:	Rajneesh Bhardwaj <rajneesh.bhardwaj@intel.com>
 M:	Vishwanath Somayaji <vishwanath.somayaji@intel.com>
 L:	platform-driver-x86@vger.kernel.org
 S:	Maintained
 F:	arch/x86/include/asm/pmc_core.h
 F:	drivers/platform/x86/intel_pmc_core*
 
 INVENSENSE MPU-3050 GYROSCOPE DRIVER
 M:	Linus Walleij <linus.walleij@linaro.org>
 L:	linux-iio@vger.kernel.org
 S:	Maintained
 F:	drivers/iio/gyro/mpu3050*
 F:	Documentation/devicetree/bindings/iio/gyroscope/inv,mpu3050.txt
 
 IOC3 ETHERNET DRIVER
 M:	Ralf Baechle <ralf@linux-mips.org>
 L:	linux-mips@linux-mips.org
 S:	Maintained
 F:	drivers/net/ethernet/sgi/ioc3-eth.c
 
 IOC3 SERIAL DRIVER
 M:	Pat Gefre <pfg@sgi.com>
 L:	linux-serial@vger.kernel.org
 S:	Maintained
 F:	drivers/tty/serial/ioc3_serial.c
 
 IOMMU DRIVERS
 M:	Joerg Roedel <joro@8bytes.org>
 L:	iommu@lists.linux-foundation.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/joro/iommu.git
 S:	Maintained
 F:	Documentation/devicetree/bindings/iommu/
 F:	drivers/iommu/
 
 IP MASQUERADING
 M:	Juanjo Ciarlante <jjciarla@raiz.uncu.edu.ar>
 S:	Maintained
 F:	net/ipv4/netfilter/ipt_MASQUERADE.c
 
 IPMI SUBSYSTEM
 M:	Corey Minyard <minyard@acm.org>
 L:	openipmi-developer@lists.sourceforge.net (moderated for non-subscribers)
 W:	http://openipmi.sourceforge.net/
 S:	Supported
 F:	Documentation/IPMI.txt
 F:	drivers/char/ipmi/
 F:	include/linux/ipmi*
 F:	include/uapi/linux/ipmi*
 
 QCOM AUDIO (ASoC) DRIVERS
 M:	Patrick Lai <plai@codeaurora.org>
 M:	Banajit Goswami <bgoswami@codeaurora.org>
 L:	alsa-devel@alsa-project.org (moderated for non-subscribers)
 S:	Supported
 F:	sound/soc/qcom/
 
 IPS SCSI RAID DRIVER
 M:	Adaptec OEM Raid Solutions <aacraid@adaptec.com>
 L:	linux-scsi@vger.kernel.org
 W:	http://www.adaptec.com/
 S:	Maintained
 F:	drivers/scsi/ips*
 
 IPVS
 M:	Wensong Zhang <wensong@linux-vs.org>
 M:	Simon Horman <horms@verge.net.au>
 M:	Julian Anastasov <ja@ssi.bg>
 L:	netdev@vger.kernel.org
 L:	lvs-devel@vger.kernel.org
 S:	Maintained
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/horms/ipvs-next.git
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/horms/ipvs.git
 F:	Documentation/networking/ipvs-sysctl.txt
 F:	include/net/ip_vs.h
 F:	include/uapi/linux/ip_vs.h
 F:	net/netfilter/ipvs/
 
 IPWIRELESS DRIVER
 M:	Jiri Kosina <jikos@kernel.org>
 M:	David Sterba <dsterba@suse.com>
 S:	Odd Fixes
 F:	drivers/tty/ipwireless/
 
 IPX NETWORK LAYER
 L:	netdev@vger.kernel.org
 S:	Odd fixes
 F:	include/net/ipx.h
 F:	include/uapi/linux/ipx.h
 F:	net/ipx/
 
 IRDA SUBSYSTEM
 M:	Samuel Ortiz <samuel@sortiz.org>
 L:	irda-users@lists.sourceforge.net (subscribers-only)
 L:	netdev@vger.kernel.org
 W:	http://irda.sourceforge.net/
 S:	Maintained
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/sameo/irda-2.6.git
 F:	Documentation/networking/irda.txt
 F:	drivers/net/irda/
 F:	include/net/irda/
 F:	net/irda/
 
 IRQ SUBSYSTEM
 M:	Thomas Gleixner <tglx@linutronix.de>
 L:	linux-kernel@vger.kernel.org
 S:	Maintained
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip.git irq/core
 F:	kernel/irq/
 
 IRQCHIP DRIVERS
 M:	Thomas Gleixner <tglx@linutronix.de>
 M:	Jason Cooper <jason@lakedaemon.net>
 M:	Marc Zyngier <marc.zyngier@arm.com>
 L:	linux-kernel@vger.kernel.org
 S:	Maintained
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip.git irq/core
 T:	git git://git.infradead.org/users/jcooper/linux.git irqchip/core
 F:	Documentation/devicetree/bindings/interrupt-controller/
 F:	drivers/irqchip/
 
 IRQ DOMAINS (IRQ NUMBER MAPPING LIBRARY)
 M:	Marc Zyngier <marc.zyngier@arm.com>
 S:	Maintained
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip.git irq/core
 F:	Documentation/IRQ-domain.txt
 F:	include/linux/irqdomain.h
 F:	kernel/irq/irqdomain.c
 F:	kernel/irq/msi.c
 
 ISA
 M:	William Breathitt Gray <vilhelm.gray@gmail.com>
 S:	Maintained
 F:	Documentation/isa.txt
 F:	drivers/base/isa.c
 F:	include/linux/isa.h
 
 ISAPNP
 M:	Jaroslav Kysela <perex@perex.cz>
 S:	Maintained
 F:	Documentation/isapnp.txt
 F:	drivers/pnp/isapnp/
 F:	include/linux/isapnp.h
 
 ISA RADIO MODULE
 M:	Hans Verkuil <hverkuil@xs4all.nl>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 W:	https://linuxtv.org
 S:	Maintained
 F:	drivers/media/radio/radio-isa*
 
 iSCSI BOOT FIRMWARE TABLE (iBFT) DRIVER
 M:	Peter Jones <pjones@redhat.com>
 M:	Konrad Rzeszutek Wilk <konrad@kernel.org>
 S:	Maintained
 F:	drivers/firmware/iscsi_ibft*
 
 ISCSI
 M:	Lee Duncan <lduncan@suse.com>
 M:	Chris Leech <cleech@redhat.com>
 L:	open-iscsi@googlegroups.com
 W:	www.open-iscsi.com
 S:	Maintained
 F:	drivers/scsi/*iscsi*
 F:	include/scsi/*iscsi*
 
 ISCSI EXTENSIONS FOR RDMA (ISER) INITIATOR
 M:	Or Gerlitz <ogerlitz@mellanox.com>
 M:	Sagi Grimberg <sagi@grimberg.me>
 M:	Roi Dayan <roid@mellanox.com>
 L:	linux-rdma@vger.kernel.org
 S:	Supported
 W:	http://www.openfabrics.org
 W:	www.open-iscsi.org
 Q:	http://patchwork.kernel.org/project/linux-rdma/list/
 F:	drivers/infiniband/ulp/iser/
 
 ISCSI EXTENSIONS FOR RDMA (ISER) TARGET
 M:	Sagi Grimberg <sagi@grimberg.me>
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/nab/target-pending.git master
 L:	linux-rdma@vger.kernel.org
 L:	target-devel@vger.kernel.org
 S:	Supported
 W:	http://www.linux-iscsi.org
 F:	drivers/infiniband/ulp/isert
 
 ISDN SUBSYSTEM
 M:	Karsten Keil <isdn@linux-pingi.de>
 L:	isdn4linux@listserv.isdn4linux.de (subscribers-only)
 L:	netdev@vger.kernel.org
 W:	http://www.isdn4linux.de
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/kkeil/isdn-2.6.git
 S:	Maintained
 F:	Documentation/isdn/
 F:	drivers/isdn/
 F:	include/linux/isdn.h
 F:	include/linux/isdn/
 F:	include/uapi/linux/isdn.h
 F:	include/uapi/linux/isdn/
 
 ISDN SUBSYSTEM (Eicon active card driver)
 M:	Armin Schindler <mac@melware.de>
 L:	isdn4linux@listserv.isdn4linux.de (subscribers-only)
 W:	http://www.melware.de
 S:	Maintained
 F:	drivers/isdn/hardware/eicon/
 
 IT87 HARDWARE MONITORING DRIVER
 M:	Jean Delvare <jdelvare@suse.com>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	Documentation/hwmon/it87
 F:	drivers/hwmon/it87.c
 
 IT913X MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://palosaari.fi/linux/
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/anttip/media_tree.git
 S:	Maintained
 F:	drivers/media/tuners/it913x*
 
 IVTV VIDEO4LINUX DRIVER
 M:	Andy Walls <awalls@md.metrocast.net>
 L:	ivtv-devel@ivtvdriver.org (subscribers-only)
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 W:	http://www.ivtvdriver.org
 S:	Maintained
 F:	Documentation/media/v4l-drivers/ivtv*
 F:	drivers/media/pci/ivtv/
 F:	include/uapi/linux/ivtv*
 
 IX2505V MEDIA DRIVER
 M:	Malcolm Priestley <tvboxspy@gmail.com>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 S:	Maintained
 F:	drivers/media/dvb-frontends/ix2505v*
 
 JC42.4 TEMPERATURE SENSOR DRIVER
 M:	Guenter Roeck <linux@roeck-us.net>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	drivers/hwmon/jc42.c
 F:	Documentation/hwmon/jc42
 
 JFS FILESYSTEM
 M:	Dave Kleikamp <shaggy@kernel.org>
 L:	jfs-discussion@lists.sourceforge.net
 W:	http://jfs.sourceforge.net/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/shaggy/jfs-2.6.git
 S:	Maintained
 F:	Documentation/filesystems/jfs.txt
 F:	fs/jfs/
 
 JME NETWORK DRIVER
 M:	Guo-Fu Tseng <cooldavid@cooldavid.org>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/ethernet/jme.*
 
 JOURNALLING FLASH FILE SYSTEM V2 (JFFS2)
 M:	David Woodhouse <dwmw2@infradead.org>
 L:	linux-mtd@lists.infradead.org
 W:	http://www.linux-mtd.infradead.org/doc/jffs2.html
 S:	Maintained
 F:	fs/jffs2/
 F:	include/uapi/linux/jffs2.h
 
 JOURNALLING LAYER FOR BLOCK DEVICES (JBD2)
 M:	"Theodore Ts'o" <tytso@mit.edu>
 M:	Jan Kara <jack@suse.com>
 L:	linux-ext4@vger.kernel.org
 S:	Maintained
 F:	fs/jbd2/
 F:	include/linux/jbd2.h
 
 JPU V4L2 MEM2MEM DRIVER FOR RENESAS
 M:	Mikhail Ulyanov <mikhail.ulyanov@cogentembedded.com>
 L:	linux-media@vger.kernel.org
 S:	Maintained
 F:	drivers/media/platform/rcar_jpu.c
 
 JSM Neo PCI based serial card
 M:	Gabriel Krisman Bertazi <krisman@linux.vnet.ibm.com>
 L:	linux-serial@vger.kernel.org
 S:	Maintained
 F:	drivers/tty/serial/jsm/
 
 K10TEMP HARDWARE MONITORING DRIVER
 M:	Clemens Ladisch <clemens@ladisch.de>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	Documentation/hwmon/k10temp
 F:	drivers/hwmon/k10temp.c
 
 K8TEMP HARDWARE MONITORING DRIVER
 M:	Rudolf Marek <r.marek@assembler.cz>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	Documentation/hwmon/k8temp
 F:	drivers/hwmon/k8temp.c
 
 KASAN
 M:	Andrey Ryabinin <aryabinin@virtuozzo.com>
 R:	Alexander Potapenko <glider@google.com>
 R:	Dmitry Vyukov <dvyukov@google.com>
 L:	kasan-dev@googlegroups.com
 S:	Maintained
 F:	arch/*/include/asm/kasan.h
 F:	arch/*/mm/kasan_init*
 F:	Documentation/dev-tools/kasan.rst
 F:	include/linux/kasan*.h
 F:	lib/test_kasan.c
 F:	mm/kasan/
 F:	scripts/Makefile.kasan
 
 KCONFIG
 M:	"Yann E. MORIN" <yann.morin.1998@free.fr>
 L:	linux-kbuild@vger.kernel.org
 T:	git git://gitorious.org/linux-kconfig/linux-kconfig
 S:	Maintained
 F:	Documentation/kbuild/kconfig-language.txt
 F:	scripts/kconfig/
 
 KDUMP
 M:	Dave Young <dyoung@redhat.com>
 M:	Baoquan He <bhe@redhat.com>
 R:	Vivek Goyal <vgoyal@redhat.com>
 L:	kexec@lists.infradead.org
 W:	http://lse.sourceforge.net/kdump/
 S:	Maintained
 F:	Documentation/kdump/
 
 KEENE FM RADIO TRANSMITTER DRIVER
 M:	Hans Verkuil <hverkuil@xs4all.nl>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 W:	https://linuxtv.org
 S:	Maintained
 F:	drivers/media/radio/radio-keene*
 
 KERNEL AUTOMOUNTER v4 (AUTOFS4)
 M:	Ian Kent <raven@themaw.net>
 L:	autofs@vger.kernel.org
 S:	Maintained
 F:	fs/autofs4/
 
 KERNEL BUILD + files below scripts/ (unless maintained elsewhere)
 M:	Michal Marek <mmarek@suse.com>
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/mmarek/kbuild.git for-next
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/mmarek/kbuild.git rc-fixes
 L:	linux-kbuild@vger.kernel.org
 S:	Maintained
 F:	Documentation/kbuild/
 F:	Makefile
 F:	scripts/Makefile.*
 F:	scripts/basic/
 F:	scripts/mk*
 F:	scripts/package/
 
 KERNEL JANITORS
 L:	kernel-janitors@vger.kernel.org
 W:	http://kernelnewbies.org/KernelJanitors
 S:	Odd Fixes
 
 KERNEL NFSD, SUNRPC, AND LOCKD SERVERS
 M:	"J. Bruce Fields" <bfields@fieldses.org>
 M:	Jeff Layton <jlayton@poochiereds.net>
 L:	linux-nfs@vger.kernel.org
 W:	http://nfs.sourceforge.net/
 T:	git git://linux-nfs.org/~bfields/linux.git
 S:	Supported
 F:	fs/nfsd/
 F:	include/uapi/linux/nfsd/
 F:	fs/lockd/
 F:	fs/nfs_common/
 F:	net/sunrpc/
 F:	include/linux/lockd/
 F:	include/linux/sunrpc/
 F:	include/uapi/linux/sunrpc/
 
 KERNEL SELFTEST FRAMEWORK
 M:	Shuah Khan <shuahkh@osg.samsung.com>
 M:	Shuah Khan <shuah@kernel.org>
 L:	linux-kselftest@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/shuah/linux-kselftest
 S:	Maintained
 F:	tools/testing/selftests
 
 KERNEL VIRTUAL MACHINE (KVM)
 M:	Paolo Bonzini <pbonzini@redhat.com>
 M:	Radim KrÄmÃ¡Å <rkrcmar@redhat.com>
 L:	kvm@vger.kernel.org
 W:	http://www.linux-kvm.org
 T:	git git://git.kernel.org/pub/scm/virt/kvm/kvm.git
 S:	Supported
 F:	Documentation/*/kvm*.txt
 F:	Documentation/virtual/kvm/
 F:	arch/*/kvm/
 F:	arch/x86/kernel/kvm.c
 F:	arch/x86/kernel/kvmclock.c
 F:	arch/*/include/asm/kvm*
 F:	include/linux/kvm*
 F:	include/uapi/linux/kvm*
 F:	virt/kvm/
 F:	tools/kvm/
 
 KERNEL VIRTUAL MACHINE (KVM) FOR AMD-V
 M:	Joerg Roedel <joro@8bytes.org>
 L:	kvm@vger.kernel.org
 W:	http://www.linux-kvm.org/
 S:	Maintained
 F:	arch/x86/include/asm/svm.h
 F:	arch/x86/kvm/svm.c
 
 KERNEL VIRTUAL MACHINE (KVM) FOR POWERPC
 M:	Alexander Graf <agraf@suse.com>
 L:	kvm-ppc@vger.kernel.org
 W:	http://www.linux-kvm.org/
 T:	git git://github.com/agraf/linux-2.6.git
 S:	Supported
 F:	arch/powerpc/include/asm/kvm*
 F:	arch/powerpc/kvm/
 
 KERNEL VIRTUAL MACHINE for s390 (KVM/s390)
 M:	Christian Borntraeger <borntraeger@de.ibm.com>
 M:	Cornelia Huck <cornelia.huck@de.ibm.com>
 L:	linux-s390@vger.kernel.org
 W:	http://www.ibm.com/developerworks/linux/linux390/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/kvms390/linux.git
 S:	Supported
 F:	Documentation/s390/kvm.txt
 F:	arch/s390/include/asm/kvm*
 F:	arch/s390/kvm/
 
 KERNEL VIRTUAL MACHINE (KVM) FOR ARM
 M:	Christoffer Dall <christoffer.dall@linaro.org>
 M:	Marc Zyngier <marc.zyngier@arm.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 L:	kvmarm@lists.cs.columbia.edu
 W:	http://systems.cs.columbia.edu/projects/kvm-arm
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/kvmarm/kvmarm.git
 S:	Supported
 F:	arch/arm/include/uapi/asm/kvm*
 F:	arch/arm/include/asm/kvm*
 F:	arch/arm/kvm/
 F:	virt/kvm/arm/
 F:	include/kvm/arm_*
 
 KERNEL VIRTUAL MACHINE FOR ARM64 (KVM/arm64)
 M:	Christoffer Dall <christoffer.dall@linaro.org>
 M:	Marc Zyngier <marc.zyngier@arm.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 L:	kvmarm@lists.cs.columbia.edu
 S:	Maintained
 F:	arch/arm64/include/uapi/asm/kvm*
 F:	arch/arm64/include/asm/kvm*
 F:	arch/arm64/kvm/
 
 KERNEL VIRTUAL MACHINE FOR MIPS (KVM/mips)
 M:	James Hogan <james.hogan@imgtec.com>
 L:	linux-mips@linux-mips.org
 S:	Supported
 F:	arch/mips/include/uapi/asm/kvm*
 F:	arch/mips/include/asm/kvm*
 F:	arch/mips/kvm/
 
 KEXEC
 M:	Eric Biederman <ebiederm@xmission.com>
 W:	http://kernel.org/pub/linux/utils/kernel/kexec/
 L:	kexec@lists.infradead.org
 S:	Maintained
 F:	include/linux/kexec.h
 F:	include/uapi/linux/kexec.h
 F:	kernel/kexec*
 
 KEYS/KEYRINGS:
 M:	David Howells <dhowells@redhat.com>
 L:	keyrings@vger.kernel.org
 S:	Maintained
 F:	Documentation/security/keys.txt
 F:	include/linux/key.h
 F:	include/linux/key-type.h
 F:	include/linux/keyctl.h
 F:	include/uapi/linux/keyctl.h
 F:	include/keys/
 F:	security/keys/
 
 KEYS-TRUSTED
 M:	David Safford <safford@us.ibm.com>
 M:	Mimi Zohar <zohar@linux.vnet.ibm.com>
 L:	linux-security-module@vger.kernel.org
 L:	keyrings@vger.kernel.org
 S:	Supported
 F:	Documentation/security/keys-trusted-encrypted.txt
 F:	include/keys/trusted-type.h
 F:	security/keys/trusted.c
 F:	security/keys/trusted.h
 
 KEYS-ENCRYPTED
 M:	Mimi Zohar <zohar@linux.vnet.ibm.com>
 M:	David Safford <safford@us.ibm.com>
 L:	linux-security-module@vger.kernel.org
 L:	keyrings@vger.kernel.org
 S:	Supported
 F:	Documentation/security/keys-trusted-encrypted.txt
 F:	include/keys/encrypted-type.h
 F:	security/keys/encrypted-keys/
 
 KGDB / KDB /debug_core
 M:	Jason Wessel <jason.wessel@windriver.com>
 W:	http://kgdb.wiki.kernel.org/
 L:	kgdb-bugreport@lists.sourceforge.net
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/jwessel/kgdb.git
 S:	Maintained
 F:	Documentation/DocBook/kgdb.tmpl
 F:	drivers/misc/kgdbts.c
 F:	drivers/tty/serial/kgdboc.c
 F:	include/linux/kdb.h
 F:	include/linux/kgdb.h
 F:	kernel/debug/
 
 KMEMCHECK
 M:	Vegard Nossum <vegardno@ifi.uio.no>
 M:	Pekka Enberg <penberg@kernel.org>
 S:	Maintained
 F:	Documentation/dev-tools/kmemcheck.rst
 F:	arch/x86/include/asm/kmemcheck.h
 F:	arch/x86/mm/kmemcheck/
 F:	include/linux/kmemcheck.h
 F:	mm/kmemcheck.c
 
 KMEMLEAK
 M:	Catalin Marinas <catalin.marinas@arm.com>
 S:	Maintained
 F:	Documentation/dev-tools/kmemleak.rst
 F:	include/linux/kmemleak.h
 F:	mm/kmemleak.c
 F:	mm/kmemleak-test.c
 
 KPROBES
 M:	Ananth N Mavinakayanahalli <ananth@linux.vnet.ibm.com>
 M:	Anil S Keshavamurthy <anil.s.keshavamurthy@intel.com>
 M:	"David S. Miller" <davem@davemloft.net>
 M:	Masami Hiramatsu <mhiramat@kernel.org>
 S:	Maintained
 F:	Documentation/kprobes.txt
 F:	include/linux/kprobes.h
 F:	kernel/kprobes.c
 
 KS0108 LCD CONTROLLER DRIVER
 M:	Miguel Ojeda Sandonis <miguel.ojeda.sandonis@gmail.com>
 W:	http://miguelojeda.es/auxdisplay.htm
 W:	http://jair.lab.fi.uva.es/~migojed/auxdisplay.htm
 S:	Maintained
 F:	Documentation/auxdisplay/ks0108
 F:	drivers/auxdisplay/ks0108.c
 F:	include/linux/ks0108.h
 
 L3MDEV
 M:	David Ahern <dsa@cumulusnetworks.com>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	net/l3mdev
 F:	include/net/l3mdev.h
 
 LANTIQ MIPS ARCHITECTURE
 M:	John Crispin <john@phrozen.org>
 L:	linux-mips@linux-mips.org
 S:	Maintained
 F:	arch/mips/lantiq
 
 LAPB module
 L:	linux-x25@vger.kernel.org
 S:	Orphan
 F:	Documentation/networking/lapb-module.txt
 F:	include/*/lapb.h
 F:	net/lapb/
 
 LASI 53c700 driver for PARISC
 M:	"James E.J. Bottomley" <James.Bottomley@HansenPartnership.com>
 L:	linux-scsi@vger.kernel.org
 S:	Maintained
 F:	Documentation/scsi/53c700.txt
 F:	drivers/scsi/53c700*
 
 LED SUBSYSTEM
 M:	Richard Purdie <rpurdie@rpsys.net>
 M:	Jacek Anaszewski <jacek.anaszewski@gmail.com>
 M:	Pavel Machek <pavel@ucw.cz>
 L:	linux-leds@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/j.anaszewski/linux-leds.git
 S:	Maintained
 F:	Documentation/devicetree/bindings/leds/
 F:	drivers/leds/
 F:	include/linux/leds.h
 
 LEGACY EEPROM DRIVER
 M:	Jean Delvare <jdelvare@suse.com>
 S:	Maintained
 F:	Documentation/misc-devices/eeprom
 F:	drivers/misc/eeprom/eeprom.c
 
 LEGO USB Tower driver
 M:	Juergen Stuber <starblue@users.sourceforge.net>
 L:	legousb-devel@lists.sourceforge.net
 W:	http://legousb.sourceforge.net/
 S:	Maintained
 F:	drivers/usb/misc/legousbtower.c
 
 LG2160 MEDIA DRIVER
 M:	Michael Krufky <mkrufky@linuxtv.org>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://github.com/mkrufky
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/mkrufky/tuners.git
 S:	Maintained
 F:	drivers/media/dvb-frontends/lg2160.*
 
 LGDT3305 MEDIA DRIVER
 M:	Michael Krufky <mkrufky@linuxtv.org>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://github.com/mkrufky
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/mkrufky/tuners.git
 S:	Maintained
 F:	drivers/media/dvb-frontends/lgdt3305.*
 
 LGUEST
 M:	Rusty Russell <rusty@rustcorp.com.au>
 L:	lguest@lists.ozlabs.org
 W:	http://lguest.ozlabs.org/
 S:	Odd Fixes
 F:	arch/x86/include/asm/lguest*.h
 F:	arch/x86/lguest/
 F:	drivers/lguest/
 F:	include/linux/lguest*.h
 F:	tools/lguest/
 
 LIBATA SUBSYSTEM (Serial and Parallel ATA drivers)
 M:	Tejun Heo <tj@kernel.org>
 L:	linux-ide@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/tj/libata.git
 S:	Maintained
 F:	drivers/ata/
 F:	include/linux/ata.h
 F:	include/linux/libata.h
 F:	Documentation/devicetree/bindings/ata/
 
 LIBATA PATA ARASAN COMPACT FLASH CONTROLLER
 M:	Viresh Kumar <vireshk@kernel.org>
 L:	linux-ide@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/tj/libata.git
 S:	Maintained
 F:	include/linux/pata_arasan_cf_data.h
 F:	drivers/ata/pata_arasan_cf.c
 
 LIBATA PATA DRIVERS
 M:	Bartlomiej Zolnierkiewicz <b.zolnierkie@samsung.com>
 M:	Tejun Heo <tj@kernel.org>
 L:	linux-ide@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/tj/libata.git
 S:	Maintained
 F:	drivers/ata/pata_*.c
 F:	drivers/ata/ata_generic.c
 
 LIBATA SATA AHCI PLATFORM devices support
 M:	Hans de Goede <hdegoede@redhat.com>
 M:	Tejun Heo <tj@kernel.org>
 L:	linux-ide@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/tj/libata.git
 S:	Maintained
 F:	drivers/ata/ahci_platform.c
 F:	drivers/ata/libahci_platform.c
 F:	include/linux/ahci_platform.h
 
 LIBATA SATA PROMISE TX2/TX4 CONTROLLER DRIVER
 M:	Mikael Pettersson <mikpelinux@gmail.com>
 L:	linux-ide@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/tj/libata.git
 S:	Maintained
 F:	drivers/ata/sata_promise.*
 
 LIBLOCKDEP
 M:	Sasha Levin <sasha.levin@oracle.com>
 S:	Maintained
 F:	tools/lib/lockdep/
 
 LIBNVDIMM: NON-VOLATILE MEMORY DEVICE SUBSYSTEM
 M:	Dan Williams <dan.j.williams@intel.com>
 L:	linux-nvdimm@lists.01.org
 Q:	https://patchwork.kernel.org/project/linux-nvdimm/list/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/nvdimm/nvdimm.git
 S:	Supported
 F:	drivers/nvdimm/*
 F:	include/linux/nd.h
 F:	include/linux/libnvdimm.h
 F:	include/uapi/linux/ndctl.h
 
 LIBNVDIMM BLK: MMIO-APERTURE DRIVER
 M:	Ross Zwisler <ross.zwisler@linux.intel.com>
 L:	linux-nvdimm@lists.01.org
 Q:	https://patchwork.kernel.org/project/linux-nvdimm/list/
 S:	Supported
 F:	drivers/nvdimm/blk.c
 F:	drivers/nvdimm/region_devs.c
 F:	drivers/acpi/nfit*
 
 LIBNVDIMM BTT: BLOCK TRANSLATION TABLE
 M:	Vishal Verma <vishal.l.verma@intel.com>
 L:	linux-nvdimm@lists.01.org
 Q:	https://patchwork.kernel.org/project/linux-nvdimm/list/
 S:	Supported
 F:	drivers/nvdimm/btt*
 
 LIBNVDIMM PMEM: PERSISTENT MEMORY DRIVER
 M:	Ross Zwisler <ross.zwisler@linux.intel.com>
 L:	linux-nvdimm@lists.01.org
 Q:	https://patchwork.kernel.org/project/linux-nvdimm/list/
 S:	Supported
 F:	drivers/nvdimm/pmem.c
 F:	include/linux/pmem.h
 F:	arch/*/include/asm/pmem.h
 
 LIGHTNVM PLATFORM SUPPORT
 M:	Matias Bjorling <mb@lightnvm.io>
 W:	http://github/OpenChannelSSD
 L:	linux-block@vger.kernel.org
 S:	Maintained
 F:	drivers/lightnvm/
 F:	include/linux/lightnvm.h
 F:	include/uapi/linux/lightnvm.h
 
 LINUX FOR POWERPC (32-BIT AND 64-BIT)
 M:	Benjamin Herrenschmidt <benh@kernel.crashing.org>
 M:	Paul Mackerras <paulus@samba.org>
 M:	Michael Ellerman <mpe@ellerman.id.au>
 W:	https://github.com/linuxppc/linux/wiki
 L:	linuxppc-dev@lists.ozlabs.org
 Q:	http://patchwork.ozlabs.org/project/linuxppc-dev/list/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux.git
 S:	Supported
 F:	Documentation/powerpc/
 F:	arch/powerpc/
 F:	drivers/char/tpm/tpm_ibmvtpm*
 F:	drivers/crypto/nx/
 F:	drivers/crypto/vmx/
 F:	drivers/net/ethernet/ibm/ibmveth.*
 F:	drivers/net/ethernet/ibm/ibmvnic.*
 F:	drivers/pci/hotplug/pnv_php.c
 F:	drivers/pci/hotplug/rpa*
 F:	drivers/scsi/ibmvscsi/
 F:	tools/testing/selftests/powerpc
 N:	opal
 N:	/pmac
 N:	powermac
 N:	powernv
 N:	[^a-z0-9]ps3
 N:	pseries
 
 LINUX FOR POWER MACINTOSH
 M:	Benjamin Herrenschmidt <benh@kernel.crashing.org>
 W:	http://www.penguinppc.org/
 L:	linuxppc-dev@lists.ozlabs.org
 S:	Maintained
 F:	arch/powerpc/platforms/powermac/
 F:	drivers/macintosh/
 
 LINUX FOR POWERPC EMBEDDED MPC5XXX
 M:	Anatolij Gustschin <agust@denx.de>
 L:	linuxppc-dev@lists.ozlabs.org
 T:	git git://git.denx.de/linux-denx-agust.git
 S:	Maintained
 F:	arch/powerpc/platforms/512x/
 F:	arch/powerpc/platforms/52xx/
 
 LINUX FOR POWERPC EMBEDDED PPC4XX
 M:	Alistair Popple <alistair@popple.id.au>
 M:	Matt Porter <mporter@kernel.crashing.org>
 W:	http://www.penguinppc.org/
 L:	linuxppc-dev@lists.ozlabs.org
 S:	Maintained
 F:	arch/powerpc/platforms/40x/
 F:	arch/powerpc/platforms/44x/
 
 LINUX FOR POWERPC EMBEDDED XILINX VIRTEX
 L:	linuxppc-dev@lists.ozlabs.org
 S:	Orphan
 F:	arch/powerpc/*/*virtex*
 F:	arch/powerpc/*/*/*virtex*
 
 LINUX FOR POWERPC EMBEDDED PPC8XX
 M:	Vitaly Bordug <vitb@kernel.crashing.org>
 W:	http://www.penguinppc.org/
 L:	linuxppc-dev@lists.ozlabs.org
 S:	Maintained
 F:	arch/powerpc/platforms/8xx/
 
 LINUX FOR POWERPC EMBEDDED PPC83XX AND PPC85XX
 M:	Scott Wood <oss@buserror.net>
 M:	Kumar Gala <galak@kernel.crashing.org>
 W:	http://www.penguinppc.org/
 L:	linuxppc-dev@lists.ozlabs.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/scottwood/linux.git
 S:	Maintained
 F:	arch/powerpc/platforms/83xx/
 F:	arch/powerpc/platforms/85xx/
 
 LINUX FOR POWERPC PA SEMI PWRFICIENT
 L:	linuxppc-dev@lists.ozlabs.org
 S:	Orphan
 F:	arch/powerpc/platforms/pasemi/
 F:	drivers/*/*pasemi*
 F:	drivers/*/*/*pasemi*
 
 LINUX SECURITY MODULE (LSM) FRAMEWORK
 M:	Chris Wright <chrisw@sous-sol.org>
 L:	linux-security-module@vger.kernel.org
 S:	Supported
 
 LIS3LV02D ACCELEROMETER DRIVER
 M:	Eric Piel <eric.piel@tremplin-utc.net>
 S:	Maintained
 F:	Documentation/misc-devices/lis3lv02d
 F:	drivers/misc/lis3lv02d/
 F:	drivers/platform/x86/hp_accel.c
 
 LIVE PATCHING
 M:	Josh Poimboeuf <jpoimboe@redhat.com>
 M:	Jessica Yu <jeyu@redhat.com>
 M:	Jiri Kosina <jikos@kernel.org>
 M:	Miroslav Benes <mbenes@suse.cz>
 R:	Petr Mladek <pmladek@suse.com>
 S:	Maintained
 F:	kernel/livepatch/
 F:	include/linux/livepatch.h
 F:	arch/x86/include/asm/livepatch.h
 F:	arch/x86/kernel/livepatch.c
 F:	Documentation/livepatch/
 F:	Documentation/ABI/testing/sysfs-kernel-livepatch
 F:	samples/livepatch/
 L:	live-patching@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/jikos/livepatching.git
 
 LINUX KERNEL DUMP TEST MODULE (LKDTM)
 M:	Kees Cook <keescook@chromium.org>
 S:	Maintained
 F:	drivers/misc/lkdtm*
 
 LLC (802.2)
 L:	netdev@vger.kernel.org
 S:	Odd fixes
 F:	include/linux/llc.h
 F:	include/uapi/linux/llc.h
 F:	include/net/llc*
 F:	net/llc/
 
 LM73 HARDWARE MONITOR DRIVER
 M:	Guillaume Ligneul <guillaume.ligneul@gmail.com>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	drivers/hwmon/lm73.c
 
 LM78 HARDWARE MONITOR DRIVER
 M:	Jean Delvare <jdelvare@suse.com>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	Documentation/hwmon/lm78
 F:	drivers/hwmon/lm78.c
 
 LM83 HARDWARE MONITOR DRIVER
 M:	Jean Delvare <jdelvare@suse.com>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	Documentation/hwmon/lm83
 F:	drivers/hwmon/lm83.c
 
 LM90 HARDWARE MONITOR DRIVER
 M:	Jean Delvare <jdelvare@suse.com>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	Documentation/hwmon/lm90
 F:	Documentation/devicetree/bindings/hwmon/lm90.txt
 F:	drivers/hwmon/lm90.c
 F:	include/dt-bindings/thermal/lm90.h
 
 LM95234 HARDWARE MONITOR DRIVER
 M:	Guenter Roeck <linux@roeck-us.net>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	Documentation/hwmon/lm95234
 F:	drivers/hwmon/lm95234.c
 
 LME2510 MEDIA DRIVER
 M:	Malcolm Priestley <tvboxspy@gmail.com>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 S:	Maintained
 F:	drivers/media/usb/dvb-usb-v2/lmedm04*
 
 LOCKING PRIMITIVES
 M:	Peter Zijlstra <peterz@infradead.org>
 M:	Ingo Molnar <mingo@redhat.com>
 L:	linux-kernel@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip.git locking/core
 S:	Maintained
 F:	Documentation/locking/
 F:	include/linux/lockdep.h
 F:	include/linux/spinlock*.h
 F:	arch/*/include/asm/spinlock*.h
 F:	include/linux/rwlock*.h
 F:	include/linux/mutex*.h
 F:	arch/*/include/asm/mutex*.h
 F:	include/linux/rwsem*.h
 F:	arch/*/include/asm/rwsem.h
 F:	include/linux/seqlock.h
 F:	lib/locking*.[ch]
 F:	kernel/locking/
 
 LOGICAL DISK MANAGER SUPPORT (LDM, Windows 2000/XP/Vista Dynamic Disks)
 M:	"Richard Russon (FlatCap)" <ldm@flatcap.org>
 L:	linux-ntfs-dev@lists.sourceforge.net
 W:	http://www.linux-ntfs.org/content/view/19/37/
 S:	Maintained
 F:	Documentation/ldm.txt
 F:	block/partitions/ldm.*
 
 LSILOGIC MPT FUSION DRIVERS (FC/SAS/SPI)
 M:	Sathya Prakash <sathya.prakash@broadcom.com>
 M:	Chaitra P B <chaitra.basappa@broadcom.com>
 M:	Suganath Prabu Subramani <suganath-prabu.subramani@broadcom.com>
 L:	MPT-FusionLinux.pdl@broadcom.com
 L:	linux-scsi@vger.kernel.org
 W:	http://www.avagotech.com/support/
 S:	Supported
 F:	drivers/message/fusion/
 F:	drivers/scsi/mpt2sas/
 F:	drivers/scsi/mpt3sas/
 
 LSILOGIC/SYMBIOS/NCR 53C8XX and 53C1010 PCI-SCSI drivers
 M:	Matthew Wilcox <matthew@wil.cx>
 L:	linux-scsi@vger.kernel.org
 S:	Maintained
 F:	drivers/scsi/sym53c8xx_2/
 
 LTC4261 HARDWARE MONITOR DRIVER
 M:	Guenter Roeck <linux@roeck-us.net>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	Documentation/hwmon/ltc4261
 F:	drivers/hwmon/ltc4261.c
 
 LTP (Linux Test Project)
 M:	Mike Frysinger <vapier@gentoo.org>
 M:	Cyril Hrubis <chrubis@suse.cz>
 M:	Wanlong Gao <wanlong.gao@gmail.com>
 M:	Jan Stancek <jstancek@redhat.com>
 M:	Stanislav Kholmanskikh <stanislav.kholmanskikh@oracle.com>
 M:	Alexey Kodanev <alexey.kodanev@oracle.com>
 L:	ltp@lists.linux.it (subscribers-only)
 W:	http://linux-test-project.github.io/
 T:	git git://github.com/linux-test-project/ltp.git
 S:	Maintained
 
 M32R ARCHITECTURE
 W:	http://www.linux-m32r.org/
 S:	Orphan
 F:	arch/m32r/
 
 M68K ARCHITECTURE
 M:	Geert Uytterhoeven <geert@linux-m68k.org>
 L:	linux-m68k@lists.linux-m68k.org
 W:	http://www.linux-m68k.org/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/geert/linux-m68k.git
 S:	Maintained
 F:	arch/m68k/
 F:	drivers/zorro/
 
 M68K ON APPLE MACINTOSH
 M:	Joshua Thompson <funaho@jurai.org>
 W:	http://www.mac.linux-m68k.org/
 L:	linux-m68k@lists.linux-m68k.org
 S:	Maintained
 F:	arch/m68k/mac/
 
 M68K ON HP9000/300
 M:	Philip Blundell <philb@gnu.org>
 W:	http://www.tazenda.demon.co.uk/phil/linux-hp
 S:	Maintained
 F:	arch/m68k/hp300/
 
 M88DS3103 MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://palosaari.fi/linux/
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/anttip/media_tree.git
 S:	Maintained
 F:	drivers/media/dvb-frontends/m88ds3103*
 
 M88RS2000 MEDIA DRIVER
 M:	Malcolm Priestley <tvboxspy@gmail.com>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 S:	Maintained
 F:	drivers/media/dvb-frontends/m88rs2000*
 
 MA901 MASTERKIT USB FM RADIO DRIVER
 M:	Alexey Klimov <klimov.linux@gmail.com>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Maintained
 F:	drivers/media/radio/radio-ma901.c
 
 MAC80211
 M:	Johannes Berg <johannes@sipsolutions.net>
 L:	linux-wireless@vger.kernel.org
 W:	http://wireless.kernel.org/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/jberg/mac80211.git
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/jberg/mac80211-next.git
 S:	Maintained
 F:	Documentation/networking/mac80211-injection.txt
 F:	include/net/mac80211.h
 F:	net/mac80211/
 F:	drivers/net/wireless/mac80211_hwsim.[ch]
 
 MACVLAN DRIVER
 M:	Patrick McHardy <kaber@trash.net>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/macvlan.c
 F:	include/linux/if_macvlan.h
 
 MAILBOX API
 M:	Jassi Brar <jassisinghbrar@gmail.com>
 L:	linux-kernel@vger.kernel.org
 S:	Maintained
 F:	drivers/mailbox/
 F:	include/linux/mailbox_client.h
 F:	include/linux/mailbox_controller.h
 
 MAN-PAGES: MANUAL PAGES FOR LINUX -- Sections 2, 3, 4, 5, and 7
 M:	Michael Kerrisk <mtk.manpages@gmail.com>
 W:	http://www.kernel.org/doc/man-pages
 L:	linux-man@vger.kernel.org
 S:	Maintained
 
 MARDUK (CREATOR CI40) DEVICE TREE SUPPORT
 M:	Rahul Bedarkar <rahul.bedarkar@imgtec.com>
 L:	linux-mips@linux-mips.org
 S:	Maintained
 F:	arch/mips/boot/dts/img/pistachio_marduk.dts
 
 MARVELL 88E6XXX ETHERNET SWITCH FABRIC DRIVER
 M:	Andrew Lunn <andrew@lunn.ch>
 M:	Vivien Didelot <vivien.didelot@savoirfairelinux.com>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/dsa/mv88e6xxx/
 F:	Documentation/devicetree/bindings/net/dsa/marvell.txt
 
 MARVELL ARMADA DRM SUPPORT
 M:	Russell King <linux@armlinux.org.uk>
 S:	Maintained
 T:	git git://git.armlinux.org.uk/~rmk/linux-arm.git drm-armada-devel
 T:	git git://git.armlinux.org.uk/~rmk/linux-arm.git drm-armada-fixes
 F:	drivers/gpu/drm/armada/
 F:	include/uapi/drm/armada_drm.h
 F:	Documentation/devicetree/bindings/display/armada/
 
 MARVELL CRYPTO DRIVER
 M:	Boris Brezillon <boris.brezillon@free-electrons.com>
 M:	Arnaud Ebalard <arno@natisbad.org>
 F:	drivers/crypto/marvell/
 S:	Maintained
 L:	linux-crypto@vger.kernel.org
 
 MARVELL GIGABIT ETHERNET DRIVERS (skge/sky2)
 M:	Mirko Lindner <mlindner@marvell.com>
 M:	Stephen Hemminger <stephen@networkplumber.org>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/ethernet/marvell/sk*
 
 MARVELL LIBERTAS WIRELESS DRIVER
 L:	libertas-dev@lists.infradead.org
 S:	Orphan
 F:	drivers/net/wireless/marvell/libertas/
 
 MARVELL MV643XX ETHERNET DRIVER
 M:	Sebastian Hesselbarth <sebastian.hesselbarth@gmail.com>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/ethernet/marvell/mv643xx_eth.*
 F:	include/linux/mv643xx.h
 
 MARVELL MVNETA ETHERNET DRIVER
 M:	Thomas Petazzoni <thomas.petazzoni@free-electrons.com>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/ethernet/marvell/mvneta.*
 
 MARVELL MWIFIEX WIRELESS DRIVER
 M:	Amitkumar Karwar <akarwar@marvell.com>
 M:	Nishant Sarmukadam <nishants@marvell.com>
 L:	linux-wireless@vger.kernel.org
 S:	Maintained
 F:	drivers/net/wireless/marvell/mwifiex/
 
 MARVELL MWL8K WIRELESS DRIVER
 M:	Lennert Buytenhek <buytenh@wantstofly.org>
 L:	linux-wireless@vger.kernel.org
 S:	Odd Fixes
 F:	drivers/net/wireless/marvell/mwl8k.c
 
 MARVELL SOC MMC/SD/SDIO CONTROLLER DRIVER
 M:	Nicolas Pitre <nico@fluxnic.net>
 S:	Odd Fixes
 F:	drivers/mmc/host/mvsdio.*
 
 MATROX FRAMEBUFFER DRIVER
 L:	linux-fbdev@vger.kernel.org
 S:	Orphan
 F:	drivers/video/fbdev/matrox/matroxfb_*
 F:	include/uapi/linux/matroxfb.h
 
 MAX16065 HARDWARE MONITOR DRIVER
 M:	Guenter Roeck <linux@roeck-us.net>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	Documentation/hwmon/max16065
 F:	drivers/hwmon/max16065.c
 
 MAX20751 HARDWARE MONITOR DRIVER
 M:	Guenter Roeck <linux@roeck-us.net>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	Documentation/hwmon/max20751
 F:	drivers/hwmon/max20751.c
 
 MAX6650 HARDWARE MONITOR AND FAN CONTROLLER DRIVER
 L:	linux-hwmon@vger.kernel.org
 S:	Orphan
 F:	Documentation/hwmon/max6650
 F:	drivers/hwmon/max6650.c
 
 MAX6697 HARDWARE MONITOR DRIVER
 M:	Guenter Roeck <linux@roeck-us.net>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	Documentation/hwmon/max6697
 F:	Documentation/devicetree/bindings/i2c/max6697.txt
 F:	drivers/hwmon/max6697.c
 F:	include/linux/platform_data/max6697.h
 
 MAX9860 MONO AUDIO VOICE CODEC DRIVER
 M:	Peter Rosin <peda@axentia.se>
 L:	alsa-devel@alsa-project.org (moderated for non-subscribers)
 S:	Maintained
 F:	Documentation/devicetree/bindings/sound/max9860.txt
 F:	sound/soc/codecs/max9860.*
 
 MAXIM MUIC CHARGER DRIVERS FOR EXYNOS BASED BOARDS
 M:	Krzysztof Kozlowski <krzk@kernel.org>
 M:	Bartlomiej Zolnierkiewicz <b.zolnierkie@samsung.com>
 L:	linux-pm@vger.kernel.org
 S:	Supported
 F:	drivers/power/supply/max14577_charger.c
 F:	drivers/power/supply/max77693_charger.c
 
 MAXIM MAX77802 MULTIFUNCTION PMIC DEVICE DRIVERS
 M:	Javier Martinez Canillas <javier@osg.samsung.com>
 L:	linux-kernel@vger.kernel.org
 S:	Supported
 F:	drivers/*/*max77802*.c
 F:	Documentation/devicetree/bindings/*/*max77802.txt
 F:	include/dt-bindings/*/*max77802.h
 
 MAXIM PMIC AND MUIC DRIVERS FOR EXYNOS BASED BOARDS
 M:	Chanwoo Choi <cw00.choi@samsung.com>
 M:	Krzysztof Kozlowski <krzk@kernel.org>
 M:	Bartlomiej Zolnierkiewicz <b.zolnierkie@samsung.com>
 L:	linux-kernel@vger.kernel.org
 S:	Supported
 F:	drivers/*/max14577*.c
 F:	drivers/*/max77686*.c
 F:	drivers/*/max77693*.c
 F:	drivers/extcon/extcon-max14577.c
 F:	drivers/extcon/extcon-max77693.c
 F:	drivers/rtc/rtc-max77686.c
 F:	drivers/clk/clk-max77686.c
 F:	Documentation/devicetree/bindings/mfd/max14577.txt
 F:	Documentation/devicetree/bindings/*/max77686.txt
 F:	Documentation/devicetree/bindings/mfd/max77693.txt
 F:	Documentation/devicetree/bindings/clock/maxim,max77686.txt
 F:	include/linux/mfd/max14577*.h
 F:	include/linux/mfd/max77686*.h
 F:	include/linux/mfd/max77693*.h
 
 MAXIRADIO FM RADIO RECEIVER DRIVER
 M:	Hans Verkuil <hverkuil@xs4all.nl>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 W:	https://linuxtv.org
 S:	Maintained
 F:	drivers/media/radio/radio-maxiradio*
 
 MCP4531 MICROCHIP DIGITAL POTENTIOMETER DRIVER
 M:	Peter Rosin <peda@axentia.se>
 L:	linux-iio@vger.kernel.org
 S:	Maintained
 F:	Documentation/ABI/testing/sysfs-bus-iio-potentiometer-mcp4531
 F:	drivers/iio/potentiometer/mcp4531.c
 
 MEASUREMENT COMPUTING CIO-DAC IIO DRIVER
 M:	William Breathitt Gray <vilhelm.gray@gmail.com>
 L:	linux-iio@vger.kernel.org
 S:	Maintained
 F:	drivers/iio/dac/cio-dac.c
 
 MEDIA DRIVERS FOR RENESAS - FCP
 M:	Laurent Pinchart <laurent.pinchart@ideasonboard.com>
 L:	linux-media@vger.kernel.org
 L:	linux-renesas-soc@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Supported
 F:	Documentation/devicetree/bindings/media/renesas,fcp.txt
 F:	drivers/media/platform/rcar-fcp.c
 F:	include/media/rcar-fcp.h
 
 MEDIA DRIVERS FOR RENESAS - FDP1
 M:	Kieran Bingham <kieran@bingham.xyz>
 L:	linux-media@vger.kernel.org
 L:	linux-renesas-soc@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Supported
 F:	Documentation/devicetree/bindings/media/renesas,fdp1.txt
 F:	drivers/media/platform/rcar_fdp1.c
 
 MEDIA DRIVERS FOR RENESAS - VIN
 M:	Niklas SÃ¶derlund <niklas.soderlund@ragnatech.se>
 L:	linux-media@vger.kernel.org
 L:	linux-renesas-soc@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Supported
 F:	Documentation/devicetree/bindings/media/rcar_vin.txt
 F:	drivers/media/platform/rcar-vin/
 
 MEDIA DRIVERS FOR RENESAS - VSP1
 M:	Laurent Pinchart <laurent.pinchart@ideasonboard.com>
 L:	linux-media@vger.kernel.org
 L:	linux-renesas-soc@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Supported
 F:	Documentation/devicetree/bindings/media/renesas,vsp1.txt
 F:	drivers/media/platform/vsp1/
 
 MEDIA DRIVERS FOR HELENE
 M:	Abylay Ospan <aospan@netup.ru>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://netup.tv/
 T:	git git://linuxtv.org/media_tree.git
 S:	Supported
 F:	drivers/media/dvb-frontends/helene*
 
 MEDIA DRIVERS FOR ASCOT2E
 M:	Sergey Kozlov <serjk@netup.ru>
 M:	Abylay Ospan <aospan@netup.ru>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://netup.tv/
 T:	git git://linuxtv.org/media_tree.git
 S:	Supported
 F:	drivers/media/dvb-frontends/ascot2e*
 
 MEDIA DRIVERS FOR CXD2841ER
 M:	Sergey Kozlov <serjk@netup.ru>
 M:	Abylay Ospan <aospan@netup.ru>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://netup.tv/
 T:	git git://linuxtv.org/media_tree.git
 S:	Supported
 F:	drivers/media/dvb-frontends/cxd2841er*
 
 MEDIA DRIVERS FOR HORUS3A
 M:	Sergey Kozlov <serjk@netup.ru>
 M:	Abylay Ospan <aospan@netup.ru>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://netup.tv/
 T:	git git://linuxtv.org/media_tree.git
 S:	Supported
 F:	drivers/media/dvb-frontends/horus3a*
 
 MEDIA DRIVERS FOR LNBH25
 M:	Sergey Kozlov <serjk@netup.ru>
 M:	Abylay Ospan <aospan@netup.ru>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://netup.tv/
 T:	git git://linuxtv.org/media_tree.git
 S:	Supported
 F:	drivers/media/dvb-frontends/lnbh25*
 
 MEDIA DRIVERS FOR NETUP PCI UNIVERSAL DVB devices
 M:	Sergey Kozlov <serjk@netup.ru>
 M:	Abylay Ospan <aospan@netup.ru>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://netup.tv/
 T:	git git://linuxtv.org/media_tree.git
 S:	Supported
 F:	drivers/media/pci/netup_unidvb/*
 
 MEDIA INPUT INFRASTRUCTURE (V4L/DVB)
 M:	Mauro Carvalho Chehab <mchehab@s-opensource.com>
 M:	Mauro Carvalho Chehab <mchehab@kernel.org>
 P:	LinuxTV.org Project
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 Q:	http://patchwork.kernel.org/project/linux-media/list/
 T:	git git://linuxtv.org/media_tree.git
 S:	Maintained
 F:	Documentation/media/
 F:	drivers/media/
 F:	drivers/staging/media/
 F:	include/linux/platform_data/media/
 F:	include/media/
 F:	include/uapi/linux/dvb/
 F:	include/uapi/linux/videodev2.h
 F:	include/uapi/linux/media.h
 F:	include/uapi/linux/v4l2-*
 F:	include/uapi/linux/meye.h
 F:	include/uapi/linux/ivtv*
 F:	include/uapi/linux/uvcvideo.h
 
 MEDIATEK ETHERNET DRIVER
 M:	Felix Fietkau <nbd@openwrt.org>
 M:	John Crispin <blogic@openwrt.org>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/ethernet/mediatek/
 
 MEDIATEK MEDIA DRIVER
 M:	Tiffany Lin <tiffany.lin@mediatek.com>
 M:	Andrew-CT Chen <andrew-ct.chen@mediatek.com>
 S:	Supported
 F:	drivers/media/platform/mtk-vcodec/
 F:	drivers/media/platform/mtk-vpu/
 F:	Documentation/devicetree/bindings/media/mediatek-vcodec.txt
 F:	Documentation/devicetree/bindings/media/mediatek-vpu.txt
 
 MEDIATEK MDP DRIVER
 M:	Minghsiu Tsai <minghsiu.tsai@mediatek.com>
 M:	Houlong Wei <houlong.wei@mediatek.com>
 M:	Andrew-CT Chen <andrew-ct.chen@mediatek.com>
 S:	Supported
 F:	drivers/media/platform/mtk-mdp/
 F:	drivers/media/platform/mtk-vpu/
 F:	Documentation/devicetree/bindings/media/mediatek-mdp.txt
 
 MEDIATEK MT7601U WIRELESS LAN DRIVER
 M:	Jakub Kicinski <kubakici@wp.pl>
 L:	linux-wireless@vger.kernel.org
 S:	Maintained
 F:	drivers/net/wireless/mediatek/mt7601u/
 
 MEGARAID SCSI/SAS DRIVERS
 M:	Kashyap Desai <kashyap.desai@broadcom.com>
 M:	Sumit Saxena <sumit.saxena@broadcom.com>
 M:	Shivasharan S <shivasharan.srikanteshwara@broadcom.com>
 L:	megaraidlinux.pdl@broadcom.com
 L:	linux-scsi@vger.kernel.org
 W:	http://www.avagotech.com/support/
 S:	Maintained
 F:	Documentation/scsi/megaraid.txt
 F:	drivers/scsi/megaraid.*
 F:	drivers/scsi/megaraid/
 
 MELFAS MIP4 TOUCHSCREEN DRIVER
 M:	Sangwon Jee <jeesw@melfas.com>
 W:	http://www.melfas.com
 S:	Supported
 F:	drivers/input/touchscreen/melfas_mip4.c
 F:	Documentation/devicetree/bindings/input/touchscreen/melfas_mip4.txt
 
 MELLANOX ETHERNET DRIVER (mlx4_en)
 M:	Tariq Toukan <tariqt@mellanox.com>
 L:	netdev@vger.kernel.org
 S:	Supported
 W:	http://www.mellanox.com
 Q:	http://patchwork.ozlabs.org/project/netdev/list/
 F:	drivers/net/ethernet/mellanox/mlx4/en_*
 
 MELLANOX ETHERNET DRIVER (mlx5e)
 M:	Saeed Mahameed <saeedm@mellanox.com>
 L:	netdev@vger.kernel.org
 S:	Supported
 W:	http://www.mellanox.com
 Q:	http://patchwork.ozlabs.org/project/netdev/list/
 F:	drivers/net/ethernet/mellanox/mlx5/core/en_*
 
 MELLANOX ETHERNET SWITCH DRIVERS
 M:	Jiri Pirko <jiri@mellanox.com>
 M:	Ido Schimmel <idosch@mellanox.com>
 L:	netdev@vger.kernel.org
 S:	Supported
 W:	http://www.mellanox.com
 Q:	http://patchwork.ozlabs.org/project/netdev/list/
 F:	drivers/net/ethernet/mellanox/mlxsw/
 
 MELLANOX MLXCPLD I2C AND MUX DRIVER
 M:	Vadim Pasternak <vadimp@mellanox.com>
 M:	Michael Shych <michaelsh@mellanox.com>
 L:	linux-i2c@vger.kernel.org
 S:	Supported
 F:	drivers/i2c/busses/i2c-mlxcpld.c
 F:	drivers/i2c/muxes/i2c-mux-mlxcpld.c
 F:	Documentation/i2c/busses/i2c-mlxcpld
 
 MELLANOX MLXCPLD LED DRIVER
 M:	Vadim Pasternak <vadimp@mellanox.com>
 L:	linux-leds@vger.kernel.org
 S:	Supported
 F:	drivers/leds/leds-mlxcpld.c
 F:	Documentation/leds/leds-mlxcpld.txt
 
 MELLANOX PLATFORM DRIVER
 M:      Vadim Pasternak <vadimp@mellanox.com>
 L:      platform-driver-x86@vger.kernel.org
 S:      Supported
 F:      drivers/platform/x86/mlx-platform.c
 
 MELLANOX MLX CPLD HOTPLUG DRIVER
 M:	Vadim Pasternak <vadimp@mellanox.com>
 L:	platform-driver-x86@vger.kernel.org
 S:	Supported
 F:	drivers/platform/x86/mlxcpld-hotplug.c
 F:	include/linux/platform_data/mlxcpld-hotplug.h
 
 SOFT-ROCE DRIVER (rxe)
 M:	Moni Shoua <monis@mellanox.com>
 L:	linux-rdma@vger.kernel.org
 S:	Supported
 W:	https://github.com/SoftRoCE/rxe-dev/wiki/rxe-dev:-Home
 Q:	http://patchwork.kernel.org/project/linux-rdma/list/
 F:	drivers/infiniband/sw/rxe/
 F:	include/uapi/rdma/rdma_user_rxe.h
 
 MEMBARRIER SUPPORT
 M:	Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
 M:	"Paul E. McKenney" <paulmck@linux.vnet.ibm.com>
 L:	linux-kernel@vger.kernel.org
 S:	Supported
 F:	kernel/membarrier.c
 F:	include/uapi/linux/membarrier.h
 
 MEMORY MANAGEMENT
 L:	linux-mm@kvack.org
 W:	http://www.linux-mm.org
 S:	Maintained
 F:	include/linux/mm.h
 F:	include/linux/gfp.h
 F:	include/linux/mmzone.h
 F:	include/linux/memory_hotplug.h
 F:	include/linux/vmalloc.h
 F:	mm/
 
 MEMORY TECHNOLOGY DEVICES (MTD)
 M:	David Woodhouse <dwmw2@infradead.org>
 M:	Brian Norris <computersforpeace@gmail.com>
 M:	Boris Brezillon <boris.brezillon@free-electrons.com>
 M:	Marek Vasut <marek.vasut@gmail.com>
 M:	Richard Weinberger <richard@nod.at>
 M:	Cyrille Pitchen <cyrille.pitchen@atmel.com>
 L:	linux-mtd@lists.infradead.org
 W:	http://www.linux-mtd.infradead.org/
 Q:	http://patchwork.ozlabs.org/project/linux-mtd/list/
 T:	git git://git.infradead.org/linux-mtd.git
 T:	git git://git.infradead.org/l2-mtd.git
 S:	Maintained
 F:	Documentation/devicetree/bindings/mtd/
 F:	drivers/mtd/
 F:	include/linux/mtd/
 F:	include/uapi/mtd/
 
 MEN A21 WATCHDOG DRIVER
 M:	Johannes Thumshirn <morbidrsa@gmail.com>
 L:	linux-watchdog@vger.kernel.org
 S:	Maintained
 F:	drivers/watchdog/mena21_wdt.c
 
 MEN CHAMELEON BUS (mcb)
 M:	Johannes Thumshirn <morbidrsa@gmail.com>
 S:	Maintained
 F:	drivers/mcb/
 F:	include/linux/mcb.h
 F:	Documentation/men-chameleon-bus.txt
 
 MEN F21BMC (Board Management Controller)
 M:	Andreas Werner <andreas.werner@men.de>
 S:	Supported
 F:	drivers/mfd/menf21bmc.c
 F:	drivers/watchdog/menf21bmc_wdt.c
 F:	drivers/leds/leds-menf21bmc.c
 F:	drivers/hwmon/menf21bmc_hwmon.c
 F:	Documentation/hwmon/menf21bmc
 
 METAG ARCHITECTURE
 M:	James Hogan <james.hogan@imgtec.com>
 L:	linux-metag@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/jhogan/metag.git
 S:	Odd Fixes
 F:	arch/metag/
 F:	Documentation/metag/
 F:	Documentation/devicetree/bindings/metag/
 F:	Documentation/devicetree/bindings/interrupt-controller/img,*
 F:	drivers/clocksource/metag_generic.c
 F:	drivers/irqchip/irq-metag.c
 F:	drivers/irqchip/irq-metag-ext.c
 F:	drivers/tty/metag_da.c
 
 MICROBLAZE ARCHITECTURE
 M:	Michal Simek <monstr@monstr.eu>
 W:	http://www.monstr.eu/fdt/
 T:	git git://git.monstr.eu/linux-2.6-microblaze.git
 S:	Supported
 F:	arch/microblaze/
 
 MICROCHIP / ATMEL AT91 / AT32 SERIAL DRIVER
 M:	Richard Genoud <richard.genoud@gmail.com>
 S:	Maintained
 F:	drivers/tty/serial/atmel_serial.c
 F:	include/linux/atmel_serial.h
 
 MICROCHIP / ATMEL DMA DRIVER
 M:	Ludovic Desroches <ludovic.desroches@microchip.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 L:	dmaengine@vger.kernel.org
 S:	Supported
 F:	drivers/dma/at_hdmac.c
 F:	drivers/dma/at_hdmac_regs.h
 F:	include/linux/platform_data/dma-atmel.h
 
 MICROCHIP / ATMEL ISC DRIVER
 M:	Songjun Wu <songjun.wu@microchip.com>
 L:	linux-media@vger.kernel.org
 S:	Supported
 F:	drivers/media/platform/atmel/atmel-isc.c
 F:	drivers/media/platform/atmel/atmel-isc-regs.h
 F:	devicetree/bindings/media/atmel-isc.txt
 
 MICROCHIP USB251XB DRIVER
 M:	Richard Leitner <richard.leitner@skidata.com>
 L:	linux-usb@vger.kernel.org
 S:	Maintained
 F:	drivers/usb/misc/usb251xb.c
 F:	include/linux/platform_data/usb251xb.h
 F:	Documentation/devicetree/bindings/usb/usb251xb.txt
 
 MICROSOFT SURFACE PRO 3 BUTTON DRIVER
 M:	Chen Yu <yu.c.chen@intel.com>
 L:	platform-driver-x86@vger.kernel.org
 S:	Supported
 F:	drivers/platform/x86/surfacepro3_button.c
 
 MICROTEK X6 SCANNER
 M:	Oliver Neukum <oliver@neukum.org>
 S:	Maintained
 F:	drivers/usb/image/microtek.*
 
 MIPS
 M:	Ralf Baechle <ralf@linux-mips.org>
 L:	linux-mips@linux-mips.org
 W:	http://www.linux-mips.org/
 T:	git git://git.linux-mips.org/pub/scm/ralf/linux.git
 Q:	http://patchwork.linux-mips.org/project/linux-mips/list/
 S:	Supported
 F:	Documentation/devicetree/bindings/mips/
 F:	Documentation/mips/
 F:	arch/mips/
 
 MIPS/LOONGSON1 ARCHITECTURE
 M:	Keguang Zhang <keguang.zhang@gmail.com>
 L:	linux-mips@linux-mips.org
 S:	Maintained
 F:	arch/mips/loongson32/
 F:	arch/mips/include/asm/mach-loongson32/
 F:	drivers/*/*loongson1*
 F:	drivers/*/*/*loongson1*
 
 MIROSOUND PCM20 FM RADIO RECEIVER DRIVER
 M:	Hans Verkuil <hverkuil@xs4all.nl>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 W:	https://linuxtv.org
 S:	Odd Fixes
 F:	drivers/media/radio/radio-miropcm20*
 
 MELLANOX MLX4 core VPI driver
 M:	Yishai Hadas <yishaih@mellanox.com>
 L:	netdev@vger.kernel.org
 L:	linux-rdma@vger.kernel.org
 W:	http://www.mellanox.com
 Q:	http://patchwork.ozlabs.org/project/netdev/list/
 S:	Supported
 F:	drivers/net/ethernet/mellanox/mlx4/
 F:	include/linux/mlx4/
 F:	include/uapi/rdma/mlx4-abi.h
 
 MELLANOX MLX4 IB driver
 M:	Yishai Hadas <yishaih@mellanox.com>
 L:	linux-rdma@vger.kernel.org
 W:	http://www.mellanox.com
 Q:	http://patchwork.kernel.org/project/linux-rdma/list/
 S:	Supported
 F:	drivers/infiniband/hw/mlx4/
 F:	include/linux/mlx4/
 
 MELLANOX MLX5 core VPI driver
 M:	Saeed Mahameed <saeedm@mellanox.com>
 M:	Matan Barak <matanb@mellanox.com>
 M:	Leon Romanovsky <leonro@mellanox.com>
 L:	netdev@vger.kernel.org
 L:	linux-rdma@vger.kernel.org
 W:	http://www.mellanox.com
 Q:	http://patchwork.ozlabs.org/project/netdev/list/
 S:	Supported
 F:	drivers/net/ethernet/mellanox/mlx5/core/
 F:	include/linux/mlx5/
 F:	include/uapi/rdma/mlx5-abi.h
 
 MELLANOX MLX5 IB driver
 M:	Matan Barak <matanb@mellanox.com>
 M:	Leon Romanovsky <leonro@mellanox.com>
 L:	linux-rdma@vger.kernel.org
 W:	http://www.mellanox.com
 Q:	http://patchwork.kernel.org/project/linux-rdma/list/
 S:	Supported
 F:	drivers/infiniband/hw/mlx5/
 F:	include/linux/mlx5/
 
 MELEXIS MLX90614 DRIVER
 M:	Crt Mori <cmo@melexis.com>
 L:	linux-iio@vger.kernel.org
 W:	http://www.melexis.com
 S:	Supported
 F:	drivers/iio/temperature/mlx90614.c
 
 MICROSEMI SMART ARRAY SMARTPQI DRIVER (smartpqi)
 M:	Don Brace <don.brace@microsemi.com>
 L:	esc.storagedev@microsemi.com
 L:	linux-scsi@vger.kernel.org
 S:	Supported
 F:	drivers/scsi/smartpqi/smartpqi*.[ch]
 F:	drivers/scsi/smartpqi/Kconfig
 F:	drivers/scsi/smartpqi/Makefile
 F:	include/linux/cciss*.h
 F:	include/uapi/linux/cciss*.h
 F:	Documentation/scsi/smartpqi.txt
 
 MN88472 MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://palosaari.fi/linux/
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 S:	Maintained
 F:	drivers/media/dvb-frontends/mn88472*
 
 MN88473 MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://palosaari.fi/linux/
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 S:	Maintained
 F:	drivers/media/dvb-frontends/mn88473*
 
 MODULE SUPPORT
 M:	Jessica Yu <jeyu@redhat.com>
 M:	Rusty Russell <rusty@rustcorp.com.au>
 S:	Maintained
 F:	include/linux/module.h
 F:	kernel/module.c
 
 MOTION EYE VAIO PICTUREBOOK CAMERA DRIVER
 W:	http://popies.net/meye/
 S:	Orphan
 F:	Documentation/media/v4l-drivers/meye*
 F:	drivers/media/pci/meye/
 F:	include/uapi/linux/meye.h
 
 MOXA SMARTIO/INDUSTIO/INTELLIO SERIAL CARD
 M:	Jiri Slaby <jirislaby@gmail.com>
 S:	Maintained
 F:	Documentation/serial/moxa-smartio
 F:	drivers/tty/mxser.*
 
 MR800 AVERMEDIA USB FM RADIO DRIVER
 M:	Alexey Klimov <klimov.linux@gmail.com>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Maintained
 F:	drivers/media/radio/radio-mr800.c
 
 MRF24J40 IEEE 802.15.4 RADIO DRIVER
 M:	Alan Ott <alan@signal11.us>
 L:	linux-wpan@vger.kernel.org
 S:	Maintained
 F:	drivers/net/ieee802154/mrf24j40.c
 F:	Documentation/devicetree/bindings/net/ieee802154/mrf24j40.txt
 
 MSI LAPTOP SUPPORT
 M:	"Lee, Chun-Yi" <jlee@suse.com>
 L:	platform-driver-x86@vger.kernel.org
 S:	Maintained
 F:	drivers/platform/x86/msi-laptop.c
 
 MSI WMI SUPPORT
 L:	platform-driver-x86@vger.kernel.org
 S:	Orphan
 F:	drivers/platform/x86/msi-wmi.c
 
 MSI001 MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://palosaari.fi/linux/
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/anttip/media_tree.git
 S:	Maintained
 F:	drivers/media/tuners/msi001*
 
 MSI2500 MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://palosaari.fi/linux/
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/anttip/media_tree.git
 S:	Maintained
 F:	drivers/media/usb/msi2500/
 
 MSYSTEMS DISKONCHIP G3 MTD DRIVER
 M:	Robert Jarzmik <robert.jarzmik@free.fr>
 L:	linux-mtd@lists.infradead.org
 S:	Maintained
 F:	drivers/mtd/devices/docg3*
 
 MT9M032 APTINA SENSOR DRIVER
 M:	Laurent Pinchart <laurent.pinchart@ideasonboard.com>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Maintained
 F:	drivers/media/i2c/mt9m032.c
 F:	include/media/i2c/mt9m032.h
 
 MT9P031 APTINA CAMERA SENSOR
 M:	Laurent Pinchart <laurent.pinchart@ideasonboard.com>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Maintained
 F:	drivers/media/i2c/mt9p031.c
 F:	include/media/i2c/mt9p031.h
 
 MT9T001 APTINA CAMERA SENSOR
 M:	Laurent Pinchart <laurent.pinchart@ideasonboard.com>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Maintained
 F:	drivers/media/i2c/mt9t001.c
 F:	include/media/i2c/mt9t001.h
 
 MT9V032 APTINA CAMERA SENSOR
 M:	Laurent Pinchart <laurent.pinchart@ideasonboard.com>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Maintained
 F:	Documentation/devicetree/bindings/media/i2c/mt9v032.txt
 F:	drivers/media/i2c/mt9v032.c
 F:	include/media/i2c/mt9v032.h
 
 MULTIFUNCTION DEVICES (MFD)
 M:	Lee Jones <lee.jones@linaro.org>
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/lee/mfd.git
 S:	Supported
 F:	Documentation/devicetree/bindings/mfd/
 F:	drivers/mfd/
 F:	include/linux/mfd/
 
 MULTIMEDIA CARD (MMC), SECURE DIGITAL (SD) AND SDIO SUBSYSTEM
 M:	Ulf Hansson <ulf.hansson@linaro.org>
 L:	linux-mmc@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/ulfh/mmc.git
 S:	Maintained
 F:	Documentation/devicetree/bindings/mmc/
 F:	drivers/mmc/
 F:	include/linux/mmc/
 F:	include/uapi/linux/mmc/
 
 MULTIMEDIA CARD (MMC) ETC. OVER SPI
 S:	Orphan
 F:	drivers/mmc/host/mmc_spi.c
 F:	include/linux/spi/mmc_spi.h
 
 MULTISOUND SOUND DRIVER
 M:	Andrew Veliath <andrewtv@usa.net>
 S:	Maintained
 F:	Documentation/sound/oss/MultiSound
 F:	sound/oss/msnd*
 
 MULTITECH MULTIPORT CARD (ISICOM)
 S:	Orphan
 F:	drivers/tty/isicom.c
 F:	include/linux/isicom.h
 
 MUSB MULTIPOINT HIGH SPEED DUAL-ROLE CONTROLLER
 M:	Bin Liu <b-liu@ti.com>
 L:	linux-usb@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/balbi/usb.git
 S:	Maintained
 F:	drivers/usb/musb/
 
 MXL5007T MEDIA DRIVER
 M:	Michael Krufky <mkrufky@linuxtv.org>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://github.com/mkrufky
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/mkrufky/tuners.git
 S:	Maintained
 F:	drivers/media/tuners/mxl5007t.*
 
 MXSFB DRM DRIVER
 M:	Marek Vasut <marex@denx.de>
 S:	Supported
 F:	drivers/gpu/drm/mxsfb/
 F:	Documentation/devicetree/bindings/display/mxsfb-drm.txt
 
 MYRICOM MYRI-10G 10GbE DRIVER (MYRI10GE)
 M:	Hyong-Youb Kim <hykim@myri.com>
 L:	netdev@vger.kernel.org
 W:	https://www.myricom.com/support/downloads/myri10ge.html
 S:	Supported
 F:	drivers/net/ethernet/myricom/myri10ge/
 
 NAND FLASH SUBSYSTEM
 M:	Boris Brezillon <boris.brezillon@free-electrons.com>
 R:	Richard Weinberger <richard@nod.at>
 L:	linux-mtd@lists.infradead.org
 W:	http://www.linux-mtd.infradead.org/
 Q:	http://patchwork.ozlabs.org/project/linux-mtd/list/
 T:	git git://github.com/linux-nand/linux.git
 S:	Maintained
 F:	drivers/mtd/nand/
 F:	include/linux/mtd/nand*.h
 
 NATSEMI ETHERNET DRIVER (DP8381x)
 S:	Orphan
 F:	drivers/net/ethernet/natsemi/natsemi.c
 
 NATIVE INSTRUMENTS USB SOUND INTERFACE DRIVER
 M:	Daniel Mack <zonque@gmail.com>
 S:	Maintained
 L:	alsa-devel@alsa-project.org (moderated for non-subscribers)
 W:	http://www.native-instruments.com
 F:	sound/usb/caiaq/
 
 NCP FILESYSTEM
 M:	Petr Vandrovec <petr@vandrovec.name>
 S:	Odd Fixes
 F:	fs/ncpfs/
 
 NCR 5380 SCSI DRIVERS
 M:	Finn Thain <fthain@telegraphics.com.au>
 M:	Michael Schmitz <schmitzmic@gmail.com>
 L:	linux-scsi@vger.kernel.org
 S:	Maintained
 F:	Documentation/scsi/g_NCR5380.txt
 F:	drivers/scsi/NCR5380.*
 F:	drivers/scsi/arm/cumana_1.c
 F:	drivers/scsi/arm/oak.c
 F:	drivers/scsi/atari_scsi.*
 F:	drivers/scsi/dmx3191d.c
 F:	drivers/scsi/g_NCR5380.*
 F:	drivers/scsi/mac_scsi.*
 F:	drivers/scsi/sun3_scsi.*
 F:	drivers/scsi/sun3_scsi_vme.c
 
 NCR DUAL 700 SCSI DRIVER (MICROCHANNEL)
 M:	"James E.J. Bottomley" <James.Bottomley@HansenPartnership.com>
 L:	linux-scsi@vger.kernel.org
 S:	Maintained
 F:	drivers/scsi/NCR_D700.*
 
 NCT6775 HARDWARE MONITOR DRIVER
 M:	Guenter Roeck <linux@roeck-us.net>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	Documentation/hwmon/nct6775
 F:	drivers/hwmon/nct6775.c
 
 NETEFFECT IWARP RNIC DRIVER (IW_NES)
 M:	Faisal Latif <faisal.latif@intel.com>
 L:	linux-rdma@vger.kernel.org
 W:	http://www.intel.com/Products/Server/Adapters/Server-Cluster/Server-Cluster-overview.htm
 S:	Supported
 F:	drivers/infiniband/hw/nes/
 F:	include/uapi/rdma/nes-abi.h
 
 NETEM NETWORK EMULATOR
 M:	Stephen Hemminger <stephen@networkplumber.org>
 L:	netem@lists.linux-foundation.org (moderated for non-subscribers)
 S:	Maintained
 F:	net/sched/sch_netem.c
 
 NETERION 10GbE DRIVERS (s2io/vxge)
 M:	Jon Mason <jdmason@kudzu.us>
 L:	netdev@vger.kernel.org
 S:	Supported
 F:	Documentation/networking/s2io.txt
 F:	Documentation/networking/vxge.txt
 F:	drivers/net/ethernet/neterion/
 
 NETFILTER
 M:	Pablo Neira Ayuso <pablo@netfilter.org>
 M:	Jozsef Kadlecsik <kadlec@blackhole.kfki.hu>
 L:	netfilter-devel@vger.kernel.org
 L:	coreteam@netfilter.org
 W:	http://www.netfilter.org/
 W:	http://www.iptables.org/
 Q:	http://patchwork.ozlabs.org/project/netfilter-devel/list/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/pablo/nf.git
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/pablo/nf-next.git
 S:	Supported
 F:	include/linux/netfilter*
 F:	include/linux/netfilter/
 F:	include/net/netfilter/
 F:	include/uapi/linux/netfilter*
 F:	include/uapi/linux/netfilter/
 F:	net/*/netfilter.c
 F:	net/*/netfilter/
 F:	net/netfilter/
 F:	net/bridge/br_netfilter*.c
 
 NETLABEL
 M:	Paul Moore <paul@paul-moore.com>
 W:	http://netlabel.sf.net
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	Documentation/netlabel/
 F:	include/net/netlabel.h
 F:	net/netlabel/
 
 NETROM NETWORK LAYER
 M:	Ralf Baechle <ralf@linux-mips.org>
 L:	linux-hams@vger.kernel.org
 W:	http://www.linux-ax25.org/
 S:	Maintained
 F:	include/net/netrom.h
 F:	include/uapi/linux/netrom.h
 F:	net/netrom/
 
 NETRONOME ETHERNET DRIVERS
 M:	Jakub Kicinski <jakub.kicinski@netronome.com>
 L:	oss-drivers@netronome.com
 S:	Maintained
 F:	drivers/net/ethernet/netronome/
 
 NETWORK BLOCK DEVICE (NBD)
 M:	Josef Bacik <jbacik@fb.com>
 S:	Maintained
 L:	linux-block@vger.kernel.org
 L:	nbd-general@lists.sourceforge.net
 F:	Documentation/blockdev/nbd.txt
 F:	drivers/block/nbd.c
 F:	include/uapi/linux/nbd.h
 
 NETWORK DROP MONITOR
 M:	Neil Horman <nhorman@tuxdriver.com>
 L:	netdev@vger.kernel.org
 S:	Maintained
 W:	https://fedorahosted.org/dropwatch/
 F:	net/core/drop_monitor.c
 
 NETWORKING [DSA]
 M:	Andrew Lunn <andrew@lunn.ch>
 M:	Vivien Didelot <vivien.didelot@savoirfairelinux.com>
 M:	Florian Fainelli <f.fainelli@gmail.com>
 S:	Maintained
 F:	net/dsa/
 F:	include/net/dsa.h
 F:	drivers/net/dsa/
 
 NETWORKING [GENERAL]
 M:	"David S. Miller" <davem@davemloft.net>
 L:	netdev@vger.kernel.org
 W:	http://www.linuxfoundation.org/en/Net
 Q:	http://patchwork.ozlabs.org/project/netdev/list/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/davem/net.git
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next.git
 S:	Maintained
 F:	net/
 F:	include/net/
 F:	include/linux/in.h
 F:	include/linux/net.h
 F:	include/linux/netdevice.h
 F:	include/uapi/linux/in.h
 F:	include/uapi/linux/net.h
 F:	include/uapi/linux/netdevice.h
 F:	include/uapi/linux/net_namespace.h
 F:	tools/net/
 F:	tools/testing/selftests/net/
 F:	lib/random32.c
 
 NETWORKING [IPv4/IPv6]
 M:	"David S. Miller" <davem@davemloft.net>
 M:	Alexey Kuznetsov <kuznet@ms2.inr.ac.ru>
 M:	James Morris <jmorris@namei.org>
 M:	Hideaki YOSHIFUJI <yoshfuji@linux-ipv6.org>
 M:	Patrick McHardy <kaber@trash.net>
 L:	netdev@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/davem/net.git
 S:	Maintained
 F:	net/ipv4/
 F:	net/ipv6/
 F:	include/net/ip*
 F:	arch/x86/net/*
 
 NETWORKING [IPSEC]
 M:	Steffen Klassert <steffen.klassert@secunet.com>
 M:	Herbert Xu <herbert@gondor.apana.org.au>
 M:	"David S. Miller" <davem@davemloft.net>
 L:	netdev@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/klassert/ipsec.git
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/klassert/ipsec-next.git
 S:	Maintained
 F:	net/core/flow.c
 F:	net/xfrm/
 F:	net/key/
 F:	net/ipv4/xfrm*
 F:	net/ipv4/esp4.c
 F:	net/ipv4/ah4.c
 F:	net/ipv4/ipcomp.c
 F:	net/ipv4/ip_vti.c
 F:	net/ipv6/xfrm*
 F:	net/ipv6/esp6.c
 F:	net/ipv6/ah6.c
 F:	net/ipv6/ipcomp6.c
 F:	net/ipv6/ip6_vti.c
 F:	include/uapi/linux/xfrm.h
 F:	include/net/xfrm.h
 
 NETWORKING [LABELED] (NetLabel, CIPSO, Labeled IPsec, SECMARK)
 M:	Paul Moore <paul@paul-moore.com>
 L:	netdev@vger.kernel.org
 S:	Maintained
 
 NETWORKING [WIRELESS]
 L:	linux-wireless@vger.kernel.org
 Q:	http://patchwork.kernel.org/project/linux-wireless/list/
 
 NETWORKING DRIVERS
 L:	netdev@vger.kernel.org
 W:	http://www.linuxfoundation.org/en/Net
 Q:	http://patchwork.ozlabs.org/project/netdev/list/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/davem/net.git
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next.git
 S:	Odd Fixes
 F:	Documentation/devicetree/bindings/net/
 F:	drivers/net/
 F:	include/linux/if_*
 F:	include/linux/netdevice.h
 F:	include/linux/etherdevice.h
 F:	include/linux/fcdevice.h
 F:	include/linux/fddidevice.h
 F:	include/linux/hippidevice.h
 F:	include/linux/inetdevice.h
 F:	include/uapi/linux/if_*
 F:	include/uapi/linux/netdevice.h
 
 NETWORKING DRIVERS (WIRELESS)
 M:	Kalle Valo <kvalo@codeaurora.org>
 L:	linux-wireless@vger.kernel.org
 Q:	http://patchwork.kernel.org/project/linux-wireless/list/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/kvalo/wireless-drivers.git
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/kvalo/wireless-drivers-next.git
 S:	Maintained
 F:	Documentation/devicetree/bindings/net/wireless/
 F:	drivers/net/wireless/
 
 NETXEN (1/10) GbE SUPPORT
 M:	Manish Chopra <manish.chopra@cavium.com>
 M:	Rahul Verma <rahul.verma@cavium.com>
 M:	Dept-GELinuxNICDev@cavium.com
 L:	netdev@vger.kernel.org
 S:	Supported
 F:	drivers/net/ethernet/qlogic/netxen/
 
 NFC SUBSYSTEM
 M:	Lauro Ramos Venancio <lauro.venancio@openbossa.org>
 M:	Aloisio Almeida Jr <aloisio.almeida@openbossa.org>
 M:	Samuel Ortiz <sameo@linux.intel.com>
 L:	linux-wireless@vger.kernel.org
 L:	linux-nfc@lists.01.org (subscribers-only)
 S:	Supported
 F:	net/nfc/
 F:	include/net/nfc/
 F:	include/uapi/linux/nfc.h
 F:	drivers/nfc/
 F:	include/linux/platform_data/nfcmrvl.h
 F:	include/linux/platform_data/nxp-nci.h
 F:	include/linux/platform_data/pn544.h
 F:	include/linux/platform_data/st21nfca.h
 F:	include/linux/platform_data/st-nci.h
 F:	Documentation/devicetree/bindings/net/nfc/
 
 NFS, SUNRPC, AND LOCKD CLIENTS
 M:	Trond Myklebust <trond.myklebust@primarydata.com>
 M:	Anna Schumaker <anna.schumaker@netapp.com>
 L:	linux-nfs@vger.kernel.org
 W:	http://client.linux-nfs.org
 T:	git git://git.linux-nfs.org/projects/trondmy/linux-nfs.git
 S:	Maintained
 F:	fs/lockd/
 F:	fs/nfs/
 F:	fs/nfs_common/
 F:	net/sunrpc/
 F:	include/linux/lockd/
 F:	include/linux/nfs*
 F:	include/linux/sunrpc/
 F:	include/uapi/linux/nfs*
 F:	include/uapi/linux/sunrpc/
 
 NILFS2 FILESYSTEM
 M:	Ryusuke Konishi <konishi.ryusuke@lab.ntt.co.jp>
 L:	linux-nilfs@vger.kernel.org
 W:	http://nilfs.sourceforge.net/
 W:	http://nilfs.osdn.jp/
 T:	git git://github.com/konis/nilfs2.git
 S:	Supported
 F:	Documentation/filesystems/nilfs2.txt
 F:	fs/nilfs2/
 F:	include/trace/events/nilfs2.h
 F:	include/uapi/linux/nilfs2_api.h
 F:	include/uapi/linux/nilfs2_ondisk.h
 
 NINJA SCSI-3 / NINJA SCSI-32Bi (16bit/CardBus) PCMCIA SCSI HOST ADAPTER DRIVER
 M:	YOKOTA Hiroshi <yokota@netlab.is.tsukuba.ac.jp>
 W:	http://www.netlab.is.tsukuba.ac.jp/~yokota/izumi/ninja/
 S:	Maintained
 F:	Documentation/scsi/NinjaSCSI.txt
 F:	drivers/scsi/pcmcia/nsp_*
 
 NINJA SCSI-32Bi/UDE PCI/CARDBUS SCSI HOST ADAPTER DRIVER
 M:	GOTO Masanori <gotom@debian.or.jp>
 M:	YOKOTA Hiroshi <yokota@netlab.is.tsukuba.ac.jp>
 W:	http://www.netlab.is.tsukuba.ac.jp/~yokota/izumi/ninja/
 S:	Maintained
 F:	Documentation/scsi/NinjaSCSI.txt
 F:	drivers/scsi/nsp32*
 
 NIOS2 ARCHITECTURE
 M:	Ley Foon Tan <lftan@altera.com>
 L:	nios2-dev@lists.rocketboards.org (moderated for non-subscribers)
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/lftan/nios2.git
 S:	Maintained
 F:	arch/nios2/
 
 NOKIA N900 CAMERA SUPPORT (ET8EK8 SENSOR, AD5820 FOCUS)
 M:	Pavel Machek <pavel@ucw.cz>
 M:	Sakari Ailus <sakari.ailus@iki.fi>
 L:	linux-media@vger.kernel.org
 S:	Maintained
 F:	drivers/media/i2c/et8ek8
 F:	drivers/media/i2c/ad5820.c
 
 NOKIA N900 CAMERA SUPPORT (ET8EK8 SENSOR, AD5820 FOCUS)
 M:	Pavel Machek <pavel@ucw.cz>
 M:	Sakari Ailus <sakari.ailus@iki.fi>
 L:	linux-media@vger.kernel.org
 S:	Maintained
 F:	drivers/media/i2c/et8ek8
 F:	drivers/media/i2c/ad5820.c
 
 NOKIA N900 POWER SUPPLY DRIVERS
 R:	Pali RohÃ¡r <pali.rohar@gmail.com>
 F:	include/linux/power/bq2415x_charger.h
 F:	include/linux/power/bq27xxx_battery.h
 F:	include/linux/power/isp1704_charger.h
 F:	drivers/power/supply/bq2415x_charger.c
 F:	drivers/power/supply/bq27xxx_battery.c
 F:	drivers/power/supply/bq27xxx_battery_i2c.c
 F:	drivers/power/supply/isp1704_charger.c
 F:	drivers/power/supply/rx51_battery.c
 
 NTB DRIVER CORE
 M:	Jon Mason <jdmason@kudzu.us>
 M:	Dave Jiang <dave.jiang@intel.com>
 M:	Allen Hubbe <Allen.Hubbe@emc.com>
 L:	linux-ntb@googlegroups.com
 S:	Supported
 W:	https://github.com/jonmason/ntb/wiki
 T:	git git://github.com/jonmason/ntb.git
 F:	drivers/ntb/
 F:	drivers/net/ntb_netdev.c
 F:	include/linux/ntb.h
 F:	include/linux/ntb_transport.h
 F:	tools/testing/selftests/ntb/
 
 NTB INTEL DRIVER
 M:	Jon Mason <jdmason@kudzu.us>
 M:	Dave Jiang <dave.jiang@intel.com>
 L:	linux-ntb@googlegroups.com
 S:	Supported
 W:	https://github.com/jonmason/ntb/wiki
 T:	git git://github.com/jonmason/ntb.git
 F:	drivers/ntb/hw/intel/
 
 NTB AMD DRIVER
 M:	Shyam Sundar S K <Shyam-sundar.S-k@amd.com>
 L:	linux-ntb@googlegroups.com
 S:	Supported
 F:	drivers/ntb/hw/amd/
 
 NTFS FILESYSTEM
 M:	Anton Altaparmakov <anton@tuxera.com>
 L:	linux-ntfs-dev@lists.sourceforge.net
 W:	http://www.tuxera.com/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/aia21/ntfs.git
 S:	Supported
 F:	Documentation/filesystems/ntfs.txt
 F:	fs/ntfs/
 
 NVIDIA (rivafb and nvidiafb) FRAMEBUFFER DRIVER
 M:	Antonino Daplas <adaplas@gmail.com>
 L:	linux-fbdev@vger.kernel.org
 S:	Maintained
 F:	drivers/video/fbdev/riva/
 F:	drivers/video/fbdev/nvidia/
 
 NVM EXPRESS DRIVER
 M:	Keith Busch <keith.busch@intel.com>
 M:	Jens Axboe <axboe@fb.com>
 M:	Christoph Hellwig <hch@lst.de>
 M:	Sagi Grimberg <sagi@grimberg.me>
 L:	linux-nvme@lists.infradead.org
 T:	git://git.infradead.org/nvme.git
 W:	http://git.infradead.org/nvme.git
 S:	Supported
 F:	drivers/nvme/host/
 F:	include/linux/nvme.h
 F:	include/uapi/linux/nvme_ioctl.h
 
 NVM EXPRESS TARGET DRIVER
 M:	Christoph Hellwig <hch@lst.de>
 M:	Sagi Grimberg <sagi@grimberg.me>
 L:	linux-nvme@lists.infradead.org
 T:	git://git.infradead.org/nvme.git
 W:	http://git.infradead.org/nvme.git
 S:	Supported
 F:	drivers/nvme/target/
 
 NVM EXPRESS FC TRANSPORT DRIVERS
 M:	James Smart <james.smart@broadcom.com>
 L:	linux-nvme@lists.infradead.org
 S:	Supported
 F:	include/linux/nvme-fc.h
 F:	include/linux/nvme-fc-driver.h
 F:	drivers/nvme/host/fc.c
 F:	drivers/nvme/target/fc.c
 F:	drivers/nvme/target/fcloop.c
 
 NVMEM FRAMEWORK
 M:	Srinivas Kandagatla <srinivas.kandagatla@linaro.org>
 M:	Maxime Ripard <maxime.ripard@free-electrons.com>
 S:	Maintained
 F:	drivers/nvmem/
 F:	Documentation/devicetree/bindings/nvmem/
 F:	include/linux/nvmem-consumer.h
 F:	include/linux/nvmem-provider.h
 
 NXP-NCI NFC DRIVER
 M:	ClÃ©ment Perrochaud <clement.perrochaud@effinnov.com>
 R:	Charles Gorand <charles.gorand@effinnov.com>
 L:	linux-nfc@lists.01.org (moderated for non-subscribers)
 S:	Supported
 F:	drivers/nfc/nxp-nci
 
 NXP TDA998X DRM DRIVER
 M:	Russell King <linux@armlinux.org.uk>
 S:	Supported
 T:	git git://git.armlinux.org.uk/~rmk/linux-arm.git drm-tda998x-devel
 T:	git git://git.armlinux.org.uk/~rmk/linux-arm.git drm-tda998x-fixes
 F:	drivers/gpu/drm/i2c/tda998x_drv.c
 F:	include/drm/i2c/tda998x.h
 
 NXP TFA9879 DRIVER
 M:	Peter Rosin <peda@axentia.se>
 L:	alsa-devel@alsa-project.org (moderated for non-subscribers)
 S:	Maintained
 F:	sound/soc/codecs/tfa9879*
 
 OBJTOOL
 M:	Josh Poimboeuf <jpoimboe@redhat.com>
 S:	Supported
 F:	tools/objtool/
 
 OMAP SUPPORT
 M:	Tony Lindgren <tony@atomide.com>
 L:	linux-omap@vger.kernel.org
 W:	http://www.muru.com/linux/omap/
 W:	http://linux.omap.com/
 Q:	http://patchwork.kernel.org/project/linux-omap/list/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/tmlind/linux-omap.git
 S:	Maintained
 F:	arch/arm/*omap*/
 F:	arch/arm/configs/omap1_defconfig
 F:	arch/arm/configs/omap2plus_defconfig
 F:	drivers/i2c/busses/i2c-omap.c
 F:	drivers/irqchip/irq-omap-intc.c
 F:	drivers/mfd/*omap*.c
 F:	drivers/mfd/menelaus.c
 F:	drivers/mfd/palmas.c
 F:	drivers/mfd/tps65217.c
 F:	drivers/mfd/tps65218.c
 F:	drivers/mfd/tps65910.c
 F:	drivers/mfd/twl-core.[ch]
 F:	drivers/mfd/twl4030*.c
 F:	drivers/mfd/twl6030*.c
 F:	drivers/mfd/twl6040*.c
 F:	drivers/regulator/palmas-regulator*.c
 F:	drivers/regulator/pbias-regulator.c
 F:	drivers/regulator/tps65217-regulator.c
 F:	drivers/regulator/tps65218-regulator.c
 F:	drivers/regulator/tps65910-regulator.c
 F:	drivers/regulator/twl-regulator.c
 F:	drivers/regulator/twl6030-regulator.c
 F:	include/linux/i2c-omap.h
 
 OMAP DEVICE TREE SUPPORT
 M:	BenoÃ®t Cousson <bcousson@baylibre.com>
 M:	Tony Lindgren <tony@atomide.com>
 L:	linux-omap@vger.kernel.org
 L:	devicetree@vger.kernel.org
 S:	Maintained
 F:	arch/arm/boot/dts/*omap*
 F:	arch/arm/boot/dts/*am3*
 F:	arch/arm/boot/dts/*am4*
 F:	arch/arm/boot/dts/*am5*
 F:	arch/arm/boot/dts/*dra7*
 
 OMAP CLOCK FRAMEWORK SUPPORT
 M:	Paul Walmsley <paul@pwsan.com>
 L:	linux-omap@vger.kernel.org
 S:	Maintained
 F:	arch/arm/*omap*/*clock*
 
 OMAP POWER MANAGEMENT SUPPORT
 M:	Kevin Hilman <khilman@kernel.org>
 L:	linux-omap@vger.kernel.org
 S:	Maintained
 F:	arch/arm/*omap*/*pm*
 F:	drivers/cpufreq/omap-cpufreq.c
 
 OMAP POWERDOMAIN SOC ADAPTATION LAYER SUPPORT
 M:	Rajendra Nayak <rnayak@codeaurora.org>
 M:	Paul Walmsley <paul@pwsan.com>
 L:	linux-omap@vger.kernel.org
 S:	Maintained
 F:	arch/arm/mach-omap2/prm*
 
 OMAP AUDIO SUPPORT
 M:	Peter Ujfalusi <peter.ujfalusi@ti.com>
 M:	Jarkko Nikula <jarkko.nikula@bitmer.com>
 L:	alsa-devel@alsa-project.org (moderated for non-subscribers)
 L:	linux-omap@vger.kernel.org
 S:	Maintained
 F:	sound/soc/omap/
 
 OMAP GENERAL PURPOSE MEMORY CONTROLLER SUPPORT
 M:	Roger Quadros <rogerq@ti.com>
 M:	Tony Lindgren <tony@atomide.com>
 L:	linux-omap@vger.kernel.org
 S:	Maintained
 F:	drivers/memory/omap-gpmc.c
 F:	arch/arm/mach-omap2/*gpmc*
 
 OMAP FRAMEBUFFER SUPPORT
 M:	Tomi Valkeinen <tomi.valkeinen@ti.com>
 L:	linux-fbdev@vger.kernel.org
 L:	linux-omap@vger.kernel.org
 S:	Maintained
 F:	drivers/video/fbdev/omap/
 
 OMAP DISPLAY SUBSYSTEM and FRAMEBUFFER SUPPORT (DSS2)
 M:	Tomi Valkeinen <tomi.valkeinen@ti.com>
 L:	linux-omap@vger.kernel.org
 L:	linux-fbdev@vger.kernel.org
 S:	Maintained
 F:	drivers/video/fbdev/omap2/
 F:	Documentation/arm/OMAP/DSS
 
 OMAP HARDWARE SPINLOCK SUPPORT
 M:	Ohad Ben-Cohen <ohad@wizery.com>
 L:	linux-omap@vger.kernel.org
 S:	Maintained
 F:	drivers/hwspinlock/omap_hwspinlock.c
 
 OMAP MMC SUPPORT
 M:	Jarkko Lavinen <jarkko.lavinen@nokia.com>
 L:	linux-omap@vger.kernel.org
 S:	Maintained
 F:	drivers/mmc/host/omap.c
 
 OMAP HS MMC SUPPORT
 L:	linux-mmc@vger.kernel.org
 L:	linux-omap@vger.kernel.org
 S:	Orphan
 F:	drivers/mmc/host/omap_hsmmc.c
 
 OMAP RANDOM NUMBER GENERATOR SUPPORT
 M:	Deepak Saxena <dsaxena@plexity.net>
 S:	Maintained
 F:	drivers/char/hw_random/omap-rng.c
 
 OMAP HWMOD SUPPORT
 M:	BenoÃ®t Cousson <bcousson@baylibre.com>
 M:	Paul Walmsley <paul@pwsan.com>
 L:	linux-omap@vger.kernel.org
 S:	Maintained
 F:	arch/arm/mach-omap2/omap_hwmod.*
 
 OMAP HWMOD DATA
 M:	Paul Walmsley <paul@pwsan.com>
 L:	linux-omap@vger.kernel.org
 S:	Maintained
 F:	arch/arm/mach-omap2/omap_hwmod*data*
 
 OMAP HWMOD DATA FOR OMAP4-BASED DEVICES
 M:	BenoÃ®t Cousson <bcousson@baylibre.com>
 L:	linux-omap@vger.kernel.org
 S:	Maintained
 F:	arch/arm/mach-omap2/omap_hwmod_44xx_data.c
 
 OMAP IMAGING SUBSYSTEM (OMAP3 ISP and OMAP4 ISS)
 M:	Laurent Pinchart <laurent.pinchart@ideasonboard.com>
 L:	linux-media@vger.kernel.org
 S:	Maintained
 F:	Documentation/devicetree/bindings/media/ti,omap3isp.txt
 F:	drivers/media/platform/omap3isp/
 F:	drivers/staging/media/omap4iss/
 
 OMAP USB SUPPORT
 L:	linux-usb@vger.kernel.org
 L:	linux-omap@vger.kernel.org
 S:	Orphan
 F:	drivers/usb/*/*omap*
 F:	arch/arm/*omap*/usb*
 
 OMAP GPIO DRIVER
 M:	Grygorii Strashko <grygorii.strashko@ti.com>
 M:	Santosh Shilimkar <ssantosh@kernel.org>
 M:	Kevin Hilman <khilman@kernel.org>
 L:	linux-omap@vger.kernel.org
 S:	Maintained
 F:	Documentation/devicetree/bindings/gpio/gpio-omap.txt
 F:	drivers/gpio/gpio-omap.c
 
 OMAP/NEWFLOW NANOBONE MACHINE SUPPORT
 M:	Mark Jackson <mpfj@newflow.co.uk>
 L:	linux-omap@vger.kernel.org
 S:	Maintained
 F:	arch/arm/boot/dts/am335x-nano.dts
 
 OMFS FILESYSTEM
 M:	Bob Copeland <me@bobcopeland.com>
 L:	linux-karma-devel@lists.sourceforge.net
 S:	Maintained
 F:	Documentation/filesystems/omfs.txt
 F:	fs/omfs/
 
 OMNIKEY CARDMAN 4000 DRIVER
 M:	Harald Welte <laforge@gnumonks.org>
 S:	Maintained
 F:	drivers/char/pcmcia/cm4000_cs.c
 F:	include/linux/cm4000_cs.h
 F:	include/uapi/linux/cm4000_cs.h
 
 OMNIKEY CARDMAN 4040 DRIVER
 M:	Harald Welte <laforge@gnumonks.org>
 S:	Maintained
 F:	drivers/char/pcmcia/cm4040_cs.*
 
 OMNIVISION OV7670 SENSOR DRIVER
 M:	Jonathan Corbet <corbet@lwn.net>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Maintained
 F:	drivers/media/i2c/ov7670.c
 
 ONENAND FLASH DRIVER
 M:	Kyungmin Park <kyungmin.park@samsung.com>
 L:	linux-mtd@lists.infradead.org
 S:	Maintained
 F:	drivers/mtd/onenand/
 F:	include/linux/mtd/onenand*.h
 
 ONSTREAM SCSI TAPE DRIVER
 M:	Willem Riede <osst@riede.org>
 L:	osst-users@lists.sourceforge.net
 L:	linux-scsi@vger.kernel.org
 S:	Maintained
 F:	Documentation/scsi/osst.txt
 F:	drivers/scsi/osst.*
 F:	drivers/scsi/osst_*.h
 F:	drivers/scsi/st.h
 
 OPENCORES I2C BUS DRIVER
 M:	Peter Korsgaard <jacmet@sunsite.dk>
 L:	linux-i2c@vger.kernel.org
 S:	Maintained
 F:	Documentation/i2c/busses/i2c-ocores
 F:	drivers/i2c/busses/i2c-ocores.c
 
 OPEN FIRMWARE AND FLATTENED DEVICE TREE
 M:	Rob Herring <robh+dt@kernel.org>
 M:	Frank Rowand <frowand.list@gmail.com>
 L:	devicetree@vger.kernel.org
 W:	http://www.devicetree.org/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/robh/linux.git
 S:	Maintained
 F:	drivers/of/
 F:	include/linux/of*.h
 F:	scripts/dtc/
 
 OPEN FIRMWARE AND FLATTENED DEVICE TREE BINDINGS
 M:	Rob Herring <robh+dt@kernel.org>
 M:	Mark Rutland <mark.rutland@arm.com>
 L:	devicetree@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/robh/linux.git
 Q:	http://patchwork.ozlabs.org/project/devicetree-bindings/list/
 S:	Maintained
 F:	Documentation/devicetree/
 F:	arch/*/boot/dts/
 F:	include/dt-bindings/
 
 OPEN FIRMWARE AND DEVICE TREE OVERLAYS
 M:	Pantelis Antoniou <pantelis.antoniou@konsulko.com>
 L:	devicetree@vger.kernel.org
 S:	Maintained
 F:	Documentation/devicetree/dynamic-resolution-notes.txt
 F:	Documentation/devicetree/overlay-notes.txt
 F:	drivers/of/overlay.c
 F:	drivers/of/resolver.c
 
 OPENRISC ARCHITECTURE
 M:	Jonas Bonn <jonas@southpole.se>
 M:	Stefan Kristiansson <stefan.kristiansson@saunalahti.fi>
 M:	Stafford Horne <shorne@gmail.com>
 L:	openrisc@lists.librecores.org
 W:	http://openrisc.io
 S:	Maintained
 F:	arch/openrisc/
 
 OPENVSWITCH
 M:	Pravin Shelar <pshelar@nicira.com>
 L:	netdev@vger.kernel.org
 L:	dev@openvswitch.org
 W:	http://openvswitch.org
 S:	Maintained
 F:	net/openvswitch/
 F:	include/uapi/linux/openvswitch.h
 
 OPERATING PERFORMANCE POINTS (OPP)
 M:	Viresh Kumar <vireshk@kernel.org>
 M:	Nishanth Menon <nm@ti.com>
 M:	Stephen Boyd <sboyd@codeaurora.org>
 L:	linux-pm@vger.kernel.org
 S:	Maintained
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/vireshk/pm.git
 F:	drivers/base/power/opp/
 F:	include/linux/pm_opp.h
 F:	Documentation/power/opp.txt
 F:	Documentation/devicetree/bindings/opp/
 
 OPL4 DRIVER
 M:	Clemens Ladisch <clemens@ladisch.de>
 L:	alsa-devel@alsa-project.org (moderated for non-subscribers)
 T:	git git://git.alsa-project.org/alsa-kernel.git
 S:	Maintained
 F:	sound/drivers/opl4/
 
 OPROFILE
 M:	Robert Richter <rric@kernel.org>
 L:	oprofile-list@lists.sf.net
 S:	Maintained
 F:	arch/*/include/asm/oprofile*.h
 F:	arch/*/oprofile/
 F:	drivers/oprofile/
 F:	include/linux/oprofile.h
 
 ORACLE CLUSTER FILESYSTEM 2 (OCFS2)
 M:	Mark Fasheh <mfasheh@versity.com>
 M:	Joel Becker <jlbec@evilplan.org>
 L:	ocfs2-devel@oss.oracle.com (moderated for non-subscribers)
 W:	http://ocfs2.wiki.kernel.org
 S:	Supported
 F:	Documentation/filesystems/ocfs2.txt
 F:	Documentation/filesystems/dlmfs.txt
 F:	fs/ocfs2/
 
 ORINOCO DRIVER
 L:	linux-wireless@vger.kernel.org
 W:	http://wireless.kernel.org/en/users/Drivers/orinoco
 W:	http://www.nongnu.org/orinoco/
 S:	Orphan
 F:	drivers/net/wireless/intersil/orinoco/
 
 OSD LIBRARY and FILESYSTEM
 M:	Boaz Harrosh <ooo@electrozaur.com>
 M:	Benny Halevy <bhalevy@primarydata.com>
 L:	osd-dev@open-osd.org
 W:	http://open-osd.org
 T:	git git://git.open-osd.org/open-osd.git
 S:	Maintained
 F:	drivers/scsi/osd/
 F:	include/scsi/osd_*
 F:	fs/exofs/
 
 OVERLAY FILESYSTEM
 M:	Miklos Szeredi <miklos@szeredi.hu>
 L:	linux-unionfs@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/mszeredi/vfs.git
 S:	Supported
 F:	fs/overlayfs/
 F:	Documentation/filesystems/overlayfs.txt
 
 ORANGEFS FILESYSTEM
 M:	Mike Marshall <hubcap@omnibond.com>
 L:	pvfs2-developers@beowulf-underground.org (subscribers-only)
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/hubcap/linux.git
 S:	Supported
 F:	fs/orangefs/
 F:	Documentation/filesystems/orangefs.txt
 
 P54 WIRELESS DRIVER
 M:	Christian Lamparter <chunkeey@googlemail.com>
 L:	linux-wireless@vger.kernel.org
 W:	http://wireless.kernel.org/en/users/Drivers/p54
 S:	Maintained
 F:	drivers/net/wireless/intersil/p54/
 
 PA SEMI ETHERNET DRIVER
 L:	netdev@vger.kernel.org
 S:	Orphan
 F:	drivers/net/ethernet/pasemi/*
 
 PA SEMI SMBUS DRIVER
 L:	linux-i2c@vger.kernel.org
 S:	Orphan
 F:	drivers/i2c/busses/i2c-pasemi.c
 
 PADATA PARALLEL EXECUTION MECHANISM
 M:	Steffen Klassert <steffen.klassert@secunet.com>
 L:	linux-crypto@vger.kernel.org
 S:	Maintained
 F:	kernel/padata.c
 F:	include/linux/padata.h
 F:	Documentation/padata.txt
 
 PANASONIC LAPTOP ACPI EXTRAS DRIVER
 M:	Harald Welte <laforge@gnumonks.org>
 L:	platform-driver-x86@vger.kernel.org
 S:	Maintained
 F:	drivers/platform/x86/panasonic-laptop.c
 
 PANASONIC MN10300/AM33/AM34 PORT
 M:	David Howells <dhowells@redhat.com>
 L:	linux-am33-list@redhat.com (moderated for non-subscribers)
 W:	ftp://ftp.redhat.com/pub/redhat/gnupro/AM33/
 S:	Maintained
 F:	Documentation/mn10300/
 F:	arch/mn10300/
 
 PARALLEL LCD/KEYPAD PANEL DRIVER
 M:      Willy Tarreau <willy@haproxy.com>
 M:      Ksenija Stanojevic <ksenija.stanojevic@gmail.com>
 S:      Odd Fixes
 F:      Documentation/misc-devices/lcd-panel-cgram.txt
 F:      drivers/misc/panel.c
 
 PARALLEL PORT SUBSYSTEM
 M:	Sudip Mukherjee <sudipm.mukherjee@gmail.com>
 M:	Sudip Mukherjee <sudip.mukherjee@codethink.co.uk>
 L:	linux-parport@lists.infradead.org (subscribers-only)
 S:	Maintained
 F:	drivers/parport/
 F:	include/linux/parport*.h
 F:	drivers/char/ppdev.c
 F:	include/uapi/linux/ppdev.h
 F:	Documentation/parport*.txt
 
 PARAVIRT_OPS INTERFACE
 M:	Jeremy Fitzhardinge <jeremy@goop.org>
 M:	Chris Wright <chrisw@sous-sol.org>
 M:	Alok Kataria <akataria@vmware.com>
 M:	Rusty Russell <rusty@rustcorp.com.au>
 L:	virtualization@lists.linux-foundation.org
 S:	Supported
 F:	Documentation/virtual/paravirt_ops.txt
 F:	arch/*/kernel/paravirt*
 F:	arch/*/include/asm/paravirt.h
 F:	include/linux/hypervisor.h
 
 PARIDE DRIVERS FOR PARALLEL PORT IDE DEVICES
 M:	Tim Waugh <tim@cyberelk.net>
 L:	linux-parport@lists.infradead.org (subscribers-only)
 S:	Maintained
 F:	Documentation/blockdev/paride.txt
 F:	drivers/block/paride/
 
 PARISC ARCHITECTURE
 M:	"James E.J. Bottomley" <jejb@parisc-linux.org>
 M:	Helge Deller <deller@gmx.de>
 L:	linux-parisc@vger.kernel.org
 W:	http://www.parisc-linux.org/
 Q:	http://patchwork.kernel.org/project/linux-parisc/list/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/jejb/parisc-2.6.git
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/deller/parisc-linux.git
 S:	Maintained
 F:	arch/parisc/
 F:	Documentation/parisc/
 F:	drivers/parisc/
 F:	drivers/char/agp/parisc-agp.c
 F:	drivers/input/serio/gscps2.c
 F:	drivers/parport/parport_gsc.*
 F:	drivers/tty/serial/8250/8250_gsc.c
 F:	drivers/video/fbdev/sti*
 F:	drivers/video/console/sti*
 F:	drivers/video/logo/logo_parisc*
 
 PARMAN
 M:	Jiri Pirko <jiri@mellanox.com>
 L:	netdev@vger.kernel.org
 S:	Supported
 F:	lib/parman.c
 F:	lib/test_parman.c
 F:	include/linux/parman.h
 
 PC87360 HARDWARE MONITORING DRIVER
 M:	Jim Cromie <jim.cromie@gmail.com>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	Documentation/hwmon/pc87360
 F:	drivers/hwmon/pc87360.c
 
 PC8736x GPIO DRIVER
 M:	Jim Cromie <jim.cromie@gmail.com>
 S:	Maintained
 F:	drivers/char/pc8736x_gpio.c
 
 PC87427 HARDWARE MONITORING DRIVER
 M:	Jean Delvare <jdelvare@suse.com>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	Documentation/hwmon/pc87427
 F:	drivers/hwmon/pc87427.c
 
 PCA9532 LED DRIVER
 M:	Riku Voipio <riku.voipio@iki.fi>
 S:	Maintained
 F:	drivers/leds/leds-pca9532.c
 F:	include/linux/leds-pca9532.h
 
 PCA9541 I2C BUS MASTER SELECTOR DRIVER
 M:	Guenter Roeck <linux@roeck-us.net>
 L:	linux-i2c@vger.kernel.org
 S:	Maintained
 F:	drivers/i2c/muxes/i2c-mux-pca9541.c
 
 PCDP - PRIMARY CONSOLE AND DEBUG PORT
 M:	Khalid Aziz <khalid@gonehiking.org>
 S:	Maintained
 F:	drivers/firmware/pcdp.*
 
 PCI ERROR RECOVERY
 M:	Linas Vepstas <linasvepstas@gmail.com>
 L:	linux-pci@vger.kernel.org
 S:	Supported
 F:	Documentation/PCI/pci-error-recovery.txt
 
 PCI ENHANCED ERROR HANDLING (EEH) FOR POWERPC
 M:	Russell Currey <ruscur@russell.cc>
 L:	linuxppc-dev@lists.ozlabs.org
 S:	Supported
 F:	Documentation/powerpc/eeh-pci-error-recovery.txt
 F:	arch/powerpc/kernel/eeh*.c
 F:	arch/powerpc/platforms/*/eeh*.c
 F:	arch/powerpc/include/*/eeh*.h
 
 PCI SUBSYSTEM
 M:	Bjorn Helgaas <bhelgaas@google.com>
 L:	linux-pci@vger.kernel.org
 Q:	http://patchwork.ozlabs.org/project/linux-pci/list/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/helgaas/pci.git
 S:	Supported
 F:	Documentation/devicetree/bindings/pci/
 F:	Documentation/PCI/
 F:	drivers/pci/
 F:	include/linux/pci*
 F:	arch/x86/pci/
 F:	arch/x86/kernel/quirks.c
 
 PCI DRIVER FOR ALTERA PCIE IP
 M:	Ley Foon Tan <lftan@altera.com>
 L:	rfi@lists.rocketboards.org (moderated for non-subscribers)
 L:	linux-pci@vger.kernel.org
 S:	Supported
 F:	Documentation/devicetree/bindings/pci/altera-pcie.txt
 F:	drivers/pci/host/pcie-altera.c
 
 PCI DRIVER FOR ARM VERSATILE PLATFORM
 M:	Rob Herring <robh@kernel.org>
 L:	linux-pci@vger.kernel.org
 L:	linux-arm-kernel@lists.infradead.org
 S:	Maintained
 F:	Documentation/devicetree/bindings/pci/versatile.txt
 F:	drivers/pci/host/pci-versatile.c
 
 PCI DRIVER FOR ARMADA 8K
 M:	Thomas Petazzoni <thomas.petazzoni@free-electrons.com>
 L:	linux-pci@vger.kernel.org
 L:	linux-arm-kernel@lists.infradead.org
 S:	Maintained
 F:	Documentation/devicetree/bindings/pci/pci-armada8k.txt
 F:	drivers/pci/host/pcie-armada8k.c
 
 PCI DRIVER FOR APPLIEDMICRO XGENE
 M:	Tanmay Inamdar <tinamdar@apm.com>
 L:	linux-pci@vger.kernel.org
 L:	linux-arm-kernel@lists.infradead.org
 S:	Maintained
 F:	Documentation/devicetree/bindings/pci/xgene-pci.txt
 F:	drivers/pci/host/pci-xgene.c
 
 PCI DRIVER FOR FREESCALE LAYERSCAPE
 M:	Minghuan Lian <minghuan.Lian@freescale.com>
 M:	Mingkai Hu <mingkai.hu@freescale.com>
 M:	Roy Zang <tie-fei.zang@freescale.com>
 L:	linuxppc-dev@lists.ozlabs.org
 L:	linux-pci@vger.kernel.org
 L:	linux-arm-kernel@lists.infradead.org
 S:	Maintained
 F:	drivers/pci/host/*layerscape*
 
 PCI DRIVER FOR IMX6
 M:	Richard Zhu <hongxing.zhu@nxp.com>
 M:	Lucas Stach <l.stach@pengutronix.de>
 L:	linux-pci@vger.kernel.org
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	Documentation/devicetree/bindings/pci/fsl,imx6q-pcie.txt
 F:	drivers/pci/host/*imx6*
 
 PCI DRIVER FOR TI KEYSTONE
 M:	Murali Karicheri <m-karicheri2@ti.com>
 L:	linux-pci@vger.kernel.org
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	drivers/pci/host/*keystone*
 
 PCI DRIVER FOR MVEBU (Marvell Armada 370 and Armada XP SOC support)
 M:	Thomas Petazzoni <thomas.petazzoni@free-electrons.com>
 M:	Jason Cooper <jason@lakedaemon.net>
 L:	linux-pci@vger.kernel.org
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	drivers/pci/host/*mvebu*
 
 PCI DRIVER FOR AARDVARK (Marvell Armada 3700)
 M:	Thomas Petazzoni <thomas.petazzoni@free-electrons.com>
 L:	linux-pci@vger.kernel.org
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	Documentation/devicetree/bindings/pci/aardvark-pci.txt
 F:	drivers/pci/host/pci-aardvark.c
 
 PCI DRIVER FOR NVIDIA TEGRA
 M:	Thierry Reding <thierry.reding@gmail.com>
 L:	linux-tegra@vger.kernel.org
 L:	linux-pci@vger.kernel.org
 S:	Supported
 F:	Documentation/devicetree/bindings/pci/nvidia,tegra20-pcie.txt
 F:	drivers/pci/host/pci-tegra.c
 
 PCI DRIVER FOR TI DRA7XX
 M:	Kishon Vijay Abraham I <kishon@ti.com>
 L:	linux-omap@vger.kernel.org
 L:	linux-pci@vger.kernel.org
 S:	Supported
 F:	Documentation/devicetree/bindings/pci/ti-pci.txt
 F:	drivers/pci/host/pci-dra7xx.c
 
 PCI DRIVER FOR RENESAS R-CAR
 M:	Simon Horman <horms@verge.net.au>
 L:	linux-pci@vger.kernel.org
 L:	linux-renesas-soc@vger.kernel.org
 S:	Maintained
 F:	drivers/pci/host/*rcar*
 
 PCI DRIVER FOR SAMSUNG EXYNOS
 M:	Jingoo Han <jingoohan1@gmail.com>
 L:	linux-pci@vger.kernel.org
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 L:	linux-samsung-soc@vger.kernel.org (moderated for non-subscribers)
 S:	Maintained
 F:	drivers/pci/host/pci-exynos.c
 
 PCI DRIVER FOR SYNOPSIS DESIGNWARE
 M:	Jingoo Han <jingoohan1@gmail.com>
 M:	Joao Pinto <Joao.Pinto@synopsys.com>
 L:	linux-pci@vger.kernel.org
 S:	Maintained
 F:	Documentation/devicetree/bindings/pci/designware-pcie.txt
 F:	drivers/pci/host/*designware*
 
 PCI DRIVER FOR GENERIC OF HOSTS
 M:	Will Deacon <will.deacon@arm.com>
 L:	linux-pci@vger.kernel.org
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	Documentation/devicetree/bindings/pci/host-generic-pci.txt
 F:	drivers/pci/host/pci-host-common.c
 F:	drivers/pci/host/pci-host-generic.c
 
 PCI DRIVER FOR INTEL VOLUME MANAGEMENT DEVICE (VMD)
 M:	Keith Busch <keith.busch@intel.com>
 L:	linux-pci@vger.kernel.org
 S:	Supported
 F:	drivers/pci/host/vmd.c
 
 PCIE DRIVER FOR ST SPEAR13XX
 M:	Pratyush Anand <pratyush.anand@gmail.com>
 L:	linux-pci@vger.kernel.org
 S:	Maintained
 F:	drivers/pci/host/*spear*
 
 PCI MSI DRIVER FOR ALTERA MSI IP
 M:	Ley Foon Tan <lftan@altera.com>
 L:	rfi@lists.rocketboards.org (moderated for non-subscribers)
 L:	linux-pci@vger.kernel.org
 S:	Supported
 F:	Documentation/devicetree/bindings/pci/altera-pcie-msi.txt
 F:	drivers/pci/host/pcie-altera-msi.c
 
 PCI MSI DRIVER FOR APPLIEDMICRO XGENE
 M:	Duc Dang <dhdang@apm.com>
 L:	linux-pci@vger.kernel.org
 L:	linux-arm-kernel@lists.infradead.org
 S:	Maintained
 F:	Documentation/devicetree/bindings/pci/xgene-pci-msi.txt
 F:	drivers/pci/host/pci-xgene-msi.c
 
 PCIE DRIVER FOR AXIS ARTPEC
 M:	Niklas Cassel <niklas.cassel@axis.com>
 M:	Jesper Nilsson <jesper.nilsson@axis.com>
 L:	linux-arm-kernel@axis.com
 L:	linux-pci@vger.kernel.org
 S:	Maintained
 F:	Documentation/devicetree/bindings/pci/axis,artpec*
 F:	drivers/pci/host/*artpec*
 
 PCIE DRIVER FOR HISILICON
 M:	Zhou Wang <wangzhou1@hisilicon.com>
 M:	Gabriele Paoloni <gabriele.paoloni@huawei.com>
 L:	linux-pci@vger.kernel.org
 S:	Maintained
 F:	Documentation/devicetree/bindings/pci/hisilicon-pcie.txt
 F:	drivers/pci/host/pcie-hisi.c
 
 PCIE DRIVER FOR ROCKCHIP
 M:	Shawn Lin <shawn.lin@rock-chips.com>
 M:	Wenrui Li <wenrui.li@rock-chips.com>
 L:	linux-pci@vger.kernel.org
 L:	linux-rockchip@lists.infradead.org
 S:	Maintained
 F:	Documentation/devicetree/bindings/pci/rockchip-pcie.txt
 F:	drivers/pci/host/pcie-rockchip.c
 
 PCIE DRIVER FOR QUALCOMM MSM
 M:     Stanimir Varbanov <svarbanov@mm-sol.com>
 L:     linux-pci@vger.kernel.org
 L:     linux-arm-msm@vger.kernel.org
 S:     Maintained
 F:     drivers/pci/host/*qcom*
 
 PCIE DRIVER FOR CAVIUM THUNDERX
 M:	David Daney <david.daney@cavium.com>
 L:	linux-pci@vger.kernel.org
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Supported
 F:	Documentation/devicetree/bindings/pci/pci-thunder-*
 F:	drivers/pci/host/pci-thunder-*
 
 PCMCIA SUBSYSTEM
 P:	Linux PCMCIA Team
 L:	linux-pcmcia@lists.infradead.org
 W:	http://lists.infradead.org/mailman/listinfo/linux-pcmcia
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/brodo/pcmcia.git
 S:	Maintained
 F:	Documentation/pcmcia/
 F:	tools/pcmcia/
 F:	drivers/pcmcia/
 F:	include/pcmcia/
 
 PCNET32 NETWORK DRIVER
 M:	Don Fry <pcnet32@frontier.com>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/ethernet/amd/pcnet32.c
 
 PCRYPT PARALLEL CRYPTO ENGINE
 M:	Steffen Klassert <steffen.klassert@secunet.com>
 L:	linux-crypto@vger.kernel.org
 S:	Maintained
 F:	crypto/pcrypt.c
 F:	include/crypto/pcrypt.h
 
 PER-CPU MEMORY ALLOCATOR
 M:	Tejun Heo <tj@kernel.org>
 M:	Christoph Lameter <cl@linux.com>
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/tj/percpu.git
 S:	Maintained
 F:	include/linux/percpu*.h
 F:	mm/percpu*.c
 F:	arch/*/include/asm/percpu.h
 
 PER-TASK DELAY ACCOUNTING
 M:	Balbir Singh <bsingharora@gmail.com>
 S:	Maintained
 F:	include/linux/delayacct.h
 F:	kernel/delayacct.c
 
 PERFORMANCE EVENTS SUBSYSTEM
 M:	Peter Zijlstra <peterz@infradead.org>
 M:	Ingo Molnar <mingo@redhat.com>
 M:	Arnaldo Carvalho de Melo <acme@kernel.org>
 R:	Alexander Shishkin <alexander.shishkin@linux.intel.com>
 L:	linux-kernel@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip.git perf/core
 S:	Supported
 F:	kernel/events/*
 F:	include/linux/perf_event.h
 F:	include/uapi/linux/perf_event.h
 F:	arch/*/kernel/perf_event*.c
 F:	arch/*/kernel/*/perf_event*.c
 F:	arch/*/kernel/*/*/perf_event*.c
 F:	arch/*/include/asm/perf_event.h
 F:	arch/*/kernel/perf_callchain.c
 F:	arch/*/events/*
 F:	tools/perf/
 
 PERSONALITY HANDLING
 M:	Christoph Hellwig <hch@infradead.org>
 L:	linux-abi-devel@lists.sourceforge.net
 S:	Maintained
 F:	include/linux/personality.h
 F:	include/uapi/linux/personality.h
 
 PHONET PROTOCOL
 M:	Remi Denis-Courmont <courmisch@gmail.com>
 S:	Supported
 F:	Documentation/networking/phonet.txt
 F:	include/linux/phonet.h
 F:	include/net/phonet/
 F:	include/uapi/linux/phonet.h
 F:	net/phonet/
 
 PHRAM MTD DRIVER
 M:	Joern Engel <joern@lazybastard.org>
 L:	linux-mtd@lists.infradead.org
 S:	Maintained
 F:	drivers/mtd/devices/phram.c
 
 PICOLCD HID DRIVER
 M:	Bruno PrÃ©mont <bonbons@linux-vserver.org>
 L:	linux-input@vger.kernel.org
 S:	Maintained
 F:	drivers/hid/hid-picolcd*
 
 PICOXCELL SUPPORT
 M:	Jamie Iles <jamie@jamieiles.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 T:	git git://github.com/jamieiles/linux-2.6-ji.git
 S:	Supported
 F:	arch/arm/boot/dts/picoxcell*
 F:	arch/arm/mach-picoxcell/
 F:	drivers/crypto/picoxcell*
 
 PIN CONTROL SUBSYSTEM
 M:	Linus Walleij <linus.walleij@linaro.org>
 L:	linux-gpio@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/linusw/linux-pinctrl.git
 S:	Maintained
 F:	Documentation/devicetree/bindings/pinctrl/
 F:	Documentation/pinctrl.txt
 F:	drivers/pinctrl/
 F:	include/linux/pinctrl/
 
 PIN CONTROLLER - ATMEL AT91
 M:	Jean-Christophe Plagniol-Villard <plagnioj@jcrosoft.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	drivers/pinctrl/pinctrl-at91.*
 
 PIN CONTROLLER - ATMEL AT91 PIO4
 M:	Ludovic Desroches <ludovic.desroches@microchip.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 L:	linux-gpio@vger.kernel.org
 S:	Supported
 F:	drivers/pinctrl/pinctrl-at91-pio4.*
 
 PIN CONTROLLER - INTEL
 M:	Mika Westerberg <mika.westerberg@linux.intel.com>
 M:	Heikki Krogerus <heikki.krogerus@linux.intel.com>
 S:	Maintained
 F:	drivers/pinctrl/intel/
 
 PIN CONTROLLER - RENESAS
 M:	Laurent Pinchart <laurent.pinchart@ideasonboard.com>
 M:	Geert Uytterhoeven <geert+renesas@glider.be>
 L:	linux-renesas-soc@vger.kernel.org
 S:	Maintained
 F:	drivers/pinctrl/sh-pfc/
 
 PIN CONTROLLER - SAMSUNG
 M:	Tomasz Figa <tomasz.figa@gmail.com>
 M:	Krzysztof Kozlowski <krzk@kernel.org>
 M:	Sylwester Nawrocki <s.nawrocki@samsung.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 L:	linux-samsung-soc@vger.kernel.org (moderated for non-subscribers)
 S:	Maintained
 F:	drivers/pinctrl/samsung/
 F:	include/dt-bindings/pinctrl/samsung.h
 F:	Documentation/devicetree/bindings/pinctrl/samsung-pinctrl.txt
 
 PIN CONTROLLER - SINGLE
 M:	Tony Lindgren <tony@atomide.com>
 M:	Haojian Zhuang <haojian.zhuang@linaro.org>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 L:	linux-omap@vger.kernel.org
 S:	Maintained
 F:	drivers/pinctrl/pinctrl-single.c
 
 PIN CONTROLLER - ST SPEAR
 M:	Viresh Kumar <vireshk@kernel.org>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 W:	http://www.st.com/spear
 S:	Maintained
 F:	drivers/pinctrl/spear/
 
 PISTACHIO SOC SUPPORT
 M:      James Hartley <james.hartley@imgtec.com>
 M:      Ionela Voinescu <ionela.voinescu@imgtec.com>
 L:      linux-mips@linux-mips.org
 S:      Maintained
 F:      arch/mips/pistachio/
 F:      arch/mips/include/asm/mach-pistachio/
 F:      arch/mips/boot/dts/img/pistachio*
 F:      arch/mips/configs/pistachio*_defconfig
 
 PKTCDVD DRIVER
 S:	Orphan
 M:	linux-block@vger.kernel.org
 F:	drivers/block/pktcdvd.c
 F:	include/linux/pktcdvd.h
 F:	include/uapi/linux/pktcdvd.h
 
 PKUNITY SOC DRIVERS
 M:	Guan Xuetao <gxt@mprc.pku.edu.cn>
 W:	http://mprc.pku.edu.cn/~guanxuetao/linux
 S:	Maintained
 T:	git git://github.com/gxt/linux.git
 F:	drivers/input/serio/i8042-unicore32io.h
 F:	drivers/i2c/busses/i2c-puv3.c
 F:	drivers/video/fbdev/fb-puv3.c
 F:	drivers/rtc/rtc-puv3.c
 
 PMBUS HARDWARE MONITORING DRIVERS
 M:	Guenter Roeck <linux@roeck-us.net>
 L:	linux-hwmon@vger.kernel.org
 W:	http://hwmon.wiki.kernel.org/
 W:	http://www.roeck-us.net/linux/drivers/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/groeck/linux-staging.git
 S:	Maintained
 F:	Documentation/hwmon/pmbus
 F:	drivers/hwmon/pmbus/
 F:	include/linux/i2c/pmbus.h
 
 PMC SIERRA MaxRAID DRIVER
 L:	linux-scsi@vger.kernel.org
 W:	http://www.pmc-sierra.com/
 S:	Orphan
 F:	drivers/scsi/pmcraid.*
 
 PMC SIERRA PM8001 DRIVER
 M:	Jack Wang <jinpu.wang@profitbricks.com>
 M:	lindar_liu@usish.com
 L:	pmchba@pmcs.com
 L:	linux-scsi@vger.kernel.org
 S:	Supported
 F:	drivers/scsi/pm8001/
 
 POSIX CLOCKS and TIMERS
 M:	Thomas Gleixner <tglx@linutronix.de>
 L:	linux-kernel@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip.git timers/core
 S:	Maintained
 F:	fs/timerfd.c
 F:	include/linux/timer*
 F:	kernel/time/*timer*
 
 POWER MANAGEMENT CORE
 M:	"Rafael J. Wysocki" <rjw@rjwysocki.net>
 L:	linux-pm@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm
 B:	https://bugzilla.kernel.org
 S:	Supported
 F:	drivers/base/power/
 F:	include/linux/pm.h
 F:	include/linux/pm_*
 F:	include/linux/powercap.h
 F:	drivers/powercap/
 
 POWER SUPPLY CLASS/SUBSYSTEM and DRIVERS
 M:	Sebastian Reichel <sre@kernel.org>
 L:	linux-pm@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/sre/linux-power-supply.git
 S:	Maintained
 F:	Documentation/devicetree/bindings/power/supply/
 F:	include/linux/power_supply.h
 F:	drivers/power/supply/
 
 POWER STATE COORDINATION INTERFACE (PSCI)
 M:	Mark Rutland <mark.rutland@arm.com>
 M:	Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
 L:	linux-arm-kernel@lists.infradead.org
 S:	Maintained
 F:	drivers/firmware/psci*.c
 F:	include/linux/psci.h
 F:	include/uapi/linux/psci.h
 
 POWERNV OPERATOR PANEL LCD DISPLAY DRIVER
 M:	Suraj Jitindar Singh <sjitindarsingh@gmail.com>
 L:	linuxppc-dev@lists.ozlabs.org
 S:	Maintained
 F:	drivers/char/powernv-op-panel.c
 
 PNP SUPPORT
 M:	"Rafael J. Wysocki" <rafael.j.wysocki@intel.com>
 S:	Maintained
 F:	drivers/pnp/
 
 PPP PROTOCOL DRIVERS AND COMPRESSORS
 M:	Paul Mackerras <paulus@samba.org>
 L:	linux-ppp@vger.kernel.org
 S:	Maintained
 F:	drivers/net/ppp/ppp_*
 
 PPP OVER ATM (RFC 2364)
 M:	Mitchell Blank Jr <mitch@sfgoth.com>
 S:	Maintained
 F:	net/atm/pppoatm.c
 F:	include/uapi/linux/atmppp.h
 
 PPP OVER ETHERNET
 M:	Michal Ostrowski <mostrows@earthlink.net>
 S:	Maintained
 F:	drivers/net/ppp/pppoe.c
 F:	drivers/net/ppp/pppox.c
 
 PPP OVER L2TP
 M:	James Chapman <jchapman@katalix.com>
 S:	Maintained
 F:	net/l2tp/l2tp_ppp.c
 F:	include/linux/if_pppol2tp.h
 F:	include/uapi/linux/if_pppol2tp.h
 
 PPS SUPPORT
 M:	Rodolfo Giometti <giometti@enneenne.com>
 W:	http://wiki.enneenne.com/index.php/LinuxPPS_support
 L:	linuxpps@ml.enneenne.com (subscribers-only)
 S:	Maintained
 F:	Documentation/pps/
 F:	drivers/pps/
 F:	include/linux/pps*.h
 
 PPTP DRIVER
 M:	Dmitry Kozlov <xeb@mail.ru>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/ppp/pptp.c
 W:	http://sourceforge.net/projects/accel-pptp
 
 PREEMPTIBLE KERNEL
 M:	Robert Love <rml@tech9.net>
 L:	kpreempt-tech@lists.sourceforge.net
 W:	ftp://ftp.kernel.org/pub/linux/kernel/people/rml/preempt-kernel
 S:	Supported
 F:	Documentation/preempt-locking.txt
 F:	include/linux/preempt.h
 
 PRISM54 WIRELESS DRIVER
 M:	"Luis R. Rodriguez" <mcgrof@gmail.com>
 L:	linux-wireless@vger.kernel.org
 W:	http://wireless.kernel.org/en/users/Drivers/p54
 S:	Obsolete
 F:	drivers/net/wireless/intersil/prism54/
 
 PS3 NETWORK SUPPORT
 M:	Geoff Levand <geoff@infradead.org>
 L:	netdev@vger.kernel.org
 L:	linuxppc-dev@lists.ozlabs.org
 S:	Maintained
 F:	drivers/net/ethernet/toshiba/ps3_gelic_net.*
 
 PS3 PLATFORM SUPPORT
 M:	Geoff Levand <geoff@infradead.org>
 L:	linuxppc-dev@lists.ozlabs.org
 S:	Maintained
 F:	arch/powerpc/boot/ps3*
 F:	arch/powerpc/include/asm/lv1call.h
 F:	arch/powerpc/include/asm/ps3*.h
 F:	arch/powerpc/platforms/ps3/
 F:	drivers/*/ps3*
 F:	drivers/ps3/
 F:	drivers/rtc/rtc-ps3.c
 F:	drivers/usb/host/*ps3.c
 F:	sound/ppc/snd_ps3*
 
 PS3VRAM DRIVER
 M:	Jim Paris <jim@jtan.com>
 M:	Geoff Levand <geoff@infradead.org>
 L:	linuxppc-dev@lists.ozlabs.org
 S:	Maintained
 F:	drivers/block/ps3vram.c
 
 PSAMPLE PACKET SAMPLING SUPPORT:
 M:	Yotam Gigi <yotamg@mellanox.com>
 S:	Maintained
 F:	net/psample
 F:	include/net/psample.h
 F:	include/uapi/linux/psample.h
 
 PSTORE FILESYSTEM
 M:	Kees Cook <keescook@chromium.org>
 M:	Anton Vorontsov <anton@enomsg.org>
 M:	Colin Cross <ccross@android.com>
 M:	Tony Luck <tony.luck@intel.com>
 S:	Maintained
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/kees/linux.git for-next/pstore
 F:	fs/pstore/
 F:	include/linux/pstore*
 F:	drivers/firmware/efi/efi-pstore.c
 F:	drivers/acpi/apei/erst.c
 F:	Documentation/admin-guide/ramoops.rst
 F:	Documentation/devicetree/bindings/reserved-memory/ramoops.txt
 K:	\b(pstore|ramoops)
 
 PTP HARDWARE CLOCK SUPPORT
 M:	Richard Cochran <richardcochran@gmail.com>
 L:	netdev@vger.kernel.org
 S:	Maintained
 W:	http://linuxptp.sourceforge.net/
 F:	Documentation/ABI/testing/sysfs-ptp
 F:	Documentation/ptp/*
 F:	drivers/net/ethernet/freescale/gianfar_ptp.c
 F:	drivers/net/phy/dp83640*
 F:	drivers/ptp/*
 F:	include/linux/ptp_cl*
 
 PTRACE SUPPORT
 M:	Roland McGrath <roland@hack.frob.com>
 M:	Oleg Nesterov <oleg@redhat.com>
 S:	Maintained
 F:	include/asm-generic/syscall.h
 F:	include/linux/ptrace.h
 F:	include/linux/regset.h
 F:	include/linux/tracehook.h
 F:	include/uapi/linux/ptrace.h
 F:	kernel/ptrace.c
 
 PULSE8-CEC DRIVER
 M:	Hans Verkuil <hverkuil@xs4all.nl>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Maintained
 F:	drivers/media/usb/pulse8-cec/*
 
 PVRUSB2 VIDEO4LINUX DRIVER
 M:	Mike Isely <isely@pobox.com>
 L:	pvrusb2@isely.net	(subscribers-only)
 L:	linux-media@vger.kernel.org
 W:	http://www.isely.net/pvrusb2/
 T:	git git://linuxtv.org/media_tree.git
 S:	Maintained
 F:	Documentation/media/v4l-drivers/pvrusb2*
 F:	drivers/media/usb/pvrusb2/
 
 PWC WEBCAM DRIVER
 M:	Hans Verkuil <hverkuil@xs4all.nl>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Odd Fixes
 F:	drivers/media/usb/pwc/*
 
 PWM FAN DRIVER
 M:	Kamil Debski <kamil@wypas.org>
 M:	Bartlomiej Zolnierkiewicz <b.zolnierkie@samsung.com>
 L:	linux-hwmon@vger.kernel.org
 S:	Supported
 F:	Documentation/devicetree/bindings/hwmon/pwm-fan.txt
 F:	Documentation/hwmon/pwm-fan
 F:	drivers/hwmon/pwm-fan.c
 
 PWM SUBSYSTEM
 M:	Thierry Reding <thierry.reding@gmail.com>
 L:	linux-pwm@vger.kernel.org
 S:	Maintained
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/thierry.reding/linux-pwm.git
 F:	Documentation/pwm.txt
 F:	Documentation/devicetree/bindings/pwm/
 F:	include/linux/pwm.h
 F:	drivers/pwm/
 F:	drivers/video/backlight/pwm_bl.c
 F:	include/linux/pwm_backlight.h
 
 PXA2xx/PXA3xx SUPPORT
 M:	Daniel Mack <daniel@zonque.org>
 M:	Haojian Zhuang <haojian.zhuang@gmail.com>
 M:	Robert Jarzmik <robert.jarzmik@free.fr>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 T:	git git://github.com/hzhuang1/linux.git
 T:	git git://github.com/rjarzmik/linux.git
 S:	Maintained
 F:	arch/arm/boot/dts/pxa*
 F:	arch/arm/mach-pxa/
 F:	drivers/dma/pxa*
 F:	drivers/pcmcia/pxa2xx*
 F:	drivers/pinctrl/pxa/
 F:	drivers/spi/spi-pxa2xx*
 F:	drivers/usb/gadget/udc/pxa2*
 F:	include/sound/pxa2xx-lib.h
 F:	sound/arm/pxa*
 F:	sound/soc/pxa/
 
 PXA GPIO DRIVER
 M:	Robert Jarzmik <robert.jarzmik@free.fr>
 L:	linux-gpio@vger.kernel.org
 S:	Maintained
 F:	drivers/gpio/gpio-pxa.c
 
 PXA3xx NAND FLASH DRIVER
 M:	Ezequiel Garcia <ezequiel.garcia@free-electrons.com>
 L:	linux-mtd@lists.infradead.org
 S:	Maintained
 F:	drivers/mtd/nand/pxa3xx_nand.c
 
 MMP SUPPORT
 M:	Eric Miao <eric.y.miao@gmail.com>
 M:	Haojian Zhuang <haojian.zhuang@gmail.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 T:	git git://github.com/hzhuang1/linux.git
 T:	git git://git.linaro.org/people/ycmiao/pxa-linux.git
 S:	Maintained
 F:	arch/arm/boot/dts/mmp*
 F:	arch/arm/mach-mmp/
 
 PXA MMCI DRIVER
 S:	Orphan
 
 PXA RTC DRIVER
 M:	Robert Jarzmik <robert.jarzmik@free.fr>
 L:	rtc-linux@googlegroups.com
 S:	Maintained
 
 QAT DRIVER
 M:	Giovanni Cabiddu <giovanni.cabiddu@intel.com>
 M:	Salvatore Benedetto <salvatore.benedetto@intel.com>
 L:	qat-linux@intel.com
 S:	Supported
 F:	drivers/crypto/qat/
 
 QIB DRIVER
 M:	Mike Marciniszyn <infinipath@intel.com>
 L:	linux-rdma@vger.kernel.org
 S:	Supported
 F:	drivers/infiniband/hw/qib/
 
 QLOGIC QLA1280 SCSI DRIVER
 M:	Michael Reed <mdr@sgi.com>
 L:	linux-scsi@vger.kernel.org
 S:	Maintained
 F:	drivers/scsi/qla1280.[ch]
 
 QLOGIC QLA2XXX FC-SCSI DRIVER
 M:	qla2xxx-upstream@qlogic.com
 L:	linux-scsi@vger.kernel.org
 S:	Supported
 F:	Documentation/scsi/LICENSE.qla2xxx
 F:	drivers/scsi/qla2xxx/
 
 QLOGIC QLA4XXX iSCSI DRIVER
 M:	QLogic-Storage-Upstream@qlogic.com
 L:	linux-scsi@vger.kernel.org
 S:	Supported
 F:	Documentation/scsi/LICENSE.qla4xxx
 F:	drivers/scsi/qla4xxx/
 
 QLOGIC QLA3XXX NETWORK DRIVER
 M:	Dept-GELinuxNICDev@cavium.com
 L:	netdev@vger.kernel.org
 S:	Supported
 F:	Documentation/networking/LICENSE.qla3xxx
 F:	drivers/net/ethernet/qlogic/qla3xxx.*
 
 QLOGIC QLCNIC (1/10)Gb ETHERNET DRIVER
 M:	Harish Patil <harish.patil@cavium.com>
 M:	Manish Chopra <manish.chopra@cavium.com>
 M:	Dept-GELinuxNICDev@cavium.com
 L:	netdev@vger.kernel.org
 S:	Supported
 F:	drivers/net/ethernet/qlogic/qlcnic/
 
 QLOGIC QLGE 10Gb ETHERNET DRIVER
 M:	Harish Patil <harish.patil@cavium.com>
 M:	Manish Chopra <manish.chopra@cavium.com>
 M:	Dept-GELinuxNICDev@cavium.com
 L:	netdev@vger.kernel.org
 S:	Supported
 F:	drivers/net/ethernet/qlogic/qlge/
 
 QLOGIC QL4xxx ETHERNET DRIVER
 M:	Yuval Mintz <Yuval.Mintz@cavium.com>
 M:	Ariel Elior <Ariel.Elior@cavium.com>
 M:	everest-linux-l2@cavium.com
 L:	netdev@vger.kernel.org
 S:	Supported
 F:	drivers/net/ethernet/qlogic/qed/
 F:	include/linux/qed/
 F:	drivers/net/ethernet/qlogic/qede/
 
 QLOGIC QL41xxx ISCSI DRIVER
 M:	QLogic-Storage-Upstream@cavium.com
 L:	linux-scsi@vger.kernel.org
 S:	Supported
 F:	drivers/scsi/qedi/
 
 QNX4 FILESYSTEM
 M:	Anders Larsen <al@alarsen.net>
 W:	http://www.alarsen.net/linux/qnx4fs/
 S:	Maintained
 F:	fs/qnx4/
 F:	include/uapi/linux/qnx4_fs.h
 F:	include/uapi/linux/qnxtypes.h
 
 QORIQ DPAA2 FSL-MC BUS DRIVER
 M:	Stuart Yoder <stuart.yoder@nxp.com>
 L:	linux-kernel@vger.kernel.org
 S:	Maintained
 F:	drivers/staging/fsl-mc/
 
 QT1010 MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://palosaari.fi/linux/
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/anttip/media_tree.git
 S:	Maintained
 F:	drivers/media/tuners/qt1010*
 
 QUALCOMM ATHEROS ATH9K WIRELESS DRIVER
 M:	QCA ath9k Development <ath9k-devel@qca.qualcomm.com>
 L:	linux-wireless@vger.kernel.org
 W:	http://wireless.kernel.org/en/users/Drivers/ath9k
 S:	Supported
 F:	drivers/net/wireless/ath/ath9k/
 
 QUALCOMM ATHEROS ATH10K WIRELESS DRIVER
 M:	Kalle Valo <kvalo@qca.qualcomm.com>
 L:	ath10k@lists.infradead.org
 W:	http://wireless.kernel.org/en/users/Drivers/ath10k
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/kvalo/ath.git
 S:	Supported
 F:	drivers/net/wireless/ath/ath10k/
 
 QUALCOMM EMAC GIGABIT ETHERNET DRIVER
 M:	Timur Tabi <timur@codeaurora.org>
 L:	netdev@vger.kernel.org
 S:	Supported
 F:	drivers/net/ethernet/qualcomm/emac/
 
 QUALCOMM HEXAGON ARCHITECTURE
 M:	Richard Kuo <rkuo@codeaurora.org>
 L:	linux-hexagon@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/rkuo/linux-hexagon-kernel.git
 S:	Supported
 F:	arch/hexagon/
 
 QUALCOMM WCN36XX WIRELESS DRIVER
 M:	Eugene Krasnikov <k.eugene.e@gmail.com>
 L:	wcn36xx@lists.infradead.org
 W:	http://wireless.kernel.org/en/users/Drivers/wcn36xx
 T:	git git://github.com/KrasnikovEugene/wcn36xx.git
 S:	Supported
 F:	drivers/net/wireless/ath/wcn36xx/
 
 QEMU MACHINE EMULATOR AND VIRTUALIZER SUPPORT
 M:	Gabriel Somlo <somlo@cmu.edu>
 M:	"Michael S. Tsirkin" <mst@redhat.com>
 L:	qemu-devel@nongnu.org
 S:	Maintained
 F:	drivers/firmware/qemu_fw_cfg.c
 
 RADOS BLOCK DEVICE (RBD)
 M:	Ilya Dryomov <idryomov@gmail.com>
 M:	Sage Weil <sage@redhat.com>
 M:	Alex Elder <elder@kernel.org>
 L:	ceph-devel@vger.kernel.org
 W:	http://ceph.com/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/sage/ceph-client.git
 T:	git git://github.com/ceph/ceph-client.git
 S:	Supported
 F:	Documentation/ABI/testing/sysfs-bus-rbd
 F:	drivers/block/rbd.c
 F:	drivers/block/rbd_types.h
 
 RADEON FRAMEBUFFER DISPLAY DRIVER
 M:	Benjamin Herrenschmidt <benh@kernel.crashing.org>
 L:	linux-fbdev@vger.kernel.org
 S:	Maintained
 F:	drivers/video/fbdev/aty/radeon*
 F:	include/uapi/linux/radeonfb.h
 
 RADIOSHARK RADIO DRIVER
 M:	Hans Verkuil <hverkuil@xs4all.nl>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Maintained
 F:	drivers/media/radio/radio-shark.c
 
 RADIOSHARK2 RADIO DRIVER
 M:	Hans Verkuil <hverkuil@xs4all.nl>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Maintained
 F:	drivers/media/radio/radio-shark2.c
 F:	drivers/media/radio/radio-tea5777.c
 
 RAGE128 FRAMEBUFFER DISPLAY DRIVER
 M:	Paul Mackerras <paulus@samba.org>
 L:	linux-fbdev@vger.kernel.org
 S:	Maintained
 F:	drivers/video/fbdev/aty/aty128fb.c
 
 RALINK MIPS ARCHITECTURE
 M:	John Crispin <john@phrozen.org>
 L:	linux-mips@linux-mips.org
 S:	Maintained
 F:	arch/mips/ralink
 
 RALINK RT2X00 WIRELESS LAN DRIVER
 P:	rt2x00 project
 M:	Stanislaw Gruszka <sgruszka@redhat.com>
 M:	Helmut Schaa <helmut.schaa@googlemail.com>
 L:	linux-wireless@vger.kernel.org
 S:	Maintained
 F:	drivers/net/wireless/ralink/rt2x00/
 
 RAMDISK RAM BLOCK DEVICE DRIVER
 M:	Jens Axboe <axboe@kernel.dk>
 S:	Maintained
 F:	Documentation/blockdev/ramdisk.txt
 F:	drivers/block/brd.c
 
 RANDOM NUMBER DRIVER
 M:	"Theodore Ts'o" <tytso@mit.edu>
 S:	Maintained
 F:	drivers/char/random.c
 
 RAPIDIO SUBSYSTEM
 M:	Matt Porter <mporter@kernel.crashing.org>
 M:	Alexandre Bounine <alexandre.bounine@idt.com>
 S:	Maintained
 F:	drivers/rapidio/
 
 RAYLINK/WEBGEAR 802.11 WIRELESS LAN DRIVER
 L:	linux-wireless@vger.kernel.org
 S:	Orphan
 F:	drivers/net/wireless/ray*
 
 RCUTORTURE MODULE
 M:	Josh Triplett <josh@joshtriplett.org>
 M:	"Paul E. McKenney" <paulmck@linux.vnet.ibm.com>
 L:	linux-kernel@vger.kernel.org
 S:	Supported
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/paulmck/linux-rcu.git
 F:	Documentation/RCU/torture.txt
 F:	kernel/rcu/rcutorture.c
 
 RCUTORTURE TEST FRAMEWORK
 M:	"Paul E. McKenney" <paulmck@linux.vnet.ibm.com>
 M:	Josh Triplett <josh@joshtriplett.org>
 R:	Steven Rostedt <rostedt@goodmis.org>
 R:	Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
 R:	Lai Jiangshan <jiangshanlai@gmail.com>
 L:	linux-kernel@vger.kernel.org
 S:	Supported
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/paulmck/linux-rcu.git
 F:	tools/testing/selftests/rcutorture
 
 RDC R-321X SoC
 M:	Florian Fainelli <florian@openwrt.org>
 S:	Maintained
 
 RDC R6040 FAST ETHERNET DRIVER
 M:	Florian Fainelli <f.fainelli@gmail.com>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/ethernet/rdc/r6040.c
 
 RDS - RELIABLE DATAGRAM SOCKETS
 M:	Santosh Shilimkar <santosh.shilimkar@oracle.com>
 L:	netdev@vger.kernel.org
 L:	linux-rdma@vger.kernel.org
 L:	rds-devel@oss.oracle.com (moderated for non-subscribers)
 W:	https://oss.oracle.com/projects/rds/
 S:	Supported
 F:	net/rds/
 F:	Documentation/networking/rds.txt
 
 RDMAVT - RDMA verbs software
 M:	Dennis Dalessandro <dennis.dalessandro@intel.com>
 L:	linux-rdma@vger.kernel.org
 S:	Supported
 F:	drivers/infiniband/sw/rdmavt
 
 RDT - RESOURCE ALLOCATION
 M:	Fenghua Yu <fenghua.yu@intel.com>
 L:	linux-kernel@vger.kernel.org
 S:	Supported
 F:	arch/x86/kernel/cpu/intel_rdt*
 F:	arch/x86/include/asm/intel_rdt*
 F:	Documentation/x86/intel_rdt*
 
 READ-COPY UPDATE (RCU)
 M:	"Paul E. McKenney" <paulmck@linux.vnet.ibm.com>
 M:	Josh Triplett <josh@joshtriplett.org>
 R:	Steven Rostedt <rostedt@goodmis.org>
 R:	Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
 R:	Lai Jiangshan <jiangshanlai@gmail.com>
 L:	linux-kernel@vger.kernel.org
 W:	http://www.rdrop.com/users/paulmck/RCU/
 S:	Supported
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/paulmck/linux-rcu.git
 F:	Documentation/RCU/
 X:	Documentation/RCU/torture.txt
 F:	include/linux/rcu*
 X:	include/linux/srcu.h
 F:	kernel/rcu/
 X:	kernel/torture.c
 
 REAL TIME CLOCK (RTC) SUBSYSTEM
 M:	Alessandro Zummo <a.zummo@towertech.it>
 M:	Alexandre Belloni <alexandre.belloni@free-electrons.com>
 L:	rtc-linux@googlegroups.com
 Q:	http://patchwork.ozlabs.org/project/rtc-linux/list/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/abelloni/linux.git
 S:	Maintained
 F:	Documentation/devicetree/bindings/rtc/
 F:	Documentation/rtc.txt
 F:	drivers/rtc/
 F:	include/linux/rtc.h
 F:	include/uapi/linux/rtc.h
 F:	include/linux/rtc/
 F:	include/linux/platform_data/rtc-*
 F:	tools/testing/selftests/timers/rtctest.c
 
 REALTEK AUDIO CODECS
 M:	Bard Liao <bardliao@realtek.com>
 M:	Oder Chiou <oder_chiou@realtek.com>
 S:	Maintained
 F:	sound/soc/codecs/rt*
 F:	include/sound/rt*.h
 
 REISERFS FILE SYSTEM
 L:	reiserfs-devel@vger.kernel.org
 S:	Supported
 F:	fs/reiserfs/
 
 REGISTER MAP ABSTRACTION
 M:	Mark Brown <broonie@kernel.org>
 L:	linux-kernel@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/broonie/regmap.git
 S:	Supported
 F:	Documentation/devicetree/bindings/regmap/
 F:	drivers/base/regmap/
 F:	include/linux/regmap.h
 
 REMOTE PROCESSOR (REMOTEPROC) SUBSYSTEM
 M:	Ohad Ben-Cohen <ohad@wizery.com>
 M:	Bjorn Andersson <bjorn.andersson@linaro.org>
 L:	linux-remoteproc@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/ohad/remoteproc.git
 S:	Maintained
 F:	Documentation/devicetree/bindings/remoteproc/
 F:	Documentation/remoteproc.txt
 F:	drivers/remoteproc/
 F:	include/linux/remoteproc.h
 
 REMOTE PROCESSOR MESSAGING (RPMSG) SUBSYSTEM
 M:	Ohad Ben-Cohen <ohad@wizery.com>
 M:	Bjorn Andersson <bjorn.andersson@linaro.org>
 L:	linux-remoteproc@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/ohad/rpmsg.git
 S:	Maintained
 F:	drivers/rpmsg/
 F:	Documentation/rpmsg.txt
 F:	include/linux/rpmsg.h
 
 RENESAS CLOCK DRIVERS
 M:	Geert Uytterhoeven <geert+renesas@glider.be>
 L:	linux-renesas-soc@vger.kernel.org
 S:	Supported
 F:	drivers/clk/renesas/
 
 RENESAS ETHERNET DRIVERS
 R:	Sergei Shtylyov <sergei.shtylyov@cogentembedded.com>
 L:	netdev@vger.kernel.org
 L:	linux-renesas-soc@vger.kernel.org
 F:	drivers/net/ethernet/renesas/
 F:	include/linux/sh_eth.h
 
 RENESAS USB2 PHY DRIVER
 M:	Yoshihiro Shimoda <yoshihiro.shimoda.uh@renesas.com>
 L:	linux-renesas-soc@vger.kernel.org
 S:	Maintained
 F:	drivers/phy/phy-rcar-gen3-usb2.c
 
 RESET CONTROLLER FRAMEWORK
 M:	Philipp Zabel <p.zabel@pengutronix.de>
 T:	git git://git.pengutronix.de/git/pza/linux
 S:	Maintained
 F:	drivers/reset/
 F:	Documentation/devicetree/bindings/reset/
 F:	include/dt-bindings/reset/
 F:	include/linux/reset.h
 F:	include/linux/reset-controller.h
 
 RFKILL
 M:	Johannes Berg <johannes@sipsolutions.net>
 L:	linux-wireless@vger.kernel.org
 W:	http://wireless.kernel.org/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/jberg/mac80211.git
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/jberg/mac80211-next.git
 S:	Maintained
 F:	Documentation/rfkill.txt
 F:	net/rfkill/
 
 RHASHTABLE
 M:	Thomas Graf <tgraf@suug.ch>
 M:	Herbert Xu <herbert@gondor.apana.org.au>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	lib/rhashtable.c
 F:	include/linux/rhashtable.h
 
 RICOH SMARTMEDIA/XD DRIVER
 M:	Maxim Levitsky <maximlevitsky@gmail.com>
 S:	Maintained
 F:	drivers/mtd/nand/r852.c
 F:	drivers/mtd/nand/r852.h
 
 RICOH R5C592 MEMORYSTICK DRIVER
 M:	Maxim Levitsky <maximlevitsky@gmail.com>
 S:	Maintained
 F:	drivers/memstick/host/r592.*
 
 ROCCAT DRIVERS
 M:	Stefan Achatz <erazor_de@users.sourceforge.net>
 W:	http://sourceforge.net/projects/roccat/
 S:	Maintained
 F:	drivers/hid/hid-roccat*
 F:	include/linux/hid-roccat*
 F:	Documentation/ABI/*/sysfs-driver-hid-roccat*
 
 ROCKER DRIVER
 M:	Jiri Pirko <jiri@resnulli.us>
 L:	netdev@vger.kernel.org
 S:	Supported
 F:	drivers/net/ethernet/rocker/
 
 ROCKETPORT DRIVER
 P:	Comtrol Corp.
 W:	http://www.comtrol.com
 S:	Maintained
 F:	Documentation/serial/rocket.txt
 F:	drivers/tty/rocket*
 
 ROCKETPORT EXPRESS/INFINITY DRIVER
 M:	Kevin Cernekee <cernekee@gmail.com>
 L:	linux-serial@vger.kernel.org
 S:	Odd Fixes
 F:	drivers/tty/serial/rp2.*
 
 ROSE NETWORK LAYER
 M:	Ralf Baechle <ralf@linux-mips.org>
 L:	linux-hams@vger.kernel.org
 W:	http://www.linux-ax25.org/
 S:	Maintained
 F:	include/net/rose.h
 F:	include/uapi/linux/rose.h
 F:	net/rose/
 
 RTL2830 MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://palosaari.fi/linux/
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/anttip/media_tree.git
 S:	Maintained
 F:	drivers/media/dvb-frontends/rtl2830*
 
 RTL2832 MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://palosaari.fi/linux/
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/anttip/media_tree.git
 S:	Maintained
 F:	drivers/media/dvb-frontends/rtl2832*
 
 RTL2832_SDR MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://palosaari.fi/linux/
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/anttip/media_tree.git
 S:	Maintained
 F:	drivers/media/dvb-frontends/rtl2832_sdr*
 
 RTL8180 WIRELESS DRIVER
 L:	linux-wireless@vger.kernel.org
 W:	http://wireless.kernel.org/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/linville/wireless-testing.git
 S:	Orphan
 F:	drivers/net/wireless/realtek/rtl818x/rtl8180/
 
 RTL8187 WIRELESS DRIVER
 M:	Herton Ronaldo Krzesinski <herton@canonical.com>
 M:	Hin-Tak Leung <htl10@users.sourceforge.net>
 M:	Larry Finger <Larry.Finger@lwfinger.net>
 L:	linux-wireless@vger.kernel.org
 W:	http://wireless.kernel.org/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/linville/wireless-testing.git
 S:	Maintained
 F:	drivers/net/wireless/realtek/rtl818x/rtl8187/
 
 RTL8192CE WIRELESS DRIVER
 M:	Larry Finger <Larry.Finger@lwfinger.net>
 M:	Chaoming Li <chaoming_li@realsil.com.cn>
 L:	linux-wireless@vger.kernel.org
 W:	http://wireless.kernel.org/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/linville/wireless-testing.git
 S:	Maintained
 F:	drivers/net/wireless/realtek/rtlwifi/
 F:	drivers/net/wireless/realtek/rtlwifi/rtl8192ce/
 
 RTL8XXXU WIRELESS DRIVER (rtl8xxxu)
 M:	Jes Sorensen <Jes.Sorensen@gmail.com>
 L:	linux-wireless@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/jes/linux.git rtl8xxxu-devel
 S:	Maintained
 F:	drivers/net/wireless/realtek/rtl8xxxu/
 
 S3 SAVAGE FRAMEBUFFER DRIVER
 M:	Antonino Daplas <adaplas@gmail.com>
 L:	linux-fbdev@vger.kernel.org
 S:	Maintained
 F:	drivers/video/fbdev/savage/
 
 S390
 M:	Martin Schwidefsky <schwidefsky@de.ibm.com>
 M:	Heiko Carstens <heiko.carstens@de.ibm.com>
 L:	linux-s390@vger.kernel.org
 W:	http://www.ibm.com/developerworks/linux/linux390/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/s390/linux.git
 S:	Supported
 F:	arch/s390/
 F:	drivers/s390/
 F:	Documentation/s390/
 F:	Documentation/DocBook/s390*
 
 S390 COMMON I/O LAYER
 M:	Sebastian Ott <sebott@linux.vnet.ibm.com>
 M:	Peter Oberparleiter <oberpar@linux.vnet.ibm.com>
 L:	linux-s390@vger.kernel.org
 W:	http://www.ibm.com/developerworks/linux/linux390/
 S:	Supported
 F:	drivers/s390/cio/
 
 S390 DASD DRIVER
 M:	Stefan Haberland <sth@linux.vnet.ibm.com>
 M:	Jan Hoeppner <hoeppner@linux.vnet.ibm.com>
 L:	linux-s390@vger.kernel.org
 W:	http://www.ibm.com/developerworks/linux/linux390/
 S:	Supported
 F:	drivers/s390/block/dasd*
 F:	block/partitions/ibm.c
 
 S390 NETWORK DRIVERS
 M:	Ursula Braun <ubraun@linux.vnet.ibm.com>
 L:	linux-s390@vger.kernel.org
 W:	http://www.ibm.com/developerworks/linux/linux390/
 S:	Supported
 F:	drivers/s390/net/
 
 S390 PCI SUBSYSTEM
 M:	Sebastian Ott <sebott@linux.vnet.ibm.com>
 M:	Gerald Schaefer <gerald.schaefer@de.ibm.com>
 L:	linux-s390@vger.kernel.org
 W:	http://www.ibm.com/developerworks/linux/linux390/
 S:	Supported
 F:	arch/s390/pci/
 F:	drivers/pci/hotplug/s390_pci_hpc.c
 
 S390 ZCRYPT DRIVER
 M:	Harald Freudenberger <freude@de.ibm.com>
 L:	linux-s390@vger.kernel.org
 W:	http://www.ibm.com/developerworks/linux/linux390/
 S:	Supported
 F:	drivers/s390/crypto/
 
 S390 ZFCP DRIVER
 M:	Steffen Maier <maier@linux.vnet.ibm.com>
 L:	linux-s390@vger.kernel.org
 W:	http://www.ibm.com/developerworks/linux/linux390/
 S:	Supported
 F:	drivers/s390/scsi/zfcp_*
 
 S390 IUCV NETWORK LAYER
 M:	Ursula Braun <ubraun@linux.vnet.ibm.com>
 L:	linux-s390@vger.kernel.org
 W:	http://www.ibm.com/developerworks/linux/linux390/
 S:	Supported
 F:	drivers/s390/net/*iucv*
 F:	include/net/iucv/
 F:	net/iucv/
 
 S390 IOMMU (PCI)
 M:	Gerald Schaefer <gerald.schaefer@de.ibm.com>
 L:	linux-s390@vger.kernel.org
 W:	http://www.ibm.com/developerworks/linux/linux390/
 S:	Supported
 F:	drivers/iommu/s390-iommu.c
 
 S3C24XX SD/MMC Driver
 M:	Ben Dooks <ben-linux@fluff.org>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Supported
 F:	drivers/mmc/host/s3cmci.*
 
 SAA6588 RDS RECEIVER DRIVER
 M:	Hans Verkuil <hverkuil@xs4all.nl>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 W:	https://linuxtv.org
 S:	Odd Fixes
 F:	drivers/media/i2c/saa6588*
 
 SAA7134 VIDEO4LINUX DRIVER
 M:	Mauro Carvalho Chehab <mchehab@s-opensource.com>
 M:	Mauro Carvalho Chehab <mchehab@kernel.org>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Odd fixes
 F:	Documentation/media/v4l-drivers/saa7134*
 F:	drivers/media/pci/saa7134/
 
 SAA7146 VIDEO4LINUX-2 DRIVER
 M:	Hans Verkuil <hverkuil@xs4all.nl>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Maintained
 F:	drivers/media/common/saa7146/
 F:	drivers/media/pci/saa7146/
 F:	include/media/saa7146*
 
 SAMSUNG LAPTOP DRIVER
 M:	Corentin Chary <corentin.chary@gmail.com>
 L:	platform-driver-x86@vger.kernel.org
 S:	Maintained
 F:	drivers/platform/x86/samsung-laptop.c
 
 SAMSUNG AUDIO (ASoC) DRIVERS
 M:	Krzysztof Kozlowski <krzk@kernel.org>
 M:	Sangbeom Kim <sbkim73@samsung.com>
 M:	Sylwester Nawrocki <s.nawrocki@samsung.com>
 L:	alsa-devel@alsa-project.org (moderated for non-subscribers)
 S:	Supported
 F:	sound/soc/samsung/
 
 SAMSUNG FRAMEBUFFER DRIVER
 M:	Jingoo Han <jingoohan1@gmail.com>
 L:	linux-fbdev@vger.kernel.org
 S:	Maintained
 F:	drivers/video/fbdev/s3c-fb.c
 
 SAMSUNG MULTIFUNCTION PMIC DEVICE DRIVERS
 M:	Sangbeom Kim <sbkim73@samsung.com>
 M:	Krzysztof Kozlowski <krzk@kernel.org>
 M:	Bartlomiej Zolnierkiewicz <b.zolnierkie@samsung.com>
 L:	linux-kernel@vger.kernel.org
 L:	linux-samsung-soc@vger.kernel.org
 S:	Supported
 F:	drivers/mfd/sec*.c
 F:	drivers/regulator/s2m*.c
 F:	drivers/regulator/s5m*.c
 F:	drivers/clk/clk-s2mps11.c
 F:	drivers/rtc/rtc-s5m.c
 F:	include/linux/mfd/samsung/
 F:	Documentation/devicetree/bindings/mfd/samsung,sec-core.txt
 F:	Documentation/devicetree/bindings/regulator/samsung,s2m*.txt
 F:	Documentation/devicetree/bindings/regulator/samsung,s5m*.txt
 F:	Documentation/devicetree/bindings/clock/samsung,s2mps11.txt
 
 SAMSUNG S5P/EXYNOS4 SOC SERIES CAMERA SUBSYSTEM DRIVERS
 M:	Kyungmin Park <kyungmin.park@samsung.com>
 M:	Sylwester Nawrocki <s.nawrocki@samsung.com>
 L:	linux-media@vger.kernel.org
 Q:	https://patchwork.linuxtv.org/project/linux-media/list/
 S:	Supported
 F:	drivers/media/platform/exynos4-is/
 
 SAMSUNG S3C24XX/S3C64XX SOC SERIES CAMIF DRIVER
 M:	Sylwester Nawrocki <sylvester.nawrocki@gmail.com>
 L:	linux-media@vger.kernel.org
 L:	linux-samsung-soc@vger.kernel.org (moderated for non-subscribers)
 S:	Maintained
 F:	drivers/media/platform/s3c-camif/
 F:	include/media/drv-intf/s3c_camif.h
 
 SAMSUNG S5C73M3 CAMERA DRIVER
 M:	Kyungmin Park <kyungmin.park@samsung.com>
 M:	Andrzej Hajda <a.hajda@samsung.com>
 L:	linux-media@vger.kernel.org
 S:	Supported
 F:	drivers/media/i2c/s5c73m3/*
 
 SAMSUNG S5K5BAF CAMERA DRIVER
 M:	Kyungmin Park <kyungmin.park@samsung.com>
 M:	Andrzej Hajda <a.hajda@samsung.com>
 L:	linux-media@vger.kernel.org
 S:	Supported
 F:	drivers/media/i2c/s5k5baf.c
 
 SAMSUNG S3FWRN5 NFC DRIVER
 M:	Robert Baldyga <r.baldyga@samsung.com>
 M:	Krzysztof Opasiak <k.opasiak@samsung.com>
 L:	linux-nfc@lists.01.org (moderated for non-subscribers)
 S:	Supported
 F:	drivers/nfc/s3fwrn5
 
 SAMSUNG SOC CLOCK DRIVERS
 M:	Sylwester Nawrocki <s.nawrocki@samsung.com>
 M:	Tomasz Figa <tomasz.figa@gmail.com>
 M:	Chanwoo Choi <cw00.choi@samsung.com>
 S:	Supported
 L:	linux-samsung-soc@vger.kernel.org (moderated for non-subscribers)
 F:	drivers/clk/samsung/
 F:	include/dt-bindings/clock/exynos*.h
 F:	Documentation/devicetree/bindings/clock/exynos*.txt
 
 SAMSUNG SPI DRIVERS
 M:	Kukjin Kim <kgene@kernel.org>
 M:	Krzysztof Kozlowski <krzk@kernel.org>
 M:	Andi Shyti <andi.shyti@samsung.com>
 L:	linux-spi@vger.kernel.org
 L:	linux-samsung-soc@vger.kernel.org (moderated for non-subscribers)
 S:	Maintained
 F:	Documentation/devicetree/bindings/spi/spi-samsung.txt
 F:	drivers/spi/spi-s3c*
 F:	include/linux/platform_data/spi-s3c64xx.h
 
 SAMSUNG SXGBE DRIVERS
 M:	Byungho An <bh74.an@samsung.com>
 M:	Girish K S <ks.giri@samsung.com>
 M:	Vipul Pandya <vipul.pandya@samsung.com>
 S:	Supported
 L:	netdev@vger.kernel.org
 F:	drivers/net/ethernet/samsung/sxgbe/
 
 SAMSUNG THERMAL DRIVER
 M:	Bartlomiej Zolnierkiewicz <b.zolnierkie@samsung.com>
 L:	linux-pm@vger.kernel.org
 L:	linux-samsung-soc@vger.kernel.org
 S:	Supported
 T:	git https://github.com/lmajewski/linux-samsung-thermal.git
 F:	drivers/thermal/samsung/
 
 SAMSUNG USB2 PHY DRIVER
 M:	Kamil Debski <kamil@wypas.org>
 M:	Sylwester Nawrocki <s.nawrocki@samsung.com>
 L:	linux-kernel@vger.kernel.org
 S:	Supported
 F:	Documentation/devicetree/bindings/phy/samsung-phy.txt
 F:	Documentation/phy/samsung-usb2.txt
 F:	drivers/phy/phy-exynos4210-usb2.c
 F:	drivers/phy/phy-exynos4x12-usb2.c
 F:	drivers/phy/phy-exynos5250-usb2.c
 F:	drivers/phy/phy-s5pv210-usb2.c
 F:	drivers/phy/phy-samsung-usb2.c
 F:	drivers/phy/phy-samsung-usb2.h
 
 SERIAL DRIVERS
 M:	Greg Kroah-Hartman <gregkh@linuxfoundation.org>
 L:	linux-serial@vger.kernel.org
 S:	Maintained
 F:	Documentation/devicetree/bindings/serial/
 F:	drivers/tty/serial/
 
 SERIAL IR RECEIVER
 M:	Sean Young <sean@mess.org>
 L:	linux-media@vger.kernel.org
 S:	Maintained
 F:	drivers/media/rc/serial_ir.c
 
 STI CEC DRIVER
 M:	Benjamin Gaignard <benjamin.gaignard@linaro.org>
 L:	kernel@stlinux.com
 S:	Maintained
 F:	drivers/staging/media/st-cec/
 F:	Documentation/devicetree/bindings/media/stih-cec.txt
 
 SHARED MEMORY COMMUNICATIONS (SMC) SOCKETS
 M:	Ursula Braun <ubraun@linux.vnet.ibm.com>
 L:	linux-s390@vger.kernel.org
 W:	http://www.ibm.com/developerworks/linux/linux390/
 S:	Supported
 F:	net/smc/
 
 SYNOPSYS DESIGNWARE DMAC DRIVER
 M:	Viresh Kumar <vireshk@kernel.org>
 M:	Andy Shevchenko <andriy.shevchenko@linux.intel.com>
 S:	Maintained
 F:	include/linux/dma/dw.h
 F:	include/linux/platform_data/dma-dw.h
 F:	drivers/dma/dw/
 
 SYNOPSYS DESIGNWARE I2C DRIVER
 M:	Jarkko Nikula <jarkko.nikula@linux.intel.com>
 R:	Andy Shevchenko <andriy.shevchenko@linux.intel.com>
 R:	Mika Westerberg <mika.westerberg@linux.intel.com>
 L:	linux-i2c@vger.kernel.org
 S:	Maintained
 F:	drivers/i2c/busses/i2c-designware-*
 F:	include/linux/platform_data/i2c-designware.h
 
 SYNOPSYS DESIGNWARE MMC/SD/SDIO DRIVER
 M:	Jaehoon Chung <jh80.chung@samsung.com>
 L:	linux-mmc@vger.kernel.org
 S:	Maintained
 F:	drivers/mmc/host/dw_mmc*
 
 SYSTEM TRACE MODULE CLASS
 M:	Alexander Shishkin <alexander.shishkin@linux.intel.com>
 S:	Maintained
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/ash/stm.git
 F:	Documentation/trace/stm.txt
 F:	drivers/hwtracing/stm/
 F:	include/linux/stm.h
 F:	include/uapi/linux/stm.h
 
 THUNDERBOLT DRIVER
 M:	Andreas Noever <andreas.noever@gmail.com>
 S:	Maintained
 F:	drivers/thunderbolt/
 
 TI BQ27XXX POWER SUPPLY DRIVER
 R:	Andrew F. Davis <afd@ti.com>
 F:	include/linux/power/bq27xxx_battery.h
 F:	drivers/power/supply/bq27xxx_battery.c
 F:	drivers/power/supply/bq27xxx_battery_i2c.c
 
 TIMEKEEPING, CLOCKSOURCE CORE, NTP, ALARMTIMER
 M:	John Stultz <john.stultz@linaro.org>
 M:	Thomas Gleixner <tglx@linutronix.de>
 L:	linux-kernel@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip.git timers/core
 S:	Supported
 F:	include/linux/clocksource.h
 F:	include/linux/time.h
 F:	include/linux/timex.h
 F:	include/uapi/linux/time.h
 F:	include/uapi/linux/timex.h
 F:	kernel/time/clocksource.c
 F:	kernel/time/time*.c
 F:	kernel/time/alarmtimer.c
 F:	kernel/time/ntp.c
 F:	tools/testing/selftests/timers/
 
 SC1200 WDT DRIVER
 M:	Zwane Mwaikambo <zwanem@gmail.com>
 S:	Maintained
 F:	drivers/watchdog/sc1200wdt.c
 
 SCHEDULER
 M:	Ingo Molnar <mingo@redhat.com>
 M:	Peter Zijlstra <peterz@infradead.org>
 L:	linux-kernel@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip.git sched/core
 S:	Maintained
 F:	kernel/sched/
 F:	include/linux/sched.h
 F:	include/uapi/linux/sched.h
 F:	include/linux/wait.h
 
 SCORE ARCHITECTURE
 M:	Chen Liqin <liqin.linux@gmail.com>
 M:	Lennox Wu <lennox.wu@gmail.com>
 W:	http://www.sunplus.com
 S:	Supported
 F:	arch/score/
 
 SCR24X CHIP CARD INTERFACE DRIVER
 M:	Lubomir Rintel <lkundrak@v3.sk>
 S:	Supported
 F:	drivers/char/pcmcia/scr24x_cs.c
 
 SYSTEM CONTROL & POWER INTERFACE (SCPI) Message Protocol drivers
 M:	Sudeep Holla <sudeep.holla@arm.com>
 L:	linux-arm-kernel@lists.infradead.org
 S:	Maintained
 F:	Documentation/devicetree/bindings/arm/arm,scpi.txt
 F:	drivers/clk/clk-scpi.c
 F:	drivers/cpufreq/scpi-cpufreq.c
 F:	drivers/firmware/arm_scpi.c
 F:	include/linux/scpi_protocol.h
 
 SCSI CDROM DRIVER
 M:	Jens Axboe <axboe@kernel.dk>
 L:	linux-scsi@vger.kernel.org
 W:	http://www.kernel.dk
 S:	Maintained
 F:	drivers/scsi/sr*
 
 SCSI RDMA PROTOCOL (SRP) INITIATOR
 M:	Bart Van Assche <bart.vanassche@sandisk.com>
 L:	linux-rdma@vger.kernel.org
 S:	Supported
 W:	http://www.openfabrics.org
 Q:	http://patchwork.kernel.org/project/linux-rdma/list/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/dad/srp-initiator.git
 F:	drivers/infiniband/ulp/srp/
 F:	include/scsi/srp.h
 
 SCSI SG DRIVER
 M:	Doug Gilbert <dgilbert@interlog.com>
 L:	linux-scsi@vger.kernel.org
 W:	http://sg.danny.cz/sg
 S:	Maintained
 F:	Documentation/scsi/scsi-generic.txt
 F:	drivers/scsi/sg.c
 F:	include/scsi/sg.h
 
 SCSI SUBSYSTEM
 M:	"James E.J. Bottomley" <jejb@linux.vnet.ibm.com>
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/jejb/scsi.git
 M:	"Martin K. Petersen" <martin.petersen@oracle.com>
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/mkp/scsi.git
 L:	linux-scsi@vger.kernel.org
 S:	Maintained
 F:	Documentation/devicetree/bindings/scsi/
 F:	drivers/scsi/
 F:	include/scsi/
 
 SCSI TAPE DRIVER
 M:	Kai MÃ¤kisara <Kai.Makisara@kolumbus.fi>
 L:	linux-scsi@vger.kernel.org
 S:	Maintained
 F:	Documentation/scsi/st.txt
 F:	drivers/scsi/st.*
 F:	drivers/scsi/st_*.h
 
 SCTP PROTOCOL
 M:	Vlad Yasevich <vyasevich@gmail.com>
 M:	Neil Horman <nhorman@tuxdriver.com>
 L:	linux-sctp@vger.kernel.org
 W:	http://lksctp.sourceforge.net
 S:	Maintained
 F:	Documentation/networking/sctp.txt
 F:	include/linux/sctp.h
 F:	include/uapi/linux/sctp.h
 F:	include/net/sctp/
 F:	net/sctp/
 
 SCx200 CPU SUPPORT
 M:	Jim Cromie <jim.cromie@gmail.com>
 S:	Odd Fixes
 F:	Documentation/i2c/busses/scx200_acb
 F:	arch/x86/platform/scx200/
 F:	drivers/watchdog/scx200_wdt.c
 F:	drivers/i2c/busses/scx200*
 F:	drivers/mtd/maps/scx200_docflash.c
 F:	include/linux/scx200.h
 
 SCx200 GPIO DRIVER
 M:	Jim Cromie <jim.cromie@gmail.com>
 S:	Maintained
 F:	drivers/char/scx200_gpio.c
 F:	include/linux/scx200_gpio.h
 
 SCx200 HRT CLOCKSOURCE DRIVER
 M:	Jim Cromie <jim.cromie@gmail.com>
 S:	Maintained
 F:	drivers/clocksource/scx200_hrt.c
 
 SDRICOH_CS MMC/SD HOST CONTROLLER INTERFACE DRIVER
 M:	Sascha Sommer <saschasommer@freenet.de>
 L:	sdricohcs-devel@lists.sourceforge.net (subscribers-only)
 S:	Maintained
 F:	drivers/mmc/host/sdricoh_cs.c
 
 SECURE DIGITAL HOST CONTROLLER INTERFACE (SDHCI) DRIVER
 M:	Adrian Hunter <adrian.hunter@intel.com>
 L:	linux-mmc@vger.kernel.org
 T:	git git://git.infradead.org/users/ahunter/linux-sdhci.git
 S:	Maintained
 F:	drivers/mmc/host/sdhci*
 F:	include/linux/mmc/sdhci*
 
 SECURE COMPUTING
 M:	Kees Cook <keescook@chromium.org>
 R:	Andy Lutomirski <luto@amacapital.net>
 R:	Will Drewry <wad@chromium.org>
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/kees/linux.git seccomp
 S:	Supported
 F:	kernel/seccomp.c
 F:	include/uapi/linux/seccomp.h
 F:	include/linux/seccomp.h
 F:	tools/testing/selftests/seccomp/*
 K:	\bsecure_computing
 K:	\bTIF_SECCOMP\b
 
 SECURE DIGITAL HOST CONTROLLER INTERFACE (SDHCI) Broadcom BRCMSTB DRIVER
 M:	Al Cooper <alcooperx@gmail.com>
 L:	linux-mmc@vger.kernel.org
 L:	bcm-kernel-feedback-list@broadcom.com
 S:	Maintained
 F:	drivers/mmc/host/sdhci-brcmstb*
 
 SECURE DIGITAL HOST CONTROLLER INTERFACE (SDHCI) SAMSUNG DRIVER
 M:	Ben Dooks <ben-linux@fluff.org>
 M:	Jaehoon Chung <jh80.chung@samsung.com>
 L:	linux-mmc@vger.kernel.org
 S:	Maintained
 F:	drivers/mmc/host/sdhci-s3c*
 
 SECURE DIGITAL HOST CONTROLLER INTERFACE (SDHCI) ST SPEAR DRIVER
 M:	Viresh Kumar <vireshk@kernel.org>
 L:	linux-mmc@vger.kernel.org
 S:	Maintained
 F:	drivers/mmc/host/sdhci-spear.c
 
 SECURE ENCRYPTING DEVICE (SED) OPAL DRIVER
 M:	Scott Bauer <scott.bauer@intel.com>
 M:	Jonathan Derrick <jonathan.derrick@intel.com>
 M:	Rafael Antognolli <rafael.antognolli@intel.com>
 L:	linux-block@vger.kernel.org
 S:	Supported
 F:	block/sed*
 F:	block/opal_proto.h
 F:	include/linux/sed*
 F:	include/uapi/linux/sed*
 
 SECURITY SUBSYSTEM
 M:	James Morris <james.l.morris@oracle.com>
 M:	"Serge E. Hallyn" <serge@hallyn.com>
 L:	linux-security-module@vger.kernel.org (suggested Cc:)
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/jmorris/linux-security.git
 W:	http://kernsec.org/
 S:	Supported
 F:	security/
 
 SECURITY CONTACT
 M:	Security Officers <security@kernel.org>
 S:	Supported
 
 SELINUX SECURITY MODULE
 M:	Paul Moore <paul@paul-moore.com>
 M:	Stephen Smalley <sds@tycho.nsa.gov>
 M:	Eric Paris <eparis@parisplace.org>
 L:	selinux@tycho.nsa.gov (moderated for non-subscribers)
 W:	http://selinuxproject.org
 T:	git git://git.infradead.org/users/pcmoore/selinux
 S:	Supported
 F:	include/linux/selinux*
 F:	security/selinux/
 F:	scripts/selinux/
 
 APPARMOR SECURITY MODULE
 M:	John Johansen <john.johansen@canonical.com>
 L:	apparmor@lists.ubuntu.com (subscribers-only, general discussion)
 W:	apparmor.wiki.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/jj/apparmor-dev.git
 S:	Supported
 F:	security/apparmor/
 
 LOADPIN SECURITY MODULE
 M:	Kees Cook <keescook@chromium.org>
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/kees/linux.git lsm/loadpin
 S:	Supported
 F:	security/loadpin/
 
 YAMA SECURITY MODULE
 M:	Kees Cook <keescook@chromium.org>
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/kees/linux.git yama/tip
 S:	Supported
 F:	security/yama/
 
 SENSABLE PHANTOM
 M:	Jiri Slaby <jirislaby@gmail.com>
 S:	Maintained
 F:	drivers/misc/phantom.c
 F:	include/uapi/linux/phantom.h
 
 Emulex 10Gbps iSCSI - OneConnect DRIVER
 M:	Subbu Seetharaman <subbu.seetharaman@broadcom.com>
 M:	Ketan Mukadam <ketan.mukadam@broadcom.com>
 M:	Jitendra Bhivare <jitendra.bhivare@broadcom.com>
 L:	linux-scsi@vger.kernel.org
 W:	http://www.broadcom.com
 S:	Supported
 F:	drivers/scsi/be2iscsi/
 
 Emulex 10Gbps NIC BE2, BE3-R, Lancer, Skyhawk-R DRIVER (be2net)
 M:	Sathya Perla <sathya.perla@broadcom.com>
 M:	Ajit Khaparde <ajit.khaparde@broadcom.com>
 M:	Sriharsha Basavapatna <sriharsha.basavapatna@broadcom.com>
 M:	Somnath Kotur <somnath.kotur@broadcom.com>
 L:	netdev@vger.kernel.org
 W:	http://www.emulex.com
 S:	Supported
 F:	drivers/net/ethernet/emulex/benet/
 
 EMULEX ONECONNECT ROCE DRIVER
 M:	Selvin Xavier <selvin.xavier@avagotech.com>
 M:	Devesh Sharma <devesh.sharma@avagotech.com>
 L:	linux-rdma@vger.kernel.org
 W:	http://www.emulex.com
 S:	Supported
 F:	drivers/infiniband/hw/ocrdma/
 F:	include/uapi/rdma/ocrdma-abi.h
 
 SFC NETWORK DRIVER
 M:	Solarflare linux maintainers <linux-net-drivers@solarflare.com>
 M:	Edward Cree <ecree@solarflare.com>
 M:	Bert Kenward <bkenward@solarflare.com>
 L:	netdev@vger.kernel.org
 S:	Supported
 F:	drivers/net/ethernet/sfc/
 
 SGI GRU DRIVER
 M:	Dimitri Sivanich <sivanich@sgi.com>
 S:	Maintained
 F:	drivers/misc/sgi-gru/
 
 SGI SN-IA64 (Altix) SERIAL CONSOLE DRIVER
 M:	Pat Gefre <pfg@sgi.com>
 L:	linux-ia64@vger.kernel.org
 S:	Supported
 F:	Documentation/ia64/serial.txt
 F:	drivers/tty/serial/ioc?_serial.c
 F:	include/linux/ioc?.h
 
 SGI XP/XPC/XPNET DRIVER
 M:	Cliff Whickman <cpw@sgi.com>
 M:	Robin Holt <robinmholt@gmail.com>
 S:	Maintained
 F:	drivers/misc/sgi-xp/
 
 SI2157 MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://palosaari.fi/linux/
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/anttip/media_tree.git
 S:	Maintained
 F:	drivers/media/tuners/si2157*
 
 SI2168 MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://palosaari.fi/linux/
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/anttip/media_tree.git
 S:	Maintained
 F:	drivers/media/dvb-frontends/si2168*
 
 SI470X FM RADIO RECEIVER I2C DRIVER
 M:	Hans Verkuil <hverkuil@xs4all.nl>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 W:	https://linuxtv.org
 S:	Odd Fixes
 F:	drivers/media/radio/si470x/radio-si470x-i2c.c
 
 SI470X FM RADIO RECEIVER USB DRIVER
 M:	Hans Verkuil <hverkuil@xs4all.nl>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 W:	https://linuxtv.org
 S:	Maintained
 F:	drivers/media/radio/si470x/radio-si470x-common.c
 F:	drivers/media/radio/si470x/radio-si470x.h
 F:	drivers/media/radio/si470x/radio-si470x-usb.c
 
 SI4713 FM RADIO TRANSMITTER I2C DRIVER
 M:	Eduardo Valentin <edubezval@gmail.com>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 W:	https://linuxtv.org
 S:	Odd Fixes
 F:	drivers/media/radio/si4713/si4713.?
 
 SI4713 FM RADIO TRANSMITTER PLATFORM DRIVER
 M:	Eduardo Valentin <edubezval@gmail.com>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 W:	https://linuxtv.org
 S:	Odd Fixes
 F:	drivers/media/radio/si4713/radio-platform-si4713.c
 
 SI4713 FM RADIO TRANSMITTER USB DRIVER
 M:	Hans Verkuil <hverkuil@xs4all.nl>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 W:	https://linuxtv.org
 S:	Maintained
 F:	drivers/media/radio/si4713/radio-usb-si4713.c
 
 SIANO DVB DRIVER
 M:	Mauro Carvalho Chehab <mchehab@s-opensource.com>
 M:	Mauro Carvalho Chehab <mchehab@kernel.org>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Odd fixes
 F:	drivers/media/common/siano/
 F:	drivers/media/usb/siano/
 F:	drivers/media/usb/siano/
 F:	drivers/media/mmc/siano/
 
 SIMPLEFB FB DRIVER
 M:	Hans de Goede <hdegoede@redhat.com>
 L:	linux-fbdev@vger.kernel.org
 S:	Maintained
 F:	Documentation/devicetree/bindings/display/simple-framebuffer.txt
 F:	drivers/video/fbdev/simplefb.c
 F:	include/linux/platform_data/simplefb.h
 
 SH_VEU V4L2 MEM2MEM DRIVER
 L:	linux-media@vger.kernel.org
 S:	Orphan
 F:	drivers/media/platform/sh_veu.c
 
 SH_VOU V4L2 OUTPUT DRIVER
 L:	linux-media@vger.kernel.org
 S:	Orphan
 F:	drivers/media/platform/sh_vou.c
 F:	include/media/drv-intf/sh_vou.h
 
 SIMPLE FIRMWARE INTERFACE (SFI)
 M:	Len Brown <lenb@kernel.org>
 L:	sfi-devel@simplefirmware.org
 W:	http://simplefirmware.org/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/lenb/linux-sfi-2.6.git
 S:	Supported
 F:	arch/x86/platform/sfi/
 F:	drivers/sfi/
 F:	include/linux/sfi*.h
 
 SIMTEC EB110ATX (Chalice CATS)
 P:	Ben Dooks
 P:	Vincent Sanders <vince@simtec.co.uk>
 M:	Simtec Linux Team <linux@simtec.co.uk>
 W:	http://www.simtec.co.uk/products/EB110ATX/
 S:	Supported
 
 SIMTEC EB2410ITX (BAST)
 P:	Ben Dooks
 P:	Vincent Sanders <vince@simtec.co.uk>
 M:	Simtec Linux Team <linux@simtec.co.uk>
 W:	http://www.simtec.co.uk/products/EB2410ITX/
 S:	Supported
 F:	arch/arm/mach-s3c24xx/mach-bast.c
 F:	arch/arm/mach-s3c24xx/bast-ide.c
 F:	arch/arm/mach-s3c24xx/bast-irq.c
 
 SIPHASH PRF ROUTINES
 M:	Jason A. Donenfeld <Jason@zx2c4.com>
 S:	Maintained
 F:	lib/siphash.c
 F:	lib/test_siphash.c
 F:	include/linux/siphash.h
 
 TI DAVINCI MACHINE SUPPORT
 M:	Sekhar Nori <nsekhar@ti.com>
 M:	Kevin Hilman <khilman@kernel.org>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/nsekhar/linux-davinci.git
 S:	Supported
 F:	arch/arm/mach-davinci/
 F:	drivers/i2c/busses/i2c-davinci.c
 
 TI DAVINCI SERIES MEDIA DRIVER
 M:	"Lad, Prabhakar" <prabhakar.csengg@gmail.com>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/mhadli/v4l-dvb-davinci_devices.git
 S:	Maintained
 F:	drivers/media/platform/davinci/
 F:	include/media/davinci/
 
 TI AM437X VPFE DRIVER
 M:	"Lad, Prabhakar" <prabhakar.csengg@gmail.com>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/mhadli/v4l-dvb-davinci_devices.git
 S:	Maintained
 F:	drivers/media/platform/am437x/
 
 OV2659 OMNIVISION SENSOR DRIVER
 M:	"Lad, Prabhakar" <prabhakar.csengg@gmail.com>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/mhadli/v4l-dvb-davinci_devices.git
 S:	Maintained
 F:	drivers/media/i2c/ov2659.c
 F:	include/media/i2c/ov2659.h
 
 SILICON MOTION SM712 FRAME BUFFER DRIVER
 M:	Sudip Mukherjee <sudipm.mukherjee@gmail.com>
 M:	Teddy Wang <teddy.wang@siliconmotion.com>
 M:	Sudip Mukherjee <sudip.mukherjee@codethink.co.uk>
 L:	linux-fbdev@vger.kernel.org
 S:	Maintained
 F:	drivers/video/fbdev/sm712*
 F:	Documentation/fb/sm712fb.txt
 
 SIS 190 ETHERNET DRIVER
 M:	Francois Romieu <romieu@fr.zoreil.com>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/ethernet/sis/sis190.c
 
 SIS 900/7016 FAST ETHERNET DRIVER
 M:	Daniele Venzano <venza@brownhat.org>
 W:	http://www.brownhat.org/sis900.html
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/ethernet/sis/sis900.*
 
 SIS FRAMEBUFFER DRIVER
 M:	Thomas Winischhofer <thomas@winischhofer.net>
 W:	http://www.winischhofer.net/linuxsisvga.shtml
 S:	Maintained
 F:	Documentation/fb/sisfb.txt
 F:	drivers/video/fbdev/sis/
 F:	include/video/sisfb.h
 
 SIS USB2VGA DRIVER
 M:	Thomas Winischhofer <thomas@winischhofer.net>
 W:	http://www.winischhofer.at/linuxsisusbvga.shtml
 S:	Maintained
 F:	drivers/usb/misc/sisusbvga/
 
 SLAB ALLOCATOR
 M:	Christoph Lameter <cl@linux.com>
 M:	Pekka Enberg <penberg@kernel.org>
 M:	David Rientjes <rientjes@google.com>
 M:	Joonsoo Kim <iamjoonsoo.kim@lge.com>
 M:	Andrew Morton <akpm@linux-foundation.org>
 L:	linux-mm@kvack.org
 S:	Maintained
 F:	include/linux/sl?b*.h
 F:	mm/sl?b*
 
 SLEEPABLE READ-COPY UPDATE (SRCU)
 M:	Lai Jiangshan <jiangshanlai@gmail.com>
 M:	"Paul E. McKenney" <paulmck@linux.vnet.ibm.com>
 M:	Josh Triplett <josh@joshtriplett.org>
 R:	Steven Rostedt <rostedt@goodmis.org>
 R:	Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
 L:	linux-kernel@vger.kernel.org
 W:	http://www.rdrop.com/users/paulmck/RCU/
 S:	Supported
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/paulmck/linux-rcu.git
 F:	include/linux/srcu.h
 F:	kernel/rcu/srcu.c
 
 SMACK SECURITY MODULE
 M:	Casey Schaufler <casey@schaufler-ca.com>
 L:	linux-security-module@vger.kernel.org
 W:	http://schaufler-ca.com
 T:	git git://github.com/cschaufler/smack-next
 S:	Maintained
 F:	Documentation/security/Smack.txt
 F:	security/smack/
 
 DRIVERS FOR ADAPTIVE VOLTAGE SCALING (AVS)
 M:	Kevin Hilman <khilman@kernel.org>
 M:	Nishanth Menon <nm@ti.com>
 S:	Maintained
 F:	drivers/power/avs/
 F:	include/linux/power/smartreflex.h
 L:	linux-pm@vger.kernel.org
 
 SMC91x ETHERNET DRIVER
 M:	Nicolas Pitre <nico@fluxnic.net>
 S:	Odd Fixes
 F:	drivers/net/ethernet/smsc/smc91x.*
 
 SMIA AND SMIA++ IMAGE SENSOR DRIVER
 M:	Sakari Ailus <sakari.ailus@iki.fi>
 L:	linux-media@vger.kernel.org
 S:	Maintained
 F:	drivers/media/i2c/smiapp/
 F:	include/media/i2c/smiapp.h
 F:	drivers/media/i2c/smiapp-pll.c
 F:	drivers/media/i2c/smiapp-pll.h
 F:	include/uapi/linux/smiapp.h
 F:	Documentation/devicetree/bindings/media/i2c/nokia,smia.txt
 
 SMM665 HARDWARE MONITOR DRIVER
 M:	Guenter Roeck <linux@roeck-us.net>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	Documentation/hwmon/smm665
 F:	drivers/hwmon/smm665.c
 
 SMSC EMC2103 HARDWARE MONITOR DRIVER
 M:	Steve Glendinning <steve.glendinning@shawell.net>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	Documentation/hwmon/emc2103
 F:	drivers/hwmon/emc2103.c
 
 SMSC SCH5627 HARDWARE MONITOR DRIVER
 M:	Hans de Goede <hdegoede@redhat.com>
 L:	linux-hwmon@vger.kernel.org
 S:	Supported
 F:	Documentation/hwmon/sch5627
 F:	drivers/hwmon/sch5627.c
 
 SMSC47B397 HARDWARE MONITOR DRIVER
 M:	Jean Delvare <jdelvare@suse.com>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	Documentation/hwmon/smsc47b397
 F:	drivers/hwmon/smsc47b397.c
 
 SMSC911x ETHERNET DRIVER
 M:	Steve Glendinning <steve.glendinning@shawell.net>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	include/linux/smsc911x.h
 F:	drivers/net/ethernet/smsc/smsc911x.*
 
 SMSC9420 PCI ETHERNET DRIVER
 M:	Steve Glendinning <steve.glendinning@shawell.net>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/ethernet/smsc/smsc9420.*
 
 SMSC UFX6000 and UFX7000 USB to VGA DRIVER
 M:	Steve Glendinning <steve.glendinning@shawell.net>
 L:	linux-fbdev@vger.kernel.org
 S:	Maintained
 F:	drivers/video/fbdev/smscufx.c
 
 SOC-CAMERA V4L2 SUBSYSTEM
 M:	Guennadi Liakhovetski <g.liakhovetski@gmx.de>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Maintained
 F:	include/media/soc*
 F:	drivers/media/i2c/soc_camera/
 F:	drivers/media/platform/soc_camera/
 
 SOEKRIS NET48XX LED SUPPORT
 M:	Chris Boot <bootc@bootc.net>
 S:	Maintained
 F:	drivers/leds/leds-net48xx.c
 
 SOFTLOGIC 6x10 MPEG CODEC
 M:	Bluecherry Maintainers <maintainers@bluecherrydvr.com>
 M:	Andrey Utkin <andrey.utkin@corp.bluecherry.net>
 M:	Andrey Utkin <andrey.krieger.utkin@gmail.com>
 M:	Ismael Luceno <ismael@iodev.co.uk>
 L:	linux-media@vger.kernel.org
 S:	Supported
 F:	drivers/media/pci/solo6x10/
 
 SOFTWARE RAID (Multiple Disks) SUPPORT
 M:	Shaohua Li <shli@kernel.org>
 L:	linux-raid@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/shli/md.git
 S:	Supported
 F:	drivers/md/
 F:	include/linux/raid/
 F:	include/uapi/linux/raid/
 
 SONIC NETWORK DRIVER
 M:	Thomas Bogendoerfer <tsbogend@alpha.franken.de>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/ethernet/natsemi/sonic.*
 
 SONICS SILICON BACKPLANE DRIVER (SSB)
 M:	Michael Buesch <m@bues.ch>
 L:	linux-wireless@vger.kernel.org
 S:	Maintained
 F:	drivers/ssb/
 F:	include/linux/ssb/
 
 SONY VAIO CONTROL DEVICE DRIVER
 M:	Mattia Dongili <malattia@linux.it>
 L:	platform-driver-x86@vger.kernel.org
 W:	http://www.linux.it/~malattia/wiki/index.php/Sony_drivers
 S:	Maintained
 F:	Documentation/laptops/sony-laptop.txt
 F:	drivers/char/sonypi.c
 F:	drivers/platform/x86/sony-laptop.c
 F:	include/linux/sony-laptop.h
 
 SONY MEMORYSTICK CARD SUPPORT
 M:	Alex Dubov <oakad@yahoo.com>
 W:	http://tifmxx.berlios.de/
 S:	Maintained
 F:	drivers/memstick/host/tifm_ms.c
 
 SONY MEMORYSTICK STANDARD SUPPORT
 M:	Maxim Levitsky <maximlevitsky@gmail.com>
 S:	Maintained
 F:	drivers/memstick/core/ms_block.*
 
 SOUND
 M:	Jaroslav Kysela <perex@perex.cz>
 M:	Takashi Iwai <tiwai@suse.com>
 L:	alsa-devel@alsa-project.org (moderated for non-subscribers)
 W:	http://www.alsa-project.org/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/tiwai/sound.git
 T:	git git://git.alsa-project.org/alsa-kernel.git
 Q:	http://patchwork.kernel.org/project/alsa-devel/list/
 S:	Maintained
 F:	Documentation/sound/
 F:	include/sound/
 F:	include/uapi/sound/
 F:	sound/
 
 SOUND - COMPRESSED AUDIO
 M:	Vinod Koul <vinod.koul@intel.com>
 L:	alsa-devel@alsa-project.org (moderated for non-subscribers)
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/tiwai/sound.git
 S:	Supported
 F:	Documentation/sound/alsa/compress_offload.txt
 F:	include/sound/compress_driver.h
 F:	include/uapi/sound/compress_*
 F:	sound/core/compress_offload.c
 F:	sound/soc/soc-compress.c
 
 SOUND - SOC LAYER / DYNAMIC AUDIO POWER MANAGEMENT (ASoC)
 M:	Liam Girdwood <lgirdwood@gmail.com>
 M:	Mark Brown <broonie@kernel.org>
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/broonie/sound.git
 L:	alsa-devel@alsa-project.org (moderated for non-subscribers)
 W:	http://alsa-project.org/main/index.php/ASoC
 S:	Supported
 F:	Documentation/devicetree/bindings/sound/
 F:	Documentation/sound/alsa/soc/
 F:	sound/soc/
 F:	include/sound/soc*
 
 SOUND - DMAENGINE HELPERS
 M:	Lars-Peter Clausen <lars@metafoo.de>
 S:	Supported
 F:	include/sound/dmaengine_pcm.h
 F:	sound/core/pcm_dmaengine.c
 F:	sound/soc/soc-generic-dmaengine-pcm.c
 
 SP2 MEDIA DRIVER
 M:	Olli Salonen <olli.salonen@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 S:	Maintained
 F:	drivers/media/dvb-frontends/sp2*
 
 SPARC + UltraSPARC (sparc/sparc64)
 M:	"David S. Miller" <davem@davemloft.net>
 L:	sparclinux@vger.kernel.org
 Q:	http://patchwork.ozlabs.org/project/sparclinux/list/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/davem/sparc.git
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/davem/sparc-next.git
 S:	Maintained
 F:	arch/sparc/
 F:	drivers/sbus/
 
 SPARC SERIAL DRIVERS
 M:	"David S. Miller" <davem@davemloft.net>
 L:	sparclinux@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/davem/sparc.git
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/davem/sparc-next.git
 S:	Maintained
 F:	include/linux/sunserialcore.h
 F:	drivers/tty/serial/suncore.c
 F:	drivers/tty/serial/sunhv.c
 F:	drivers/tty/serial/sunsab.c
 F:	drivers/tty/serial/sunsab.h
 F:	drivers/tty/serial/sunsu.c
 F:	drivers/tty/serial/sunzilog.c
 F:	drivers/tty/serial/sunzilog.h
 
 SPARSE CHECKER
 M:	"Christopher Li" <sparse@chrisli.org>
 L:	linux-sparse@vger.kernel.org
 W:	https://sparse.wiki.kernel.org/
 T:	git git://git.kernel.org/pub/scm/devel/sparse/sparse.git
 T:	git git://git.kernel.org/pub/scm/devel/sparse/chrisl/sparse.git
 S:	Maintained
 F:	include/linux/compiler.h
 
 SPEAR PLATFORM SUPPORT
 M:	Viresh Kumar <vireshk@kernel.org>
 M:	Shiraz Hashim <shiraz.linux.kernel@gmail.com>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 W:	http://www.st.com/spear
 S:	Maintained
 F:	arch/arm/boot/dts/spear*
 F:	arch/arm/mach-spear/
 
 SPEAR CLOCK FRAMEWORK SUPPORT
 M:	Viresh Kumar <vireshk@kernel.org>
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 W:	http://www.st.com/spear
 S:	Maintained
 F:	drivers/clk/spear/
 
 SPI NOR SUBSYSTEM
 M:	Cyrille Pitchen <cyrille.pitchen@atmel.com>
 M:	Marek Vasut <marek.vasut@gmail.com>
 L:	linux-mtd@lists.infradead.org
 W:	http://www.linux-mtd.infradead.org/
 Q:	http://patchwork.ozlabs.org/project/linux-mtd/list/
 T:	git git://github.com/spi-nor/linux.git
 S:	Maintained
 F:	drivers/mtd/spi-nor/
 F:	include/linux/mtd/spi-nor.h
 
 SPI SUBSYSTEM
 M:	Mark Brown <broonie@kernel.org>
 L:	linux-spi@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/broonie/spi.git
 Q:	http://patchwork.kernel.org/project/spi-devel-general/list/
 S:	Maintained
 F:	Documentation/devicetree/bindings/spi/
 F:	Documentation/spi/
 F:	drivers/spi/
 F:	include/linux/spi/
 F:	include/uapi/linux/spi/
 F:	tools/spi/
 
 SPIDERNET NETWORK DRIVER for CELL
 M:	Ishizaki Kou <kou.ishizaki@toshiba.co.jp>
 L:	netdev@vger.kernel.org
 S:	Supported
 F:	Documentation/networking/spider_net.txt
 F:	drivers/net/ethernet/toshiba/spider_net*
 
 SPU FILE SYSTEM
 M:	Jeremy Kerr <jk@ozlabs.org>
 L:	linuxppc-dev@lists.ozlabs.org
 W:	http://www.ibm.com/developerworks/power/cell/
 S:	Supported
 F:	Documentation/filesystems/spufs.txt
 F:	arch/powerpc/platforms/cell/spufs/
 
 SQUASHFS FILE SYSTEM
 M:	Phillip Lougher <phillip@squashfs.org.uk>
 L:	squashfs-devel@lists.sourceforge.net (subscribers-only)
 W:	http://squashfs.org.uk
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/pkl/squashfs-next.git
 S:	Maintained
 F:	Documentation/filesystems/squashfs.txt
 F:	fs/squashfs/
 
 SRM (Alpha) environment access
 M:	Jan-Benedict Glaw <jbglaw@lug-owl.de>
 S:	Maintained
 F:	arch/alpha/kernel/srm_env.c
 
 STABLE BRANCH
 M:	Greg Kroah-Hartman <gregkh@linuxfoundation.org>
 L:	stable@vger.kernel.org
 S:	Supported
 F:	Documentation/process/stable-kernel-rules.rst
 
 STAGING SUBSYSTEM
 M:	Greg Kroah-Hartman <gregkh@linuxfoundation.org>
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/staging.git
 L:	devel@driverdev.osuosl.org
 S:	Supported
 F:	drivers/staging/
 
 STAGING - COMEDI
 M:	Ian Abbott <abbotti@mev.co.uk>
 M:	H Hartley Sweeten <hsweeten@visionengravers.com>
 S:	Odd Fixes
 F:	drivers/staging/comedi/
 
 STAGING - FLARION FT1000 DRIVERS
 M:	Marek Belisko <marek.belisko@gmail.com>
 S:	Odd Fixes
 F:	drivers/staging/ft1000/
 
 STAGING - INDUSTRIAL IO
 M:	Jonathan Cameron <jic23@kernel.org>
 L:	linux-iio@vger.kernel.org
 S:	Odd Fixes
 F:	Documentation/devicetree/bindings/staging/iio/
 F:	drivers/staging/iio/
 
 STAGING - LIRC (LINUX INFRARED REMOTE CONTROL) DRIVERS
 M:	Jarod Wilson <jarod@wilsonet.com>
 W:	http://www.lirc.org/
 S:	Odd Fixes
 F:	drivers/staging/media/lirc/
 
 STAGING - LUSTRE PARALLEL FILESYSTEM
 M:	Oleg Drokin <oleg.drokin@intel.com>
 M:	Andreas Dilger <andreas.dilger@intel.com>
 M:	James Simmons <jsimmons@infradead.org>
 L:	lustre-devel@lists.lustre.org (moderated for non-subscribers)
 W:	http://wiki.lustre.org/
 S:	Maintained
 F:	drivers/staging/lustre
 
 STAGING - NVIDIA COMPLIANT EMBEDDED CONTROLLER INTERFACE (nvec)
 M:	Marc Dietrich <marvin24@gmx.de>
 L:	ac100@lists.launchpad.net (moderated for non-subscribers)
 L:	linux-tegra@vger.kernel.org
 S:	Maintained
 F:	drivers/staging/nvec/
 
 STAGING - OLPC SECONDARY DISPLAY CONTROLLER (DCON)
 M:	Jens Frederich <jfrederich@gmail.com>
 M:	Daniel Drake <dsd@laptop.org>
 M:	Jon Nettleton <jon.nettleton@gmail.com>
 W:	http://wiki.laptop.org/go/DCON
 S:	Maintained
 F:	drivers/staging/olpc_dcon/
 
 STAGING - REALTEK RTL8712U DRIVERS
 M:	Larry Finger <Larry.Finger@lwfinger.net>
 M:	Florian Schilhabel <florian.c.schilhabel@googlemail.com>.
 S:	Odd Fixes
 F:	drivers/staging/rtl8712/
 
 STAGING - SILICON MOTION SM750 FRAME BUFFER DRIVER
 M:	Sudip Mukherjee <sudipm.mukherjee@gmail.com>
 M:	Teddy Wang <teddy.wang@siliconmotion.com>
 M:	Sudip Mukherjee <sudip.mukherjee@codethink.co.uk>
 L:	linux-fbdev@vger.kernel.org
 S:	Maintained
 F:	drivers/staging/sm750fb/
 
 STAGING - SPEAKUP CONSOLE SPEECH DRIVER
 M:	William Hubbs <w.d.hubbs@gmail.com>
 M:	Chris Brannon <chris@the-brannons.com>
 M:	Kirk Reiser <kirk@reisers.ca>
 M:	Samuel Thibault <samuel.thibault@ens-lyon.org>
 L:	speakup@linux-speakup.org
 W:	http://www.linux-speakup.org/
 S:	Odd Fixes
 F:	drivers/staging/speakup/
 
 STAGING - VIA VT665X DRIVERS
 M:	Forest Bond <forest@alittletooquiet.net>
 S:	Odd Fixes
 F:	drivers/staging/vt665?/
 
 STAGING - WILC1000 WIFI DRIVER
 M:	Aditya Shankar <aditya.shankar@microchip.com>
 M:	Ganesh Krishna <ganesh.krishna@microchip.com>
 L:	linux-wireless@vger.kernel.org
 S:	Supported
 F:	drivers/staging/wilc1000/
 
 STAGING - XGI Z7,Z9,Z11 PCI DISPLAY DRIVER
 M:	Arnaud Patard <arnaud.patard@rtp-net.org>
 S:	Odd Fixes
 F:	drivers/staging/xgifb/
 
 STARFIRE/DURALAN NETWORK DRIVER
 M:	Ion Badulescu <ionut@badula.org>
 S:	Odd Fixes
 F:	drivers/net/ethernet/adaptec/starfire*
 
 SUN3/3X
 M:	Sam Creasey <sammy@sammy.net>
 W:	http://sammy.net/sun3/
 S:	Maintained
 F:	arch/m68k/kernel/*sun3*
 F:	arch/m68k/sun3*/
 F:	arch/m68k/include/asm/sun3*
 F:	drivers/net/ethernet/i825xx/sun3*
 
 SUN4I LOW RES ADC ATTACHED TABLET KEYS DRIVER
 M:	Hans de Goede <hdegoede@redhat.com>
 L:	linux-input@vger.kernel.org
 S:	Maintained
 F:	Documentation/devicetree/bindings/input/sun4i-lradc-keys.txt
 F:	drivers/input/keyboard/sun4i-lradc-keys.c
 
 SUNDANCE NETWORK DRIVER
 M:	Denis Kirjanov <kda@linux-powerpc.org>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/ethernet/dlink/sundance.c
 
 SUPERH
 M:	Yoshinori Sato <ysato@users.sourceforge.jp>
 M:	Rich Felker <dalias@libc.org>
 L:	linux-sh@vger.kernel.org
 Q:	http://patchwork.kernel.org/project/linux-sh/list/
 S:	Maintained
 F:	Documentation/sh/
 F:	arch/sh/
 F:	drivers/sh/
 
 SUSPEND TO RAM
 M:	"Rafael J. Wysocki" <rjw@rjwysocki.net>
 M:	Len Brown <len.brown@intel.com>
 M:	Pavel Machek <pavel@ucw.cz>
 L:	linux-pm@vger.kernel.org
 B:	https://bugzilla.kernel.org
 S:	Supported
 F:	Documentation/power/
 F:	arch/x86/kernel/acpi/
 F:	drivers/base/power/
 F:	kernel/power/
 F:	include/linux/suspend.h
 F:	include/linux/freezer.h
 F:	include/linux/pm.h
 
 SVGA HANDLING
 M:	Martin Mares <mj@ucw.cz>
 L:	linux-video@atrey.karlin.mff.cuni.cz
 S:	Maintained
 F:	Documentation/svga.txt
 F:	arch/x86/boot/video*
 
 SWIOTLB SUBSYSTEM
 M:	Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
 L:	linux-kernel@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/konrad/swiotlb.git
 S:	Supported
 F:	lib/swiotlb.c
 F:	arch/*/kernel/pci-swiotlb.c
 F:	include/linux/swiotlb.h
 
 SWITCHDEV
 M:	Jiri Pirko <jiri@resnulli.us>
 M:	Ivan Vecera <ivecera@redhat.com>
 L:	netdev@vger.kernel.org
 S:	Supported
 F:	net/switchdev/
 F:	include/net/switchdev.h
 
 SYNOPSYS ARC ARCHITECTURE
 M:	Vineet Gupta <vgupta@synopsys.com>
 L:	linux-snps-arc@lists.infradead.org
 S:	Supported
 F:	arch/arc/
 F:	Documentation/devicetree/bindings/arc/*
 F:	Documentation/devicetree/bindings/interrupt-controller/snps,arc*
 F:	drivers/clocksource/arc_timer.c
 F:	drivers/tty/serial/arc_uart.c
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/vgupta/arc.git
 
 SYNOPSYS ARC SDP platform support
 M:	Alexey Brodkin <abrodkin@synopsys.com>
 S:	Supported
 F:	arch/arc/plat-axs10x
 F:	arch/arc/boot/dts/ax*
 F:	Documentation/devicetree/bindings/arc/axs10*
 
 SYSTEM CONFIGURATION (SYSCON)
 M:	Lee Jones <lee.jones@linaro.org>
 M:	Arnd Bergmann <arnd@arndb.de>
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/lee/mfd.git
 S:	Supported
 F:	drivers/mfd/syscon.c
 
 SYSTEM RESET/SHUTDOWN DRIVERS
 M:	Sebastian Reichel <sre@kernel.org>
 L:	linux-pm@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/sre/linux-power-supply.git
 S:	Maintained
 F:	Documentation/devicetree/bindings/power/reset/
 F:	drivers/power/reset/
 
 SYSV FILESYSTEM
 M:	Christoph Hellwig <hch@infradead.org>
 S:	Maintained
 F:	Documentation/filesystems/sysv-fs.txt
 F:	fs/sysv/
 F:	include/linux/sysv_fs.h
 
 TARGET SUBSYSTEM
 M:	"Nicholas A. Bellinger" <nab@linux-iscsi.org>
 L:	linux-scsi@vger.kernel.org
 L:	target-devel@vger.kernel.org
 W:	http://www.linux-iscsi.org
 W:	http://groups.google.com/group/linux-iscsi-target-dev
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/nab/target-pending.git master
 S:	Supported
 F:	drivers/target/
 F:	include/target/
 F:	Documentation/target/
 
 TASKSTATS STATISTICS INTERFACE
 M:	Balbir Singh <bsingharora@gmail.com>
 S:	Maintained
 F:	Documentation/accounting/taskstats*
 F:	include/linux/taskstats*
 F:	kernel/taskstats.c
 
 TC CLASSIFIER
 M:	Jamal Hadi Salim <jhs@mojatatu.com>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	include/net/pkt_cls.h
 F:	include/uapi/linux/pkt_cls.h
 F:	net/sched/
 
 TCP LOW PRIORITY MODULE
 M:	"Wong Hoi Sing, Edison" <hswong3i@gmail.com>
 M:	"Hung Hing Lun, Mike" <hlhung3i@gmail.com>
 W:	http://tcp-lp-mod.sourceforge.net/
 S:	Maintained
 F:	net/ipv4/tcp_lp.c
 
 TDA10071 MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://palosaari.fi/linux/
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/anttip/media_tree.git
 S:	Maintained
 F:	drivers/media/dvb-frontends/tda10071*
 
 TDA18212 MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://palosaari.fi/linux/
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/anttip/media_tree.git
 S:	Maintained
 F:	drivers/media/tuners/tda18212*
 
 TDA18218 MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://palosaari.fi/linux/
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/anttip/media_tree.git
 S:	Maintained
 F:	drivers/media/tuners/tda18218*
 
 TDA18271 MEDIA DRIVER
 M:	Michael Krufky <mkrufky@linuxtv.org>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://github.com/mkrufky
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/mkrufky/tuners.git
 S:	Maintained
 F:	drivers/media/tuners/tda18271*
 
 TDA827x MEDIA DRIVER
 M:	Michael Krufky <mkrufky@linuxtv.org>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://github.com/mkrufky
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/mkrufky/tuners.git
 S:	Maintained
 F:	drivers/media/tuners/tda8290.*
 
 TDA8290 MEDIA DRIVER
 M:	Michael Krufky <mkrufky@linuxtv.org>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://github.com/mkrufky
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/mkrufky/tuners.git
 S:	Maintained
 F:	drivers/media/tuners/tda8290.*
 
 TDA9840 MEDIA DRIVER
 M:	Hans Verkuil <hverkuil@xs4all.nl>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 W:	https://linuxtv.org
 S:	Maintained
 F:	drivers/media/i2c/tda9840*
 
 TEA5761 TUNER DRIVER
 M:	Mauro Carvalho Chehab <mchehab@s-opensource.com>
 M:	Mauro Carvalho Chehab <mchehab@kernel.org>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Odd fixes
 F:	drivers/media/tuners/tea5761.*
 
 TEA5767 TUNER DRIVER
 M:	Mauro Carvalho Chehab <mchehab@s-opensource.com>
 M:	Mauro Carvalho Chehab <mchehab@kernel.org>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Maintained
 F:	drivers/media/tuners/tea5767.*
 
 TEA6415C MEDIA DRIVER
 M:	Hans Verkuil <hverkuil@xs4all.nl>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 W:	https://linuxtv.org
 S:	Maintained
 F:	drivers/media/i2c/tea6415c*
 
 TEA6420 MEDIA DRIVER
 M:	Hans Verkuil <hverkuil@xs4all.nl>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 W:	https://linuxtv.org
 S:	Maintained
 F:	drivers/media/i2c/tea6420*
 
 TEAM DRIVER
 M:	Jiri Pirko <jiri@resnulli.us>
 L:	netdev@vger.kernel.org
 S:	Supported
 F:	drivers/net/team/
 F:	include/linux/if_team.h
 F:	include/uapi/linux/if_team.h
 
 TECHNOLOGIC SYSTEMS TS-5500 PLATFORM SUPPORT
 M:	"Savoir-faire Linux Inc." <kernel@savoirfairelinux.com>
 S:	Maintained
 F:	arch/x86/platform/ts5500/
 
 TECHNOTREND USB IR RECEIVER
 M:	Sean Young <sean@mess.org>
 L:	linux-media@vger.kernel.org
 S:	Maintained
 F:	drivers/media/rc/ttusbir.c
 
 TEGRA ARCHITECTURE SUPPORT
 M:	Stephen Warren <swarren@wwwdotorg.org>
 M:	Thierry Reding <thierry.reding@gmail.com>
 M:	Alexandre Courbot <gnurou@gmail.com>
 L:	linux-tegra@vger.kernel.org
 Q:	http://patchwork.ozlabs.org/project/linux-tegra/list/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/tegra/linux.git
 S:	Supported
 N:	[^a-z]tegra
 
 TEGRA CLOCK DRIVER
 M:	Peter De Schrijver <pdeschrijver@nvidia.com>
 M:	Prashant Gaikwad <pgaikwad@nvidia.com>
 S:	Supported
 F:	drivers/clk/tegra/
 
 TEGRA DMA DRIVERS
 M:	Laxman Dewangan <ldewangan@nvidia.com>
 M:	Jon Hunter <jonathanh@nvidia.com>
 S:	Supported
 F:	drivers/dma/tegra*
 
 TEGRA I2C DRIVER
 M:	Laxman Dewangan <ldewangan@nvidia.com>
 S:	Supported
 F:	drivers/i2c/busses/i2c-tegra.c
 
 TEGRA IOMMU DRIVERS
 M:	Hiroshi Doyu <hdoyu@nvidia.com>
 S:	Supported
 F:	drivers/iommu/tegra*
 
 TEGRA KBC DRIVER
 M:	Rakesh Iyer <riyer@nvidia.com>
 M:	Laxman Dewangan <ldewangan@nvidia.com>
 S:	Supported
 F:	drivers/input/keyboard/tegra-kbc.c
 
 TEGRA PWM DRIVER
 M:	Thierry Reding <thierry.reding@gmail.com>
 S:	Supported
 F:	drivers/pwm/pwm-tegra.c
 
 TEGRA SERIAL DRIVER
 M:	Laxman Dewangan <ldewangan@nvidia.com>
 S:	Supported
 F:	drivers/tty/serial/serial-tegra.c
 
 TEGRA SPI DRIVER
 M:	Laxman Dewangan <ldewangan@nvidia.com>
 S:	Supported
 F:	drivers/spi/spi-tegra*
 
 TEHUTI ETHERNET DRIVER
 M:	Andy Gospodarek <andy@greyhouse.net>
 L:	netdev@vger.kernel.org
 S:	Supported
 F:	drivers/net/ethernet/tehuti/*
 
 Telecom Clock Driver for MCPL0010
 M:	Mark Gross <mark.gross@intel.com>
 S:	Supported
 F:	drivers/char/tlclk.c
 
 TENSILICA XTENSA PORT (xtensa)
 M:	Chris Zankel <chris@zankel.net>
 M:	Max Filippov <jcmvbkbc@gmail.com>
 L:	linux-xtensa@linux-xtensa.org
 T:	git git://github.com/czankel/xtensa-linux.git
 S:	Maintained
 F:	arch/xtensa/
 F:	drivers/irqchip/irq-xtensa-*
 
 Texas Instruments' System Control Interface (TISCI) Protocol Driver
 M:	Nishanth Menon <nm@ti.com>
 M:	Tero Kristo <t-kristo@ti.com>
 M:	Santosh Shilimkar <ssantosh@kernel.org>
 L:	linux-arm-kernel@lists.infradead.org
 S:	Maintained
 F:	Documentation/devicetree/bindings/arm/keystone/ti,sci.txt
 F:	drivers/firmware/ti_sci*
 F:	include/linux/soc/ti/ti_sci_protocol.h
 
 THANKO'S RAREMONO AM/FM/SW RADIO RECEIVER USB DRIVER
 M:	Hans Verkuil <hverkuil@xs4all.nl>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 W:	https://linuxtv.org
 S:	Maintained
 F:	drivers/media/radio/radio-raremono.c
 
 THERMAL
 M:	Zhang Rui <rui.zhang@intel.com>
 M:	Eduardo Valentin <edubezval@gmail.com>
 L:	linux-pm@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/rzhang/linux.git
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/evalenti/linux-soc-thermal.git
 Q:	https://patchwork.kernel.org/project/linux-pm/list/
 S:	Supported
 F:	drivers/thermal/
 F:	include/linux/thermal.h
 F:	include/uapi/linux/thermal.h
 F:	include/linux/cpu_cooling.h
 F:	Documentation/devicetree/bindings/thermal/
 
 THERMAL/CPU_COOLING
 M:	Amit Daniel Kachhap <amit.kachhap@gmail.com>
 M:	Viresh Kumar <viresh.kumar@linaro.org>
 M:	Javi Merino <javi.merino@kernel.org>
 L:	linux-pm@vger.kernel.org
 S:	Supported
 F:	Documentation/thermal/cpu-cooling-api.txt
 F:	drivers/thermal/cpu_cooling.c
 F:	include/linux/cpu_cooling.h
 
 THINKPAD ACPI EXTRAS DRIVER
 M:	Henrique de Moraes Holschuh <ibm-acpi@hmh.eng.br>
 L:	ibm-acpi-devel@lists.sourceforge.net
 L:	platform-driver-x86@vger.kernel.org
 W:	http://ibm-acpi.sourceforge.net
 W:	http://thinkwiki.org/wiki/Ibm-acpi
 T:	git git://repo.or.cz/linux-2.6/linux-acpi-2.6/ibm-acpi-2.6.git
 S:	Maintained
 F:	drivers/platform/x86/thinkpad_acpi.c
 
 TI BANDGAP AND THERMAL DRIVER
 M:	Eduardo Valentin <edubezval@gmail.com>
 M:	Keerthy <j-keerthy@ti.com>
 L:	linux-pm@vger.kernel.org
 L:	linux-omap@vger.kernel.org
 S:	Maintained
 F:	drivers/thermal/ti-soc-thermal/
 
 TI VPE/CAL DRIVERS
 M:	Benoit Parrot <bparrot@ti.com>
 L:	linux-media@vger.kernel.org
 W:	http://linuxtv.org/
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 S:	Maintained
 F:	drivers/media/platform/ti-vpe/
 
 TI CDCE706 CLOCK DRIVER
 M:	Max Filippov <jcmvbkbc@gmail.com>
 S:	Maintained
 F:	drivers/clk/clk-cdce706.c
 
 TI CLOCK DRIVER
 M:	Tero Kristo <t-kristo@ti.com>
 L:	linux-omap@vger.kernel.org
 S:	Maintained
 F:	drivers/clk/ti/
 F:	include/linux/clk/ti.h
 
 TI ETHERNET SWITCH DRIVER (CPSW)
 M:	Mugunthan V N <mugunthanvnm@ti.com>
 R:	Grygorii Strashko <grygorii.strashko@ti.com>
 L:	linux-omap@vger.kernel.org
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/ethernet/ti/cpsw*
 F:	drivers/net/ethernet/ti/davinci*
 
 TI FLASH MEDIA INTERFACE DRIVER
 M:	Alex Dubov <oakad@yahoo.com>
 S:	Maintained
 F:	drivers/misc/tifm*
 F:	drivers/mmc/host/tifm_sd.c
 F:	include/linux/tifm.h
 
 TI KEYSTONE MULTICORE NAVIGATOR DRIVERS
 M:	Santosh Shilimkar <ssantosh@kernel.org>
 L:	linux-kernel@vger.kernel.org
 L:	linux-arm-kernel@lists.infradead.org (moderated for non-subscribers)
 S:	Maintained
 F:	drivers/soc/ti/*
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/ssantosh/linux-keystone.git
 
 
 TI LM49xxx FAMILY ASoC CODEC DRIVERS
 M:	M R Swami Reddy <mr.swami.reddy@ti.com>
 M:	Vishwas A Deshpande <vishwas.a.deshpande@ti.com>
 L:	alsa-devel@alsa-project.org (moderated for non-subscribers)
 S:	Maintained
 F:	sound/soc/codecs/lm49453*
 F:	sound/soc/codecs/isabelle*
 
 TI LP855x BACKLIGHT DRIVER
 M:	Milo Kim <milo.kim@ti.com>
 S:	Maintained
 F:	Documentation/backlight/lp855x-driver.txt
 F:	drivers/video/backlight/lp855x_bl.c
 F:	include/linux/platform_data/lp855x.h
 
 TI LP8727 CHARGER DRIVER
 M:	Milo Kim <milo.kim@ti.com>
 S:	Maintained
 F:	drivers/power/supply/lp8727_charger.c
 F:	include/linux/platform_data/lp8727.h
 
 TI LP8788 MFD DRIVER
 M:	Milo Kim <milo.kim@ti.com>
 S:	Maintained
 F:	drivers/iio/adc/lp8788_adc.c
 F:	drivers/leds/leds-lp8788.c
 F:	drivers/mfd/lp8788*.c
 F:	drivers/power/supply/lp8788-charger.c
 F:	drivers/regulator/lp8788-*.c
 F:	include/linux/mfd/lp8788*.h
 
 TI NETCP ETHERNET DRIVER
 M:	Wingman Kwok <w-kwok2@ti.com>
 M:	Murali Karicheri <m-karicheri2@ti.com>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/ethernet/ti/netcp*
 
 TI TAS571X FAMILY ASoC CODEC DRIVER
 M:	Kevin Cernekee <cernekee@chromium.org>
 L:	alsa-devel@alsa-project.org (moderated for non-subscribers)
 S:	Odd Fixes
 F:	sound/soc/codecs/tas571x*
 
 TI TWL4030 SERIES SOC CODEC DRIVER
 M:	Peter Ujfalusi <peter.ujfalusi@ti.com>
 L:	alsa-devel@alsa-project.org (moderated for non-subscribers)
 S:	Maintained
 F:	sound/soc/codecs/twl4030*
 
 TI WILINK WIRELESS DRIVERS
 L:	linux-wireless@vger.kernel.org
 W:	http://wireless.kernel.org/en/users/Drivers/wl12xx
 W:	http://wireless.kernel.org/en/users/Drivers/wl1251
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/luca/wl12xx.git
 S:	Orphan
 F:	drivers/net/wireless/ti/
 F:	include/linux/wl12xx.h
 
 TIPC NETWORK LAYER
 M:	Jon Maloy <jon.maloy@ericsson.com>
 M:	Ying Xue <ying.xue@windriver.com>
 L:	netdev@vger.kernel.org (core kernel code)
 L:	tipc-discussion@lists.sourceforge.net (user apps, general discussion)
 W:	http://tipc.sourceforge.net/
 S:	Maintained
 F:	include/uapi/linux/tipc*.h
 F:	net/tipc/
 
 TILE ARCHITECTURE
 M:	Chris Metcalf <cmetcalf@mellanox.com>
 W:	http://www.mellanox.com/repository/solutions/tile-scm/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/cmetcalf/linux-tile.git
 S:	Supported
 F:	arch/tile/
 F:	drivers/char/tile-srom.c
 F:	drivers/edac/tile_edac.c
 F:	drivers/net/ethernet/tile/
 F:	drivers/rtc/rtc-tile.c
 F:	drivers/tty/hvc/hvc_tile.c
 F:	drivers/tty/serial/tilegx.c
 F:	drivers/usb/host/*-tilegx.c
 F:	include/linux/usb/tilegx.h
 
 TLAN NETWORK DRIVER
 M:	Samuel Chessman <chessman@tux.org>
 L:	tlan-devel@lists.sourceforge.net (subscribers-only)
 W:	http://sourceforge.net/projects/tlan/
 S:	Maintained
 F:	Documentation/networking/tlan.txt
 F:	drivers/net/ethernet/ti/tlan.*
 
 TOMOYO SECURITY MODULE
 M:	Kentaro Takeda <takedakn@nttdata.co.jp>
 M:	Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>
 L:	tomoyo-dev-en@lists.sourceforge.jp (subscribers-only, for developers in English)
 L:	tomoyo-users-en@lists.sourceforge.jp (subscribers-only, for users in English)
 L:	tomoyo-dev@lists.sourceforge.jp (subscribers-only, for developers in Japanese)
 L:	tomoyo-users@lists.sourceforge.jp (subscribers-only, for users in Japanese)
 W:	http://tomoyo.sourceforge.jp/
 T:	quilt http://svn.sourceforge.jp/svnroot/tomoyo/trunk/2.5.x/tomoyo-lsm/patches/
 S:	Maintained
 F:	security/tomoyo/
 
 TOPSTAR LAPTOP EXTRAS DRIVER
 M:	Herton Ronaldo Krzesinski <herton@canonical.com>
 L:	platform-driver-x86@vger.kernel.org
 S:	Maintained
 F:	drivers/platform/x86/topstar-laptop.c
 
 TOSHIBA ACPI EXTRAS DRIVER
 M:	Azael Avalos <coproscefalo@gmail.com>
 L:	platform-driver-x86@vger.kernel.org
 S:	Maintained
 F:	drivers/platform/x86/toshiba_acpi.c
 
 TOSHIBA BLUETOOTH DRIVER
 M:	Azael Avalos <coproscefalo@gmail.com>
 L:	platform-driver-x86@vger.kernel.org
 S:	Maintained
 F:	drivers/platform/x86/toshiba_bluetooth.c
 
 TOSHIBA HDD ACTIVE PROTECTION SENSOR DRIVER
 M:	Azael Avalos <coproscefalo@gmail.com>
 L:	platform-driver-x86@vger.kernel.org
 S:	Maintained
 F:	drivers/platform/x86/toshiba_haps.c
 
 TOSHIBA WMI HOTKEYS DRIVER
 M:	Azael Avalos <coproscefalo@gmail.com>
 L:	platform-driver-x86@vger.kernel.org
 S:	Maintained
 F:	drivers/platform/x86/toshiba-wmi.c
 
 TOSHIBA SMM DRIVER
 M:	Jonathan Buzzard <jonathan@buzzard.org.uk>
 W:	http://www.buzzard.org.uk/toshiba/
 S:	Maintained
 F:	drivers/char/toshiba.c
 F:	include/linux/toshiba.h
 F:	include/uapi/linux/toshiba.h
 
 TOSHIBA TC358743 DRIVER
 M:	Mats Randgaard <matrandg@cisco.com>
 L:	linux-media@vger.kernel.org
 S:	Maintained
 F:	drivers/media/i2c/tc358743*
 F:	include/media/i2c/tc358743.h
 
 TMIO/SDHI MMC DRIVER
 M:	Wolfram Sang <wsa+renesas@sang-engineering.com>
 L:	linux-mmc@vger.kernel.org
 S:	Supported
 F:	drivers/mmc/host/tmio_mmc*
 F:	drivers/mmc/host/sh_mobile_sdhi.c
 F:	include/linux/mfd/tmio.h
 
 TMP401 HARDWARE MONITOR DRIVER
 M:	Guenter Roeck <linux@roeck-us.net>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	Documentation/hwmon/tmp401
 F:	drivers/hwmon/tmp401.c
 
 TMPFS (SHMEM FILESYSTEM)
 M:	Hugh Dickins <hughd@google.com>
 L:	linux-mm@kvack.org
 S:	Maintained
 F:	include/linux/shmem_fs.h
 F:	mm/shmem.c
 
 TM6000 VIDEO4LINUX DRIVER
 M:	Mauro Carvalho Chehab <mchehab@s-opensource.com>
 M:	Mauro Carvalho Chehab <mchehab@kernel.org>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Odd fixes
 F:	drivers/media/usb/tm6000/
 F:	Documentation/media/v4l-drivers/tm6000*
 
 TW5864 VIDEO4LINUX DRIVER
 M:	Bluecherry Maintainers <maintainers@bluecherrydvr.com>
 M:	Andrey Utkin <andrey.utkin@corp.bluecherry.net>
 M:	Andrey Utkin <andrey_utkin@fastmail.com>
 L:	linux-media@vger.kernel.org
 S:	Supported
 F:	drivers/media/pci/tw5864/
 
 TW68 VIDEO4LINUX DRIVER
 M:	Hans Verkuil <hverkuil@xs4all.nl>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 W:	https://linuxtv.org
 S:	Odd Fixes
 F:	drivers/media/pci/tw68/
 
 TW686X VIDEO4LINUX DRIVER
 M:	Ezequiel Garcia <ezequiel@vanguardiasur.com.ar>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 W:	http://linuxtv.org
 S:	Maintained
 F:	drivers/media/pci/tw686x/
 
 TPM DEVICE DRIVER
 M:	Peter Huewe <peterhuewe@gmx.de>
 M:	Marcel Selhorst <tpmdd@selhorst.net>
 M:	Jarkko Sakkinen <jarkko.sakkinen@linux.intel.com>
 R:	Jason Gunthorpe <jgunthorpe@obsidianresearch.com>
 W:	http://tpmdd.sourceforge.net
 L:	tpmdd-devel@lists.sourceforge.net (moderated for non-subscribers)
 Q:	https://patchwork.kernel.org/project/tpmdd-devel/list/
 T:	git git://git.infradead.org/users/jjs/linux-tpmdd.git
 S:	Maintained
 F:	drivers/char/tpm/
 
 TPM IBM_VTPM DEVICE DRIVER
 M:	Ashley Lai <ashleydlai@gmail.com>
 W:	http://tpmdd.sourceforge.net
 L:	tpmdd-devel@lists.sourceforge.net (moderated for non-subscribers)
 S:	Maintained
 F:	drivers/char/tpm/tpm_ibmvtpm*
 
 TRACING
 M:	Steven Rostedt <rostedt@goodmis.org>
 M:	Ingo Molnar <mingo@redhat.com>
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip.git perf/core
 S:	Maintained
 F:	Documentation/trace/ftrace.txt
 F:	arch/*/*/*/ftrace.h
 F:	arch/*/kernel/ftrace.c
 F:	include/*/ftrace.h
 F:	include/linux/trace*.h
 F:	include/trace/
 F:	kernel/trace/
 F:	tools/testing/selftests/ftrace/
 
 TRACING MMIO ACCESSES (MMIOTRACE)
 M:	Steven Rostedt <rostedt@goodmis.org>
 M:	Ingo Molnar <mingo@kernel.org>
 R:	Karol Herbst <karolherbst@gmail.com>
 R:	Pekka Paalanen <ppaalanen@gmail.com>
 S:	Maintained
 L:	linux-kernel@vger.kernel.org
 L:	nouveau@lists.freedesktop.org
 F:	kernel/trace/trace_mmiotrace.c
 F:	include/linux/mmiotrace.h
 F:	arch/x86/mm/kmmio.c
 F:	arch/x86/mm/mmio-mod.c
 F:	arch/x86/mm/testmmiotrace.c
 
 TRIVIAL PATCHES
 M:	Jiri Kosina <trivial@kernel.org>
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/jikos/trivial.git
 S:	Maintained
 K:	^Subject:.*(?i)trivial
 
 TTY LAYER
 M:	Greg Kroah-Hartman <gregkh@linuxfoundation.org>
 M:	Jiri Slaby <jslaby@suse.com>
 S:	Supported
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/tty.git
 F:	Documentation/serial/
 F:	drivers/tty/
 F:	drivers/tty/serial/serial_core.c
 F:	include/linux/serial_core.h
 F:	include/linux/serial.h
 F:	include/linux/tty.h
 F:	include/uapi/linux/serial_core.h
 F:	include/uapi/linux/serial.h
 F:	include/uapi/linux/tty.h
 
 TUA9001 MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 W:	http://palosaari.fi/linux/
 Q:	http://patchwork.linuxtv.org/project/linux-media/list/
 T:	git git://linuxtv.org/anttip/media_tree.git
 S:	Maintained
 F:	drivers/media/tuners/tua9001*
 
 TULIP NETWORK DRIVERS
 L:	netdev@vger.kernel.org
 L:	linux-parisc@vger.kernel.org
 S:	Orphan
 F:	drivers/net/ethernet/dec/tulip/
 
 TUN/TAP driver
 M:	Maxim Krasnyansky <maxk@qti.qualcomm.com>
 W:	http://vtun.sourceforge.net/tun
 S:	Maintained
 F:	Documentation/networking/tuntap.txt
 F:	arch/um/os-Linux/drivers/
 
 TURBOCHANNEL SUBSYSTEM
 M:	"Maciej W. Rozycki" <macro@linux-mips.org>
 M:	Ralf Baechle <ralf@linux-mips.org>
 L:	linux-mips@linux-mips.org
 Q:	http://patchwork.linux-mips.org/project/linux-mips/list/
 S:	Maintained
 F:	drivers/tc/
 F:	include/linux/tc.h
 
 UBI FILE SYSTEM (UBIFS)
 M:	Richard Weinberger <richard@nod.at>
 M:	Artem Bityutskiy <dedekind1@gmail.com>
 M:	Adrian Hunter <adrian.hunter@intel.com>
 L:	linux-mtd@lists.infradead.org
 T:	git git://git.infradead.org/ubifs-2.6.git
 W:	http://www.linux-mtd.infradead.org/doc/ubifs.html
 S:	Supported
 F:	Documentation/filesystems/ubifs.txt
 F:	fs/ubifs/
 
 UCLINUX (M68KNOMMU AND COLDFIRE)
 M:	Greg Ungerer <gerg@linux-m68k.org>
 W:	http://www.linux-m68k.org/
 W:	http://www.uclinux.org/
 L:	linux-m68k@lists.linux-m68k.org
 L:	uclinux-dev@uclinux.org  (subscribers-only)
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/gerg/m68knommu.git
 S:	Maintained
 F:	arch/m68k/coldfire/
 F:	arch/m68k/68*/
 F:	arch/m68k/*/*_no.*
 F:	arch/m68k/include/asm/*_no.*
 
 UDF FILESYSTEM
 M:	Jan Kara <jack@suse.com>
 S:	Maintained
 F:	Documentation/filesystems/udf.txt
 F:	fs/udf/
 
 UDRAW TABLET
 M:	Bastien Nocera <hadess@hadess.net>
 L:	linux-input@vger.kernel.org
 S:	Maintained
 F:	drivers/hid/hid-udraw.c
 
 UFS FILESYSTEM
 M:	Evgeniy Dushistov <dushistov@mail.ru>
 S:	Maintained
 F:	Documentation/filesystems/ufs.txt
 F:	fs/ufs/
 
 UHID USERSPACE HID IO DRIVER:
 M:	David Herrmann <dh.herrmann@googlemail.com>
 L:	linux-input@vger.kernel.org
 S:	Maintained
 F:	drivers/hid/uhid.c
 F:	include/uapi/linux/uhid.h
 
 ULTRA-WIDEBAND (UWB) SUBSYSTEM:
 L:	linux-usb@vger.kernel.org
 S:	Orphan
 F:	drivers/uwb/
 F:	include/linux/uwb.h
 F:	include/linux/uwb/
 
 UNICORE32 ARCHITECTURE:
 M:	Guan Xuetao <gxt@mprc.pku.edu.cn>
 W:	http://mprc.pku.edu.cn/~guanxuetao/linux
 S:	Maintained
 T:	git git://github.com/gxt/linux.git
 F:	arch/unicore32/
 
 UNIFDEF
 M:	Tony Finch <dot@dotat.at>
 W:	http://dotat.at/prog/unifdef
 S:	Maintained
 F:	scripts/unifdef.c
 
 UNIFORM CDROM DRIVER
 M:	Jens Axboe <axboe@kernel.dk>
 W:	http://www.kernel.dk
 S:	Maintained
 F:	Documentation/cdrom/
 F:	drivers/cdrom/cdrom.c
 F:	include/linux/cdrom.h
 F:	include/uapi/linux/cdrom.h
 
 UNISYS S-PAR DRIVERS
 M:	David Kershner <david.kershner@unisys.com>
 L:	sparmaintainer@unisys.com (Unisys internal)
 S:	Supported
 F:	drivers/staging/unisys/
 
 UNIVERSAL FLASH STORAGE HOST CONTROLLER DRIVER
 M:	Vinayak Holikatti <vinholikatti@gmail.com>
 L:	linux-scsi@vger.kernel.org
 S:	Supported
 F:	Documentation/scsi/ufs.txt
 F:	drivers/scsi/ufs/
 
 UNIVERSAL FLASH STORAGE HOST CONTROLLER DRIVER DWC HOOKS
 M:	Manjunath M Bettegowda <manjumb@synopsys.com>
 M:	Prabu Thangamuthu <prabut@synopsys.com>
 L:	linux-scsi@vger.kernel.org
 S:	Supported
 F:	drivers/scsi/ufs/*dwc*
 
 UNSORTED BLOCK IMAGES (UBI)
 M:	Artem Bityutskiy <dedekind1@gmail.com>
 M:	Richard Weinberger <richard@nod.at>
 W:	http://www.linux-mtd.infradead.org/
 L:	linux-mtd@lists.infradead.org
 T:	git git://git.infradead.org/ubifs-2.6.git
 S:	Supported
 F:	drivers/mtd/ubi/
 F:	include/linux/mtd/ubi.h
 F:	include/uapi/mtd/ubi-user.h
 
 USB ACM DRIVER
 M:	Oliver Neukum <oneukum@suse.com>
 L:	linux-usb@vger.kernel.org
 S:	Maintained
 F:	Documentation/usb/acm.txt
 F:	drivers/usb/class/cdc-acm.*
 
 USB AR5523 WIRELESS DRIVER
 M:	Pontus Fuchs <pontus.fuchs@gmail.com>
 L:	linux-wireless@vger.kernel.org
 S:	Maintained
 F:	drivers/net/wireless/ath/ar5523/
 
 USB ATTACHED SCSI
 M:	Oliver Neukum <oneukum@suse.com>
 L:	linux-usb@vger.kernel.org
 L:	linux-scsi@vger.kernel.org
 S:	Maintained
 F:	drivers/usb/storage/uas.c
 
 USB CDC ETHERNET DRIVER
 M:	Oliver Neukum <oliver@neukum.org>
 L:	linux-usb@vger.kernel.org
 S:	Maintained
 F:	drivers/net/usb/cdc_*.c
 F:	include/uapi/linux/usb/cdc.h
 
 USB CHAOSKEY DRIVER
 M:	Keith Packard <keithp@keithp.com>
 L:	linux-usb@vger.kernel.org
 S:	Maintained
 F:	drivers/usb/misc/chaoskey.c
 
 USB CYPRESS C67X00 DRIVER
 M:	Peter Korsgaard <jacmet@sunsite.dk>
 L:	linux-usb@vger.kernel.org
 S:	Maintained
 F:	drivers/usb/c67x00/
 
 USB DAVICOM DM9601 DRIVER
 M:	Peter Korsgaard <jacmet@sunsite.dk>
 L:	netdev@vger.kernel.org
 W:	http://www.linux-usb.org/usbnet
 S:	Maintained
 F:	drivers/net/usb/dm9601.c
 
 USB DIAMOND RIO500 DRIVER
 M:	Cesar Miquel <miquel@df.uba.ar>
 L:	rio500-users@lists.sourceforge.net
 W:	http://rio500.sourceforge.net
 S:	Maintained
 F:	drivers/usb/misc/rio500*
 
 USB EHCI DRIVER
 M:	Alan Stern <stern@rowland.harvard.edu>
 L:	linux-usb@vger.kernel.org
 S:	Maintained
 F:	Documentation/usb/ehci.txt
 F:	drivers/usb/host/ehci*
 
 USB GADGET/PERIPHERAL SUBSYSTEM
 M:	Felipe Balbi <balbi@kernel.org>
 L:	linux-usb@vger.kernel.org
 W:	http://www.linux-usb.org/gadget
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/balbi/usb.git
 S:	Maintained
 F:	drivers/usb/gadget/
 F:	include/linux/usb/gadget*
 
 USB HID/HIDBP DRIVERS (USB KEYBOARDS, MICE, REMOTE CONTROLS, ...)
 M:	Jiri Kosina <jikos@kernel.org>
 R:	Benjamin Tissoires <benjamin.tissoires@redhat.com>
 L:	linux-usb@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/jikos/hid.git
 S:	Maintained
 F:	Documentation/hid/hiddev.txt
 F:	drivers/hid/usbhid/
 
 USB ISP116X DRIVER
 M:	Olav Kongas <ok@artecdesign.ee>
 L:	linux-usb@vger.kernel.org
 S:	Maintained
 F:	drivers/usb/host/isp116x*
 F:	include/linux/usb/isp116x.h
 
 USB LAN78XX ETHERNET DRIVER
 M:	Woojung Huh <woojung.huh@microchip.com>
 M:	Microchip Linux Driver Support <UNGLinuxDriver@microchip.com>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/usb/lan78xx.*
 
 USB MASS STORAGE DRIVER
 M:	Alan Stern <stern@rowland.harvard.edu>
 L:	linux-usb@vger.kernel.org
 L:	usb-storage@lists.one-eyed-alien.net
 S:	Maintained
 W:	http://www.one-eyed-alien.net/~mdharm/linux-usb/
 F:	drivers/usb/storage/
 
 USB MIDI DRIVER
 M:	Clemens Ladisch <clemens@ladisch.de>
 L:	alsa-devel@alsa-project.org (moderated for non-subscribers)
 T:	git git://git.alsa-project.org/alsa-kernel.git
 S:	Maintained
 F:	sound/usb/midi.*
 
 USB NETWORKING DRIVERS
 L:	linux-usb@vger.kernel.org
 S:	Odd Fixes
 F:	drivers/net/usb/
 
 USB OHCI DRIVER
 M:	Alan Stern <stern@rowland.harvard.edu>
 L:	linux-usb@vger.kernel.org
 S:	Maintained
 F:	Documentation/usb/ohci.txt
 F:	drivers/usb/host/ohci*
 
 USB OTG FSM (Finite State Machine)
 M:	Peter Chen <Peter.Chen@nxp.com>
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/peter.chen/usb.git
 L:	linux-usb@vger.kernel.org
 S:	Maintained
 F:	drivers/usb/common/usb-otg-fsm.c
 
 USB OVER IP DRIVER
 M:	Valentina Manea <valentina.manea.m@gmail.com>
 M:	Shuah Khan <shuahkh@osg.samsung.com>
 M:	Shuah Khan <shuah@kernel.org>
 L:	linux-usb@vger.kernel.org
 S:	Maintained
 F:	Documentation/usb/usbip_protocol.txt
 F:	drivers/usb/usbip/
 F:	tools/usb/usbip/
 
 USB PEGASUS DRIVER
 M:	Petko Manolov <petkan@nucleusys.com>
 L:	linux-usb@vger.kernel.org
 L:	netdev@vger.kernel.org
 T:	git git://github.com/petkan/pegasus.git
 W:	https://github.com/petkan/pegasus
 S:	Maintained
 F:	drivers/net/usb/pegasus.*
 
 USB PHY LAYER
 M:	Felipe Balbi <balbi@kernel.org>
 L:	linux-usb@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/balbi/usb.git
 S:	Maintained
 F:	drivers/usb/phy/
 
 USB PRINTER DRIVER (usblp)
 M:	Pete Zaitcev <zaitcev@redhat.com>
 L:	linux-usb@vger.kernel.org
 S:	Supported
 F:	drivers/usb/class/usblp.c
 
 USB QMI WWAN NETWORK DRIVER
 M:	BjÃ¸rn Mork <bjorn@mork.no>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	Documentation/ABI/testing/sysfs-class-net-qmi
 F:	drivers/net/usb/qmi_wwan.c
 
 USB RTL8150 DRIVER
 M:	Petko Manolov <petkan@nucleusys.com>
 L:	linux-usb@vger.kernel.org
 L:	netdev@vger.kernel.org
 T:	git git://github.com/petkan/rtl8150.git
 W:	https://github.com/petkan/rtl8150
 S:	Maintained
 F:	drivers/net/usb/rtl8150.c
 
 USB SERIAL SUBSYSTEM
 M:	Johan Hovold <johan@kernel.org>
 L:	linux-usb@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/johan/usb-serial.git
 S:	Maintained
 F:	Documentation/usb/usb-serial.txt
 F:	drivers/usb/serial/
 F:	include/linux/usb/serial.h
 
 USB SMSC75XX ETHERNET DRIVER
 M:	Steve Glendinning <steve.glendinning@shawell.net>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/usb/smsc75xx.*
 
 USB SMSC95XX ETHERNET DRIVER
 M:	Steve Glendinning <steve.glendinning@shawell.net>
 M:	Microchip Linux Driver Support <UNGLinuxDriver@microchip.com>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/usb/smsc95xx.*
 
 USB SUBSYSTEM
 M:	Greg Kroah-Hartman <gregkh@linuxfoundation.org>
 L:	linux-usb@vger.kernel.org
 W:	http://www.linux-usb.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/usb.git
 S:	Supported
 F:	Documentation/devicetree/bindings/usb/
 F:	Documentation/usb/
 F:	drivers/usb/
 F:	include/linux/usb.h
 F:	include/linux/usb/
 
 USB UHCI DRIVER
 M:	Alan Stern <stern@rowland.harvard.edu>
 L:	linux-usb@vger.kernel.org
 S:	Maintained
 F:	drivers/usb/host/uhci*
 
 USB "USBNET" DRIVER FRAMEWORK
 M:	Oliver Neukum <oneukum@suse.com>
 L:	netdev@vger.kernel.org
 W:	http://www.linux-usb.org/usbnet
 S:	Maintained
 F:	drivers/net/usb/usbnet.c
 F:	include/linux/usb/usbnet.h
 
 USB VIDEO CLASS
 M:	Laurent Pinchart <laurent.pinchart@ideasonboard.com>
 L:	linux-uvc-devel@lists.sourceforge.net (subscribers-only)
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 W:	http://www.ideasonboard.org/uvc/
 S:	Maintained
 F:	drivers/media/usb/uvc/
 F:	include/uapi/linux/uvcvideo.h
 
 USB VISION DRIVER
 M:	Hans Verkuil <hverkuil@xs4all.nl>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 W:	https://linuxtv.org
 S:	Odd Fixes
 F:	drivers/media/usb/usbvision/
 
 USB WEBCAM GADGET
 M:	Laurent Pinchart <laurent.pinchart@ideasonboard.com>
 L:	linux-usb@vger.kernel.org
 S:	Maintained
 F:	drivers/usb/gadget/function/*uvc*
 F:	drivers/usb/gadget/legacy/webcam.c
 
 USB WIRELESS RNDIS DRIVER (rndis_wlan)
 M:	Jussi Kivilinna <jussi.kivilinna@iki.fi>
 L:	linux-wireless@vger.kernel.org
 S:	Maintained
 F:	drivers/net/wireless/rndis_wlan.c
 
 USB XHCI DRIVER
 M:	Mathias Nyman <mathias.nyman@intel.com>
 L:	linux-usb@vger.kernel.org
 S:	Supported
 F:	drivers/usb/host/xhci*
 F:	drivers/usb/host/pci-quirks*
 
 USB ZD1201 DRIVER
 L:	linux-wireless@vger.kernel.org
 W:	http://linux-lc100020.sourceforge.net
 S:	Orphan
 F:	drivers/net/wireless/zydas/zd1201.*
 
 USB ZR364XX DRIVER
 M:	Antoine Jacquet <royale@zerezo.com>
 L:	linux-usb@vger.kernel.org
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 W:	http://royale.zerezo.com/zr364xx/
 S:	Maintained
 F:	Documentation/media/v4l-drivers/zr364xx*
 F:	drivers/media/usb/zr364xx/
 
 ULPI BUS
 M:	Heikki Krogerus <heikki.krogerus@linux.intel.com>
 L:	linux-usb@vger.kernel.org
 S:	Maintained
 F:	drivers/usb/common/ulpi.c
 F:	include/linux/ulpi/
 
 USER-MODE LINUX (UML)
 M:	Jeff Dike <jdike@addtoit.com>
 M:	Richard Weinberger <richard@nod.at>
 L:	user-mode-linux-devel@lists.sourceforge.net
 L:	user-mode-linux-user@lists.sourceforge.net
 W:	http://user-mode-linux.sourceforge.net
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/rw/uml.git
 S:	Maintained
 F:	Documentation/virtual/uml/
 F:	arch/um/
 F:	arch/x86/um/
 F:	fs/hostfs/
 F:	fs/hppfs/
 
 USERSPACE I/O (UIO)
 M:	Greg Kroah-Hartman <gregkh@linuxfoundation.org>
 S:	Maintained
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/char-misc.git
-F:	Documentation/DocBook/uio-howto.tmpl
+F:	Documentation/driver-api/uio-howto.rst
 F:	drivers/uio/
 F:	include/linux/uio*.h
 
 UTIL-LINUX PACKAGE
 M:	Karel Zak <kzak@redhat.com>
 L:	util-linux@vger.kernel.org
 W:	http://en.wikipedia.org/wiki/Util-linux
 T:	git git://git.kernel.org/pub/scm/utils/util-linux/util-linux.git
 S:	Maintained
 
 UVESAFB DRIVER
 M:	Michal Januszewski <spock@gentoo.org>
 L:	linux-fbdev@vger.kernel.org
 W:	http://dev.gentoo.org/~spock/projects/uvesafb/
 S:	Maintained
 F:	Documentation/fb/uvesafb.txt
 F:	drivers/video/fbdev/uvesafb.*
 
 VF610 NAND DRIVER
 M:	Stefan Agner <stefan@agner.ch>
 L:	linux-mtd@lists.infradead.org
 S:	Supported
 F:	drivers/mtd/nand/vf610_nfc.c
 
 VFAT/FAT/MSDOS FILESYSTEM
 M:	OGAWA Hirofumi <hirofumi@mail.parknet.co.jp>
 S:	Maintained
 F:	Documentation/filesystems/vfat.txt
 F:	fs/fat/
 
 VFIO DRIVER
 M:	Alex Williamson <alex.williamson@redhat.com>
 L:	kvm@vger.kernel.org
 T:	git git://github.com/awilliam/linux-vfio.git
 S:	Maintained
 F:	Documentation/vfio.txt
 F:	drivers/vfio/
 F:	include/linux/vfio.h
 F:	include/uapi/linux/vfio.h
 
 VFIO MEDIATED DEVICE DRIVERS
 M:	Kirti Wankhede <kwankhede@nvidia.com>
 L:	kvm@vger.kernel.org
 S:	Maintained
 F:	Documentation/vfio-mediated-device.txt
 F:	drivers/vfio/mdev/
 F:	include/linux/mdev.h
 F:	samples/vfio-mdev/
 
 VFIO PLATFORM DRIVER
 M:	Baptiste Reynal <b.reynal@virtualopensystems.com>
 L:	kvm@vger.kernel.org
 S:	Maintained
 F:	drivers/vfio/platform/
 
 VIDEOBUF2 FRAMEWORK
 M:	Pawel Osciak <pawel@osciak.com>
 M:	Marek Szyprowski <m.szyprowski@samsung.com>
 M:	Kyungmin Park <kyungmin.park@samsung.com>
 L:	linux-media@vger.kernel.org
 S:	Maintained
 F:	drivers/media/v4l2-core/videobuf2-*
 F:	include/media/videobuf2-*
 
 VIRTIO AND VHOST VSOCK DRIVER
 M:	Stefan Hajnoczi <stefanha@redhat.com>
 L:	kvm@vger.kernel.org
 L:	virtualization@lists.linux-foundation.org
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	include/linux/virtio_vsock.h
 F:	include/uapi/linux/virtio_vsock.h
 F:	net/vmw_vsock/virtio_transport_common.c
 F:	net/vmw_vsock/virtio_transport.c
 F:	drivers/vhost/vsock.c
 F:	drivers/vhost/vsock.h
 
 VIRTUAL SERIO DEVICE DRIVER
 M:	Stephen Chandler Paul <thatslyude@gmail.com>
 S:	Maintained
 F:	drivers/input/serio/userio.c
 F:	include/uapi/linux/userio.h
 
 VIRTIO CONSOLE DRIVER
 M:	Amit Shah <amit@kernel.org>
 L:	virtualization@lists.linux-foundation.org
 S:	Maintained
 F:	drivers/char/virtio_console.c
 F:	include/linux/virtio_console.h
 F:	include/uapi/linux/virtio_console.h
 
 VIRTIO CORE, NET AND BLOCK DRIVERS
 M:	"Michael S. Tsirkin" <mst@redhat.com>
 M:	Jason Wang <jasowang@redhat.com>
 L:	virtualization@lists.linux-foundation.org
 S:	Maintained
 F:	Documentation/devicetree/bindings/virtio/
 F:	drivers/virtio/
 F:	tools/virtio/
 F:	drivers/net/virtio_net.c
 F:	drivers/block/virtio_blk.c
 F:	include/linux/virtio_*.h
 F:	include/uapi/linux/virtio_*.h
 F:	drivers/crypto/virtio/
 
 VIRTIO DRIVERS FOR S390
 M:	Christian Borntraeger <borntraeger@de.ibm.com>
 M:	Cornelia Huck <cornelia.huck@de.ibm.com>
 L:	linux-s390@vger.kernel.org
 L:	virtualization@lists.linux-foundation.org
 L:	kvm@vger.kernel.org
 S:	Supported
 F:	drivers/s390/virtio/
 
 VIRTIO GPU DRIVER
 M:	David Airlie <airlied@linux.ie>
 M:	Gerd Hoffmann <kraxel@redhat.com>
 L:	dri-devel@lists.freedesktop.org
 L:	virtualization@lists.linux-foundation.org
 T:	git git://git.kraxel.org/linux drm-qemu
 S:	Maintained
 F:	drivers/gpu/drm/virtio/
 F:	include/uapi/linux/virtio_gpu.h
 
 VIRTIO HOST (VHOST)
 M:	"Michael S. Tsirkin" <mst@redhat.com>
 M:	Jason Wang <jasowang@redhat.com>
 L:	kvm@vger.kernel.org
 L:	virtualization@lists.linux-foundation.org
 L:	netdev@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/mst/vhost.git
 S:	Maintained
 F:	drivers/vhost/
 F:	include/uapi/linux/vhost.h
 
 VIRTIO INPUT DRIVER
 M:	Gerd Hoffmann <kraxel@redhat.com>
 S:	Maintained
 F:	drivers/virtio/virtio_input.c
 F:	include/uapi/linux/virtio_input.h
 
 VIRTIO CRYPTO DRIVER
 M:  Gonglei <arei.gonglei@huawei.com>
 L:  virtualization@lists.linux-foundation.org
 L:  linux-crypto@vger.kernel.org
 S:  Maintained
 F:  drivers/crypto/virtio/
 F:  include/uapi/linux/virtio_crypto.h
 
 VIA RHINE NETWORK DRIVER
 S:	Orphan
 F:	drivers/net/ethernet/via/via-rhine.c
 
 VIA SD/MMC CARD CONTROLLER DRIVER
 M:	Bruce Chang <brucechang@via.com.tw>
 M:	Harald Welte <HaraldWelte@viatech.com>
 S:	Maintained
 F:	drivers/mmc/host/via-sdmmc.c
 
 VIA UNICHROME(PRO)/CHROME9 FRAMEBUFFER DRIVER
 M:	Florian Tobias Schandinat <FlorianSchandinat@gmx.de>
 L:	linux-fbdev@vger.kernel.org
 S:	Maintained
 F:	include/linux/via-core.h
 F:	include/linux/via-gpio.h
 F:	include/linux/via_i2c.h
 F:	drivers/video/fbdev/via/
 
 VIA VELOCITY NETWORK DRIVER
 M:	Francois Romieu <romieu@fr.zoreil.com>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/ethernet/via/via-velocity.*
 
 VIRT LIB
 M:	Alex Williamson <alex.williamson@redhat.com>
 M:	Paolo Bonzini <pbonzini@redhat.com>
 L:	kvm@vger.kernel.org
 S:	Supported
 F:	virt/lib/
 
 VIVID VIRTUAL VIDEO DRIVER
 M:	Hans Verkuil <hverkuil@xs4all.nl>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 W:	https://linuxtv.org
 S:	Maintained
 F:	drivers/media/platform/vivid/*
 
 VLAN (802.1Q)
 M:	Patrick McHardy <kaber@trash.net>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/macvlan.c
 F:	include/linux/if_*vlan.h
 F:	net/8021q/
 
 VLYNQ BUS
 M:	Florian Fainelli <f.fainelli@gmail.com>
 L:	openwrt-devel@lists.openwrt.org (subscribers-only)
 S:	Maintained
 F:	drivers/vlynq/vlynq.c
 F:	include/linux/vlynq.h
 
 VME SUBSYSTEM
 M:	Martyn Welch <martyn@welchs.me.uk>
 M:	Manohar Vanga <manohar.vanga@gmail.com>
 M:	Greg Kroah-Hartman <gregkh@linuxfoundation.org>
 L:	devel@driverdev.osuosl.org
 S:	Maintained
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/driver-core.git
 F:	Documentation/driver-api/vme.rst
 F:	drivers/staging/vme/
 F:	drivers/vme/
 F:	include/linux/vme*
 
 VMWARE HYPERVISOR INTERFACE
 M:	Alok Kataria <akataria@vmware.com>
 L:	virtualization@lists.linux-foundation.org
 S:	Supported
 F:	arch/x86/kernel/cpu/vmware.c
 
 VMWARE BALLOON DRIVER
 M:	Xavier Deguillard <xdeguillard@vmware.com>
 M:	Philip Moltmann <moltmann@vmware.com>
 M:	"VMware, Inc." <pv-drivers@vmware.com>
 L:	linux-kernel@vger.kernel.org
 S:	Maintained
 F:	drivers/misc/vmw_balloon.c
 
 VMWARE VMMOUSE SUBDRIVER
 M:	"VMware Graphics" <linux-graphics-maintainer@vmware.com>
 M:	"VMware, Inc." <pv-drivers@vmware.com>
 L:	linux-input@vger.kernel.org
 S:	Maintained
 F:	drivers/input/mouse/vmmouse.c
 F:	drivers/input/mouse/vmmouse.h
 
 VMWARE VMXNET3 ETHERNET DRIVER
 M:	Shrikrishna Khare <skhare@vmware.com>
 M:	"VMware, Inc." <pv-drivers@vmware.com>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/vmxnet3/
 
 VMware PVSCSI driver
 M:	Jim Gill <jgill@vmware.com>
 M:	VMware PV-Drivers <pv-drivers@vmware.com>
 L:	linux-scsi@vger.kernel.org
 S:	Maintained
 F:	drivers/scsi/vmw_pvscsi.c
 F:	drivers/scsi/vmw_pvscsi.h
 
 VMWARE PVRDMA DRIVER
 M:	Adit Ranadive <aditr@vmware.com>
 M:	VMware PV-Drivers <pv-drivers@vmware.com>
 L:	linux-rdma@vger.kernel.org
 S:	Maintained
 F:	drivers/infiniband/hw/vmw_pvrdma/
 
 VOLTAGE AND CURRENT REGULATOR FRAMEWORK
 M:	Liam Girdwood <lgirdwood@gmail.com>
 M:	Mark Brown <broonie@kernel.org>
 L:	linux-kernel@vger.kernel.org
 W:	http://www.slimlogic.co.uk/?p=48
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/broonie/regulator.git
 S:	Supported
 F:	Documentation/devicetree/bindings/regulator/
 F:	drivers/regulator/
 F:	include/dt-bindings/regulator/
 F:	include/linux/regulator/
 
 VRF
 M:	David Ahern <dsa@cumulusnetworks.com>
 M:	Shrijeet Mukherjee <shm@cumulusnetworks.com>
 L:	netdev@vger.kernel.org
 S:	Maintained
 F:	drivers/net/vrf.c
 F:	Documentation/networking/vrf.txt
 
 VT1211 HARDWARE MONITOR DRIVER
 M:	Juerg Haefliger <juergh@gmail.com>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	Documentation/hwmon/vt1211
 F:	drivers/hwmon/vt1211.c
 
 VT8231 HARDWARE MONITOR DRIVER
 M:	Roger Lucas <vt8231@hiddenengine.co.uk>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	drivers/hwmon/vt8231.c
 
 VUB300 USB to SDIO/SD/MMC bridge chip
 M:	Tony Olech <tony.olech@elandigitalsystems.com>
 L:	linux-mmc@vger.kernel.org
 L:	linux-usb@vger.kernel.org
 S:	Supported
 F:	drivers/mmc/host/vub300.c
 
 W1 DALLAS'S 1-WIRE BUS
 M:	Evgeniy Polyakov <zbr@ioremap.net>
 S:	Maintained
 F:	Documentation/w1/
 F:	drivers/w1/
 
 W83791D HARDWARE MONITORING DRIVER
 M:	Marc Hulsman <m.hulsman@tudelft.nl>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	Documentation/hwmon/w83791d
 F:	drivers/hwmon/w83791d.c
 
 W83793 HARDWARE MONITORING DRIVER
 M:	Rudolf Marek <r.marek@assembler.cz>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	Documentation/hwmon/w83793
 F:	drivers/hwmon/w83793.c
 
 W83795 HARDWARE MONITORING DRIVER
 M:	Jean Delvare <jdelvare@suse.com>
 L:	linux-hwmon@vger.kernel.org
 S:	Maintained
 F:	drivers/hwmon/w83795.c
 
 W83L51xD SD/MMC CARD INTERFACE DRIVER
 M:	Pierre Ossman <pierre@ossman.eu>
 S:	Maintained
 F:	drivers/mmc/host/wbsd.*
 
 WACOM PROTOCOL 4 SERIAL TABLETS
 M:	Julian Squires <julian@cipht.net>
 M:	Hans de Goede <hdegoede@redhat.com>
 L:	linux-input@vger.kernel.org
 S:	Maintained
 F:	drivers/input/tablet/wacom_serial4.c
 
 WATCHDOG DEVICE DRIVERS
 M:	Wim Van Sebroeck <wim@iguana.be>
 R:	Guenter Roeck <linux@roeck-us.net>
 L:	linux-watchdog@vger.kernel.org
 W:	http://www.linux-watchdog.org/
 T:	git git://www.linux-watchdog.org/linux-watchdog.git
 S:	Maintained
 F:	Documentation/devicetree/bindings/watchdog/
 F:	Documentation/watchdog/
 F:	drivers/watchdog/
 F:	include/linux/watchdog.h
 F:	include/uapi/linux/watchdog.h
 
 WIIMOTE HID DRIVER
 M:	David Herrmann <dh.herrmann@googlemail.com>
 L:	linux-input@vger.kernel.org
 S:	Maintained
 F:	drivers/hid/hid-wiimote*
 
 WINBOND CIR DRIVER
 M:	David HÃ¤rdeman <david@hardeman.nu>
 S:	Maintained
 F:	drivers/media/rc/winbond-cir.c
 
 WINSYSTEMS EBC-C384 WATCHDOG DRIVER
 M:	William Breathitt Gray <vilhelm.gray@gmail.com>
 L:	linux-watchdog@vger.kernel.org
 S:	Maintained
 F:	drivers/watchdog/ebc-c384_wdt.c
 
 WINSYSTEMS WS16C48 GPIO DRIVER
 M:	William Breathitt Gray <vilhelm.gray@gmail.com>
 L:	linux-gpio@vger.kernel.org
 S:	Maintained
 F:	drivers/gpio/gpio-ws16c48.c
 
 WIMAX STACK
 M:	Inaky Perez-Gonzalez <inaky.perez-gonzalez@intel.com>
 M:	linux-wimax@intel.com
 L:	wimax@linuxwimax.org (subscribers-only)
 S:	Supported
 W:	http://linuxwimax.org
 F:	Documentation/wimax/README.wimax
 F:	include/linux/wimax/debug.h
 F:	include/net/wimax.h
 F:	include/uapi/linux/wimax.h
 F:	net/wimax/
 
 WISTRON LAPTOP BUTTON DRIVER
 M:	Miloslav Trmac <mitr@volny.cz>
 S:	Maintained
 F:	drivers/input/misc/wistron_btns.c
 
 WL3501 WIRELESS PCMCIA CARD DRIVER
 L:	linux-wireless@vger.kernel.org
 S:	Odd fixes
 F:	drivers/net/wireless/wl3501*
 
 WOLFSON MICROELECTRONICS DRIVERS
 L:	patches@opensource.wolfsonmicro.com
 T:	git https://github.com/CirrusLogic/linux-drivers.git
 W:	https://github.com/CirrusLogic/linux-drivers/wiki
 S:	Supported
 F:	Documentation/hwmon/wm83??
 F:	Documentation/devicetree/bindings/extcon/extcon-arizona.txt
 F:	Documentation/devicetree/bindings/regulator/arizona-regulator.txt
 F:	Documentation/devicetree/bindings/mfd/arizona.txt
 F:	arch/arm/mach-s3c64xx/mach-crag6410*
 F:	drivers/clk/clk-wm83*.c
 F:	drivers/extcon/extcon-arizona.c
 F:	drivers/leds/leds-wm83*.c
 F:	drivers/gpio/gpio-*wm*.c
 F:	drivers/gpio/gpio-arizona.c
 F:	drivers/hwmon/wm83??-hwmon.c
 F:	drivers/input/misc/wm831x-on.c
 F:	drivers/input/touchscreen/wm831x-ts.c
 F:	drivers/input/touchscreen/wm97*.c
 F:	drivers/mfd/arizona*
 F:	drivers/mfd/wm*.c
 F:	drivers/mfd/cs47l24*
 F:	drivers/power/supply/wm83*.c
 F:	drivers/rtc/rtc-wm83*.c
 F:	drivers/regulator/wm8*.c
 F:	drivers/video/backlight/wm83*_bl.c
 F:	drivers/watchdog/wm83*_wdt.c
 F:	include/linux/mfd/arizona/
 F:	include/linux/mfd/wm831x/
 F:	include/linux/mfd/wm8350/
 F:	include/linux/mfd/wm8400*
 F:	include/linux/wm97xx.h
 F:	include/sound/wm????.h
 F:	sound/soc/codecs/arizona.?
 F:	sound/soc/codecs/wm*
 F:	sound/soc/codecs/cs47l24*
 
 WORKQUEUE
 M:	Tejun Heo <tj@kernel.org>
 R:	Lai Jiangshan <jiangshanlai@gmail.com>
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/tj/wq.git
 S:	Maintained
 F:	include/linux/workqueue.h
 F:	kernel/workqueue.c
 F:	Documentation/core-api/workqueue.rst
 
 X-POWERS MULTIFUNCTION PMIC DEVICE DRIVERS
 M:	Chen-Yu Tsai <wens@csie.org>
 L:	linux-kernel@vger.kernel.org
 S:	Maintained
 N:	axp[128]
 
 X.25 NETWORK LAYER
 M:	Andrew Hendry <andrew.hendry@gmail.com>
 L:	linux-x25@vger.kernel.org
 S:	Odd Fixes
 F:	Documentation/networking/x25*
 F:	include/net/x25*
 F:	net/x25/
 
 X86 ARCHITECTURE (32-BIT AND 64-BIT)
 M:	Thomas Gleixner <tglx@linutronix.de>
 M:	Ingo Molnar <mingo@redhat.com>
 M:	"H. Peter Anvin" <hpa@zytor.com>
 M:	x86@kernel.org
 L:	linux-kernel@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip.git x86/core
 S:	Maintained
 F:	Documentation/x86/
 F:	arch/x86/
 
 X86 PLATFORM DRIVERS
 M:	Darren Hart <dvhart@infradead.org>
 M:	Andy Shevchenko <andy@infradead.org>
 L:	platform-driver-x86@vger.kernel.org
 T:	git git://git.infradead.org/users/dvhart/linux-platform-drivers-x86.git
 S:	Maintained
 F:	drivers/platform/x86/
 F:	drivers/platform/olpc/
 
 X86 MCE INFRASTRUCTURE
 M:	Tony Luck <tony.luck@intel.com>
 M:	Borislav Petkov <bp@alien8.de>
 L:	linux-edac@vger.kernel.org
 S:	Maintained
 F:	arch/x86/kernel/cpu/mcheck/*
 
 X86 MICROCODE UPDATE SUPPORT
 M:	Borislav Petkov <bp@alien8.de>
 S:	Maintained
 F:	arch/x86/kernel/cpu/microcode/*
 
 X86 VDSO
 M:	Andy Lutomirski <luto@amacapital.net>
 L:	linux-kernel@vger.kernel.org
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip.git x86/vdso
 S:	Maintained
 F:	arch/x86/entry/vdso/
 
 XC2028/3028 TUNER DRIVER
 M:	Mauro Carvalho Chehab <mchehab@s-opensource.com>
 M:	Mauro Carvalho Chehab <mchehab@kernel.org>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Maintained
 F:	drivers/media/tuners/tuner-xc2028.*
 
 XEN HYPERVISOR INTERFACE
 M:	Boris Ostrovsky <boris.ostrovsky@oracle.com>
 M:	Juergen Gross <jgross@suse.com>
 L:	xen-devel@lists.xenproject.org (moderated for non-subscribers)
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/xen/tip.git
 S:	Supported
 F:	arch/x86/xen/
 F:	drivers/*/xen-*front.c
 F:	drivers/xen/
 F:	arch/x86/include/asm/xen/
 F:	include/xen/
 F:	include/uapi/xen/
 
 XEN HYPERVISOR ARM
 M:	Stefano Stabellini <sstabellini@kernel.org>
 L:	xen-devel@lists.xenproject.org (moderated for non-subscribers)
 S:	Maintained
 F:	arch/arm/xen/
 F:	arch/arm/include/asm/xen/
 
 XEN HYPERVISOR ARM64
 M:	Stefano Stabellini <sstabellini@kernel.org>
 L:	xen-devel@lists.xenproject.org (moderated for non-subscribers)
 S:	Maintained
 F:	arch/arm64/xen/
 F:	arch/arm64/include/asm/xen/
 
 XEN NETWORK BACKEND DRIVER
 M:	Wei Liu <wei.liu2@citrix.com>
 M:	Paul Durrant <paul.durrant@citrix.com>
 L:	xen-devel@lists.xenproject.org (moderated for non-subscribers)
 L:	netdev@vger.kernel.org
 S:	Supported
 F:	drivers/net/xen-netback/*
 
 XEN PCI SUBSYSTEM
 M:	Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
 L:	xen-devel@lists.xenproject.org (moderated for non-subscribers)
 S:	Supported
 F:	arch/x86/pci/*xen*
 F:	drivers/pci/*xen*
 
 XEN BLOCK SUBSYSTEM
 M:	Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
 M:	Roger Pau MonnÃ© <roger.pau@citrix.com>
 L:	xen-devel@lists.xenproject.org (moderated for non-subscribers)
 S:	Supported
 F:	drivers/block/xen-blkback/*
 F:	drivers/block/xen*
 
 XEN PVSCSI DRIVERS
 M:	Juergen Gross <jgross@suse.com>
 L:	xen-devel@lists.xenproject.org (moderated for non-subscribers)
 L:	linux-scsi@vger.kernel.org
 S:	Supported
 F:	drivers/scsi/xen-scsifront.c
 F:	drivers/xen/xen-scsiback.c
 F:	include/xen/interface/io/vscsiif.h
 
 XEN SWIOTLB SUBSYSTEM
 M:	Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
 L:	xen-devel@lists.xenproject.org (moderated for non-subscribers)
 S:	Supported
 F:	arch/x86/xen/*swiotlb*
 F:	drivers/xen/*swiotlb*
 
 XFS FILESYSTEM
 M:	Darrick J. Wong <darrick.wong@oracle.com>
 M:	linux-xfs@vger.kernel.org
 L:	linux-xfs@vger.kernel.org
 W:	http://xfs.org/
 T:	git git://git.kernel.org/pub/scm/fs/xfs/xfs-linux.git
 S:	Supported
 F:	Documentation/filesystems/xfs.txt
 F:	fs/xfs/
 
 XILINX AXI ETHERNET DRIVER
 M:	Anirudha Sarangi <anirudh@xilinx.com>
 M:	John Linn <John.Linn@xilinx.com>
 S:	Maintained
 F:	drivers/net/ethernet/xilinx/xilinx_axienet*
 
 XILINX UARTLITE SERIAL DRIVER
 M:	Peter Korsgaard <jacmet@sunsite.dk>
 L:	linux-serial@vger.kernel.org
 S:	Maintained
 F:	drivers/tty/serial/uartlite.c
 
 XILINX VIDEO IP CORES
 M:	Hyun Kwon <hyun.kwon@xilinx.com>
 M:	Laurent Pinchart <laurent.pinchart@ideasonboard.com>
 L:	linux-media@vger.kernel.org
 T:	git git://linuxtv.org/media_tree.git
 S:	Supported
 F:	Documentation/devicetree/bindings/media/xilinx/
 F:	drivers/media/platform/xilinx/
 F:	include/uapi/linux/xilinx-v4l2-controls.h
 
 XILLYBUS DRIVER
 M:	Eli Billauer <eli.billauer@gmail.com>
 L:	linux-kernel@vger.kernel.org
 S:	Supported
 F:	drivers/char/xillybus/
 
 XTENSA XTFPGA PLATFORM SUPPORT
 M:	Max Filippov <jcmvbkbc@gmail.com>
 L:	linux-xtensa@linux-xtensa.org
 S:	Maintained
 F:	drivers/spi/spi-xtensa-xtfpga.c
 F:	sound/soc/xtensa/xtfpga-i2s.c
 
 YAM DRIVER FOR AX.25
 M:	Jean-Paul Roubelat <jpr@f6fbb.org>
 L:	linux-hams@vger.kernel.org
 S:	Maintained
 F:	drivers/net/hamradio/yam*
 F:	include/linux/yam.h
 
 YEALINK PHONE DRIVER
 M:	Henk Vergonet <Henk.Vergonet@gmail.com>
 L:	usbb2k-api-dev@nongnu.org
 S:	Maintained
 F:	Documentation/input/yealink.txt
 F:	drivers/input/misc/yealink.*
 
 Z8530 DRIVER FOR AX.25
 M:	Joerg Reuter <jreuter@yaina.de>
 W:	http://yaina.de/jreuter/
 W:	http://www.qsl.net/dl1bke/
 L:	linux-hams@vger.kernel.org
 S:	Maintained
 F:	Documentation/networking/z8530drv.txt
 F:	drivers/net/hamradio/*scc.c
 F:	drivers/net/hamradio/z8530.h
 
 ZBUD COMPRESSED PAGE ALLOCATOR
 M:	Seth Jennings <sjenning@redhat.com>
 M:	Dan Streetman <ddstreet@ieee.org>
 L:	linux-mm@kvack.org
 S:	Maintained
 F:	mm/zbud.c
 F:	include/linux/zbud.h
 
 ZD1211RW WIRELESS DRIVER
 M:	Daniel Drake <dsd@gentoo.org>
 M:	Ulrich Kunitz <kune@deine-taler.de>
 W:	http://zd1211.ath.cx/wiki/DriverRewrite
 L:	linux-wireless@vger.kernel.org
 L:	zd1211-devs@lists.sourceforge.net (subscribers-only)
 S:	Maintained
 F:	drivers/net/wireless/zydas/zd1211rw/
 
 ZD1301_DEMOD MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org/
 W:	http://palosaari.fi/linux/
 Q:	https://patchwork.linuxtv.org/project/linux-media/list/
 S:	Maintained
 F:	drivers/media/dvb-frontends/zd1301_demod*
 
 ZD1301 MEDIA DRIVER
 M:	Antti Palosaari <crope@iki.fi>
 L:	linux-media@vger.kernel.org
 W:	https://linuxtv.org/
 W:	http://palosaari.fi/linux/
 Q:	https://patchwork.linuxtv.org/project/linux-media/list/
 S:	Maintained
 F:	drivers/media/usb/dvb-usb-v2/zd1301*
 
 ZPOOL COMPRESSED PAGE STORAGE API
 M:	Dan Streetman <ddstreet@ieee.org>
 L:	linux-mm@kvack.org
 S:	Maintained
 F:	mm/zpool.c
 F:	include/linux/zpool.h
 
 ZR36067 VIDEO FOR LINUX DRIVER
 L:	mjpeg-users@lists.sourceforge.net
 L:	linux-media@vger.kernel.org
 W:	http://mjpeg.sourceforge.net/driver-zoran/
 T:	hg https://linuxtv.org/hg/v4l-dvb
 S:	Odd Fixes
 F:	drivers/media/pci/zoran/
 
 ZRAM COMPRESSED RAM BLOCK DEVICE DRVIER
 M:	Minchan Kim <minchan@kernel.org>
 M:	Nitin Gupta <ngupta@vflare.org>
 R:	Sergey Senozhatsky <sergey.senozhatsky.work@gmail.com>
 L:	linux-kernel@vger.kernel.org
 S:	Maintained
 F:	drivers/block/zram/
 F:	Documentation/blockdev/zram.txt
 
 ZS DECSTATION Z85C30 SERIAL DRIVER
 M:	"Maciej W. Rozycki" <macro@linux-mips.org>
 S:	Maintained
 F:	drivers/tty/serial/zs.*
 
 ZSMALLOC COMPRESSED SLAB MEMORY ALLOCATOR
 M:	Minchan Kim <minchan@kernel.org>
 M:	Nitin Gupta <ngupta@vflare.org>
 R:	Sergey Senozhatsky <sergey.senozhatsky.work@gmail.com>
 L:	linux-mm@kvack.org
 S:	Maintained
 F:	mm/zsmalloc.c
 F:	include/linux/zsmalloc.h
 F:	Documentation/vm/zsmalloc.txt
 
 ZSWAP COMPRESSED SWAP CACHING
 M:	Seth Jennings <sjenning@redhat.com>
 M:	Dan Streetman <ddstreet@ieee.org>
 L:	linux-mm@kvack.org
 S:	Maintained
 F:	mm/zswap.c
 
 THE REST
 M:	Linus Torvalds <torvalds@linux-foundation.org>
 L:	linux-kernel@vger.kernel.org
 Q:	http://patchwork.kernel.org/project/LKML/list/
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git
 S:	Buried alive in reporters
 F:	*
 F:	*/
diff --git a/arch/arm/mach-davinci/da850.c b/arch/arm/mach-davinci/da850.c
index 1d873d15b545..9780829f8a05 100644
--- a/arch/arm/mach-davinci/da850.c
+++ b/arch/arm/mach-davinci/da850.c
@@ -1,1385 +1,1377 @@
 /*
  * TI DA850/OMAP-L138 chip specific setup
  *
  * Copyright (C) 2009 Texas Instruments Incorporated - http://www.ti.com/
  *
  * Derived from: arch/arm/mach-davinci/da830.c
  * Original Copyrights follow:
  *
  * 2009 (c) MontaVista Software, Inc. This file is licensed under
  * the terms of the GNU General Public License version 2. This program
  * is licensed "as is" without any warranty of any kind, whether express
  * or implied.
  */
 #include <linux/clkdev.h>
 #include <linux/gpio.h>
 #include <linux/init.h>
 #include <linux/clk.h>
 #include <linux/platform_device.h>
 #include <linux/cpufreq.h>
 #include <linux/regulator/consumer.h>
 #include <linux/platform_data/gpio-davinci.h>
 
 #include <asm/mach/map.h>
 
 #include "psc.h"
 #include <mach/irqs.h>
 #include <mach/cputype.h>
 #include <mach/common.h>
 #include <mach/time.h>
 #include <mach/da8xx.h>
 #include <mach/cpufreq.h>
 #include <mach/pm.h>
 
 #include "clock.h"
 #include "mux.h"
 
 #define DA850_PLL1_BASE		0x01e1a000
 #define DA850_TIMER64P2_BASE	0x01f0c000
 #define DA850_TIMER64P3_BASE	0x01f0d000
 
 #define DA850_REF_FREQ		24000000
 
 #define CFGCHIP3_ASYNC3_CLKSRC	BIT(4)
 #define CFGCHIP3_PLL1_MASTER_LOCK	BIT(5)
 #define CFGCHIP0_PLL_MASTER_LOCK	BIT(4)
 
 static int da850_set_armrate(struct clk *clk, unsigned long rate);
 static int da850_round_armrate(struct clk *clk, unsigned long rate);
 static int da850_set_pll0rate(struct clk *clk, unsigned long armrate);
 
 static struct pll_data pll0_data = {
 	.num		= 1,
 	.phys_base	= DA8XX_PLL0_BASE,
 	.flags		= PLL_HAS_PREDIV | PLL_HAS_POSTDIV,
 };
 
 static struct clk ref_clk = {
 	.name		= "ref_clk",
 	.rate		= DA850_REF_FREQ,
 	.set_rate	= davinci_simple_set_rate,
 };
 
 static struct clk pll0_clk = {
 	.name		= "pll0",
 	.parent		= &ref_clk,
 	.pll_data	= &pll0_data,
 	.flags		= CLK_PLL,
 	.set_rate	= da850_set_pll0rate,
 };
 
 static struct clk pll0_aux_clk = {
 	.name		= "pll0_aux_clk",
 	.parent		= &pll0_clk,
 	.flags		= CLK_PLL | PRE_PLL,
 };
 
 static struct clk pll0_sysclk1 = {
 	.name		= "pll0_sysclk1",
 	.parent		= &pll0_clk,
 	.flags		= CLK_PLL,
 	.div_reg	= PLLDIV1,
 };
 
 static struct clk pll0_sysclk2 = {
 	.name		= "pll0_sysclk2",
 	.parent		= &pll0_clk,
 	.flags		= CLK_PLL,
 	.div_reg	= PLLDIV2,
 };
 
 static struct clk pll0_sysclk3 = {
 	.name		= "pll0_sysclk3",
 	.parent		= &pll0_clk,
 	.flags		= CLK_PLL,
 	.div_reg	= PLLDIV3,
 	.set_rate	= davinci_set_sysclk_rate,
 	.maxrate	= 100000000,
 };
 
 static struct clk pll0_sysclk4 = {
 	.name		= "pll0_sysclk4",
 	.parent		= &pll0_clk,
 	.flags		= CLK_PLL,
 	.div_reg	= PLLDIV4,
 };
 
 static struct clk pll0_sysclk5 = {
 	.name		= "pll0_sysclk5",
 	.parent		= &pll0_clk,
 	.flags		= CLK_PLL,
 	.div_reg	= PLLDIV5,
 };
 
 static struct clk pll0_sysclk6 = {
 	.name		= "pll0_sysclk6",
 	.parent		= &pll0_clk,
 	.flags		= CLK_PLL,
 	.div_reg	= PLLDIV6,
 };
 
 static struct clk pll0_sysclk7 = {
 	.name		= "pll0_sysclk7",
 	.parent		= &pll0_clk,
 	.flags		= CLK_PLL,
 	.div_reg	= PLLDIV7,
 };
 
 static struct pll_data pll1_data = {
 	.num		= 2,
 	.phys_base	= DA850_PLL1_BASE,
 	.flags		= PLL_HAS_POSTDIV,
 };
 
 static struct clk pll1_clk = {
 	.name		= "pll1",
 	.parent		= &ref_clk,
 	.pll_data	= &pll1_data,
 	.flags		= CLK_PLL,
 };
 
 static struct clk pll1_aux_clk = {
 	.name		= "pll1_aux_clk",
 	.parent		= &pll1_clk,
 	.flags		= CLK_PLL | PRE_PLL,
 };
 
 static struct clk pll1_sysclk2 = {
 	.name		= "pll1_sysclk2",
 	.parent		= &pll1_clk,
 	.flags		= CLK_PLL,
 	.div_reg	= PLLDIV2,
 };
 
 static struct clk pll1_sysclk3 = {
 	.name		= "pll1_sysclk3",
 	.parent		= &pll1_clk,
 	.flags		= CLK_PLL,
 	.div_reg	= PLLDIV3,
 };
 
 static int da850_async3_set_parent(struct clk *clk, struct clk *parent)
 {
 	u32 val;
 
 	val = readl(DA8XX_SYSCFG0_VIRT(DA8XX_CFGCHIP3_REG));
 
 	if (parent == &pll0_sysclk2) {
 		val &= ~CFGCHIP3_ASYNC3_CLKSRC;
 	} else if (parent == &pll1_sysclk2) {
 		val |= CFGCHIP3_ASYNC3_CLKSRC;
 	} else {
 		pr_err("Bad parent on async3 clock mux\n");
 		return -EINVAL;
 	}
 
 	writel(val, DA8XX_SYSCFG0_VIRT(DA8XX_CFGCHIP3_REG));
 
 	return 0;
 }
 
 static struct clk async3_clk = {
 	.name		= "async3",
 	.parent		= &pll1_sysclk2,
 	.set_parent	= da850_async3_set_parent,
 };
 
 static struct clk i2c0_clk = {
 	.name		= "i2c0",
 	.parent		= &pll0_aux_clk,
 };
 
 static struct clk timerp64_0_clk = {
 	.name		= "timer0",
 	.parent		= &pll0_aux_clk,
 };
 
 static struct clk timerp64_1_clk = {
 	.name		= "timer1",
 	.parent		= &pll0_aux_clk,
 };
 
 static struct clk arm_rom_clk = {
 	.name		= "arm_rom",
 	.parent		= &pll0_sysclk2,
 	.lpsc		= DA8XX_LPSC0_ARM_RAM_ROM,
 	.flags		= ALWAYS_ENABLED,
 };
 
 static struct clk tpcc0_clk = {
 	.name		= "tpcc0",
 	.parent		= &pll0_sysclk2,
 	.lpsc		= DA8XX_LPSC0_TPCC,
 	.flags		= ALWAYS_ENABLED | CLK_PSC,
 };
 
 static struct clk tptc0_clk = {
 	.name		= "tptc0",
 	.parent		= &pll0_sysclk2,
 	.lpsc		= DA8XX_LPSC0_TPTC0,
 	.flags		= ALWAYS_ENABLED,
 };
 
 static struct clk tptc1_clk = {
 	.name		= "tptc1",
 	.parent		= &pll0_sysclk2,
 	.lpsc		= DA8XX_LPSC0_TPTC1,
 	.flags		= ALWAYS_ENABLED,
 };
 
 static struct clk tpcc1_clk = {
 	.name		= "tpcc1",
 	.parent		= &pll0_sysclk2,
 	.lpsc		= DA850_LPSC1_TPCC1,
 	.gpsc		= 1,
 	.flags		= CLK_PSC | ALWAYS_ENABLED,
 };
 
 static struct clk tptc2_clk = {
 	.name		= "tptc2",
 	.parent		= &pll0_sysclk2,
 	.lpsc		= DA850_LPSC1_TPTC2,
 	.gpsc		= 1,
 	.flags		= ALWAYS_ENABLED,
 };
 
 static struct clk pruss_clk = {
 	.name		= "pruss",
 	.parent		= &pll0_sysclk2,
 	.lpsc		= DA8XX_LPSC0_PRUSS,
 };
 
 static struct clk uart0_clk = {
 	.name		= "uart0",
 	.parent		= &pll0_sysclk2,
 	.lpsc		= DA8XX_LPSC0_UART0,
 };
 
 static struct clk uart1_clk = {
 	.name		= "uart1",
 	.parent		= &async3_clk,
 	.lpsc		= DA8XX_LPSC1_UART1,
 	.gpsc		= 1,
 };
 
 static struct clk uart2_clk = {
 	.name		= "uart2",
 	.parent		= &async3_clk,
 	.lpsc		= DA8XX_LPSC1_UART2,
 	.gpsc		= 1,
 };
 
 static struct clk aintc_clk = {
 	.name		= "aintc",
 	.parent		= &pll0_sysclk4,
 	.lpsc		= DA8XX_LPSC0_AINTC,
 	.flags		= ALWAYS_ENABLED,
 };
 
 static struct clk gpio_clk = {
 	.name		= "gpio",
 	.parent		= &pll0_sysclk4,
 	.lpsc		= DA8XX_LPSC1_GPIO,
 	.gpsc		= 1,
 };
 
 static struct clk i2c1_clk = {
 	.name		= "i2c1",
 	.parent		= &pll0_sysclk4,
 	.lpsc		= DA8XX_LPSC1_I2C,
 	.gpsc		= 1,
 };
 
 static struct clk emif3_clk = {
 	.name		= "emif3",
 	.parent		= &pll0_sysclk5,
 	.lpsc		= DA8XX_LPSC1_EMIF3C,
 	.gpsc		= 1,
 	.flags		= ALWAYS_ENABLED,
 };
 
 static struct clk arm_clk = {
 	.name		= "arm",
 	.parent		= &pll0_sysclk6,
 	.lpsc		= DA8XX_LPSC0_ARM,
 	.flags		= ALWAYS_ENABLED,
 	.set_rate	= da850_set_armrate,
 	.round_rate	= da850_round_armrate,
 };
 
 static struct clk rmii_clk = {
 	.name		= "rmii",
 	.parent		= &pll0_sysclk7,
 };
 
 static struct clk emac_clk = {
 	.name		= "emac",
 	.parent		= &pll0_sysclk4,
 	.lpsc		= DA8XX_LPSC1_CPGMAC,
 	.gpsc		= 1,
 };
 
 /*
  * In order to avoid adding the emac_clk to the clock lookup table twice (and
  * screwing up the linked list in the process) create a separate clock for
  * mdio inheriting the rate from emac_clk.
  */
 static struct clk mdio_clk = {
 	.name		= "mdio",
 	.parent		= &emac_clk,
 };
 
 static struct clk mcasp_clk = {
 	.name		= "mcasp",
 	.parent		= &async3_clk,
 	.lpsc		= DA8XX_LPSC1_McASP0,
 	.gpsc		= 1,
 };
 
 static struct clk mcbsp0_clk = {
 	.name		= "mcbsp0",
 	.parent		= &async3_clk,
 	.lpsc		= DA850_LPSC1_McBSP0,
 	.gpsc		= 1,
 };
 
 static struct clk mcbsp1_clk = {
 	.name		= "mcbsp1",
 	.parent		= &async3_clk,
 	.lpsc		= DA850_LPSC1_McBSP1,
 	.gpsc		= 1,
 };
 
 static struct clk lcdc_clk = {
 	.name		= "lcdc",
 	.parent		= &pll0_sysclk2,
 	.lpsc		= DA8XX_LPSC1_LCDC,
 	.gpsc		= 1,
 };
 
 static struct clk mmcsd0_clk = {
 	.name		= "mmcsd0",
 	.parent		= &pll0_sysclk2,
 	.lpsc		= DA8XX_LPSC0_MMC_SD,
 };
 
 static struct clk mmcsd1_clk = {
 	.name		= "mmcsd1",
 	.parent		= &pll0_sysclk2,
 	.lpsc		= DA850_LPSC1_MMC_SD1,
 	.gpsc		= 1,
 };
 
 static struct clk aemif_clk = {
 	.name		= "aemif",
 	.parent		= &pll0_sysclk3,
 	.lpsc		= DA8XX_LPSC0_EMIF25,
 	.flags		= ALWAYS_ENABLED,
 };
 
 /*
  * In order to avoid adding the aemif_clk to the clock lookup table twice (and
  * screwing up the linked list in the process) create a separate clock for
  * nand inheriting the rate from aemif_clk.
  */
 static struct clk aemif_nand_clk = {
 	.name		= "nand",
 	.parent		= &aemif_clk,
 };
 
 static struct clk usb11_clk = {
 	.name		= "usb11",
 	.parent		= &pll0_sysclk4,
 	.lpsc		= DA8XX_LPSC1_USB11,
 	.gpsc		= 1,
 };
 
 static struct clk usb20_clk = {
 	.name		= "usb20",
 	.parent		= &pll0_sysclk2,
 	.lpsc		= DA8XX_LPSC1_USB20,
 	.gpsc		= 1,
 };
 
 static struct clk spi0_clk = {
 	.name		= "spi0",
 	.parent		= &pll0_sysclk2,
 	.lpsc		= DA8XX_LPSC0_SPI0,
 };
 
 static struct clk spi1_clk = {
 	.name		= "spi1",
 	.parent		= &async3_clk,
 	.lpsc		= DA8XX_LPSC1_SPI1,
 	.gpsc		= 1,
 };
 
 static struct clk vpif_clk = {
 	.name		= "vpif",
 	.parent		= &pll0_sysclk2,
 	.lpsc		= DA850_LPSC1_VPIF,
 	.gpsc		= 1,
 };
 
 static struct clk sata_clk = {
 	.name		= "sata",
 	.parent		= &pll0_sysclk2,
 	.lpsc		= DA850_LPSC1_SATA,
 	.gpsc		= 1,
 	.flags		= PSC_FORCE,
 };
 
 static struct clk dsp_clk = {
 	.name		= "dsp",
 	.parent		= &pll0_sysclk1,
 	.domain		= DAVINCI_GPSC_DSPDOMAIN,
 	.lpsc		= DA8XX_LPSC0_GEM,
 	.flags		= PSC_LRST | PSC_FORCE,
 };
 
 static struct clk ehrpwm_clk = {
 	.name		= "ehrpwm",
 	.parent		= &async3_clk,
 	.lpsc		= DA8XX_LPSC1_PWM,
 	.gpsc		= 1,
 };
 
 static struct clk ehrpwm0_clk = {
 	.name		= "ehrpwm0",
 	.parent		= &ehrpwm_clk,
 };
 
 static struct clk ehrpwm1_clk = {
 	.name		= "ehrpwm1",
 	.parent		= &ehrpwm_clk,
 };
 
 #define DA8XX_EHRPWM_TBCLKSYNC	BIT(12)
 
 static void ehrpwm_tblck_enable(struct clk *clk)
 {
 	u32 val;
 
 	val = readl(DA8XX_SYSCFG0_VIRT(DA8XX_CFGCHIP1_REG));
 	val |= DA8XX_EHRPWM_TBCLKSYNC;
 	writel(val, DA8XX_SYSCFG0_VIRT(DA8XX_CFGCHIP1_REG));
 }
 
 static void ehrpwm_tblck_disable(struct clk *clk)
 {
 	u32 val;
 
 	val = readl(DA8XX_SYSCFG0_VIRT(DA8XX_CFGCHIP1_REG));
 	val &= ~DA8XX_EHRPWM_TBCLKSYNC;
 	writel(val, DA8XX_SYSCFG0_VIRT(DA8XX_CFGCHIP1_REG));
 }
 
 static struct clk ehrpwm_tbclk = {
 	.name		= "ehrpwm_tbclk",
 	.parent		= &ehrpwm_clk,
 	.clk_enable	= ehrpwm_tblck_enable,
 	.clk_disable	= ehrpwm_tblck_disable,
 };
 
 static struct clk ehrpwm0_tbclk = {
 	.name		= "ehrpwm0_tbclk",
 	.parent		= &ehrpwm_tbclk,
 };
 
 static struct clk ehrpwm1_tbclk = {
 	.name		= "ehrpwm1_tbclk",
 	.parent		= &ehrpwm_tbclk,
 };
 
 static struct clk ecap_clk = {
 	.name		= "ecap",
 	.parent		= &async3_clk,
 	.lpsc		= DA8XX_LPSC1_ECAP,
 	.gpsc		= 1,
 };
 
 static struct clk ecap0_clk = {
 	.name		= "ecap0_clk",
 	.parent		= &ecap_clk,
 };
 
 static struct clk ecap1_clk = {
 	.name		= "ecap1_clk",
 	.parent		= &ecap_clk,
 };
 
 static struct clk ecap2_clk = {
 	.name		= "ecap2_clk",
 	.parent		= &ecap_clk,
 };
 
 static struct clk_lookup da850_clks[] = {
 	CLK(NULL,		"ref",		&ref_clk),
 	CLK(NULL,		"pll0",		&pll0_clk),
 	CLK(NULL,		"pll0_aux",	&pll0_aux_clk),
 	CLK(NULL,		"pll0_sysclk1",	&pll0_sysclk1),
 	CLK(NULL,		"pll0_sysclk2",	&pll0_sysclk2),
 	CLK(NULL,		"pll0_sysclk3",	&pll0_sysclk3),
 	CLK(NULL,		"pll0_sysclk4",	&pll0_sysclk4),
 	CLK(NULL,		"pll0_sysclk5",	&pll0_sysclk5),
 	CLK(NULL,		"pll0_sysclk6",	&pll0_sysclk6),
 	CLK(NULL,		"pll0_sysclk7",	&pll0_sysclk7),
 	CLK(NULL,		"pll1",		&pll1_clk),
 	CLK(NULL,		"pll1_aux",	&pll1_aux_clk),
 	CLK(NULL,		"pll1_sysclk2",	&pll1_sysclk2),
 	CLK(NULL,		"pll1_sysclk3",	&pll1_sysclk3),
 	CLK(NULL,		"async3",	&async3_clk),
 	CLK("i2c_davinci.1",	NULL,		&i2c0_clk),
 	CLK(NULL,		"timer0",	&timerp64_0_clk),
 	CLK("davinci-wdt",	NULL,		&timerp64_1_clk),
 	CLK(NULL,		"arm_rom",	&arm_rom_clk),
 	CLK(NULL,		"tpcc0",	&tpcc0_clk),
 	CLK(NULL,		"tptc0",	&tptc0_clk),
 	CLK(NULL,		"tptc1",	&tptc1_clk),
 	CLK(NULL,		"tpcc1",	&tpcc1_clk),
 	CLK(NULL,		"tptc2",	&tptc2_clk),
 	CLK("pruss_uio",	"pruss",	&pruss_clk),
 	CLK("serial8250.0",	NULL,		&uart0_clk),
 	CLK("serial8250.1",	NULL,		&uart1_clk),
 	CLK("serial8250.2",	NULL,		&uart2_clk),
 	CLK(NULL,		"aintc",	&aintc_clk),
 	CLK(NULL,		"gpio",		&gpio_clk),
 	CLK("i2c_davinci.2",	NULL,		&i2c1_clk),
 	CLK(NULL,		"emif3",	&emif3_clk),
 	CLK(NULL,		"arm",		&arm_clk),
 	CLK(NULL,		"rmii",		&rmii_clk),
 	CLK("davinci_emac.1",	NULL,		&emac_clk),
 	CLK("davinci_mdio.0",	"fck",		&mdio_clk),
 	CLK("davinci-mcasp.0",	NULL,		&mcasp_clk),
 	CLK("davinci-mcbsp.0",	NULL,		&mcbsp0_clk),
 	CLK("davinci-mcbsp.1",	NULL,		&mcbsp1_clk),
 	CLK("da8xx_lcdc.0",	"fck",		&lcdc_clk),
 	CLK("da830-mmc.0",	NULL,		&mmcsd0_clk),
 	CLK("da830-mmc.1",	NULL,		&mmcsd1_clk),
 	CLK("ti-aemif",		NULL,		&aemif_clk),
-	/*
-	 * The only user of this clock is davinci_nand and it get's it through
-	 * con_id. The nand node itself is created from within the aemif
-	 * driver to guarantee that it's probed after the aemif timing
-	 * parameters are configured. of_dev_auxdata is not accessible from
-	 * the aemif driver and can't be passed to of_platform_populate(). For
-	 * that reason we're leaving the dev_id here as NULL.
-	 */
-	CLK(NULL,		"aemif",	&aemif_nand_clk),
+	CLK("davinci-nand.0",	"aemif",	&aemif_nand_clk),
 	CLK("ohci-da8xx",	"usb11",	&usb11_clk),
 	CLK("musb-da8xx",	"usb20",	&usb20_clk),
 	CLK("spi_davinci.0",	NULL,		&spi0_clk),
 	CLK("spi_davinci.1",	NULL,		&spi1_clk),
 	CLK("vpif",		NULL,		&vpif_clk),
 	CLK("ahci_da850",		NULL,		&sata_clk),
 	CLK("davinci-rproc.0",	NULL,		&dsp_clk),
 	CLK(NULL,		NULL,		&ehrpwm_clk),
 	CLK("ehrpwm.0",		"fck",		&ehrpwm0_clk),
 	CLK("ehrpwm.1",		"fck",		&ehrpwm1_clk),
 	CLK(NULL,		NULL,		&ehrpwm_tbclk),
 	CLK("ehrpwm.0",		"tbclk",	&ehrpwm0_tbclk),
 	CLK("ehrpwm.1",		"tbclk",	&ehrpwm1_tbclk),
 	CLK(NULL,		NULL,		&ecap_clk),
 	CLK("ecap.0",		"fck",		&ecap0_clk),
 	CLK("ecap.1",		"fck",		&ecap1_clk),
 	CLK("ecap.2",		"fck",		&ecap2_clk),
 	CLK(NULL,		NULL,		NULL),
 };
 
 /*
  * Device specific mux setup
  *
  *		soc	description	mux	mode	mode	mux	dbg
  *					reg	offset	mask	mode
  */
 static const struct mux_config da850_pins[] = {
 #ifdef CONFIG_DAVINCI_MUX
 	/* UART0 function */
 	MUX_CFG(DA850, NUART0_CTS,	3,	24,	15,	2,	false)
 	MUX_CFG(DA850, NUART0_RTS,	3,	28,	15,	2,	false)
 	MUX_CFG(DA850, UART0_RXD,	3,	16,	15,	2,	false)
 	MUX_CFG(DA850, UART0_TXD,	3,	20,	15,	2,	false)
 	/* UART1 function */
 	MUX_CFG(DA850, UART1_RXD,	4,	24,	15,	2,	false)
 	MUX_CFG(DA850, UART1_TXD,	4,	28,	15,	2,	false)
 	/* UART2 function */
 	MUX_CFG(DA850, UART2_RXD,	4,	16,	15,	2,	false)
 	MUX_CFG(DA850, UART2_TXD,	4,	20,	15,	2,	false)
 	/* I2C1 function */
 	MUX_CFG(DA850, I2C1_SCL,	4,	16,	15,	4,	false)
 	MUX_CFG(DA850, I2C1_SDA,	4,	20,	15,	4,	false)
 	/* I2C0 function */
 	MUX_CFG(DA850, I2C0_SDA,	4,	12,	15,	2,	false)
 	MUX_CFG(DA850, I2C0_SCL,	4,	8,	15,	2,	false)
 	/* EMAC function */
 	MUX_CFG(DA850, MII_TXEN,	2,	4,	15,	8,	false)
 	MUX_CFG(DA850, MII_TXCLK,	2,	8,	15,	8,	false)
 	MUX_CFG(DA850, MII_COL,		2,	12,	15,	8,	false)
 	MUX_CFG(DA850, MII_TXD_3,	2,	16,	15,	8,	false)
 	MUX_CFG(DA850, MII_TXD_2,	2,	20,	15,	8,	false)
 	MUX_CFG(DA850, MII_TXD_1,	2,	24,	15,	8,	false)
 	MUX_CFG(DA850, MII_TXD_0,	2,	28,	15,	8,	false)
 	MUX_CFG(DA850, MII_RXCLK,	3,	0,	15,	8,	false)
 	MUX_CFG(DA850, MII_RXDV,	3,	4,	15,	8,	false)
 	MUX_CFG(DA850, MII_RXER,	3,	8,	15,	8,	false)
 	MUX_CFG(DA850, MII_CRS,		3,	12,	15,	8,	false)
 	MUX_CFG(DA850, MII_RXD_3,	3,	16,	15,	8,	false)
 	MUX_CFG(DA850, MII_RXD_2,	3,	20,	15,	8,	false)
 	MUX_CFG(DA850, MII_RXD_1,	3,	24,	15,	8,	false)
 	MUX_CFG(DA850, MII_RXD_0,	3,	28,	15,	8,	false)
 	MUX_CFG(DA850, MDIO_CLK,	4,	0,	15,	8,	false)
 	MUX_CFG(DA850, MDIO_D,		4,	4,	15,	8,	false)
 	MUX_CFG(DA850, RMII_TXD_0,	14,	12,	15,	8,	false)
 	MUX_CFG(DA850, RMII_TXD_1,	14,	8,	15,	8,	false)
 	MUX_CFG(DA850, RMII_TXEN,	14,	16,	15,	8,	false)
 	MUX_CFG(DA850, RMII_CRS_DV,	15,	4,	15,	8,	false)
 	MUX_CFG(DA850, RMII_RXD_0,	14,	24,	15,	8,	false)
 	MUX_CFG(DA850, RMII_RXD_1,	14,	20,	15,	8,	false)
 	MUX_CFG(DA850, RMII_RXER,	14,	28,	15,	8,	false)
 	MUX_CFG(DA850, RMII_MHZ_50_CLK,	15,	0,	15,	0,	false)
 	/* McASP function */
 	MUX_CFG(DA850,	ACLKR,		0,	0,	15,	1,	false)
 	MUX_CFG(DA850,	ACLKX,		0,	4,	15,	1,	false)
 	MUX_CFG(DA850,	AFSR,		0,	8,	15,	1,	false)
 	MUX_CFG(DA850,	AFSX,		0,	12,	15,	1,	false)
 	MUX_CFG(DA850,	AHCLKR,		0,	16,	15,	1,	false)
 	MUX_CFG(DA850,	AHCLKX,		0,	20,	15,	1,	false)
 	MUX_CFG(DA850,	AMUTE,		0,	24,	15,	1,	false)
 	MUX_CFG(DA850,	AXR_15,		1,	0,	15,	1,	false)
 	MUX_CFG(DA850,	AXR_14,		1,	4,	15,	1,	false)
 	MUX_CFG(DA850,	AXR_13,		1,	8,	15,	1,	false)
 	MUX_CFG(DA850,	AXR_12,		1,	12,	15,	1,	false)
 	MUX_CFG(DA850,	AXR_11,		1,	16,	15,	1,	false)
 	MUX_CFG(DA850,	AXR_10,		1,	20,	15,	1,	false)
 	MUX_CFG(DA850,	AXR_9,		1,	24,	15,	1,	false)
 	MUX_CFG(DA850,	AXR_8,		1,	28,	15,	1,	false)
 	MUX_CFG(DA850,	AXR_7,		2,	0,	15,	1,	false)
 	MUX_CFG(DA850,	AXR_6,		2,	4,	15,	1,	false)
 	MUX_CFG(DA850,	AXR_5,		2,	8,	15,	1,	false)
 	MUX_CFG(DA850,	AXR_4,		2,	12,	15,	1,	false)
 	MUX_CFG(DA850,	AXR_3,		2,	16,	15,	1,	false)
 	MUX_CFG(DA850,	AXR_2,		2,	20,	15,	1,	false)
 	MUX_CFG(DA850,	AXR_1,		2,	24,	15,	1,	false)
 	MUX_CFG(DA850,	AXR_0,		2,	28,	15,	1,	false)
 	/* LCD function */
 	MUX_CFG(DA850, LCD_D_7,		16,	8,	15,	2,	false)
 	MUX_CFG(DA850, LCD_D_6,		16,	12,	15,	2,	false)
 	MUX_CFG(DA850, LCD_D_5,		16,	16,	15,	2,	false)
 	MUX_CFG(DA850, LCD_D_4,		16,	20,	15,	2,	false)
 	MUX_CFG(DA850, LCD_D_3,		16,	24,	15,	2,	false)
 	MUX_CFG(DA850, LCD_D_2,		16,	28,	15,	2,	false)
 	MUX_CFG(DA850, LCD_D_1,		17,	0,	15,	2,	false)
 	MUX_CFG(DA850, LCD_D_0,		17,	4,	15,	2,	false)
 	MUX_CFG(DA850, LCD_D_15,	17,	8,	15,	2,	false)
 	MUX_CFG(DA850, LCD_D_14,	17,	12,	15,	2,	false)
 	MUX_CFG(DA850, LCD_D_13,	17,	16,	15,	2,	false)
 	MUX_CFG(DA850, LCD_D_12,	17,	20,	15,	2,	false)
 	MUX_CFG(DA850, LCD_D_11,	17,	24,	15,	2,	false)
 	MUX_CFG(DA850, LCD_D_10,	17,	28,	15,	2,	false)
 	MUX_CFG(DA850, LCD_D_9,		18,	0,	15,	2,	false)
 	MUX_CFG(DA850, LCD_D_8,		18,	4,	15,	2,	false)
 	MUX_CFG(DA850, LCD_PCLK,	18,	24,	15,	2,	false)
 	MUX_CFG(DA850, LCD_HSYNC,	19,	0,	15,	2,	false)
 	MUX_CFG(DA850, LCD_VSYNC,	19,	4,	15,	2,	false)
 	MUX_CFG(DA850, NLCD_AC_ENB_CS,	19,	24,	15,	2,	false)
 	/* MMC/SD0 function */
 	MUX_CFG(DA850, MMCSD0_DAT_0,	10,	8,	15,	2,	false)
 	MUX_CFG(DA850, MMCSD0_DAT_1,	10,	12,	15,	2,	false)
 	MUX_CFG(DA850, MMCSD0_DAT_2,	10,	16,	15,	2,	false)
 	MUX_CFG(DA850, MMCSD0_DAT_3,	10,	20,	15,	2,	false)
 	MUX_CFG(DA850, MMCSD0_CLK,	10,	0,	15,	2,	false)
 	MUX_CFG(DA850, MMCSD0_CMD,	10,	4,	15,	2,	false)
 	/* MMC/SD1 function */
 	MUX_CFG(DA850, MMCSD1_DAT_0,	18,	8,	15,	2,	false)
 	MUX_CFG(DA850, MMCSD1_DAT_1,	19,	16,	15,	2,	false)
 	MUX_CFG(DA850, MMCSD1_DAT_2,	19,	12,	15,	2,	false)
 	MUX_CFG(DA850, MMCSD1_DAT_3,	19,	8,	15,	2,	false)
 	MUX_CFG(DA850, MMCSD1_CLK,	18,	12,	15,	2,	false)
 	MUX_CFG(DA850, MMCSD1_CMD,	18,	16,	15,	2,	false)
 	/* EMIF2.5/EMIFA function */
 	MUX_CFG(DA850, EMA_D_7,		9,	0,	15,	1,	false)
 	MUX_CFG(DA850, EMA_D_6,		9,	4,	15,	1,	false)
 	MUX_CFG(DA850, EMA_D_5,		9,	8,	15,	1,	false)
 	MUX_CFG(DA850, EMA_D_4,		9,	12,	15,	1,	false)
 	MUX_CFG(DA850, EMA_D_3,		9,	16,	15,	1,	false)
 	MUX_CFG(DA850, EMA_D_2,		9,	20,	15,	1,	false)
 	MUX_CFG(DA850, EMA_D_1,		9,	24,	15,	1,	false)
 	MUX_CFG(DA850, EMA_D_0,		9,	28,	15,	1,	false)
 	MUX_CFG(DA850, EMA_A_1,		12,	24,	15,	1,	false)
 	MUX_CFG(DA850, EMA_A_2,		12,	20,	15,	1,	false)
 	MUX_CFG(DA850, NEMA_CS_3,	7,	4,	15,	1,	false)
 	MUX_CFG(DA850, NEMA_CS_4,	7,	8,	15,	1,	false)
 	MUX_CFG(DA850, NEMA_WE,		7,	16,	15,	1,	false)
 	MUX_CFG(DA850, NEMA_OE,		7,	20,	15,	1,	false)
 	MUX_CFG(DA850, EMA_A_0,		12,	28,	15,	1,	false)
 	MUX_CFG(DA850, EMA_A_3,		12,	16,	15,	1,	false)
 	MUX_CFG(DA850, EMA_A_4,		12,	12,	15,	1,	false)
 	MUX_CFG(DA850, EMA_A_5,		12,	8,	15,	1,	false)
 	MUX_CFG(DA850, EMA_A_6,		12,	4,	15,	1,	false)
 	MUX_CFG(DA850, EMA_A_7,		12,	0,	15,	1,	false)
 	MUX_CFG(DA850, EMA_A_8,		11,	28,	15,	1,	false)
 	MUX_CFG(DA850, EMA_A_9,		11,	24,	15,	1,	false)
 	MUX_CFG(DA850, EMA_A_10,	11,	20,	15,	1,	false)
 	MUX_CFG(DA850, EMA_A_11,	11,	16,	15,	1,	false)
 	MUX_CFG(DA850, EMA_A_12,	11,	12,	15,	1,	false)
 	MUX_CFG(DA850, EMA_A_13,	11,	8,	15,	1,	false)
 	MUX_CFG(DA850, EMA_A_14,	11,	4,	15,	1,	false)
 	MUX_CFG(DA850, EMA_A_15,	11,	0,	15,	1,	false)
 	MUX_CFG(DA850, EMA_A_16,	10,	28,	15,	1,	false)
 	MUX_CFG(DA850, EMA_A_17,	10,	24,	15,	1,	false)
 	MUX_CFG(DA850, EMA_A_18,	10,	20,	15,	1,	false)
 	MUX_CFG(DA850, EMA_A_19,	10,	16,	15,	1,	false)
 	MUX_CFG(DA850, EMA_A_20,	10,	12,	15,	1,	false)
 	MUX_CFG(DA850, EMA_A_21,	10,	8,	15,	1,	false)
 	MUX_CFG(DA850, EMA_A_22,	10,	4,	15,	1,	false)
 	MUX_CFG(DA850, EMA_A_23,	10,	0,	15,	1,	false)
 	MUX_CFG(DA850, EMA_D_8,		8,	28,	15,	1,	false)
 	MUX_CFG(DA850, EMA_D_9,		8,	24,	15,	1,	false)
 	MUX_CFG(DA850, EMA_D_10,	8,	20,	15,	1,	false)
 	MUX_CFG(DA850, EMA_D_11,	8,	16,	15,	1,	false)
 	MUX_CFG(DA850, EMA_D_12,	8,	12,	15,	1,	false)
 	MUX_CFG(DA850, EMA_D_13,	8,	8,	15,	1,	false)
 	MUX_CFG(DA850, EMA_D_14,	8,	4,	15,	1,	false)
 	MUX_CFG(DA850, EMA_D_15,	8,	0,	15,	1,	false)
 	MUX_CFG(DA850, EMA_BA_1,	5,	24,	15,	1,	false)
 	MUX_CFG(DA850, EMA_CLK,		6,	0,	15,	1,	false)
 	MUX_CFG(DA850, EMA_WAIT_1,	6,	24,	15,	1,	false)
 	MUX_CFG(DA850, NEMA_CS_2,	7,	0,	15,	1,	false)
 	/* GPIO function */
 	MUX_CFG(DA850, GPIO2_4,		6,	12,	15,	8,	false)
 	MUX_CFG(DA850, GPIO2_6,		6,	4,	15,	8,	false)
 	MUX_CFG(DA850, GPIO2_8,		5,	28,	15,	8,	false)
 	MUX_CFG(DA850, GPIO2_15,	5,	0,	15,	8,	false)
 	MUX_CFG(DA850, GPIO3_12,	7,	12,	15,	8,	false)
 	MUX_CFG(DA850, GPIO3_13,	7,	8,	15,	8,	false)
 	MUX_CFG(DA850, GPIO4_0,		10,	28,	15,	8,	false)
 	MUX_CFG(DA850, GPIO4_1,		10,	24,	15,	8,	false)
 	MUX_CFG(DA850, GPIO6_9,		13,	24,	15,	8,	false)
 	MUX_CFG(DA850, GPIO6_10,	13,	20,	15,	8,	false)
 	MUX_CFG(DA850, GPIO6_13,	13,	8,	15,	8,	false)
 	MUX_CFG(DA850, RTC_ALARM,	0,	28,	15,	2,	false)
 	/* VPIF Capture */
 	MUX_CFG(DA850, VPIF_DIN0,	15,	4,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_DIN1,	15,	0,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_DIN2,	14,	28,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_DIN3,	14,	24,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_DIN4,	14,	20,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_DIN5,	14,	16,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_DIN6,	14,	12,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_DIN7,	14,	8,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_DIN8,	16,	4,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_DIN9,	16,	0,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_DIN10,	15,	28,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_DIN11,	15,	24,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_DIN12,	15,	20,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_DIN13,	15,	16,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_DIN14,	15,	12,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_DIN15,	15,	8,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_CLKIN0,	14,	0,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_CLKIN1,	14,	4,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_CLKIN2,	19,	8,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_CLKIN3,	19,	16,	15,	1,	false)
 	/* VPIF Display */
 	MUX_CFG(DA850, VPIF_DOUT0,	17,	4,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_DOUT1,	17,	0,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_DOUT2,	16,	28,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_DOUT3,	16,	24,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_DOUT4,	16,	20,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_DOUT5,	16,	16,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_DOUT6,	16,	12,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_DOUT7,	16,	8,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_DOUT8,	18,	4,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_DOUT9,	18,	0,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_DOUT10,	17,	28,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_DOUT11,	17,	24,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_DOUT12,	17,	20,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_DOUT13,	17,	16,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_DOUT14,	17,	12,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_DOUT15,	17,	8,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_CLKO2,	19,	12,	15,	1,	false)
 	MUX_CFG(DA850, VPIF_CLKO3,	19,	20,	15,	1,	false)
 #endif
 };
 
 const short da850_i2c0_pins[] __initconst = {
 	DA850_I2C0_SDA, DA850_I2C0_SCL,
 	-1
 };
 
 const short da850_i2c1_pins[] __initconst = {
 	DA850_I2C1_SCL, DA850_I2C1_SDA,
 	-1
 };
 
 const short da850_lcdcntl_pins[] __initconst = {
 	DA850_LCD_D_0, DA850_LCD_D_1, DA850_LCD_D_2, DA850_LCD_D_3,
 	DA850_LCD_D_4, DA850_LCD_D_5, DA850_LCD_D_6, DA850_LCD_D_7,
 	DA850_LCD_D_8, DA850_LCD_D_9, DA850_LCD_D_10, DA850_LCD_D_11,
 	DA850_LCD_D_12, DA850_LCD_D_13, DA850_LCD_D_14, DA850_LCD_D_15,
 	DA850_LCD_PCLK, DA850_LCD_HSYNC, DA850_LCD_VSYNC, DA850_NLCD_AC_ENB_CS,
 	-1
 };
 
 const short da850_vpif_capture_pins[] __initconst = {
 	DA850_VPIF_DIN0, DA850_VPIF_DIN1, DA850_VPIF_DIN2, DA850_VPIF_DIN3,
 	DA850_VPIF_DIN4, DA850_VPIF_DIN5, DA850_VPIF_DIN6, DA850_VPIF_DIN7,
 	DA850_VPIF_DIN8, DA850_VPIF_DIN9, DA850_VPIF_DIN10, DA850_VPIF_DIN11,
 	DA850_VPIF_DIN12, DA850_VPIF_DIN13, DA850_VPIF_DIN14, DA850_VPIF_DIN15,
 	DA850_VPIF_CLKIN0, DA850_VPIF_CLKIN1, DA850_VPIF_CLKIN2,
 	DA850_VPIF_CLKIN3,
 	-1
 };
 
 const short da850_vpif_display_pins[] __initconst = {
 	DA850_VPIF_DOUT0, DA850_VPIF_DOUT1, DA850_VPIF_DOUT2, DA850_VPIF_DOUT3,
 	DA850_VPIF_DOUT4, DA850_VPIF_DOUT5, DA850_VPIF_DOUT6, DA850_VPIF_DOUT7,
 	DA850_VPIF_DOUT8, DA850_VPIF_DOUT9, DA850_VPIF_DOUT10,
 	DA850_VPIF_DOUT11, DA850_VPIF_DOUT12, DA850_VPIF_DOUT13,
 	DA850_VPIF_DOUT14, DA850_VPIF_DOUT15, DA850_VPIF_CLKO2,
 	DA850_VPIF_CLKO3,
 	-1
 };
 
 /* FIQ are pri 0-1; otherwise 2-7, with 7 lowest priority */
 static u8 da850_default_priorities[DA850_N_CP_INTC_IRQ] = {
 	[IRQ_DA8XX_COMMTX]		= 7,
 	[IRQ_DA8XX_COMMRX]		= 7,
 	[IRQ_DA8XX_NINT]		= 7,
 	[IRQ_DA8XX_EVTOUT0]		= 7,
 	[IRQ_DA8XX_EVTOUT1]		= 7,
 	[IRQ_DA8XX_EVTOUT2]		= 7,
 	[IRQ_DA8XX_EVTOUT3]		= 7,
 	[IRQ_DA8XX_EVTOUT4]		= 7,
 	[IRQ_DA8XX_EVTOUT5]		= 7,
 	[IRQ_DA8XX_EVTOUT6]		= 7,
 	[IRQ_DA8XX_EVTOUT7]		= 7,
 	[IRQ_DA8XX_CCINT0]		= 7,
 	[IRQ_DA8XX_CCERRINT]		= 7,
 	[IRQ_DA8XX_TCERRINT0]		= 7,
 	[IRQ_DA8XX_AEMIFINT]		= 7,
 	[IRQ_DA8XX_I2CINT0]		= 7,
 	[IRQ_DA8XX_MMCSDINT0]		= 7,
 	[IRQ_DA8XX_MMCSDINT1]		= 7,
 	[IRQ_DA8XX_ALLINT0]		= 7,
 	[IRQ_DA8XX_RTC]			= 7,
 	[IRQ_DA8XX_SPINT0]		= 7,
 	[IRQ_DA8XX_TINT12_0]		= 7,
 	[IRQ_DA8XX_TINT34_0]		= 7,
 	[IRQ_DA8XX_TINT12_1]		= 7,
 	[IRQ_DA8XX_TINT34_1]		= 7,
 	[IRQ_DA8XX_UARTINT0]		= 7,
 	[IRQ_DA8XX_KEYMGRINT]		= 7,
 	[IRQ_DA850_MPUADDRERR0]		= 7,
 	[IRQ_DA8XX_CHIPINT0]		= 7,
 	[IRQ_DA8XX_CHIPINT1]		= 7,
 	[IRQ_DA8XX_CHIPINT2]		= 7,
 	[IRQ_DA8XX_CHIPINT3]		= 7,
 	[IRQ_DA8XX_TCERRINT1]		= 7,
 	[IRQ_DA8XX_C0_RX_THRESH_PULSE]	= 7,
 	[IRQ_DA8XX_C0_RX_PULSE]		= 7,
 	[IRQ_DA8XX_C0_TX_PULSE]		= 7,
 	[IRQ_DA8XX_C0_MISC_PULSE]	= 7,
 	[IRQ_DA8XX_C1_RX_THRESH_PULSE]	= 7,
 	[IRQ_DA8XX_C1_RX_PULSE]		= 7,
 	[IRQ_DA8XX_C1_TX_PULSE]		= 7,
 	[IRQ_DA8XX_C1_MISC_PULSE]	= 7,
 	[IRQ_DA8XX_MEMERR]		= 7,
 	[IRQ_DA8XX_GPIO0]		= 7,
 	[IRQ_DA8XX_GPIO1]		= 7,
 	[IRQ_DA8XX_GPIO2]		= 7,
 	[IRQ_DA8XX_GPIO3]		= 7,
 	[IRQ_DA8XX_GPIO4]		= 7,
 	[IRQ_DA8XX_GPIO5]		= 7,
 	[IRQ_DA8XX_GPIO6]		= 7,
 	[IRQ_DA8XX_GPIO7]		= 7,
 	[IRQ_DA8XX_GPIO8]		= 7,
 	[IRQ_DA8XX_I2CINT1]		= 7,
 	[IRQ_DA8XX_LCDINT]		= 7,
 	[IRQ_DA8XX_UARTINT1]		= 7,
 	[IRQ_DA8XX_MCASPINT]		= 7,
 	[IRQ_DA8XX_ALLINT1]		= 7,
 	[IRQ_DA8XX_SPINT1]		= 7,
 	[IRQ_DA8XX_UHPI_INT1]		= 7,
 	[IRQ_DA8XX_USB_INT]		= 7,
 	[IRQ_DA8XX_IRQN]		= 7,
 	[IRQ_DA8XX_RWAKEUP]		= 7,
 	[IRQ_DA8XX_UARTINT2]		= 7,
 	[IRQ_DA8XX_DFTSSINT]		= 7,
 	[IRQ_DA8XX_EHRPWM0]		= 7,
 	[IRQ_DA8XX_EHRPWM0TZ]		= 7,
 	[IRQ_DA8XX_EHRPWM1]		= 7,
 	[IRQ_DA8XX_EHRPWM1TZ]		= 7,
 	[IRQ_DA850_SATAINT]		= 7,
 	[IRQ_DA850_TINTALL_2]		= 7,
 	[IRQ_DA8XX_ECAP0]		= 7,
 	[IRQ_DA8XX_ECAP1]		= 7,
 	[IRQ_DA8XX_ECAP2]		= 7,
 	[IRQ_DA850_MMCSDINT0_1]		= 7,
 	[IRQ_DA850_MMCSDINT1_1]		= 7,
 	[IRQ_DA850_T12CMPINT0_2]	= 7,
 	[IRQ_DA850_T12CMPINT1_2]	= 7,
 	[IRQ_DA850_T12CMPINT2_2]	= 7,
 	[IRQ_DA850_T12CMPINT3_2]	= 7,
 	[IRQ_DA850_T12CMPINT4_2]	= 7,
 	[IRQ_DA850_T12CMPINT5_2]	= 7,
 	[IRQ_DA850_T12CMPINT6_2]	= 7,
 	[IRQ_DA850_T12CMPINT7_2]	= 7,
 	[IRQ_DA850_T12CMPINT0_3]	= 7,
 	[IRQ_DA850_T12CMPINT1_3]	= 7,
 	[IRQ_DA850_T12CMPINT2_3]	= 7,
 	[IRQ_DA850_T12CMPINT3_3]	= 7,
 	[IRQ_DA850_T12CMPINT4_3]	= 7,
 	[IRQ_DA850_T12CMPINT5_3]	= 7,
 	[IRQ_DA850_T12CMPINT6_3]	= 7,
 	[IRQ_DA850_T12CMPINT7_3]	= 7,
 	[IRQ_DA850_RPIINT]		= 7,
 	[IRQ_DA850_VPIFINT]		= 7,
 	[IRQ_DA850_CCINT1]		= 7,
 	[IRQ_DA850_CCERRINT1]		= 7,
 	[IRQ_DA850_TCERRINT2]		= 7,
 	[IRQ_DA850_TINTALL_3]		= 7,
 	[IRQ_DA850_MCBSP0RINT]		= 7,
 	[IRQ_DA850_MCBSP0XINT]		= 7,
 	[IRQ_DA850_MCBSP1RINT]		= 7,
 	[IRQ_DA850_MCBSP1XINT]		= 7,
 	[IRQ_DA8XX_ARMCLKSTOPREQ]	= 7,
 };
 
 static struct map_desc da850_io_desc[] = {
 	{
 		.virtual	= IO_VIRT,
 		.pfn		= __phys_to_pfn(IO_PHYS),
 		.length		= IO_SIZE,
 		.type		= MT_DEVICE
 	},
 	{
 		.virtual	= DA8XX_CP_INTC_VIRT,
 		.pfn		= __phys_to_pfn(DA8XX_CP_INTC_BASE),
 		.length		= DA8XX_CP_INTC_SIZE,
 		.type		= MT_DEVICE
 	},
 };
 
 static u32 da850_psc_bases[] = { DA8XX_PSC0_BASE, DA8XX_PSC1_BASE };
 
 /* Contents of JTAG ID register used to identify exact cpu type */
 static struct davinci_id da850_ids[] = {
 	{
 		.variant	= 0x0,
 		.part_no	= 0xb7d1,
 		.manufacturer	= 0x017,	/* 0x02f >> 1 */
 		.cpu_id		= DAVINCI_CPU_ID_DA850,
 		.name		= "da850/omap-l138",
 	},
 	{
 		.variant	= 0x1,
 		.part_no	= 0xb7d1,
 		.manufacturer	= 0x017,	/* 0x02f >> 1 */
 		.cpu_id		= DAVINCI_CPU_ID_DA850,
 		.name		= "da850/omap-l138/am18x",
 	},
 };
 
 static struct davinci_timer_instance da850_timer_instance[4] = {
 	{
 		.base		= DA8XX_TIMER64P0_BASE,
 		.bottom_irq	= IRQ_DA8XX_TINT12_0,
 		.top_irq	= IRQ_DA8XX_TINT34_0,
 	},
 	{
 		.base		= DA8XX_TIMER64P1_BASE,
 		.bottom_irq	= IRQ_DA8XX_TINT12_1,
 		.top_irq	= IRQ_DA8XX_TINT34_1,
 	},
 	{
 		.base		= DA850_TIMER64P2_BASE,
 		.bottom_irq	= IRQ_DA850_TINT12_2,
 		.top_irq	= IRQ_DA850_TINT34_2,
 	},
 	{
 		.base		= DA850_TIMER64P3_BASE,
 		.bottom_irq	= IRQ_DA850_TINT12_3,
 		.top_irq	= IRQ_DA850_TINT34_3,
 	},
 };
 
 /*
  * T0_BOT: Timer 0, bottom		: Used for clock_event
  * T0_TOP: Timer 0, top			: Used for clocksource
  * T1_BOT, T1_TOP: Timer 1, bottom & top: Used for watchdog timer
  */
 static struct davinci_timer_info da850_timer_info = {
 	.timers		= da850_timer_instance,
 	.clockevent_id	= T0_BOT,
 	.clocksource_id	= T0_TOP,
 };
 
 #ifdef CONFIG_CPU_FREQ
 /*
  * Notes:
  * According to the TRM, minimum PLLM results in maximum power savings.
  * The OPP definitions below should keep the PLLM as low as possible.
  *
  * The output of the PLLM must be between 300 to 600 MHz.
  */
 struct da850_opp {
 	unsigned int	freq;	/* in KHz */
 	unsigned int	prediv;
 	unsigned int	mult;
 	unsigned int	postdiv;
 	unsigned int	cvdd_min; /* in uV */
 	unsigned int	cvdd_max; /* in uV */
 };
 
 static const struct da850_opp da850_opp_456 = {
 	.freq		= 456000,
 	.prediv		= 1,
 	.mult		= 19,
 	.postdiv	= 1,
 	.cvdd_min	= 1300000,
 	.cvdd_max	= 1350000,
 };
 
 static const struct da850_opp da850_opp_408 = {
 	.freq		= 408000,
 	.prediv		= 1,
 	.mult		= 17,
 	.postdiv	= 1,
 	.cvdd_min	= 1300000,
 	.cvdd_max	= 1350000,
 };
 
 static const struct da850_opp da850_opp_372 = {
 	.freq		= 372000,
 	.prediv		= 2,
 	.mult		= 31,
 	.postdiv	= 1,
 	.cvdd_min	= 1200000,
 	.cvdd_max	= 1320000,
 };
 
 static const struct da850_opp da850_opp_300 = {
 	.freq		= 300000,
 	.prediv		= 1,
 	.mult		= 25,
 	.postdiv	= 2,
 	.cvdd_min	= 1200000,
 	.cvdd_max	= 1320000,
 };
 
 static const struct da850_opp da850_opp_200 = {
 	.freq		= 200000,
 	.prediv		= 1,
 	.mult		= 25,
 	.postdiv	= 3,
 	.cvdd_min	= 1100000,
 	.cvdd_max	= 1160000,
 };
 
 static const struct da850_opp da850_opp_96 = {
 	.freq		= 96000,
 	.prediv		= 1,
 	.mult		= 20,
 	.postdiv	= 5,
 	.cvdd_min	= 1000000,
 	.cvdd_max	= 1050000,
 };
 
 #define OPP(freq) 		\
 	{				\
 		.driver_data = (unsigned int) &da850_opp_##freq,	\
 		.frequency = freq * 1000, \
 	}
 
 static struct cpufreq_frequency_table da850_freq_table[] = {
 	OPP(456),
 	OPP(408),
 	OPP(372),
 	OPP(300),
 	OPP(200),
 	OPP(96),
 	{
 		.driver_data		= 0,
 		.frequency	= CPUFREQ_TABLE_END,
 	},
 };
 
 #ifdef CONFIG_REGULATOR
 static int da850_set_voltage(unsigned int index);
 static int da850_regulator_init(void);
 #endif
 
 static struct davinci_cpufreq_config cpufreq_info = {
 	.freq_table = da850_freq_table,
 #ifdef CONFIG_REGULATOR
 	.init = da850_regulator_init,
 	.set_voltage = da850_set_voltage,
 #endif
 };
 
 #ifdef CONFIG_REGULATOR
 static struct regulator *cvdd;
 
 static int da850_set_voltage(unsigned int index)
 {
 	struct da850_opp *opp;
 
 	if (!cvdd)
 		return -ENODEV;
 
 	opp = (struct da850_opp *) cpufreq_info.freq_table[index].driver_data;
 
 	return regulator_set_voltage(cvdd, opp->cvdd_min, opp->cvdd_max);
 }
 
 static int da850_regulator_init(void)
 {
 	cvdd = regulator_get(NULL, "cvdd");
 	if (WARN(IS_ERR(cvdd), "Unable to obtain voltage regulator for CVDD;"
 					" voltage scaling unsupported\n")) {
 		return PTR_ERR(cvdd);
 	}
 
 	return 0;
 }
 #endif
 
 static struct platform_device da850_cpufreq_device = {
 	.name			= "cpufreq-davinci",
 	.dev = {
 		.platform_data	= &cpufreq_info,
 	},
 	.id = -1,
 };
 
 unsigned int da850_max_speed = 300000;
 
 int da850_register_cpufreq(char *async_clk)
 {
 	int i;
 
 	/* cpufreq driver can help keep an "async" clock constant */
 	if (async_clk)
 		clk_add_alias("async", da850_cpufreq_device.name,
 							async_clk, NULL);
 	for (i = 0; i < ARRAY_SIZE(da850_freq_table); i++) {
 		if (da850_freq_table[i].frequency <= da850_max_speed) {
 			cpufreq_info.freq_table = &da850_freq_table[i];
 			break;
 		}
 	}
 
 	return platform_device_register(&da850_cpufreq_device);
 }
 
 static int da850_round_armrate(struct clk *clk, unsigned long rate)
 {
 	int ret = 0, diff;
 	unsigned int best = (unsigned int) -1;
 	struct cpufreq_frequency_table *table = cpufreq_info.freq_table;
 	struct cpufreq_frequency_table *pos;
 
 	rate /= 1000; /* convert to kHz */
 
 	cpufreq_for_each_entry(pos, table) {
 		diff = pos->frequency - rate;
 		if (diff < 0)
 			diff = -diff;
 
 		if (diff < best) {
 			best = diff;
 			ret = pos->frequency;
 		}
 	}
 
 	return ret * 1000;
 }
 
 static int da850_set_armrate(struct clk *clk, unsigned long index)
 {
 	struct clk *pllclk = &pll0_clk;
 
 	return clk_set_rate(pllclk, index);
 }
 
 static int da850_set_pll0rate(struct clk *clk, unsigned long index)
 {
 	unsigned int prediv, mult, postdiv;
 	struct da850_opp *opp;
 	struct pll_data *pll = clk->pll_data;
 	int ret;
 
 	opp = (struct da850_opp *) cpufreq_info.freq_table[index].driver_data;
 	prediv = opp->prediv;
 	mult = opp->mult;
 	postdiv = opp->postdiv;
 
 	ret = davinci_set_pllrate(pll, prediv, mult, postdiv);
 	if (WARN_ON(ret))
 		return ret;
 
 	return 0;
 }
 #else
 int __init da850_register_cpufreq(char *async_clk)
 {
 	return 0;
 }
 
 static int da850_set_armrate(struct clk *clk, unsigned long rate)
 {
 	return -EINVAL;
 }
 
 static int da850_set_pll0rate(struct clk *clk, unsigned long armrate)
 {
 	return -EINVAL;
 }
 
 static int da850_round_armrate(struct clk *clk, unsigned long rate)
 {
 	return clk->rate;
 }
 #endif
 
 /* VPIF resource, platform data */
 static u64 da850_vpif_dma_mask = DMA_BIT_MASK(32);
 
 static struct resource da850_vpif_resource[] = {
 	{
 		.start = DA8XX_VPIF_BASE,
 		.end   = DA8XX_VPIF_BASE + 0xfff,
 		.flags = IORESOURCE_MEM,
 	}
 };
 
 static struct platform_device da850_vpif_dev = {
 	.name		= "vpif",
 	.id		= -1,
 	.dev		= {
 		.dma_mask		= &da850_vpif_dma_mask,
 		.coherent_dma_mask	= DMA_BIT_MASK(32),
 	},
 	.resource	= da850_vpif_resource,
 	.num_resources	= ARRAY_SIZE(da850_vpif_resource),
 };
 
 static struct resource da850_vpif_display_resource[] = {
 	{
 		.start = IRQ_DA850_VPIFINT,
 		.end   = IRQ_DA850_VPIFINT,
 		.flags = IORESOURCE_IRQ,
 	},
 };
 
 static struct platform_device da850_vpif_display_dev = {
 	.name		= "vpif_display",
 	.id		= -1,
 	.dev		= {
 		.dma_mask		= &da850_vpif_dma_mask,
 		.coherent_dma_mask	= DMA_BIT_MASK(32),
 	},
 	.resource       = da850_vpif_display_resource,
 	.num_resources  = ARRAY_SIZE(da850_vpif_display_resource),
 };
 
 static struct resource da850_vpif_capture_resource[] = {
 	{
 		.start = IRQ_DA850_VPIFINT,
 		.end   = IRQ_DA850_VPIFINT,
 		.flags = IORESOURCE_IRQ,
 	},
 	{
 		.start = IRQ_DA850_VPIFINT,
 		.end   = IRQ_DA850_VPIFINT,
 		.flags = IORESOURCE_IRQ,
 	},
 };
 
 static struct platform_device da850_vpif_capture_dev = {
 	.name		= "vpif_capture",
 	.id		= -1,
 	.dev		= {
 		.dma_mask		= &da850_vpif_dma_mask,
 		.coherent_dma_mask	= DMA_BIT_MASK(32),
 	},
 	.resource       = da850_vpif_capture_resource,
 	.num_resources  = ARRAY_SIZE(da850_vpif_capture_resource),
 };
 
 int __init da850_register_vpif(void)
 {
 	return platform_device_register(&da850_vpif_dev);
 }
 
 int __init da850_register_vpif_display(struct vpif_display_config
 						*display_config)
 {
 	da850_vpif_display_dev.dev.platform_data = display_config;
 	return platform_device_register(&da850_vpif_display_dev);
 }
 
 int __init da850_register_vpif_capture(struct vpif_capture_config
 							*capture_config)
 {
 	da850_vpif_capture_dev.dev.platform_data = capture_config;
 	return platform_device_register(&da850_vpif_capture_dev);
 }
 
 static struct davinci_gpio_platform_data da850_gpio_platform_data = {
 	.ngpio = 144,
 };
 
 int __init da850_register_gpio(void)
 {
 	return da8xx_register_gpio(&da850_gpio_platform_data);
 }
 
 static struct davinci_soc_info davinci_soc_info_da850 = {
 	.io_desc		= da850_io_desc,
 	.io_desc_num		= ARRAY_SIZE(da850_io_desc),
 	.jtag_id_reg		= DA8XX_SYSCFG0_BASE + DA8XX_JTAG_ID_REG,
 	.ids			= da850_ids,
 	.ids_num		= ARRAY_SIZE(da850_ids),
 	.cpu_clks		= da850_clks,
 	.psc_bases		= da850_psc_bases,
 	.psc_bases_num		= ARRAY_SIZE(da850_psc_bases),
 	.pinmux_base		= DA8XX_SYSCFG0_BASE + 0x120,
 	.pinmux_pins		= da850_pins,
 	.pinmux_pins_num	= ARRAY_SIZE(da850_pins),
 	.intc_base		= DA8XX_CP_INTC_BASE,
 	.intc_type		= DAVINCI_INTC_TYPE_CP_INTC,
 	.intc_irq_prios		= da850_default_priorities,
 	.intc_irq_num		= DA850_N_CP_INTC_IRQ,
 	.timer_info		= &da850_timer_info,
 	.emac_pdata		= &da8xx_emac_pdata,
 	.sram_dma		= DA8XX_SHARED_RAM_BASE,
 	.sram_len		= SZ_128K,
 };
 
 void __init da850_init(void)
 {
 	unsigned int v;
 
 	davinci_common_init(&davinci_soc_info_da850);
 
 	da8xx_syscfg0_base = ioremap(DA8XX_SYSCFG0_BASE, SZ_4K);
 	if (WARN(!da8xx_syscfg0_base, "Unable to map syscfg0 module"))
 		return;
 
 	da8xx_syscfg1_base = ioremap(DA8XX_SYSCFG1_BASE, SZ_4K);
 	if (WARN(!da8xx_syscfg1_base, "Unable to map syscfg1 module"))
 		return;
 
 	/* Unlock writing to PLL0 registers */
 	v = __raw_readl(DA8XX_SYSCFG0_VIRT(DA8XX_CFGCHIP0_REG));
 	v &= ~CFGCHIP0_PLL_MASTER_LOCK;
 	__raw_writel(v, DA8XX_SYSCFG0_VIRT(DA8XX_CFGCHIP0_REG));
 
 	/* Unlock writing to PLL1 registers */
 	v = __raw_readl(DA8XX_SYSCFG0_VIRT(DA8XX_CFGCHIP3_REG));
 	v &= ~CFGCHIP3_PLL1_MASTER_LOCK;
 	__raw_writel(v, DA8XX_SYSCFG0_VIRT(DA8XX_CFGCHIP3_REG));
 
 	davinci_clk_init(davinci_soc_info_da850.cpu_clks);
 }
diff --git a/arch/arm/mach-davinci/da8xx-dt.c b/arch/arm/mach-davinci/da8xx-dt.c
index 9ee44da6eb7b..06205fe4c120 100644
--- a/arch/arm/mach-davinci/da8xx-dt.c
+++ b/arch/arm/mach-davinci/da8xx-dt.c
@@ -1,84 +1,94 @@
 /*
  * Copyright (C) 2012 Texas Instruments Incorporated - http://www.ti.com/
  *
  * Modified from mach-omap/omap2/board-generic.c
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License version 2 as
  * published by the Free Software Foundation.
  */
 #include <linux/io.h>
 #include <linux/of_irq.h>
 #include <linux/of_platform.h>
 #include <linux/irqdomain.h>
+#include <linux/platform_data/ti-aemif.h>
 
 #include <asm/mach/arch.h>
 
 #include <mach/common.h>
 #include "cp_intc.h"
 #include <mach/da8xx.h>
 
+static struct of_dev_auxdata da850_aemif_auxdata_lookup[] = {
+	OF_DEV_AUXDATA("ti,davinci-nand", 0x62000000, "davinci-nand.0", NULL),
+	{}
+};
+
+static struct aemif_platform_data aemif_data = {
+	.dev_lookup = da850_aemif_auxdata_lookup,
+};
+
 static struct of_dev_auxdata da850_auxdata_lookup[] __initdata = {
 	OF_DEV_AUXDATA("ti,davinci-i2c", 0x01c22000, "i2c_davinci.1", NULL),
 	OF_DEV_AUXDATA("ti,davinci-i2c", 0x01e28000, "i2c_davinci.2", NULL),
 	OF_DEV_AUXDATA("ti,davinci-wdt", 0x01c21000, "davinci-wdt", NULL),
 	OF_DEV_AUXDATA("ti,da830-mmc", 0x01c40000, "da830-mmc.0", NULL),
 	OF_DEV_AUXDATA("ti,da850-ehrpwm", 0x01f00000, "ehrpwm.0", NULL),
 	OF_DEV_AUXDATA("ti,da850-ehrpwm", 0x01f02000, "ehrpwm.1", NULL),
 	OF_DEV_AUXDATA("ti,da850-ecap", 0x01f06000, "ecap.0", NULL),
 	OF_DEV_AUXDATA("ti,da850-ecap", 0x01f07000, "ecap.1", NULL),
 	OF_DEV_AUXDATA("ti,da850-ecap", 0x01f08000, "ecap.2", NULL),
 	OF_DEV_AUXDATA("ti,da830-spi", 0x01c41000, "spi_davinci.0", NULL),
 	OF_DEV_AUXDATA("ti,da830-spi", 0x01f0e000, "spi_davinci.1", NULL),
 	OF_DEV_AUXDATA("ns16550a", 0x01c42000, "serial8250.0", NULL),
 	OF_DEV_AUXDATA("ns16550a", 0x01d0c000, "serial8250.1", NULL),
 	OF_DEV_AUXDATA("ns16550a", 0x01d0d000, "serial8250.2", NULL),
 	OF_DEV_AUXDATA("ti,davinci_mdio", 0x01e24000, "davinci_mdio.0", NULL),
 	OF_DEV_AUXDATA("ti,davinci-dm6467-emac", 0x01e20000, "davinci_emac.1",
 		       NULL),
 	OF_DEV_AUXDATA("ti,da830-mcasp-audio", 0x01d00000, "davinci-mcasp.0", NULL),
-	OF_DEV_AUXDATA("ti,da850-aemif", 0x68000000, "ti-aemif", NULL),
+	OF_DEV_AUXDATA("ti,da850-aemif", 0x68000000, "ti-aemif", &aemif_data),
 	OF_DEV_AUXDATA("ti,da850-tilcdc", 0x01e13000, "da8xx_lcdc.0", NULL),
 	OF_DEV_AUXDATA("ti,da830-ohci", 0x01e25000, "ohci-da8xx", NULL),
 	OF_DEV_AUXDATA("ti,da830-musb", 0x01e00000, "musb-da8xx", NULL),
 	OF_DEV_AUXDATA("ti,da830-usb-phy", 0x01c1417c, "da8xx-usb-phy", NULL),
 	{}
 };
 
 #ifdef CONFIG_ARCH_DAVINCI_DA850
 
 static void __init da850_init_machine(void)
 {
 	int ret;
 
 	ret = da8xx_register_usb20_phy_clk(false);
 	if (ret)
 		pr_warn("%s: registering USB 2.0 PHY clock failed: %d",
 			__func__, ret);
 	ret = da8xx_register_usb11_phy_clk(false);
 	if (ret)
 		pr_warn("%s: registering USB 1.1 PHY clock failed: %d",
 			__func__, ret);
 
 	of_platform_default_populate(NULL, da850_auxdata_lookup, NULL);
 	davinci_pm_init();
 }
 
 static const char *const da850_boards_compat[] __initconst = {
 	"enbw,cmc",
 	"ti,da850-lcdk",
 	"ti,da850-evm",
 	"ti,da850",
 	NULL,
 };
 
 DT_MACHINE_START(DA850_DT, "Generic DA850/OMAP-L138/AM18x")
 	.map_io		= da850_init,
 	.init_time	= davinci_timer_init,
 	.init_machine	= da850_init_machine,
 	.dt_compat	= da850_boards_compat,
 	.init_late	= davinci_init_late,
 	.restart	= da8xx_restart,
 MACHINE_END
 
 #endif
diff --git a/arch/x86/Kbuild b/arch/x86/Kbuild
index eb3abf8ac44e..586b786b3edf 100644
--- a/arch/x86/Kbuild
+++ b/arch/x86/Kbuild
@@ -1,24 +1,27 @@
 obj-y += entry/
 
 obj-$(CONFIG_PERF_EVENTS) += events/
 
 obj-$(CONFIG_KVM) += kvm/
 
 # Xen paravirtualization support
 obj-$(CONFIG_XEN) += xen/
 
+# Hyper-V paravirtualization support
+obj-$(CONFIG_HYPERVISOR_GUEST) += hyperv/
+
 # lguest paravirtualization support
 obj-$(CONFIG_LGUEST_GUEST) += lguest/
 
 obj-y += realmode/
 obj-y += kernel/
 obj-y += mm/
 
 obj-y += crypto/
 
 obj-$(CONFIG_IA32_EMULATION) += ia32/
 
 obj-y += platform/
 obj-y += net/
 
 obj-$(CONFIG_KEXEC_FILE) += purgatory/
diff --git a/arch/x86/hyperv/Makefile b/arch/x86/hyperv/Makefile
new file mode 100644
index 000000000000..171ae09864d7
--- /dev/null
+++ b/arch/x86/hyperv/Makefile
@@ -0,0 +1 @@
+obj-y		:= hv_init.o
diff --git a/arch/x86/hyperv/hv_init.c b/arch/x86/hyperv/hv_init.c
new file mode 100644
index 000000000000..db64baf0e500
--- /dev/null
+++ b/arch/x86/hyperv/hv_init.c
@@ -0,0 +1,277 @@
+/*
+ * X86 specific Hyper-V initialization code.
+ *
+ * Copyright (C) 2016, Microsoft, Inc.
+ *
+ * Author : K. Y. Srinivasan <kys@microsoft.com>
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 as published
+ * by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, GOOD TITLE or
+ * NON INFRINGEMENT.  See the GNU General Public License for more
+ * details.
+ *
+ */
+
+#include <linux/types.h>
+#include <asm/hypervisor.h>
+#include <asm/hyperv.h>
+#include <asm/mshyperv.h>
+#include <linux/version.h>
+#include <linux/vmalloc.h>
+#include <linux/mm.h>
+#include <linux/clockchips.h>
+
+
+#ifdef CONFIG_X86_64
+
+static struct ms_hyperv_tsc_page *tsc_pg;
+
+static u64 read_hv_clock_tsc(struct clocksource *arg)
+{
+	u64 current_tick;
+
+	if (tsc_pg->tsc_sequence != 0) {
+		/*
+		 * Use the tsc page to compute the value.
+		 */
+
+		while (1) {
+			u64 tmp;
+			u32 sequence = tsc_pg->tsc_sequence;
+			u64 cur_tsc;
+			u64 scale = tsc_pg->tsc_scale;
+			s64 offset = tsc_pg->tsc_offset;
+
+			rdtscll(cur_tsc);
+			/* current_tick = ((cur_tsc *scale) >> 64) + offset */
+			asm("mulq %3"
+				: "=d" (current_tick), "=a" (tmp)
+				: "a" (cur_tsc), "r" (scale));
+
+			current_tick += offset;
+			if (tsc_pg->tsc_sequence == sequence)
+				return current_tick;
+
+			if (tsc_pg->tsc_sequence != 0)
+				continue;
+			/*
+			 * Fallback using MSR method.
+			 */
+			break;
+		}
+	}
+	rdmsrl(HV_X64_MSR_TIME_REF_COUNT, current_tick);
+	return current_tick;
+}
+
+static struct clocksource hyperv_cs_tsc = {
+		.name		= "hyperv_clocksource_tsc_page",
+		.rating		= 400,
+		.read		= read_hv_clock_tsc,
+		.mask		= CLOCKSOURCE_MASK(64),
+		.flags		= CLOCK_SOURCE_IS_CONTINUOUS,
+};
+#endif
+
+static u64 read_hv_clock_msr(struct clocksource *arg)
+{
+	u64 current_tick;
+	/*
+	 * Read the partition counter to get the current tick count. This count
+	 * is set to 0 when the partition is created and is incremented in
+	 * 100 nanosecond units.
+	 */
+	rdmsrl(HV_X64_MSR_TIME_REF_COUNT, current_tick);
+	return current_tick;
+}
+
+static struct clocksource hyperv_cs_msr = {
+	.name		= "hyperv_clocksource_msr",
+	.rating		= 400,
+	.read		= read_hv_clock_msr,
+	.mask		= CLOCKSOURCE_MASK(64),
+	.flags		= CLOCK_SOURCE_IS_CONTINUOUS,
+};
+
+static void *hypercall_pg;
+struct clocksource *hyperv_cs;
+EXPORT_SYMBOL_GPL(hyperv_cs);
+
+/*
+ * This function is to be invoked early in the boot sequence after the
+ * hypervisor has been detected.
+ *
+ * 1. Setup the hypercall page.
+ * 2. Register Hyper-V specific clocksource.
+ */
+void hyperv_init(void)
+{
+	u64 guest_id;
+	union hv_x64_msr_hypercall_contents hypercall_msr;
+
+	if (x86_hyper != &x86_hyper_ms_hyperv)
+		return;
+
+	/*
+	 * Setup the hypercall page and enable hypercalls.
+	 * 1. Register the guest ID
+	 * 2. Enable the hypercall and register the hypercall page
+	 */
+	guest_id = generate_guest_id(0, LINUX_VERSION_CODE, 0);
+	wrmsrl(HV_X64_MSR_GUEST_OS_ID, guest_id);
+
+	hypercall_pg  = __vmalloc(PAGE_SIZE, GFP_KERNEL, PAGE_KERNEL_RX);
+	if (hypercall_pg == NULL) {
+		wrmsrl(HV_X64_MSR_GUEST_OS_ID, 0);
+		return;
+	}
+
+	rdmsrl(HV_X64_MSR_HYPERCALL, hypercall_msr.as_uint64);
+	hypercall_msr.enable = 1;
+	hypercall_msr.guest_physical_address = vmalloc_to_pfn(hypercall_pg);
+	wrmsrl(HV_X64_MSR_HYPERCALL, hypercall_msr.as_uint64);
+
+	/*
+	 * Register Hyper-V specific clocksource.
+	 */
+#ifdef CONFIG_X86_64
+	if (ms_hyperv.features & HV_X64_MSR_REFERENCE_TSC_AVAILABLE) {
+		union hv_x64_msr_hypercall_contents tsc_msr;
+
+		tsc_pg = __vmalloc(PAGE_SIZE, GFP_KERNEL, PAGE_KERNEL);
+		if (!tsc_pg)
+			goto register_msr_cs;
+
+		hyperv_cs = &hyperv_cs_tsc;
+
+		rdmsrl(HV_X64_MSR_REFERENCE_TSC, tsc_msr.as_uint64);
+
+		tsc_msr.enable = 1;
+		tsc_msr.guest_physical_address = vmalloc_to_pfn(tsc_pg);
+
+		wrmsrl(HV_X64_MSR_REFERENCE_TSC, tsc_msr.as_uint64);
+		clocksource_register_hz(&hyperv_cs_tsc, NSEC_PER_SEC/100);
+		return;
+	}
+#endif
+	/*
+	 * For 32 bit guests just use the MSR based mechanism for reading
+	 * the partition counter.
+	 */
+
+register_msr_cs:
+	hyperv_cs = &hyperv_cs_msr;
+	if (ms_hyperv.features & HV_X64_MSR_TIME_REF_COUNT_AVAILABLE)
+		clocksource_register_hz(&hyperv_cs_msr, NSEC_PER_SEC/100);
+}
+
+/*
+ * This routine is called before kexec/kdump, it does the required cleanup.
+ */
+void hyperv_cleanup(void)
+{
+	union hv_x64_msr_hypercall_contents hypercall_msr;
+
+	/* Reset our OS id */
+	wrmsrl(HV_X64_MSR_GUEST_OS_ID, 0);
+
+	/* Reset the hypercall page */
+	hypercall_msr.as_uint64 = 0;
+	wrmsrl(HV_X64_MSR_HYPERCALL, hypercall_msr.as_uint64);
+
+	/* Reset the TSC page */
+	hypercall_msr.as_uint64 = 0;
+	wrmsrl(HV_X64_MSR_REFERENCE_TSC, hypercall_msr.as_uint64);
+}
+EXPORT_SYMBOL_GPL(hyperv_cleanup);
+
+/*
+ * hv_do_hypercall- Invoke the specified hypercall
+ */
+u64 hv_do_hypercall(u64 control, void *input, void *output)
+{
+	u64 input_address = (input) ? virt_to_phys(input) : 0;
+	u64 output_address = (output) ? virt_to_phys(output) : 0;
+#ifdef CONFIG_X86_64
+	u64 hv_status = 0;
+
+	if (!hypercall_pg)
+		return (u64)ULLONG_MAX;
+
+	__asm__ __volatile__("mov %0, %%r8" : : "r" (output_address) : "r8");
+	__asm__ __volatile__("call *%3" : "=a" (hv_status) :
+			     "c" (control), "d" (input_address),
+			     "m" (hypercall_pg));
+
+	return hv_status;
+
+#else
+
+	u32 control_hi = control >> 32;
+	u32 control_lo = control & 0xFFFFFFFF;
+	u32 hv_status_hi = 1;
+	u32 hv_status_lo = 1;
+	u32 input_address_hi = input_address >> 32;
+	u32 input_address_lo = input_address & 0xFFFFFFFF;
+	u32 output_address_hi = output_address >> 32;
+	u32 output_address_lo = output_address & 0xFFFFFFFF;
+
+	if (!hypercall_pg)
+		return (u64)ULLONG_MAX;
+
+	__asm__ __volatile__ ("call *%8" : "=d"(hv_status_hi),
+			      "=a"(hv_status_lo) : "d" (control_hi),
+			      "a" (control_lo), "b" (input_address_hi),
+			      "c" (input_address_lo), "D"(output_address_hi),
+			      "S"(output_address_lo), "m" (hypercall_pg));
+
+	return hv_status_lo | ((u64)hv_status_hi << 32);
+#endif /* !x86_64 */
+}
+EXPORT_SYMBOL_GPL(hv_do_hypercall);
+
+void hyperv_report_panic(struct pt_regs *regs)
+{
+	static bool panic_reported;
+
+	/*
+	 * We prefer to report panic on 'die' chain as we have proper
+	 * registers to report, but if we miss it (e.g. on BUG()) we need
+	 * to report it on 'panic'.
+	 */
+	if (panic_reported)
+		return;
+	panic_reported = true;
+
+	wrmsrl(HV_X64_MSR_CRASH_P0, regs->ip);
+	wrmsrl(HV_X64_MSR_CRASH_P1, regs->ax);
+	wrmsrl(HV_X64_MSR_CRASH_P2, regs->bx);
+	wrmsrl(HV_X64_MSR_CRASH_P3, regs->cx);
+	wrmsrl(HV_X64_MSR_CRASH_P4, regs->dx);
+
+	/*
+	 * Let Hyper-V know there is crash data available
+	 */
+	wrmsrl(HV_X64_MSR_CRASH_CTL, HV_CRASH_CTL_CRASH_NOTIFY);
+}
+EXPORT_SYMBOL_GPL(hyperv_report_panic);
+
+bool hv_is_hypercall_page_setup(void)
+{
+	union hv_x64_msr_hypercall_contents hypercall_msr;
+
+	/* Check if the hypercall page is setup */
+	hypercall_msr.as_uint64 = 0;
+	rdmsrl(HV_X64_MSR_HYPERCALL, hypercall_msr.as_uint64);
+
+	if (!hypercall_msr.enable)
+		return false;
+
+	return true;
+}
+EXPORT_SYMBOL_GPL(hv_is_hypercall_page_setup);
diff --git a/arch/x86/include/asm/mshyperv.h b/arch/x86/include/asm/mshyperv.h
index aaf59b7da98a..7c9c895432a9 100644
--- a/arch/x86/include/asm/mshyperv.h
+++ b/arch/x86/include/asm/mshyperv.h
@@ -1,28 +1,179 @@
 #ifndef _ASM_X86_MSHYPER_H
 #define _ASM_X86_MSHYPER_H
 
 #include <linux/types.h>
 #include <linux/interrupt.h>
+#include <linux/clocksource.h>
 #include <asm/hyperv.h>
 
+/*
+ * The below CPUID leaves are present if VersionAndFeatures.HypervisorPresent
+ * is set by CPUID(HVCPUID_VERSION_FEATURES).
+ */
+enum hv_cpuid_function {
+	HVCPUID_VERSION_FEATURES		= 0x00000001,
+	HVCPUID_VENDOR_MAXFUNCTION		= 0x40000000,
+	HVCPUID_INTERFACE			= 0x40000001,
+
+	/*
+	 * The remaining functions depend on the value of
+	 * HVCPUID_INTERFACE
+	 */
+	HVCPUID_VERSION				= 0x40000002,
+	HVCPUID_FEATURES			= 0x40000003,
+	HVCPUID_ENLIGHTENMENT_INFO		= 0x40000004,
+	HVCPUID_IMPLEMENTATION_LIMITS		= 0x40000005,
+};
+
 struct ms_hyperv_info {
 	u32 features;
 	u32 misc_features;
 	u32 hints;
 };
 
 extern struct ms_hyperv_info ms_hyperv;
 
+/*
+ * Declare the MSR used to setup pages used to communicate with the hypervisor.
+ */
+union hv_x64_msr_hypercall_contents {
+	u64 as_uint64;
+	struct {
+		u64 enable:1;
+		u64 reserved:11;
+		u64 guest_physical_address:52;
+	};
+};
+
+/*
+ * TSC page layout.
+ */
+
+struct ms_hyperv_tsc_page {
+	volatile u32 tsc_sequence;
+	u32 reserved1;
+	volatile u64 tsc_scale;
+	volatile s64 tsc_offset;
+	u64 reserved2[509];
+};
+
+/*
+ * The guest OS needs to register the guest ID with the hypervisor.
+ * The guest ID is a 64 bit entity and the structure of this ID is
+ * specified in the Hyper-V specification:
+ *
+ * msdn.microsoft.com/en-us/library/windows/hardware/ff542653%28v=vs.85%29.aspx
+ *
+ * While the current guideline does not specify how Linux guest ID(s)
+ * need to be generated, our plan is to publish the guidelines for
+ * Linux and other guest operating systems that currently are hosted
+ * on Hyper-V. The implementation here conforms to this yet
+ * unpublished guidelines.
+ *
+ *
+ * Bit(s)
+ * 63 - Indicates if the OS is Open Source or not; 1 is Open Source
+ * 62:56 - Os Type; Linux is 0x100
+ * 55:48 - Distro specific identification
+ * 47:16 - Linux kernel version number
+ * 15:0  - Distro specific identification
+ *
+ *
+ */
+
+#define HV_LINUX_VENDOR_ID              0x8100
+
+/*
+ * Generate the guest ID based on the guideline described above.
+ */
+
+static inline  __u64 generate_guest_id(__u64 d_info1, __u64 kernel_version,
+				       __u64 d_info2)
+{
+	__u64 guest_id = 0;
+
+	guest_id = (((__u64)HV_LINUX_VENDOR_ID) << 48);
+	guest_id |= (d_info1 << 48);
+	guest_id |= (kernel_version << 16);
+	guest_id |= d_info2;
+
+	return guest_id;
+}
+
+
+/* Free the message slot and signal end-of-message if required */
+static inline void vmbus_signal_eom(struct hv_message *msg, u32 old_msg_type)
+{
+	/*
+	 * On crash we're reading some other CPU's message page and we need
+	 * to be careful: this other CPU may already had cleared the header
+	 * and the host may already had delivered some other message there.
+	 * In case we blindly write msg->header.message_type we're going
+	 * to lose it. We can still lose a message of the same type but
+	 * we count on the fact that there can only be one
+	 * CHANNELMSG_UNLOAD_RESPONSE and we don't care about other messages
+	 * on crash.
+	 */
+	if (cmpxchg(&msg->header.message_type, old_msg_type,
+		    HVMSG_NONE) != old_msg_type)
+		return;
+
+	/*
+	 * Make sure the write to MessageType (ie set to
+	 * HVMSG_NONE) happens before we read the
+	 * MessagePending and EOMing. Otherwise, the EOMing
+	 * will not deliver any more messages since there is
+	 * no empty slot
+	 */
+	mb();
+
+	if (msg->header.message_flags.msg_pending) {
+		/*
+		 * This will cause message queue rescan to
+		 * possibly deliver another msg from the
+		 * hypervisor
+		 */
+		wrmsrl(HV_X64_MSR_EOM, 0);
+	}
+}
+
+#define hv_get_current_tick(tick) rdmsrl(HV_X64_MSR_TIME_REF_COUNT, tick)
+#define hv_init_timer(timer, tick) wrmsrl(timer, tick)
+#define hv_init_timer_config(config, val) wrmsrl(config, val)
+
+#define hv_get_simp(val) rdmsrl(HV_X64_MSR_SIMP, val)
+#define hv_set_simp(val) wrmsrl(HV_X64_MSR_SIMP, val)
+
+#define hv_get_siefp(val) rdmsrl(HV_X64_MSR_SIEFP, val)
+#define hv_set_siefp(val) wrmsrl(HV_X64_MSR_SIEFP, val)
+
+#define hv_get_synic_state(val) rdmsrl(HV_X64_MSR_SCONTROL, val)
+#define hv_set_synic_state(val) wrmsrl(HV_X64_MSR_SCONTROL, val)
+
+#define hv_get_vp_index(index) rdmsrl(HV_X64_MSR_VP_INDEX, index)
+
+#define hv_get_synint_state(int_num, val) rdmsrl(int_num, val)
+#define hv_set_synint_state(int_num, val) wrmsrl(int_num, val)
+
 void hyperv_callback_vector(void);
 #ifdef CONFIG_TRACING
 #define trace_hyperv_callback_vector hyperv_callback_vector
 #endif
 void hyperv_vector_handler(struct pt_regs *regs);
 void hv_setup_vmbus_irq(void (*handler)(void));
 void hv_remove_vmbus_irq(void);
 
 void hv_setup_kexec_handler(void (*handler)(void));
 void hv_remove_kexec_handler(void);
 void hv_setup_crash_handler(void (*handler)(struct pt_regs *regs));
 void hv_remove_crash_handler(void);
+
+#if IS_ENABLED(CONFIG_HYPERV)
+extern struct clocksource *hyperv_cs;
+
+void hyperv_init(void);
+void hyperv_report_panic(struct pt_regs *regs);
+bool hv_is_hypercall_page_setup(void);
+void hyperv_cleanup(void);
+#endif
 #endif
diff --git a/arch/x86/include/uapi/asm/hyperv.h b/arch/x86/include/uapi/asm/hyperv.h
index 9b1a91834ac8..3a20ccf787b8 100644
--- a/arch/x86/include/uapi/asm/hyperv.h
+++ b/arch/x86/include/uapi/asm/hyperv.h
@@ -1,366 +1,374 @@
 #ifndef _ASM_X86_HYPERV_H
 #define _ASM_X86_HYPERV_H
 
 #include <linux/types.h>
 
 /*
  * The below CPUID leaves are present if VersionAndFeatures.HypervisorPresent
  * is set by CPUID(HvCpuIdFunctionVersionAndFeatures).
  */
 #define HYPERV_CPUID_VENDOR_AND_MAX_FUNCTIONS	0x40000000
 #define HYPERV_CPUID_INTERFACE			0x40000001
 #define HYPERV_CPUID_VERSION			0x40000002
 #define HYPERV_CPUID_FEATURES			0x40000003
 #define HYPERV_CPUID_ENLIGHTMENT_INFO		0x40000004
 #define HYPERV_CPUID_IMPLEMENT_LIMITS		0x40000005
 
 #define HYPERV_HYPERVISOR_PRESENT_BIT		0x80000000
 #define HYPERV_CPUID_MIN			0x40000005
 #define HYPERV_CPUID_MAX			0x4000ffff
 
 /*
  * Feature identification. EAX indicates which features are available
  * to the partition based upon the current partition privileges.
  */
 
 /* VP Runtime (HV_X64_MSR_VP_RUNTIME) available */
 #define HV_X64_MSR_VP_RUNTIME_AVAILABLE		(1 << 0)
 /* Partition Reference Counter (HV_X64_MSR_TIME_REF_COUNT) available*/
 #define HV_X64_MSR_TIME_REF_COUNT_AVAILABLE	(1 << 1)
 /* Partition reference TSC MSR is available */
 #define HV_X64_MSR_REFERENCE_TSC_AVAILABLE              (1 << 9)
 
 /* A partition's reference time stamp counter (TSC) page */
 #define HV_X64_MSR_REFERENCE_TSC		0x40000021
 
 /*
  * There is a single feature flag that signifies the presence of the MSR
  * that can be used to retrieve both the local APIC Timer frequency as
  * well as the TSC frequency.
  */
 
 /* Local APIC timer frequency MSR (HV_X64_MSR_APIC_FREQUENCY) is available */
 #define HV_X64_MSR_APIC_FREQUENCY_AVAILABLE (1 << 11)
 
 /* TSC frequency MSR (HV_X64_MSR_TSC_FREQUENCY) is available */
 #define HV_X64_MSR_TSC_FREQUENCY_AVAILABLE (1 << 11)
 
 /*
  * Basic SynIC MSRs (HV_X64_MSR_SCONTROL through HV_X64_MSR_EOM
  * and HV_X64_MSR_SINT0 through HV_X64_MSR_SINT15) available
  */
 #define HV_X64_MSR_SYNIC_AVAILABLE		(1 << 2)
 /*
  * Synthetic Timer MSRs (HV_X64_MSR_STIMER0_CONFIG through
  * HV_X64_MSR_STIMER3_COUNT) available
  */
 #define HV_X64_MSR_SYNTIMER_AVAILABLE		(1 << 3)
 /*
  * APIC access MSRs (HV_X64_MSR_EOI, HV_X64_MSR_ICR and HV_X64_MSR_TPR)
  * are available
  */
 #define HV_X64_MSR_APIC_ACCESS_AVAILABLE	(1 << 4)
 /* Hypercall MSRs (HV_X64_MSR_GUEST_OS_ID and HV_X64_MSR_HYPERCALL) available*/
 #define HV_X64_MSR_HYPERCALL_AVAILABLE		(1 << 5)
 /* Access virtual processor index MSR (HV_X64_MSR_VP_INDEX) available*/
 #define HV_X64_MSR_VP_INDEX_AVAILABLE		(1 << 6)
 /* Virtual system reset MSR (HV_X64_MSR_RESET) is available*/
 #define HV_X64_MSR_RESET_AVAILABLE		(1 << 7)
  /*
   * Access statistics pages MSRs (HV_X64_MSR_STATS_PARTITION_RETAIL_PAGE,
   * HV_X64_MSR_STATS_PARTITION_INTERNAL_PAGE, HV_X64_MSR_STATS_VP_RETAIL_PAGE,
   * HV_X64_MSR_STATS_VP_INTERNAL_PAGE) available
   */
 #define HV_X64_MSR_STAT_PAGES_AVAILABLE		(1 << 8)
 
+/* Crash MSR available */
+#define HV_FEATURE_GUEST_CRASH_MSR_AVAILABLE (1 << 10)
+
 /*
  * Feature identification: EBX indicates which flags were specified at
  * partition creation. The format is the same as the partition creation
  * flag structure defined in section Partition Creation Flags.
  */
 #define HV_X64_CREATE_PARTITIONS		(1 << 0)
 #define HV_X64_ACCESS_PARTITION_ID		(1 << 1)
 #define HV_X64_ACCESS_MEMORY_POOL		(1 << 2)
 #define HV_X64_ADJUST_MESSAGE_BUFFERS		(1 << 3)
 #define HV_X64_POST_MESSAGES			(1 << 4)
 #define HV_X64_SIGNAL_EVENTS			(1 << 5)
 #define HV_X64_CREATE_PORT			(1 << 6)
 #define HV_X64_CONNECT_PORT			(1 << 7)
 #define HV_X64_ACCESS_STATS			(1 << 8)
 #define HV_X64_DEBUGGING			(1 << 11)
 #define HV_X64_CPU_POWER_MANAGEMENT		(1 << 12)
 #define HV_X64_CONFIGURE_PROFILER		(1 << 13)
 
 /*
  * Feature identification. EDX indicates which miscellaneous features
  * are available to the partition.
  */
 /* The MWAIT instruction is available (per section MONITOR / MWAIT) */
 #define HV_X64_MWAIT_AVAILABLE				(1 << 0)
 /* Guest debugging support is available */
 #define HV_X64_GUEST_DEBUGGING_AVAILABLE		(1 << 1)
 /* Performance Monitor support is available*/
 #define HV_X64_PERF_MONITOR_AVAILABLE			(1 << 2)
 /* Support for physical CPU dynamic partitioning events is available*/
 #define HV_X64_CPU_DYNAMIC_PARTITIONING_AVAILABLE	(1 << 3)
 /*
  * Support for passing hypercall input parameter block via XMM
  * registers is available
  */
 #define HV_X64_HYPERCALL_PARAMS_XMM_AVAILABLE		(1 << 4)
 /* Support for a virtual guest idle state is available */
 #define HV_X64_GUEST_IDLE_STATE_AVAILABLE		(1 << 5)
 /* Guest crash data handler available */
 #define HV_X64_GUEST_CRASH_MSR_AVAILABLE		(1 << 10)
 
 /*
  * Implementation recommendations. Indicates which behaviors the hypervisor
  * recommends the OS implement for optimal performance.
  */
  /*
   * Recommend using hypercall for address space switches rather
   * than MOV to CR3 instruction
   */
 #define HV_X64_MWAIT_RECOMMENDED		(1 << 0)
 /* Recommend using hypercall for local TLB flushes rather
  * than INVLPG or MOV to CR3 instructions */
 #define HV_X64_LOCAL_TLB_FLUSH_RECOMMENDED	(1 << 1)
 /*
  * Recommend using hypercall for remote TLB flushes rather
  * than inter-processor interrupts
  */
 #define HV_X64_REMOTE_TLB_FLUSH_RECOMMENDED	(1 << 2)
 /*
  * Recommend using MSRs for accessing APIC registers
  * EOI, ICR and TPR rather than their memory-mapped counterparts
  */
 #define HV_X64_APIC_ACCESS_RECOMMENDED		(1 << 3)
 /* Recommend using the hypervisor-provided MSR to initiate a system RESET */
 #define HV_X64_SYSTEM_RESET_RECOMMENDED		(1 << 4)
 /*
  * Recommend using relaxed timing for this partition. If used,
  * the VM should disable any watchdog timeouts that rely on the
  * timely delivery of external interrupts
  */
 #define HV_X64_RELAXED_TIMING_RECOMMENDED	(1 << 5)
 
+/*
+ * Crash notification flag.
+ */
+#define HV_CRASH_CTL_CRASH_NOTIFY (1ULL << 63)
+
 /* MSR used to identify the guest OS. */
 #define HV_X64_MSR_GUEST_OS_ID			0x40000000
 
 /* MSR used to setup pages used to communicate with the hypervisor. */
 #define HV_X64_MSR_HYPERCALL			0x40000001
 
 /* MSR used to provide vcpu index */
 #define HV_X64_MSR_VP_INDEX			0x40000002
 
 /* MSR used to reset the guest OS. */
 #define HV_X64_MSR_RESET			0x40000003
 
 /* MSR used to provide vcpu runtime in 100ns units */
 #define HV_X64_MSR_VP_RUNTIME			0x40000010
 
 /* MSR used to read the per-partition time reference counter */
 #define HV_X64_MSR_TIME_REF_COUNT		0x40000020
 
 /* MSR used to retrieve the TSC frequency */
 #define HV_X64_MSR_TSC_FREQUENCY		0x40000022
 
 /* MSR used to retrieve the local APIC timer frequency */
 #define HV_X64_MSR_APIC_FREQUENCY		0x40000023
 
 /* Define the virtual APIC registers */
 #define HV_X64_MSR_EOI				0x40000070
 #define HV_X64_MSR_ICR				0x40000071
 #define HV_X64_MSR_TPR				0x40000072
 #define HV_X64_MSR_APIC_ASSIST_PAGE		0x40000073
 
 /* Define synthetic interrupt controller model specific registers. */
 #define HV_X64_MSR_SCONTROL			0x40000080
 #define HV_X64_MSR_SVERSION			0x40000081
 #define HV_X64_MSR_SIEFP			0x40000082
 #define HV_X64_MSR_SIMP				0x40000083
 #define HV_X64_MSR_EOM				0x40000084
 #define HV_X64_MSR_SINT0			0x40000090
 #define HV_X64_MSR_SINT1			0x40000091
 #define HV_X64_MSR_SINT2			0x40000092
 #define HV_X64_MSR_SINT3			0x40000093
 #define HV_X64_MSR_SINT4			0x40000094
 #define HV_X64_MSR_SINT5			0x40000095
 #define HV_X64_MSR_SINT6			0x40000096
 #define HV_X64_MSR_SINT7			0x40000097
 #define HV_X64_MSR_SINT8			0x40000098
 #define HV_X64_MSR_SINT9			0x40000099
 #define HV_X64_MSR_SINT10			0x4000009A
 #define HV_X64_MSR_SINT11			0x4000009B
 #define HV_X64_MSR_SINT12			0x4000009C
 #define HV_X64_MSR_SINT13			0x4000009D
 #define HV_X64_MSR_SINT14			0x4000009E
 #define HV_X64_MSR_SINT15			0x4000009F
 
 /*
  * Synthetic Timer MSRs. Four timers per vcpu.
  */
 #define HV_X64_MSR_STIMER0_CONFIG		0x400000B0
 #define HV_X64_MSR_STIMER0_COUNT		0x400000B1
 #define HV_X64_MSR_STIMER1_CONFIG		0x400000B2
 #define HV_X64_MSR_STIMER1_COUNT		0x400000B3
 #define HV_X64_MSR_STIMER2_CONFIG		0x400000B4
 #define HV_X64_MSR_STIMER2_COUNT		0x400000B5
 #define HV_X64_MSR_STIMER3_CONFIG		0x400000B6
 #define HV_X64_MSR_STIMER3_COUNT		0x400000B7
 
 /* Hyper-V guest crash notification MSR's */
 #define HV_X64_MSR_CRASH_P0			0x40000100
 #define HV_X64_MSR_CRASH_P1			0x40000101
 #define HV_X64_MSR_CRASH_P2			0x40000102
 #define HV_X64_MSR_CRASH_P3			0x40000103
 #define HV_X64_MSR_CRASH_P4			0x40000104
 #define HV_X64_MSR_CRASH_CTL			0x40000105
 #define HV_X64_MSR_CRASH_CTL_NOTIFY		(1ULL << 63)
 #define HV_X64_MSR_CRASH_PARAMS		\
 		(1 + (HV_X64_MSR_CRASH_P4 - HV_X64_MSR_CRASH_P0))
 
 #define HV_X64_MSR_HYPERCALL_ENABLE		0x00000001
 #define HV_X64_MSR_HYPERCALL_PAGE_ADDRESS_SHIFT	12
 #define HV_X64_MSR_HYPERCALL_PAGE_ADDRESS_MASK	\
 		(~((1ull << HV_X64_MSR_HYPERCALL_PAGE_ADDRESS_SHIFT) - 1))
 
 /* Declare the various hypercall operations. */
 #define HVCALL_NOTIFY_LONG_SPIN_WAIT		0x0008
 #define HVCALL_POST_MESSAGE			0x005c
 #define HVCALL_SIGNAL_EVENT			0x005d
 
 #define HV_X64_MSR_APIC_ASSIST_PAGE_ENABLE		0x00000001
 #define HV_X64_MSR_APIC_ASSIST_PAGE_ADDRESS_SHIFT	12
 #define HV_X64_MSR_APIC_ASSIST_PAGE_ADDRESS_MASK	\
 		(~((1ull << HV_X64_MSR_APIC_ASSIST_PAGE_ADDRESS_SHIFT) - 1))
 
 #define HV_X64_MSR_TSC_REFERENCE_ENABLE		0x00000001
 #define HV_X64_MSR_TSC_REFERENCE_ADDRESS_SHIFT	12
 
 #define HV_PROCESSOR_POWER_STATE_C0		0
 #define HV_PROCESSOR_POWER_STATE_C1		1
 #define HV_PROCESSOR_POWER_STATE_C2		2
 #define HV_PROCESSOR_POWER_STATE_C3		3
 
 /* hypercall status code */
 #define HV_STATUS_SUCCESS			0
 #define HV_STATUS_INVALID_HYPERCALL_CODE	2
 #define HV_STATUS_INVALID_HYPERCALL_INPUT	3
 #define HV_STATUS_INVALID_ALIGNMENT		4
 #define HV_STATUS_INSUFFICIENT_MEMORY		11
 #define HV_STATUS_INVALID_CONNECTION_ID		18
 #define HV_STATUS_INSUFFICIENT_BUFFERS		19
 
 typedef struct _HV_REFERENCE_TSC_PAGE {
 	__u32 tsc_sequence;
 	__u32 res1;
 	__u64 tsc_scale;
 	__s64 tsc_offset;
 } HV_REFERENCE_TSC_PAGE, *PHV_REFERENCE_TSC_PAGE;
 
 /* Define the number of synthetic interrupt sources. */
 #define HV_SYNIC_SINT_COUNT		(16)
 /* Define the expected SynIC version. */
 #define HV_SYNIC_VERSION_1		(0x1)
 
 #define HV_SYNIC_CONTROL_ENABLE		(1ULL << 0)
 #define HV_SYNIC_SIMP_ENABLE		(1ULL << 0)
 #define HV_SYNIC_SIEFP_ENABLE		(1ULL << 0)
 #define HV_SYNIC_SINT_MASKED		(1ULL << 16)
 #define HV_SYNIC_SINT_AUTO_EOI		(1ULL << 17)
 #define HV_SYNIC_SINT_VECTOR_MASK	(0xFF)
 
 #define HV_SYNIC_STIMER_COUNT		(4)
 
 /* Define synthetic interrupt controller message constants. */
 #define HV_MESSAGE_SIZE			(256)
 #define HV_MESSAGE_PAYLOAD_BYTE_COUNT	(240)
 #define HV_MESSAGE_PAYLOAD_QWORD_COUNT	(30)
 
 /* Define hypervisor message types. */
 enum hv_message_type {
 	HVMSG_NONE			= 0x00000000,
 
 	/* Memory access messages. */
 	HVMSG_UNMAPPED_GPA		= 0x80000000,
 	HVMSG_GPA_INTERCEPT		= 0x80000001,
 
 	/* Timer notification messages. */
 	HVMSG_TIMER_EXPIRED			= 0x80000010,
 
 	/* Error messages. */
 	HVMSG_INVALID_VP_REGISTER_VALUE	= 0x80000020,
 	HVMSG_UNRECOVERABLE_EXCEPTION	= 0x80000021,
 	HVMSG_UNSUPPORTED_FEATURE		= 0x80000022,
 
 	/* Trace buffer complete messages. */
 	HVMSG_EVENTLOG_BUFFERCOMPLETE	= 0x80000040,
 
 	/* Platform-specific processor intercept messages. */
 	HVMSG_X64_IOPORT_INTERCEPT		= 0x80010000,
 	HVMSG_X64_MSR_INTERCEPT		= 0x80010001,
 	HVMSG_X64_CPUID_INTERCEPT		= 0x80010002,
 	HVMSG_X64_EXCEPTION_INTERCEPT	= 0x80010003,
 	HVMSG_X64_APIC_EOI			= 0x80010004,
 	HVMSG_X64_LEGACY_FP_ERROR		= 0x80010005
 };
 
 /* Define synthetic interrupt controller message flags. */
 union hv_message_flags {
 	__u8 asu8;
 	struct {
 		__u8 msg_pending:1;
 		__u8 reserved:7;
 	};
 };
 
 /* Define port identifier type. */
 union hv_port_id {
 	__u32 asu32;
 	struct {
 		__u32 id:24;
 		__u32 reserved:8;
 	} u;
 };
 
 /* Define synthetic interrupt controller message header. */
 struct hv_message_header {
 	__u32 message_type;
 	__u8 payload_size;
 	union hv_message_flags message_flags;
 	__u8 reserved[2];
 	union {
 		__u64 sender;
 		union hv_port_id port;
 	};
 };
 
 /* Define synthetic interrupt controller message format. */
 struct hv_message {
 	struct hv_message_header header;
 	union {
 		__u64 payload[HV_MESSAGE_PAYLOAD_QWORD_COUNT];
 	} u;
 };
 
 /* Define the synthetic interrupt message page layout. */
 struct hv_message_page {
 	struct hv_message sint_message[HV_SYNIC_SINT_COUNT];
 };
 
 /* Define timer message payload structure. */
 struct hv_timer_message_payload {
 	__u32 timer_index;
 	__u32 reserved;
 	__u64 expiration_time;	/* When the timer expired */
 	__u64 delivery_time;	/* When the message was delivered */
 };
 
 #define HV_STIMER_ENABLE		(1ULL << 0)
 #define HV_STIMER_PERIODIC		(1ULL << 1)
 #define HV_STIMER_LAZY			(1ULL << 2)
 #define HV_STIMER_AUTOENABLE		(1ULL << 3)
 #define HV_STIMER_SINT(config)		(__u8)(((config) >> 16) & 0x0F)
 
 #endif
diff --git a/arch/x86/kernel/cpu/mshyperv.c b/arch/x86/kernel/cpu/mshyperv.c
index 65e20c97e04b..b5375b9497b3 100644
--- a/arch/x86/kernel/cpu/mshyperv.c
+++ b/arch/x86/kernel/cpu/mshyperv.c
@@ -1,237 +1,241 @@
 /*
  * HyperV  Detection code.
  *
  * Copyright (C) 2010, Novell, Inc.
  * Author : K. Y. Srinivasan <ksrinivasan@novell.com>
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
  * the Free Software Foundation; version 2 of the License.
  *
  */
 
 #include <linux/types.h>
 #include <linux/time.h>
 #include <linux/clocksource.h>
 #include <linux/init.h>
 #include <linux/export.h>
 #include <linux/hardirq.h>
 #include <linux/efi.h>
 #include <linux/interrupt.h>
 #include <linux/irq.h>
 #include <linux/kexec.h>
 #include <asm/processor.h>
 #include <asm/hypervisor.h>
 #include <asm/hyperv.h>
 #include <asm/mshyperv.h>
 #include <asm/desc.h>
 #include <asm/irq_regs.h>
 #include <asm/i8259.h>
 #include <asm/apic.h>
 #include <asm/timer.h>
 #include <asm/reboot.h>
 #include <asm/nmi.h>
 
 struct ms_hyperv_info ms_hyperv;
 EXPORT_SYMBOL_GPL(ms_hyperv);
 
 #if IS_ENABLED(CONFIG_HYPERV)
 static void (*vmbus_handler)(void);
 static void (*hv_kexec_handler)(void);
 static void (*hv_crash_handler)(struct pt_regs *regs);
 
 void hyperv_vector_handler(struct pt_regs *regs)
 {
 	struct pt_regs *old_regs = set_irq_regs(regs);
 
 	entering_irq();
 	inc_irq_stat(irq_hv_callback_count);
 	if (vmbus_handler)
 		vmbus_handler();
 
 	exiting_irq();
 	set_irq_regs(old_regs);
 }
 
 void hv_setup_vmbus_irq(void (*handler)(void))
 {
 	vmbus_handler = handler;
 	/*
 	 * Setup the IDT for hypervisor callback. Prevent reallocation
 	 * at module reload.
 	 */
 	if (!test_bit(HYPERVISOR_CALLBACK_VECTOR, used_vectors))
 		alloc_intr_gate(HYPERVISOR_CALLBACK_VECTOR,
 				hyperv_callback_vector);
 }
 
 void hv_remove_vmbus_irq(void)
 {
 	/* We have no way to deallocate the interrupt gate */
 	vmbus_handler = NULL;
 }
 EXPORT_SYMBOL_GPL(hv_setup_vmbus_irq);
 EXPORT_SYMBOL_GPL(hv_remove_vmbus_irq);
 
 void hv_setup_kexec_handler(void (*handler)(void))
 {
 	hv_kexec_handler = handler;
 }
 EXPORT_SYMBOL_GPL(hv_setup_kexec_handler);
 
 void hv_remove_kexec_handler(void)
 {
 	hv_kexec_handler = NULL;
 }
 EXPORT_SYMBOL_GPL(hv_remove_kexec_handler);
 
 void hv_setup_crash_handler(void (*handler)(struct pt_regs *regs))
 {
 	hv_crash_handler = handler;
 }
 EXPORT_SYMBOL_GPL(hv_setup_crash_handler);
 
 void hv_remove_crash_handler(void)
 {
 	hv_crash_handler = NULL;
 }
 EXPORT_SYMBOL_GPL(hv_remove_crash_handler);
 
 #ifdef CONFIG_KEXEC_CORE
 static void hv_machine_shutdown(void)
 {
 	if (kexec_in_progress && hv_kexec_handler)
 		hv_kexec_handler();
 	native_machine_shutdown();
 }
 
 static void hv_machine_crash_shutdown(struct pt_regs *regs)
 {
 	if (hv_crash_handler)
 		hv_crash_handler(regs);
 	native_machine_crash_shutdown(regs);
 }
 #endif /* CONFIG_KEXEC_CORE */
 #endif /* CONFIG_HYPERV */
 
 static uint32_t  __init ms_hyperv_platform(void)
 {
 	u32 eax;
 	u32 hyp_signature[3];
 
 	if (!boot_cpu_has(X86_FEATURE_HYPERVISOR))
 		return 0;
 
 	cpuid(HYPERV_CPUID_VENDOR_AND_MAX_FUNCTIONS,
 	      &eax, &hyp_signature[0], &hyp_signature[1], &hyp_signature[2]);
 
 	if (eax >= HYPERV_CPUID_MIN &&
 	    eax <= HYPERV_CPUID_MAX &&
 	    !memcmp("Microsoft Hv", hyp_signature, 12))
 		return HYPERV_CPUID_VENDOR_AND_MAX_FUNCTIONS;
 
 	return 0;
 }
 
-static u64 read_hv_clock(struct clocksource *arg)
-{
-	u64 current_tick;
-	/*
-	 * Read the partition counter to get the current tick count. This count
-	 * is set to 0 when the partition is created and is incremented in
-	 * 100 nanosecond units.
-	 */
-	rdmsrl(HV_X64_MSR_TIME_REF_COUNT, current_tick);
-	return current_tick;
-}
-
-static struct clocksource hyperv_cs = {
-	.name		= "hyperv_clocksource",
-	.rating		= 400, /* use this when running on Hyperv*/
-	.read		= read_hv_clock,
-	.mask		= CLOCKSOURCE_MASK(64),
-	.flags		= CLOCK_SOURCE_IS_CONTINUOUS,
-};
-
 static unsigned char hv_get_nmi_reason(void)
 {
 	return 0;
 }
 
 #ifdef CONFIG_X86_LOCAL_APIC
 /*
  * Prior to WS2016 Debug-VM sends NMIs to all CPUs which makes
  * it dificult to process CHANNELMSG_UNLOAD in case of crash. Handle
  * unknown NMI on the first CPU which gets it.
  */
 static int hv_nmi_unknown(unsigned int val, struct pt_regs *regs)
 {
 	static atomic_t nmi_cpu = ATOMIC_INIT(-1);
 
 	if (!unknown_nmi_panic)
 		return NMI_DONE;
 
 	if (atomic_cmpxchg(&nmi_cpu, -1, raw_smp_processor_id()) != -1)
 		return NMI_HANDLED;
 
 	return NMI_DONE;
 }
 #endif
 
 static void __init ms_hyperv_init_platform(void)
 {
+	int hv_host_info_eax;
+	int hv_host_info_ebx;
+	int hv_host_info_ecx;
+	int hv_host_info_edx;
+
 	/*
 	 * Extract the features and hints
 	 */
 	ms_hyperv.features = cpuid_eax(HYPERV_CPUID_FEATURES);
 	ms_hyperv.misc_features = cpuid_edx(HYPERV_CPUID_FEATURES);
 	ms_hyperv.hints    = cpuid_eax(HYPERV_CPUID_ENLIGHTMENT_INFO);
 
 	pr_info("HyperV: features 0x%x, hints 0x%x\n",
 		ms_hyperv.features, ms_hyperv.hints);
 
+	/*
+	 * Extract host information.
+	 */
+	if (cpuid_eax(HVCPUID_VENDOR_MAXFUNCTION) >= HVCPUID_VERSION) {
+		hv_host_info_eax = cpuid_eax(HVCPUID_VERSION);
+		hv_host_info_ebx = cpuid_ebx(HVCPUID_VERSION);
+		hv_host_info_ecx = cpuid_ecx(HVCPUID_VERSION);
+		hv_host_info_edx = cpuid_edx(HVCPUID_VERSION);
+
+		pr_info("Hyper-V Host Build:%d-%d.%d-%d-%d.%d\n",
+			hv_host_info_eax, hv_host_info_ebx >> 16,
+			hv_host_info_ebx & 0xFFFF, hv_host_info_ecx,
+			hv_host_info_edx >> 24, hv_host_info_edx & 0xFFFFFF);
+	}
+
 #ifdef CONFIG_X86_LOCAL_APIC
 	if (ms_hyperv.features & HV_X64_MSR_APIC_FREQUENCY_AVAILABLE) {
 		/*
 		 * Get the APIC frequency.
 		 */
 		u64	hv_lapic_frequency;
 
 		rdmsrl(HV_X64_MSR_APIC_FREQUENCY, hv_lapic_frequency);
 		hv_lapic_frequency = div_u64(hv_lapic_frequency, HZ);
 		lapic_timer_frequency = hv_lapic_frequency;
 		pr_info("HyperV: LAPIC Timer Frequency: %#x\n",
 			lapic_timer_frequency);
 	}
 
 	register_nmi_handler(NMI_UNKNOWN, hv_nmi_unknown, NMI_FLAG_FIRST,
 			     "hv_nmi_unknown");
 #endif
 
-	if (ms_hyperv.features & HV_X64_MSR_TIME_REF_COUNT_AVAILABLE)
-		clocksource_register_hz(&hyperv_cs, NSEC_PER_SEC/100);
-
 #ifdef CONFIG_X86_IO_APIC
 	no_timer_check = 1;
 #endif
 
 #if IS_ENABLED(CONFIG_HYPERV) && defined(CONFIG_KEXEC_CORE)
 	machine_ops.shutdown = hv_machine_shutdown;
 	machine_ops.crash_shutdown = hv_machine_crash_shutdown;
 #endif
 	mark_tsc_unstable("running on Hyper-V");
 
 	/*
 	 * Generation 2 instances don't support reading the NMI status from
 	 * 0x61 port.
 	 */
 	if (efi_enabled(EFI_BOOT))
 		x86_platform.get_nmi_reason = hv_get_nmi_reason;
+
+#if IS_ENABLED(CONFIG_HYPERV)
+	/*
+	 * Setup the hook to get control post apic initialization.
+	 */
+	x86_platform.apic_post_init = hyperv_init;
+#endif
 }
 
 const __refconst struct hypervisor_x86 x86_hyper_ms_hyperv = {
 	.name			= "Microsoft HyperV",
 	.detect			= ms_hyperv_platform,
 	.init_platform		= ms_hyperv_init_platform,
 };
 EXPORT_SYMBOL(x86_hyper_ms_hyperv);
diff --git a/arch/x86/platform/goldfish/goldfish.c b/arch/x86/platform/goldfish/goldfish.c
index 1693107a518e..0d17c0aafeb1 100644
--- a/arch/x86/platform/goldfish/goldfish.c
+++ b/arch/x86/platform/goldfish/goldfish.c
@@ -1,51 +1,63 @@
 /*
  * Copyright (C) 2007 Google, Inc.
  * Copyright (C) 2011 Intel, Inc.
  * Copyright (C) 2013 Intel, Inc.
  *
  * This software is licensed under the terms of the GNU General Public
  * License version 2, as published by the Free Software Foundation, and
  * may be copied, distributed, and modified under those terms.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
  *
  */
 
 #include <linux/kernel.h>
 #include <linux/irq.h>
 #include <linux/platform_device.h>
 
 /*
  * Where in virtual device memory the IO devices (timers, system controllers
  * and so on)
  */
 
 #define GOLDFISH_PDEV_BUS_BASE	(0xff001000)
 #define GOLDFISH_PDEV_BUS_END	(0xff7fffff)
 #define GOLDFISH_PDEV_BUS_IRQ	(4)
 
 #define GOLDFISH_TTY_BASE	(0x2000)
 
 static struct resource goldfish_pdev_bus_resources[] = {
 	{
 		.start  = GOLDFISH_PDEV_BUS_BASE,
 		.end    = GOLDFISH_PDEV_BUS_END,
 		.flags  = IORESOURCE_MEM,
 	},
 	{
 		.start	= GOLDFISH_PDEV_BUS_IRQ,
 		.end	= GOLDFISH_PDEV_BUS_IRQ,
 		.flags	= IORESOURCE_IRQ,
 	}
 };
 
+static bool goldfish_enable __initdata;
+
+static int __init goldfish_setup(char *str)
+{
+	goldfish_enable = true;
+	return 0;
+}
+__setup("goldfish", goldfish_setup);
+
 static int __init goldfish_init(void)
 {
+	if (!goldfish_enable)
+		return -ENODEV;
+
 	platform_device_register_simple("goldfish_pdev_bus", -1,
-						goldfish_pdev_bus_resources, 2);
+					goldfish_pdev_bus_resources, 2);
 	return 0;
 }
 device_initcall(goldfish_init);
diff --git a/drivers/Kconfig b/drivers/Kconfig
index e1e2066cecdb..117ca14ccf85 100644
--- a/drivers/Kconfig
+++ b/drivers/Kconfig
@@ -1,205 +1,207 @@
 menu "Device Drivers"
 
 source "drivers/amba/Kconfig"
 
 source "drivers/base/Kconfig"
 
 source "drivers/bus/Kconfig"
 
 source "drivers/connector/Kconfig"
 
 source "drivers/mtd/Kconfig"
 
 source "drivers/of/Kconfig"
 
 source "drivers/parport/Kconfig"
 
 source "drivers/pnp/Kconfig"
 
 source "drivers/block/Kconfig"
 
 source "drivers/nvme/Kconfig"
 
 # misc before ide - BLK_DEV_SGIIOC4 depends on SGI_IOC4
 
 source "drivers/misc/Kconfig"
 
 source "drivers/ide/Kconfig"
 
 source "drivers/scsi/Kconfig"
 
 source "drivers/ata/Kconfig"
 
 source "drivers/md/Kconfig"
 
 source "drivers/target/Kconfig"
 
 source "drivers/message/fusion/Kconfig"
 
 source "drivers/firewire/Kconfig"
 
 source "drivers/macintosh/Kconfig"
 
 source "drivers/net/Kconfig"
 
 source "drivers/isdn/Kconfig"
 
 source "drivers/lightnvm/Kconfig"
 
 # input before char - char/joystick depends on it. As does USB.
 
 source "drivers/input/Kconfig"
 
 source "drivers/char/Kconfig"
 
 source "drivers/i2c/Kconfig"
 
 source "drivers/spi/Kconfig"
 
 source "drivers/spmi/Kconfig"
 
 source "drivers/hsi/Kconfig"
 
 source "drivers/pps/Kconfig"
 
 source "drivers/ptp/Kconfig"
 
 source "drivers/pinctrl/Kconfig"
 
 source "drivers/gpio/Kconfig"
 
 source "drivers/w1/Kconfig"
 
 source "drivers/power/Kconfig"
 
 source "drivers/hwmon/Kconfig"
 
 source "drivers/thermal/Kconfig"
 
 source "drivers/watchdog/Kconfig"
 
 source "drivers/ssb/Kconfig"
 
 source "drivers/bcma/Kconfig"
 
 source "drivers/mfd/Kconfig"
 
 source "drivers/regulator/Kconfig"
 
 source "drivers/media/Kconfig"
 
 source "drivers/video/Kconfig"
 
 source "sound/Kconfig"
 
 source "drivers/hid/Kconfig"
 
 source "drivers/usb/Kconfig"
 
 source "drivers/uwb/Kconfig"
 
 source "drivers/mmc/Kconfig"
 
 source "drivers/memstick/Kconfig"
 
 source "drivers/leds/Kconfig"
 
 source "drivers/accessibility/Kconfig"
 
 source "drivers/infiniband/Kconfig"
 
 source "drivers/edac/Kconfig"
 
 source "drivers/rtc/Kconfig"
 
 source "drivers/dma/Kconfig"
 
 source "drivers/dma-buf/Kconfig"
 
 source "drivers/dca/Kconfig"
 
 source "drivers/auxdisplay/Kconfig"
 
 source "drivers/uio/Kconfig"
 
 source "drivers/vfio/Kconfig"
 
 source "drivers/vlynq/Kconfig"
 
 source "drivers/virt/Kconfig"
 
 source "drivers/virtio/Kconfig"
 
 source "drivers/hv/Kconfig"
 
 source "drivers/xen/Kconfig"
 
 source "drivers/staging/Kconfig"
 
 source "drivers/platform/Kconfig"
 
 source "drivers/clk/Kconfig"
 
 source "drivers/hwspinlock/Kconfig"
 
 source "drivers/clocksource/Kconfig"
 
 source "drivers/mailbox/Kconfig"
 
 source "drivers/iommu/Kconfig"
 
 source "drivers/remoteproc/Kconfig"
 
 source "drivers/rpmsg/Kconfig"
 
 source "drivers/soc/Kconfig"
 
 source "drivers/devfreq/Kconfig"
 
 source "drivers/extcon/Kconfig"
 
 source "drivers/memory/Kconfig"
 
 source "drivers/iio/Kconfig"
 
 source "drivers/ntb/Kconfig"
 
 source "drivers/vme/Kconfig"
 
 source "drivers/pwm/Kconfig"
 
 source "drivers/irqchip/Kconfig"
 
 source "drivers/ipack/Kconfig"
 
 source "drivers/reset/Kconfig"
 
 source "drivers/fmc/Kconfig"
 
 source "drivers/phy/Kconfig"
 
 source "drivers/powercap/Kconfig"
 
 source "drivers/mcb/Kconfig"
 
 source "drivers/perf/Kconfig"
 
 source "drivers/ras/Kconfig"
 
 source "drivers/thunderbolt/Kconfig"
 
 source "drivers/android/Kconfig"
 
 source "drivers/nvdimm/Kconfig"
 
 source "drivers/dax/Kconfig"
 
 source "drivers/nvmem/Kconfig"
 
 source "drivers/hwtracing/stm/Kconfig"
 
 source "drivers/hwtracing/intel_th/Kconfig"
 
 source "drivers/fpga/Kconfig"
 
+source "drivers/fsi/Kconfig"
+
 endmenu
diff --git a/drivers/Makefile b/drivers/Makefile
index 060026a02f59..67ce51d62015 100644
--- a/drivers/Makefile
+++ b/drivers/Makefile
@@ -1,175 +1,176 @@
 #
 # Makefile for the Linux kernel device drivers.
 #
 # 15 Sep 2000, Christoph Hellwig <hch@infradead.org>
 # Rewritten to use lists instead of if-statements.
 #
 
 obj-y				+= irqchip/
 obj-y				+= bus/
 
 obj-$(CONFIG_GENERIC_PHY)	+= phy/
 
 # GPIO must come after pinctrl as gpios may need to mux pins etc
 obj-$(CONFIG_PINCTRL)		+= pinctrl/
 obj-$(CONFIG_GPIOLIB)		+= gpio/
 obj-y				+= pwm/
 obj-$(CONFIG_PCI)		+= pci/
 obj-$(CONFIG_PARISC)		+= parisc/
 obj-$(CONFIG_RAPIDIO)		+= rapidio/
 obj-y				+= video/
 obj-y				+= idle/
 
 # IPMI must come before ACPI in order to provide IPMI opregion support
 obj-y				+= char/ipmi/
 
 obj-$(CONFIG_ACPI)		+= acpi/
 obj-$(CONFIG_SFI)		+= sfi/
 # PnP must come after ACPI since it will eventually need to check if acpi
 # was used and do nothing if so
 obj-$(CONFIG_PNP)		+= pnp/
 obj-y				+= amba/
 
 obj-y				+= clk/
 # Many drivers will want to use DMA so this has to be made available
 # really early.
 obj-$(CONFIG_DMADEVICES)	+= dma/
 
 # SOC specific infrastructure drivers.
 obj-y				+= soc/
 
 obj-$(CONFIG_VIRTIO)		+= virtio/
 obj-$(CONFIG_XEN)		+= xen/
 
 # regulators early, since some subsystems rely on them to initialize
 obj-$(CONFIG_REGULATOR)		+= regulator/
 
 # reset controllers early, since gpu drivers might rely on them to initialize
 obj-$(CONFIG_RESET_CONTROLLER)	+= reset/
 
 # tty/ comes before char/ so that the VT console is the boot-time
 # default.
 obj-y				+= tty/
 obj-y				+= char/
 
 # iommu/ comes before gpu as gpu are using iommu controllers
 obj-$(CONFIG_IOMMU_SUPPORT)	+= iommu/
 
 # gpu/ comes after char for AGP vs DRM startup and after iommu
 obj-y				+= gpu/
 
 obj-$(CONFIG_CONNECTOR)		+= connector/
 
 # i810fb and intelfb depend on char/agp/
 obj-$(CONFIG_FB_I810)           += video/fbdev/i810/
 obj-$(CONFIG_FB_INTEL)          += video/fbdev/intelfb/
 
 obj-$(CONFIG_PARPORT)		+= parport/
 obj-$(CONFIG_NVM)		+= lightnvm/
 obj-y				+= base/ block/ misc/ mfd/ nfc/
 obj-$(CONFIG_LIBNVDIMM)		+= nvdimm/
 obj-$(CONFIG_DEV_DAX)		+= dax/
 obj-$(CONFIG_DMA_SHARED_BUFFER) += dma-buf/
 obj-$(CONFIG_NUBUS)		+= nubus/
 obj-y				+= macintosh/
 obj-$(CONFIG_IDE)		+= ide/
 obj-$(CONFIG_SCSI)		+= scsi/
 obj-y				+= nvme/
 obj-$(CONFIG_ATA)		+= ata/
 obj-$(CONFIG_TARGET_CORE)	+= target/
 obj-$(CONFIG_MTD)		+= mtd/
 obj-$(CONFIG_SPI)		+= spi/
 obj-$(CONFIG_SPMI)		+= spmi/
 obj-$(CONFIG_HSI)		+= hsi/
 obj-y				+= net/
 obj-$(CONFIG_ATM)		+= atm/
 obj-$(CONFIG_FUSION)		+= message/
 obj-y				+= firewire/
 obj-$(CONFIG_UIO)		+= uio/
 obj-$(CONFIG_VFIO)		+= vfio/
 obj-y				+= cdrom/
 obj-y				+= auxdisplay/
 obj-$(CONFIG_PCCARD)		+= pcmcia/
 obj-$(CONFIG_DIO)		+= dio/
 obj-$(CONFIG_SBUS)		+= sbus/
 obj-$(CONFIG_ZORRO)		+= zorro/
 obj-$(CONFIG_ATA_OVER_ETH)	+= block/aoe/
 obj-$(CONFIG_PARIDE) 		+= block/paride/
 obj-$(CONFIG_TC)		+= tc/
 obj-$(CONFIG_UWB)		+= uwb/
 obj-$(CONFIG_USB_PHY)		+= usb/
 obj-$(CONFIG_USB)		+= usb/
 obj-$(CONFIG_PCI)		+= usb/
 obj-$(CONFIG_USB_GADGET)	+= usb/
 obj-$(CONFIG_SERIO)		+= input/serio/
 obj-$(CONFIG_GAMEPORT)		+= input/gameport/
 obj-$(CONFIG_INPUT)		+= input/
 obj-$(CONFIG_RTC_LIB)		+= rtc/
 obj-y				+= i2c/ media/
 obj-$(CONFIG_PPS)		+= pps/
 obj-y				+= ptp/
 obj-$(CONFIG_W1)		+= w1/
 obj-y				+= power/
 obj-$(CONFIG_HWMON)		+= hwmon/
 obj-$(CONFIG_THERMAL)		+= thermal/
 obj-$(CONFIG_WATCHDOG)		+= watchdog/
 obj-$(CONFIG_MD)		+= md/
 obj-$(CONFIG_BT)		+= bluetooth/
 obj-$(CONFIG_ACCESSIBILITY)	+= accessibility/
 obj-$(CONFIG_ISDN)		+= isdn/
 obj-$(CONFIG_EDAC)		+= edac/
 obj-$(CONFIG_EISA)		+= eisa/
 obj-y				+= lguest/
 obj-$(CONFIG_CPU_FREQ)		+= cpufreq/
 obj-$(CONFIG_CPU_IDLE)		+= cpuidle/
 obj-y				+= mmc/
 obj-$(CONFIG_MEMSTICK)		+= memstick/
 obj-$(CONFIG_NEW_LEDS)		+= leds/
 obj-$(CONFIG_INFINIBAND)	+= infiniband/
 obj-$(CONFIG_SGI_SN)		+= sn/
 obj-y				+= firmware/
 obj-$(CONFIG_CRYPTO)		+= crypto/
 obj-$(CONFIG_SUPERH)		+= sh/
 ifndef CONFIG_ARCH_USES_GETTIMEOFFSET
 obj-y				+= clocksource/
 endif
 obj-$(CONFIG_DCA)		+= dca/
 obj-$(CONFIG_HID)		+= hid/
 obj-$(CONFIG_PPC_PS3)		+= ps3/
 obj-$(CONFIG_OF)		+= of/
 obj-$(CONFIG_SSB)		+= ssb/
 obj-$(CONFIG_BCMA)		+= bcma/
 obj-$(CONFIG_VHOST_RING)	+= vhost/
 obj-$(CONFIG_VHOST)		+= vhost/
 obj-$(CONFIG_VLYNQ)		+= vlynq/
 obj-$(CONFIG_STAGING)		+= staging/
 obj-y				+= platform/
 
 obj-$(CONFIG_MAILBOX)		+= mailbox/
 obj-$(CONFIG_HWSPINLOCK)	+= hwspinlock/
 obj-$(CONFIG_REMOTEPROC)	+= remoteproc/
 obj-$(CONFIG_RPMSG)		+= rpmsg/
 
 # Virtualization drivers
 obj-$(CONFIG_VIRT_DRIVERS)	+= virt/
 obj-$(CONFIG_HYPERV)		+= hv/
 
 obj-$(CONFIG_PM_DEVFREQ)	+= devfreq/
 obj-$(CONFIG_EXTCON)		+= extcon/
 obj-$(CONFIG_MEMORY)		+= memory/
 obj-$(CONFIG_IIO)		+= iio/
 obj-$(CONFIG_VME_BUS)		+= vme/
 obj-$(CONFIG_IPACK_BUS)		+= ipack/
 obj-$(CONFIG_NTB)		+= ntb/
 obj-$(CONFIG_FMC)		+= fmc/
 obj-$(CONFIG_POWERCAP)		+= powercap/
 obj-$(CONFIG_MCB)		+= mcb/
 obj-$(CONFIG_PERF_EVENTS)	+= perf/
 obj-$(CONFIG_RAS)		+= ras/
 obj-$(CONFIG_THUNDERBOLT)	+= thunderbolt/
 obj-$(CONFIG_CORESIGHT)		+= hwtracing/coresight/
 obj-y				+= hwtracing/intel_th/
 obj-$(CONFIG_STM)		+= hwtracing/stm/
 obj-$(CONFIG_ANDROID)		+= android/
 obj-$(CONFIG_NVMEM)		+= nvmem/
 obj-$(CONFIG_FPGA)		+= fpga/
+obj-$(CONFIG_FSI)		+= fsi/
diff --git a/drivers/android/Kconfig b/drivers/android/Kconfig
index bdfc6c6f4f5a..a82fc022d34b 100644
--- a/drivers/android/Kconfig
+++ b/drivers/android/Kconfig
@@ -1,37 +1,49 @@
 menu "Android"
 
 config ANDROID
 	bool "Android Drivers"
 	---help---
 	  Enable support for various drivers needed on the Android platform
 
 if ANDROID
 
 config ANDROID_BINDER_IPC
 	bool "Android Binder IPC Driver"
 	depends on MMU
 	default n
 	---help---
 	  Binder is used in Android for both communication between processes,
 	  and remote method invocation.
 
 	  This means one Android process can call a method/routine in another
 	  Android process, using Binder to identify, invoke and pass arguments
 	  between said processes.
 
+config ANDROID_BINDER_DEVICES
+	string "Android Binder devices"
+	depends on ANDROID_BINDER_IPC
+	default "binder"
+	---help---
+	  Default value for the binder.devices parameter.
+
+	  The binder.devices parameter is a comma-separated list of strings
+	  that specifies the names of the binder device nodes that will be
+	  created. Each binder device has its own context manager, and is
+	  therefore logically separated from the other devices.
+
 config ANDROID_BINDER_IPC_32BIT
 	bool
 	depends on !64BIT && ANDROID_BINDER_IPC
 	default y
 	---help---
 	  The Binder API has been changed to support both 32 and 64bit
 	  applications in a mixed environment.
 
 	  Enable this to support an old 32-bit Android user-space (v4.4 and
 	  earlier).
 
 	  Note that enabling this will break newer Android user-space.
 
 endif # if ANDROID
 
 endmenu
diff --git a/drivers/android/binder.c b/drivers/android/binder.c
index 3c71b982bf2a..9451b762fa1c 100644
--- a/drivers/android/binder.c
+++ b/drivers/android/binder.c
@@ -1,3738 +1,4291 @@
 /* binder.c
  *
  * Android IPC Subsystem
  *
  * Copyright (C) 2007-2008 Google, Inc.
  *
  * This software is licensed under the terms of the GNU General Public
  * License version 2, as published by the Free Software Foundation, and
  * may be copied, distributed, and modified under those terms.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
  *
  */
 
 #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
 
 #include <asm/cacheflush.h>
 #include <linux/fdtable.h>
 #include <linux/file.h>
 #include <linux/freezer.h>
 #include <linux/fs.h>
 #include <linux/list.h>
 #include <linux/miscdevice.h>
 #include <linux/mm.h>
 #include <linux/module.h>
 #include <linux/mutex.h>
 #include <linux/nsproxy.h>
 #include <linux/poll.h>
 #include <linux/debugfs.h>
 #include <linux/rbtree.h>
 #include <linux/sched.h>
 #include <linux/seq_file.h>
 #include <linux/uaccess.h>
 #include <linux/vmalloc.h>
 #include <linux/slab.h>
 #include <linux/pid_namespace.h>
 #include <linux/security.h>
 
 #ifdef CONFIG_ANDROID_BINDER_IPC_32BIT
 #define BINDER_IPC_32BIT 1
 #endif
 
 #include <uapi/linux/android/binder.h>
 #include "binder_trace.h"
 
 static DEFINE_MUTEX(binder_main_lock);
 static DEFINE_MUTEX(binder_deferred_lock);
 static DEFINE_MUTEX(binder_mmap_lock);
 
+static HLIST_HEAD(binder_devices);
 static HLIST_HEAD(binder_procs);
 static HLIST_HEAD(binder_deferred_list);
 static HLIST_HEAD(binder_dead_nodes);
 
 static struct dentry *binder_debugfs_dir_entry_root;
 static struct dentry *binder_debugfs_dir_entry_proc;
-static struct binder_node *binder_context_mgr_node;
-static kuid_t binder_context_mgr_uid = INVALID_UID;
 static int binder_last_id;
 
 #define BINDER_DEBUG_ENTRY(name) \
 static int binder_##name##_open(struct inode *inode, struct file *file) \
 { \
 	return single_open(file, binder_##name##_show, inode->i_private); \
 } \
 \
 static const struct file_operations binder_##name##_fops = { \
 	.owner = THIS_MODULE, \
 	.open = binder_##name##_open, \
 	.read = seq_read, \
 	.llseek = seq_lseek, \
 	.release = single_release, \
 }
 
 static int binder_proc_show(struct seq_file *m, void *unused);
 BINDER_DEBUG_ENTRY(proc);
 
 /* This is only defined in include/asm-arm/sizes.h */
 #ifndef SZ_1K
 #define SZ_1K                               0x400
 #endif
 
 #ifndef SZ_4M
 #define SZ_4M                               0x400000
 #endif
 
 #define FORBIDDEN_MMAP_FLAGS                (VM_WRITE)
 
 #define BINDER_SMALL_BUF_SIZE (PAGE_SIZE * 64)
 
 enum {
 	BINDER_DEBUG_USER_ERROR             = 1U << 0,
 	BINDER_DEBUG_FAILED_TRANSACTION     = 1U << 1,
 	BINDER_DEBUG_DEAD_TRANSACTION       = 1U << 2,
 	BINDER_DEBUG_OPEN_CLOSE             = 1U << 3,
 	BINDER_DEBUG_DEAD_BINDER            = 1U << 4,
 	BINDER_DEBUG_DEATH_NOTIFICATION     = 1U << 5,
 	BINDER_DEBUG_READ_WRITE             = 1U << 6,
 	BINDER_DEBUG_USER_REFS              = 1U << 7,
 	BINDER_DEBUG_THREADS                = 1U << 8,
 	BINDER_DEBUG_TRANSACTION            = 1U << 9,
 	BINDER_DEBUG_TRANSACTION_COMPLETE   = 1U << 10,
 	BINDER_DEBUG_FREE_BUFFER            = 1U << 11,
 	BINDER_DEBUG_INTERNAL_REFS          = 1U << 12,
 	BINDER_DEBUG_BUFFER_ALLOC           = 1U << 13,
 	BINDER_DEBUG_PRIORITY_CAP           = 1U << 14,
 	BINDER_DEBUG_BUFFER_ALLOC_ASYNC     = 1U << 15,
 };
 static uint32_t binder_debug_mask = BINDER_DEBUG_USER_ERROR |
 	BINDER_DEBUG_FAILED_TRANSACTION | BINDER_DEBUG_DEAD_TRANSACTION;
 module_param_named(debug_mask, binder_debug_mask, uint, S_IWUSR | S_IRUGO);
 
 static bool binder_debug_no_lock;
 module_param_named(proc_no_lock, binder_debug_no_lock, bool, S_IWUSR | S_IRUGO);
 
+static char *binder_devices_param = CONFIG_ANDROID_BINDER_DEVICES;
+module_param_named(devices, binder_devices_param, charp, 0444);
+
 static DECLARE_WAIT_QUEUE_HEAD(binder_user_error_wait);
 static int binder_stop_on_user_error;
 
 static int binder_set_stop_on_user_error(const char *val,
 					 struct kernel_param *kp)
 {
 	int ret;
 
 	ret = param_set_int(val, kp);
 	if (binder_stop_on_user_error < 2)
 		wake_up(&binder_user_error_wait);
 	return ret;
 }
 module_param_call(stop_on_user_error, binder_set_stop_on_user_error,
 	param_get_int, &binder_stop_on_user_error, S_IWUSR | S_IRUGO);
 
 #define binder_debug(mask, x...) \
 	do { \
 		if (binder_debug_mask & mask) \
 			pr_info(x); \
 	} while (0)
 
 #define binder_user_error(x...) \
 	do { \
 		if (binder_debug_mask & BINDER_DEBUG_USER_ERROR) \
 			pr_info(x); \
 		if (binder_stop_on_user_error) \
 			binder_stop_on_user_error = 2; \
 	} while (0)
 
+#define to_flat_binder_object(hdr) \
+	container_of(hdr, struct flat_binder_object, hdr)
+
+#define to_binder_fd_object(hdr) container_of(hdr, struct binder_fd_object, hdr)
+
+#define to_binder_buffer_object(hdr) \
+	container_of(hdr, struct binder_buffer_object, hdr)
+
+#define to_binder_fd_array_object(hdr) \
+	container_of(hdr, struct binder_fd_array_object, hdr)
+
 enum binder_stat_types {
 	BINDER_STAT_PROC,
 	BINDER_STAT_THREAD,
 	BINDER_STAT_NODE,
 	BINDER_STAT_REF,
 	BINDER_STAT_DEATH,
 	BINDER_STAT_TRANSACTION,
 	BINDER_STAT_TRANSACTION_COMPLETE,
 	BINDER_STAT_COUNT
 };
 
 struct binder_stats {
 	int br[_IOC_NR(BR_FAILED_REPLY) + 1];
-	int bc[_IOC_NR(BC_DEAD_BINDER_DONE) + 1];
+	int bc[_IOC_NR(BC_REPLY_SG) + 1];
 	int obj_created[BINDER_STAT_COUNT];
 	int obj_deleted[BINDER_STAT_COUNT];
 };
 
 static struct binder_stats binder_stats;
 
 static inline void binder_stats_deleted(enum binder_stat_types type)
 {
 	binder_stats.obj_deleted[type]++;
 }
 
 static inline void binder_stats_created(enum binder_stat_types type)
 {
 	binder_stats.obj_created[type]++;
 }
 
 struct binder_transaction_log_entry {
 	int debug_id;
 	int call_type;
 	int from_proc;
 	int from_thread;
 	int target_handle;
 	int to_proc;
 	int to_thread;
 	int to_node;
 	int data_size;
 	int offsets_size;
+	const char *context_name;
 };
 struct binder_transaction_log {
 	int next;
 	int full;
 	struct binder_transaction_log_entry entry[32];
 };
 static struct binder_transaction_log binder_transaction_log;
 static struct binder_transaction_log binder_transaction_log_failed;
 
 static struct binder_transaction_log_entry *binder_transaction_log_add(
 	struct binder_transaction_log *log)
 {
 	struct binder_transaction_log_entry *e;
 
 	e = &log->entry[log->next];
 	memset(e, 0, sizeof(*e));
 	log->next++;
 	if (log->next == ARRAY_SIZE(log->entry)) {
 		log->next = 0;
 		log->full = 1;
 	}
 	return e;
 }
 
+struct binder_context {
+	struct binder_node *binder_context_mgr_node;
+	kuid_t binder_context_mgr_uid;
+	const char *name;
+};
+
+struct binder_device {
+	struct hlist_node hlist;
+	struct miscdevice miscdev;
+	struct binder_context context;
+};
+
 struct binder_work {
 	struct list_head entry;
 	enum {
 		BINDER_WORK_TRANSACTION = 1,
 		BINDER_WORK_TRANSACTION_COMPLETE,
 		BINDER_WORK_NODE,
 		BINDER_WORK_DEAD_BINDER,
 		BINDER_WORK_DEAD_BINDER_AND_CLEAR,
 		BINDER_WORK_CLEAR_DEATH_NOTIFICATION,
 	} type;
 };
 
 struct binder_node {
 	int debug_id;
 	struct binder_work work;
 	union {
 		struct rb_node rb_node;
 		struct hlist_node dead_node;
 	};
 	struct binder_proc *proc;
 	struct hlist_head refs;
 	int internal_strong_refs;
 	int local_weak_refs;
 	int local_strong_refs;
 	binder_uintptr_t ptr;
 	binder_uintptr_t cookie;
 	unsigned has_strong_ref:1;
 	unsigned pending_strong_ref:1;
 	unsigned has_weak_ref:1;
 	unsigned pending_weak_ref:1;
 	unsigned has_async_transaction:1;
 	unsigned accept_fds:1;
 	unsigned min_priority:8;
 	struct list_head async_todo;
 };
 
 struct binder_ref_death {
 	struct binder_work work;
 	binder_uintptr_t cookie;
 };
 
 struct binder_ref {
 	/* Lookups needed: */
 	/*   node + proc => ref (transaction) */
 	/*   desc + proc => ref (transaction, inc/dec ref) */
 	/*   node => refs + procs (proc exit) */
 	int debug_id;
 	struct rb_node rb_node_desc;
 	struct rb_node rb_node_node;
 	struct hlist_node node_entry;
 	struct binder_proc *proc;
 	struct binder_node *node;
 	uint32_t desc;
 	int strong;
 	int weak;
 	struct binder_ref_death *death;
 };
 
 struct binder_buffer {
 	struct list_head entry; /* free and allocated entries by address */
 	struct rb_node rb_node; /* free entry by size or allocated entry */
 				/* by address */
 	unsigned free:1;
 	unsigned allow_user_free:1;
 	unsigned async_transaction:1;
 	unsigned debug_id:29;
 
 	struct binder_transaction *transaction;
 
 	struct binder_node *target_node;
 	size_t data_size;
 	size_t offsets_size;
+	size_t extra_buffers_size;
 	uint8_t data[0];
 };
 
 enum binder_deferred_state {
 	BINDER_DEFERRED_PUT_FILES    = 0x01,
 	BINDER_DEFERRED_FLUSH        = 0x02,
 	BINDER_DEFERRED_RELEASE      = 0x04,
 };
 
 struct binder_proc {
 	struct hlist_node proc_node;
 	struct rb_root threads;
 	struct rb_root nodes;
 	struct rb_root refs_by_desc;
 	struct rb_root refs_by_node;
 	int pid;
 	struct vm_area_struct *vma;
 	struct mm_struct *vma_vm_mm;
 	struct task_struct *tsk;
 	struct files_struct *files;
 	struct hlist_node deferred_work_node;
 	int deferred_work;
 	void *buffer;
 	ptrdiff_t user_buffer_offset;
 
 	struct list_head buffers;
 	struct rb_root free_buffers;
 	struct rb_root allocated_buffers;
 	size_t free_async_space;
 
 	struct page **pages;
 	size_t buffer_size;
 	uint32_t buffer_free;
 	struct list_head todo;
 	wait_queue_head_t wait;
 	struct binder_stats stats;
 	struct list_head delivered_death;
 	int max_threads;
 	int requested_threads;
 	int requested_threads_started;
 	int ready_threads;
 	long default_priority;
 	struct dentry *debugfs_entry;
+	struct binder_context *context;
 };
 
 enum {
 	BINDER_LOOPER_STATE_REGISTERED  = 0x01,
 	BINDER_LOOPER_STATE_ENTERED     = 0x02,
 	BINDER_LOOPER_STATE_EXITED      = 0x04,
 	BINDER_LOOPER_STATE_INVALID     = 0x08,
 	BINDER_LOOPER_STATE_WAITING     = 0x10,
 	BINDER_LOOPER_STATE_NEED_RETURN = 0x20
 };
 
 struct binder_thread {
 	struct binder_proc *proc;
 	struct rb_node rb_node;
 	int pid;
 	int looper;
 	struct binder_transaction *transaction_stack;
 	struct list_head todo;
 	uint32_t return_error; /* Write failed, return error code in read buf */
 	uint32_t return_error2; /* Write failed, return error code in read */
 		/* buffer. Used when sending a reply to a dead process that */
 		/* we are also waiting on */
 	wait_queue_head_t wait;
 	struct binder_stats stats;
 };
 
 struct binder_transaction {
 	int debug_id;
 	struct binder_work work;
 	struct binder_thread *from;
 	struct binder_transaction *from_parent;
 	struct binder_proc *to_proc;
 	struct binder_thread *to_thread;
 	struct binder_transaction *to_parent;
 	unsigned need_reply:1;
 	/* unsigned is_dead:1; */	/* not used at the moment */
 
 	struct binder_buffer *buffer;
 	unsigned int	code;
 	unsigned int	flags;
 	long	priority;
 	long	saved_priority;
 	kuid_t	sender_euid;
 };
 
 static void
 binder_defer_work(struct binder_proc *proc, enum binder_deferred_state defer);
 
 static int task_get_unused_fd_flags(struct binder_proc *proc, int flags)
 {
 	struct files_struct *files = proc->files;
 	unsigned long rlim_cur;
 	unsigned long irqs;
 
 	if (files == NULL)
 		return -ESRCH;
 
 	if (!lock_task_sighand(proc->tsk, &irqs))
 		return -EMFILE;
 
 	rlim_cur = task_rlimit(proc->tsk, RLIMIT_NOFILE);
 	unlock_task_sighand(proc->tsk, &irqs);
 
 	return __alloc_fd(files, 0, rlim_cur, flags);
 }
 
 /*
  * copied from fd_install
  */
 static void task_fd_install(
 	struct binder_proc *proc, unsigned int fd, struct file *file)
 {
 	if (proc->files)
 		__fd_install(proc->files, fd, file);
 }
 
 /*
  * copied from sys_close
  */
 static long task_close_fd(struct binder_proc *proc, unsigned int fd)
 {
 	int retval;
 
 	if (proc->files == NULL)
 		return -ESRCH;
 
 	retval = __close_fd(proc->files, fd);
 	/* can't restart close syscall because file table entry was cleared */
 	if (unlikely(retval == -ERESTARTSYS ||
 		     retval == -ERESTARTNOINTR ||
 		     retval == -ERESTARTNOHAND ||
 		     retval == -ERESTART_RESTARTBLOCK))
 		retval = -EINTR;
 
 	return retval;
 }
 
 static inline void binder_lock(const char *tag)
 {
 	trace_binder_lock(tag);
 	mutex_lock(&binder_main_lock);
 	trace_binder_locked(tag);
 }
 
 static inline void binder_unlock(const char *tag)
 {
 	trace_binder_unlock(tag);
 	mutex_unlock(&binder_main_lock);
 }
 
 static void binder_set_nice(long nice)
 {
 	long min_nice;
 
 	if (can_nice(current, nice)) {
 		set_user_nice(current, nice);
 		return;
 	}
 	min_nice = rlimit_to_nice(current->signal->rlim[RLIMIT_NICE].rlim_cur);
 	binder_debug(BINDER_DEBUG_PRIORITY_CAP,
 		     "%d: nice value %ld not allowed use %ld instead\n",
 		      current->pid, nice, min_nice);
 	set_user_nice(current, min_nice);
 	if (min_nice <= MAX_NICE)
 		return;
 	binder_user_error("%d RLIMIT_NICE not set\n", current->pid);
 }
 
 static size_t binder_buffer_size(struct binder_proc *proc,
 				 struct binder_buffer *buffer)
 {
 	if (list_is_last(&buffer->entry, &proc->buffers))
 		return proc->buffer + proc->buffer_size - (void *)buffer->data;
 	return (size_t)list_entry(buffer->entry.next,
 			  struct binder_buffer, entry) - (size_t)buffer->data;
 }
 
 static void binder_insert_free_buffer(struct binder_proc *proc,
 				      struct binder_buffer *new_buffer)
 {
 	struct rb_node **p = &proc->free_buffers.rb_node;
 	struct rb_node *parent = NULL;
 	struct binder_buffer *buffer;
 	size_t buffer_size;
 	size_t new_buffer_size;
 
 	BUG_ON(!new_buffer->free);
 
 	new_buffer_size = binder_buffer_size(proc, new_buffer);
 
 	binder_debug(BINDER_DEBUG_BUFFER_ALLOC,
 		     "%d: add free buffer, size %zd, at %p\n",
 		      proc->pid, new_buffer_size, new_buffer);
 
 	while (*p) {
 		parent = *p;
 		buffer = rb_entry(parent, struct binder_buffer, rb_node);
 		BUG_ON(!buffer->free);
 
 		buffer_size = binder_buffer_size(proc, buffer);
 
 		if (new_buffer_size < buffer_size)
 			p = &parent->rb_left;
 		else
 			p = &parent->rb_right;
 	}
 	rb_link_node(&new_buffer->rb_node, parent, p);
 	rb_insert_color(&new_buffer->rb_node, &proc->free_buffers);
 }
 
 static void binder_insert_allocated_buffer(struct binder_proc *proc,
 					   struct binder_buffer *new_buffer)
 {
 	struct rb_node **p = &proc->allocated_buffers.rb_node;
 	struct rb_node *parent = NULL;
 	struct binder_buffer *buffer;
 
 	BUG_ON(new_buffer->free);
 
 	while (*p) {
 		parent = *p;
 		buffer = rb_entry(parent, struct binder_buffer, rb_node);
 		BUG_ON(buffer->free);
 
 		if (new_buffer < buffer)
 			p = &parent->rb_left;
 		else if (new_buffer > buffer)
 			p = &parent->rb_right;
 		else
 			BUG();
 	}
 	rb_link_node(&new_buffer->rb_node, parent, p);
 	rb_insert_color(&new_buffer->rb_node, &proc->allocated_buffers);
 }
 
 static struct binder_buffer *binder_buffer_lookup(struct binder_proc *proc,
 						  uintptr_t user_ptr)
 {
 	struct rb_node *n = proc->allocated_buffers.rb_node;
 	struct binder_buffer *buffer;
 	struct binder_buffer *kern_ptr;
 
 	kern_ptr = (struct binder_buffer *)(user_ptr - proc->user_buffer_offset
 		- offsetof(struct binder_buffer, data));
 
 	while (n) {
 		buffer = rb_entry(n, struct binder_buffer, rb_node);
 		BUG_ON(buffer->free);
 
 		if (kern_ptr < buffer)
 			n = n->rb_left;
 		else if (kern_ptr > buffer)
 			n = n->rb_right;
 		else
 			return buffer;
 	}
 	return NULL;
 }
 
 static int binder_update_page_range(struct binder_proc *proc, int allocate,
 				    void *start, void *end,
 				    struct vm_area_struct *vma)
 {
 	void *page_addr;
 	unsigned long user_page_addr;
 	struct page **page;
 	struct mm_struct *mm;
 
 	binder_debug(BINDER_DEBUG_BUFFER_ALLOC,
 		     "%d: %s pages %p-%p\n", proc->pid,
 		     allocate ? "allocate" : "free", start, end);
 
 	if (end <= start)
 		return 0;
 
 	trace_binder_update_page_range(proc, allocate, start, end);
 
 	if (vma)
 		mm = NULL;
 	else
 		mm = get_task_mm(proc->tsk);
 
 	if (mm) {
 		down_write(&mm->mmap_sem);
 		vma = proc->vma;
 		if (vma && mm != proc->vma_vm_mm) {
 			pr_err("%d: vma mm and task mm mismatch\n",
 				proc->pid);
 			vma = NULL;
 		}
 	}
 
 	if (allocate == 0)
 		goto free_range;
 
 	if (vma == NULL) {
 		pr_err("%d: binder_alloc_buf failed to map pages in userspace, no vma\n",
 			proc->pid);
 		goto err_no_vma;
 	}
 
 	for (page_addr = start; page_addr < end; page_addr += PAGE_SIZE) {
 		int ret;
 
 		page = &proc->pages[(page_addr - proc->buffer) / PAGE_SIZE];
 
 		BUG_ON(*page);
 		*page = alloc_page(GFP_KERNEL | __GFP_HIGHMEM | __GFP_ZERO);
 		if (*page == NULL) {
 			pr_err("%d: binder_alloc_buf failed for page at %p\n",
 				proc->pid, page_addr);
 			goto err_alloc_page_failed;
 		}
 		ret = map_kernel_range_noflush((unsigned long)page_addr,
 					PAGE_SIZE, PAGE_KERNEL, page);
 		flush_cache_vmap((unsigned long)page_addr,
 				(unsigned long)page_addr + PAGE_SIZE);
 		if (ret != 1) {
 			pr_err("%d: binder_alloc_buf failed to map page at %p in kernel\n",
 			       proc->pid, page_addr);
 			goto err_map_kernel_failed;
 		}
 		user_page_addr =
 			(uintptr_t)page_addr + proc->user_buffer_offset;
 		ret = vm_insert_page(vma, user_page_addr, page[0]);
 		if (ret) {
 			pr_err("%d: binder_alloc_buf failed to map page at %lx in userspace\n",
 			       proc->pid, user_page_addr);
 			goto err_vm_insert_page_failed;
 		}
 		/* vm_insert_page does not seem to increment the refcount */
 	}
 	if (mm) {
 		up_write(&mm->mmap_sem);
 		mmput(mm);
 	}
 	return 0;
 
 free_range:
 	for (page_addr = end - PAGE_SIZE; page_addr >= start;
 	     page_addr -= PAGE_SIZE) {
 		page = &proc->pages[(page_addr - proc->buffer) / PAGE_SIZE];
 		if (vma)
 			zap_page_range(vma, (uintptr_t)page_addr +
 				proc->user_buffer_offset, PAGE_SIZE, NULL);
 err_vm_insert_page_failed:
 		unmap_kernel_range((unsigned long)page_addr, PAGE_SIZE);
 err_map_kernel_failed:
 		__free_page(*page);
 		*page = NULL;
 err_alloc_page_failed:
 		;
 	}
 err_no_vma:
 	if (mm) {
 		up_write(&mm->mmap_sem);
 		mmput(mm);
 	}
 	return -ENOMEM;
 }
 
 static struct binder_buffer *binder_alloc_buf(struct binder_proc *proc,
 					      size_t data_size,
-					      size_t offsets_size, int is_async)
+					      size_t offsets_size,
+					      size_t extra_buffers_size,
+					      int is_async)
 {
 	struct rb_node *n = proc->free_buffers.rb_node;
 	struct binder_buffer *buffer;
 	size_t buffer_size;
 	struct rb_node *best_fit = NULL;
 	void *has_page_addr;
 	void *end_page_addr;
-	size_t size;
+	size_t size, data_offsets_size;
 
 	if (proc->vma == NULL) {
 		pr_err("%d: binder_alloc_buf, no vma\n",
 		       proc->pid);
 		return NULL;
 	}
 
-	size = ALIGN(data_size, sizeof(void *)) +
+	data_offsets_size = ALIGN(data_size, sizeof(void *)) +
 		ALIGN(offsets_size, sizeof(void *));
 
-	if (size < data_size || size < offsets_size) {
+	if (data_offsets_size < data_size || data_offsets_size < offsets_size) {
 		binder_user_error("%d: got transaction with invalid size %zd-%zd\n",
 				proc->pid, data_size, offsets_size);
 		return NULL;
 	}
-
+	size = data_offsets_size + ALIGN(extra_buffers_size, sizeof(void *));
+	if (size < data_offsets_size || size < extra_buffers_size) {
+		binder_user_error("%d: got transaction with invalid extra_buffers_size %zd\n",
+				  proc->pid, extra_buffers_size);
+		return NULL;
+	}
 	if (is_async &&
 	    proc->free_async_space < size + sizeof(struct binder_buffer)) {
 		binder_debug(BINDER_DEBUG_BUFFER_ALLOC,
 			     "%d: binder_alloc_buf size %zd failed, no async space left\n",
 			      proc->pid, size);
 		return NULL;
 	}
 
 	while (n) {
 		buffer = rb_entry(n, struct binder_buffer, rb_node);
 		BUG_ON(!buffer->free);
 		buffer_size = binder_buffer_size(proc, buffer);
 
 		if (size < buffer_size) {
 			best_fit = n;
 			n = n->rb_left;
 		} else if (size > buffer_size)
 			n = n->rb_right;
 		else {
 			best_fit = n;
 			break;
 		}
 	}
 	if (best_fit == NULL) {
 		pr_err("%d: binder_alloc_buf size %zd failed, no address space\n",
 			proc->pid, size);
 		return NULL;
 	}
 	if (n == NULL) {
 		buffer = rb_entry(best_fit, struct binder_buffer, rb_node);
 		buffer_size = binder_buffer_size(proc, buffer);
 	}
 
 	binder_debug(BINDER_DEBUG_BUFFER_ALLOC,
 		     "%d: binder_alloc_buf size %zd got buffer %p size %zd\n",
 		      proc->pid, size, buffer, buffer_size);
 
 	has_page_addr =
 		(void *)(((uintptr_t)buffer->data + buffer_size) & PAGE_MASK);
 	if (n == NULL) {
 		if (size + sizeof(struct binder_buffer) + 4 >= buffer_size)
 			buffer_size = size; /* no room for other buffers */
 		else
 			buffer_size = size + sizeof(struct binder_buffer);
 	}
 	end_page_addr =
 		(void *)PAGE_ALIGN((uintptr_t)buffer->data + buffer_size);
 	if (end_page_addr > has_page_addr)
 		end_page_addr = has_page_addr;
 	if (binder_update_page_range(proc, 1,
 	    (void *)PAGE_ALIGN((uintptr_t)buffer->data), end_page_addr, NULL))
 		return NULL;
 
 	rb_erase(best_fit, &proc->free_buffers);
 	buffer->free = 0;
 	binder_insert_allocated_buffer(proc, buffer);
 	if (buffer_size != size) {
 		struct binder_buffer *new_buffer = (void *)buffer->data + size;
 
 		list_add(&new_buffer->entry, &buffer->entry);
 		new_buffer->free = 1;
 		binder_insert_free_buffer(proc, new_buffer);
 	}
 	binder_debug(BINDER_DEBUG_BUFFER_ALLOC,
 		     "%d: binder_alloc_buf size %zd got %p\n",
 		      proc->pid, size, buffer);
 	buffer->data_size = data_size;
 	buffer->offsets_size = offsets_size;
+	buffer->extra_buffers_size = extra_buffers_size;
 	buffer->async_transaction = is_async;
 	if (is_async) {
 		proc->free_async_space -= size + sizeof(struct binder_buffer);
 		binder_debug(BINDER_DEBUG_BUFFER_ALLOC_ASYNC,
 			     "%d: binder_alloc_buf size %zd async free %zd\n",
 			      proc->pid, size, proc->free_async_space);
 	}
 
 	return buffer;
 }
 
 static void *buffer_start_page(struct binder_buffer *buffer)
 {
 	return (void *)((uintptr_t)buffer & PAGE_MASK);
 }
 
 static void *buffer_end_page(struct binder_buffer *buffer)
 {
 	return (void *)(((uintptr_t)(buffer + 1) - 1) & PAGE_MASK);
 }
 
 static void binder_delete_free_buffer(struct binder_proc *proc,
 				      struct binder_buffer *buffer)
 {
 	struct binder_buffer *prev, *next = NULL;
 	int free_page_end = 1;
 	int free_page_start = 1;
 
 	BUG_ON(proc->buffers.next == &buffer->entry);
 	prev = list_entry(buffer->entry.prev, struct binder_buffer, entry);
 	BUG_ON(!prev->free);
 	if (buffer_end_page(prev) == buffer_start_page(buffer)) {
 		free_page_start = 0;
 		if (buffer_end_page(prev) == buffer_end_page(buffer))
 			free_page_end = 0;
 		binder_debug(BINDER_DEBUG_BUFFER_ALLOC,
 			     "%d: merge free, buffer %p share page with %p\n",
 			      proc->pid, buffer, prev);
 	}
 
 	if (!list_is_last(&buffer->entry, &proc->buffers)) {
 		next = list_entry(buffer->entry.next,
 				  struct binder_buffer, entry);
 		if (buffer_start_page(next) == buffer_end_page(buffer)) {
 			free_page_end = 0;
 			if (buffer_start_page(next) ==
 			    buffer_start_page(buffer))
 				free_page_start = 0;
 			binder_debug(BINDER_DEBUG_BUFFER_ALLOC,
 				     "%d: merge free, buffer %p share page with %p\n",
 				      proc->pid, buffer, prev);
 		}
 	}
 	list_del(&buffer->entry);
 	if (free_page_start || free_page_end) {
 		binder_debug(BINDER_DEBUG_BUFFER_ALLOC,
 			     "%d: merge free, buffer %p do not share page%s%s with %p or %p\n",
 			     proc->pid, buffer, free_page_start ? "" : " end",
 			     free_page_end ? "" : " start", prev, next);
 		binder_update_page_range(proc, 0, free_page_start ?
 			buffer_start_page(buffer) : buffer_end_page(buffer),
 			(free_page_end ? buffer_end_page(buffer) :
 			buffer_start_page(buffer)) + PAGE_SIZE, NULL);
 	}
 }
 
 static void binder_free_buf(struct binder_proc *proc,
 			    struct binder_buffer *buffer)
 {
 	size_t size, buffer_size;
 
 	buffer_size = binder_buffer_size(proc, buffer);
 
 	size = ALIGN(buffer->data_size, sizeof(void *)) +
-		ALIGN(buffer->offsets_size, sizeof(void *));
+		ALIGN(buffer->offsets_size, sizeof(void *)) +
+		ALIGN(buffer->extra_buffers_size, sizeof(void *));
 
 	binder_debug(BINDER_DEBUG_BUFFER_ALLOC,
 		     "%d: binder_free_buf %p size %zd buffer_size %zd\n",
 		      proc->pid, buffer, size, buffer_size);
 
 	BUG_ON(buffer->free);
 	BUG_ON(size > buffer_size);
 	BUG_ON(buffer->transaction != NULL);
 	BUG_ON((void *)buffer < proc->buffer);
 	BUG_ON((void *)buffer > proc->buffer + proc->buffer_size);
 
 	if (buffer->async_transaction) {
 		proc->free_async_space += size + sizeof(struct binder_buffer);
 
 		binder_debug(BINDER_DEBUG_BUFFER_ALLOC_ASYNC,
 			     "%d: binder_free_buf size %zd async free %zd\n",
 			      proc->pid, size, proc->free_async_space);
 	}
 
 	binder_update_page_range(proc, 0,
 		(void *)PAGE_ALIGN((uintptr_t)buffer->data),
 		(void *)(((uintptr_t)buffer->data + buffer_size) & PAGE_MASK),
 		NULL);
 	rb_erase(&buffer->rb_node, &proc->allocated_buffers);
 	buffer->free = 1;
 	if (!list_is_last(&buffer->entry, &proc->buffers)) {
 		struct binder_buffer *next = list_entry(buffer->entry.next,
 						struct binder_buffer, entry);
 
 		if (next->free) {
 			rb_erase(&next->rb_node, &proc->free_buffers);
 			binder_delete_free_buffer(proc, next);
 		}
 	}
 	if (proc->buffers.next != &buffer->entry) {
 		struct binder_buffer *prev = list_entry(buffer->entry.prev,
 						struct binder_buffer, entry);
 
 		if (prev->free) {
 			binder_delete_free_buffer(proc, buffer);
 			rb_erase(&prev->rb_node, &proc->free_buffers);
 			buffer = prev;
 		}
 	}
 	binder_insert_free_buffer(proc, buffer);
 }
 
 static struct binder_node *binder_get_node(struct binder_proc *proc,
 					   binder_uintptr_t ptr)
 {
 	struct rb_node *n = proc->nodes.rb_node;
 	struct binder_node *node;
 
 	while (n) {
 		node = rb_entry(n, struct binder_node, rb_node);
 
 		if (ptr < node->ptr)
 			n = n->rb_left;
 		else if (ptr > node->ptr)
 			n = n->rb_right;
 		else
 			return node;
 	}
 	return NULL;
 }
 
 static struct binder_node *binder_new_node(struct binder_proc *proc,
 					   binder_uintptr_t ptr,
 					   binder_uintptr_t cookie)
 {
 	struct rb_node **p = &proc->nodes.rb_node;
 	struct rb_node *parent = NULL;
 	struct binder_node *node;
 
 	while (*p) {
 		parent = *p;
 		node = rb_entry(parent, struct binder_node, rb_node);
 
 		if (ptr < node->ptr)
 			p = &(*p)->rb_left;
 		else if (ptr > node->ptr)
 			p = &(*p)->rb_right;
 		else
 			return NULL;
 	}
 
 	node = kzalloc(sizeof(*node), GFP_KERNEL);
 	if (node == NULL)
 		return NULL;
 	binder_stats_created(BINDER_STAT_NODE);
 	rb_link_node(&node->rb_node, parent, p);
 	rb_insert_color(&node->rb_node, &proc->nodes);
 	node->debug_id = ++binder_last_id;
 	node->proc = proc;
 	node->ptr = ptr;
 	node->cookie = cookie;
 	node->work.type = BINDER_WORK_NODE;
 	INIT_LIST_HEAD(&node->work.entry);
 	INIT_LIST_HEAD(&node->async_todo);
 	binder_debug(BINDER_DEBUG_INTERNAL_REFS,
 		     "%d:%d node %d u%016llx c%016llx created\n",
 		     proc->pid, current->pid, node->debug_id,
 		     (u64)node->ptr, (u64)node->cookie);
 	return node;
 }
 
 static int binder_inc_node(struct binder_node *node, int strong, int internal,
 			   struct list_head *target_list)
 {
 	if (strong) {
 		if (internal) {
 			if (target_list == NULL &&
 			    node->internal_strong_refs == 0 &&
-			    !(node == binder_context_mgr_node &&
-			    node->has_strong_ref)) {
+			    !(node->proc &&
+			      node == node->proc->context->binder_context_mgr_node &&
+			      node->has_strong_ref)) {
 				pr_err("invalid inc strong node for %d\n",
 					node->debug_id);
 				return -EINVAL;
 			}
 			node->internal_strong_refs++;
 		} else
 			node->local_strong_refs++;
 		if (!node->has_strong_ref && target_list) {
 			list_del_init(&node->work.entry);
 			list_add_tail(&node->work.entry, target_list);
 		}
 	} else {
 		if (!internal)
 			node->local_weak_refs++;
 		if (!node->has_weak_ref && list_empty(&node->work.entry)) {
 			if (target_list == NULL) {
 				pr_err("invalid inc weak node for %d\n",
 					node->debug_id);
 				return -EINVAL;
 			}
 			list_add_tail(&node->work.entry, target_list);
 		}
 	}
 	return 0;
 }
 
 static int binder_dec_node(struct binder_node *node, int strong, int internal)
 {
 	if (strong) {
 		if (internal)
 			node->internal_strong_refs--;
 		else
 			node->local_strong_refs--;
 		if (node->local_strong_refs || node->internal_strong_refs)
 			return 0;
 	} else {
 		if (!internal)
 			node->local_weak_refs--;
 		if (node->local_weak_refs || !hlist_empty(&node->refs))
 			return 0;
 	}
 	if (node->proc && (node->has_strong_ref || node->has_weak_ref)) {
 		if (list_empty(&node->work.entry)) {
 			list_add_tail(&node->work.entry, &node->proc->todo);
 			wake_up_interruptible(&node->proc->wait);
 		}
 	} else {
 		if (hlist_empty(&node->refs) && !node->local_strong_refs &&
 		    !node->local_weak_refs) {
 			list_del_init(&node->work.entry);
 			if (node->proc) {
 				rb_erase(&node->rb_node, &node->proc->nodes);
 				binder_debug(BINDER_DEBUG_INTERNAL_REFS,
 					     "refless node %d deleted\n",
 					     node->debug_id);
 			} else {
 				hlist_del(&node->dead_node);
 				binder_debug(BINDER_DEBUG_INTERNAL_REFS,
 					     "dead node %d deleted\n",
 					     node->debug_id);
 			}
 			kfree(node);
 			binder_stats_deleted(BINDER_STAT_NODE);
 		}
 	}
 
 	return 0;
 }
 
 
 static struct binder_ref *binder_get_ref(struct binder_proc *proc,
 					 u32 desc, bool need_strong_ref)
 {
 	struct rb_node *n = proc->refs_by_desc.rb_node;
 	struct binder_ref *ref;
 
 	while (n) {
 		ref = rb_entry(n, struct binder_ref, rb_node_desc);
 
 		if (desc < ref->desc) {
 			n = n->rb_left;
 		} else if (desc > ref->desc) {
 			n = n->rb_right;
 		} else if (need_strong_ref && !ref->strong) {
 			binder_user_error("tried to use weak ref as strong ref\n");
 			return NULL;
 		} else {
 			return ref;
 		}
 	}
 	return NULL;
 }
 
 static struct binder_ref *binder_get_ref_for_node(struct binder_proc *proc,
 						  struct binder_node *node)
 {
 	struct rb_node *n;
 	struct rb_node **p = &proc->refs_by_node.rb_node;
 	struct rb_node *parent = NULL;
 	struct binder_ref *ref, *new_ref;
+	struct binder_context *context = proc->context;
 
 	while (*p) {
 		parent = *p;
 		ref = rb_entry(parent, struct binder_ref, rb_node_node);
 
 		if (node < ref->node)
 			p = &(*p)->rb_left;
 		else if (node > ref->node)
 			p = &(*p)->rb_right;
 		else
 			return ref;
 	}
 	new_ref = kzalloc(sizeof(*ref), GFP_KERNEL);
 	if (new_ref == NULL)
 		return NULL;
 	binder_stats_created(BINDER_STAT_REF);
 	new_ref->debug_id = ++binder_last_id;
 	new_ref->proc = proc;
 	new_ref->node = node;
 	rb_link_node(&new_ref->rb_node_node, parent, p);
 	rb_insert_color(&new_ref->rb_node_node, &proc->refs_by_node);
 
-	new_ref->desc = (node == binder_context_mgr_node) ? 0 : 1;
+	new_ref->desc = (node == context->binder_context_mgr_node) ? 0 : 1;
 	for (n = rb_first(&proc->refs_by_desc); n != NULL; n = rb_next(n)) {
 		ref = rb_entry(n, struct binder_ref, rb_node_desc);
 		if (ref->desc > new_ref->desc)
 			break;
 		new_ref->desc = ref->desc + 1;
 	}
 
 	p = &proc->refs_by_desc.rb_node;
 	while (*p) {
 		parent = *p;
 		ref = rb_entry(parent, struct binder_ref, rb_node_desc);
 
 		if (new_ref->desc < ref->desc)
 			p = &(*p)->rb_left;
 		else if (new_ref->desc > ref->desc)
 			p = &(*p)->rb_right;
 		else
 			BUG();
 	}
 	rb_link_node(&new_ref->rb_node_desc, parent, p);
 	rb_insert_color(&new_ref->rb_node_desc, &proc->refs_by_desc);
 	if (node) {
 		hlist_add_head(&new_ref->node_entry, &node->refs);
 
 		binder_debug(BINDER_DEBUG_INTERNAL_REFS,
 			     "%d new ref %d desc %d for node %d\n",
 			      proc->pid, new_ref->debug_id, new_ref->desc,
 			      node->debug_id);
 	} else {
 		binder_debug(BINDER_DEBUG_INTERNAL_REFS,
 			     "%d new ref %d desc %d for dead node\n",
 			      proc->pid, new_ref->debug_id, new_ref->desc);
 	}
 	return new_ref;
 }
 
 static void binder_delete_ref(struct binder_ref *ref)
 {
 	binder_debug(BINDER_DEBUG_INTERNAL_REFS,
 		     "%d delete ref %d desc %d for node %d\n",
 		      ref->proc->pid, ref->debug_id, ref->desc,
 		      ref->node->debug_id);
 
 	rb_erase(&ref->rb_node_desc, &ref->proc->refs_by_desc);
 	rb_erase(&ref->rb_node_node, &ref->proc->refs_by_node);
 	if (ref->strong)
 		binder_dec_node(ref->node, 1, 1);
 	hlist_del(&ref->node_entry);
 	binder_dec_node(ref->node, 0, 1);
 	if (ref->death) {
 		binder_debug(BINDER_DEBUG_DEAD_BINDER,
 			     "%d delete ref %d desc %d has death notification\n",
 			      ref->proc->pid, ref->debug_id, ref->desc);
 		list_del(&ref->death->work.entry);
 		kfree(ref->death);
 		binder_stats_deleted(BINDER_STAT_DEATH);
 	}
 	kfree(ref);
 	binder_stats_deleted(BINDER_STAT_REF);
 }
 
 static int binder_inc_ref(struct binder_ref *ref, int strong,
 			  struct list_head *target_list)
 {
 	int ret;
 
 	if (strong) {
 		if (ref->strong == 0) {
 			ret = binder_inc_node(ref->node, 1, 1, target_list);
 			if (ret)
 				return ret;
 		}
 		ref->strong++;
 	} else {
 		if (ref->weak == 0) {
 			ret = binder_inc_node(ref->node, 0, 1, target_list);
 			if (ret)
 				return ret;
 		}
 		ref->weak++;
 	}
 	return 0;
 }
 
 
 static int binder_dec_ref(struct binder_ref *ref, int strong)
 {
 	if (strong) {
 		if (ref->strong == 0) {
 			binder_user_error("%d invalid dec strong, ref %d desc %d s %d w %d\n",
 					  ref->proc->pid, ref->debug_id,
 					  ref->desc, ref->strong, ref->weak);
 			return -EINVAL;
 		}
 		ref->strong--;
 		if (ref->strong == 0) {
 			int ret;
 
 			ret = binder_dec_node(ref->node, strong, 1);
 			if (ret)
 				return ret;
 		}
 	} else {
 		if (ref->weak == 0) {
 			binder_user_error("%d invalid dec weak, ref %d desc %d s %d w %d\n",
 					  ref->proc->pid, ref->debug_id,
 					  ref->desc, ref->strong, ref->weak);
 			return -EINVAL;
 		}
 		ref->weak--;
 	}
 	if (ref->strong == 0 && ref->weak == 0)
 		binder_delete_ref(ref);
 	return 0;
 }
 
 static void binder_pop_transaction(struct binder_thread *target_thread,
 				   struct binder_transaction *t)
 {
 	if (target_thread) {
 		BUG_ON(target_thread->transaction_stack != t);
 		BUG_ON(target_thread->transaction_stack->from != target_thread);
 		target_thread->transaction_stack =
 			target_thread->transaction_stack->from_parent;
 		t->from = NULL;
 	}
 	t->need_reply = 0;
 	if (t->buffer)
 		t->buffer->transaction = NULL;
 	kfree(t);
 	binder_stats_deleted(BINDER_STAT_TRANSACTION);
 }
 
 static void binder_send_failed_reply(struct binder_transaction *t,
 				     uint32_t error_code)
 {
 	struct binder_thread *target_thread;
 	struct binder_transaction *next;
 
 	BUG_ON(t->flags & TF_ONE_WAY);
 	while (1) {
 		target_thread = t->from;
 		if (target_thread) {
 			if (target_thread->return_error != BR_OK &&
 			   target_thread->return_error2 == BR_OK) {
 				target_thread->return_error2 =
 					target_thread->return_error;
 				target_thread->return_error = BR_OK;
 			}
 			if (target_thread->return_error == BR_OK) {
 				binder_debug(BINDER_DEBUG_FAILED_TRANSACTION,
 					     "send failed reply for transaction %d to %d:%d\n",
 					      t->debug_id,
 					      target_thread->proc->pid,
 					      target_thread->pid);
 
 				binder_pop_transaction(target_thread, t);
 				target_thread->return_error = error_code;
 				wake_up_interruptible(&target_thread->wait);
 			} else {
 				pr_err("reply failed, target thread, %d:%d, has error code %d already\n",
 					target_thread->proc->pid,
 					target_thread->pid,
 					target_thread->return_error);
 			}
 			return;
 		}
 		next = t->from_parent;
 
 		binder_debug(BINDER_DEBUG_FAILED_TRANSACTION,
 			     "send failed reply for transaction %d, target dead\n",
 			     t->debug_id);
 
 		binder_pop_transaction(target_thread, t);
 		if (next == NULL) {
 			binder_debug(BINDER_DEBUG_DEAD_BINDER,
 				     "reply failed, no target thread at root\n");
 			return;
 		}
 		t = next;
 		binder_debug(BINDER_DEBUG_DEAD_BINDER,
 			     "reply failed, no target thread -- retry %d\n",
 			      t->debug_id);
 	}
 }
 
+/**
+ * binder_validate_object() - checks for a valid metadata object in a buffer.
+ * @buffer:	binder_buffer that we're parsing.
+ * @offset:	offset in the buffer at which to validate an object.
+ *
+ * Return:	If there's a valid metadata object at @offset in @buffer, the
+ *		size of that object. Otherwise, it returns zero.
+ */
+static size_t binder_validate_object(struct binder_buffer *buffer, u64 offset)
+{
+	/* Check if we can read a header first */
+	struct binder_object_header *hdr;
+	size_t object_size = 0;
+
+	if (offset > buffer->data_size - sizeof(*hdr) ||
+	    buffer->data_size < sizeof(*hdr) ||
+	    !IS_ALIGNED(offset, sizeof(u32)))
+		return 0;
+
+	/* Ok, now see if we can read a complete object. */
+	hdr = (struct binder_object_header *)(buffer->data + offset);
+	switch (hdr->type) {
+	case BINDER_TYPE_BINDER:
+	case BINDER_TYPE_WEAK_BINDER:
+	case BINDER_TYPE_HANDLE:
+	case BINDER_TYPE_WEAK_HANDLE:
+		object_size = sizeof(struct flat_binder_object);
+		break;
+	case BINDER_TYPE_FD:
+		object_size = sizeof(struct binder_fd_object);
+		break;
+	case BINDER_TYPE_PTR:
+		object_size = sizeof(struct binder_buffer_object);
+		break;
+	case BINDER_TYPE_FDA:
+		object_size = sizeof(struct binder_fd_array_object);
+		break;
+	default:
+		return 0;
+	}
+	if (offset <= buffer->data_size - object_size &&
+	    buffer->data_size >= object_size)
+		return object_size;
+	else
+		return 0;
+}
+
+/**
+ * binder_validate_ptr() - validates binder_buffer_object in a binder_buffer.
+ * @b:		binder_buffer containing the object
+ * @index:	index in offset array at which the binder_buffer_object is
+ *		located
+ * @start:	points to the start of the offset array
+ * @num_valid:	the number of valid offsets in the offset array
+ *
+ * Return:	If @index is within the valid range of the offset array
+ *		described by @start and @num_valid, and if there's a valid
+ *		binder_buffer_object at the offset found in index @index
+ *		of the offset array, that object is returned. Otherwise,
+ *		%NULL is returned.
+ *		Note that the offset found in index @index itself is not
+ *		verified; this function assumes that @num_valid elements
+ *		from @start were previously verified to have valid offsets.
+ */
+static struct binder_buffer_object *binder_validate_ptr(struct binder_buffer *b,
+							binder_size_t index,
+							binder_size_t *start,
+							binder_size_t num_valid)
+{
+	struct binder_buffer_object *buffer_obj;
+	binder_size_t *offp;
+
+	if (index >= num_valid)
+		return NULL;
+
+	offp = start + index;
+	buffer_obj = (struct binder_buffer_object *)(b->data + *offp);
+	if (buffer_obj->hdr.type != BINDER_TYPE_PTR)
+		return NULL;
+
+	return buffer_obj;
+}
+
+/**
+ * binder_validate_fixup() - validates pointer/fd fixups happen in order.
+ * @b:			transaction buffer
+ * @objects_start	start of objects buffer
+ * @buffer:		binder_buffer_object in which to fix up
+ * @offset:		start offset in @buffer to fix up
+ * @last_obj:		last binder_buffer_object that we fixed up in
+ * @last_min_offset:	minimum fixup offset in @last_obj
+ *
+ * Return:		%true if a fixup in buffer @buffer at offset @offset is
+ *			allowed.
+ *
+ * For safety reasons, we only allow fixups inside a buffer to happen
+ * at increasing offsets; additionally, we only allow fixup on the last
+ * buffer object that was verified, or one of its parents.
+ *
+ * Example of what is allowed:
+ *
+ * A
+ *   B (parent = A, offset = 0)
+ *   C (parent = A, offset = 16)
+ *     D (parent = C, offset = 0)
+ *   E (parent = A, offset = 32) // min_offset is 16 (C.parent_offset)
+ *
+ * Examples of what is not allowed:
+ *
+ * Decreasing offsets within the same parent:
+ * A
+ *   C (parent = A, offset = 16)
+ *   B (parent = A, offset = 0) // decreasing offset within A
+ *
+ * Referring to a parent that wasn't the last object or any of its parents:
+ * A
+ *   B (parent = A, offset = 0)
+ *   C (parent = A, offset = 0)
+ *   C (parent = A, offset = 16)
+ *     D (parent = B, offset = 0) // B is not A or any of A's parents
+ */
+static bool binder_validate_fixup(struct binder_buffer *b,
+				  binder_size_t *objects_start,
+				  struct binder_buffer_object *buffer,
+				  binder_size_t fixup_offset,
+				  struct binder_buffer_object *last_obj,
+				  binder_size_t last_min_offset)
+{
+	if (!last_obj) {
+		/* Nothing to fix up in */
+		return false;
+	}
+
+	while (last_obj != buffer) {
+		/*
+		 * Safe to retrieve the parent of last_obj, since it
+		 * was already previously verified by the driver.
+		 */
+		if ((last_obj->flags & BINDER_BUFFER_FLAG_HAS_PARENT) == 0)
+			return false;
+		last_min_offset = last_obj->parent_offset + sizeof(uintptr_t);
+		last_obj = (struct binder_buffer_object *)
+			(b->data + *(objects_start + last_obj->parent));
+	}
+	return (fixup_offset >= last_min_offset);
+}
+
 static void binder_transaction_buffer_release(struct binder_proc *proc,
 					      struct binder_buffer *buffer,
 					      binder_size_t *failed_at)
 {
-	binder_size_t *offp, *off_end;
+	binder_size_t *offp, *off_start, *off_end;
 	int debug_id = buffer->debug_id;
 
 	binder_debug(BINDER_DEBUG_TRANSACTION,
 		     "%d buffer release %d, size %zd-%zd, failed at %p\n",
 		     proc->pid, buffer->debug_id,
 		     buffer->data_size, buffer->offsets_size, failed_at);
 
 	if (buffer->target_node)
 		binder_dec_node(buffer->target_node, 1, 0);
 
-	offp = (binder_size_t *)(buffer->data +
-				 ALIGN(buffer->data_size, sizeof(void *)));
+	off_start = (binder_size_t *)(buffer->data +
+				      ALIGN(buffer->data_size, sizeof(void *)));
 	if (failed_at)
 		off_end = failed_at;
 	else
-		off_end = (void *)offp + buffer->offsets_size;
-	for (; offp < off_end; offp++) {
-		struct flat_binder_object *fp;
+		off_end = (void *)off_start + buffer->offsets_size;
+	for (offp = off_start; offp < off_end; offp++) {
+		struct binder_object_header *hdr;
+		size_t object_size = binder_validate_object(buffer, *offp);
 
-		if (*offp > buffer->data_size - sizeof(*fp) ||
-		    buffer->data_size < sizeof(*fp) ||
-		    !IS_ALIGNED(*offp, sizeof(u32))) {
-			pr_err("transaction release %d bad offset %lld, size %zd\n",
+		if (object_size == 0) {
+			pr_err("transaction release %d bad object at offset %lld, size %zd\n",
 			       debug_id, (u64)*offp, buffer->data_size);
 			continue;
 		}
-		fp = (struct flat_binder_object *)(buffer->data + *offp);
-		switch (fp->type) {
+		hdr = (struct binder_object_header *)(buffer->data + *offp);
+		switch (hdr->type) {
 		case BINDER_TYPE_BINDER:
 		case BINDER_TYPE_WEAK_BINDER: {
-			struct binder_node *node = binder_get_node(proc, fp->binder);
+			struct flat_binder_object *fp;
+			struct binder_node *node;
 
+			fp = to_flat_binder_object(hdr);
+			node = binder_get_node(proc, fp->binder);
 			if (node == NULL) {
 				pr_err("transaction release %d bad node %016llx\n",
 				       debug_id, (u64)fp->binder);
 				break;
 			}
 			binder_debug(BINDER_DEBUG_TRANSACTION,
 				     "        node %d u%016llx\n",
 				     node->debug_id, (u64)node->ptr);
-			binder_dec_node(node, fp->type == BINDER_TYPE_BINDER, 0);
+			binder_dec_node(node, hdr->type == BINDER_TYPE_BINDER,
+					0);
 		} break;
 		case BINDER_TYPE_HANDLE:
 		case BINDER_TYPE_WEAK_HANDLE: {
+			struct flat_binder_object *fp;
 			struct binder_ref *ref;
 
+			fp = to_flat_binder_object(hdr);
 			ref = binder_get_ref(proc, fp->handle,
-					     fp->type == BINDER_TYPE_HANDLE);
-
+					     hdr->type == BINDER_TYPE_HANDLE);
 			if (ref == NULL) {
 				pr_err("transaction release %d bad handle %d\n",
 				 debug_id, fp->handle);
 				break;
 			}
 			binder_debug(BINDER_DEBUG_TRANSACTION,
 				     "        ref %d desc %d (node %d)\n",
 				     ref->debug_id, ref->desc, ref->node->debug_id);
-			binder_dec_ref(ref, fp->type == BINDER_TYPE_HANDLE);
+			binder_dec_ref(ref, hdr->type == BINDER_TYPE_HANDLE);
 		} break;
 
-		case BINDER_TYPE_FD:
+		case BINDER_TYPE_FD: {
+			struct binder_fd_object *fp = to_binder_fd_object(hdr);
+
 			binder_debug(BINDER_DEBUG_TRANSACTION,
-				     "        fd %d\n", fp->handle);
+				     "        fd %d\n", fp->fd);
 			if (failed_at)
-				task_close_fd(proc, fp->handle);
+				task_close_fd(proc, fp->fd);
+		} break;
+		case BINDER_TYPE_PTR:
+			/*
+			 * Nothing to do here, this will get cleaned up when the
+			 * transaction buffer gets freed
+			 */
 			break;
-
+		case BINDER_TYPE_FDA: {
+			struct binder_fd_array_object *fda;
+			struct binder_buffer_object *parent;
+			uintptr_t parent_buffer;
+			u32 *fd_array;
+			size_t fd_index;
+			binder_size_t fd_buf_size;
+
+			fda = to_binder_fd_array_object(hdr);
+			parent = binder_validate_ptr(buffer, fda->parent,
+						     off_start,
+						     offp - off_start);
+			if (!parent) {
+				pr_err("transaction release %d bad parent offset",
+				       debug_id);
+				continue;
+			}
+			/*
+			 * Since the parent was already fixed up, convert it
+			 * back to kernel address space to access it
+			 */
+			parent_buffer = parent->buffer -
+				proc->user_buffer_offset;
+
+			fd_buf_size = sizeof(u32) * fda->num_fds;
+			if (fda->num_fds >= SIZE_MAX / sizeof(u32)) {
+				pr_err("transaction release %d invalid number of fds (%lld)\n",
+				       debug_id, (u64)fda->num_fds);
+				continue;
+			}
+			if (fd_buf_size > parent->length ||
+			    fda->parent_offset > parent->length - fd_buf_size) {
+				/* No space for all file descriptors here. */
+				pr_err("transaction release %d not enough space for %lld fds in buffer\n",
+				       debug_id, (u64)fda->num_fds);
+				continue;
+			}
+			fd_array = (u32 *)(parent_buffer + fda->parent_offset);
+			for (fd_index = 0; fd_index < fda->num_fds; fd_index++)
+				task_close_fd(proc, fd_array[fd_index]);
+		} break;
 		default:
 			pr_err("transaction release %d bad object type %x\n",
-				debug_id, fp->type);
+				debug_id, hdr->type);
 			break;
 		}
 	}
 }
 
+static int binder_translate_binder(struct flat_binder_object *fp,
+				   struct binder_transaction *t,
+				   struct binder_thread *thread)
+{
+	struct binder_node *node;
+	struct binder_ref *ref;
+	struct binder_proc *proc = thread->proc;
+	struct binder_proc *target_proc = t->to_proc;
+
+	node = binder_get_node(proc, fp->binder);
+	if (!node) {
+		node = binder_new_node(proc, fp->binder, fp->cookie);
+		if (!node)
+			return -ENOMEM;
+
+		node->min_priority = fp->flags & FLAT_BINDER_FLAG_PRIORITY_MASK;
+		node->accept_fds = !!(fp->flags & FLAT_BINDER_FLAG_ACCEPTS_FDS);
+	}
+	if (fp->cookie != node->cookie) {
+		binder_user_error("%d:%d sending u%016llx node %d, cookie mismatch %016llx != %016llx\n",
+				  proc->pid, thread->pid, (u64)fp->binder,
+				  node->debug_id, (u64)fp->cookie,
+				  (u64)node->cookie);
+		return -EINVAL;
+	}
+	if (security_binder_transfer_binder(proc->tsk, target_proc->tsk))
+		return -EPERM;
+
+	ref = binder_get_ref_for_node(target_proc, node);
+	if (!ref)
+		return -EINVAL;
+
+	if (fp->hdr.type == BINDER_TYPE_BINDER)
+		fp->hdr.type = BINDER_TYPE_HANDLE;
+	else
+		fp->hdr.type = BINDER_TYPE_WEAK_HANDLE;
+	fp->binder = 0;
+	fp->handle = ref->desc;
+	fp->cookie = 0;
+	binder_inc_ref(ref, fp->hdr.type == BINDER_TYPE_HANDLE, &thread->todo);
+
+	trace_binder_transaction_node_to_ref(t, node, ref);
+	binder_debug(BINDER_DEBUG_TRANSACTION,
+		     "        node %d u%016llx -> ref %d desc %d\n",
+		     node->debug_id, (u64)node->ptr,
+		     ref->debug_id, ref->desc);
+
+	return 0;
+}
+
+static int binder_translate_handle(struct flat_binder_object *fp,
+				   struct binder_transaction *t,
+				   struct binder_thread *thread)
+{
+	struct binder_ref *ref;
+	struct binder_proc *proc = thread->proc;
+	struct binder_proc *target_proc = t->to_proc;
+
+	ref = binder_get_ref(proc, fp->handle,
+			     fp->hdr.type == BINDER_TYPE_HANDLE);
+	if (!ref) {
+		binder_user_error("%d:%d got transaction with invalid handle, %d\n",
+				  proc->pid, thread->pid, fp->handle);
+		return -EINVAL;
+	}
+	if (security_binder_transfer_binder(proc->tsk, target_proc->tsk))
+		return -EPERM;
+
+	if (ref->node->proc == target_proc) {
+		if (fp->hdr.type == BINDER_TYPE_HANDLE)
+			fp->hdr.type = BINDER_TYPE_BINDER;
+		else
+			fp->hdr.type = BINDER_TYPE_WEAK_BINDER;
+		fp->binder = ref->node->ptr;
+		fp->cookie = ref->node->cookie;
+		binder_inc_node(ref->node, fp->hdr.type == BINDER_TYPE_BINDER,
+				0, NULL);
+		trace_binder_transaction_ref_to_node(t, ref);
+		binder_debug(BINDER_DEBUG_TRANSACTION,
+			     "        ref %d desc %d -> node %d u%016llx\n",
+			     ref->debug_id, ref->desc, ref->node->debug_id,
+			     (u64)ref->node->ptr);
+	} else {
+		struct binder_ref *new_ref;
+
+		new_ref = binder_get_ref_for_node(target_proc, ref->node);
+		if (!new_ref)
+			return -EINVAL;
+
+		fp->binder = 0;
+		fp->handle = new_ref->desc;
+		fp->cookie = 0;
+		binder_inc_ref(new_ref, fp->hdr.type == BINDER_TYPE_HANDLE,
+			       NULL);
+		trace_binder_transaction_ref_to_ref(t, ref, new_ref);
+		binder_debug(BINDER_DEBUG_TRANSACTION,
+			     "        ref %d desc %d -> ref %d desc %d (node %d)\n",
+			     ref->debug_id, ref->desc, new_ref->debug_id,
+			     new_ref->desc, ref->node->debug_id);
+	}
+	return 0;
+}
+
+static int binder_translate_fd(int fd,
+			       struct binder_transaction *t,
+			       struct binder_thread *thread,
+			       struct binder_transaction *in_reply_to)
+{
+	struct binder_proc *proc = thread->proc;
+	struct binder_proc *target_proc = t->to_proc;
+	int target_fd;
+	struct file *file;
+	int ret;
+	bool target_allows_fd;
+
+	if (in_reply_to)
+		target_allows_fd = !!(in_reply_to->flags & TF_ACCEPT_FDS);
+	else
+		target_allows_fd = t->buffer->target_node->accept_fds;
+	if (!target_allows_fd) {
+		binder_user_error("%d:%d got %s with fd, %d, but target does not allow fds\n",
+				  proc->pid, thread->pid,
+				  in_reply_to ? "reply" : "transaction",
+				  fd);
+		ret = -EPERM;
+		goto err_fd_not_accepted;
+	}
+
+	file = fget(fd);
+	if (!file) {
+		binder_user_error("%d:%d got transaction with invalid fd, %d\n",
+				  proc->pid, thread->pid, fd);
+		ret = -EBADF;
+		goto err_fget;
+	}
+	ret = security_binder_transfer_file(proc->tsk, target_proc->tsk, file);
+	if (ret < 0) {
+		ret = -EPERM;
+		goto err_security;
+	}
+
+	target_fd = task_get_unused_fd_flags(target_proc, O_CLOEXEC);
+	if (target_fd < 0) {
+		ret = -ENOMEM;
+		goto err_get_unused_fd;
+	}
+	task_fd_install(target_proc, target_fd, file);
+	trace_binder_transaction_fd(t, fd, target_fd);
+	binder_debug(BINDER_DEBUG_TRANSACTION, "        fd %d -> %d\n",
+		     fd, target_fd);
+
+	return target_fd;
+
+err_get_unused_fd:
+err_security:
+	fput(file);
+err_fget:
+err_fd_not_accepted:
+	return ret;
+}
+
+static int binder_translate_fd_array(struct binder_fd_array_object *fda,
+				     struct binder_buffer_object *parent,
+				     struct binder_transaction *t,
+				     struct binder_thread *thread,
+				     struct binder_transaction *in_reply_to)
+{
+	binder_size_t fdi, fd_buf_size, num_installed_fds;
+	int target_fd;
+	uintptr_t parent_buffer;
+	u32 *fd_array;
+	struct binder_proc *proc = thread->proc;
+	struct binder_proc *target_proc = t->to_proc;
+
+	fd_buf_size = sizeof(u32) * fda->num_fds;
+	if (fda->num_fds >= SIZE_MAX / sizeof(u32)) {
+		binder_user_error("%d:%d got transaction with invalid number of fds (%lld)\n",
+				  proc->pid, thread->pid, (u64)fda->num_fds);
+		return -EINVAL;
+	}
+	if (fd_buf_size > parent->length ||
+	    fda->parent_offset > parent->length - fd_buf_size) {
+		/* No space for all file descriptors here. */
+		binder_user_error("%d:%d not enough space to store %lld fds in buffer\n",
+				  proc->pid, thread->pid, (u64)fda->num_fds);
+		return -EINVAL;
+	}
+	/*
+	 * Since the parent was already fixed up, convert it
+	 * back to the kernel address space to access it
+	 */
+	parent_buffer = parent->buffer - target_proc->user_buffer_offset;
+	fd_array = (u32 *)(parent_buffer + fda->parent_offset);
+	if (!IS_ALIGNED((unsigned long)fd_array, sizeof(u32))) {
+		binder_user_error("%d:%d parent offset not aligned correctly.\n",
+				  proc->pid, thread->pid);
+		return -EINVAL;
+	}
+	for (fdi = 0; fdi < fda->num_fds; fdi++) {
+		target_fd = binder_translate_fd(fd_array[fdi], t, thread,
+						in_reply_to);
+		if (target_fd < 0)
+			goto err_translate_fd_failed;
+		fd_array[fdi] = target_fd;
+	}
+	return 0;
+
+err_translate_fd_failed:
+	/*
+	 * Failed to allocate fd or security error, free fds
+	 * installed so far.
+	 */
+	num_installed_fds = fdi;
+	for (fdi = 0; fdi < num_installed_fds; fdi++)
+		task_close_fd(target_proc, fd_array[fdi]);
+	return target_fd;
+}
+
+static int binder_fixup_parent(struct binder_transaction *t,
+			       struct binder_thread *thread,
+			       struct binder_buffer_object *bp,
+			       binder_size_t *off_start,
+			       binder_size_t num_valid,
+			       struct binder_buffer_object *last_fixup_obj,
+			       binder_size_t last_fixup_min_off)
+{
+	struct binder_buffer_object *parent;
+	u8 *parent_buffer;
+	struct binder_buffer *b = t->buffer;
+	struct binder_proc *proc = thread->proc;
+	struct binder_proc *target_proc = t->to_proc;
+
+	if (!(bp->flags & BINDER_BUFFER_FLAG_HAS_PARENT))
+		return 0;
+
+	parent = binder_validate_ptr(b, bp->parent, off_start, num_valid);
+	if (!parent) {
+		binder_user_error("%d:%d got transaction with invalid parent offset or type\n",
+				  proc->pid, thread->pid);
+		return -EINVAL;
+	}
+
+	if (!binder_validate_fixup(b, off_start,
+				   parent, bp->parent_offset,
+				   last_fixup_obj,
+				   last_fixup_min_off)) {
+		binder_user_error("%d:%d got transaction with out-of-order buffer fixup\n",
+				  proc->pid, thread->pid);
+		return -EINVAL;
+	}
+
+	if (parent->length < sizeof(binder_uintptr_t) ||
+	    bp->parent_offset > parent->length - sizeof(binder_uintptr_t)) {
+		/* No space for a pointer here! */
+		binder_user_error("%d:%d got transaction with invalid parent offset\n",
+				  proc->pid, thread->pid);
+		return -EINVAL;
+	}
+	parent_buffer = (u8 *)(parent->buffer -
+			       target_proc->user_buffer_offset);
+	*(binder_uintptr_t *)(parent_buffer + bp->parent_offset) = bp->buffer;
+
+	return 0;
+}
+
 static void binder_transaction(struct binder_proc *proc,
 			       struct binder_thread *thread,
-			       struct binder_transaction_data *tr, int reply)
+			       struct binder_transaction_data *tr, int reply,
+			       binder_size_t extra_buffers_size)
 {
+	int ret;
 	struct binder_transaction *t;
 	struct binder_work *tcomplete;
-	binder_size_t *offp, *off_end;
+	binder_size_t *offp, *off_end, *off_start;
 	binder_size_t off_min;
+	u8 *sg_bufp, *sg_buf_end;
 	struct binder_proc *target_proc;
 	struct binder_thread *target_thread = NULL;
 	struct binder_node *target_node = NULL;
 	struct list_head *target_list;
 	wait_queue_head_t *target_wait;
 	struct binder_transaction *in_reply_to = NULL;
 	struct binder_transaction_log_entry *e;
 	uint32_t return_error;
+	struct binder_buffer_object *last_fixup_obj = NULL;
+	binder_size_t last_fixup_min_off = 0;
+	struct binder_context *context = proc->context;
 
 	e = binder_transaction_log_add(&binder_transaction_log);
 	e->call_type = reply ? 2 : !!(tr->flags & TF_ONE_WAY);
 	e->from_proc = proc->pid;
 	e->from_thread = thread->pid;
 	e->target_handle = tr->target.handle;
 	e->data_size = tr->data_size;
 	e->offsets_size = tr->offsets_size;
+	e->context_name = proc->context->name;
 
 	if (reply) {
 		in_reply_to = thread->transaction_stack;
 		if (in_reply_to == NULL) {
 			binder_user_error("%d:%d got reply transaction with no transaction stack\n",
 					  proc->pid, thread->pid);
 			return_error = BR_FAILED_REPLY;
 			goto err_empty_call_stack;
 		}
 		binder_set_nice(in_reply_to->saved_priority);
 		if (in_reply_to->to_thread != thread) {
 			binder_user_error("%d:%d got reply transaction with bad transaction stack, transaction %d has target %d:%d\n",
 				proc->pid, thread->pid, in_reply_to->debug_id,
 				in_reply_to->to_proc ?
 				in_reply_to->to_proc->pid : 0,
 				in_reply_to->to_thread ?
 				in_reply_to->to_thread->pid : 0);
 			return_error = BR_FAILED_REPLY;
 			in_reply_to = NULL;
 			goto err_bad_call_stack;
 		}
 		thread->transaction_stack = in_reply_to->to_parent;
 		target_thread = in_reply_to->from;
 		if (target_thread == NULL) {
 			return_error = BR_DEAD_REPLY;
 			goto err_dead_binder;
 		}
 		if (target_thread->transaction_stack != in_reply_to) {
 			binder_user_error("%d:%d got reply transaction with bad target transaction stack %d, expected %d\n",
 				proc->pid, thread->pid,
 				target_thread->transaction_stack ?
 				target_thread->transaction_stack->debug_id : 0,
 				in_reply_to->debug_id);
 			return_error = BR_FAILED_REPLY;
 			in_reply_to = NULL;
 			target_thread = NULL;
 			goto err_dead_binder;
 		}
 		target_proc = target_thread->proc;
 	} else {
 		if (tr->target.handle) {
 			struct binder_ref *ref;
 
 			ref = binder_get_ref(proc, tr->target.handle, true);
 			if (ref == NULL) {
 				binder_user_error("%d:%d got transaction to invalid handle\n",
 					proc->pid, thread->pid);
 				return_error = BR_FAILED_REPLY;
 				goto err_invalid_target_handle;
 			}
 			target_node = ref->node;
 		} else {
-			target_node = binder_context_mgr_node;
+			target_node = context->binder_context_mgr_node;
 			if (target_node == NULL) {
 				return_error = BR_DEAD_REPLY;
 				goto err_no_context_mgr_node;
 			}
 		}
 		e->to_node = target_node->debug_id;
 		target_proc = target_node->proc;
 		if (target_proc == NULL) {
 			return_error = BR_DEAD_REPLY;
 			goto err_dead_binder;
 		}
 		if (security_binder_transaction(proc->tsk,
 						target_proc->tsk) < 0) {
 			return_error = BR_FAILED_REPLY;
 			goto err_invalid_target_handle;
 		}
 		if (!(tr->flags & TF_ONE_WAY) && thread->transaction_stack) {
 			struct binder_transaction *tmp;
 
 			tmp = thread->transaction_stack;
 			if (tmp->to_thread != thread) {
 				binder_user_error("%d:%d got new transaction with bad transaction stack, transaction %d has target %d:%d\n",
 					proc->pid, thread->pid, tmp->debug_id,
 					tmp->to_proc ? tmp->to_proc->pid : 0,
 					tmp->to_thread ?
 					tmp->to_thread->pid : 0);
 				return_error = BR_FAILED_REPLY;
 				goto err_bad_call_stack;
 			}
 			while (tmp) {
 				if (tmp->from && tmp->from->proc == target_proc)
 					target_thread = tmp->from;
 				tmp = tmp->from_parent;
 			}
 		}
 	}
 	if (target_thread) {
 		e->to_thread = target_thread->pid;
 		target_list = &target_thread->todo;
 		target_wait = &target_thread->wait;
 	} else {
 		target_list = &target_proc->todo;
 		target_wait = &target_proc->wait;
 	}
 	e->to_proc = target_proc->pid;
 
 	/* TODO: reuse incoming transaction for reply */
 	t = kzalloc(sizeof(*t), GFP_KERNEL);
 	if (t == NULL) {
 		return_error = BR_FAILED_REPLY;
 		goto err_alloc_t_failed;
 	}
 	binder_stats_created(BINDER_STAT_TRANSACTION);
 
 	tcomplete = kzalloc(sizeof(*tcomplete), GFP_KERNEL);
 	if (tcomplete == NULL) {
 		return_error = BR_FAILED_REPLY;
 		goto err_alloc_tcomplete_failed;
 	}
 	binder_stats_created(BINDER_STAT_TRANSACTION_COMPLETE);
 
 	t->debug_id = ++binder_last_id;
 	e->debug_id = t->debug_id;
 
 	if (reply)
 		binder_debug(BINDER_DEBUG_TRANSACTION,
-			     "%d:%d BC_REPLY %d -> %d:%d, data %016llx-%016llx size %lld-%lld\n",
+			     "%d:%d BC_REPLY %d -> %d:%d, data %016llx-%016llx size %lld-%lld-%lld\n",
 			     proc->pid, thread->pid, t->debug_id,
 			     target_proc->pid, target_thread->pid,
 			     (u64)tr->data.ptr.buffer,
 			     (u64)tr->data.ptr.offsets,
-			     (u64)tr->data_size, (u64)tr->offsets_size);
+			     (u64)tr->data_size, (u64)tr->offsets_size,
+			     (u64)extra_buffers_size);
 	else
 		binder_debug(BINDER_DEBUG_TRANSACTION,
-			     "%d:%d BC_TRANSACTION %d -> %d - node %d, data %016llx-%016llx size %lld-%lld\n",
+			     "%d:%d BC_TRANSACTION %d -> %d - node %d, data %016llx-%016llx size %lld-%lld-%lld\n",
 			     proc->pid, thread->pid, t->debug_id,
 			     target_proc->pid, target_node->debug_id,
 			     (u64)tr->data.ptr.buffer,
 			     (u64)tr->data.ptr.offsets,
-			     (u64)tr->data_size, (u64)tr->offsets_size);
+			     (u64)tr->data_size, (u64)tr->offsets_size,
+			     (u64)extra_buffers_size);
 
 	if (!reply && !(tr->flags & TF_ONE_WAY))
 		t->from = thread;
 	else
 		t->from = NULL;
 	t->sender_euid = task_euid(proc->tsk);
 	t->to_proc = target_proc;
 	t->to_thread = target_thread;
 	t->code = tr->code;
 	t->flags = tr->flags;
 	t->priority = task_nice(current);
 
 	trace_binder_transaction(reply, t, target_node);
 
 	t->buffer = binder_alloc_buf(target_proc, tr->data_size,
-		tr->offsets_size, !reply && (t->flags & TF_ONE_WAY));
+		tr->offsets_size, extra_buffers_size,
+		!reply && (t->flags & TF_ONE_WAY));
 	if (t->buffer == NULL) {
 		return_error = BR_FAILED_REPLY;
 		goto err_binder_alloc_buf_failed;
 	}
 	t->buffer->allow_user_free = 0;
 	t->buffer->debug_id = t->debug_id;
 	t->buffer->transaction = t;
 	t->buffer->target_node = target_node;
 	trace_binder_transaction_alloc_buf(t->buffer);
 	if (target_node)
 		binder_inc_node(target_node, 1, 0, NULL);
 
-	offp = (binder_size_t *)(t->buffer->data +
-				 ALIGN(tr->data_size, sizeof(void *)));
+	off_start = (binder_size_t *)(t->buffer->data +
+				      ALIGN(tr->data_size, sizeof(void *)));
+	offp = off_start;
 
 	if (copy_from_user(t->buffer->data, (const void __user *)(uintptr_t)
 			   tr->data.ptr.buffer, tr->data_size)) {
 		binder_user_error("%d:%d got transaction with invalid data ptr\n",
 				proc->pid, thread->pid);
 		return_error = BR_FAILED_REPLY;
 		goto err_copy_data_failed;
 	}
 	if (copy_from_user(offp, (const void __user *)(uintptr_t)
 			   tr->data.ptr.offsets, tr->offsets_size)) {
 		binder_user_error("%d:%d got transaction with invalid offsets ptr\n",
 				proc->pid, thread->pid);
 		return_error = BR_FAILED_REPLY;
 		goto err_copy_data_failed;
 	}
 	if (!IS_ALIGNED(tr->offsets_size, sizeof(binder_size_t))) {
 		binder_user_error("%d:%d got transaction with invalid offsets size, %lld\n",
 				proc->pid, thread->pid, (u64)tr->offsets_size);
 		return_error = BR_FAILED_REPLY;
 		goto err_bad_offset;
 	}
-	off_end = (void *)offp + tr->offsets_size;
+	if (!IS_ALIGNED(extra_buffers_size, sizeof(u64))) {
+		binder_user_error("%d:%d got transaction with unaligned buffers size, %lld\n",
+				  proc->pid, thread->pid,
+				  (u64)extra_buffers_size);
+		return_error = BR_FAILED_REPLY;
+		goto err_bad_offset;
+	}
+	off_end = (void *)off_start + tr->offsets_size;
+	sg_bufp = (u8 *)(PTR_ALIGN(off_end, sizeof(void *)));
+	sg_buf_end = sg_bufp + extra_buffers_size;
 	off_min = 0;
 	for (; offp < off_end; offp++) {
-		struct flat_binder_object *fp;
+		struct binder_object_header *hdr;
+		size_t object_size = binder_validate_object(t->buffer, *offp);
 
-		if (*offp > t->buffer->data_size - sizeof(*fp) ||
-		    *offp < off_min ||
-		    t->buffer->data_size < sizeof(*fp) ||
-		    !IS_ALIGNED(*offp, sizeof(u32))) {
-			binder_user_error("%d:%d got transaction with invalid offset, %lld (min %lld, max %lld)\n",
+		if (object_size == 0 || *offp < off_min) {
+			binder_user_error("%d:%d got transaction with invalid offset (%lld, min %lld max %lld) or object.\n",
 					  proc->pid, thread->pid, (u64)*offp,
 					  (u64)off_min,
-					  (u64)(t->buffer->data_size -
-					  sizeof(*fp)));
+					  (u64)t->buffer->data_size);
 			return_error = BR_FAILED_REPLY;
 			goto err_bad_offset;
 		}
-		fp = (struct flat_binder_object *)(t->buffer->data + *offp);
-		off_min = *offp + sizeof(struct flat_binder_object);
-		switch (fp->type) {
+
+		hdr = (struct binder_object_header *)(t->buffer->data + *offp);
+		off_min = *offp + object_size;
+		switch (hdr->type) {
 		case BINDER_TYPE_BINDER:
 		case BINDER_TYPE_WEAK_BINDER: {
-			struct binder_ref *ref;
-			struct binder_node *node = binder_get_node(proc, fp->binder);
+			struct flat_binder_object *fp;
 
-			if (node == NULL) {
-				node = binder_new_node(proc, fp->binder, fp->cookie);
-				if (node == NULL) {
-					return_error = BR_FAILED_REPLY;
-					goto err_binder_new_node_failed;
-				}
-				node->min_priority = fp->flags & FLAT_BINDER_FLAG_PRIORITY_MASK;
-				node->accept_fds = !!(fp->flags & FLAT_BINDER_FLAG_ACCEPTS_FDS);
-			}
-			if (fp->cookie != node->cookie) {
-				binder_user_error("%d:%d sending u%016llx node %d, cookie mismatch %016llx != %016llx\n",
-					proc->pid, thread->pid,
-					(u64)fp->binder, node->debug_id,
-					(u64)fp->cookie, (u64)node->cookie);
-				return_error = BR_FAILED_REPLY;
-				goto err_binder_get_ref_for_node_failed;
-			}
-			if (security_binder_transfer_binder(proc->tsk,
-							    target_proc->tsk)) {
+			fp = to_flat_binder_object(hdr);
+			ret = binder_translate_binder(fp, t, thread);
+			if (ret < 0) {
 				return_error = BR_FAILED_REPLY;
-				goto err_binder_get_ref_for_node_failed;
+				goto err_translate_failed;
 			}
-			ref = binder_get_ref_for_node(target_proc, node);
-			if (ref == NULL) {
-				return_error = BR_FAILED_REPLY;
-				goto err_binder_get_ref_for_node_failed;
-			}
-			if (fp->type == BINDER_TYPE_BINDER)
-				fp->type = BINDER_TYPE_HANDLE;
-			else
-				fp->type = BINDER_TYPE_WEAK_HANDLE;
-			fp->binder = 0;
-			fp->handle = ref->desc;
-			fp->cookie = 0;
-			binder_inc_ref(ref, fp->type == BINDER_TYPE_HANDLE,
-				       &thread->todo);
-
-			trace_binder_transaction_node_to_ref(t, node, ref);
-			binder_debug(BINDER_DEBUG_TRANSACTION,
-				     "        node %d u%016llx -> ref %d desc %d\n",
-				     node->debug_id, (u64)node->ptr,
-				     ref->debug_id, ref->desc);
 		} break;
 		case BINDER_TYPE_HANDLE:
 		case BINDER_TYPE_WEAK_HANDLE: {
-			struct binder_ref *ref;
+			struct flat_binder_object *fp;
 
-			ref = binder_get_ref(proc, fp->handle,
-					     fp->type == BINDER_TYPE_HANDLE);
+			fp = to_flat_binder_object(hdr);
+			ret = binder_translate_handle(fp, t, thread);
+			if (ret < 0) {
+				return_error = BR_FAILED_REPLY;
+				goto err_translate_failed;
+			}
+		} break;
 
-			if (ref == NULL) {
-				binder_user_error("%d:%d got transaction with invalid handle, %d\n",
-						proc->pid,
-						thread->pid, fp->handle);
+		case BINDER_TYPE_FD: {
+			struct binder_fd_object *fp = to_binder_fd_object(hdr);
+			int target_fd = binder_translate_fd(fp->fd, t, thread,
+							    in_reply_to);
+
+			if (target_fd < 0) {
 				return_error = BR_FAILED_REPLY;
-				goto err_binder_get_ref_failed;
+				goto err_translate_failed;
 			}
-			if (security_binder_transfer_binder(proc->tsk,
-							    target_proc->tsk)) {
+			fp->pad_binder = 0;
+			fp->fd = target_fd;
+		} break;
+		case BINDER_TYPE_FDA: {
+			struct binder_fd_array_object *fda =
+				to_binder_fd_array_object(hdr);
+			struct binder_buffer_object *parent =
+				binder_validate_ptr(t->buffer, fda->parent,
+						    off_start,
+						    offp - off_start);
+			if (!parent) {
+				binder_user_error("%d:%d got transaction with invalid parent offset or type\n",
+						  proc->pid, thread->pid);
 				return_error = BR_FAILED_REPLY;
-				goto err_binder_get_ref_failed;
+				goto err_bad_parent;
 			}
-			if (ref->node->proc == target_proc) {
-				if (fp->type == BINDER_TYPE_HANDLE)
-					fp->type = BINDER_TYPE_BINDER;
-				else
-					fp->type = BINDER_TYPE_WEAK_BINDER;
-				fp->binder = ref->node->ptr;
-				fp->cookie = ref->node->cookie;
-				binder_inc_node(ref->node, fp->type == BINDER_TYPE_BINDER, 0, NULL);
-				trace_binder_transaction_ref_to_node(t, ref);
-				binder_debug(BINDER_DEBUG_TRANSACTION,
-					     "        ref %d desc %d -> node %d u%016llx\n",
-					     ref->debug_id, ref->desc, ref->node->debug_id,
-					     (u64)ref->node->ptr);
-			} else {
-				struct binder_ref *new_ref;
-
-				new_ref = binder_get_ref_for_node(target_proc, ref->node);
-				if (new_ref == NULL) {
-					return_error = BR_FAILED_REPLY;
-					goto err_binder_get_ref_for_node_failed;
-				}
-				fp->binder = 0;
-				fp->handle = new_ref->desc;
-				fp->cookie = 0;
-				binder_inc_ref(new_ref, fp->type == BINDER_TYPE_HANDLE, NULL);
-				trace_binder_transaction_ref_to_ref(t, ref,
-								    new_ref);
-				binder_debug(BINDER_DEBUG_TRANSACTION,
-					     "        ref %d desc %d -> ref %d desc %d (node %d)\n",
-					     ref->debug_id, ref->desc, new_ref->debug_id,
-					     new_ref->desc, ref->node->debug_id);
+			if (!binder_validate_fixup(t->buffer, off_start,
+						   parent, fda->parent_offset,
+						   last_fixup_obj,
+						   last_fixup_min_off)) {
+				binder_user_error("%d:%d got transaction with out-of-order buffer fixup\n",
+						  proc->pid, thread->pid);
+				return_error = BR_FAILED_REPLY;
+				goto err_bad_parent;
 			}
-		} break;
-
-		case BINDER_TYPE_FD: {
-			int target_fd;
-			struct file *file;
-
-			if (reply) {
-				if (!(in_reply_to->flags & TF_ACCEPT_FDS)) {
-					binder_user_error("%d:%d got reply with fd, %d, but target does not allow fds\n",
-						proc->pid, thread->pid, fp->handle);
-					return_error = BR_FAILED_REPLY;
-					goto err_fd_not_allowed;
-				}
-			} else if (!target_node->accept_fds) {
-				binder_user_error("%d:%d got transaction with fd, %d, but target does not allow fds\n",
-					proc->pid, thread->pid, fp->handle);
+			ret = binder_translate_fd_array(fda, parent, t, thread,
+							in_reply_to);
+			if (ret < 0) {
 				return_error = BR_FAILED_REPLY;
-				goto err_fd_not_allowed;
+				goto err_translate_failed;
 			}
-
-			file = fget(fp->handle);
-			if (file == NULL) {
-				binder_user_error("%d:%d got transaction with invalid fd, %d\n",
-					proc->pid, thread->pid, fp->handle);
+			last_fixup_obj = parent;
+			last_fixup_min_off =
+				fda->parent_offset + sizeof(u32) * fda->num_fds;
+		} break;
+		case BINDER_TYPE_PTR: {
+			struct binder_buffer_object *bp =
+				to_binder_buffer_object(hdr);
+			size_t buf_left = sg_buf_end - sg_bufp;
+
+			if (bp->length > buf_left) {
+				binder_user_error("%d:%d got transaction with too large buffer\n",
+						  proc->pid, thread->pid);
 				return_error = BR_FAILED_REPLY;
-				goto err_fget_failed;
+				goto err_bad_offset;
 			}
-			if (security_binder_transfer_file(proc->tsk,
-							  target_proc->tsk,
-							  file) < 0) {
-				fput(file);
+			if (copy_from_user(sg_bufp,
+					   (const void __user *)(uintptr_t)
+					   bp->buffer, bp->length)) {
+				binder_user_error("%d:%d got transaction with invalid offsets ptr\n",
+						  proc->pid, thread->pid);
 				return_error = BR_FAILED_REPLY;
-				goto err_get_unused_fd_failed;
+				goto err_copy_data_failed;
 			}
-			target_fd = task_get_unused_fd_flags(target_proc, O_CLOEXEC);
-			if (target_fd < 0) {
-				fput(file);
+			/* Fixup buffer pointer to target proc address space */
+			bp->buffer = (uintptr_t)sg_bufp +
+				target_proc->user_buffer_offset;
+			sg_bufp += ALIGN(bp->length, sizeof(u64));
+
+			ret = binder_fixup_parent(t, thread, bp, off_start,
+						  offp - off_start,
+						  last_fixup_obj,
+						  last_fixup_min_off);
+			if (ret < 0) {
 				return_error = BR_FAILED_REPLY;
-				goto err_get_unused_fd_failed;
+				goto err_translate_failed;
 			}
-			task_fd_install(target_proc, target_fd, file);
-			trace_binder_transaction_fd(t, fp->handle, target_fd);
-			binder_debug(BINDER_DEBUG_TRANSACTION,
-				     "        fd %d -> %d\n", fp->handle, target_fd);
-			/* TODO: fput? */
-			fp->binder = 0;
-			fp->handle = target_fd;
+			last_fixup_obj = bp;
+			last_fixup_min_off = 0;
 		} break;
-
 		default:
 			binder_user_error("%d:%d got transaction with invalid object type, %x\n",
-				proc->pid, thread->pid, fp->type);
+				proc->pid, thread->pid, hdr->type);
 			return_error = BR_FAILED_REPLY;
 			goto err_bad_object_type;
 		}
 	}
 	if (reply) {
 		BUG_ON(t->buffer->async_transaction != 0);
 		binder_pop_transaction(target_thread, in_reply_to);
 	} else if (!(t->flags & TF_ONE_WAY)) {
 		BUG_ON(t->buffer->async_transaction != 0);
 		t->need_reply = 1;
 		t->from_parent = thread->transaction_stack;
 		thread->transaction_stack = t;
 	} else {
 		BUG_ON(target_node == NULL);
 		BUG_ON(t->buffer->async_transaction != 1);
 		if (target_node->has_async_transaction) {
 			target_list = &target_node->async_todo;
 			target_wait = NULL;
 		} else
 			target_node->has_async_transaction = 1;
 	}
 	t->work.type = BINDER_WORK_TRANSACTION;
 	list_add_tail(&t->work.entry, target_list);
 	tcomplete->type = BINDER_WORK_TRANSACTION_COMPLETE;
 	list_add_tail(&tcomplete->entry, &thread->todo);
 	if (target_wait)
 		wake_up_interruptible(target_wait);
 	return;
 
-err_get_unused_fd_failed:
-err_fget_failed:
-err_fd_not_allowed:
-err_binder_get_ref_for_node_failed:
-err_binder_get_ref_failed:
-err_binder_new_node_failed:
+err_translate_failed:
 err_bad_object_type:
 err_bad_offset:
+err_bad_parent:
 err_copy_data_failed:
 	trace_binder_transaction_failed_buffer_release(t->buffer);
 	binder_transaction_buffer_release(target_proc, t->buffer, offp);
 	t->buffer->transaction = NULL;
 	binder_free_buf(target_proc, t->buffer);
 err_binder_alloc_buf_failed:
 	kfree(tcomplete);
 	binder_stats_deleted(BINDER_STAT_TRANSACTION_COMPLETE);
 err_alloc_tcomplete_failed:
 	kfree(t);
 	binder_stats_deleted(BINDER_STAT_TRANSACTION);
 err_alloc_t_failed:
 err_bad_call_stack:
 err_empty_call_stack:
 err_dead_binder:
 err_invalid_target_handle:
 err_no_context_mgr_node:
 	binder_debug(BINDER_DEBUG_FAILED_TRANSACTION,
 		     "%d:%d transaction failed %d, size %lld-%lld\n",
 		     proc->pid, thread->pid, return_error,
 		     (u64)tr->data_size, (u64)tr->offsets_size);
 
 	{
 		struct binder_transaction_log_entry *fe;
 
 		fe = binder_transaction_log_add(&binder_transaction_log_failed);
 		*fe = *e;
 	}
 
 	BUG_ON(thread->return_error != BR_OK);
 	if (in_reply_to) {
 		thread->return_error = BR_TRANSACTION_COMPLETE;
 		binder_send_failed_reply(in_reply_to, return_error);
 	} else
 		thread->return_error = return_error;
 }
 
 static int binder_thread_write(struct binder_proc *proc,
 			struct binder_thread *thread,
 			binder_uintptr_t binder_buffer, size_t size,
 			binder_size_t *consumed)
 {
 	uint32_t cmd;
+	struct binder_context *context = proc->context;
 	void __user *buffer = (void __user *)(uintptr_t)binder_buffer;
 	void __user *ptr = buffer + *consumed;
 	void __user *end = buffer + size;
 
 	while (ptr < end && thread->return_error == BR_OK) {
 		if (get_user(cmd, (uint32_t __user *)ptr))
 			return -EFAULT;
 		ptr += sizeof(uint32_t);
 		trace_binder_command(cmd);
 		if (_IOC_NR(cmd) < ARRAY_SIZE(binder_stats.bc)) {
 			binder_stats.bc[_IOC_NR(cmd)]++;
 			proc->stats.bc[_IOC_NR(cmd)]++;
 			thread->stats.bc[_IOC_NR(cmd)]++;
 		}
 		switch (cmd) {
 		case BC_INCREFS:
 		case BC_ACQUIRE:
 		case BC_RELEASE:
 		case BC_DECREFS: {
 			uint32_t target;
 			struct binder_ref *ref;
 			const char *debug_string;
 
 			if (get_user(target, (uint32_t __user *)ptr))
 				return -EFAULT;
 			ptr += sizeof(uint32_t);
-			if (target == 0 && binder_context_mgr_node &&
+			if (target == 0 && context->binder_context_mgr_node &&
 			    (cmd == BC_INCREFS || cmd == BC_ACQUIRE)) {
 				ref = binder_get_ref_for_node(proc,
-					       binder_context_mgr_node);
+					context->binder_context_mgr_node);
 				if (ref->desc != target) {
 					binder_user_error("%d:%d tried to acquire reference to desc 0, got %d instead\n",
 						proc->pid, thread->pid,
 						ref->desc);
 				}
 			} else
 				ref = binder_get_ref(proc, target,
 						     cmd == BC_ACQUIRE ||
 						     cmd == BC_RELEASE);
 			if (ref == NULL) {
 				binder_user_error("%d:%d refcount change on invalid ref %d\n",
 					proc->pid, thread->pid, target);
 				break;
 			}
 			switch (cmd) {
 			case BC_INCREFS:
 				debug_string = "IncRefs";
 				binder_inc_ref(ref, 0, NULL);
 				break;
 			case BC_ACQUIRE:
 				debug_string = "Acquire";
 				binder_inc_ref(ref, 1, NULL);
 				break;
 			case BC_RELEASE:
 				debug_string = "Release";
 				binder_dec_ref(ref, 1);
 				break;
 			case BC_DECREFS:
 			default:
 				debug_string = "DecRefs";
 				binder_dec_ref(ref, 0);
 				break;
 			}
 			binder_debug(BINDER_DEBUG_USER_REFS,
 				     "%d:%d %s ref %d desc %d s %d w %d for node %d\n",
 				     proc->pid, thread->pid, debug_string, ref->debug_id,
 				     ref->desc, ref->strong, ref->weak, ref->node->debug_id);
 			break;
 		}
 		case BC_INCREFS_DONE:
 		case BC_ACQUIRE_DONE: {
 			binder_uintptr_t node_ptr;
 			binder_uintptr_t cookie;
 			struct binder_node *node;
 
 			if (get_user(node_ptr, (binder_uintptr_t __user *)ptr))
 				return -EFAULT;
 			ptr += sizeof(binder_uintptr_t);
 			if (get_user(cookie, (binder_uintptr_t __user *)ptr))
 				return -EFAULT;
 			ptr += sizeof(binder_uintptr_t);
 			node = binder_get_node(proc, node_ptr);
 			if (node == NULL) {
 				binder_user_error("%d:%d %s u%016llx no match\n",
 					proc->pid, thread->pid,
 					cmd == BC_INCREFS_DONE ?
 					"BC_INCREFS_DONE" :
 					"BC_ACQUIRE_DONE",
 					(u64)node_ptr);
 				break;
 			}
 			if (cookie != node->cookie) {
 				binder_user_error("%d:%d %s u%016llx node %d cookie mismatch %016llx != %016llx\n",
 					proc->pid, thread->pid,
 					cmd == BC_INCREFS_DONE ?
 					"BC_INCREFS_DONE" : "BC_ACQUIRE_DONE",
 					(u64)node_ptr, node->debug_id,
 					(u64)cookie, (u64)node->cookie);
 				break;
 			}
 			if (cmd == BC_ACQUIRE_DONE) {
 				if (node->pending_strong_ref == 0) {
 					binder_user_error("%d:%d BC_ACQUIRE_DONE node %d has no pending acquire request\n",
 						proc->pid, thread->pid,
 						node->debug_id);
 					break;
 				}
 				node->pending_strong_ref = 0;
 			} else {
 				if (node->pending_weak_ref == 0) {
 					binder_user_error("%d:%d BC_INCREFS_DONE node %d has no pending increfs request\n",
 						proc->pid, thread->pid,
 						node->debug_id);
 					break;
 				}
 				node->pending_weak_ref = 0;
 			}
 			binder_dec_node(node, cmd == BC_ACQUIRE_DONE, 0);
 			binder_debug(BINDER_DEBUG_USER_REFS,
 				     "%d:%d %s node %d ls %d lw %d\n",
 				     proc->pid, thread->pid,
 				     cmd == BC_INCREFS_DONE ? "BC_INCREFS_DONE" : "BC_ACQUIRE_DONE",
 				     node->debug_id, node->local_strong_refs, node->local_weak_refs);
 			break;
 		}
 		case BC_ATTEMPT_ACQUIRE:
 			pr_err("BC_ATTEMPT_ACQUIRE not supported\n");
 			return -EINVAL;
 		case BC_ACQUIRE_RESULT:
 			pr_err("BC_ACQUIRE_RESULT not supported\n");
 			return -EINVAL;
 
 		case BC_FREE_BUFFER: {
 			binder_uintptr_t data_ptr;
 			struct binder_buffer *buffer;
 
 			if (get_user(data_ptr, (binder_uintptr_t __user *)ptr))
 				return -EFAULT;
 			ptr += sizeof(binder_uintptr_t);
 
 			buffer = binder_buffer_lookup(proc, data_ptr);
 			if (buffer == NULL) {
 				binder_user_error("%d:%d BC_FREE_BUFFER u%016llx no match\n",
 					proc->pid, thread->pid, (u64)data_ptr);
 				break;
 			}
 			if (!buffer->allow_user_free) {
 				binder_user_error("%d:%d BC_FREE_BUFFER u%016llx matched unreturned buffer\n",
 					proc->pid, thread->pid, (u64)data_ptr);
 				break;
 			}
 			binder_debug(BINDER_DEBUG_FREE_BUFFER,
 				     "%d:%d BC_FREE_BUFFER u%016llx found buffer %d for %s transaction\n",
 				     proc->pid, thread->pid, (u64)data_ptr,
 				     buffer->debug_id,
 				     buffer->transaction ? "active" : "finished");
 
 			if (buffer->transaction) {
 				buffer->transaction->buffer = NULL;
 				buffer->transaction = NULL;
 			}
 			if (buffer->async_transaction && buffer->target_node) {
 				BUG_ON(!buffer->target_node->has_async_transaction);
 				if (list_empty(&buffer->target_node->async_todo))
 					buffer->target_node->has_async_transaction = 0;
 				else
 					list_move_tail(buffer->target_node->async_todo.next, &thread->todo);
 			}
 			trace_binder_transaction_buffer_release(buffer);
 			binder_transaction_buffer_release(proc, buffer, NULL);
 			binder_free_buf(proc, buffer);
 			break;
 		}
 
+		case BC_TRANSACTION_SG:
+		case BC_REPLY_SG: {
+			struct binder_transaction_data_sg tr;
+
+			if (copy_from_user(&tr, ptr, sizeof(tr)))
+				return -EFAULT;
+			ptr += sizeof(tr);
+			binder_transaction(proc, thread, &tr.transaction_data,
+					   cmd == BC_REPLY_SG, tr.buffers_size);
+			break;
+		}
 		case BC_TRANSACTION:
 		case BC_REPLY: {
 			struct binder_transaction_data tr;
 
 			if (copy_from_user(&tr, ptr, sizeof(tr)))
 				return -EFAULT;
 			ptr += sizeof(tr);
-			binder_transaction(proc, thread, &tr, cmd == BC_REPLY);
+			binder_transaction(proc, thread, &tr,
+					   cmd == BC_REPLY, 0);
 			break;
 		}
 
 		case BC_REGISTER_LOOPER:
 			binder_debug(BINDER_DEBUG_THREADS,
 				     "%d:%d BC_REGISTER_LOOPER\n",
 				     proc->pid, thread->pid);
 			if (thread->looper & BINDER_LOOPER_STATE_ENTERED) {
 				thread->looper |= BINDER_LOOPER_STATE_INVALID;
 				binder_user_error("%d:%d ERROR: BC_REGISTER_LOOPER called after BC_ENTER_LOOPER\n",
 					proc->pid, thread->pid);
 			} else if (proc->requested_threads == 0) {
 				thread->looper |= BINDER_LOOPER_STATE_INVALID;
 				binder_user_error("%d:%d ERROR: BC_REGISTER_LOOPER called without request\n",
 					proc->pid, thread->pid);
 			} else {
 				proc->requested_threads--;
 				proc->requested_threads_started++;
 			}
 			thread->looper |= BINDER_LOOPER_STATE_REGISTERED;
 			break;
 		case BC_ENTER_LOOPER:
 			binder_debug(BINDER_DEBUG_THREADS,
 				     "%d:%d BC_ENTER_LOOPER\n",
 				     proc->pid, thread->pid);
 			if (thread->looper & BINDER_LOOPER_STATE_REGISTERED) {
 				thread->looper |= BINDER_LOOPER_STATE_INVALID;
 				binder_user_error("%d:%d ERROR: BC_ENTER_LOOPER called after BC_REGISTER_LOOPER\n",
 					proc->pid, thread->pid);
 			}
 			thread->looper |= BINDER_LOOPER_STATE_ENTERED;
 			break;
 		case BC_EXIT_LOOPER:
 			binder_debug(BINDER_DEBUG_THREADS,
 				     "%d:%d BC_EXIT_LOOPER\n",
 				     proc->pid, thread->pid);
 			thread->looper |= BINDER_LOOPER_STATE_EXITED;
 			break;
 
 		case BC_REQUEST_DEATH_NOTIFICATION:
 		case BC_CLEAR_DEATH_NOTIFICATION: {
 			uint32_t target;
 			binder_uintptr_t cookie;
 			struct binder_ref *ref;
 			struct binder_ref_death *death;
 
 			if (get_user(target, (uint32_t __user *)ptr))
 				return -EFAULT;
 			ptr += sizeof(uint32_t);
 			if (get_user(cookie, (binder_uintptr_t __user *)ptr))
 				return -EFAULT;
 			ptr += sizeof(binder_uintptr_t);
 			ref = binder_get_ref(proc, target, false);
 			if (ref == NULL) {
 				binder_user_error("%d:%d %s invalid ref %d\n",
 					proc->pid, thread->pid,
 					cmd == BC_REQUEST_DEATH_NOTIFICATION ?
 					"BC_REQUEST_DEATH_NOTIFICATION" :
 					"BC_CLEAR_DEATH_NOTIFICATION",
 					target);
 				break;
 			}
 
 			binder_debug(BINDER_DEBUG_DEATH_NOTIFICATION,
 				     "%d:%d %s %016llx ref %d desc %d s %d w %d for node %d\n",
 				     proc->pid, thread->pid,
 				     cmd == BC_REQUEST_DEATH_NOTIFICATION ?
 				     "BC_REQUEST_DEATH_NOTIFICATION" :
 				     "BC_CLEAR_DEATH_NOTIFICATION",
 				     (u64)cookie, ref->debug_id, ref->desc,
 				     ref->strong, ref->weak, ref->node->debug_id);
 
 			if (cmd == BC_REQUEST_DEATH_NOTIFICATION) {
 				if (ref->death) {
 					binder_user_error("%d:%d BC_REQUEST_DEATH_NOTIFICATION death notification already set\n",
 						proc->pid, thread->pid);
 					break;
 				}
 				death = kzalloc(sizeof(*death), GFP_KERNEL);
 				if (death == NULL) {
 					thread->return_error = BR_ERROR;
 					binder_debug(BINDER_DEBUG_FAILED_TRANSACTION,
 						     "%d:%d BC_REQUEST_DEATH_NOTIFICATION failed\n",
 						     proc->pid, thread->pid);
 					break;
 				}
 				binder_stats_created(BINDER_STAT_DEATH);
 				INIT_LIST_HEAD(&death->work.entry);
 				death->cookie = cookie;
 				ref->death = death;
 				if (ref->node->proc == NULL) {
 					ref->death->work.type = BINDER_WORK_DEAD_BINDER;
 					if (thread->looper & (BINDER_LOOPER_STATE_REGISTERED | BINDER_LOOPER_STATE_ENTERED)) {
 						list_add_tail(&ref->death->work.entry, &thread->todo);
 					} else {
 						list_add_tail(&ref->death->work.entry, &proc->todo);
 						wake_up_interruptible(&proc->wait);
 					}
 				}
 			} else {
 				if (ref->death == NULL) {
 					binder_user_error("%d:%d BC_CLEAR_DEATH_NOTIFICATION death notification not active\n",
 						proc->pid, thread->pid);
 					break;
 				}
 				death = ref->death;
 				if (death->cookie != cookie) {
 					binder_user_error("%d:%d BC_CLEAR_DEATH_NOTIFICATION death notification cookie mismatch %016llx != %016llx\n",
 						proc->pid, thread->pid,
 						(u64)death->cookie,
 						(u64)cookie);
 					break;
 				}
 				ref->death = NULL;
 				if (list_empty(&death->work.entry)) {
 					death->work.type = BINDER_WORK_CLEAR_DEATH_NOTIFICATION;
 					if (thread->looper & (BINDER_LOOPER_STATE_REGISTERED | BINDER_LOOPER_STATE_ENTERED)) {
 						list_add_tail(&death->work.entry, &thread->todo);
 					} else {
 						list_add_tail(&death->work.entry, &proc->todo);
 						wake_up_interruptible(&proc->wait);
 					}
 				} else {
 					BUG_ON(death->work.type != BINDER_WORK_DEAD_BINDER);
 					death->work.type = BINDER_WORK_DEAD_BINDER_AND_CLEAR;
 				}
 			}
 		} break;
 		case BC_DEAD_BINDER_DONE: {
 			struct binder_work *w;
 			binder_uintptr_t cookie;
 			struct binder_ref_death *death = NULL;
 
 			if (get_user(cookie, (binder_uintptr_t __user *)ptr))
 				return -EFAULT;
 
 			ptr += sizeof(cookie);
 			list_for_each_entry(w, &proc->delivered_death, entry) {
 				struct binder_ref_death *tmp_death = container_of(w, struct binder_ref_death, work);
 
 				if (tmp_death->cookie == cookie) {
 					death = tmp_death;
 					break;
 				}
 			}
 			binder_debug(BINDER_DEBUG_DEAD_BINDER,
 				     "%d:%d BC_DEAD_BINDER_DONE %016llx found %p\n",
 				     proc->pid, thread->pid, (u64)cookie,
 				     death);
 			if (death == NULL) {
 				binder_user_error("%d:%d BC_DEAD_BINDER_DONE %016llx not found\n",
 					proc->pid, thread->pid, (u64)cookie);
 				break;
 			}
 
 			list_del_init(&death->work.entry);
 			if (death->work.type == BINDER_WORK_DEAD_BINDER_AND_CLEAR) {
 				death->work.type = BINDER_WORK_CLEAR_DEATH_NOTIFICATION;
 				if (thread->looper & (BINDER_LOOPER_STATE_REGISTERED | BINDER_LOOPER_STATE_ENTERED)) {
 					list_add_tail(&death->work.entry, &thread->todo);
 				} else {
 					list_add_tail(&death->work.entry, &proc->todo);
 					wake_up_interruptible(&proc->wait);
 				}
 			}
 		} break;
 
 		default:
 			pr_err("%d:%d unknown command %d\n",
 			       proc->pid, thread->pid, cmd);
 			return -EINVAL;
 		}
 		*consumed = ptr - buffer;
 	}
 	return 0;
 }
 
 static void binder_stat_br(struct binder_proc *proc,
 			   struct binder_thread *thread, uint32_t cmd)
 {
 	trace_binder_return(cmd);
 	if (_IOC_NR(cmd) < ARRAY_SIZE(binder_stats.br)) {
 		binder_stats.br[_IOC_NR(cmd)]++;
 		proc->stats.br[_IOC_NR(cmd)]++;
 		thread->stats.br[_IOC_NR(cmd)]++;
 	}
 }
 
 static int binder_has_proc_work(struct binder_proc *proc,
 				struct binder_thread *thread)
 {
 	return !list_empty(&proc->todo) ||
 		(thread->looper & BINDER_LOOPER_STATE_NEED_RETURN);
 }
 
 static int binder_has_thread_work(struct binder_thread *thread)
 {
 	return !list_empty(&thread->todo) || thread->return_error != BR_OK ||
 		(thread->looper & BINDER_LOOPER_STATE_NEED_RETURN);
 }
 
 static int binder_thread_read(struct binder_proc *proc,
 			      struct binder_thread *thread,
 			      binder_uintptr_t binder_buffer, size_t size,
 			      binder_size_t *consumed, int non_block)
 {
 	void __user *buffer = (void __user *)(uintptr_t)binder_buffer;
 	void __user *ptr = buffer + *consumed;
 	void __user *end = buffer + size;
 
 	int ret = 0;
 	int wait_for_proc_work;
 
 	if (*consumed == 0) {
 		if (put_user(BR_NOOP, (uint32_t __user *)ptr))
 			return -EFAULT;
 		ptr += sizeof(uint32_t);
 	}
 
 retry:
 	wait_for_proc_work = thread->transaction_stack == NULL &&
 				list_empty(&thread->todo);
 
 	if (thread->return_error != BR_OK && ptr < end) {
 		if (thread->return_error2 != BR_OK) {
 			if (put_user(thread->return_error2, (uint32_t __user *)ptr))
 				return -EFAULT;
 			ptr += sizeof(uint32_t);
 			binder_stat_br(proc, thread, thread->return_error2);
 			if (ptr == end)
 				goto done;
 			thread->return_error2 = BR_OK;
 		}
 		if (put_user(thread->return_error, (uint32_t __user *)ptr))
 			return -EFAULT;
 		ptr += sizeof(uint32_t);
 		binder_stat_br(proc, thread, thread->return_error);
 		thread->return_error = BR_OK;
 		goto done;
 	}
 
 
 	thread->looper |= BINDER_LOOPER_STATE_WAITING;
 	if (wait_for_proc_work)
 		proc->ready_threads++;
 
 	binder_unlock(__func__);
 
 	trace_binder_wait_for_work(wait_for_proc_work,
 				   !!thread->transaction_stack,
 				   !list_empty(&thread->todo));
 	if (wait_for_proc_work) {
 		if (!(thread->looper & (BINDER_LOOPER_STATE_REGISTERED |
 					BINDER_LOOPER_STATE_ENTERED))) {
 			binder_user_error("%d:%d ERROR: Thread waiting for process work before calling BC_REGISTER_LOOPER or BC_ENTER_LOOPER (state %x)\n",
 				proc->pid, thread->pid, thread->looper);
 			wait_event_interruptible(binder_user_error_wait,
 						 binder_stop_on_user_error < 2);
 		}
 		binder_set_nice(proc->default_priority);
 		if (non_block) {
 			if (!binder_has_proc_work(proc, thread))
 				ret = -EAGAIN;
 		} else
 			ret = wait_event_freezable_exclusive(proc->wait, binder_has_proc_work(proc, thread));
 	} else {
 		if (non_block) {
 			if (!binder_has_thread_work(thread))
 				ret = -EAGAIN;
 		} else
 			ret = wait_event_freezable(thread->wait, binder_has_thread_work(thread));
 	}
 
 	binder_lock(__func__);
 
 	if (wait_for_proc_work)
 		proc->ready_threads--;
 	thread->looper &= ~BINDER_LOOPER_STATE_WAITING;
 
 	if (ret)
 		return ret;
 
 	while (1) {
 		uint32_t cmd;
 		struct binder_transaction_data tr;
 		struct binder_work *w;
 		struct binder_transaction *t = NULL;
 
 		if (!list_empty(&thread->todo)) {
 			w = list_first_entry(&thread->todo, struct binder_work,
 					     entry);
 		} else if (!list_empty(&proc->todo) && wait_for_proc_work) {
 			w = list_first_entry(&proc->todo, struct binder_work,
 					     entry);
 		} else {
 			/* no data added */
 			if (ptr - buffer == 4 &&
 			    !(thread->looper & BINDER_LOOPER_STATE_NEED_RETURN))
 				goto retry;
 			break;
 		}
 
 		if (end - ptr < sizeof(tr) + 4)
 			break;
 
 		switch (w->type) {
 		case BINDER_WORK_TRANSACTION: {
 			t = container_of(w, struct binder_transaction, work);
 		} break;
 		case BINDER_WORK_TRANSACTION_COMPLETE: {
 			cmd = BR_TRANSACTION_COMPLETE;
 			if (put_user(cmd, (uint32_t __user *)ptr))
 				return -EFAULT;
 			ptr += sizeof(uint32_t);
 
 			binder_stat_br(proc, thread, cmd);
 			binder_debug(BINDER_DEBUG_TRANSACTION_COMPLETE,
 				     "%d:%d BR_TRANSACTION_COMPLETE\n",
 				     proc->pid, thread->pid);
 
 			list_del(&w->entry);
 			kfree(w);
 			binder_stats_deleted(BINDER_STAT_TRANSACTION_COMPLETE);
 		} break;
 		case BINDER_WORK_NODE: {
 			struct binder_node *node = container_of(w, struct binder_node, work);
 			uint32_t cmd = BR_NOOP;
 			const char *cmd_name;
 			int strong = node->internal_strong_refs || node->local_strong_refs;
 			int weak = !hlist_empty(&node->refs) || node->local_weak_refs || strong;
 
 			if (weak && !node->has_weak_ref) {
 				cmd = BR_INCREFS;
 				cmd_name = "BR_INCREFS";
 				node->has_weak_ref = 1;
 				node->pending_weak_ref = 1;
 				node->local_weak_refs++;
 			} else if (strong && !node->has_strong_ref) {
 				cmd = BR_ACQUIRE;
 				cmd_name = "BR_ACQUIRE";
 				node->has_strong_ref = 1;
 				node->pending_strong_ref = 1;
 				node->local_strong_refs++;
 			} else if (!strong && node->has_strong_ref) {
 				cmd = BR_RELEASE;
 				cmd_name = "BR_RELEASE";
 				node->has_strong_ref = 0;
 			} else if (!weak && node->has_weak_ref) {
 				cmd = BR_DECREFS;
 				cmd_name = "BR_DECREFS";
 				node->has_weak_ref = 0;
 			}
 			if (cmd != BR_NOOP) {
 				if (put_user(cmd, (uint32_t __user *)ptr))
 					return -EFAULT;
 				ptr += sizeof(uint32_t);
 				if (put_user(node->ptr,
 					     (binder_uintptr_t __user *)ptr))
 					return -EFAULT;
 				ptr += sizeof(binder_uintptr_t);
 				if (put_user(node->cookie,
 					     (binder_uintptr_t __user *)ptr))
 					return -EFAULT;
 				ptr += sizeof(binder_uintptr_t);
 
 				binder_stat_br(proc, thread, cmd);
 				binder_debug(BINDER_DEBUG_USER_REFS,
 					     "%d:%d %s %d u%016llx c%016llx\n",
 					     proc->pid, thread->pid, cmd_name,
 					     node->debug_id,
 					     (u64)node->ptr, (u64)node->cookie);
 			} else {
 				list_del_init(&w->entry);
 				if (!weak && !strong) {
 					binder_debug(BINDER_DEBUG_INTERNAL_REFS,
 						     "%d:%d node %d u%016llx c%016llx deleted\n",
 						     proc->pid, thread->pid,
 						     node->debug_id,
 						     (u64)node->ptr,
 						     (u64)node->cookie);
 					rb_erase(&node->rb_node, &proc->nodes);
 					kfree(node);
 					binder_stats_deleted(BINDER_STAT_NODE);
 				} else {
 					binder_debug(BINDER_DEBUG_INTERNAL_REFS,
 						     "%d:%d node %d u%016llx c%016llx state unchanged\n",
 						     proc->pid, thread->pid,
 						     node->debug_id,
 						     (u64)node->ptr,
 						     (u64)node->cookie);
 				}
 			}
 		} break;
 		case BINDER_WORK_DEAD_BINDER:
 		case BINDER_WORK_DEAD_BINDER_AND_CLEAR:
 		case BINDER_WORK_CLEAR_DEATH_NOTIFICATION: {
 			struct binder_ref_death *death;
 			uint32_t cmd;
 
 			death = container_of(w, struct binder_ref_death, work);
 			if (w->type == BINDER_WORK_CLEAR_DEATH_NOTIFICATION)
 				cmd = BR_CLEAR_DEATH_NOTIFICATION_DONE;
 			else
 				cmd = BR_DEAD_BINDER;
 			if (put_user(cmd, (uint32_t __user *)ptr))
 				return -EFAULT;
 			ptr += sizeof(uint32_t);
 			if (put_user(death->cookie,
 				     (binder_uintptr_t __user *)ptr))
 				return -EFAULT;
 			ptr += sizeof(binder_uintptr_t);
 			binder_stat_br(proc, thread, cmd);
 			binder_debug(BINDER_DEBUG_DEATH_NOTIFICATION,
 				     "%d:%d %s %016llx\n",
 				      proc->pid, thread->pid,
 				      cmd == BR_DEAD_BINDER ?
 				      "BR_DEAD_BINDER" :
 				      "BR_CLEAR_DEATH_NOTIFICATION_DONE",
 				      (u64)death->cookie);
 
 			if (w->type == BINDER_WORK_CLEAR_DEATH_NOTIFICATION) {
 				list_del(&w->entry);
 				kfree(death);
 				binder_stats_deleted(BINDER_STAT_DEATH);
 			} else
 				list_move(&w->entry, &proc->delivered_death);
 			if (cmd == BR_DEAD_BINDER)
 				goto done; /* DEAD_BINDER notifications can cause transactions */
 		} break;
 		}
 
 		if (!t)
 			continue;
 
 		BUG_ON(t->buffer == NULL);
 		if (t->buffer->target_node) {
 			struct binder_node *target_node = t->buffer->target_node;
 
 			tr.target.ptr = target_node->ptr;
 			tr.cookie =  target_node->cookie;
 			t->saved_priority = task_nice(current);
 			if (t->priority < target_node->min_priority &&
 			    !(t->flags & TF_ONE_WAY))
 				binder_set_nice(t->priority);
 			else if (!(t->flags & TF_ONE_WAY) ||
 				 t->saved_priority > target_node->min_priority)
 				binder_set_nice(target_node->min_priority);
 			cmd = BR_TRANSACTION;
 		} else {
 			tr.target.ptr = 0;
 			tr.cookie = 0;
 			cmd = BR_REPLY;
 		}
 		tr.code = t->code;
 		tr.flags = t->flags;
 		tr.sender_euid = from_kuid(current_user_ns(), t->sender_euid);
 
 		if (t->from) {
 			struct task_struct *sender = t->from->proc->tsk;
 
 			tr.sender_pid = task_tgid_nr_ns(sender,
 							task_active_pid_ns(current));
 		} else {
 			tr.sender_pid = 0;
 		}
 
 		tr.data_size = t->buffer->data_size;
 		tr.offsets_size = t->buffer->offsets_size;
 		tr.data.ptr.buffer = (binder_uintptr_t)(
 					(uintptr_t)t->buffer->data +
 					proc->user_buffer_offset);
 		tr.data.ptr.offsets = tr.data.ptr.buffer +
 					ALIGN(t->buffer->data_size,
 					    sizeof(void *));
 
 		if (put_user(cmd, (uint32_t __user *)ptr))
 			return -EFAULT;
 		ptr += sizeof(uint32_t);
 		if (copy_to_user(ptr, &tr, sizeof(tr)))
 			return -EFAULT;
 		ptr += sizeof(tr);
 
 		trace_binder_transaction_received(t);
 		binder_stat_br(proc, thread, cmd);
 		binder_debug(BINDER_DEBUG_TRANSACTION,
 			     "%d:%d %s %d %d:%d, cmd %d size %zd-%zd ptr %016llx-%016llx\n",
 			     proc->pid, thread->pid,
 			     (cmd == BR_TRANSACTION) ? "BR_TRANSACTION" :
 			     "BR_REPLY",
 			     t->debug_id, t->from ? t->from->proc->pid : 0,
 			     t->from ? t->from->pid : 0, cmd,
 			     t->buffer->data_size, t->buffer->offsets_size,
 			     (u64)tr.data.ptr.buffer, (u64)tr.data.ptr.offsets);
 
 		list_del(&t->work.entry);
 		t->buffer->allow_user_free = 1;
 		if (cmd == BR_TRANSACTION && !(t->flags & TF_ONE_WAY)) {
 			t->to_parent = thread->transaction_stack;
 			t->to_thread = thread;
 			thread->transaction_stack = t;
 		} else {
 			t->buffer->transaction = NULL;
 			kfree(t);
 			binder_stats_deleted(BINDER_STAT_TRANSACTION);
 		}
 		break;
 	}
 
 done:
 
 	*consumed = ptr - buffer;
 	if (proc->requested_threads + proc->ready_threads == 0 &&
 	    proc->requested_threads_started < proc->max_threads &&
 	    (thread->looper & (BINDER_LOOPER_STATE_REGISTERED |
 	     BINDER_LOOPER_STATE_ENTERED)) /* the user-space code fails to */
 	     /*spawn a new thread if we leave this out */) {
 		proc->requested_threads++;
 		binder_debug(BINDER_DEBUG_THREADS,
 			     "%d:%d BR_SPAWN_LOOPER\n",
 			     proc->pid, thread->pid);
 		if (put_user(BR_SPAWN_LOOPER, (uint32_t __user *)buffer))
 			return -EFAULT;
 		binder_stat_br(proc, thread, BR_SPAWN_LOOPER);
 	}
 	return 0;
 }
 
 static void binder_release_work(struct list_head *list)
 {
 	struct binder_work *w;
 
 	while (!list_empty(list)) {
 		w = list_first_entry(list, struct binder_work, entry);
 		list_del_init(&w->entry);
 		switch (w->type) {
 		case BINDER_WORK_TRANSACTION: {
 			struct binder_transaction *t;
 
 			t = container_of(w, struct binder_transaction, work);
 			if (t->buffer->target_node &&
 			    !(t->flags & TF_ONE_WAY)) {
 				binder_send_failed_reply(t, BR_DEAD_REPLY);
 			} else {
 				binder_debug(BINDER_DEBUG_DEAD_TRANSACTION,
 					"undelivered transaction %d\n",
 					t->debug_id);
 				t->buffer->transaction = NULL;
 				kfree(t);
 				binder_stats_deleted(BINDER_STAT_TRANSACTION);
 			}
 		} break;
 		case BINDER_WORK_TRANSACTION_COMPLETE: {
 			binder_debug(BINDER_DEBUG_DEAD_TRANSACTION,
 				"undelivered TRANSACTION_COMPLETE\n");
 			kfree(w);
 			binder_stats_deleted(BINDER_STAT_TRANSACTION_COMPLETE);
 		} break;
 		case BINDER_WORK_DEAD_BINDER_AND_CLEAR:
 		case BINDER_WORK_CLEAR_DEATH_NOTIFICATION: {
 			struct binder_ref_death *death;
 
 			death = container_of(w, struct binder_ref_death, work);
 			binder_debug(BINDER_DEBUG_DEAD_TRANSACTION,
 				"undelivered death notification, %016llx\n",
 				(u64)death->cookie);
 			kfree(death);
 			binder_stats_deleted(BINDER_STAT_DEATH);
 		} break;
 		default:
 			pr_err("unexpected work type, %d, not freed\n",
 			       w->type);
 			break;
 		}
 	}
 
 }
 
 static struct binder_thread *binder_get_thread(struct binder_proc *proc)
 {
 	struct binder_thread *thread = NULL;
 	struct rb_node *parent = NULL;
 	struct rb_node **p = &proc->threads.rb_node;
 
 	while (*p) {
 		parent = *p;
 		thread = rb_entry(parent, struct binder_thread, rb_node);
 
 		if (current->pid < thread->pid)
 			p = &(*p)->rb_left;
 		else if (current->pid > thread->pid)
 			p = &(*p)->rb_right;
 		else
 			break;
 	}
 	if (*p == NULL) {
 		thread = kzalloc(sizeof(*thread), GFP_KERNEL);
 		if (thread == NULL)
 			return NULL;
 		binder_stats_created(BINDER_STAT_THREAD);
 		thread->proc = proc;
 		thread->pid = current->pid;
 		init_waitqueue_head(&thread->wait);
 		INIT_LIST_HEAD(&thread->todo);
 		rb_link_node(&thread->rb_node, parent, p);
 		rb_insert_color(&thread->rb_node, &proc->threads);
 		thread->looper |= BINDER_LOOPER_STATE_NEED_RETURN;
 		thread->return_error = BR_OK;
 		thread->return_error2 = BR_OK;
 	}
 	return thread;
 }
 
 static int binder_free_thread(struct binder_proc *proc,
 			      struct binder_thread *thread)
 {
 	struct binder_transaction *t;
 	struct binder_transaction *send_reply = NULL;
 	int active_transactions = 0;
 
 	rb_erase(&thread->rb_node, &proc->threads);
 	t = thread->transaction_stack;
 	if (t && t->to_thread == thread)
 		send_reply = t;
 	while (t) {
 		active_transactions++;
 		binder_debug(BINDER_DEBUG_DEAD_TRANSACTION,
 			     "release %d:%d transaction %d %s, still active\n",
 			      proc->pid, thread->pid,
 			     t->debug_id,
 			     (t->to_thread == thread) ? "in" : "out");
 
 		if (t->to_thread == thread) {
 			t->to_proc = NULL;
 			t->to_thread = NULL;
 			if (t->buffer) {
 				t->buffer->transaction = NULL;
 				t->buffer = NULL;
 			}
 			t = t->to_parent;
 		} else if (t->from == thread) {
 			t->from = NULL;
 			t = t->from_parent;
 		} else
 			BUG();
 	}
 	if (send_reply)
 		binder_send_failed_reply(send_reply, BR_DEAD_REPLY);
 	binder_release_work(&thread->todo);
 	kfree(thread);
 	binder_stats_deleted(BINDER_STAT_THREAD);
 	return active_transactions;
 }
 
 static unsigned int binder_poll(struct file *filp,
 				struct poll_table_struct *wait)
 {
 	struct binder_proc *proc = filp->private_data;
 	struct binder_thread *thread = NULL;
 	int wait_for_proc_work;
 
 	binder_lock(__func__);
 
 	thread = binder_get_thread(proc);
 
 	wait_for_proc_work = thread->transaction_stack == NULL &&
 		list_empty(&thread->todo) && thread->return_error == BR_OK;
 
 	binder_unlock(__func__);
 
 	if (wait_for_proc_work) {
 		if (binder_has_proc_work(proc, thread))
 			return POLLIN;
 		poll_wait(filp, &proc->wait, wait);
 		if (binder_has_proc_work(proc, thread))
 			return POLLIN;
 	} else {
 		if (binder_has_thread_work(thread))
 			return POLLIN;
 		poll_wait(filp, &thread->wait, wait);
 		if (binder_has_thread_work(thread))
 			return POLLIN;
 	}
 	return 0;
 }
 
 static int binder_ioctl_write_read(struct file *filp,
 				unsigned int cmd, unsigned long arg,
 				struct binder_thread *thread)
 {
 	int ret = 0;
 	struct binder_proc *proc = filp->private_data;
 	unsigned int size = _IOC_SIZE(cmd);
 	void __user *ubuf = (void __user *)arg;
 	struct binder_write_read bwr;
 
 	if (size != sizeof(struct binder_write_read)) {
 		ret = -EINVAL;
 		goto out;
 	}
 	if (copy_from_user(&bwr, ubuf, sizeof(bwr))) {
 		ret = -EFAULT;
 		goto out;
 	}
 	binder_debug(BINDER_DEBUG_READ_WRITE,
 		     "%d:%d write %lld at %016llx, read %lld at %016llx\n",
 		     proc->pid, thread->pid,
 		     (u64)bwr.write_size, (u64)bwr.write_buffer,
 		     (u64)bwr.read_size, (u64)bwr.read_buffer);
 
 	if (bwr.write_size > 0) {
 		ret = binder_thread_write(proc, thread,
 					  bwr.write_buffer,
 					  bwr.write_size,
 					  &bwr.write_consumed);
 		trace_binder_write_done(ret);
 		if (ret < 0) {
 			bwr.read_consumed = 0;
 			if (copy_to_user(ubuf, &bwr, sizeof(bwr)))
 				ret = -EFAULT;
 			goto out;
 		}
 	}
 	if (bwr.read_size > 0) {
 		ret = binder_thread_read(proc, thread, bwr.read_buffer,
 					 bwr.read_size,
 					 &bwr.read_consumed,
 					 filp->f_flags & O_NONBLOCK);
 		trace_binder_read_done(ret);
 		if (!list_empty(&proc->todo))
 			wake_up_interruptible(&proc->wait);
 		if (ret < 0) {
 			if (copy_to_user(ubuf, &bwr, sizeof(bwr)))
 				ret = -EFAULT;
 			goto out;
 		}
 	}
 	binder_debug(BINDER_DEBUG_READ_WRITE,
 		     "%d:%d wrote %lld of %lld, read return %lld of %lld\n",
 		     proc->pid, thread->pid,
 		     (u64)bwr.write_consumed, (u64)bwr.write_size,
 		     (u64)bwr.read_consumed, (u64)bwr.read_size);
 	if (copy_to_user(ubuf, &bwr, sizeof(bwr))) {
 		ret = -EFAULT;
 		goto out;
 	}
 out:
 	return ret;
 }
 
 static int binder_ioctl_set_ctx_mgr(struct file *filp)
 {
 	int ret = 0;
 	struct binder_proc *proc = filp->private_data;
+	struct binder_context *context = proc->context;
+
 	kuid_t curr_euid = current_euid();
 
-	if (binder_context_mgr_node != NULL) {
+	if (context->binder_context_mgr_node) {
 		pr_err("BINDER_SET_CONTEXT_MGR already set\n");
 		ret = -EBUSY;
 		goto out;
 	}
 	ret = security_binder_set_context_mgr(proc->tsk);
 	if (ret < 0)
 		goto out;
-	if (uid_valid(binder_context_mgr_uid)) {
-		if (!uid_eq(binder_context_mgr_uid, curr_euid)) {
+	if (uid_valid(context->binder_context_mgr_uid)) {
+		if (!uid_eq(context->binder_context_mgr_uid, curr_euid)) {
 			pr_err("BINDER_SET_CONTEXT_MGR bad uid %d != %d\n",
 			       from_kuid(&init_user_ns, curr_euid),
 			       from_kuid(&init_user_ns,
-					binder_context_mgr_uid));
+					 context->binder_context_mgr_uid));
 			ret = -EPERM;
 			goto out;
 		}
 	} else {
-		binder_context_mgr_uid = curr_euid;
+		context->binder_context_mgr_uid = curr_euid;
 	}
-	binder_context_mgr_node = binder_new_node(proc, 0, 0);
-	if (binder_context_mgr_node == NULL) {
+	context->binder_context_mgr_node = binder_new_node(proc, 0, 0);
+	if (!context->binder_context_mgr_node) {
 		ret = -ENOMEM;
 		goto out;
 	}
-	binder_context_mgr_node->local_weak_refs++;
-	binder_context_mgr_node->local_strong_refs++;
-	binder_context_mgr_node->has_strong_ref = 1;
-	binder_context_mgr_node->has_weak_ref = 1;
+	context->binder_context_mgr_node->local_weak_refs++;
+	context->binder_context_mgr_node->local_strong_refs++;
+	context->binder_context_mgr_node->has_strong_ref = 1;
+	context->binder_context_mgr_node->has_weak_ref = 1;
 out:
 	return ret;
 }
 
 static long binder_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)
 {
 	int ret;
 	struct binder_proc *proc = filp->private_data;
 	struct binder_thread *thread;
 	unsigned int size = _IOC_SIZE(cmd);
 	void __user *ubuf = (void __user *)arg;
 
 	/*pr_info("binder_ioctl: %d:%d %x %lx\n",
 			proc->pid, current->pid, cmd, arg);*/
 
 	if (unlikely(current->mm != proc->vma_vm_mm)) {
 		pr_err("current mm mismatch proc mm\n");
 		return -EINVAL;
 	}
 	trace_binder_ioctl(cmd, arg);
 
 	ret = wait_event_interruptible(binder_user_error_wait, binder_stop_on_user_error < 2);
 	if (ret)
 		goto err_unlocked;
 
 	binder_lock(__func__);
 	thread = binder_get_thread(proc);
 	if (thread == NULL) {
 		ret = -ENOMEM;
 		goto err;
 	}
 
 	switch (cmd) {
 	case BINDER_WRITE_READ:
 		ret = binder_ioctl_write_read(filp, cmd, arg, thread);
 		if (ret)
 			goto err;
 		break;
 	case BINDER_SET_MAX_THREADS:
 		if (copy_from_user(&proc->max_threads, ubuf, sizeof(proc->max_threads))) {
 			ret = -EINVAL;
 			goto err;
 		}
 		break;
 	case BINDER_SET_CONTEXT_MGR:
 		ret = binder_ioctl_set_ctx_mgr(filp);
 		if (ret)
 			goto err;
 		break;
 	case BINDER_THREAD_EXIT:
 		binder_debug(BINDER_DEBUG_THREADS, "%d:%d exit\n",
 			     proc->pid, thread->pid);
 		binder_free_thread(proc, thread);
 		thread = NULL;
 		break;
 	case BINDER_VERSION: {
 		struct binder_version __user *ver = ubuf;
 
 		if (size != sizeof(struct binder_version)) {
 			ret = -EINVAL;
 			goto err;
 		}
 		if (put_user(BINDER_CURRENT_PROTOCOL_VERSION,
 			     &ver->protocol_version)) {
 			ret = -EINVAL;
 			goto err;
 		}
 		break;
 	}
 	default:
 		ret = -EINVAL;
 		goto err;
 	}
 	ret = 0;
 err:
 	if (thread)
 		thread->looper &= ~BINDER_LOOPER_STATE_NEED_RETURN;
 	binder_unlock(__func__);
 	wait_event_interruptible(binder_user_error_wait, binder_stop_on_user_error < 2);
 	if (ret && ret != -ERESTARTSYS)
 		pr_info("%d:%d ioctl %x %lx returned %d\n", proc->pid, current->pid, cmd, arg, ret);
 err_unlocked:
 	trace_binder_ioctl_done(ret);
 	return ret;
 }
 
 static void binder_vma_open(struct vm_area_struct *vma)
 {
 	struct binder_proc *proc = vma->vm_private_data;
 
 	binder_debug(BINDER_DEBUG_OPEN_CLOSE,
 		     "%d open vm area %lx-%lx (%ld K) vma %lx pagep %lx\n",
 		     proc->pid, vma->vm_start, vma->vm_end,
 		     (vma->vm_end - vma->vm_start) / SZ_1K, vma->vm_flags,
 		     (unsigned long)pgprot_val(vma->vm_page_prot));
 }
 
 static void binder_vma_close(struct vm_area_struct *vma)
 {
 	struct binder_proc *proc = vma->vm_private_data;
 
 	binder_debug(BINDER_DEBUG_OPEN_CLOSE,
 		     "%d close vm area %lx-%lx (%ld K) vma %lx pagep %lx\n",
 		     proc->pid, vma->vm_start, vma->vm_end,
 		     (vma->vm_end - vma->vm_start) / SZ_1K, vma->vm_flags,
 		     (unsigned long)pgprot_val(vma->vm_page_prot));
 	proc->vma = NULL;
 	proc->vma_vm_mm = NULL;
 	binder_defer_work(proc, BINDER_DEFERRED_PUT_FILES);
 }
 
 static int binder_vm_fault(struct vm_area_struct *vma, struct vm_fault *vmf)
 {
 	return VM_FAULT_SIGBUS;
 }
 
 static const struct vm_operations_struct binder_vm_ops = {
 	.open = binder_vma_open,
 	.close = binder_vma_close,
 	.fault = binder_vm_fault,
 };
 
 static int binder_mmap(struct file *filp, struct vm_area_struct *vma)
 {
 	int ret;
 	struct vm_struct *area;
 	struct binder_proc *proc = filp->private_data;
 	const char *failure_string;
 	struct binder_buffer *buffer;
 
 	if (proc->tsk != current)
 		return -EINVAL;
 
 	if ((vma->vm_end - vma->vm_start) > SZ_4M)
 		vma->vm_end = vma->vm_start + SZ_4M;
 
 	binder_debug(BINDER_DEBUG_OPEN_CLOSE,
 		     "binder_mmap: %d %lx-%lx (%ld K) vma %lx pagep %lx\n",
 		     proc->pid, vma->vm_start, vma->vm_end,
 		     (vma->vm_end - vma->vm_start) / SZ_1K, vma->vm_flags,
 		     (unsigned long)pgprot_val(vma->vm_page_prot));
 
 	if (vma->vm_flags & FORBIDDEN_MMAP_FLAGS) {
 		ret = -EPERM;
 		failure_string = "bad vm_flags";
 		goto err_bad_arg;
 	}
 	vma->vm_flags = (vma->vm_flags | VM_DONTCOPY) & ~VM_MAYWRITE;
 
 	mutex_lock(&binder_mmap_lock);
 	if (proc->buffer) {
 		ret = -EBUSY;
 		failure_string = "already mapped";
 		goto err_already_mapped;
 	}
 
 	area = get_vm_area(vma->vm_end - vma->vm_start, VM_IOREMAP);
 	if (area == NULL) {
 		ret = -ENOMEM;
 		failure_string = "get_vm_area";
 		goto err_get_vm_area_failed;
 	}
 	proc->buffer = area->addr;
 	proc->user_buffer_offset = vma->vm_start - (uintptr_t)proc->buffer;
 	mutex_unlock(&binder_mmap_lock);
 
 #ifdef CONFIG_CPU_CACHE_VIPT
 	if (cache_is_vipt_aliasing()) {
 		while (CACHE_COLOUR((vma->vm_start ^ (uint32_t)proc->buffer))) {
 			pr_info("binder_mmap: %d %lx-%lx maps %p bad alignment\n", proc->pid, vma->vm_start, vma->vm_end, proc->buffer);
 			vma->vm_start += PAGE_SIZE;
 		}
 	}
 #endif
 	proc->pages = kzalloc(sizeof(proc->pages[0]) * ((vma->vm_end - vma->vm_start) / PAGE_SIZE), GFP_KERNEL);
 	if (proc->pages == NULL) {
 		ret = -ENOMEM;
 		failure_string = "alloc page array";
 		goto err_alloc_pages_failed;
 	}
 	proc->buffer_size = vma->vm_end - vma->vm_start;
 
 	vma->vm_ops = &binder_vm_ops;
 	vma->vm_private_data = proc;
 
 	if (binder_update_page_range(proc, 1, proc->buffer, proc->buffer + PAGE_SIZE, vma)) {
 		ret = -ENOMEM;
 		failure_string = "alloc small buf";
 		goto err_alloc_small_buf_failed;
 	}
 	buffer = proc->buffer;
 	INIT_LIST_HEAD(&proc->buffers);
 	list_add(&buffer->entry, &proc->buffers);
 	buffer->free = 1;
 	binder_insert_free_buffer(proc, buffer);
 	proc->free_async_space = proc->buffer_size / 2;
 	barrier();
 	proc->files = get_files_struct(current);
 	proc->vma = vma;
 	proc->vma_vm_mm = vma->vm_mm;
 
 	/*pr_info("binder_mmap: %d %lx-%lx maps %p\n",
 		 proc->pid, vma->vm_start, vma->vm_end, proc->buffer);*/
 	return 0;
 
 err_alloc_small_buf_failed:
 	kfree(proc->pages);
 	proc->pages = NULL;
 err_alloc_pages_failed:
 	mutex_lock(&binder_mmap_lock);
 	vfree(proc->buffer);
 	proc->buffer = NULL;
 err_get_vm_area_failed:
 err_already_mapped:
 	mutex_unlock(&binder_mmap_lock);
 err_bad_arg:
 	pr_err("binder_mmap: %d %lx-%lx %s failed %d\n",
 	       proc->pid, vma->vm_start, vma->vm_end, failure_string, ret);
 	return ret;
 }
 
 static int binder_open(struct inode *nodp, struct file *filp)
 {
 	struct binder_proc *proc;
+	struct binder_device *binder_dev;
 
 	binder_debug(BINDER_DEBUG_OPEN_CLOSE, "binder_open: %d:%d\n",
 		     current->group_leader->pid, current->pid);
 
 	proc = kzalloc(sizeof(*proc), GFP_KERNEL);
 	if (proc == NULL)
 		return -ENOMEM;
 	get_task_struct(current);
 	proc->tsk = current;
 	proc->vma_vm_mm = current->mm;
 	INIT_LIST_HEAD(&proc->todo);
 	init_waitqueue_head(&proc->wait);
 	proc->default_priority = task_nice(current);
+	binder_dev = container_of(filp->private_data, struct binder_device,
+				  miscdev);
+	proc->context = &binder_dev->context;
 
 	binder_lock(__func__);
 
 	binder_stats_created(BINDER_STAT_PROC);
 	hlist_add_head(&proc->proc_node, &binder_procs);
 	proc->pid = current->group_leader->pid;
 	INIT_LIST_HEAD(&proc->delivered_death);
 	filp->private_data = proc;
 
 	binder_unlock(__func__);
 
 	if (binder_debugfs_dir_entry_proc) {
 		char strbuf[11];
 
 		snprintf(strbuf, sizeof(strbuf), "%u", proc->pid);
+		/*
+		 * proc debug entries are shared between contexts, so
+		 * this will fail if the process tries to open the driver
+		 * again with a different context. The priting code will
+		 * anyway print all contexts that a given PID has, so this
+		 * is not a problem.
+		 */
 		proc->debugfs_entry = debugfs_create_file(strbuf, S_IRUGO,
-			binder_debugfs_dir_entry_proc, proc, &binder_proc_fops);
+			binder_debugfs_dir_entry_proc,
+			(void *)(unsigned long)proc->pid,
+			&binder_proc_fops);
 	}
 
 	return 0;
 }
 
 static int binder_flush(struct file *filp, fl_owner_t id)
 {
 	struct binder_proc *proc = filp->private_data;
 
 	binder_defer_work(proc, BINDER_DEFERRED_FLUSH);
 
 	return 0;
 }
 
 static void binder_deferred_flush(struct binder_proc *proc)
 {
 	struct rb_node *n;
 	int wake_count = 0;
 
 	for (n = rb_first(&proc->threads); n != NULL; n = rb_next(n)) {
 		struct binder_thread *thread = rb_entry(n, struct binder_thread, rb_node);
 
 		thread->looper |= BINDER_LOOPER_STATE_NEED_RETURN;
 		if (thread->looper & BINDER_LOOPER_STATE_WAITING) {
 			wake_up_interruptible(&thread->wait);
 			wake_count++;
 		}
 	}
 	wake_up_interruptible_all(&proc->wait);
 
 	binder_debug(BINDER_DEBUG_OPEN_CLOSE,
 		     "binder_flush: %d woke %d threads\n", proc->pid,
 		     wake_count);
 }
 
 static int binder_release(struct inode *nodp, struct file *filp)
 {
 	struct binder_proc *proc = filp->private_data;
 
 	debugfs_remove(proc->debugfs_entry);
 	binder_defer_work(proc, BINDER_DEFERRED_RELEASE);
 
 	return 0;
 }
 
 static int binder_node_release(struct binder_node *node, int refs)
 {
 	struct binder_ref *ref;
 	int death = 0;
 
 	list_del_init(&node->work.entry);
 	binder_release_work(&node->async_todo);
 
 	if (hlist_empty(&node->refs)) {
 		kfree(node);
 		binder_stats_deleted(BINDER_STAT_NODE);
 
 		return refs;
 	}
 
 	node->proc = NULL;
 	node->local_strong_refs = 0;
 	node->local_weak_refs = 0;
 	hlist_add_head(&node->dead_node, &binder_dead_nodes);
 
 	hlist_for_each_entry(ref, &node->refs, node_entry) {
 		refs++;
 
 		if (!ref->death)
 			continue;
 
 		death++;
 
 		if (list_empty(&ref->death->work.entry)) {
 			ref->death->work.type = BINDER_WORK_DEAD_BINDER;
 			list_add_tail(&ref->death->work.entry,
 				      &ref->proc->todo);
 			wake_up_interruptible(&ref->proc->wait);
 		} else
 			BUG();
 	}
 
 	binder_debug(BINDER_DEBUG_DEAD_BINDER,
 		     "node %d now dead, refs %d, death %d\n",
 		     node->debug_id, refs, death);
 
 	return refs;
 }
 
 static void binder_deferred_release(struct binder_proc *proc)
 {
 	struct binder_transaction *t;
+	struct binder_context *context = proc->context;
 	struct rb_node *n;
 	int threads, nodes, incoming_refs, outgoing_refs, buffers,
 		active_transactions, page_count;
 
 	BUG_ON(proc->vma);
 	BUG_ON(proc->files);
 
 	hlist_del(&proc->proc_node);
 
-	if (binder_context_mgr_node && binder_context_mgr_node->proc == proc) {
+	if (context->binder_context_mgr_node &&
+	    context->binder_context_mgr_node->proc == proc) {
 		binder_debug(BINDER_DEBUG_DEAD_BINDER,
 			     "%s: %d context_mgr_node gone\n",
 			     __func__, proc->pid);
-		binder_context_mgr_node = NULL;
+		context->binder_context_mgr_node = NULL;
 	}
 
 	threads = 0;
 	active_transactions = 0;
 	while ((n = rb_first(&proc->threads))) {
 		struct binder_thread *thread;
 
 		thread = rb_entry(n, struct binder_thread, rb_node);
 		threads++;
 		active_transactions += binder_free_thread(proc, thread);
 	}
 
 	nodes = 0;
 	incoming_refs = 0;
 	while ((n = rb_first(&proc->nodes))) {
 		struct binder_node *node;
 
 		node = rb_entry(n, struct binder_node, rb_node);
 		nodes++;
 		rb_erase(&node->rb_node, &proc->nodes);
 		incoming_refs = binder_node_release(node, incoming_refs);
 	}
 
 	outgoing_refs = 0;
 	while ((n = rb_first(&proc->refs_by_desc))) {
 		struct binder_ref *ref;
 
 		ref = rb_entry(n, struct binder_ref, rb_node_desc);
 		outgoing_refs++;
 		binder_delete_ref(ref);
 	}
 
 	binder_release_work(&proc->todo);
 	binder_release_work(&proc->delivered_death);
 
 	buffers = 0;
 	while ((n = rb_first(&proc->allocated_buffers))) {
 		struct binder_buffer *buffer;
 
 		buffer = rb_entry(n, struct binder_buffer, rb_node);
 
 		t = buffer->transaction;
 		if (t) {
 			t->buffer = NULL;
 			buffer->transaction = NULL;
 			pr_err("release proc %d, transaction %d, not freed\n",
 			       proc->pid, t->debug_id);
 			/*BUG();*/
 		}
 
 		binder_free_buf(proc, buffer);
 		buffers++;
 	}
 
 	binder_stats_deleted(BINDER_STAT_PROC);
 
 	page_count = 0;
 	if (proc->pages) {
 		int i;
 
 		for (i = 0; i < proc->buffer_size / PAGE_SIZE; i++) {
 			void *page_addr;
 
 			if (!proc->pages[i])
 				continue;
 
 			page_addr = proc->buffer + i * PAGE_SIZE;
 			binder_debug(BINDER_DEBUG_BUFFER_ALLOC,
 				     "%s: %d: page %d at %p not freed\n",
 				     __func__, proc->pid, i, page_addr);
 			unmap_kernel_range((unsigned long)page_addr, PAGE_SIZE);
 			__free_page(proc->pages[i]);
 			page_count++;
 		}
 		kfree(proc->pages);
 		vfree(proc->buffer);
 	}
 
 	put_task_struct(proc->tsk);
 
 	binder_debug(BINDER_DEBUG_OPEN_CLOSE,
 		     "%s: %d threads %d, nodes %d (ref %d), refs %d, active transactions %d, buffers %d, pages %d\n",
 		     __func__, proc->pid, threads, nodes, incoming_refs,
 		     outgoing_refs, active_transactions, buffers, page_count);
 
 	kfree(proc);
 }
 
 static void binder_deferred_func(struct work_struct *work)
 {
 	struct binder_proc *proc;
 	struct files_struct *files;
 
 	int defer;
 
 	do {
 		binder_lock(__func__);
 		mutex_lock(&binder_deferred_lock);
 		if (!hlist_empty(&binder_deferred_list)) {
 			proc = hlist_entry(binder_deferred_list.first,
 					struct binder_proc, deferred_work_node);
 			hlist_del_init(&proc->deferred_work_node);
 			defer = proc->deferred_work;
 			proc->deferred_work = 0;
 		} else {
 			proc = NULL;
 			defer = 0;
 		}
 		mutex_unlock(&binder_deferred_lock);
 
 		files = NULL;
 		if (defer & BINDER_DEFERRED_PUT_FILES) {
 			files = proc->files;
 			if (files)
 				proc->files = NULL;
 		}
 
 		if (defer & BINDER_DEFERRED_FLUSH)
 			binder_deferred_flush(proc);
 
 		if (defer & BINDER_DEFERRED_RELEASE)
 			binder_deferred_release(proc); /* frees proc */
 
 		binder_unlock(__func__);
 		if (files)
 			put_files_struct(files);
 	} while (proc);
 }
 static DECLARE_WORK(binder_deferred_work, binder_deferred_func);
 
 static void
 binder_defer_work(struct binder_proc *proc, enum binder_deferred_state defer)
 {
 	mutex_lock(&binder_deferred_lock);
 	proc->deferred_work |= defer;
 	if (hlist_unhashed(&proc->deferred_work_node)) {
 		hlist_add_head(&proc->deferred_work_node,
 				&binder_deferred_list);
 		schedule_work(&binder_deferred_work);
 	}
 	mutex_unlock(&binder_deferred_lock);
 }
 
 static void print_binder_transaction(struct seq_file *m, const char *prefix,
 				     struct binder_transaction *t)
 {
 	seq_printf(m,
 		   "%s %d: %p from %d:%d to %d:%d code %x flags %x pri %ld r%d",
 		   prefix, t->debug_id, t,
 		   t->from ? t->from->proc->pid : 0,
 		   t->from ? t->from->pid : 0,
 		   t->to_proc ? t->to_proc->pid : 0,
 		   t->to_thread ? t->to_thread->pid : 0,
 		   t->code, t->flags, t->priority, t->need_reply);
 	if (t->buffer == NULL) {
 		seq_puts(m, " buffer free\n");
 		return;
 	}
 	if (t->buffer->target_node)
 		seq_printf(m, " node %d",
 			   t->buffer->target_node->debug_id);
 	seq_printf(m, " size %zd:%zd data %p\n",
 		   t->buffer->data_size, t->buffer->offsets_size,
 		   t->buffer->data);
 }
 
 static void print_binder_buffer(struct seq_file *m, const char *prefix,
 				struct binder_buffer *buffer)
 {
 	seq_printf(m, "%s %d: %p size %zd:%zd %s\n",
 		   prefix, buffer->debug_id, buffer->data,
 		   buffer->data_size, buffer->offsets_size,
 		   buffer->transaction ? "active" : "delivered");
 }
 
 static void print_binder_work(struct seq_file *m, const char *prefix,
 			      const char *transaction_prefix,
 			      struct binder_work *w)
 {
 	struct binder_node *node;
 	struct binder_transaction *t;
 
 	switch (w->type) {
 	case BINDER_WORK_TRANSACTION:
 		t = container_of(w, struct binder_transaction, work);
 		print_binder_transaction(m, transaction_prefix, t);
 		break;
 	case BINDER_WORK_TRANSACTION_COMPLETE:
 		seq_printf(m, "%stransaction complete\n", prefix);
 		break;
 	case BINDER_WORK_NODE:
 		node = container_of(w, struct binder_node, work);
 		seq_printf(m, "%snode work %d: u%016llx c%016llx\n",
 			   prefix, node->debug_id,
 			   (u64)node->ptr, (u64)node->cookie);
 		break;
 	case BINDER_WORK_DEAD_BINDER:
 		seq_printf(m, "%shas dead binder\n", prefix);
 		break;
 	case BINDER_WORK_DEAD_BINDER_AND_CLEAR:
 		seq_printf(m, "%shas cleared dead binder\n", prefix);
 		break;
 	case BINDER_WORK_CLEAR_DEATH_NOTIFICATION:
 		seq_printf(m, "%shas cleared death notification\n", prefix);
 		break;
 	default:
 		seq_printf(m, "%sunknown work: type %d\n", prefix, w->type);
 		break;
 	}
 }
 
 static void print_binder_thread(struct seq_file *m,
 				struct binder_thread *thread,
 				int print_always)
 {
 	struct binder_transaction *t;
 	struct binder_work *w;
 	size_t start_pos = m->count;
 	size_t header_pos;
 
 	seq_printf(m, "  thread %d: l %02x\n", thread->pid, thread->looper);
 	header_pos = m->count;
 	t = thread->transaction_stack;
 	while (t) {
 		if (t->from == thread) {
 			print_binder_transaction(m,
 						 "    outgoing transaction", t);
 			t = t->from_parent;
 		} else if (t->to_thread == thread) {
 			print_binder_transaction(m,
 						 "    incoming transaction", t);
 			t = t->to_parent;
 		} else {
 			print_binder_transaction(m, "    bad transaction", t);
 			t = NULL;
 		}
 	}
 	list_for_each_entry(w, &thread->todo, entry) {
 		print_binder_work(m, "    ", "    pending transaction", w);
 	}
 	if (!print_always && m->count == header_pos)
 		m->count = start_pos;
 }
 
 static void print_binder_node(struct seq_file *m, struct binder_node *node)
 {
 	struct binder_ref *ref;
 	struct binder_work *w;
 	int count;
 
 	count = 0;
 	hlist_for_each_entry(ref, &node->refs, node_entry)
 		count++;
 
 	seq_printf(m, "  node %d: u%016llx c%016llx hs %d hw %d ls %d lw %d is %d iw %d",
 		   node->debug_id, (u64)node->ptr, (u64)node->cookie,
 		   node->has_strong_ref, node->has_weak_ref,
 		   node->local_strong_refs, node->local_weak_refs,
 		   node->internal_strong_refs, count);
 	if (count) {
 		seq_puts(m, " proc");
 		hlist_for_each_entry(ref, &node->refs, node_entry)
 			seq_printf(m, " %d", ref->proc->pid);
 	}
 	seq_puts(m, "\n");
 	list_for_each_entry(w, &node->async_todo, entry)
 		print_binder_work(m, "    ",
 				  "    pending async transaction", w);
 }
 
 static void print_binder_ref(struct seq_file *m, struct binder_ref *ref)
 {
 	seq_printf(m, "  ref %d: desc %d %snode %d s %d w %d d %p\n",
 		   ref->debug_id, ref->desc, ref->node->proc ? "" : "dead ",
 		   ref->node->debug_id, ref->strong, ref->weak, ref->death);
 }
 
 static void print_binder_proc(struct seq_file *m,
 			      struct binder_proc *proc, int print_all)
 {
 	struct binder_work *w;
 	struct rb_node *n;
 	size_t start_pos = m->count;
 	size_t header_pos;
 
 	seq_printf(m, "proc %d\n", proc->pid);
+	seq_printf(m, "context %s\n", proc->context->name);
 	header_pos = m->count;
 
 	for (n = rb_first(&proc->threads); n != NULL; n = rb_next(n))
 		print_binder_thread(m, rb_entry(n, struct binder_thread,
 						rb_node), print_all);
 	for (n = rb_first(&proc->nodes); n != NULL; n = rb_next(n)) {
 		struct binder_node *node = rb_entry(n, struct binder_node,
 						    rb_node);
 		if (print_all || node->has_async_transaction)
 			print_binder_node(m, node);
 	}
 	if (print_all) {
 		for (n = rb_first(&proc->refs_by_desc);
 		     n != NULL;
 		     n = rb_next(n))
 			print_binder_ref(m, rb_entry(n, struct binder_ref,
 						     rb_node_desc));
 	}
 	for (n = rb_first(&proc->allocated_buffers); n != NULL; n = rb_next(n))
 		print_binder_buffer(m, "  buffer",
 				    rb_entry(n, struct binder_buffer, rb_node));
 	list_for_each_entry(w, &proc->todo, entry)
 		print_binder_work(m, "  ", "  pending transaction", w);
 	list_for_each_entry(w, &proc->delivered_death, entry) {
 		seq_puts(m, "  has delivered dead binder\n");
 		break;
 	}
 	if (!print_all && m->count == header_pos)
 		m->count = start_pos;
 }
 
 static const char * const binder_return_strings[] = {
 	"BR_ERROR",
 	"BR_OK",
 	"BR_TRANSACTION",
 	"BR_REPLY",
 	"BR_ACQUIRE_RESULT",
 	"BR_DEAD_REPLY",
 	"BR_TRANSACTION_COMPLETE",
 	"BR_INCREFS",
 	"BR_ACQUIRE",
 	"BR_RELEASE",
 	"BR_DECREFS",
 	"BR_ATTEMPT_ACQUIRE",
 	"BR_NOOP",
 	"BR_SPAWN_LOOPER",
 	"BR_FINISHED",
 	"BR_DEAD_BINDER",
 	"BR_CLEAR_DEATH_NOTIFICATION_DONE",
 	"BR_FAILED_REPLY"
 };
 
 static const char * const binder_command_strings[] = {
 	"BC_TRANSACTION",
 	"BC_REPLY",
 	"BC_ACQUIRE_RESULT",
 	"BC_FREE_BUFFER",
 	"BC_INCREFS",
 	"BC_ACQUIRE",
 	"BC_RELEASE",
 	"BC_DECREFS",
 	"BC_INCREFS_DONE",
 	"BC_ACQUIRE_DONE",
 	"BC_ATTEMPT_ACQUIRE",
 	"BC_REGISTER_LOOPER",
 	"BC_ENTER_LOOPER",
 	"BC_EXIT_LOOPER",
 	"BC_REQUEST_DEATH_NOTIFICATION",
 	"BC_CLEAR_DEATH_NOTIFICATION",
-	"BC_DEAD_BINDER_DONE"
+	"BC_DEAD_BINDER_DONE",
+	"BC_TRANSACTION_SG",
+	"BC_REPLY_SG",
 };
 
 static const char * const binder_objstat_strings[] = {
 	"proc",
 	"thread",
 	"node",
 	"ref",
 	"death",
 	"transaction",
 	"transaction_complete"
 };
 
 static void print_binder_stats(struct seq_file *m, const char *prefix,
 			       struct binder_stats *stats)
 {
 	int i;
 
 	BUILD_BUG_ON(ARRAY_SIZE(stats->bc) !=
 		     ARRAY_SIZE(binder_command_strings));
 	for (i = 0; i < ARRAY_SIZE(stats->bc); i++) {
 		if (stats->bc[i])
 			seq_printf(m, "%s%s: %d\n", prefix,
 				   binder_command_strings[i], stats->bc[i]);
 	}
 
 	BUILD_BUG_ON(ARRAY_SIZE(stats->br) !=
 		     ARRAY_SIZE(binder_return_strings));
 	for (i = 0; i < ARRAY_SIZE(stats->br); i++) {
 		if (stats->br[i])
 			seq_printf(m, "%s%s: %d\n", prefix,
 				   binder_return_strings[i], stats->br[i]);
 	}
 
 	BUILD_BUG_ON(ARRAY_SIZE(stats->obj_created) !=
 		     ARRAY_SIZE(binder_objstat_strings));
 	BUILD_BUG_ON(ARRAY_SIZE(stats->obj_created) !=
 		     ARRAY_SIZE(stats->obj_deleted));
 	for (i = 0; i < ARRAY_SIZE(stats->obj_created); i++) {
 		if (stats->obj_created[i] || stats->obj_deleted[i])
 			seq_printf(m, "%s%s: active %d total %d\n", prefix,
 				binder_objstat_strings[i],
 				stats->obj_created[i] - stats->obj_deleted[i],
 				stats->obj_created[i]);
 	}
 }
 
 static void print_binder_proc_stats(struct seq_file *m,
 				    struct binder_proc *proc)
 {
 	struct binder_work *w;
 	struct rb_node *n;
 	int count, strong, weak;
 
 	seq_printf(m, "proc %d\n", proc->pid);
+	seq_printf(m, "context %s\n", proc->context->name);
 	count = 0;
 	for (n = rb_first(&proc->threads); n != NULL; n = rb_next(n))
 		count++;
 	seq_printf(m, "  threads: %d\n", count);
 	seq_printf(m, "  requested threads: %d+%d/%d\n"
 			"  ready threads %d\n"
 			"  free async space %zd\n", proc->requested_threads,
 			proc->requested_threads_started, proc->max_threads,
 			proc->ready_threads, proc->free_async_space);
 	count = 0;
 	for (n = rb_first(&proc->nodes); n != NULL; n = rb_next(n))
 		count++;
 	seq_printf(m, "  nodes: %d\n", count);
 	count = 0;
 	strong = 0;
 	weak = 0;
 	for (n = rb_first(&proc->refs_by_desc); n != NULL; n = rb_next(n)) {
 		struct binder_ref *ref = rb_entry(n, struct binder_ref,
 						  rb_node_desc);
 		count++;
 		strong += ref->strong;
 		weak += ref->weak;
 	}
 	seq_printf(m, "  refs: %d s %d w %d\n", count, strong, weak);
 
 	count = 0;
 	for (n = rb_first(&proc->allocated_buffers); n != NULL; n = rb_next(n))
 		count++;
 	seq_printf(m, "  buffers: %d\n", count);
 
 	count = 0;
 	list_for_each_entry(w, &proc->todo, entry) {
 		switch (w->type) {
 		case BINDER_WORK_TRANSACTION:
 			count++;
 			break;
 		default:
 			break;
 		}
 	}
 	seq_printf(m, "  pending transactions: %d\n", count);
 
 	print_binder_stats(m, "  ", &proc->stats);
 }
 
 
 static int binder_state_show(struct seq_file *m, void *unused)
 {
 	struct binder_proc *proc;
 	struct binder_node *node;
 	int do_lock = !binder_debug_no_lock;
 
 	if (do_lock)
 		binder_lock(__func__);
 
 	seq_puts(m, "binder state:\n");
 
 	if (!hlist_empty(&binder_dead_nodes))
 		seq_puts(m, "dead nodes:\n");
 	hlist_for_each_entry(node, &binder_dead_nodes, dead_node)
 		print_binder_node(m, node);
 
 	hlist_for_each_entry(proc, &binder_procs, proc_node)
 		print_binder_proc(m, proc, 1);
 	if (do_lock)
 		binder_unlock(__func__);
 	return 0;
 }
 
 static int binder_stats_show(struct seq_file *m, void *unused)
 {
 	struct binder_proc *proc;
 	int do_lock = !binder_debug_no_lock;
 
 	if (do_lock)
 		binder_lock(__func__);
 
 	seq_puts(m, "binder stats:\n");
 
 	print_binder_stats(m, "", &binder_stats);
 
 	hlist_for_each_entry(proc, &binder_procs, proc_node)
 		print_binder_proc_stats(m, proc);
 	if (do_lock)
 		binder_unlock(__func__);
 	return 0;
 }
 
 static int binder_transactions_show(struct seq_file *m, void *unused)
 {
 	struct binder_proc *proc;
 	int do_lock = !binder_debug_no_lock;
 
 	if (do_lock)
 		binder_lock(__func__);
 
 	seq_puts(m, "binder transactions:\n");
 	hlist_for_each_entry(proc, &binder_procs, proc_node)
 		print_binder_proc(m, proc, 0);
 	if (do_lock)
 		binder_unlock(__func__);
 	return 0;
 }
 
 static int binder_proc_show(struct seq_file *m, void *unused)
 {
 	struct binder_proc *itr;
-	struct binder_proc *proc = m->private;
+	int pid = (unsigned long)m->private;
 	int do_lock = !binder_debug_no_lock;
-	bool valid_proc = false;
 
 	if (do_lock)
 		binder_lock(__func__);
 
 	hlist_for_each_entry(itr, &binder_procs, proc_node) {
-		if (itr == proc) {
-			valid_proc = true;
-			break;
+		if (itr->pid == pid) {
+			seq_puts(m, "binder proc state:\n");
+			print_binder_proc(m, itr, 1);
 		}
 	}
-	if (valid_proc) {
-		seq_puts(m, "binder proc state:\n");
-		print_binder_proc(m, proc, 1);
-	}
 	if (do_lock)
 		binder_unlock(__func__);
 	return 0;
 }
 
 static void print_binder_transaction_log_entry(struct seq_file *m,
 					struct binder_transaction_log_entry *e)
 {
 	seq_printf(m,
-		   "%d: %s from %d:%d to %d:%d node %d handle %d size %d:%d\n",
+		   "%d: %s from %d:%d to %d:%d context %s node %d handle %d size %d:%d\n",
 		   e->debug_id, (e->call_type == 2) ? "reply" :
 		   ((e->call_type == 1) ? "async" : "call "), e->from_proc,
-		   e->from_thread, e->to_proc, e->to_thread, e->to_node,
-		   e->target_handle, e->data_size, e->offsets_size);
+		   e->from_thread, e->to_proc, e->to_thread, e->context_name,
+		   e->to_node, e->target_handle, e->data_size, e->offsets_size);
 }
 
 static int binder_transaction_log_show(struct seq_file *m, void *unused)
 {
 	struct binder_transaction_log *log = m->private;
 	int i;
 
 	if (log->full) {
 		for (i = log->next; i < ARRAY_SIZE(log->entry); i++)
 			print_binder_transaction_log_entry(m, &log->entry[i]);
 	}
 	for (i = 0; i < log->next; i++)
 		print_binder_transaction_log_entry(m, &log->entry[i]);
 	return 0;
 }
 
 static const struct file_operations binder_fops = {
 	.owner = THIS_MODULE,
 	.poll = binder_poll,
 	.unlocked_ioctl = binder_ioctl,
 	.compat_ioctl = binder_ioctl,
 	.mmap = binder_mmap,
 	.open = binder_open,
 	.flush = binder_flush,
 	.release = binder_release,
 };
 
-static struct miscdevice binder_miscdev = {
-	.minor = MISC_DYNAMIC_MINOR,
-	.name = "binder",
-	.fops = &binder_fops
-};
-
 BINDER_DEBUG_ENTRY(state);
 BINDER_DEBUG_ENTRY(stats);
 BINDER_DEBUG_ENTRY(transactions);
 BINDER_DEBUG_ENTRY(transaction_log);
 
+static int __init init_binder_device(const char *name)
+{
+	int ret;
+	struct binder_device *binder_device;
+
+	binder_device = kzalloc(sizeof(*binder_device), GFP_KERNEL);
+	if (!binder_device)
+		return -ENOMEM;
+
+	binder_device->miscdev.fops = &binder_fops;
+	binder_device->miscdev.minor = MISC_DYNAMIC_MINOR;
+	binder_device->miscdev.name = name;
+
+	binder_device->context.binder_context_mgr_uid = INVALID_UID;
+	binder_device->context.name = name;
+
+	ret = misc_register(&binder_device->miscdev);
+	if (ret < 0) {
+		kfree(binder_device);
+		return ret;
+	}
+
+	hlist_add_head(&binder_device->hlist, &binder_devices);
+
+	return ret;
+}
+
 static int __init binder_init(void)
 {
 	int ret;
+	char *device_name, *device_names;
+	struct binder_device *device;
+	struct hlist_node *tmp;
 
 	binder_debugfs_dir_entry_root = debugfs_create_dir("binder", NULL);
 	if (binder_debugfs_dir_entry_root)
 		binder_debugfs_dir_entry_proc = debugfs_create_dir("proc",
 						 binder_debugfs_dir_entry_root);
-	ret = misc_register(&binder_miscdev);
+
 	if (binder_debugfs_dir_entry_root) {
 		debugfs_create_file("state",
 				    S_IRUGO,
 				    binder_debugfs_dir_entry_root,
 				    NULL,
 				    &binder_state_fops);
 		debugfs_create_file("stats",
 				    S_IRUGO,
 				    binder_debugfs_dir_entry_root,
 				    NULL,
 				    &binder_stats_fops);
 		debugfs_create_file("transactions",
 				    S_IRUGO,
 				    binder_debugfs_dir_entry_root,
 				    NULL,
 				    &binder_transactions_fops);
 		debugfs_create_file("transaction_log",
 				    S_IRUGO,
 				    binder_debugfs_dir_entry_root,
 				    &binder_transaction_log,
 				    &binder_transaction_log_fops);
 		debugfs_create_file("failed_transaction_log",
 				    S_IRUGO,
 				    binder_debugfs_dir_entry_root,
 				    &binder_transaction_log_failed,
 				    &binder_transaction_log_fops);
 	}
+
+	/*
+	 * Copy the module_parameter string, because we don't want to
+	 * tokenize it in-place.
+	 */
+	device_names = kzalloc(strlen(binder_devices_param) + 1, GFP_KERNEL);
+	if (!device_names) {
+		ret = -ENOMEM;
+		goto err_alloc_device_names_failed;
+	}
+	strcpy(device_names, binder_devices_param);
+
+	while ((device_name = strsep(&device_names, ","))) {
+		ret = init_binder_device(device_name);
+		if (ret)
+			goto err_init_binder_device_failed;
+	}
+
+	return ret;
+
+err_init_binder_device_failed:
+	hlist_for_each_entry_safe(device, tmp, &binder_devices, hlist) {
+		misc_deregister(&device->miscdev);
+		hlist_del(&device->hlist);
+		kfree(device);
+	}
+err_alloc_device_names_failed:
+	debugfs_remove_recursive(binder_debugfs_dir_entry_root);
+
 	return ret;
 }
 
 device_initcall(binder_init);
 
 #define CREATE_TRACE_POINTS
 #include "binder_trace.h"
 
 MODULE_LICENSE("GPL v2");
diff --git a/drivers/auxdisplay/ht16k33.c b/drivers/auxdisplay/ht16k33.c
index eeb323f56c07..f66b45b235b0 100644
--- a/drivers/auxdisplay/ht16k33.c
+++ b/drivers/auxdisplay/ht16k33.c
@@ -1,563 +1,543 @@
 /*
  * HT16K33 driver
  *
  * Author: Robin van der Gracht <robin@protonic.nl>
  *
  * Copyright: (C) 2016 Protonic Holland.
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License version 2 as
  * published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful, but
  * WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
  * General Public License for more details.
  */
 
 #include <linux/kernel.h>
 #include <linux/module.h>
 #include <linux/interrupt.h>
 #include <linux/i2c.h>
 #include <linux/of.h>
 #include <linux/fb.h>
 #include <linux/slab.h>
 #include <linux/backlight.h>
 #include <linux/input.h>
 #include <linux/input/matrix_keypad.h>
 #include <linux/workqueue.h>
 #include <linux/mm.h>
 
 /* Registers */
 #define REG_SYSTEM_SETUP		0x20
 #define REG_SYSTEM_SETUP_OSC_ON		BIT(0)
 
 #define REG_DISPLAY_SETUP		0x80
 #define REG_DISPLAY_SETUP_ON		BIT(0)
 
 #define REG_ROWINT_SET			0xA0
 #define REG_ROWINT_SET_INT_EN		BIT(0)
 #define REG_ROWINT_SET_INT_ACT_HIGH	BIT(1)
 
 #define REG_BRIGHTNESS			0xE0
 
 /* Defines */
 #define DRIVER_NAME			"ht16k33"
 
 #define MIN_BRIGHTNESS			0x1
 #define MAX_BRIGHTNESS			0x10
 
 #define HT16K33_MATRIX_LED_MAX_COLS	8
 #define HT16K33_MATRIX_LED_MAX_ROWS	16
 #define HT16K33_MATRIX_KEYPAD_MAX_COLS	3
 #define HT16K33_MATRIX_KEYPAD_MAX_ROWS	12
 
 #define BYTES_PER_ROW		(HT16K33_MATRIX_LED_MAX_ROWS / 8)
 #define HT16K33_FB_SIZE		(HT16K33_MATRIX_LED_MAX_COLS * BYTES_PER_ROW)
 
 struct ht16k33_keypad {
+	struct i2c_client *client;
 	struct input_dev *dev;
-	spinlock_t lock;
-	struct delayed_work work;
 	uint32_t cols;
 	uint32_t rows;
 	uint32_t row_shift;
 	uint32_t debounce_ms;
 	uint16_t last_key_state[HT16K33_MATRIX_KEYPAD_MAX_COLS];
+
+	wait_queue_head_t wait;
+	bool stopped;
 };
 
 struct ht16k33_fbdev {
 	struct fb_info *info;
 	uint32_t refresh_rate;
 	uint8_t *buffer;
 	uint8_t *cache;
 	struct delayed_work work;
 };
 
 struct ht16k33_priv {
 	struct i2c_client *client;
 	struct ht16k33_keypad keypad;
 	struct ht16k33_fbdev fbdev;
-	struct workqueue_struct *workqueue;
 };
 
 static struct fb_fix_screeninfo ht16k33_fb_fix = {
 	.id		= DRIVER_NAME,
 	.type		= FB_TYPE_PACKED_PIXELS,
 	.visual		= FB_VISUAL_MONO10,
 	.xpanstep	= 0,
 	.ypanstep	= 0,
 	.ywrapstep	= 0,
 	.line_length	= HT16K33_MATRIX_LED_MAX_ROWS,
 	.accel		= FB_ACCEL_NONE,
 };
 
 static struct fb_var_screeninfo ht16k33_fb_var = {
 	.xres = HT16K33_MATRIX_LED_MAX_ROWS,
 	.yres = HT16K33_MATRIX_LED_MAX_COLS,
 	.xres_virtual = HT16K33_MATRIX_LED_MAX_ROWS,
 	.yres_virtual = HT16K33_MATRIX_LED_MAX_COLS,
 	.bits_per_pixel = 1,
 	.red = { 0, 1, 0 },
 	.green = { 0, 1, 0 },
 	.blue = { 0, 1, 0 },
 	.left_margin = 0,
 	.right_margin = 0,
 	.upper_margin = 0,
 	.lower_margin = 0,
 	.vmode = FB_VMODE_NONINTERLACED,
 };
 
 static int ht16k33_display_on(struct ht16k33_priv *priv)
 {
 	uint8_t data = REG_DISPLAY_SETUP | REG_DISPLAY_SETUP_ON;
 
 	return i2c_smbus_write_byte(priv->client, data);
 }
 
 static int ht16k33_display_off(struct ht16k33_priv *priv)
 {
 	return i2c_smbus_write_byte(priv->client, REG_DISPLAY_SETUP);
 }
 
 static void ht16k33_fb_queue(struct ht16k33_priv *priv)
 {
 	struct ht16k33_fbdev *fbdev = &priv->fbdev;
 
-	queue_delayed_work(priv->workqueue, &fbdev->work,
-		msecs_to_jiffies(HZ / fbdev->refresh_rate));
-}
-
-static void ht16k33_keypad_queue(struct ht16k33_priv *priv)
-{
-	struct ht16k33_keypad *keypad = &priv->keypad;
-
-	queue_delayed_work(priv->workqueue, &keypad->work,
-		msecs_to_jiffies(keypad->debounce_ms));
+	schedule_delayed_work(&fbdev->work,
+			      msecs_to_jiffies(HZ / fbdev->refresh_rate));
 }
 
 /*
  * This gets the fb data from cache and copies it to ht16k33 display RAM
  */
 static void ht16k33_fb_update(struct work_struct *work)
 {
 	struct ht16k33_fbdev *fbdev =
 		container_of(work, struct ht16k33_fbdev, work.work);
 	struct ht16k33_priv *priv =
 		container_of(fbdev, struct ht16k33_priv, fbdev);
 
 	uint8_t *p1, *p2;
 	int len, pos = 0, first = -1;
 
 	p1 = fbdev->cache;
 	p2 = fbdev->buffer;
 
 	/* Search for the first byte with changes */
 	while (pos < HT16K33_FB_SIZE && first < 0) {
 		if (*(p1++) - *(p2++))
 			first = pos;
 		pos++;
 	}
 
 	/* No changes found */
 	if (first < 0)
 		goto requeue;
 
 	len = HT16K33_FB_SIZE - first;
 	p1 = fbdev->cache + HT16K33_FB_SIZE - 1;
 	p2 = fbdev->buffer + HT16K33_FB_SIZE - 1;
 
 	/* Determine i2c transfer length */
 	while (len > 1) {
 		if (*(p1--) - *(p2--))
 			break;
 		len--;
 	}
 
 	p1 = fbdev->cache + first;
 	p2 = fbdev->buffer + first;
 	if (!i2c_smbus_write_i2c_block_data(priv->client, first, len, p2))
 		memcpy(p1, p2, len);
 requeue:
 	ht16k33_fb_queue(priv);
 }
 
-static int ht16k33_keypad_start(struct input_dev *dev)
-{
-	struct ht16k33_priv *priv = input_get_drvdata(dev);
-	struct ht16k33_keypad *keypad = &priv->keypad;
-
-	/*
-	 * Schedule an immediate key scan to capture current key state;
-	 * columns will be activated and IRQs be enabled after the scan.
-	 */
-	queue_delayed_work(priv->workqueue, &keypad->work, 0);
-	return 0;
-}
-
-static void ht16k33_keypad_stop(struct input_dev *dev)
-{
-	struct ht16k33_priv *priv = input_get_drvdata(dev);
-	struct ht16k33_keypad *keypad = &priv->keypad;
-
-	cancel_delayed_work(&keypad->work);
-	/*
-	 * ht16k33_keypad_scan() will leave IRQs enabled;
-	 * we should disable them now.
-	 */
-	disable_irq_nosync(priv->client->irq);
-}
-
 static int ht16k33_initialize(struct ht16k33_priv *priv)
 {
 	uint8_t byte;
 	int err;
 	uint8_t data[HT16K33_MATRIX_LED_MAX_COLS * 2];
 
 	/* Clear RAM (8 * 16 bits) */
 	memset(data, 0, sizeof(data));
 	err = i2c_smbus_write_block_data(priv->client, 0, sizeof(data), data);
 	if (err)
 		return err;
 
 	/* Turn on internal oscillator */
 	byte = REG_SYSTEM_SETUP_OSC_ON | REG_SYSTEM_SETUP;
 	err = i2c_smbus_write_byte(priv->client, byte);
 	if (err)
 		return err;
 
 	/* Configure INT pin */
 	byte = REG_ROWINT_SET | REG_ROWINT_SET_INT_ACT_HIGH;
 	if (priv->client->irq > 0)
 		byte |= REG_ROWINT_SET_INT_EN;
 	return i2c_smbus_write_byte(priv->client, byte);
 }
 
-/*
- * This gets the keys from keypad and reports it to input subsystem
- */
-static void ht16k33_keypad_scan(struct work_struct *work)
-{
-	struct ht16k33_keypad *keypad =
-		container_of(work, struct ht16k33_keypad, work.work);
-	struct ht16k33_priv *priv =
-		container_of(keypad, struct ht16k33_priv, keypad);
-	const unsigned short *keycodes = keypad->dev->keycode;
-	uint16_t bits_changed, new_state[HT16K33_MATRIX_KEYPAD_MAX_COLS];
-	uint8_t data[HT16K33_MATRIX_KEYPAD_MAX_COLS * 2];
-	int row, col, code;
-	bool reschedule = false;
-
-	if (i2c_smbus_read_i2c_block_data(priv->client, 0x40, 6, data) != 6) {
-		dev_err(&priv->client->dev, "Failed to read key data\n");
-		goto end;
-	}
-
-	for (col = 0; col < keypad->cols; col++) {
-		new_state[col] = (data[col * 2 + 1] << 8) | data[col * 2];
-		if (new_state[col])
-			reschedule = true;
-		bits_changed = keypad->last_key_state[col] ^ new_state[col];
-
-		while (bits_changed) {
-			row = ffs(bits_changed) - 1;
-			code = MATRIX_SCAN_CODE(row, col, keypad->row_shift);
-			input_event(keypad->dev, EV_MSC, MSC_SCAN, code);
-			input_report_key(keypad->dev, keycodes[code],
-					 new_state[col] & BIT(row));
-			bits_changed &= ~BIT(row);
-		}
-	}
-	input_sync(keypad->dev);
-	memcpy(keypad->last_key_state, new_state, sizeof(new_state));
-
-end:
-	if (reschedule)
-		ht16k33_keypad_queue(priv);
-	else
-		enable_irq(priv->client->irq);
-}
-
-static irqreturn_t ht16k33_irq_thread(int irq, void *dev)
-{
-	struct ht16k33_priv *priv = dev;
-
-	disable_irq_nosync(priv->client->irq);
-	ht16k33_keypad_queue(priv);
-
-	return IRQ_HANDLED;
-}
-
 static int ht16k33_bl_update_status(struct backlight_device *bl)
 {
 	int brightness = bl->props.brightness;
 	struct ht16k33_priv *priv = bl_get_data(bl);
 
 	if (bl->props.power != FB_BLANK_UNBLANK ||
 	    bl->props.fb_blank != FB_BLANK_UNBLANK ||
 	    bl->props.state & BL_CORE_FBBLANK || brightness == 0) {
 		return ht16k33_display_off(priv);
 	}
 
 	ht16k33_display_on(priv);
 	return i2c_smbus_write_byte(priv->client,
 				    REG_BRIGHTNESS | (brightness - 1));
 }
 
 static int ht16k33_bl_check_fb(struct backlight_device *bl, struct fb_info *fi)
 {
 	struct ht16k33_priv *priv = bl_get_data(bl);
 
 	return (fi == NULL) || (fi->par == priv);
 }
 
 static const struct backlight_ops ht16k33_bl_ops = {
 	.update_status	= ht16k33_bl_update_status,
 	.check_fb	= ht16k33_bl_check_fb,
 };
 
 static int ht16k33_mmap(struct fb_info *info, struct vm_area_struct *vma)
 {
 	struct ht16k33_priv *priv = info->par;
 
 	return vm_insert_page(vma, vma->vm_start,
 			      virt_to_page(priv->fbdev.buffer));
 }
 
 static struct fb_ops ht16k33_fb_ops = {
 	.owner = THIS_MODULE,
 	.fb_read = fb_sys_read,
 	.fb_write = fb_sys_write,
 	.fb_fillrect = sys_fillrect,
 	.fb_copyarea = sys_copyarea,
 	.fb_imageblit = sys_imageblit,
 	.fb_mmap = ht16k33_mmap,
 };
 
+/*
+ * This gets the keys from keypad and reports it to input subsystem.
+ * Returns true if a key is pressed.
+ */
+static bool ht16k33_keypad_scan(struct ht16k33_keypad *keypad)
+{
+	const unsigned short *keycodes = keypad->dev->keycode;
+	u16 new_state[HT16K33_MATRIX_KEYPAD_MAX_COLS];
+	u8 data[HT16K33_MATRIX_KEYPAD_MAX_COLS * 2];
+	unsigned long bits_changed;
+	int row, col, code;
+	bool pressed = false;
+
+	if (i2c_smbus_read_i2c_block_data(keypad->client, 0x40, 6, data) != 6) {
+		dev_err(&keypad->client->dev, "Failed to read key data\n");
+		return false;
+	}
+
+	for (col = 0; col < keypad->cols; col++) {
+		new_state[col] = (data[col * 2 + 1] << 8) | data[col * 2];
+		if (new_state[col])
+			pressed = true;
+		bits_changed = keypad->last_key_state[col] ^ new_state[col];
+
+		for_each_set_bit(row, &bits_changed, BITS_PER_LONG) {
+			code = MATRIX_SCAN_CODE(row, col, keypad->row_shift);
+			input_event(keypad->dev, EV_MSC, MSC_SCAN, code);
+			input_report_key(keypad->dev, keycodes[code],
+					 new_state[col] & BIT(row));
+		}
+	}
+	input_sync(keypad->dev);
+	memcpy(keypad->last_key_state, new_state, sizeof(new_state));
+
+	return pressed;
+}
+
+static irqreturn_t ht16k33_keypad_irq_thread(int irq, void *dev)
+{
+	struct ht16k33_keypad *keypad = dev;
+
+	do {
+		wait_event_timeout(keypad->wait, keypad->stopped,
+				    msecs_to_jiffies(keypad->debounce_ms));
+		if (keypad->stopped)
+			break;
+	} while (ht16k33_keypad_scan(keypad));
+
+	return IRQ_HANDLED;
+}
+
+static int ht16k33_keypad_start(struct input_dev *dev)
+{
+	struct ht16k33_keypad *keypad = input_get_drvdata(dev);
+
+	keypad->stopped = false;
+	mb();
+	enable_irq(keypad->client->irq);
+
+	return 0;
+}
+
+static void ht16k33_keypad_stop(struct input_dev *dev)
+{
+	struct ht16k33_keypad *keypad = input_get_drvdata(dev);
+
+	keypad->stopped = true;
+	mb();
+	wake_up(&keypad->wait);
+	disable_irq(keypad->client->irq);
+}
+
+static int ht16k33_keypad_probe(struct i2c_client *client,
+				struct ht16k33_keypad *keypad)
+{
+	struct device_node *node = client->dev.of_node;
+	u32 rows = HT16K33_MATRIX_KEYPAD_MAX_ROWS;
+	u32 cols = HT16K33_MATRIX_KEYPAD_MAX_COLS;
+	int err;
+
+	keypad->client = client;
+	init_waitqueue_head(&keypad->wait);
+
+	keypad->dev = devm_input_allocate_device(&client->dev);
+	if (!keypad->dev)
+		return -ENOMEM;
+
+	input_set_drvdata(keypad->dev, keypad);
+
+	keypad->dev->name = DRIVER_NAME"-keypad";
+	keypad->dev->id.bustype = BUS_I2C;
+	keypad->dev->open = ht16k33_keypad_start;
+	keypad->dev->close = ht16k33_keypad_stop;
+
+	if (!of_get_property(node, "linux,no-autorepeat", NULL))
+		__set_bit(EV_REP, keypad->dev->evbit);
+
+	err = of_property_read_u32(node, "debounce-delay-ms",
+				   &keypad->debounce_ms);
+	if (err) {
+		dev_err(&client->dev, "key debounce delay not specified\n");
+		return err;
+	}
+
+	err = matrix_keypad_parse_of_params(&client->dev, &rows, &cols);
+	if (err)
+		return err;
+
+	keypad->rows = rows;
+	keypad->cols = cols;
+	keypad->row_shift = get_count_order(cols);
+
+	err = matrix_keypad_build_keymap(NULL, NULL, rows, cols, NULL,
+					 keypad->dev);
+	if (err) {
+		dev_err(&client->dev, "failed to build keymap\n");
+		return err;
+	}
+
+	err = devm_request_threaded_irq(&client->dev, client->irq,
+					NULL, ht16k33_keypad_irq_thread,
+					IRQF_TRIGGER_HIGH | IRQF_ONESHOT,
+					DRIVER_NAME, keypad);
+	if (err) {
+		dev_err(&client->dev, "irq request failed %d, error %d\n",
+			client->irq, err);
+		return err;
+	}
+
+	ht16k33_keypad_stop(keypad->dev);
+
+	err = input_register_device(keypad->dev);
+	if (err)
+		return err;
+
+	return 0;
+}
+
 static int ht16k33_probe(struct i2c_client *client,
 				  const struct i2c_device_id *id)
 {
 	int err;
-	uint32_t rows, cols, dft_brightness;
+	uint32_t dft_brightness;
 	struct backlight_device *bl;
 	struct backlight_properties bl_props;
 	struct ht16k33_priv *priv;
-	struct ht16k33_keypad *keypad;
 	struct ht16k33_fbdev *fbdev;
 	struct device_node *node = client->dev.of_node;
 
 	if (!i2c_check_functionality(client->adapter, I2C_FUNC_I2C)) {
 		dev_err(&client->dev, "i2c_check_functionality error\n");
 		return -EIO;
 	}
 
 	if (client->irq <= 0) {
 		dev_err(&client->dev, "No IRQ specified\n");
 		return -EINVAL;
 	}
 
 	priv = devm_kzalloc(&client->dev, sizeof(*priv), GFP_KERNEL);
 	if (!priv)
 		return -ENOMEM;
 
 	priv->client = client;
 	i2c_set_clientdata(client, priv);
 	fbdev = &priv->fbdev;
-	keypad = &priv->keypad;
-
-	priv->workqueue = create_singlethread_workqueue(DRIVER_NAME "-wq");
-	if (priv->workqueue == NULL)
-		return -ENOMEM;
 
 	err = ht16k33_initialize(priv);
 	if (err)
-		goto err_destroy_wq;
+		return err;
 
 	/* Framebuffer (2 bytes per column) */
 	BUILD_BUG_ON(PAGE_SIZE < HT16K33_FB_SIZE);
 	fbdev->buffer = (unsigned char *) get_zeroed_page(GFP_KERNEL);
-	if (!fbdev->buffer) {
-		err = -ENOMEM;
-		goto err_free_fbdev;
-	}
+	if (!fbdev->buffer)
+		return -ENOMEM;
 
 	fbdev->cache = devm_kmalloc(&client->dev, HT16K33_FB_SIZE, GFP_KERNEL);
 	if (!fbdev->cache) {
 		err = -ENOMEM;
 		goto err_fbdev_buffer;
 	}
 
 	fbdev->info = framebuffer_alloc(0, &client->dev);
 	if (!fbdev->info) {
 		err = -ENOMEM;
 		goto err_fbdev_buffer;
 	}
 
 	err = of_property_read_u32(node, "refresh-rate-hz",
 		&fbdev->refresh_rate);
 	if (err) {
 		dev_err(&client->dev, "refresh rate not specified\n");
 		goto err_fbdev_info;
 	}
 	fb_bl_default_curve(fbdev->info, 0, MIN_BRIGHTNESS, MAX_BRIGHTNESS);
 
 	INIT_DELAYED_WORK(&fbdev->work, ht16k33_fb_update);
 	fbdev->info->fbops = &ht16k33_fb_ops;
 	fbdev->info->screen_base = (char __iomem *) fbdev->buffer;
 	fbdev->info->screen_size = HT16K33_FB_SIZE;
 	fbdev->info->fix = ht16k33_fb_fix;
 	fbdev->info->var = ht16k33_fb_var;
 	fbdev->info->pseudo_palette = NULL;
 	fbdev->info->flags = FBINFO_FLAG_DEFAULT;
 	fbdev->info->par = priv;
 
 	err = register_framebuffer(fbdev->info);
 	if (err)
 		goto err_fbdev_info;
 
-	/* Keypad */
-	keypad->dev = devm_input_allocate_device(&client->dev);
-	if (!keypad->dev) {
-		err = -ENOMEM;
-		goto err_fbdev_unregister;
-	}
-
-	keypad->dev->name = DRIVER_NAME"-keypad";
-	keypad->dev->id.bustype = BUS_I2C;
-	keypad->dev->open = ht16k33_keypad_start;
-	keypad->dev->close = ht16k33_keypad_stop;
-
-	if (!of_get_property(node, "linux,no-autorepeat", NULL))
-		__set_bit(EV_REP, keypad->dev->evbit);
-
-	err = of_property_read_u32(node, "debounce-delay-ms",
-				   &keypad->debounce_ms);
-	if (err) {
-		dev_err(&client->dev, "key debounce delay not specified\n");
-		goto err_fbdev_unregister;
-	}
-
-	err = devm_request_threaded_irq(&client->dev, client->irq, NULL,
-					ht16k33_irq_thread,
-					IRQF_TRIGGER_RISING | IRQF_ONESHOT,
-					DRIVER_NAME, priv);
-	if (err) {
-		dev_err(&client->dev, "irq request failed %d, error %d\n",
-			client->irq, err);
-		goto err_fbdev_unregister;
-	}
-
-	disable_irq_nosync(client->irq);
-	rows = HT16K33_MATRIX_KEYPAD_MAX_ROWS;
-	cols = HT16K33_MATRIX_KEYPAD_MAX_COLS;
-	err = matrix_keypad_parse_of_params(&client->dev, &rows, &cols);
-	if (err)
-		goto err_fbdev_unregister;
-
-	err = matrix_keypad_build_keymap(NULL, NULL, rows, cols, NULL,
-					 keypad->dev);
-	if (err) {
-		dev_err(&client->dev, "failed to build keymap\n");
-		goto err_fbdev_unregister;
-	}
-
-	input_set_drvdata(keypad->dev, priv);
-	keypad->rows = rows;
-	keypad->cols = cols;
-	keypad->row_shift = get_count_order(cols);
-	INIT_DELAYED_WORK(&keypad->work, ht16k33_keypad_scan);
-
-	err = input_register_device(keypad->dev);
+	err = ht16k33_keypad_probe(client, &priv->keypad);
 	if (err)
 		goto err_fbdev_unregister;
 
 	/* Backlight */
 	memset(&bl_props, 0, sizeof(struct backlight_properties));
 	bl_props.type = BACKLIGHT_RAW;
 	bl_props.max_brightness = MAX_BRIGHTNESS;
 
 	bl = devm_backlight_device_register(&client->dev, DRIVER_NAME"-bl",
 					    &client->dev, priv,
 					    &ht16k33_bl_ops, &bl_props);
 	if (IS_ERR(bl)) {
 		dev_err(&client->dev, "failed to register backlight\n");
 		err = PTR_ERR(bl);
-		goto err_keypad_unregister;
+		goto err_fbdev_unregister;
 	}
 
 	err = of_property_read_u32(node, "default-brightness-level",
 				   &dft_brightness);
 	if (err) {
 		dft_brightness = MAX_BRIGHTNESS;
 	} else if (dft_brightness > MAX_BRIGHTNESS) {
 		dev_warn(&client->dev,
 			 "invalid default brightness level: %u, using %u\n",
 			 dft_brightness, MAX_BRIGHTNESS);
 		dft_brightness = MAX_BRIGHTNESS;
 	}
 
 	bl->props.brightness = dft_brightness;
 	ht16k33_bl_update_status(bl);
 
 	ht16k33_fb_queue(priv);
 	return 0;
 
-err_keypad_unregister:
-	input_unregister_device(keypad->dev);
 err_fbdev_unregister:
 	unregister_framebuffer(fbdev->info);
 err_fbdev_info:
 	framebuffer_release(fbdev->info);
 err_fbdev_buffer:
 	free_page((unsigned long) fbdev->buffer);
-err_free_fbdev:
-	kfree(fbdev);
-err_destroy_wq:
-	destroy_workqueue(priv->workqueue);
 
 	return err;
 }
 
 static int ht16k33_remove(struct i2c_client *client)
 {
 	struct ht16k33_priv *priv = i2c_get_clientdata(client);
-	struct ht16k33_keypad *keypad = &priv->keypad;
 	struct ht16k33_fbdev *fbdev = &priv->fbdev;
 
-	ht16k33_keypad_stop(keypad->dev);
-
 	cancel_delayed_work(&fbdev->work);
 	unregister_framebuffer(fbdev->info);
 	framebuffer_release(fbdev->info);
 	free_page((unsigned long) fbdev->buffer);
 
-	destroy_workqueue(priv->workqueue);
 	return 0;
 }
 
 static const struct i2c_device_id ht16k33_i2c_match[] = {
 	{ "ht16k33", 0 },
 	{ }
 };
 MODULE_DEVICE_TABLE(i2c, ht16k33_i2c_match);
 
 static const struct of_device_id ht16k33_of_match[] = {
 	{ .compatible = "holtek,ht16k33", },
 	{ }
 };
 MODULE_DEVICE_TABLE(of, ht16k33_of_match);
 
 static struct i2c_driver ht16k33_driver = {
 	.probe		= ht16k33_probe,
 	.remove		= ht16k33_remove,
 	.driver		= {
 		.name		= DRIVER_NAME,
 		.of_match_table	= of_match_ptr(ht16k33_of_match),
 	},
 	.id_table = ht16k33_i2c_match,
 };
 module_i2c_driver(ht16k33_driver);
 
 MODULE_DESCRIPTION("Holtek HT16K33 driver");
 MODULE_LICENSE("GPL");
 MODULE_AUTHOR("Robin van der Gracht <robin@protonic.nl>");
diff --git a/drivers/char/Kconfig b/drivers/char/Kconfig
index fde005ef9d36..4ee2a10207d0 100644
--- a/drivers/char/Kconfig
+++ b/drivers/char/Kconfig
@@ -1,594 +1,597 @@
 #
 # Character device configuration
 #
 
 menu "Character devices"
 
 source "drivers/tty/Kconfig"
 
 config DEVMEM
 	bool "/dev/mem virtual device support"
 	default y
 	help
 	  Say Y here if you want to support the /dev/mem device.
 	  The /dev/mem device is used to access areas of physical
 	  memory.
 	  When in doubt, say "Y".
 
 config DEVKMEM
 	bool "/dev/kmem virtual device support"
 	help
 	  Say Y here if you want to support the /dev/kmem device. The
 	  /dev/kmem device is rarely used, but can be used for certain
 	  kind of kernel debugging operations.
 	  When in doubt, say "N".
 
 config SGI_SNSC
 	bool "SGI Altix system controller communication support"
 	depends on (IA64_SGI_SN2 || IA64_GENERIC)
 	help
 	  If you have an SGI Altix and you want to enable system
 	  controller communication from user space (you want this!),
 	  say Y.  Otherwise, say N.
 
 config SGI_TIOCX
        bool "SGI TIO CX driver support"
        depends on (IA64_SGI_SN2 || IA64_GENERIC)
        help
          If you have an SGI Altix and you have fpga devices attached
          to your TIO, say Y here, otherwise say N.
 
 config SGI_MBCS
        tristate "SGI FPGA Core Services driver support"
        depends on SGI_TIOCX
        help
          If you have an SGI Altix with an attached SABrick
          say Y or M here, otherwise say N.
 
 source "drivers/tty/serial/Kconfig"
 
 config TTY_PRINTK
 	tristate "TTY driver to output user messages via printk"
 	depends on EXPERT && TTY
 	default n
 	---help---
 	  If you say Y here, the support for writing user messages (i.e.
 	  console messages) via printk is available.
 
 	  The feature is useful to inline user messages with kernel
 	  messages.
 	  In order to use this feature, you should output user messages
 	  to /dev/ttyprintk or redirect console to this TTY.
 
 	  If unsure, say N.
 
 config BFIN_OTP
 	tristate "Blackfin On-Chip OTP Memory Support"
 	depends on BLACKFIN && (BF51x || BF52x || BF54x)
 	default y
 	help
 	  If you say Y here, you will get support for a character device
 	  interface into the One Time Programmable memory pages that are
 	  stored on the Blackfin processor.  This will not get you access
 	  to the secure memory pages however.  You will need to write your
 	  own secure code and reader for that.
 
 	  To compile this driver as a module, choose M here: the module
 	  will be called bfin-otp.
 
 	  If unsure, it is safe to say Y.
 
 config BFIN_OTP_WRITE_ENABLE
 	bool "Enable writing support of OTP pages"
 	depends on BFIN_OTP
 	default n
 	help
 	  If you say Y here, you will enable support for writing of the
 	  OTP pages.  This is dangerous by nature as you can only program
 	  the pages once, so only enable this option when you actually
 	  need it so as to not inadvertently clobber data.
 
 	  If unsure, say N.
 
 config PRINTER
 	tristate "Parallel printer support"
 	depends on PARPORT
 	---help---
 	  If you intend to attach a printer to the parallel port of your Linux
 	  box (as opposed to using a serial printer; if the connector at the
 	  printer has 9 or 25 holes ["female"], then it's serial), say Y.
 	  Also read the Printing-HOWTO, available from
 	  <http://www.tldp.org/docs.html#howto>.
 
 	  It is possible to share one parallel port among several devices
 	  (e.g. printer and ZIP drive) and it is safe to compile the
 	  corresponding drivers into the kernel.
 
 	  To compile this driver as a module, choose M here and read
 	  <file:Documentation/parport.txt>.  The module will be called lp.
 
 	  If you have several parallel ports, you can specify which ports to
 	  use with the "lp" kernel command line option.  (Try "man bootparam"
 	  or see the documentation of your boot loader (lilo or loadlin) about
 	  how to pass options to the kernel at boot time.)  The syntax of the
 	  "lp" command line option can be found in <file:drivers/char/lp.c>.
 
 	  If you have more than 8 printers, you need to increase the LP_NO
 	  macro in lp.c and the PARPORT_MAX macro in parport.h.
 
 config LP_CONSOLE
 	bool "Support for console on line printer"
 	depends on PRINTER
 	---help---
 	  If you want kernel messages to be printed out as they occur, you
 	  can have a console on the printer. This option adds support for
 	  doing that; to actually get it to happen you need to pass the
 	  option "console=lp0" to the kernel at boot time.
 
 	  If the printer is out of paper (or off, or unplugged, or too
 	  busy..) the kernel will stall until the printer is ready again.
 	  By defining CONSOLE_LP_STRICT to 0 (at your own risk) you
 	  can make the kernel continue when this happens,
 	  but it'll lose the kernel messages.
 
 	  If unsure, say N.
 
 config PPDEV
 	tristate "Support for user-space parallel port device drivers"
 	depends on PARPORT
 	---help---
 	  Saying Y to this adds support for /dev/parport device nodes.  This
 	  is needed for programs that want portable access to the parallel
 	  port, for instance deviceid (which displays Plug-and-Play device
 	  IDs).
 
 	  This is the parallel port equivalent of SCSI generic support (sg).
 	  It is safe to say N to this -- it is not needed for normal printing
 	  or parallel port CD-ROM/disk support.
 
 	  To compile this driver as a module, choose M here: the
 	  module will be called ppdev.
 
 	  If unsure, say N.
 
 source "drivers/tty/hvc/Kconfig"
 
 config VIRTIO_CONSOLE
 	tristate "Virtio console"
 	depends on VIRTIO && TTY
 	select HVC_DRIVER
 	help
 	  Virtio console for use with lguest and other hypervisors.
 
 	  Also serves as a general-purpose serial device for data
 	  transfer between the guest and host.  Character devices at
 	  /dev/vportNpn will be created when corresponding ports are
 	  found, where N is the device number and n is the port number
 	  within that device.  If specified by the host, a sysfs
 	  attribute called 'name' will be populated with a name for
 	  the port which can be used by udev scripts to create a
 	  symlink to the device.
 
 config IBM_BSR
 	tristate "IBM POWER Barrier Synchronization Register support"
 	depends on PPC_PSERIES
 	help
 	  This devices exposes a hardware mechanism for fast synchronization
 	  of threads across a large system which avoids bouncing a cacheline
 	  between several cores on a system
 
 config POWERNV_OP_PANEL
 	tristate "IBM POWERNV Operator Panel Display support"
 	depends on PPC_POWERNV
 	default m
 	help
 	  If you say Y here, a special character device node, /dev/op_panel,
 	  will be created which exposes the operator panel display on IBM
 	  Power Systems machines with FSPs.
 
 	  If you don't require access to the operator panel display from user
 	  space, say N.
 
 	  If unsure, say M here to build it as a module called powernv-op-panel.
 
 source "drivers/char/ipmi/Kconfig"
 
 config DS1620
 	tristate "NetWinder thermometer support"
 	depends on ARCH_NETWINDER
 	help
 	  Say Y here to include support for the thermal management hardware
 	  found in the NetWinder. This driver allows the user to control the
 	  temperature set points and to read the current temperature.
 
 	  It is also possible to say M here to build it as a module (ds1620)
 	  It is recommended to be used on a NetWinder, but it is not a
 	  necessity.
 
 config NWBUTTON
 	tristate "NetWinder Button"
 	depends on ARCH_NETWINDER
 	---help---
 	  If you say Y here and create a character device node /dev/nwbutton
 	  with major and minor numbers 10 and 158 ("man mknod"), then every
 	  time the orange button is pressed a number of times, the number of
 	  times the button was pressed will be written to that device.
 
 	  This is most useful for applications, as yet unwritten, which
 	  perform actions based on how many times the button is pressed in a
 	  row.
 
 	  Do not hold the button down for too long, as the driver does not
 	  alter the behaviour of the hardware reset circuitry attached to the
 	  button; it will still execute a hard reset if the button is held
 	  down for longer than approximately five seconds.
 
 	  To compile this driver as a module, choose M here: the
 	  module will be called nwbutton.
 
 	  Most people will answer Y to this question and "Reboot Using Button"
 	  below to be able to initiate a system shutdown from the button.
 
 config NWBUTTON_REBOOT
 	bool "Reboot Using Button"
 	depends on NWBUTTON
 	help
 	  If you say Y here, then you will be able to initiate a system
 	  shutdown and reboot by pressing the orange button a number of times.
 	  The number of presses to initiate the shutdown is two by default,
 	  but this can be altered by modifying the value of NUM_PRESSES_REBOOT
 	  in nwbutton.h and recompiling the driver or, if you compile the
 	  driver as a module, you can specify the number of presses at load
 	  time with "insmod button reboot_count=<something>".
 
 config NWFLASH
 	tristate "NetWinder flash support"
 	depends on ARCH_NETWINDER
 	---help---
 	  If you say Y here and create a character device /dev/flash with
 	  major 10 and minor 160 you can manipulate the flash ROM containing
 	  the NetWinder firmware. Be careful as accidentally overwriting the
 	  flash contents can render your computer unbootable. On no account
 	  allow random users access to this device. :-)
 
 	  To compile this driver as a module, choose M here: the
 	  module will be called nwflash.
 
 	  If you're not sure, say N.
 
 source "drivers/char/hw_random/Kconfig"
 
 config NVRAM
 	tristate "/dev/nvram support"
 	depends on ATARI || X86 || (ARM && RTC_DRV_CMOS) || GENERIC_NVRAM
 	---help---
 	  If you say Y here and create a character special file /dev/nvram
 	  with major number 10 and minor number 144 using mknod ("man mknod"),
 	  you get read and write access to the extra bytes of non-volatile
 	  memory in the real time clock (RTC), which is contained in every PC
 	  and most Ataris.  The actual number of bytes varies, depending on the
 	  nvram in the system, but is usually 114 (128-14 for the RTC).
 
 	  This memory is conventionally called "CMOS RAM" on PCs and "NVRAM"
 	  on Ataris. /dev/nvram may be used to view settings there, or to
 	  change them (with some utility). It could also be used to frequently
 	  save a few bits of very important data that may not be lost over
 	  power-off and for which writing to disk is too insecure. Note
 	  however that most NVRAM space in a PC belongs to the BIOS and you
 	  should NEVER idly tamper with it. See Ralf Brown's interrupt list
 	  for a guide to the use of CMOS bytes by your BIOS.
 
 	  On Atari machines, /dev/nvram is always configured and does not need
 	  to be selected.
 
 	  To compile this driver as a module, choose M here: the
 	  module will be called nvram.
 
 #
 # These legacy RTC drivers just cause too many conflicts with the generic
 # RTC framework ... let's not even try to coexist any more.
 #
 if RTC_LIB=n
 
 config RTC
 	tristate "Enhanced Real Time Clock Support (legacy PC RTC driver)"
 	depends on ALPHA || (MIPS && MACH_LOONGSON64)
 	---help---
 	  If you say Y here and create a character special file /dev/rtc with
 	  major number 10 and minor number 135 using mknod ("man mknod"), you
 	  will get access to the real time clock (or hardware clock) built
 	  into your computer.
 
 	  Every PC has such a clock built in. It can be used to generate
 	  signals from as low as 1Hz up to 8192Hz, and can also be used
 	  as a 24 hour alarm. It reports status information via the file
 	  /proc/driver/rtc and its behaviour is set by various ioctls on
 	  /dev/rtc.
 
 	  If you run Linux on a multiprocessor machine and said Y to
 	  "Symmetric Multi Processing" above, you should say Y here to read
 	  and set the RTC in an SMP compatible fashion.
 
 	  If you think you have a use for such a device (such as periodic data
 	  sampling), then say Y here, and read <file:Documentation/rtc.txt>
 	  for details.
 
 	  To compile this driver as a module, choose M here: the
 	  module will be called rtc.
 
 config JS_RTC
 	tristate "Enhanced Real Time Clock Support"
 	depends on SPARC32 && PCI
 	---help---
 	  If you say Y here and create a character special file /dev/rtc with
 	  major number 10 and minor number 135 using mknod ("man mknod"), you
 	  will get access to the real time clock (or hardware clock) built
 	  into your computer.
 
 	  Every PC has such a clock built in. It can be used to generate
 	  signals from as low as 1Hz up to 8192Hz, and can also be used
 	  as a 24 hour alarm. It reports status information via the file
 	  /proc/driver/rtc and its behaviour is set by various ioctls on
 	  /dev/rtc.
 
 	  If you think you have a use for such a device (such as periodic data
 	  sampling), then say Y here, and read <file:Documentation/rtc.txt>
 	  for details.
 
 	  To compile this driver as a module, choose M here: the
 	  module will be called js-rtc.
 
 config EFI_RTC
 	bool "EFI Real Time Clock Services"
 	depends on IA64
 
 config DS1302
 	tristate "DS1302 RTC support"
 	depends on M32R && (PLAT_M32700UT || PLAT_OPSPUT)
 	help
 	  If you say Y here and create a character special file /dev/rtc with
 	  major number 121 and minor number 0 using mknod ("man mknod"), you
 	  will get access to the real time clock (or hardware clock) built
 	  into your computer.
 
 endif # RTC_LIB
 
 config DTLK
 	tristate "Double Talk PC internal speech card support"
 	depends on ISA
 	help
 	  This driver is for the DoubleTalk PC, a speech synthesizer
 	  manufactured by RC Systems (<http://www.rcsys.com/>).  It is also
 	  called the `internal DoubleTalk'.
 
 	  To compile this driver as a module, choose M here: the
 	  module will be called dtlk.
 
 config XILINX_HWICAP
 	tristate "Xilinx HWICAP Support"
 	depends on XILINX_VIRTEX || MICROBLAZE
 	help
 	  This option enables support for Xilinx Internal Configuration
 	  Access Port (ICAP) driver.  The ICAP is used on Xilinx Virtex
 	  FPGA platforms to partially reconfigure the FPGA at runtime.
 
 	  If unsure, say N.
 
 config R3964
 	tristate "Siemens R3964 line discipline"
 	depends on TTY
 	---help---
 	  This driver allows synchronous communication with devices using the
 	  Siemens R3964 packet protocol. Unless you are dealing with special
 	  hardware like PLCs, you are unlikely to need this.
 
 	  To compile this driver as a module, choose M here: the
 	  module will be called n_r3964.
 
 	  If unsure, say N.
 
 config APPLICOM
 	tristate "Applicom intelligent fieldbus card support"
 	depends on PCI
 	---help---
 	  This driver provides the kernel-side support for the intelligent
 	  fieldbus cards made by Applicom International. More information
 	  about these cards can be found on the WWW at the address
 	  <http://www.applicom-int.com/>, or by email from David Woodhouse
 	  <dwmw2@infradead.org>.
 
 	  To compile this driver as a module, choose M here: the
 	  module will be called applicom.
 
 	  If unsure, say N.
 
 config SONYPI
 	tristate "Sony Vaio Programmable I/O Control Device support"
 	depends on X86_32 && PCI && INPUT
 	---help---
 	  This driver enables access to the Sony Programmable I/O Control
 	  Device which can be found in many (all ?) Sony Vaio laptops.
 
 	  If you have one of those laptops, read
 	  <file:Documentation/laptops/sonypi.txt>, and say Y or M here.
 
 	  To compile this driver as a module, choose M here: the
 	  module will be called sonypi.
 
 config GPIO_TB0219
 	tristate "TANBAC TB0219 GPIO support"
 	depends on TANBAC_TB022X
 	select GPIO_VR41XX
 
 source "drivers/char/pcmcia/Kconfig"
 
 config MWAVE
 	tristate "ACP Modem (Mwave) support"
 	depends on X86 && TTY
 	select SERIAL_8250
 	---help---
 	  The ACP modem (Mwave) for Linux is a WinModem. It is composed of a
 	  kernel driver and a user level application. Together these components
 	  support direct attachment to public switched telephone networks (PSTNs)
 	  and support selected world wide countries.
 
 	  This version of the ACP Modem driver supports the IBM Thinkpad 600E,
 	  600, and 770 that include on board ACP modem hardware.
 
 	  The modem also supports the standard communications port interface
 	  (ttySx) and is compatible with the Hayes AT Command Set.
 
 	  The user level application needed to use this driver can be found at
 	  the IBM Linux Technology Center (LTC) web site:
 	  <http://www.ibm.com/linux/ltc/>.
 
 	  If you own one of the above IBM Thinkpads which has the Mwave chipset
 	  in it, say Y.
 
 	  To compile this driver as a module, choose M here: the
 	  module will be called mwave.
 
 config SCx200_GPIO
 	tristate "NatSemi SCx200 GPIO Support"
 	depends on SCx200
 	select NSC_GPIO
 	help
 	  Give userspace access to the GPIO pins on the National
 	  Semiconductor SCx200 processors.
 
 	  If compiled as a module, it will be called scx200_gpio.
 
 config PC8736x_GPIO
 	tristate "NatSemi PC8736x GPIO Support"
 	depends on X86_32 && !UML
 	default SCx200_GPIO	# mostly N
 	select NSC_GPIO		# needed for support routines
 	help
 	  Give userspace access to the GPIO pins on the National
 	  Semiconductor PC-8736x (x=[03456]) SuperIO chip.  The chip
 	  has multiple functional units, inc several managed by
 	  hwmon/pc87360 driver.  Tested with PC-87366
 
 	  If compiled as a module, it will be called pc8736x_gpio.
 
 config NSC_GPIO
 	tristate "NatSemi Base GPIO Support"
 	depends on X86_32
 	# selected by SCx200_GPIO and PC8736x_GPIO
 	# what about 2 selectors differing: m != y
 	help
 	  Common support used (and needed) by scx200_gpio and
 	  pc8736x_gpio drivers.  If those drivers are built as
 	  modules, this one will be too, named nsc_gpio
 
 config RAW_DRIVER
 	tristate "RAW driver (/dev/raw/rawN)"
 	depends on BLOCK
 	help
 	  The raw driver permits block devices to be bound to /dev/raw/rawN.
 	  Once bound, I/O against /dev/raw/rawN uses efficient zero-copy I/O.
 	  See the raw(8) manpage for more details.
 
           Applications should preferably open the device (eg /dev/hda1)
           with the O_DIRECT flag.
 
 config MAX_RAW_DEVS
 	int "Maximum number of RAW devices to support (1-65536)"
 	depends on RAW_DRIVER
 	range 1 65536
 	default "256"
 	help
 	  The maximum number of RAW devices that are supported.
 	  Default is 256. Increase this number in case you need lots of
 	  raw devices.
 
 config HPET
 	bool "HPET - High Precision Event Timer" if (X86 || IA64)
 	default n
 	depends on ACPI
 	help
 	  If you say Y here, you will have a miscdevice named "/dev/hpet/".  Each
 	  open selects one of the timers supported by the HPET.  The timers are
 	  non-periodic and/or periodic.
 
 config HPET_MMAP
 	bool "Allow mmap of HPET"
 	default y
 	depends on HPET
 	help
 	  If you say Y here, user applications will be able to mmap
 	  the HPET registers.
 
 config HPET_MMAP_DEFAULT
 	bool "Enable HPET MMAP access by default"
 	default y
 	depends on HPET_MMAP
 	help
 	  In some hardware implementations, the page containing HPET
 	  registers may also contain other things that shouldn't be
 	  exposed to the user.  This option selects the default (if
 	  kernel parameter hpet_mmap is not set) user access to the
 	  registers for applications that require it.
 
 config HANGCHECK_TIMER
 	tristate "Hangcheck timer"
 	depends on X86 || IA64 || PPC64 || S390
 	help
 	  The hangcheck-timer module detects when the system has gone
 	  out to lunch past a certain margin.  It can reboot the system
 	  or merely print a warning.
 
 config MMTIMER
 	tristate "MMTIMER Memory mapped RTC for SGI Altix"
 	depends on IA64_GENERIC || IA64_SGI_SN2
 	depends on POSIX_TIMERS
 	default y
 	help
 	  The mmtimer device allows direct userspace access to the
 	  Altix system timer.
 
 config UV_MMTIMER
 	tristate "UV_MMTIMER Memory mapped RTC for SGI UV"
 	depends on X86_UV
 	default m
 	help
 	  The uv_mmtimer device allows direct userspace access to the
 	  UV system timer.
 
 source "drivers/char/tpm/Kconfig"
 
 config TELCLOCK
 	tristate "Telecom clock driver for ATCA SBC"
 	depends on X86
 	default n
 	help
 	  The telecom clock device is specific to the MPCBL0010 and MPCBL0050
 	  ATCA computers and allows direct userspace access to the
 	  configuration of the telecom clock configuration settings.  This
 	  device is used for hardware synchronization across the ATCA backplane
 	  fabric.  Upon loading, the driver exports a sysfs directory,
 	  /sys/devices/platform/telco_clock, with a number of files for
 	  controlling the behavior of this hardware.
 
 config DEVPORT
-	bool
+	bool "/dev/port character device"
 	depends on ISA || PCI
 	default y
+	help
+	  Say Y here if you want to support the /dev/port device. The /dev/port
+	  device is similar to /dev/mem, but for I/O ports.
 
 source "drivers/s390/char/Kconfig"
 
 config TILE_SROM
 	tristate "Character-device access via hypervisor to the Tilera SPI ROM"
 	depends on TILE
 	default y
 	---help---
 	  This device provides character-level read-write access
 	  to the SROM, typically via the "0", "1", and "2" devices
 	  in /dev/srom/.  The Tilera hypervisor makes the flash
 	  device appear much like a simple EEPROM, and knows
 	  how to partition a single ROM for multiple purposes.
 
 source "drivers/char/xillybus/Kconfig"
 
 endmenu
 
diff --git a/drivers/char/apm-emulation.c b/drivers/char/apm-emulation.c
index dd9dfa15e9d1..1dfb9f8de171 100644
--- a/drivers/char/apm-emulation.c
+++ b/drivers/char/apm-emulation.c
@@ -1,745 +1,738 @@
 /*
  * bios-less APM driver for ARM Linux
  *  Jamey Hicks <jamey@crl.dec.com>
  *  adapted from the APM BIOS driver for Linux by Stephen Rothwell (sfr@linuxcare.com)
  *
  * APM 1.2 Reference:
  *   Intel Corporation, Microsoft Corporation. Advanced Power Management
  *   (APM) BIOS Interface Specification, Revision 1.2, February 1996.
  *
  * This document is available from Microsoft at:
  *    http://www.microsoft.com/whdc/archive/amp_12.mspx
  */
 #include <linux/module.h>
 #include <linux/poll.h>
 #include <linux/slab.h>
 #include <linux/mutex.h>
 #include <linux/proc_fs.h>
 #include <linux/seq_file.h>
 #include <linux/miscdevice.h>
 #include <linux/apm_bios.h>
 #include <linux/capability.h>
 #include <linux/sched.h>
 #include <linux/suspend.h>
 #include <linux/apm-emulation.h>
 #include <linux/freezer.h>
 #include <linux/device.h>
 #include <linux/kernel.h>
 #include <linux/list.h>
 #include <linux/init.h>
 #include <linux/completion.h>
 #include <linux/kthread.h>
 #include <linux/delay.h>
 
-
-/*
- * The apm_bios device is one of the misc char devices.
- * This is its minor number.
- */
-#define APM_MINOR_DEV	134
-
 /*
  * One option can be changed at boot time as follows:
  *	apm=on/off			enable/disable APM
  */
 
 /*
  * Maximum number of events stored
  */
 #define APM_MAX_EVENTS		16
 
 struct apm_queue {
 	unsigned int		event_head;
 	unsigned int		event_tail;
 	apm_event_t		events[APM_MAX_EVENTS];
 };
 
 /*
  * thread states (for threads using a writable /dev/apm_bios fd):
  *
  * SUSPEND_NONE:	nothing happening
  * SUSPEND_PENDING:	suspend event queued for thread and pending to be read
  * SUSPEND_READ:	suspend event read, pending acknowledgement
  * SUSPEND_ACKED:	acknowledgement received from thread (via ioctl),
  *			waiting for resume
  * SUSPEND_ACKTO:	acknowledgement timeout
  * SUSPEND_DONE:	thread had acked suspend and is now notified of
  *			resume
  *
  * SUSPEND_WAIT:	this thread invoked suspend and is waiting for resume
  *
  * A thread migrates in one of three paths:
  *	NONE -1-> PENDING -2-> READ -3-> ACKED -4-> DONE -5-> NONE
  *				    -6-> ACKTO -7-> NONE
  *	NONE -8-> WAIT -9-> NONE
  *
  * While in PENDING or READ, the thread is accounted for in the
  * suspend_acks_pending counter.
  *
  * The transitions are invoked as follows:
  *	1: suspend event is signalled from the core PM code
  *	2: the suspend event is read from the fd by the userspace thread
  *	3: userspace thread issues the APM_IOC_SUSPEND ioctl (as ack)
  *	4: core PM code signals that we have resumed
  *	5: APM_IOC_SUSPEND ioctl returns
  *
  *	6: the notifier invoked from the core PM code timed out waiting
  *	   for all relevant threds to enter ACKED state and puts those
  *	   that haven't into ACKTO
  *	7: those threads issue APM_IOC_SUSPEND ioctl too late,
  *	   get an error
  *
  *	8: userspace thread issues the APM_IOC_SUSPEND ioctl (to suspend),
  *	   ioctl code invokes pm_suspend()
  *	9: pm_suspend() returns indicating resume
  */
 enum apm_suspend_state {
 	SUSPEND_NONE,
 	SUSPEND_PENDING,
 	SUSPEND_READ,
 	SUSPEND_ACKED,
 	SUSPEND_ACKTO,
 	SUSPEND_WAIT,
 	SUSPEND_DONE,
 };
 
 /*
  * The per-file APM data
  */
 struct apm_user {
 	struct list_head	list;
 
 	unsigned int		suser: 1;
 	unsigned int		writer: 1;
 	unsigned int		reader: 1;
 
 	int			suspend_result;
 	enum apm_suspend_state	suspend_state;
 
 	struct apm_queue	queue;
 };
 
 /*
  * Local variables
  */
 static atomic_t suspend_acks_pending = ATOMIC_INIT(0);
 static atomic_t userspace_notification_inhibit = ATOMIC_INIT(0);
 static int apm_disabled;
 static struct task_struct *kapmd_tsk;
 
 static DECLARE_WAIT_QUEUE_HEAD(apm_waitqueue);
 static DECLARE_WAIT_QUEUE_HEAD(apm_suspend_waitqueue);
 
 /*
  * This is a list of everyone who has opened /dev/apm_bios
  */
 static DECLARE_RWSEM(user_list_lock);
 static LIST_HEAD(apm_user_list);
 
 /*
  * kapmd info.  kapmd provides us a process context to handle
  * "APM" events within - specifically necessary if we're going
  * to be suspending the system.
  */
 static DECLARE_WAIT_QUEUE_HEAD(kapmd_wait);
 static DEFINE_SPINLOCK(kapmd_queue_lock);
 static struct apm_queue kapmd_queue;
 
 static DEFINE_MUTEX(state_lock);
 
 static const char driver_version[] = "1.13";	/* no spaces */
 
 
 
 /*
  * Compatibility cruft until the IPAQ people move over to the new
  * interface.
  */
 static void __apm_get_power_status(struct apm_power_info *info)
 {
 }
 
 /*
  * This allows machines to provide their own "apm get power status" function.
  */
 void (*apm_get_power_status)(struct apm_power_info *) = __apm_get_power_status;
 EXPORT_SYMBOL(apm_get_power_status);
 
 
 /*
  * APM event queue management.
  */
 static inline int queue_empty(struct apm_queue *q)
 {
 	return q->event_head == q->event_tail;
 }
 
 static inline apm_event_t queue_get_event(struct apm_queue *q)
 {
 	q->event_tail = (q->event_tail + 1) % APM_MAX_EVENTS;
 	return q->events[q->event_tail];
 }
 
 static void queue_add_event(struct apm_queue *q, apm_event_t event)
 {
 	q->event_head = (q->event_head + 1) % APM_MAX_EVENTS;
 	if (q->event_head == q->event_tail) {
 		static int notified;
 
 		if (notified++ == 0)
 		    printk(KERN_ERR "apm: an event queue overflowed\n");
 		q->event_tail = (q->event_tail + 1) % APM_MAX_EVENTS;
 	}
 	q->events[q->event_head] = event;
 }
 
 static void queue_event(apm_event_t event)
 {
 	struct apm_user *as;
 
 	down_read(&user_list_lock);
 	list_for_each_entry(as, &apm_user_list, list) {
 		if (as->reader)
 			queue_add_event(&as->queue, event);
 	}
 	up_read(&user_list_lock);
 	wake_up_interruptible(&apm_waitqueue);
 }
 
 static ssize_t apm_read(struct file *fp, char __user *buf, size_t count, loff_t *ppos)
 {
 	struct apm_user *as = fp->private_data;
 	apm_event_t event;
 	int i = count, ret = 0;
 
 	if (count < sizeof(apm_event_t))
 		return -EINVAL;
 
 	if (queue_empty(&as->queue) && fp->f_flags & O_NONBLOCK)
 		return -EAGAIN;
 
 	wait_event_interruptible(apm_waitqueue, !queue_empty(&as->queue));
 
 	while ((i >= sizeof(event)) && !queue_empty(&as->queue)) {
 		event = queue_get_event(&as->queue);
 
 		ret = -EFAULT;
 		if (copy_to_user(buf, &event, sizeof(event)))
 			break;
 
 		mutex_lock(&state_lock);
 		if (as->suspend_state == SUSPEND_PENDING &&
 		    (event == APM_SYS_SUSPEND || event == APM_USER_SUSPEND))
 			as->suspend_state = SUSPEND_READ;
 		mutex_unlock(&state_lock);
 
 		buf += sizeof(event);
 		i -= sizeof(event);
 	}
 
 	if (i < count)
 		ret = count - i;
 
 	return ret;
 }
 
 static unsigned int apm_poll(struct file *fp, poll_table * wait)
 {
 	struct apm_user *as = fp->private_data;
 
 	poll_wait(fp, &apm_waitqueue, wait);
 	return queue_empty(&as->queue) ? 0 : POLLIN | POLLRDNORM;
 }
 
 /*
  * apm_ioctl - handle APM ioctl
  *
  * APM_IOC_SUSPEND
  *   This IOCTL is overloaded, and performs two functions.  It is used to:
  *     - initiate a suspend
  *     - acknowledge a suspend read from /dev/apm_bios.
  *   Only when everyone who has opened /dev/apm_bios with write permission
  *   has acknowledge does the actual suspend happen.
  */
 static long
 apm_ioctl(struct file *filp, u_int cmd, u_long arg)
 {
 	struct apm_user *as = filp->private_data;
 	int err = -EINVAL;
 
 	if (!as->suser || !as->writer)
 		return -EPERM;
 
 	switch (cmd) {
 	case APM_IOC_SUSPEND:
 		mutex_lock(&state_lock);
 
 		as->suspend_result = -EINTR;
 
 		switch (as->suspend_state) {
 		case SUSPEND_READ:
 			/*
 			 * If we read a suspend command from /dev/apm_bios,
 			 * then the corresponding APM_IOC_SUSPEND ioctl is
 			 * interpreted as an acknowledge.
 			 */
 			as->suspend_state = SUSPEND_ACKED;
 			atomic_dec(&suspend_acks_pending);
 			mutex_unlock(&state_lock);
 
 			/*
 			 * suspend_acks_pending changed, the notifier needs to
 			 * be woken up for this
 			 */
 			wake_up(&apm_suspend_waitqueue);
 
 			/*
 			 * Wait for the suspend/resume to complete.  If there
 			 * are pending acknowledges, we wait here for them.
 			 * wait_event_freezable() is interruptible and pending
 			 * signal can cause busy looping.  We aren't doing
 			 * anything critical, chill a bit on each iteration.
 			 */
 			while (wait_event_freezable(apm_suspend_waitqueue,
 					as->suspend_state != SUSPEND_ACKED))
 				msleep(10);
 			break;
 		case SUSPEND_ACKTO:
 			as->suspend_result = -ETIMEDOUT;
 			mutex_unlock(&state_lock);
 			break;
 		default:
 			as->suspend_state = SUSPEND_WAIT;
 			mutex_unlock(&state_lock);
 
 			/*
 			 * Otherwise it is a request to suspend the system.
 			 * Just invoke pm_suspend(), we'll handle it from
 			 * there via the notifier.
 			 */
 			as->suspend_result = pm_suspend(PM_SUSPEND_MEM);
 		}
 
 		mutex_lock(&state_lock);
 		err = as->suspend_result;
 		as->suspend_state = SUSPEND_NONE;
 		mutex_unlock(&state_lock);
 		break;
 	}
 
 	return err;
 }
 
 static int apm_release(struct inode * inode, struct file * filp)
 {
 	struct apm_user *as = filp->private_data;
 
 	filp->private_data = NULL;
 
 	down_write(&user_list_lock);
 	list_del(&as->list);
 	up_write(&user_list_lock);
 
 	/*
 	 * We are now unhooked from the chain.  As far as new
 	 * events are concerned, we no longer exist.
 	 */
 	mutex_lock(&state_lock);
 	if (as->suspend_state == SUSPEND_PENDING ||
 	    as->suspend_state == SUSPEND_READ)
 		atomic_dec(&suspend_acks_pending);
 	mutex_unlock(&state_lock);
 
 	wake_up(&apm_suspend_waitqueue);
 
 	kfree(as);
 	return 0;
 }
 
 static int apm_open(struct inode * inode, struct file * filp)
 {
 	struct apm_user *as;
 
 	as = kzalloc(sizeof(*as), GFP_KERNEL);
 	if (as) {
 		/*
 		 * XXX - this is a tiny bit broken, when we consider BSD
 		 * process accounting. If the device is opened by root, we
 		 * instantly flag that we used superuser privs. Who knows,
 		 * we might close the device immediately without doing a
 		 * privileged operation -- cevans
 		 */
 		as->suser = capable(CAP_SYS_ADMIN);
 		as->writer = (filp->f_mode & FMODE_WRITE) == FMODE_WRITE;
 		as->reader = (filp->f_mode & FMODE_READ) == FMODE_READ;
 
 		down_write(&user_list_lock);
 		list_add(&as->list, &apm_user_list);
 		up_write(&user_list_lock);
 
 		filp->private_data = as;
 	}
 
 	return as ? 0 : -ENOMEM;
 }
 
 static const struct file_operations apm_bios_fops = {
 	.owner		= THIS_MODULE,
 	.read		= apm_read,
 	.poll		= apm_poll,
 	.unlocked_ioctl	= apm_ioctl,
 	.open		= apm_open,
 	.release	= apm_release,
 	.llseek		= noop_llseek,
 };
 
 static struct miscdevice apm_device = {
 	.minor		= APM_MINOR_DEV,
 	.name		= "apm_bios",
 	.fops		= &apm_bios_fops
 };
 
 
 #ifdef CONFIG_PROC_FS
 /*
  * Arguments, with symbols from linux/apm_bios.h.
  *
  *   0) Linux driver version (this will change if format changes)
  *   1) APM BIOS Version.  Usually 1.0, 1.1 or 1.2.
  *   2) APM flags from APM Installation Check (0x00):
  *	bit 0: APM_16_BIT_SUPPORT
  *	bit 1: APM_32_BIT_SUPPORT
  *	bit 2: APM_IDLE_SLOWS_CLOCK
  *	bit 3: APM_BIOS_DISABLED
  *	bit 4: APM_BIOS_DISENGAGED
  *   3) AC line status
  *	0x00: Off-line
  *	0x01: On-line
  *	0x02: On backup power (BIOS >= 1.1 only)
  *	0xff: Unknown
  *   4) Battery status
  *	0x00: High
  *	0x01: Low
  *	0x02: Critical
  *	0x03: Charging
  *	0x04: Selected battery not present (BIOS >= 1.2 only)
  *	0xff: Unknown
  *   5) Battery flag
  *	bit 0: High
  *	bit 1: Low
  *	bit 2: Critical
  *	bit 3: Charging
  *	bit 7: No system battery
  *	0xff: Unknown
  *   6) Remaining battery life (percentage of charge):
  *	0-100: valid
  *	-1: Unknown
  *   7) Remaining battery life (time units):
  *	Number of remaining minutes or seconds
  *	-1: Unknown
  *   8) min = minutes; sec = seconds
  */
 static int proc_apm_show(struct seq_file *m, void *v)
 {
 	struct apm_power_info info;
 	char *units;
 
 	info.ac_line_status = 0xff;
 	info.battery_status = 0xff;
 	info.battery_flag   = 0xff;
 	info.battery_life   = -1;
 	info.time	    = -1;
 	info.units	    = -1;
 
 	if (apm_get_power_status)
 		apm_get_power_status(&info);
 
 	switch (info.units) {
 	default:	units = "?";	break;
 	case 0: 	units = "min";	break;
 	case 1: 	units = "sec";	break;
 	}
 
 	seq_printf(m, "%s 1.2 0x%02x 0x%02x 0x%02x 0x%02x %d%% %d %s\n",
 		     driver_version, APM_32_BIT_SUPPORT,
 		     info.ac_line_status, info.battery_status,
 		     info.battery_flag, info.battery_life,
 		     info.time, units);
 
 	return 0;
 }
 
 static int proc_apm_open(struct inode *inode, struct file *file)
 {
 	return single_open(file, proc_apm_show, NULL);
 }
 
 static const struct file_operations apm_proc_fops = {
 	.owner		= THIS_MODULE,
 	.open		= proc_apm_open,
 	.read		= seq_read,
 	.llseek		= seq_lseek,
 	.release	= single_release,
 };
 #endif
 
 static int kapmd(void *arg)
 {
 	do {
 		apm_event_t event;
 
 		wait_event_interruptible(kapmd_wait,
 				!queue_empty(&kapmd_queue) || kthread_should_stop());
 
 		if (kthread_should_stop())
 			break;
 
 		spin_lock_irq(&kapmd_queue_lock);
 		event = 0;
 		if (!queue_empty(&kapmd_queue))
 			event = queue_get_event(&kapmd_queue);
 		spin_unlock_irq(&kapmd_queue_lock);
 
 		switch (event) {
 		case 0:
 			break;
 
 		case APM_LOW_BATTERY:
 		case APM_POWER_STATUS_CHANGE:
 			queue_event(event);
 			break;
 
 		case APM_USER_SUSPEND:
 		case APM_SYS_SUSPEND:
 			pm_suspend(PM_SUSPEND_MEM);
 			break;
 
 		case APM_CRITICAL_SUSPEND:
 			atomic_inc(&userspace_notification_inhibit);
 			pm_suspend(PM_SUSPEND_MEM);
 			atomic_dec(&userspace_notification_inhibit);
 			break;
 		}
 	} while (1);
 
 	return 0;
 }
 
 static int apm_suspend_notifier(struct notifier_block *nb,
 				unsigned long event,
 				void *dummy)
 {
 	struct apm_user *as;
 	int err;
 	unsigned long apm_event;
 
 	/* short-cut emergency suspends */
 	if (atomic_read(&userspace_notification_inhibit))
 		return NOTIFY_DONE;
 
 	switch (event) {
 	case PM_SUSPEND_PREPARE:
 	case PM_HIBERNATION_PREPARE:
 		apm_event = (event == PM_SUSPEND_PREPARE) ?
 			APM_USER_SUSPEND : APM_USER_HIBERNATION;
 		/*
 		 * Queue an event to all "writer" users that we want
 		 * to suspend and need their ack.
 		 */
 		mutex_lock(&state_lock);
 		down_read(&user_list_lock);
 
 		list_for_each_entry(as, &apm_user_list, list) {
 			if (as->suspend_state != SUSPEND_WAIT && as->reader &&
 			    as->writer && as->suser) {
 				as->suspend_state = SUSPEND_PENDING;
 				atomic_inc(&suspend_acks_pending);
 				queue_add_event(&as->queue, apm_event);
 			}
 		}
 
 		up_read(&user_list_lock);
 		mutex_unlock(&state_lock);
 		wake_up_interruptible(&apm_waitqueue);
 
 		/*
 		 * Wait for the the suspend_acks_pending variable to drop to
 		 * zero, meaning everybody acked the suspend event (or the
 		 * process was killed.)
 		 *
 		 * If the app won't answer within a short while we assume it
 		 * locked up and ignore it.
 		 */
 		err = wait_event_interruptible_timeout(
 			apm_suspend_waitqueue,
 			atomic_read(&suspend_acks_pending) == 0,
 			5*HZ);
 
 		/* timed out */
 		if (err == 0) {
 			/*
 			 * Move anybody who timed out to "ack timeout" state.
 			 *
 			 * We could time out and the userspace does the ACK
 			 * right after we time out but before we enter the
 			 * locked section here, but that's fine.
 			 */
 			mutex_lock(&state_lock);
 			down_read(&user_list_lock);
 			list_for_each_entry(as, &apm_user_list, list) {
 				if (as->suspend_state == SUSPEND_PENDING ||
 				    as->suspend_state == SUSPEND_READ) {
 					as->suspend_state = SUSPEND_ACKTO;
 					atomic_dec(&suspend_acks_pending);
 				}
 			}
 			up_read(&user_list_lock);
 			mutex_unlock(&state_lock);
 		}
 
 		/* let suspend proceed */
 		if (err >= 0)
 			return NOTIFY_OK;
 
 		/* interrupted by signal */
 		return notifier_from_errno(err);
 
 	case PM_POST_SUSPEND:
 	case PM_POST_HIBERNATION:
 		apm_event = (event == PM_POST_SUSPEND) ?
 			APM_NORMAL_RESUME : APM_HIBERNATION_RESUME;
 		/*
 		 * Anyone on the APM queues will think we're still suspended.
 		 * Send a message so everyone knows we're now awake again.
 		 */
 		queue_event(apm_event);
 
 		/*
 		 * Finally, wake up anyone who is sleeping on the suspend.
 		 */
 		mutex_lock(&state_lock);
 		down_read(&user_list_lock);
 		list_for_each_entry(as, &apm_user_list, list) {
 			if (as->suspend_state == SUSPEND_ACKED) {
 				/*
 				 * TODO: maybe grab error code, needs core
 				 * changes to push the error to the notifier
 				 * chain (could use the second parameter if
 				 * implemented)
 				 */
 				as->suspend_result = 0;
 				as->suspend_state = SUSPEND_DONE;
 			}
 		}
 		up_read(&user_list_lock);
 		mutex_unlock(&state_lock);
 
 		wake_up(&apm_suspend_waitqueue);
 		return NOTIFY_OK;
 
 	default:
 		return NOTIFY_DONE;
 	}
 }
 
 static struct notifier_block apm_notif_block = {
 	.notifier_call = apm_suspend_notifier,
 };
 
 static int __init apm_init(void)
 {
 	int ret;
 
 	if (apm_disabled) {
 		printk(KERN_NOTICE "apm: disabled on user request.\n");
 		return -ENODEV;
 	}
 
 	kapmd_tsk = kthread_create(kapmd, NULL, "kapmd");
 	if (IS_ERR(kapmd_tsk)) {
 		ret = PTR_ERR(kapmd_tsk);
 		kapmd_tsk = NULL;
 		goto out;
 	}
 	wake_up_process(kapmd_tsk);
 
 #ifdef CONFIG_PROC_FS
 	proc_create("apm", 0, NULL, &apm_proc_fops);
 #endif
 
 	ret = misc_register(&apm_device);
 	if (ret)
 		goto out_stop;
 
 	ret = register_pm_notifier(&apm_notif_block);
 	if (ret)
 		goto out_unregister;
 
 	return 0;
 
  out_unregister:
 	misc_deregister(&apm_device);
  out_stop:
 	remove_proc_entry("apm", NULL);
 	kthread_stop(kapmd_tsk);
  out:
 	return ret;
 }
 
 static void __exit apm_exit(void)
 {
 	unregister_pm_notifier(&apm_notif_block);
 	misc_deregister(&apm_device);
 	remove_proc_entry("apm", NULL);
 
 	kthread_stop(kapmd_tsk);
 }
 
 module_init(apm_init);
 module_exit(apm_exit);
 
 MODULE_AUTHOR("Stephen Rothwell");
 MODULE_DESCRIPTION("Advanced Power Management");
 MODULE_LICENSE("GPL");
 
 #ifndef MODULE
 static int __init apm_setup(char *str)
 {
 	while ((str != NULL) && (*str != '\0')) {
 		if (strncmp(str, "off", 3) == 0)
 			apm_disabled = 1;
 		if (strncmp(str, "on", 2) == 0)
 			apm_disabled = 0;
 		str = strchr(str, ',');
 		if (str != NULL)
 			str += strspn(str, ", \t");
 	}
 	return 1;
 }
 
 __setup("apm=", apm_setup);
 #endif
 
 /**
  * apm_queue_event - queue an APM event for kapmd
  * @event: APM event
  *
  * Queue an APM event for kapmd to process and ultimately take the
  * appropriate action.  Only a subset of events are handled:
  *   %APM_LOW_BATTERY
  *   %APM_POWER_STATUS_CHANGE
  *   %APM_USER_SUSPEND
  *   %APM_SYS_SUSPEND
  *   %APM_CRITICAL_SUSPEND
  */
 void apm_queue_event(apm_event_t event)
 {
 	unsigned long flags;
 
 	spin_lock_irqsave(&kapmd_queue_lock, flags);
 	queue_add_event(&kapmd_queue, event);
 	spin_unlock_irqrestore(&kapmd_queue_lock, flags);
 
 	wake_up_interruptible(&kapmd_wait);
 }
 EXPORT_SYMBOL(apm_queue_event);
diff --git a/drivers/char/ds1302.c b/drivers/char/ds1302.c
index 7d34b203718a..c614a56e68cc 100644
--- a/drivers/char/ds1302.c
+++ b/drivers/char/ds1302.c
@@ -1,357 +1,356 @@
 /*!***************************************************************************
 *!
 *! FILE NAME  : ds1302.c
 *!
 *! DESCRIPTION: Implements an interface for the DS1302 RTC
 *!
 *! Functions exported: ds1302_readreg, ds1302_writereg, ds1302_init, get_rtc_status
 *!
 *! ---------------------------------------------------------------------------
 *!
 *! (C) Copyright 1999, 2000, 2001  Axis Communications AB, LUND, SWEDEN
 *!
 *!***************************************************************************/
 
 
 #include <linux/fs.h>
 #include <linux/init.h>
 #include <linux/mm.h>
 #include <linux/module.h>
-#include <linux/miscdevice.h>
 #include <linux/delay.h>
 #include <linux/bcd.h>
 #include <linux/mutex.h>
 #include <linux/uaccess.h>
 #include <linux/io.h>
 
 #include <asm/rtc.h>
 #if defined(CONFIG_M32R)
 #include <asm/m32r.h>
 #endif
 
 #define RTC_MAJOR_NR 121 /* local major, change later */
 
 static DEFINE_MUTEX(rtc_mutex);
 static const char ds1302_name[] = "ds1302";
 
 /* Send 8 bits. */
 static void
 out_byte_rtc(unsigned int reg_addr, unsigned char x)
 {
 	//RST H
 	outw(0x0001,(unsigned long)PLD_RTCRSTODT);
 	//write data
 	outw(((x<<8)|(reg_addr&0xff)),(unsigned long)PLD_RTCWRDATA);
 	//WE
 	outw(0x0002,(unsigned long)PLD_RTCCR);
 	//wait
 	while(inw((unsigned long)PLD_RTCCR));
 
 	//RST L
 	outw(0x0000,(unsigned long)PLD_RTCRSTODT);
 
 }
 
 static unsigned char
 in_byte_rtc(unsigned int reg_addr)
 {
 	unsigned char retval;
 
 	//RST H
 	outw(0x0001,(unsigned long)PLD_RTCRSTODT);
 	//write data
 	outw((reg_addr&0xff),(unsigned long)PLD_RTCRDDATA);
 	//RE
 	outw(0x0001,(unsigned long)PLD_RTCCR);
 	//wait
 	while(inw((unsigned long)PLD_RTCCR));
 
 	//read data
 	retval=(inw((unsigned long)PLD_RTCRDDATA) & 0xff00)>>8;
 
 	//RST L
 	outw(0x0000,(unsigned long)PLD_RTCRSTODT);
 
 	return retval;
 }
 
 /* Enable writing. */
 
 static void
 ds1302_wenable(void)
 {
 	out_byte_rtc(0x8e,0x00);
 }
 
 /* Disable writing. */
 
 static void
 ds1302_wdisable(void)
 {
 	out_byte_rtc(0x8e,0x80);
 }
 
 
 
 /* Read a byte from the selected register in the DS1302. */
 
 unsigned char
 ds1302_readreg(int reg)
 {
 	unsigned char x;
 
 	x=in_byte_rtc((0x81 | (reg << 1))); /* read register */
 
 	return x;
 }
 
 /* Write a byte to the selected register. */
 
 void
 ds1302_writereg(int reg, unsigned char val)
 {
 	ds1302_wenable();
 	out_byte_rtc((0x80 | (reg << 1)),val);
 	ds1302_wdisable();
 }
 
 void
 get_rtc_time(struct rtc_time *rtc_tm)
 {
 	unsigned long flags;
 
 	local_irq_save(flags);
 
 	rtc_tm->tm_sec = CMOS_READ(RTC_SECONDS);
 	rtc_tm->tm_min = CMOS_READ(RTC_MINUTES);
 	rtc_tm->tm_hour = CMOS_READ(RTC_HOURS);
 	rtc_tm->tm_mday = CMOS_READ(RTC_DAY_OF_MONTH);
 	rtc_tm->tm_mon = CMOS_READ(RTC_MONTH);
 	rtc_tm->tm_year = CMOS_READ(RTC_YEAR);
 
 	local_irq_restore(flags);
 
 	rtc_tm->tm_sec = bcd2bin(rtc_tm->tm_sec);
 	rtc_tm->tm_min = bcd2bin(rtc_tm->tm_min);
 	rtc_tm->tm_hour = bcd2bin(rtc_tm->tm_hour);
 	rtc_tm->tm_mday = bcd2bin(rtc_tm->tm_mday);
 	rtc_tm->tm_mon = bcd2bin(rtc_tm->tm_mon);
 	rtc_tm->tm_year = bcd2bin(rtc_tm->tm_year);
 
 	/*
 	 * Account for differences between how the RTC uses the values
 	 * and how they are defined in a struct rtc_time;
 	 */
 
 	if (rtc_tm->tm_year <= 69)
 		rtc_tm->tm_year += 100;
 
 	rtc_tm->tm_mon--;
 }
 
 static unsigned char days_in_mo[] =
     {0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31};
 
 /* ioctl that supports RTC_RD_TIME and RTC_SET_TIME (read and set time/date). */
 
 static long rtc_ioctl(struct file *file, unsigned int cmd, unsigned long arg)
 {
 	unsigned long flags;
 
 	switch(cmd) {
 		case RTC_RD_TIME:	/* read the time/date from RTC	*/
 		{
 			struct rtc_time rtc_tm;
 
 			memset(&rtc_tm, 0, sizeof (struct rtc_time));
 			mutex_lock(&rtc_mutex);
 			get_rtc_time(&rtc_tm);
 			mutex_unlock(&rtc_mutex);
 			if (copy_to_user((struct rtc_time*)arg, &rtc_tm, sizeof(struct rtc_time)))
 				return -EFAULT;
 			return 0;
 		}
 
 		case RTC_SET_TIME:	/* set the RTC */
 		{
 			struct rtc_time rtc_tm;
 			unsigned char mon, day, hrs, min, sec, leap_yr;
 			unsigned int yrs;
 
 			if (!capable(CAP_SYS_TIME))
 				return -EPERM;
 
 			if (copy_from_user(&rtc_tm, (struct rtc_time*)arg, sizeof(struct rtc_time)))
 				return -EFAULT;
 
 			yrs = rtc_tm.tm_year + 1900;
 			mon = rtc_tm.tm_mon + 1;   /* tm_mon starts at zero */
 			day = rtc_tm.tm_mday;
 			hrs = rtc_tm.tm_hour;
 			min = rtc_tm.tm_min;
 			sec = rtc_tm.tm_sec;
 
 
 			if ((yrs < 1970) || (yrs > 2069))
 				return -EINVAL;
 
 			leap_yr = ((!(yrs % 4) && (yrs % 100)) || !(yrs % 400));
 
 			if ((mon > 12) || (day == 0))
 				return -EINVAL;
 
 			if (day > (days_in_mo[mon] + ((mon == 2) && leap_yr)))
 				return -EINVAL;
 
 			if ((hrs >= 24) || (min >= 60) || (sec >= 60))
 				return -EINVAL;
 
 			if (yrs >= 2000)
 				yrs -= 2000;	/* RTC (0, 1, ... 69) */
 			else
 				yrs -= 1900;	/* RTC (70, 71, ... 99) */
 
 			sec = bin2bcd(sec);
 			min = bin2bcd(min);
 			hrs = bin2bcd(hrs);
 			day = bin2bcd(day);
 			mon = bin2bcd(mon);
 			yrs = bin2bcd(yrs);
 
 			mutex_lock(&rtc_mutex);
 			local_irq_save(flags);
 			CMOS_WRITE(yrs, RTC_YEAR);
 			CMOS_WRITE(mon, RTC_MONTH);
 			CMOS_WRITE(day, RTC_DAY_OF_MONTH);
 			CMOS_WRITE(hrs, RTC_HOURS);
 			CMOS_WRITE(min, RTC_MINUTES);
 			CMOS_WRITE(sec, RTC_SECONDS);
 			local_irq_restore(flags);
 			mutex_unlock(&rtc_mutex);
 
 			/* Notice that at this point, the RTC is updated but
 			 * the kernel is still running with the old time.
 			 * You need to set that separately with settimeofday
 			 * or adjtimex.
 			 */
 			return 0;
 		}
 
 		case RTC_SET_CHARGE: /* set the RTC TRICKLE CHARGE register */
 		{
 			int tcs_val;
 
 			if (!capable(CAP_SYS_TIME))
 				return -EPERM;
 
 			if(copy_from_user(&tcs_val, (int*)arg, sizeof(int)))
 				return -EFAULT;
 
 			mutex_lock(&rtc_mutex);
 			tcs_val = RTC_TCR_PATTERN | (tcs_val & 0x0F);
 			ds1302_writereg(RTC_TRICKLECHARGER, tcs_val);
 			mutex_unlock(&rtc_mutex);
 			return 0;
 		}
 		default:
 			return -EINVAL;
 	}
 }
 
 int
 get_rtc_status(char *buf)
 {
 	char *p;
 	struct rtc_time tm;
 
 	p = buf;
 
 	get_rtc_time(&tm);
 
 	/*
 	 * There is no way to tell if the luser has the RTC set for local
 	 * time or for Universal Standard Time (GMT). Probably local though.
 	 */
 
 	p += sprintf(p,
 		"rtc_time\t: %02d:%02d:%02d\n"
 		"rtc_date\t: %04d-%02d-%02d\n",
 		tm.tm_hour, tm.tm_min, tm.tm_sec,
 		tm.tm_year + 1900, tm.tm_mon + 1, tm.tm_mday);
 
 	return  p - buf;
 }
 
 
 /* The various file operations we support. */
 
 static const struct file_operations rtc_fops = {
 	.owner		= THIS_MODULE,
 	.unlocked_ioctl	= rtc_ioctl,
 	.llseek		= noop_llseek,
 };
 
 /* Probe for the chip by writing something to its RAM and try reading it back. */
 
 #define MAGIC_PATTERN 0x42
 
 static int __init
 ds1302_probe(void)
 {
 	int retval, res, baur;
 
 	baur=(boot_cpu_data.bus_clock/(2*1000*1000));
 
 	printk("%s: Set PLD_RTCBAUR = %d\n", ds1302_name,baur);
 
 	outw(0x0000,(unsigned long)PLD_RTCCR);
 	outw(0x0000,(unsigned long)PLD_RTCRSTODT);
 	outw(baur,(unsigned long)PLD_RTCBAUR);
 
 	/* Try to talk to timekeeper. */
 
 	ds1302_wenable();
 	/* write RAM byte 0 */
 	/* write something magic */
 	out_byte_rtc(0xc0,MAGIC_PATTERN);
 
 	/* read RAM byte 0 */
 	if((res = in_byte_rtc(0xc1)) == MAGIC_PATTERN) {
 		char buf[100];
 		ds1302_wdisable();
 		printk("%s: RTC found.\n", ds1302_name);
 		get_rtc_status(buf);
 		printk(buf);
 		retval = 1;
 	} else {
 		printk("%s: RTC not found.\n", ds1302_name);
 		retval = 0;
 	}
 
 	return retval;
 }
 
 
 /* Just probe for the RTC and register the device to handle the ioctl needed. */
 
 int __init
 ds1302_init(void)
 {
 	if (!ds1302_probe()) {
 		return -1;
   	}
 	return 0;
 }
 
 static int __init ds1302_register(void)
 {
 	ds1302_init();
 	if (register_chrdev(RTC_MAJOR_NR, ds1302_name, &rtc_fops)) {
 		printk(KERN_INFO "%s: unable to get major %d for rtc\n",
 		       ds1302_name, RTC_MAJOR_NR);
 		return -1;
 	}
 	return 0;
 }
 
 module_init(ds1302_register);
diff --git a/drivers/char/mmtimer.c b/drivers/char/mmtimer.c
index f786b18ac500..b708c85dc9c1 100644
--- a/drivers/char/mmtimer.c
+++ b/drivers/char/mmtimer.c
@@ -1,858 +1,858 @@
 /*
  * Timer device implementation for SGI SN platforms.
  *
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
  * for more details.
  *
  * Copyright (c) 2001-2006 Silicon Graphics, Inc.  All rights reserved.
  *
  * This driver exports an API that should be supportable by any HPET or IA-PC
  * multimedia timer.  The code below is currently specific to the SGI Altix
  * SHub RTC, however.
  *
  * 11/01/01 - jbarnes - initial revision
  * 9/10/04 - Christoph Lameter - remove interrupt support for kernel inclusion
  * 10/1/04 - Christoph Lameter - provide posix clock CLOCK_SGI_CYCLE
  * 10/13/04 - Christoph Lameter, Dimitri Sivanich - provide timer interrupt
  *		support via the posix timer interface
  */
 
 #include <linux/types.h>
 #include <linux/kernel.h>
 #include <linux/ioctl.h>
 #include <linux/module.h>
 #include <linux/init.h>
 #include <linux/errno.h>
 #include <linux/mm.h>
 #include <linux/fs.h>
 #include <linux/mmtimer.h>
 #include <linux/miscdevice.h>
 #include <linux/posix-timers.h>
 #include <linux/interrupt.h>
 #include <linux/time.h>
 #include <linux/math64.h>
 #include <linux/mutex.h>
 #include <linux/slab.h>
 
 #include <linux/uaccess.h>
 #include <asm/sn/addrs.h>
 #include <asm/sn/intr.h>
 #include <asm/sn/shub_mmr.h>
 #include <asm/sn/nodepda.h>
 #include <asm/sn/shubio.h>
 
 MODULE_AUTHOR("Jesse Barnes <jbarnes@sgi.com>");
 MODULE_DESCRIPTION("SGI Altix RTC Timer");
 MODULE_LICENSE("GPL");
 
 /* name of the device, usually in /dev */
 #define MMTIMER_NAME "mmtimer"
 #define MMTIMER_DESC "SGI Altix RTC Timer"
 #define MMTIMER_VERSION "2.1"
 
 #define RTC_BITS 55 /* 55 bits for this implementation */
 
 static struct k_clock sgi_clock;
 
 extern unsigned long sn_rtc_cycles_per_second;
 
 #define RTC_COUNTER_ADDR        ((long *)LOCAL_MMR_ADDR(SH_RTC))
 
 #define rtc_time()              (*RTC_COUNTER_ADDR)
 
 static DEFINE_MUTEX(mmtimer_mutex);
 static long mmtimer_ioctl(struct file *file, unsigned int cmd,
 						unsigned long arg);
 static int mmtimer_mmap(struct file *file, struct vm_area_struct *vma);
 
 /*
  * Period in femtoseconds (10^-15 s)
  */
 static unsigned long mmtimer_femtoperiod = 0;
 
 static const struct file_operations mmtimer_fops = {
 	.owner = THIS_MODULE,
 	.mmap =	mmtimer_mmap,
 	.unlocked_ioctl = mmtimer_ioctl,
 	.llseek = noop_llseek,
 };
 
 /*
  * We only have comparison registers RTC1-4 currently available per
  * node.  RTC0 is used by SAL.
  */
 /* Check for an RTC interrupt pending */
 static int mmtimer_int_pending(int comparator)
 {
 	if (HUB_L((unsigned long *)LOCAL_MMR_ADDR(SH_EVENT_OCCURRED)) &
 			SH_EVENT_OCCURRED_RTC1_INT_MASK << comparator)
 		return 1;
 	else
 		return 0;
 }
 
 /* Clear the RTC interrupt pending bit */
 static void mmtimer_clr_int_pending(int comparator)
 {
 	HUB_S((u64 *)LOCAL_MMR_ADDR(SH_EVENT_OCCURRED_ALIAS),
 		SH_EVENT_OCCURRED_RTC1_INT_MASK << comparator);
 }
 
 /* Setup timer on comparator RTC1 */
 static void mmtimer_setup_int_0(int cpu, u64 expires)
 {
 	u64 val;
 
 	/* Disable interrupt */
 	HUB_S((u64 *)LOCAL_MMR_ADDR(SH_RTC1_INT_ENABLE), 0UL);
 
 	/* Initialize comparator value */
 	HUB_S((u64 *)LOCAL_MMR_ADDR(SH_INT_CMPB), -1L);
 
 	/* Clear pending bit */
 	mmtimer_clr_int_pending(0);
 
 	val = ((u64)SGI_MMTIMER_VECTOR << SH_RTC1_INT_CONFIG_IDX_SHFT) |
 		((u64)cpu_physical_id(cpu) <<
 			SH_RTC1_INT_CONFIG_PID_SHFT);
 
 	/* Set configuration */
 	HUB_S((u64 *)LOCAL_MMR_ADDR(SH_RTC1_INT_CONFIG), val);
 
 	/* Enable RTC interrupts */
 	HUB_S((u64 *)LOCAL_MMR_ADDR(SH_RTC1_INT_ENABLE), 1UL);
 
 	/* Initialize comparator value */
 	HUB_S((u64 *)LOCAL_MMR_ADDR(SH_INT_CMPB), expires);
 
 
 }
 
 /* Setup timer on comparator RTC2 */
 static void mmtimer_setup_int_1(int cpu, u64 expires)
 {
 	u64 val;
 
 	HUB_S((u64 *)LOCAL_MMR_ADDR(SH_RTC2_INT_ENABLE), 0UL);
 
 	HUB_S((u64 *)LOCAL_MMR_ADDR(SH_INT_CMPC), -1L);
 
 	mmtimer_clr_int_pending(1);
 
 	val = ((u64)SGI_MMTIMER_VECTOR << SH_RTC2_INT_CONFIG_IDX_SHFT) |
 		((u64)cpu_physical_id(cpu) <<
 			SH_RTC2_INT_CONFIG_PID_SHFT);
 
 	HUB_S((u64 *)LOCAL_MMR_ADDR(SH_RTC2_INT_CONFIG), val);
 
 	HUB_S((u64 *)LOCAL_MMR_ADDR(SH_RTC2_INT_ENABLE), 1UL);
 
 	HUB_S((u64 *)LOCAL_MMR_ADDR(SH_INT_CMPC), expires);
 }
 
 /* Setup timer on comparator RTC3 */
 static void mmtimer_setup_int_2(int cpu, u64 expires)
 {
 	u64 val;
 
 	HUB_S((u64 *)LOCAL_MMR_ADDR(SH_RTC3_INT_ENABLE), 0UL);
 
 	HUB_S((u64 *)LOCAL_MMR_ADDR(SH_INT_CMPD), -1L);
 
 	mmtimer_clr_int_pending(2);
 
 	val = ((u64)SGI_MMTIMER_VECTOR << SH_RTC3_INT_CONFIG_IDX_SHFT) |
 		((u64)cpu_physical_id(cpu) <<
 			SH_RTC3_INT_CONFIG_PID_SHFT);
 
 	HUB_S((u64 *)LOCAL_MMR_ADDR(SH_RTC3_INT_CONFIG), val);
 
 	HUB_S((u64 *)LOCAL_MMR_ADDR(SH_RTC3_INT_ENABLE), 1UL);
 
 	HUB_S((u64 *)LOCAL_MMR_ADDR(SH_INT_CMPD), expires);
 }
 
 /*
  * This function must be called with interrupts disabled and preemption off
  * in order to insure that the setup succeeds in a deterministic time frame.
  * It will check if the interrupt setup succeeded.
  */
 static int mmtimer_setup(int cpu, int comparator, unsigned long expires,
 	u64 *set_completion_time)
 {
 	switch (comparator) {
 	case 0:
 		mmtimer_setup_int_0(cpu, expires);
 		break;
 	case 1:
 		mmtimer_setup_int_1(cpu, expires);
 		break;
 	case 2:
 		mmtimer_setup_int_2(cpu, expires);
 		break;
 	}
 	/* We might've missed our expiration time */
 	*set_completion_time = rtc_time();
 	if (*set_completion_time <= expires)
 		return 1;
 
 	/*
 	 * If an interrupt is already pending then its okay
 	 * if not then we failed
 	 */
 	return mmtimer_int_pending(comparator);
 }
 
 static int mmtimer_disable_int(long nasid, int comparator)
 {
 	switch (comparator) {
 	case 0:
 		nasid == -1 ? HUB_S((u64 *)LOCAL_MMR_ADDR(SH_RTC1_INT_ENABLE),
 			0UL) : REMOTE_HUB_S(nasid, SH_RTC1_INT_ENABLE, 0UL);
 		break;
 	case 1:
 		nasid == -1 ? HUB_S((u64 *)LOCAL_MMR_ADDR(SH_RTC2_INT_ENABLE),
 			0UL) : REMOTE_HUB_S(nasid, SH_RTC2_INT_ENABLE, 0UL);
 		break;
 	case 2:
 		nasid == -1 ? HUB_S((u64 *)LOCAL_MMR_ADDR(SH_RTC3_INT_ENABLE),
 			0UL) : REMOTE_HUB_S(nasid, SH_RTC3_INT_ENABLE, 0UL);
 		break;
 	default:
 		return -EFAULT;
 	}
 	return 0;
 }
 
 #define COMPARATOR	1		/* The comparator to use */
 
 #define TIMER_OFF	0xbadcabLL	/* Timer is not setup */
 #define TIMER_SET	0		/* Comparator is set for this timer */
 
 #define MMTIMER_INTERVAL_RETRY_INCREMENT_DEFAULT 40
 
 /* There is one of these for each timer */
 struct mmtimer {
 	struct rb_node list;
 	struct k_itimer *timer;
 	int cpu;
 };
 
 struct mmtimer_node {
 	spinlock_t lock ____cacheline_aligned;
 	struct rb_root timer_head;
 	struct rb_node *next;
 	struct tasklet_struct tasklet;
 };
 static struct mmtimer_node *timers;
 
 static unsigned mmtimer_interval_retry_increment =
 	MMTIMER_INTERVAL_RETRY_INCREMENT_DEFAULT;
 module_param(mmtimer_interval_retry_increment, uint, 0644);
 MODULE_PARM_DESC(mmtimer_interval_retry_increment,
 	"RTC ticks to add to expiration on interval retry (default 40)");
 
 /*
  * Add a new mmtimer struct to the node's mmtimer list.
  * This function assumes the struct mmtimer_node is locked.
  */
 static void mmtimer_add_list(struct mmtimer *n)
 {
 	int nodeid = n->timer->it.mmtimer.node;
 	unsigned long expires = n->timer->it.mmtimer.expires;
 	struct rb_node **link = &timers[nodeid].timer_head.rb_node;
 	struct rb_node *parent = NULL;
 	struct mmtimer *x;
 
 	/*
 	 * Find the right place in the rbtree:
 	 */
 	while (*link) {
 		parent = *link;
 		x = rb_entry(parent, struct mmtimer, list);
 
 		if (expires < x->timer->it.mmtimer.expires)
 			link = &(*link)->rb_left;
 		else
 			link = &(*link)->rb_right;
 	}
 
 	/*
 	 * Insert the timer to the rbtree and check whether it
 	 * replaces the first pending timer
 	 */
 	rb_link_node(&n->list, parent, link);
 	rb_insert_color(&n->list, &timers[nodeid].timer_head);
 
 	if (!timers[nodeid].next || expires < rb_entry(timers[nodeid].next,
 			struct mmtimer, list)->timer->it.mmtimer.expires)
 		timers[nodeid].next = &n->list;
 }
 
 /*
  * Set the comparator for the next timer.
  * This function assumes the struct mmtimer_node is locked.
  */
 static void mmtimer_set_next_timer(int nodeid)
 {
 	struct mmtimer_node *n = &timers[nodeid];
 	struct mmtimer *x;
 	struct k_itimer *t;
 	u64 expires, exp, set_completion_time;
 	int i;
 
 restart:
 	if (n->next == NULL)
 		return;
 
 	x = rb_entry(n->next, struct mmtimer, list);
 	t = x->timer;
 	if (!t->it.mmtimer.incr) {
 		/* Not an interval timer */
 		if (!mmtimer_setup(x->cpu, COMPARATOR,
 					t->it.mmtimer.expires,
 					&set_completion_time)) {
 			/* Late setup, fire now */
 			tasklet_schedule(&n->tasklet);
 		}
 		return;
 	}
 
 	/* Interval timer */
 	i = 0;
 	expires = exp = t->it.mmtimer.expires;
 	while (!mmtimer_setup(x->cpu, COMPARATOR, expires,
 				&set_completion_time)) {
 		int to;
 
 		i++;
 		expires = set_completion_time +
 				mmtimer_interval_retry_increment + (1 << i);
 		/* Calculate overruns as we go. */
 		to = ((u64)(expires - exp) / t->it.mmtimer.incr);
 		if (to) {
 			t->it_overrun += to;
 			t->it.mmtimer.expires += t->it.mmtimer.incr * to;
 			exp = t->it.mmtimer.expires;
 		}
 		if (i > 20) {
 			printk(KERN_ALERT "mmtimer: cannot reschedule timer\n");
 			t->it.mmtimer.clock = TIMER_OFF;
 			n->next = rb_next(&x->list);
 			rb_erase(&x->list, &n->timer_head);
 			kfree(x);
 			goto restart;
 		}
 	}
 }
 
 /**
  * mmtimer_ioctl - ioctl interface for /dev/mmtimer
  * @file: file structure for the device
  * @cmd: command to execute
  * @arg: optional argument to command
  *
  * Executes the command specified by @cmd.  Returns 0 for success, < 0 for
  * failure.
  *
  * Valid commands:
  *
  * %MMTIMER_GETOFFSET - Should return the offset (relative to the start
  * of the page where the registers are mapped) for the counter in question.
  *
  * %MMTIMER_GETRES - Returns the resolution of the clock in femto (10^-15)
  * seconds
  *
  * %MMTIMER_GETFREQ - Copies the frequency of the clock in Hz to the address
  * specified by @arg
  *
  * %MMTIMER_GETBITS - Returns the number of bits in the clock's counter
  *
  * %MMTIMER_MMAPAVAIL - Returns 1 if the registers can be mmap'd into userspace
  *
  * %MMTIMER_GETCOUNTER - Gets the current value in the counter and places it
  * in the address specified by @arg.
  */
 static long mmtimer_ioctl(struct file *file, unsigned int cmd,
 						unsigned long arg)
 {
 	int ret = 0;
 
 	mutex_lock(&mmtimer_mutex);
 
 	switch (cmd) {
 	case MMTIMER_GETOFFSET:	/* offset of the counter */
 		/*
 		 * SN RTC registers are on their own 64k page
 		 */
 		if(PAGE_SIZE <= (1 << 16))
 			ret = (((long)RTC_COUNTER_ADDR) & (PAGE_SIZE-1)) / 8;
 		else
 			ret = -ENOSYS;
 		break;
 
 	case MMTIMER_GETRES: /* resolution of the clock in 10^-15 s */
 		if(copy_to_user((unsigned long __user *)arg,
 				&mmtimer_femtoperiod, sizeof(unsigned long)))
 			ret = -EFAULT;
 		break;
 
 	case MMTIMER_GETFREQ: /* frequency in Hz */
 		if(copy_to_user((unsigned long __user *)arg,
 				&sn_rtc_cycles_per_second,
 				sizeof(unsigned long)))
 			ret = -EFAULT;
 		break;
 
 	case MMTIMER_GETBITS: /* number of bits in the clock */
 		ret = RTC_BITS;
 		break;
 
 	case MMTIMER_MMAPAVAIL: /* can we mmap the clock into userspace? */
 		ret = (PAGE_SIZE <= (1 << 16)) ? 1 : 0;
 		break;
 
 	case MMTIMER_GETCOUNTER:
 		if(copy_to_user((unsigned long __user *)arg,
 				RTC_COUNTER_ADDR, sizeof(unsigned long)))
 			ret = -EFAULT;
 		break;
 	default:
 		ret = -ENOTTY;
 		break;
 	}
 	mutex_unlock(&mmtimer_mutex);
 	return ret;
 }
 
 /**
  * mmtimer_mmap - maps the clock's registers into userspace
  * @file: file structure for the device
  * @vma: VMA to map the registers into
  *
  * Calls remap_pfn_range() to map the clock's registers into
  * the calling process' address space.
  */
 static int mmtimer_mmap(struct file *file, struct vm_area_struct *vma)
 {
 	unsigned long mmtimer_addr;
 
 	if (vma->vm_end - vma->vm_start != PAGE_SIZE)
 		return -EINVAL;
 
 	if (vma->vm_flags & VM_WRITE)
 		return -EPERM;
 
 	if (PAGE_SIZE > (1 << 16))
 		return -ENOSYS;
 
 	vma->vm_page_prot = pgprot_noncached(vma->vm_page_prot);
 
 	mmtimer_addr = __pa(RTC_COUNTER_ADDR);
 	mmtimer_addr &= ~(PAGE_SIZE - 1);
 	mmtimer_addr &= 0xfffffffffffffffUL;
 
 	if (remap_pfn_range(vma, vma->vm_start, mmtimer_addr >> PAGE_SHIFT,
 					PAGE_SIZE, vma->vm_page_prot)) {
 		printk(KERN_ERR "remap_pfn_range failed in mmtimer.c\n");
 		return -EAGAIN;
 	}
 
 	return 0;
 }
 
 static struct miscdevice mmtimer_miscdev = {
-	SGI_MMTIMER,
-	MMTIMER_NAME,
-	&mmtimer_fops
+	.minor = SGI_MMTIMER,
+	.name = MMTIMER_NAME,
+	.fops = &mmtimer_fops
 };
 
 static struct timespec sgi_clock_offset;
 static int sgi_clock_period;
 
 /*
  * Posix Timer Interface
  */
 
 static struct timespec sgi_clock_offset;
 static int sgi_clock_period;
 
 static int sgi_clock_get(clockid_t clockid, struct timespec *tp)
 {
 	u64 nsec;
 
 	nsec = rtc_time() * sgi_clock_period
 			+ sgi_clock_offset.tv_nsec;
 	*tp = ns_to_timespec(nsec);
 	tp->tv_sec += sgi_clock_offset.tv_sec;
 	return 0;
 };
 
 static int sgi_clock_set(const clockid_t clockid, const struct timespec *tp)
 {
 
 	u64 nsec;
 	u32 rem;
 
 	nsec = rtc_time() * sgi_clock_period;
 
 	sgi_clock_offset.tv_sec = tp->tv_sec - div_u64_rem(nsec, NSEC_PER_SEC, &rem);
 
 	if (rem <= tp->tv_nsec)
 		sgi_clock_offset.tv_nsec = tp->tv_sec - rem;
 	else {
 		sgi_clock_offset.tv_nsec = tp->tv_sec + NSEC_PER_SEC - rem;
 		sgi_clock_offset.tv_sec--;
 	}
 	return 0;
 }
 
 /**
  * mmtimer_interrupt - timer interrupt handler
  * @irq: irq received
  * @dev_id: device the irq came from
  *
  * Called when one of the comarators matches the counter, This
  * routine will send signals to processes that have requested
  * them.
  *
  * This interrupt is run in an interrupt context
  * by the SHUB. It is therefore safe to locally access SHub
  * registers.
  */
 static irqreturn_t
 mmtimer_interrupt(int irq, void *dev_id)
 {
 	unsigned long expires = 0;
 	int result = IRQ_NONE;
 	unsigned indx = cpu_to_node(smp_processor_id());
 	struct mmtimer *base;
 
 	spin_lock(&timers[indx].lock);
 	base = rb_entry(timers[indx].next, struct mmtimer, list);
 	if (base == NULL) {
 		spin_unlock(&timers[indx].lock);
 		return result;
 	}
 
 	if (base->cpu == smp_processor_id()) {
 		if (base->timer)
 			expires = base->timer->it.mmtimer.expires;
 		/* expires test won't work with shared irqs */
 		if ((mmtimer_int_pending(COMPARATOR) > 0) ||
 			(expires && (expires <= rtc_time()))) {
 			mmtimer_clr_int_pending(COMPARATOR);
 			tasklet_schedule(&timers[indx].tasklet);
 			result = IRQ_HANDLED;
 		}
 	}
 	spin_unlock(&timers[indx].lock);
 	return result;
 }
 
 static void mmtimer_tasklet(unsigned long data)
 {
 	int nodeid = data;
 	struct mmtimer_node *mn = &timers[nodeid];
 	struct mmtimer *x;
 	struct k_itimer *t;
 	unsigned long flags;
 
 	/* Send signal and deal with periodic signals */
 	spin_lock_irqsave(&mn->lock, flags);
 	if (!mn->next)
 		goto out;
 
 	x = rb_entry(mn->next, struct mmtimer, list);
 	t = x->timer;
 
 	if (t->it.mmtimer.clock == TIMER_OFF)
 		goto out;
 
 	t->it_overrun = 0;
 
 	mn->next = rb_next(&x->list);
 	rb_erase(&x->list, &mn->timer_head);
 
 	if (posix_timer_event(t, 0) != 0)
 		t->it_overrun++;
 
 	if(t->it.mmtimer.incr) {
 		t->it.mmtimer.expires += t->it.mmtimer.incr;
 		mmtimer_add_list(x);
 	} else {
 		/* Ensure we don't false trigger in mmtimer_interrupt */
 		t->it.mmtimer.clock = TIMER_OFF;
 		t->it.mmtimer.expires = 0;
 		kfree(x);
 	}
 	/* Set comparator for next timer, if there is one */
 	mmtimer_set_next_timer(nodeid);
 
 	t->it_overrun_last = t->it_overrun;
 out:
 	spin_unlock_irqrestore(&mn->lock, flags);
 }
 
 static int sgi_timer_create(struct k_itimer *timer)
 {
 	/* Insure that a newly created timer is off */
 	timer->it.mmtimer.clock = TIMER_OFF;
 	return 0;
 }
 
 /* This does not really delete a timer. It just insures
  * that the timer is not active
  *
  * Assumption: it_lock is already held with irq's disabled
  */
 static int sgi_timer_del(struct k_itimer *timr)
 {
 	cnodeid_t nodeid = timr->it.mmtimer.node;
 	unsigned long irqflags;
 
 	spin_lock_irqsave(&timers[nodeid].lock, irqflags);
 	if (timr->it.mmtimer.clock != TIMER_OFF) {
 		unsigned long expires = timr->it.mmtimer.expires;
 		struct rb_node *n = timers[nodeid].timer_head.rb_node;
 		struct mmtimer *uninitialized_var(t);
 		int r = 0;
 
 		timr->it.mmtimer.clock = TIMER_OFF;
 		timr->it.mmtimer.expires = 0;
 
 		while (n) {
 			t = rb_entry(n, struct mmtimer, list);
 			if (t->timer == timr)
 				break;
 
 			if (expires < t->timer->it.mmtimer.expires)
 				n = n->rb_left;
 			else
 				n = n->rb_right;
 		}
 
 		if (!n) {
 			spin_unlock_irqrestore(&timers[nodeid].lock, irqflags);
 			return 0;
 		}
 
 		if (timers[nodeid].next == n) {
 			timers[nodeid].next = rb_next(n);
 			r = 1;
 		}
 
 		rb_erase(n, &timers[nodeid].timer_head);
 		kfree(t);
 
 		if (r) {
 			mmtimer_disable_int(cnodeid_to_nasid(nodeid),
 				COMPARATOR);
 			mmtimer_set_next_timer(nodeid);
 		}
 	}
 	spin_unlock_irqrestore(&timers[nodeid].lock, irqflags);
 	return 0;
 }
 
 /* Assumption: it_lock is already held with irq's disabled */
 static void sgi_timer_get(struct k_itimer *timr, struct itimerspec *cur_setting)
 {
 
 	if (timr->it.mmtimer.clock == TIMER_OFF) {
 		cur_setting->it_interval.tv_nsec = 0;
 		cur_setting->it_interval.tv_sec = 0;
 		cur_setting->it_value.tv_nsec = 0;
 		cur_setting->it_value.tv_sec =0;
 		return;
 	}
 
 	cur_setting->it_interval = ns_to_timespec(timr->it.mmtimer.incr * sgi_clock_period);
 	cur_setting->it_value = ns_to_timespec((timr->it.mmtimer.expires - rtc_time()) * sgi_clock_period);
 }
 
 
 static int sgi_timer_set(struct k_itimer *timr, int flags,
 	struct itimerspec * new_setting,
 	struct itimerspec * old_setting)
 {
 	unsigned long when, period, irqflags;
 	int err = 0;
 	cnodeid_t nodeid;
 	struct mmtimer *base;
 	struct rb_node *n;
 
 	if (old_setting)
 		sgi_timer_get(timr, old_setting);
 
 	sgi_timer_del(timr);
 	when = timespec_to_ns(&new_setting->it_value);
 	period = timespec_to_ns(&new_setting->it_interval);
 
 	if (when == 0)
 		/* Clear timer */
 		return 0;
 
 	base = kmalloc(sizeof(struct mmtimer), GFP_KERNEL);
 	if (base == NULL)
 		return -ENOMEM;
 
 	if (flags & TIMER_ABSTIME) {
 		struct timespec n;
 		unsigned long now;
 
 		getnstimeofday(&n);
 		now = timespec_to_ns(&n);
 		if (when > now)
 			when -= now;
 		else
 			/* Fire the timer immediately */
 			when = 0;
 	}
 
 	/*
 	 * Convert to sgi clock period. Need to keep rtc_time() as near as possible
 	 * to getnstimeofday() in order to be as faithful as possible to the time
 	 * specified.
 	 */
 	when = (when + sgi_clock_period - 1) / sgi_clock_period + rtc_time();
 	period = (period + sgi_clock_period - 1)  / sgi_clock_period;
 
 	/*
 	 * We are allocating a local SHub comparator. If we would be moved to another
 	 * cpu then another SHub may be local to us. Prohibit that by switching off
 	 * preemption.
 	 */
 	preempt_disable();
 
 	nodeid =  cpu_to_node(smp_processor_id());
 
 	/* Lock the node timer structure */
 	spin_lock_irqsave(&timers[nodeid].lock, irqflags);
 
 	base->timer = timr;
 	base->cpu = smp_processor_id();
 
 	timr->it.mmtimer.clock = TIMER_SET;
 	timr->it.mmtimer.node = nodeid;
 	timr->it.mmtimer.incr = period;
 	timr->it.mmtimer.expires = when;
 
 	n = timers[nodeid].next;
 
 	/* Add the new struct mmtimer to node's timer list */
 	mmtimer_add_list(base);
 
 	if (timers[nodeid].next == n) {
 		/* No need to reprogram comparator for now */
 		spin_unlock_irqrestore(&timers[nodeid].lock, irqflags);
 		preempt_enable();
 		return err;
 	}
 
 	/* We need to reprogram the comparator */
 	if (n)
 		mmtimer_disable_int(cnodeid_to_nasid(nodeid), COMPARATOR);
 
 	mmtimer_set_next_timer(nodeid);
 
 	/* Unlock the node timer structure */
 	spin_unlock_irqrestore(&timers[nodeid].lock, irqflags);
 
 	preempt_enable();
 
 	return err;
 }
 
 static int sgi_clock_getres(const clockid_t which_clock, struct timespec *tp)
 {
 	tp->tv_sec = 0;
 	tp->tv_nsec = sgi_clock_period;
 	return 0;
 }
 
 static struct k_clock sgi_clock = {
 	.clock_set	= sgi_clock_set,
 	.clock_get	= sgi_clock_get,
 	.clock_getres	= sgi_clock_getres,
 	.timer_create	= sgi_timer_create,
 	.timer_set	= sgi_timer_set,
 	.timer_del	= sgi_timer_del,
 	.timer_get	= sgi_timer_get
 };
 
 /**
  * mmtimer_init - device initialization routine
  *
  * Does initial setup for the mmtimer device.
  */
 static int __init mmtimer_init(void)
 {
 	cnodeid_t node, maxn = -1;
 
 	if (!ia64_platform_is("sn2"))
 		return 0;
 
 	/*
 	 * Sanity check the cycles/sec variable
 	 */
 	if (sn_rtc_cycles_per_second < 100000) {
 		printk(KERN_ERR "%s: unable to determine clock frequency\n",
 		       MMTIMER_NAME);
 		goto out1;
 	}
 
 	mmtimer_femtoperiod = ((unsigned long)1E15 + sn_rtc_cycles_per_second /
 			       2) / sn_rtc_cycles_per_second;
 
 	if (request_irq(SGI_MMTIMER_VECTOR, mmtimer_interrupt, IRQF_PERCPU, MMTIMER_NAME, NULL)) {
 		printk(KERN_WARNING "%s: unable to allocate interrupt.",
 			MMTIMER_NAME);
 		goto out1;
 	}
 
 	if (misc_register(&mmtimer_miscdev)) {
 		printk(KERN_ERR "%s: failed to register device\n",
 		       MMTIMER_NAME);
 		goto out2;
 	}
 
 	/* Get max numbered node, calculate slots needed */
 	for_each_online_node(node) {
 		maxn = node;
 	}
 	maxn++;
 
 	/* Allocate list of node ptrs to mmtimer_t's */
 	timers = kzalloc(sizeof(struct mmtimer_node)*maxn, GFP_KERNEL);
 	if (!timers) {
 		printk(KERN_ERR "%s: failed to allocate memory for device\n",
 				MMTIMER_NAME);
 		goto out3;
 	}
 
 	/* Initialize struct mmtimer's for each online node */
 	for_each_online_node(node) {
 		spin_lock_init(&timers[node].lock);
 		tasklet_init(&timers[node].tasklet, mmtimer_tasklet,
 			(unsigned long) node);
 	}
 
 	sgi_clock_period = NSEC_PER_SEC / sn_rtc_cycles_per_second;
 	posix_timers_register_clock(CLOCK_SGI_CYCLE, &sgi_clock);
 
 	printk(KERN_INFO "%s: v%s, %ld MHz\n", MMTIMER_DESC, MMTIMER_VERSION,
 	       sn_rtc_cycles_per_second/(unsigned long)1E6);
 
 	return 0;
 
 out3:
 	misc_deregister(&mmtimer_miscdev);
 out2:
 	free_irq(SGI_MMTIMER_VECTOR, NULL);
 out1:
 	return -1;
 }
 
 module_init(mmtimer_init);
diff --git a/drivers/char/xilinx_hwicap/buffer_icap.c b/drivers/char/xilinx_hwicap/buffer_icap.c
index 53c3882e4981..35981cae1afa 100644
--- a/drivers/char/xilinx_hwicap/buffer_icap.c
+++ b/drivers/char/xilinx_hwicap/buffer_icap.c
@@ -1,365 +1,361 @@
 /*****************************************************************************
  *
  *     Author: Xilinx, Inc.
  *
  *     This program is free software; you can redistribute it and/or modify it
  *     under the terms of the GNU General Public License as published by the
  *     Free Software Foundation; either version 2 of the License, or (at your
  *     option) any later version.
  *
  *     XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
  *     AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
  *     SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
  *     OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
  *     APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
  *     THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
  *     AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
  *     FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
  *     WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
  *     IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
  *     REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
  *     INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
  *     FOR A PARTICULAR PURPOSE.
  *
  *     (c) Copyright 2003-2008 Xilinx Inc.
  *     All rights reserved.
  *
  *     You should have received a copy of the GNU General Public License along
  *     with this program; if not, write to the Free Software Foundation, Inc.,
  *     675 Mass Ave, Cambridge, MA 02139, USA.
  *
  *****************************************************************************/
 
 #include "buffer_icap.h"
 
 /* Indicates how many bytes will fit in a buffer. (1 BRAM) */
 #define XHI_MAX_BUFFER_BYTES        2048
 #define XHI_MAX_BUFFER_INTS         (XHI_MAX_BUFFER_BYTES >> 2)
 
 /* File access and error constants */
 #define XHI_DEVICE_READ_ERROR       -1
 #define XHI_DEVICE_WRITE_ERROR      -2
 #define XHI_BUFFER_OVERFLOW_ERROR   -3
 
 #define XHI_DEVICE_READ             0x1
 #define XHI_DEVICE_WRITE            0x0
 
 /* Constants for checking transfer status */
 #define XHI_CYCLE_DONE              0
 #define XHI_CYCLE_EXECUTING         1
 
 /* buffer_icap register offsets */
 
 /* Size of transfer, read & write */
 #define XHI_SIZE_REG_OFFSET        0x800L
 /* offset into bram, read & write */
 #define XHI_BRAM_OFFSET_REG_OFFSET 0x804L
 /* Read not Configure, direction of transfer.  Write only */
 #define XHI_RNC_REG_OFFSET         0x808L
 /* Indicates transfer complete. Read only */
 #define XHI_STATUS_REG_OFFSET      0x80CL
 
 /* Constants for setting the RNC register */
 #define XHI_CONFIGURE              0x0UL
 #define XHI_READBACK               0x1UL
 
 /* Constants for the Done register */
 #define XHI_NOT_FINISHED           0x0UL
 #define XHI_FINISHED               0x1UL
 
 #define XHI_BUFFER_START 0
 
 /**
  * buffer_icap_get_status - Get the contents of the status register.
  * @drvdata: a pointer to the drvdata.
  *
  * The status register contains the ICAP status and the done bit.
  *
  * D8 - cfgerr
  * D7 - dalign
  * D6 - rip
  * D5 - in_abort_l
  * D4 - Always 1
  * D3 - Always 1
  * D2 - Always 1
  * D1 - Always 1
  * D0 - Done bit
  **/
 u32 buffer_icap_get_status(struct hwicap_drvdata *drvdata)
 {
 	return in_be32(drvdata->base_address + XHI_STATUS_REG_OFFSET);
 }
 
 /**
  * buffer_icap_get_bram - Reads data from the storage buffer bram.
  * @base_address: contains the base address of the component.
  * @offset: The word offset from which the data should be read.
  *
  * A bram is used as a configuration memory cache.  One frame of data can
  * be stored in this "storage buffer".
  **/
 static inline u32 buffer_icap_get_bram(void __iomem *base_address,
 		u32 offset)
 {
 	return in_be32(base_address + (offset << 2));
 }
 
 /**
  * buffer_icap_busy - Return true if the icap device is busy
  * @base_address: is the base address of the device
  *
  * The queries the low order bit of the status register, which
  * indicates whether the current configuration or readback operation
  * has completed.
  **/
 static inline bool buffer_icap_busy(void __iomem *base_address)
 {
 	u32 status = in_be32(base_address + XHI_STATUS_REG_OFFSET);
 	return (status & 1) == XHI_NOT_FINISHED;
 }
 
 /**
  * buffer_icap_set_size - Set the size register.
  * @base_address: is the base address of the device
  * @data: The size in bytes.
  *
  * The size register holds the number of 8 bit bytes to transfer between
  * bram and the icap (or icap to bram).
  **/
 static inline void buffer_icap_set_size(void __iomem *base_address,
 		u32 data)
 {
 	out_be32(base_address + XHI_SIZE_REG_OFFSET, data);
 }
 
 /**
  * buffer_icap_set_offset - Set the bram offset register.
  * @base_address: contains the base address of the device.
  * @data: is the value to be written to the data register.
  *
  * The bram offset register holds the starting bram address to transfer
  * data from during configuration or write data to during readback.
  **/
 static inline void buffer_icap_set_offset(void __iomem *base_address,
 		u32 data)
 {
 	out_be32(base_address + XHI_BRAM_OFFSET_REG_OFFSET, data);
 }
 
 /**
  * buffer_icap_set_rnc - Set the RNC (Readback not Configure) register.
  * @base_address: contains the base address of the device.
  * @data: is the value to be written to the data register.
  *
  * The RNC register determines the direction of the data transfer.  It
  * controls whether a configuration or readback take place.  Writing to
  * this register initiates the transfer.  A value of 1 initiates a
  * readback while writing a value of 0 initiates a configuration.
  **/
 static inline void buffer_icap_set_rnc(void __iomem *base_address,
 		u32 data)
 {
 	out_be32(base_address + XHI_RNC_REG_OFFSET, data);
 }
 
 /**
  * buffer_icap_set_bram - Write data to the storage buffer bram.
  * @base_address: contains the base address of the component.
  * @offset: The word offset at which the data should be written.
  * @data: The value to be written to the bram offset.
  *
  * A bram is used as a configuration memory cache.  One frame of data can
  * be stored in this "storage buffer".
  **/
 static inline void buffer_icap_set_bram(void __iomem *base_address,
 		u32 offset, u32 data)
 {
 	out_be32(base_address + (offset << 2), data);
 }
 
 /**
  * buffer_icap_device_read - Transfer bytes from ICAP to the storage buffer.
  * @drvdata: a pointer to the drvdata.
  * @offset: The storage buffer start address.
  * @count: The number of words (32 bit) to read from the
  *           device (ICAP).
  **/
 static int buffer_icap_device_read(struct hwicap_drvdata *drvdata,
 		u32 offset, u32 count)
 {
 
 	s32 retries = 0;
 	void __iomem *base_address = drvdata->base_address;
 
 	if (buffer_icap_busy(base_address))
 		return -EBUSY;
 
 	if ((offset + count) > XHI_MAX_BUFFER_INTS)
 		return -EINVAL;
 
 	/* setSize count*4 to get bytes. */
 	buffer_icap_set_size(base_address, (count << 2));
 	buffer_icap_set_offset(base_address, offset);
 	buffer_icap_set_rnc(base_address, XHI_READBACK);
 
 	while (buffer_icap_busy(base_address)) {
 		retries++;
 		if (retries > XHI_MAX_RETRIES)
 			return -EBUSY;
 	}
 	return 0;
 
 };
 
 /**
  * buffer_icap_device_write - Transfer bytes from ICAP to the storage buffer.
  * @drvdata: a pointer to the drvdata.
  * @offset: The storage buffer start address.
  * @count: The number of words (32 bit) to read from the
  *           device (ICAP).
  **/
 static int buffer_icap_device_write(struct hwicap_drvdata *drvdata,
 		u32 offset, u32 count)
 {
 
 	s32 retries = 0;
 	void __iomem *base_address = drvdata->base_address;
 
 	if (buffer_icap_busy(base_address))
 		return -EBUSY;
 
 	if ((offset + count) > XHI_MAX_BUFFER_INTS)
 		return -EINVAL;
 
 	/* setSize count*4 to get bytes. */
 	buffer_icap_set_size(base_address, count << 2);
 	buffer_icap_set_offset(base_address, offset);
 	buffer_icap_set_rnc(base_address, XHI_CONFIGURE);
 
 	while (buffer_icap_busy(base_address)) {
 		retries++;
 		if (retries > XHI_MAX_RETRIES)
 			return -EBUSY;
 	}
 	return 0;
 
 };
 
 /**
  * buffer_icap_reset - Reset the logic of the icap device.
  * @drvdata: a pointer to the drvdata.
  *
  * Writing to the status register resets the ICAP logic in an internal
  * version of the core.  For the version of the core published in EDK,
  * this is a noop.
  **/
 void buffer_icap_reset(struct hwicap_drvdata *drvdata)
 {
     out_be32(drvdata->base_address + XHI_STATUS_REG_OFFSET, 0xFEFE);
 }
 
 /**
  * buffer_icap_set_configuration - Load a partial bitstream from system memory.
  * @drvdata: a pointer to the drvdata.
  * @data: Kernel address of the partial bitstream.
  * @size: the size of the partial bitstream in 32 bit words.
  **/
 int buffer_icap_set_configuration(struct hwicap_drvdata *drvdata, u32 *data,
 			     u32 size)
 {
 	int status;
 	s32 buffer_count = 0;
-	s32 num_writes = 0;
 	bool dirty = false;
 	u32 i;
 	void __iomem *base_address = drvdata->base_address;
 
 	/* Loop through all the data */
 	for (i = 0, buffer_count = 0; i < size; i++) {
 
 		/* Copy data to bram */
 		buffer_icap_set_bram(base_address, buffer_count, data[i]);
 		dirty = true;
 
 		if (buffer_count < XHI_MAX_BUFFER_INTS - 1) {
 			buffer_count++;
 			continue;
 		}
 
 		/* Write data to ICAP */
 		status = buffer_icap_device_write(
 				drvdata,
 				XHI_BUFFER_START,
 				XHI_MAX_BUFFER_INTS);
 		if (status != 0) {
 			/* abort. */
 			buffer_icap_reset(drvdata);
 			return status;
 		}
 
 		buffer_count = 0;
-		num_writes++;
 		dirty = false;
 	}
 
 	/* Write unwritten data to ICAP */
 	if (dirty) {
 		/* Write data to ICAP */
 		status = buffer_icap_device_write(drvdata, XHI_BUFFER_START,
 					     buffer_count);
 		if (status != 0) {
 			/* abort. */
 			buffer_icap_reset(drvdata);
 		}
 		return status;
 	}
 
 	return 0;
 };
 
 /**
  * buffer_icap_get_configuration - Read configuration data from the device.
  * @drvdata: a pointer to the drvdata.
  * @data: Address of the data representing the partial bitstream
  * @size: the size of the partial bitstream in 32 bit words.
  **/
 int buffer_icap_get_configuration(struct hwicap_drvdata *drvdata, u32 *data,
 			     u32 size)
 {
 	int status;
 	s32 buffer_count = 0;
-	s32 read_count = 0;
 	u32 i;
 	void __iomem *base_address = drvdata->base_address;
 
 	/* Loop through all the data */
 	for (i = 0, buffer_count = XHI_MAX_BUFFER_INTS; i < size; i++) {
 		if (buffer_count == XHI_MAX_BUFFER_INTS) {
 			u32 words_remaining = size - i;
 			u32 words_to_read =
 				words_remaining <
 				XHI_MAX_BUFFER_INTS ? words_remaining :
 				XHI_MAX_BUFFER_INTS;
 
 			/* Read data from ICAP */
 			status = buffer_icap_device_read(
 					drvdata,
 					XHI_BUFFER_START,
 					words_to_read);
 			if (status != 0) {
 				/* abort. */
 				buffer_icap_reset(drvdata);
 				return status;
 			}
 
 			buffer_count = 0;
-			read_count++;
 		}
 
 		/* Copy data from bram */
 		data[i] = buffer_icap_get_bram(base_address, buffer_count);
 		buffer_count++;
 	}
 
 	return 0;
 };
diff --git a/drivers/extcon/Kconfig b/drivers/extcon/Kconfig
index 04788d92ea52..96bbae579c0b 100644
--- a/drivers/extcon/Kconfig
+++ b/drivers/extcon/Kconfig
@@ -1,135 +1,145 @@
 menuconfig EXTCON
 	tristate "External Connector Class (extcon) support"
 	help
 	  Say Y here to enable external connector class (extcon) support.
 	  This allows monitoring external connectors by userspace
 	  via sysfs and uevent and supports external connectors with
 	  multiple states; i.e., an extcon that may have multiple
 	  cables attached. For example, an external connector of a device
 	  may be used to connect an HDMI cable and a AC adaptor, and to
 	  host USB ports. Many of 30-pin connectors including PDMI are
 	  also good examples.
 
 if EXTCON
 
 comment "Extcon Device Drivers"
 
 config EXTCON_ADC_JACK
 	tristate "ADC Jack extcon support"
 	depends on IIO
 	help
 	  Say Y here to enable extcon device driver based on ADC values.
 
 config EXTCON_ARIZONA
 	tristate "Wolfson Arizona EXTCON support"
 	depends on MFD_ARIZONA && INPUT && SND_SOC
 	help
 	  Say Y here to enable support for external accessory detection
 	  with Wolfson Arizona devices. These are audio CODECs with
 	  advanced audio accessory detection support.
 
 config EXTCON_AXP288
 	tristate "X-Power AXP288 EXTCON support"
 	depends on MFD_AXP20X && USB_PHY
 	help
 	  Say Y here to enable support for USB peripheral detection
 	  and USB MUX switching by X-Power AXP288 PMIC.
 
 config EXTCON_GPIO
 	tristate "GPIO extcon support"
 	depends on GPIOLIB || COMPILE_TEST
 	help
 	  Say Y here to enable GPIO based extcon support. Note that GPIO
 	  extcon supports single state per extcon instance.
 
+config EXTCON_INTEL_INT3496
+	tristate "Intel INT3496 ACPI device extcon driver"
+	depends on GPIOLIB && ACPI
+	help
+	  Say Y here to enable extcon support for USB OTG ports controlled by
+	  an Intel INT3496 ACPI device.
+
+	  This ACPI device is typically found on Intel Baytrail or Cherrytrail
+	  based tablets, or other Baytrail / Cherrytrail devices.
+
 config EXTCON_MAX14577
 	tristate "Maxim MAX14577/77836 EXTCON Support"
 	depends on MFD_MAX14577
 	select IRQ_DOMAIN
 	select REGMAP_I2C
 	help
 	  If you say yes here you get support for the MUIC device of
 	  Maxim MAX14577/77836. The MAX14577/77836 MUIC is a USB port accessory
 	  detector and switch.
 
 config EXTCON_MAX3355
 	tristate "Maxim MAX3355 USB OTG EXTCON Support"
 	depends on GPIOLIB || COMPILE_TEST
 	help
 	  If you say yes here you get support for the USB OTG role detection by
 	  MAX3355. The MAX3355 chip integrates a charge pump and comparators to
 	  enable a system with an integrated USB OTG dual-role transceiver to
 	  function as an USB OTG dual-role device.
 
 config EXTCON_MAX77693
 	tristate "Maxim MAX77693 EXTCON Support"
 	depends on MFD_MAX77693 && INPUT
 	select IRQ_DOMAIN
 	select REGMAP_I2C
 	help
 	  If you say yes here you get support for the MUIC device of
 	  Maxim MAX77693 PMIC. The MAX77693 MUIC is a USB port accessory
 	  detector and switch.
 
 config EXTCON_MAX77843
 	tristate "Maxim MAX77843 EXTCON Support"
 	depends on MFD_MAX77843
 	select IRQ_DOMAIN
 	select REGMAP_I2C
 	help
 	  If you say yes here you get support for the MUIC device of
 	  Maxim MAX77843. The MAX77843 MUIC is a USB port accessory
 	  detector add switch.
 
 config EXTCON_MAX8997
 	tristate "Maxim MAX8997 EXTCON Support"
 	depends on MFD_MAX8997 && IRQ_DOMAIN
 	help
 	  If you say yes here you get support for the MUIC device of
 	  Maxim MAX8997 PMIC. The MAX8997 MUIC is a USB port accessory
 	  detector and switch.
 
 config EXTCON_PALMAS
 	tristate "Palmas USB EXTCON support"
 	depends on MFD_PALMAS
 	help
 	  Say Y here to enable support for USB peripheral and USB host
 	  detection by palmas usb.
 
 config EXTCON_QCOM_SPMI_MISC
 	tristate "Qualcomm USB extcon support"
 	help
 	  Say Y here to enable SPMI PMIC based USB cable detection
 	  support on Qualcomm PMICs such as PM8941.
 
 config EXTCON_RT8973A
 	tristate "Richtek RT8973A EXTCON support"
 	depends on I2C
 	select IRQ_DOMAIN
 	select REGMAP_I2C
 	select REGMAP_IRQ
 	help
 	  If you say yes here you get support for the MUIC device of
 	  Richtek RT8973A. The RT8973A is a USB port accessory detector
 	  and switch that is optimized to protect low voltage system
 	  from abnormal high input voltage (up to 28V).
 
 config EXTCON_SM5502
 	tristate "Silicon Mitus SM5502 EXTCON support"
 	depends on I2C
 	select IRQ_DOMAIN
 	select REGMAP_I2C
 	select REGMAP_IRQ
 	help
 	  If you say yes here you get support for the MUIC device of
 	  Silicon Mitus SM5502. The SM5502 is a USB port accessory
 	  detector and switch.
 
 config EXTCON_USB_GPIO
 	tristate "USB GPIO extcon support"
 	depends on GPIOLIB || COMPILE_TEST
 	help
 	  Say Y here to enable GPIO based USB cable detection extcon support.
 	  Used typically if GPIO is used for USB ID pin detection.
 
 endif
diff --git a/drivers/extcon/Makefile b/drivers/extcon/Makefile
index 31a0a999c4fb..237ac3f953c2 100644
--- a/drivers/extcon/Makefile
+++ b/drivers/extcon/Makefile
@@ -1,20 +1,21 @@
 
 # Makefile for external connector class (extcon) devices
 #
 
 obj-$(CONFIG_EXTCON)		+= extcon-core.o
 extcon-core-objs		+= extcon.o devres.o
 obj-$(CONFIG_EXTCON_ADC_JACK)	+= extcon-adc-jack.o
 obj-$(CONFIG_EXTCON_ARIZONA)	+= extcon-arizona.o
 obj-$(CONFIG_EXTCON_AXP288)	+= extcon-axp288.o
 obj-$(CONFIG_EXTCON_GPIO)	+= extcon-gpio.o
+obj-$(CONFIG_EXTCON_INTEL_INT3496) += extcon-intel-int3496.o
 obj-$(CONFIG_EXTCON_MAX14577)	+= extcon-max14577.o
 obj-$(CONFIG_EXTCON_MAX3355)	+= extcon-max3355.o
 obj-$(CONFIG_EXTCON_MAX77693)	+= extcon-max77693.o
 obj-$(CONFIG_EXTCON_MAX77843)	+= extcon-max77843.o
 obj-$(CONFIG_EXTCON_MAX8997)	+= extcon-max8997.o
 obj-$(CONFIG_EXTCON_PALMAS)	+= extcon-palmas.o
 obj-$(CONFIG_EXTCON_QCOM_SPMI_MISC) += extcon-qcom-spmi-misc.o
 obj-$(CONFIG_EXTCON_RT8973A)	+= extcon-rt8973a.o
 obj-$(CONFIG_EXTCON_SM5502)	+= extcon-sm5502.o
 obj-$(CONFIG_EXTCON_USB_GPIO)	+= extcon-usb-gpio.o
diff --git a/drivers/extcon/devres.c b/drivers/extcon/devres.c
index e686acd1c459..b40eb1805927 100644
--- a/drivers/extcon/devres.c
+++ b/drivers/extcon/devres.c
@@ -1,216 +1,216 @@
 /*
  *  drivers/extcon/devres.c - EXTCON device's resource management
  *
  * Copyright (C) 2016 Samsung Electronics
  * Author: Chanwoo Choi <cw00.choi@samsung.com>
  *
  * This software is licensed under the terms of the GNU General Public
  * License version 2, as published by the Free Software Foundation, and
  * may be copied, distributed, and modified under those terms.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
  */
 
-#include <linux/extcon.h>
+#include "extcon.h"
 
 static int devm_extcon_dev_match(struct device *dev, void *res, void *data)
 {
 	struct extcon_dev **r = res;
 
 	if (WARN_ON(!r || !*r))
 		return 0;
 
 	return *r == data;
 }
 
 static void devm_extcon_dev_release(struct device *dev, void *res)
 {
 	extcon_dev_free(*(struct extcon_dev **)res);
 }
 
 
 static void devm_extcon_dev_unreg(struct device *dev, void *res)
 {
 	extcon_dev_unregister(*(struct extcon_dev **)res);
 }
 
 struct extcon_dev_notifier_devres {
 	struct extcon_dev *edev;
 	unsigned int id;
 	struct notifier_block *nb;
 };
 
 static void devm_extcon_dev_notifier_unreg(struct device *dev, void *res)
 {
 	struct extcon_dev_notifier_devres *this = res;
 
 	extcon_unregister_notifier(this->edev, this->id, this->nb);
 }
 
 /**
  * devm_extcon_dev_allocate - Allocate managed extcon device
  * @dev:		device owning the extcon device being created
  * @supported_cable:	Array of supported extcon ending with EXTCON_NONE.
  *			If supported_cable is NULL, cable name related APIs
  *			are disabled.
  *
  * This function manages automatically the memory of extcon device using device
  * resource management and simplify the control of freeing the memory of extcon
  * device.
  *
  * Returns the pointer memory of allocated extcon_dev if success
  * or ERR_PTR(err) if fail
  */
 struct extcon_dev *devm_extcon_dev_allocate(struct device *dev,
 					const unsigned int *supported_cable)
 {
 	struct extcon_dev **ptr, *edev;
 
 	ptr = devres_alloc(devm_extcon_dev_release, sizeof(*ptr), GFP_KERNEL);
 	if (!ptr)
 		return ERR_PTR(-ENOMEM);
 
 	edev = extcon_dev_allocate(supported_cable);
 	if (IS_ERR(edev)) {
 		devres_free(ptr);
 		return edev;
 	}
 
 	edev->dev.parent = dev;
 
 	*ptr = edev;
 	devres_add(dev, ptr);
 
 	return edev;
 }
 EXPORT_SYMBOL_GPL(devm_extcon_dev_allocate);
 
 /**
  * devm_extcon_dev_free() - Resource-managed extcon_dev_unregister()
  * @dev:	device the extcon belongs to
  * @edev:	the extcon device to unregister
  *
  * Free the memory that is allocated with devm_extcon_dev_allocate()
  * function.
  */
 void devm_extcon_dev_free(struct device *dev, struct extcon_dev *edev)
 {
 	WARN_ON(devres_release(dev, devm_extcon_dev_release,
 			       devm_extcon_dev_match, edev));
 }
 EXPORT_SYMBOL_GPL(devm_extcon_dev_free);
 
 /**
  * devm_extcon_dev_register() - Resource-managed extcon_dev_register()
  * @dev:	device to allocate extcon device
  * @edev:	the new extcon device to register
  *
  * Managed extcon_dev_register() function. If extcon device is attached with
  * this function, that extcon device is automatically unregistered on driver
  * detach. Internally this function calls extcon_dev_register() function.
  * To get more information, refer that function.
  *
  * If extcon device is registered with this function and the device needs to be
  * unregistered separately, devm_extcon_dev_unregister() should be used.
  *
  * Returns 0 if success or negaive error number if failure.
  */
 int devm_extcon_dev_register(struct device *dev, struct extcon_dev *edev)
 {
 	struct extcon_dev **ptr;
 	int ret;
 
 	ptr = devres_alloc(devm_extcon_dev_unreg, sizeof(*ptr), GFP_KERNEL);
 	if (!ptr)
 		return -ENOMEM;
 
 	ret = extcon_dev_register(edev);
 	if (ret) {
 		devres_free(ptr);
 		return ret;
 	}
 
 	*ptr = edev;
 	devres_add(dev, ptr);
 
 	return 0;
 }
 EXPORT_SYMBOL_GPL(devm_extcon_dev_register);
 
 /**
  * devm_extcon_dev_unregister() - Resource-managed extcon_dev_unregister()
  * @dev:	device the extcon belongs to
  * @edev:	the extcon device to unregister
  *
  * Unregister extcon device that is registered with devm_extcon_dev_register()
  * function.
  */
 void devm_extcon_dev_unregister(struct device *dev, struct extcon_dev *edev)
 {
 	WARN_ON(devres_release(dev, devm_extcon_dev_unreg,
 			       devm_extcon_dev_match, edev));
 }
 EXPORT_SYMBOL_GPL(devm_extcon_dev_unregister);
 
 /**
  * devm_extcon_register_notifier() - Resource-managed extcon_register_notifier()
  * @dev:	device to allocate extcon device
  * @edev:	the extcon device that has the external connecotr.
  * @id:		the unique id of each external connector in extcon enumeration.
  * @nb:		a notifier block to be registered.
  *
  * This function manages automatically the notifier of extcon device using
  * device resource management and simplify the control of unregistering
  * the notifier of extcon device.
  *
  * Note that the second parameter given to the callback of nb (val) is
  * "old_state", not the current state. The current state can be retrieved
  * by looking at the third pameter (edev pointer)'s state value.
  *
  * Returns 0 if success or negaive error number if failure.
  */
 int devm_extcon_register_notifier(struct device *dev, struct extcon_dev *edev,
 				unsigned int id, struct notifier_block *nb)
 {
 	struct extcon_dev_notifier_devres *ptr;
 	int ret;
 
 	ptr = devres_alloc(devm_extcon_dev_notifier_unreg, sizeof(*ptr),
 				GFP_KERNEL);
 	if (!ptr)
 		return -ENOMEM;
 
 	ret = extcon_register_notifier(edev, id, nb);
 	if (ret) {
 		devres_free(ptr);
 		return ret;
 	}
 
 	ptr->edev = edev;
 	ptr->id = id;
 	ptr->nb = nb;
 	devres_add(dev, ptr);
 
 	return 0;
 }
 EXPORT_SYMBOL(devm_extcon_register_notifier);
 
 /**
  * devm_extcon_unregister_notifier()
 			- Resource-managed extcon_unregister_notifier()
  * @dev:	device to allocate extcon device
  * @edev:	the extcon device that has the external connecotr.
  * @id:		the unique id of each external connector in extcon enumeration.
  * @nb:		a notifier block to be registered.
  */
 void devm_extcon_unregister_notifier(struct device *dev,
 				struct extcon_dev *edev, unsigned int id,
 				struct notifier_block *nb)
 {
 	WARN_ON(devres_release(dev, devm_extcon_dev_notifier_unreg,
 			       devm_extcon_dev_match, edev));
 }
 EXPORT_SYMBOL(devm_extcon_unregister_notifier);
diff --git a/drivers/extcon/extcon-adc-jack.c b/drivers/extcon/extcon-adc-jack.c
index bc538708c753..6f6537ab0a79 100644
--- a/drivers/extcon/extcon-adc-jack.c
+++ b/drivers/extcon/extcon-adc-jack.c
@@ -1,217 +1,217 @@
 /*
  * drivers/extcon/extcon-adc-jack.c
  *
  * Analog Jack extcon driver with ADC-based detection capability.
  *
  * Copyright (C) 2016 Samsung Electronics
  * Chanwoo Choi <cw00.choi@samsung.com>
  *
  * Copyright (C) 2012 Samsung Electronics
  * MyungJoo Ham <myungjoo.ham@samsung.com>
  *
  * Modified for calling to IIO to get adc by <anish.singh@samsung.com>
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License version 2 as
  * published by the Free Software Foundation.
  *
  */
 
 #include <linux/module.h>
 #include <linux/slab.h>
 #include <linux/device.h>
 #include <linux/platform_device.h>
 #include <linux/err.h>
 #include <linux/interrupt.h>
 #include <linux/workqueue.h>
 #include <linux/iio/consumer.h>
 #include <linux/extcon/extcon-adc-jack.h>
 #include <linux/extcon.h>
 
 /**
  * struct adc_jack_data - internal data for adc_jack device driver
  * @edev:		extcon device.
  * @cable_names:	list of supported cables.
  * @adc_conditions:	list of adc value conditions.
  * @num_conditions:	size of adc_conditions.
  * @irq:		irq number of attach/detach event (0 if not exist).
  * @handling_delay:	interrupt handler will schedule extcon event
  *			handling at handling_delay jiffies.
  * @handler:		extcon event handler called by interrupt handler.
  * @chan:		iio channel being queried.
  */
 struct adc_jack_data {
 	struct device *dev;
 	struct extcon_dev *edev;
 
 	const unsigned int **cable_names;
 	struct adc_jack_cond *adc_conditions;
 	int num_conditions;
 
 	int irq;
 	unsigned long handling_delay; /* in jiffies */
 	struct delayed_work handler;
 
 	struct iio_channel *chan;
 	bool wakeup_source;
 };
 
 static void adc_jack_handler(struct work_struct *work)
 {
 	struct adc_jack_data *data = container_of(to_delayed_work(work),
 			struct adc_jack_data,
 			handler);
 	struct adc_jack_cond *def;
 	int ret, adc_val;
 	int i;
 
 	ret = iio_read_channel_raw(data->chan, &adc_val);
 	if (ret < 0) {
-		dev_err(&data->edev->dev, "read channel() error: %d\n", ret);
+		dev_err(data->dev, "read channel() error: %d\n", ret);
 		return;
 	}
 
 	/* Get state from adc value with adc_conditions */
 	for (i = 0; i < data->num_conditions; i++) {
 		def = &data->adc_conditions[i];
 		if (def->min_adc <= adc_val && def->max_adc >= adc_val) {
 			extcon_set_state_sync(data->edev, def->id, true);
 			return;
 		}
 	}
 
 	/* Set the detached state if adc value is not included in the range */
 	for (i = 0; i < data->num_conditions; i++) {
 		def = &data->adc_conditions[i];
 		extcon_set_state_sync(data->edev, def->id, false);
 	}
 }
 
 static irqreturn_t adc_jack_irq_thread(int irq, void *_data)
 {
 	struct adc_jack_data *data = _data;
 
 	queue_delayed_work(system_power_efficient_wq,
 			   &data->handler, data->handling_delay);
 	return IRQ_HANDLED;
 }
 
 static int adc_jack_probe(struct platform_device *pdev)
 {
 	struct adc_jack_data *data;
 	struct adc_jack_pdata *pdata = dev_get_platdata(&pdev->dev);
 	int i, err = 0;
 
 	data = devm_kzalloc(&pdev->dev, sizeof(*data), GFP_KERNEL);
 	if (!data)
 		return -ENOMEM;
 
 	if (!pdata->cable_names) {
 		dev_err(&pdev->dev, "error: cable_names not defined.\n");
 		return -EINVAL;
 	}
 
 	data->dev = &pdev->dev;
 	data->edev = devm_extcon_dev_allocate(&pdev->dev, pdata->cable_names);
 	if (IS_ERR(data->edev)) {
 		dev_err(&pdev->dev, "failed to allocate extcon device\n");
 		return -ENOMEM;
 	}
 
 	if (!pdata->adc_conditions) {
 		dev_err(&pdev->dev, "error: adc_conditions not defined.\n");
 		return -EINVAL;
 	}
 	data->adc_conditions = pdata->adc_conditions;
 
 	/* Check the length of array and set num_conditions */
 	for (i = 0; data->adc_conditions[i].id != EXTCON_NONE; i++);
 	data->num_conditions = i;
 
 	data->chan = iio_channel_get(&pdev->dev, pdata->consumer_channel);
 	if (IS_ERR(data->chan))
 		return PTR_ERR(data->chan);
 
 	data->handling_delay = msecs_to_jiffies(pdata->handling_delay_ms);
 	data->wakeup_source = pdata->wakeup_source;
 
 	INIT_DEFERRABLE_WORK(&data->handler, adc_jack_handler);
 
 	platform_set_drvdata(pdev, data);
 
 	err = devm_extcon_dev_register(&pdev->dev, data->edev);
 	if (err)
 		return err;
 
 	data->irq = platform_get_irq(pdev, 0);
 	if (!data->irq) {
 		dev_err(&pdev->dev, "platform_get_irq failed\n");
 		return -ENODEV;
 	}
 
 	err = request_any_context_irq(data->irq, adc_jack_irq_thread,
 			pdata->irq_flags, pdata->name, data);
 
 	if (err < 0) {
 		dev_err(&pdev->dev, "error: irq %d\n", data->irq);
 		return err;
 	}
 
 	if (data->wakeup_source)
 		device_init_wakeup(&pdev->dev, 1);
 
 	adc_jack_handler(&data->handler.work);
 	return 0;
 }
 
 static int adc_jack_remove(struct platform_device *pdev)
 {
 	struct adc_jack_data *data = platform_get_drvdata(pdev);
 
 	free_irq(data->irq, data);
 	cancel_work_sync(&data->handler.work);
 	iio_channel_release(data->chan);
 
 	return 0;
 }
 
 #ifdef CONFIG_PM_SLEEP
 static int adc_jack_suspend(struct device *dev)
 {
 	struct adc_jack_data *data = dev_get_drvdata(dev);
 
 	cancel_delayed_work_sync(&data->handler);
 	if (device_may_wakeup(data->dev))
 		enable_irq_wake(data->irq);
 
 	return 0;
 }
 
 static int adc_jack_resume(struct device *dev)
 {
 	struct adc_jack_data *data = dev_get_drvdata(dev);
 
 	if (device_may_wakeup(data->dev))
 		disable_irq_wake(data->irq);
 
 	return 0;
 }
 #endif /* CONFIG_PM_SLEEP */
 
 static SIMPLE_DEV_PM_OPS(adc_jack_pm_ops,
 		adc_jack_suspend, adc_jack_resume);
 
 static struct platform_driver adc_jack_driver = {
 	.probe          = adc_jack_probe,
 	.remove         = adc_jack_remove,
 	.driver         = {
 		.name   = "adc-jack",
 		.pm = &adc_jack_pm_ops,
 	},
 };
 
 module_platform_driver(adc_jack_driver);
 
 MODULE_AUTHOR("MyungJoo Ham <myungjoo.ham@samsung.com>");
 MODULE_DESCRIPTION("ADC Jack extcon driver");
 MODULE_LICENSE("GPL v2");
diff --git a/drivers/extcon/extcon-arizona.c b/drivers/extcon/extcon-arizona.c
index d836d4ce5ee4..ed78b7c26627 100644
--- a/drivers/extcon/extcon-arizona.c
+++ b/drivers/extcon/extcon-arizona.c
@@ -1,1733 +1,1729 @@
 /*
  * extcon-arizona.c - Extcon driver Wolfson Arizona devices
  *
  *  Copyright (C) 2012-2014 Wolfson Microelectronics plc
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
  * the Free Software Foundation; either version 2 of the License, or
  * (at your option) any later version.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
  */
 
 #include <linux/kernel.h>
 #include <linux/module.h>
 #include <linux/i2c.h>
 #include <linux/slab.h>
 #include <linux/interrupt.h>
 #include <linux/err.h>
 #include <linux/gpio/consumer.h>
 #include <linux/gpio.h>
 #include <linux/input.h>
 #include <linux/platform_device.h>
 #include <linux/pm_runtime.h>
 #include <linux/property.h>
 #include <linux/regulator/consumer.h>
 #include <linux/extcon.h>
 
 #include <sound/soc.h>
 
 #include <linux/mfd/arizona/core.h>
 #include <linux/mfd/arizona/pdata.h>
 #include <linux/mfd/arizona/registers.h>
 #include <dt-bindings/mfd/arizona.h>
 
 #define ARIZONA_MAX_MICD_RANGE 8
 
 #define ARIZONA_MICD_CLAMP_MODE_JDL      0x4
 #define ARIZONA_MICD_CLAMP_MODE_JDH      0x5
 #define ARIZONA_MICD_CLAMP_MODE_JDL_GP5H 0x9
 #define ARIZONA_MICD_CLAMP_MODE_JDH_GP5H 0xb
 
 #define ARIZONA_TST_CAP_DEFAULT 0x3
 #define ARIZONA_TST_CAP_CLAMP   0x1
 
 #define ARIZONA_HPDET_MAX 10000
 
 #define HPDET_DEBOUNCE 500
 #define DEFAULT_MICD_TIMEOUT 2000
 
 #define QUICK_HEADPHONE_MAX_OHM 3
 #define MICROPHONE_MIN_OHM      1257
 #define MICROPHONE_MAX_OHM      30000
 
 #define MICD_DBTIME_TWO_READINGS 2
 #define MICD_DBTIME_FOUR_READINGS 4
 
 #define MICD_LVL_1_TO_7 (ARIZONA_MICD_LVL_1 | ARIZONA_MICD_LVL_2 | \
 			 ARIZONA_MICD_LVL_3 | ARIZONA_MICD_LVL_4 | \
 			 ARIZONA_MICD_LVL_5 | ARIZONA_MICD_LVL_6 | \
 			 ARIZONA_MICD_LVL_7)
 
 #define MICD_LVL_0_TO_7 (ARIZONA_MICD_LVL_0 | MICD_LVL_1_TO_7)
 
 #define MICD_LVL_0_TO_8 (MICD_LVL_0_TO_7 | ARIZONA_MICD_LVL_8)
 
 struct arizona_extcon_info {
 	struct device *dev;
 	struct arizona *arizona;
 	struct mutex lock;
 	struct regulator *micvdd;
 	struct input_dev *input;
 
 	u16 last_jackdet;
 
 	int micd_mode;
 	const struct arizona_micd_config *micd_modes;
 	int micd_num_modes;
 
 	const struct arizona_micd_range *micd_ranges;
 	int num_micd_ranges;
 
 	int micd_timeout;
 
 	bool micd_reva;
 	bool micd_clamp;
 
 	struct delayed_work hpdet_work;
 	struct delayed_work micd_detect_work;
 	struct delayed_work micd_timeout_work;
 
 	bool hpdet_active;
 	bool hpdet_done;
 	bool hpdet_retried;
 
 	int num_hpdet_res;
 	unsigned int hpdet_res[3];
 
 	bool mic;
 	bool detecting;
 	int jack_flips;
 
 	int hpdet_ip_version;
 
 	struct extcon_dev *edev;
 
 	struct gpio_desc *micd_pol_gpio;
 };
 
 static const struct arizona_micd_config micd_default_modes[] = {
 	{ ARIZONA_ACCDET_SRC, 1, 0 },
 	{ 0,                  2, 1 },
 };
 
 static const struct arizona_micd_range micd_default_ranges[] = {
 	{ .max =  11, .key = BTN_0 },
 	{ .max =  28, .key = BTN_1 },
 	{ .max =  54, .key = BTN_2 },
 	{ .max = 100, .key = BTN_3 },
 	{ .max = 186, .key = BTN_4 },
 	{ .max = 430, .key = BTN_5 },
 };
 
 /* The number of levels in arizona_micd_levels valid for button thresholds */
 #define ARIZONA_NUM_MICD_BUTTON_LEVELS 64
 
 static const int arizona_micd_levels[] = {
 	3, 6, 8, 11, 13, 16, 18, 21, 23, 26, 28, 31, 34, 36, 39, 41, 44, 46,
 	49, 52, 54, 57, 60, 62, 65, 67, 70, 73, 75, 78, 81, 83, 89, 94, 100,
 	105, 111, 116, 122, 127, 139, 150, 161, 173, 186, 196, 209, 220, 245,
 	270, 295, 321, 348, 375, 402, 430, 489, 550, 614, 681, 752, 903, 1071,
 	1257, 30000,
 };
 
 static const unsigned int arizona_cable[] = {
 	EXTCON_MECHANICAL,
 	EXTCON_JACK_MICROPHONE,
 	EXTCON_JACK_HEADPHONE,
 	EXTCON_JACK_LINE_OUT,
 	EXTCON_NONE,
 };
 
 static void arizona_start_hpdet_acc_id(struct arizona_extcon_info *info);
 
 static void arizona_extcon_hp_clamp(struct arizona_extcon_info *info,
 				    bool clamp)
 {
 	struct arizona *arizona = info->arizona;
 	unsigned int mask = 0, val = 0;
 	unsigned int cap_sel = 0;
 	int ret;
 
 	switch (arizona->type) {
 	case WM8998:
 	case WM1814:
 		mask = 0;
 		break;
 	case WM5110:
 	case WM8280:
 		mask = ARIZONA_HP1L_SHRTO | ARIZONA_HP1L_FLWR |
 		       ARIZONA_HP1L_SHRTI;
 		if (clamp) {
 			val = ARIZONA_HP1L_SHRTO;
 			cap_sel = ARIZONA_TST_CAP_CLAMP;
 		} else {
 			val = ARIZONA_HP1L_FLWR | ARIZONA_HP1L_SHRTI;
 			cap_sel = ARIZONA_TST_CAP_DEFAULT;
 		}
 
 		ret = regmap_update_bits(arizona->regmap,
 					 ARIZONA_HP_TEST_CTRL_1,
 					 ARIZONA_HP1_TST_CAP_SEL_MASK,
 					 cap_sel);
 		if (ret != 0)
 			dev_warn(arizona->dev,
 				 "Failed to set TST_CAP_SEL: %d\n", ret);
 		break;
 	default:
 		mask = ARIZONA_RMV_SHRT_HP1L;
 		if (clamp)
 			val = ARIZONA_RMV_SHRT_HP1L;
 		break;
 	}
 
 	snd_soc_dapm_mutex_lock(arizona->dapm);
 
 	arizona->hpdet_clamp = clamp;
 
 	/* Keep the HP output stages disabled while doing the clamp */
 	if (clamp) {
 		ret = regmap_update_bits(arizona->regmap,
 					 ARIZONA_OUTPUT_ENABLES_1,
 					 ARIZONA_OUT1L_ENA |
 					 ARIZONA_OUT1R_ENA, 0);
 		if (ret != 0)
 			dev_warn(arizona->dev,
 				"Failed to disable headphone outputs: %d\n",
 				 ret);
 	}
 
 	if (mask) {
 		ret = regmap_update_bits(arizona->regmap, ARIZONA_HP_CTRL_1L,
 					 mask, val);
 		if (ret != 0)
 			dev_warn(arizona->dev, "Failed to do clamp: %d\n",
 				 ret);
 
 		ret = regmap_update_bits(arizona->regmap, ARIZONA_HP_CTRL_1R,
 					 mask, val);
 		if (ret != 0)
 			dev_warn(arizona->dev, "Failed to do clamp: %d\n",
 				 ret);
 	}
 
 	/* Restore the desired state while not doing the clamp */
 	if (!clamp) {
 		ret = regmap_update_bits(arizona->regmap,
 					 ARIZONA_OUTPUT_ENABLES_1,
 					 ARIZONA_OUT1L_ENA |
 					 ARIZONA_OUT1R_ENA, arizona->hp_ena);
 		if (ret != 0)
 			dev_warn(arizona->dev,
 				 "Failed to restore headphone outputs: %d\n",
 				 ret);
 	}
 
 	snd_soc_dapm_mutex_unlock(arizona->dapm);
 }
 
 static void arizona_extcon_set_mode(struct arizona_extcon_info *info, int mode)
 {
 	struct arizona *arizona = info->arizona;
 
 	mode %= info->micd_num_modes;
 
-	if (arizona->pdata.micd_pol_gpio > 0)
-		gpio_set_value_cansleep(arizona->pdata.micd_pol_gpio,
-					info->micd_modes[mode].gpio);
-	else
-		gpiod_set_value_cansleep(info->micd_pol_gpio,
-					 info->micd_modes[mode].gpio);
+	gpiod_set_value_cansleep(info->micd_pol_gpio,
+				 info->micd_modes[mode].gpio);
 
 	regmap_update_bits(arizona->regmap, ARIZONA_MIC_DETECT_1,
 			   ARIZONA_MICD_BIAS_SRC_MASK,
 			   info->micd_modes[mode].bias <<
 			   ARIZONA_MICD_BIAS_SRC_SHIFT);
 	regmap_update_bits(arizona->regmap, ARIZONA_ACCESSORY_DETECT_MODE_1,
 			   ARIZONA_ACCDET_SRC, info->micd_modes[mode].src);
 
 	info->micd_mode = mode;
 
 	dev_dbg(arizona->dev, "Set jack polarity to %d\n", mode);
 }
 
 static const char *arizona_extcon_get_micbias(struct arizona_extcon_info *info)
 {
 	switch (info->micd_modes[0].bias) {
 	case 1:
 		return "MICBIAS1";
 	case 2:
 		return "MICBIAS2";
 	case 3:
 		return "MICBIAS3";
 	default:
 		return "MICVDD";
 	}
 }
 
 static void arizona_extcon_pulse_micbias(struct arizona_extcon_info *info)
 {
 	struct arizona *arizona = info->arizona;
 	const char *widget = arizona_extcon_get_micbias(info);
 	struct snd_soc_dapm_context *dapm = arizona->dapm;
 	struct snd_soc_component *component = snd_soc_dapm_to_component(dapm);
 	int ret;
 
 	ret = snd_soc_component_force_enable_pin(component, widget);
 	if (ret != 0)
 		dev_warn(arizona->dev, "Failed to enable %s: %d\n",
 			 widget, ret);
 
 	snd_soc_dapm_sync(dapm);
 
 	if (!arizona->pdata.micd_force_micbias) {
 		ret = snd_soc_component_disable_pin(component, widget);
 		if (ret != 0)
 			dev_warn(arizona->dev, "Failed to disable %s: %d\n",
 				 widget, ret);
 
 		snd_soc_dapm_sync(dapm);
 	}
 }
 
 static void arizona_start_mic(struct arizona_extcon_info *info)
 {
 	struct arizona *arizona = info->arizona;
 	bool change;
 	int ret;
 	unsigned int mode;
 
 	/* Microphone detection can't use idle mode */
 	pm_runtime_get(info->dev);
 
 	if (info->detecting) {
 		ret = regulator_allow_bypass(info->micvdd, false);
 		if (ret != 0) {
 			dev_err(arizona->dev,
 				"Failed to regulate MICVDD: %d\n",
 				ret);
 		}
 	}
 
 	ret = regulator_enable(info->micvdd);
 	if (ret != 0) {
 		dev_err(arizona->dev, "Failed to enable MICVDD: %d\n",
 			ret);
 	}
 
 	if (info->micd_reva) {
 		regmap_write(arizona->regmap, 0x80, 0x3);
 		regmap_write(arizona->regmap, 0x294, 0);
 		regmap_write(arizona->regmap, 0x80, 0x0);
 	}
 
 	if (info->detecting && arizona->pdata.micd_software_compare)
 		mode = ARIZONA_ACCDET_MODE_ADC;
 	else
 		mode = ARIZONA_ACCDET_MODE_MIC;
 
 	regmap_update_bits(arizona->regmap,
 			   ARIZONA_ACCESSORY_DETECT_MODE_1,
 			   ARIZONA_ACCDET_MODE_MASK, mode);
 
 	arizona_extcon_pulse_micbias(info);
 
 	regmap_update_bits_check(arizona->regmap, ARIZONA_MIC_DETECT_1,
 				 ARIZONA_MICD_ENA, ARIZONA_MICD_ENA,
 				 &change);
 	if (!change) {
 		regulator_disable(info->micvdd);
 		pm_runtime_put_autosuspend(info->dev);
 	}
 }
 
 static void arizona_stop_mic(struct arizona_extcon_info *info)
 {
 	struct arizona *arizona = info->arizona;
 	const char *widget = arizona_extcon_get_micbias(info);
 	struct snd_soc_dapm_context *dapm = arizona->dapm;
 	struct snd_soc_component *component = snd_soc_dapm_to_component(dapm);
 	bool change;
 	int ret;
 
 	regmap_update_bits_check(arizona->regmap, ARIZONA_MIC_DETECT_1,
 				 ARIZONA_MICD_ENA, 0,
 				 &change);
 
 	ret = snd_soc_component_disable_pin(component, widget);
 	if (ret != 0)
 		dev_warn(arizona->dev,
 			 "Failed to disable %s: %d\n",
 			 widget, ret);
 
 	snd_soc_dapm_sync(dapm);
 
 	if (info->micd_reva) {
 		regmap_write(arizona->regmap, 0x80, 0x3);
 		regmap_write(arizona->regmap, 0x294, 2);
 		regmap_write(arizona->regmap, 0x80, 0x0);
 	}
 
 	ret = regulator_allow_bypass(info->micvdd, true);
 	if (ret != 0) {
 		dev_err(arizona->dev, "Failed to bypass MICVDD: %d\n",
 			ret);
 	}
 
 	if (change) {
 		regulator_disable(info->micvdd);
 		pm_runtime_mark_last_busy(info->dev);
 		pm_runtime_put_autosuspend(info->dev);
 	}
 }
 
 static struct {
 	unsigned int threshold;
 	unsigned int factor_a;
 	unsigned int factor_b;
 } arizona_hpdet_b_ranges[] = {
 	{ 100,  5528,   362464 },
 	{ 169, 11084,  6186851 },
 	{ 169, 11065, 65460395 },
 };
 
 #define ARIZONA_HPDET_B_RANGE_MAX 0x3fb
 
 static struct {
 	int min;
 	int max;
 } arizona_hpdet_c_ranges[] = {
 	{ 0,       30 },
 	{ 8,      100 },
 	{ 100,   1000 },
 	{ 1000, 10000 },
 };
 
 static int arizona_hpdet_read(struct arizona_extcon_info *info)
 {
 	struct arizona *arizona = info->arizona;
 	unsigned int val, range;
 	int ret;
 
 	ret = regmap_read(arizona->regmap, ARIZONA_HEADPHONE_DETECT_2, &val);
 	if (ret != 0) {
 		dev_err(arizona->dev, "Failed to read HPDET status: %d\n",
 			ret);
 		return ret;
 	}
 
 	switch (info->hpdet_ip_version) {
 	case 0:
 		if (!(val & ARIZONA_HP_DONE)) {
 			dev_err(arizona->dev, "HPDET did not complete: %x\n",
 				val);
 			return -EAGAIN;
 		}
 
 		val &= ARIZONA_HP_LVL_MASK;
 		break;
 
 	case 1:
 		if (!(val & ARIZONA_HP_DONE_B)) {
 			dev_err(arizona->dev, "HPDET did not complete: %x\n",
 				val);
 			return -EAGAIN;
 		}
 
 		ret = regmap_read(arizona->regmap, ARIZONA_HP_DACVAL, &val);
 		if (ret != 0) {
 			dev_err(arizona->dev, "Failed to read HP value: %d\n",
 				ret);
 			return -EAGAIN;
 		}
 
 		regmap_read(arizona->regmap, ARIZONA_HEADPHONE_DETECT_1,
 			    &range);
 		range = (range & ARIZONA_HP_IMPEDANCE_RANGE_MASK)
 			   >> ARIZONA_HP_IMPEDANCE_RANGE_SHIFT;
 
 		if (range < ARRAY_SIZE(arizona_hpdet_b_ranges) - 1 &&
 		    (val < arizona_hpdet_b_ranges[range].threshold ||
 		     val >= ARIZONA_HPDET_B_RANGE_MAX)) {
 			range++;
 			dev_dbg(arizona->dev, "Moving to HPDET range %d\n",
 				range);
 			regmap_update_bits(arizona->regmap,
 					   ARIZONA_HEADPHONE_DETECT_1,
 					   ARIZONA_HP_IMPEDANCE_RANGE_MASK,
 					   range <<
 					   ARIZONA_HP_IMPEDANCE_RANGE_SHIFT);
 			return -EAGAIN;
 		}
 
 		/* If we go out of range report top of range */
 		if (val < arizona_hpdet_b_ranges[range].threshold ||
 		    val >= ARIZONA_HPDET_B_RANGE_MAX) {
 			dev_dbg(arizona->dev, "Measurement out of range\n");
 			return ARIZONA_HPDET_MAX;
 		}
 
 		dev_dbg(arizona->dev, "HPDET read %d in range %d\n",
 			val, range);
 
 		val = arizona_hpdet_b_ranges[range].factor_b
 			/ ((val * 100) -
 			   arizona_hpdet_b_ranges[range].factor_a);
 		break;
 
 	case 2:
 		if (!(val & ARIZONA_HP_DONE_B)) {
 			dev_err(arizona->dev, "HPDET did not complete: %x\n",
 				val);
 			return -EAGAIN;
 		}
 
 		val &= ARIZONA_HP_LVL_B_MASK;
 		/* Convert to ohms, the value is in 0.5 ohm increments */
 		val /= 2;
 
 		regmap_read(arizona->regmap, ARIZONA_HEADPHONE_DETECT_1,
 			    &range);
 		range = (range & ARIZONA_HP_IMPEDANCE_RANGE_MASK)
 			   >> ARIZONA_HP_IMPEDANCE_RANGE_SHIFT;
 
 		/* Skip up a range, or report? */
 		if (range < ARRAY_SIZE(arizona_hpdet_c_ranges) - 1 &&
 		    (val >= arizona_hpdet_c_ranges[range].max)) {
 			range++;
 			dev_dbg(arizona->dev, "Moving to HPDET range %d-%d\n",
 				arizona_hpdet_c_ranges[range].min,
 				arizona_hpdet_c_ranges[range].max);
 			regmap_update_bits(arizona->regmap,
 					   ARIZONA_HEADPHONE_DETECT_1,
 					   ARIZONA_HP_IMPEDANCE_RANGE_MASK,
 					   range <<
 					   ARIZONA_HP_IMPEDANCE_RANGE_SHIFT);
 			return -EAGAIN;
 		}
 
 		if (range && (val < arizona_hpdet_c_ranges[range].min)) {
 			dev_dbg(arizona->dev, "Reporting range boundary %d\n",
 				arizona_hpdet_c_ranges[range].min);
 			val = arizona_hpdet_c_ranges[range].min;
 		}
 		break;
 
 	default:
 		dev_warn(arizona->dev, "Unknown HPDET IP revision %d\n",
 			 info->hpdet_ip_version);
 		return -EINVAL;
 	}
 
 	dev_dbg(arizona->dev, "HP impedance %d ohms\n", val);
 	return val;
 }
 
 static int arizona_hpdet_do_id(struct arizona_extcon_info *info, int *reading,
 			       bool *mic)
 {
 	struct arizona *arizona = info->arizona;
 	int id_gpio = arizona->pdata.hpdet_id_gpio;
 
 	/*
 	 * If we're using HPDET for accessory identification we need
 	 * to take multiple measurements, step through them in sequence.
 	 */
 	if (arizona->pdata.hpdet_acc_id) {
 		info->hpdet_res[info->num_hpdet_res++] = *reading;
 
 		/* Only check the mic directly if we didn't already ID it */
 		if (id_gpio && info->num_hpdet_res == 1) {
 			dev_dbg(arizona->dev, "Measuring mic\n");
 
 			regmap_update_bits(arizona->regmap,
 					   ARIZONA_ACCESSORY_DETECT_MODE_1,
 					   ARIZONA_ACCDET_MODE_MASK |
 					   ARIZONA_ACCDET_SRC,
 					   ARIZONA_ACCDET_MODE_HPR |
 					   info->micd_modes[0].src);
 
 			gpio_set_value_cansleep(id_gpio, 1);
 
 			regmap_update_bits(arizona->regmap,
 					   ARIZONA_HEADPHONE_DETECT_1,
 					   ARIZONA_HP_POLL, ARIZONA_HP_POLL);
 			return -EAGAIN;
 		}
 
 		/* OK, got both.  Now, compare... */
 		dev_dbg(arizona->dev, "HPDET measured %d %d\n",
 			info->hpdet_res[0], info->hpdet_res[1]);
 
 		/* Take the headphone impedance for the main report */
 		*reading = info->hpdet_res[0];
 
 		/* Sometimes we get false readings due to slow insert */
 		if (*reading >= ARIZONA_HPDET_MAX && !info->hpdet_retried) {
 			dev_dbg(arizona->dev, "Retrying high impedance\n");
 			info->num_hpdet_res = 0;
 			info->hpdet_retried = true;
 			arizona_start_hpdet_acc_id(info);
 			pm_runtime_put(info->dev);
 			return -EAGAIN;
 		}
 
 		/*
 		 * If we measure the mic as high impedance
 		 */
 		if (!id_gpio || info->hpdet_res[1] > 50) {
 			dev_dbg(arizona->dev, "Detected mic\n");
 			*mic = true;
 			info->detecting = true;
 		} else {
 			dev_dbg(arizona->dev, "Detected headphone\n");
 		}
 
 		/* Make sure everything is reset back to the real polarity */
 		regmap_update_bits(arizona->regmap,
 				   ARIZONA_ACCESSORY_DETECT_MODE_1,
 				   ARIZONA_ACCDET_SRC,
 				   info->micd_modes[0].src);
 	}
 
 	return 0;
 }
 
 static irqreturn_t arizona_hpdet_irq(int irq, void *data)
 {
 	struct arizona_extcon_info *info = data;
 	struct arizona *arizona = info->arizona;
 	int id_gpio = arizona->pdata.hpdet_id_gpio;
 	unsigned int report = EXTCON_JACK_HEADPHONE;
 	int ret, reading;
 	bool mic = false;
 
 	mutex_lock(&info->lock);
 
 	/* If we got a spurious IRQ for some reason then ignore it */
 	if (!info->hpdet_active) {
 		dev_warn(arizona->dev, "Spurious HPDET IRQ\n");
 		mutex_unlock(&info->lock);
 		return IRQ_NONE;
 	}
 
 	/* If the cable was removed while measuring ignore the result */
 	ret = extcon_get_state(info->edev, EXTCON_MECHANICAL);
 	if (ret < 0) {
 		dev_err(arizona->dev, "Failed to check cable state: %d\n",
 			ret);
 		goto out;
 	} else if (!ret) {
 		dev_dbg(arizona->dev, "Ignoring HPDET for removed cable\n");
 		goto done;
 	}
 
 	ret = arizona_hpdet_read(info);
 	if (ret == -EAGAIN)
 		goto out;
 	else if (ret < 0)
 		goto done;
 	reading = ret;
 
 	/* Reset back to starting range */
 	regmap_update_bits(arizona->regmap,
 			   ARIZONA_HEADPHONE_DETECT_1,
 			   ARIZONA_HP_IMPEDANCE_RANGE_MASK | ARIZONA_HP_POLL,
 			   0);
 
 	ret = arizona_hpdet_do_id(info, &reading, &mic);
 	if (ret == -EAGAIN)
 		goto out;
 	else if (ret < 0)
 		goto done;
 
 	/* Report high impedence cables as line outputs */
 	if (reading >= 5000)
 		report = EXTCON_JACK_LINE_OUT;
 	else
 		report = EXTCON_JACK_HEADPHONE;
 
 	ret = extcon_set_state_sync(info->edev, report, true);
 	if (ret != 0)
 		dev_err(arizona->dev, "Failed to report HP/line: %d\n",
 			ret);
 
 done:
 	/* Reset back to starting range */
 	regmap_update_bits(arizona->regmap,
 			   ARIZONA_HEADPHONE_DETECT_1,
 			   ARIZONA_HP_IMPEDANCE_RANGE_MASK | ARIZONA_HP_POLL,
 			   0);
 
 	arizona_extcon_hp_clamp(info, false);
 
 	if (id_gpio)
 		gpio_set_value_cansleep(id_gpio, 0);
 
 	/* Revert back to MICDET mode */
 	regmap_update_bits(arizona->regmap,
 			   ARIZONA_ACCESSORY_DETECT_MODE_1,
 			   ARIZONA_ACCDET_MODE_MASK, ARIZONA_ACCDET_MODE_MIC);
 
 	/* If we have a mic then reenable MICDET */
 	if (mic || info->mic)
 		arizona_start_mic(info);
 
 	if (info->hpdet_active) {
 		pm_runtime_put_autosuspend(info->dev);
 		info->hpdet_active = false;
 	}
 
 	info->hpdet_done = true;
 
 out:
 	mutex_unlock(&info->lock);
 
 	return IRQ_HANDLED;
 }
 
 static void arizona_identify_headphone(struct arizona_extcon_info *info)
 {
 	struct arizona *arizona = info->arizona;
 	int ret;
 
 	if (info->hpdet_done)
 		return;
 
 	dev_dbg(arizona->dev, "Starting HPDET\n");
 
 	/* Make sure we keep the device enabled during the measurement */
 	pm_runtime_get(info->dev);
 
 	info->hpdet_active = true;
 
 	if (info->mic)
 		arizona_stop_mic(info);
 
 	arizona_extcon_hp_clamp(info, true);
 
 	ret = regmap_update_bits(arizona->regmap,
 				 ARIZONA_ACCESSORY_DETECT_MODE_1,
 				 ARIZONA_ACCDET_MODE_MASK,
 				 arizona->pdata.hpdet_channel);
 	if (ret != 0) {
 		dev_err(arizona->dev, "Failed to set HPDET mode: %d\n", ret);
 		goto err;
 	}
 
 	ret = regmap_update_bits(arizona->regmap, ARIZONA_HEADPHONE_DETECT_1,
 				 ARIZONA_HP_POLL, ARIZONA_HP_POLL);
 	if (ret != 0) {
 		dev_err(arizona->dev, "Can't start HPDETL measurement: %d\n",
 			ret);
 		goto err;
 	}
 
 	return;
 
 err:
 	regmap_update_bits(arizona->regmap, ARIZONA_ACCESSORY_DETECT_MODE_1,
 			   ARIZONA_ACCDET_MODE_MASK, ARIZONA_ACCDET_MODE_MIC);
 
 	/* Just report headphone */
 	ret = extcon_set_state_sync(info->edev, EXTCON_JACK_HEADPHONE, true);
 	if (ret != 0)
 		dev_err(arizona->dev, "Failed to report headphone: %d\n", ret);
 
 	if (info->mic)
 		arizona_start_mic(info);
 
 	info->hpdet_active = false;
 }
 
 static void arizona_start_hpdet_acc_id(struct arizona_extcon_info *info)
 {
 	struct arizona *arizona = info->arizona;
 	int hp_reading = 32;
 	bool mic;
 	int ret;
 
 	dev_dbg(arizona->dev, "Starting identification via HPDET\n");
 
 	/* Make sure we keep the device enabled during the measurement */
 	pm_runtime_get_sync(info->dev);
 
 	info->hpdet_active = true;
 
 	arizona_extcon_hp_clamp(info, true);
 
 	ret = regmap_update_bits(arizona->regmap,
 				 ARIZONA_ACCESSORY_DETECT_MODE_1,
 				 ARIZONA_ACCDET_SRC | ARIZONA_ACCDET_MODE_MASK,
 				 info->micd_modes[0].src |
 				 arizona->pdata.hpdet_channel);
 	if (ret != 0) {
 		dev_err(arizona->dev, "Failed to set HPDET mode: %d\n", ret);
 		goto err;
 	}
 
 	if (arizona->pdata.hpdet_acc_id_line) {
 		ret = regmap_update_bits(arizona->regmap,
 					 ARIZONA_HEADPHONE_DETECT_1,
 					 ARIZONA_HP_POLL, ARIZONA_HP_POLL);
 		if (ret != 0) {
 			dev_err(arizona->dev,
 				"Can't start HPDETL measurement: %d\n",
 				ret);
 			goto err;
 		}
 	} else {
 		arizona_hpdet_do_id(info, &hp_reading, &mic);
 	}
 
 	return;
 
 err:
 	regmap_update_bits(arizona->regmap, ARIZONA_ACCESSORY_DETECT_MODE_1,
 			   ARIZONA_ACCDET_MODE_MASK, ARIZONA_ACCDET_MODE_MIC);
 
 	/* Just report headphone */
 	ret = extcon_set_state_sync(info->edev, EXTCON_JACK_HEADPHONE, true);
 	if (ret != 0)
 		dev_err(arizona->dev, "Failed to report headphone: %d\n", ret);
 
 	info->hpdet_active = false;
 }
 
 static void arizona_micd_timeout_work(struct work_struct *work)
 {
 	struct arizona_extcon_info *info = container_of(work,
 						struct arizona_extcon_info,
 						micd_timeout_work.work);
 
 	mutex_lock(&info->lock);
 
 	dev_dbg(info->arizona->dev, "MICD timed out, reporting HP\n");
 
 	info->detecting = false;
 
 	arizona_identify_headphone(info);
 
 	arizona_stop_mic(info);
 
 	mutex_unlock(&info->lock);
 }
 
 static void arizona_micd_detect(struct work_struct *work)
 {
 	struct arizona_extcon_info *info = container_of(work,
 						struct arizona_extcon_info,
 						micd_detect_work.work);
 	struct arizona *arizona = info->arizona;
 	unsigned int val = 0, lvl;
 	int ret, i, key;
 
 	cancel_delayed_work_sync(&info->micd_timeout_work);
 
 	mutex_lock(&info->lock);
 
 	/* If the cable was removed while measuring ignore the result */
 	ret = extcon_get_state(info->edev, EXTCON_MECHANICAL);
 	if (ret < 0) {
 		dev_err(arizona->dev, "Failed to check cable state: %d\n",
 				ret);
 		mutex_unlock(&info->lock);
 		return;
 	} else if (!ret) {
 		dev_dbg(arizona->dev, "Ignoring MICDET for removed cable\n");
 		mutex_unlock(&info->lock);
 		return;
 	}
 
 	if (info->detecting && arizona->pdata.micd_software_compare) {
 		/* Must disable MICD before we read the ADCVAL */
 		regmap_update_bits(arizona->regmap, ARIZONA_MIC_DETECT_1,
 				   ARIZONA_MICD_ENA, 0);
 		ret = regmap_read(arizona->regmap, ARIZONA_MIC_DETECT_4, &val);
 		if (ret != 0) {
 			dev_err(arizona->dev,
 				"Failed to read MICDET_ADCVAL: %d\n",
 				ret);
 			mutex_unlock(&info->lock);
 			return;
 		}
 
 		dev_dbg(arizona->dev, "MICDET_ADCVAL: %x\n", val);
 
 		val &= ARIZONA_MICDET_ADCVAL_MASK;
 		if (val < ARRAY_SIZE(arizona_micd_levels))
 			val = arizona_micd_levels[val];
 		else
 			val = INT_MAX;
 
 		if (val <= QUICK_HEADPHONE_MAX_OHM)
 			val = ARIZONA_MICD_STS | ARIZONA_MICD_LVL_0;
 		else if (val <= MICROPHONE_MIN_OHM)
 			val = ARIZONA_MICD_STS | ARIZONA_MICD_LVL_1;
 		else if (val <= MICROPHONE_MAX_OHM)
 			val = ARIZONA_MICD_STS | ARIZONA_MICD_LVL_8;
 		else
 			val = ARIZONA_MICD_LVL_8;
 	}
 
 	for (i = 0; i < 10 && !(val & MICD_LVL_0_TO_8); i++) {
 		ret = regmap_read(arizona->regmap, ARIZONA_MIC_DETECT_3, &val);
 		if (ret != 0) {
 			dev_err(arizona->dev,
 				"Failed to read MICDET: %d\n", ret);
 			mutex_unlock(&info->lock);
 			return;
 		}
 
 		dev_dbg(arizona->dev, "MICDET: %x\n", val);
 
 		if (!(val & ARIZONA_MICD_VALID)) {
 			dev_warn(arizona->dev,
 				 "Microphone detection state invalid\n");
 			mutex_unlock(&info->lock);
 			return;
 		}
 	}
 
 	if (i == 10 && !(val & MICD_LVL_0_TO_8)) {
 		dev_err(arizona->dev, "Failed to get valid MICDET value\n");
 		mutex_unlock(&info->lock);
 		return;
 	}
 
 	/* Due to jack detect this should never happen */
 	if (!(val & ARIZONA_MICD_STS)) {
 		dev_warn(arizona->dev, "Detected open circuit\n");
 		info->mic = false;
 		arizona_stop_mic(info);
 		info->detecting = false;
 		arizona_identify_headphone(info);
 		goto handled;
 	}
 
 	/* If we got a high impedence we should have a headset, report it. */
 	if (info->detecting && (val & ARIZONA_MICD_LVL_8)) {
 		info->mic = true;
 		info->detecting = false;
 
 		arizona_identify_headphone(info);
 
 		ret = extcon_set_state_sync(info->edev,
 					      EXTCON_JACK_MICROPHONE, true);
 		if (ret != 0)
 			dev_err(arizona->dev, "Headset report failed: %d\n",
 				ret);
 
 		/* Don't need to regulate for button detection */
 		ret = regulator_allow_bypass(info->micvdd, true);
 		if (ret != 0) {
 			dev_err(arizona->dev, "Failed to bypass MICVDD: %d\n",
 				ret);
 		}
 
 		goto handled;
 	}
 
 	/* If we detected a lower impedence during initial startup
 	 * then we probably have the wrong polarity, flip it.  Don't
 	 * do this for the lowest impedences to speed up detection of
 	 * plain headphones.  If both polarities report a low
 	 * impedence then give up and report headphones.
 	 */
 	if (info->detecting && (val & MICD_LVL_1_TO_7)) {
 		if (info->jack_flips >= info->micd_num_modes * 10) {
 			dev_dbg(arizona->dev, "Detected HP/line\n");
 
 			info->detecting = false;
 
 			arizona_identify_headphone(info);
 
 			arizona_stop_mic(info);
 		} else {
 			info->micd_mode++;
 			if (info->micd_mode == info->micd_num_modes)
 				info->micd_mode = 0;
 			arizona_extcon_set_mode(info, info->micd_mode);
 
 			info->jack_flips++;
 		}
 
 		goto handled;
 	}
 
 	/*
 	 * If we're still detecting and we detect a short then we've
 	 * got a headphone.  Otherwise it's a button press.
 	 */
 	if (val & MICD_LVL_0_TO_7) {
 		if (info->mic) {
 			dev_dbg(arizona->dev, "Mic button detected\n");
 
 			lvl = val & ARIZONA_MICD_LVL_MASK;
 			lvl >>= ARIZONA_MICD_LVL_SHIFT;
 
 			for (i = 0; i < info->num_micd_ranges; i++)
 				input_report_key(info->input,
 						 info->micd_ranges[i].key, 0);
 
 			WARN_ON(!lvl);
 			WARN_ON(ffs(lvl) - 1 >= info->num_micd_ranges);
 			if (lvl && ffs(lvl) - 1 < info->num_micd_ranges) {
 				key = info->micd_ranges[ffs(lvl) - 1].key;
 				input_report_key(info->input, key, 1);
 				input_sync(info->input);
 			}
 
 		} else if (info->detecting) {
 			dev_dbg(arizona->dev, "Headphone detected\n");
 			info->detecting = false;
 			arizona_stop_mic(info);
 
 			arizona_identify_headphone(info);
 		} else {
 			dev_warn(arizona->dev, "Button with no mic: %x\n",
 				 val);
 		}
 	} else {
 		dev_dbg(arizona->dev, "Mic button released\n");
 		for (i = 0; i < info->num_micd_ranges; i++)
 			input_report_key(info->input,
 					 info->micd_ranges[i].key, 0);
 		input_sync(info->input);
 		arizona_extcon_pulse_micbias(info);
 	}
 
 handled:
 	if (info->detecting) {
 		if (arizona->pdata.micd_software_compare)
 			regmap_update_bits(arizona->regmap,
 					   ARIZONA_MIC_DETECT_1,
 					   ARIZONA_MICD_ENA,
 					   ARIZONA_MICD_ENA);
 
 		queue_delayed_work(system_power_efficient_wq,
 				   &info->micd_timeout_work,
 				   msecs_to_jiffies(info->micd_timeout));
 	}
 
 	pm_runtime_mark_last_busy(info->dev);
 	mutex_unlock(&info->lock);
 }
 
 static irqreturn_t arizona_micdet(int irq, void *data)
 {
 	struct arizona_extcon_info *info = data;
 	struct arizona *arizona = info->arizona;
 	int debounce = arizona->pdata.micd_detect_debounce;
 
 	cancel_delayed_work_sync(&info->micd_detect_work);
 	cancel_delayed_work_sync(&info->micd_timeout_work);
 
 	mutex_lock(&info->lock);
 	if (!info->detecting)
 		debounce = 0;
 	mutex_unlock(&info->lock);
 
 	if (debounce)
 		queue_delayed_work(system_power_efficient_wq,
 				   &info->micd_detect_work,
 				   msecs_to_jiffies(debounce));
 	else
 		arizona_micd_detect(&info->micd_detect_work.work);
 
 	return IRQ_HANDLED;
 }
 
 static void arizona_hpdet_work(struct work_struct *work)
 {
 	struct arizona_extcon_info *info = container_of(work,
 						struct arizona_extcon_info,
 						hpdet_work.work);
 
 	mutex_lock(&info->lock);
 	arizona_start_hpdet_acc_id(info);
 	mutex_unlock(&info->lock);
 }
 
 static irqreturn_t arizona_jackdet(int irq, void *data)
 {
 	struct arizona_extcon_info *info = data;
 	struct arizona *arizona = info->arizona;
 	unsigned int val, present, mask;
 	bool cancelled_hp, cancelled_mic;
 	int ret, i;
 
 	cancelled_hp = cancel_delayed_work_sync(&info->hpdet_work);
 	cancelled_mic = cancel_delayed_work_sync(&info->micd_timeout_work);
 
 	pm_runtime_get_sync(info->dev);
 
 	mutex_lock(&info->lock);
 
 	if (info->micd_clamp) {
 		mask = ARIZONA_MICD_CLAMP_STS;
 		present = 0;
 	} else {
 		mask = ARIZONA_JD1_STS;
 		if (arizona->pdata.jd_invert)
 			present = 0;
 		else
 			present = ARIZONA_JD1_STS;
 	}
 
 	ret = regmap_read(arizona->regmap, ARIZONA_AOD_IRQ_RAW_STATUS, &val);
 	if (ret != 0) {
 		dev_err(arizona->dev, "Failed to read jackdet status: %d\n",
 			ret);
 		mutex_unlock(&info->lock);
 		pm_runtime_put_autosuspend(info->dev);
 		return IRQ_NONE;
 	}
 
 	val &= mask;
 	if (val == info->last_jackdet) {
 		dev_dbg(arizona->dev, "Suppressing duplicate JACKDET\n");
 		if (cancelled_hp)
 			queue_delayed_work(system_power_efficient_wq,
 					   &info->hpdet_work,
 					   msecs_to_jiffies(HPDET_DEBOUNCE));
 
 		if (cancelled_mic) {
 			int micd_timeout = info->micd_timeout;
 
 			queue_delayed_work(system_power_efficient_wq,
 					   &info->micd_timeout_work,
 					   msecs_to_jiffies(micd_timeout));
 		}
 
 		goto out;
 	}
 	info->last_jackdet = val;
 
 	if (info->last_jackdet == present) {
 		dev_dbg(arizona->dev, "Detected jack\n");
 		ret = extcon_set_state_sync(info->edev,
 					      EXTCON_MECHANICAL, true);
 
 		if (ret != 0)
 			dev_err(arizona->dev, "Mechanical report failed: %d\n",
 				ret);
 
 		if (!arizona->pdata.hpdet_acc_id) {
 			info->detecting = true;
 			info->mic = false;
 			info->jack_flips = 0;
 
 			arizona_start_mic(info);
 		} else {
 			queue_delayed_work(system_power_efficient_wq,
 					   &info->hpdet_work,
 					   msecs_to_jiffies(HPDET_DEBOUNCE));
 		}
 
 		if (info->micd_clamp || !arizona->pdata.jd_invert)
 			regmap_update_bits(arizona->regmap,
 					   ARIZONA_JACK_DETECT_DEBOUNCE,
 					   ARIZONA_MICD_CLAMP_DB |
 					   ARIZONA_JD1_DB, 0);
 	} else {
 		dev_dbg(arizona->dev, "Detected jack removal\n");
 
 		arizona_stop_mic(info);
 
 		info->num_hpdet_res = 0;
 		for (i = 0; i < ARRAY_SIZE(info->hpdet_res); i++)
 			info->hpdet_res[i] = 0;
 		info->mic = false;
 		info->hpdet_done = false;
 		info->hpdet_retried = false;
 
 		for (i = 0; i < info->num_micd_ranges; i++)
 			input_report_key(info->input,
 					 info->micd_ranges[i].key, 0);
 		input_sync(info->input);
 
 		for (i = 0; i < ARRAY_SIZE(arizona_cable) - 1; i++) {
 			ret = extcon_set_state_sync(info->edev,
 					arizona_cable[i], false);
 			if (ret != 0)
 				dev_err(arizona->dev,
 					"Removal report failed: %d\n", ret);
 		}
 
 		regmap_update_bits(arizona->regmap,
 				   ARIZONA_JACK_DETECT_DEBOUNCE,
 				   ARIZONA_MICD_CLAMP_DB | ARIZONA_JD1_DB,
 				   ARIZONA_MICD_CLAMP_DB | ARIZONA_JD1_DB);
 	}
 
 	if (arizona->pdata.micd_timeout)
 		info->micd_timeout = arizona->pdata.micd_timeout;
 	else
 		info->micd_timeout = DEFAULT_MICD_TIMEOUT;
 
 out:
 	/* Clear trig_sts to make sure DCVDD is not forced up */
 	regmap_write(arizona->regmap, ARIZONA_AOD_WKUP_AND_TRIG,
 		     ARIZONA_MICD_CLAMP_FALL_TRIG_STS |
 		     ARIZONA_MICD_CLAMP_RISE_TRIG_STS |
 		     ARIZONA_JD1_FALL_TRIG_STS |
 		     ARIZONA_JD1_RISE_TRIG_STS);
 
 	mutex_unlock(&info->lock);
 
 	pm_runtime_mark_last_busy(info->dev);
 	pm_runtime_put_autosuspend(info->dev);
 
 	return IRQ_HANDLED;
 }
 
 /* Map a level onto a slot in the register bank */
 static void arizona_micd_set_level(struct arizona *arizona, int index,
 				   unsigned int level)
 {
 	int reg;
 	unsigned int mask;
 
 	reg = ARIZONA_MIC_DETECT_LEVEL_4 - (index / 2);
 
 	if (!(index % 2)) {
 		mask = 0x3f00;
 		level <<= 8;
 	} else {
 		mask = 0x3f;
 	}
 
 	/* Program the level itself */
 	regmap_update_bits(arizona->regmap, reg, mask, level);
 }
 
 static int arizona_extcon_get_micd_configs(struct device *dev,
 					   struct arizona *arizona)
 {
 	const char * const prop = "wlf,micd-configs";
 	const int entries_per_config = 3;
 	struct arizona_micd_config *micd_configs;
 	int nconfs, ret;
 	int i, j;
 	u32 *vals;
 
 	nconfs = device_property_read_u32_array(arizona->dev, prop, NULL, 0);
 	if (nconfs <= 0)
 		return 0;
 
 	vals = kcalloc(nconfs, sizeof(u32), GFP_KERNEL);
 	if (!vals)
 		return -ENOMEM;
 
 	ret = device_property_read_u32_array(arizona->dev, prop, vals, nconfs);
 	if (ret < 0)
 		goto out;
 
 	nconfs /= entries_per_config;
 
 	micd_configs = devm_kzalloc(dev,
 				    nconfs * sizeof(struct arizona_micd_range),
 				    GFP_KERNEL);
 	if (!micd_configs) {
 		ret = -ENOMEM;
 		goto out;
 	}
 
 	for (i = 0, j = 0; i < nconfs; ++i) {
 		micd_configs[i].src = vals[j++] ? ARIZONA_ACCDET_SRC : 0;
 		micd_configs[i].bias = vals[j++];
 		micd_configs[i].gpio = vals[j++];
 	}
 
 	arizona->pdata.micd_configs = micd_configs;
 	arizona->pdata.num_micd_configs = nconfs;
 
 out:
 	kfree(vals);
 	return ret;
 }
 
 static int arizona_extcon_device_get_pdata(struct device *dev,
 					   struct arizona *arizona)
 {
 	struct arizona_pdata *pdata = &arizona->pdata;
 	unsigned int val = ARIZONA_ACCDET_MODE_HPL;
 	int ret;
 
 	device_property_read_u32(arizona->dev, "wlf,hpdet-channel", &val);
 	switch (val) {
 	case ARIZONA_ACCDET_MODE_HPL:
 	case ARIZONA_ACCDET_MODE_HPR:
 		pdata->hpdet_channel = val;
 		break;
 	default:
 		dev_err(arizona->dev,
 			"Wrong wlf,hpdet-channel DT value %d\n", val);
 		pdata->hpdet_channel = ARIZONA_ACCDET_MODE_HPL;
 	}
 
 	device_property_read_u32(arizona->dev, "wlf,micd-detect-debounce",
 				 &pdata->micd_detect_debounce);
 
 	device_property_read_u32(arizona->dev, "wlf,micd-bias-start-time",
 				 &pdata->micd_bias_start_time);
 
 	device_property_read_u32(arizona->dev, "wlf,micd-rate",
 				 &pdata->micd_rate);
 
 	device_property_read_u32(arizona->dev, "wlf,micd-dbtime",
 				 &pdata->micd_dbtime);
 
 	device_property_read_u32(arizona->dev, "wlf,micd-timeout-ms",
 				 &pdata->micd_timeout);
 
 	pdata->micd_force_micbias = device_property_read_bool(arizona->dev,
 						"wlf,micd-force-micbias");
 
 	pdata->micd_software_compare = device_property_read_bool(arizona->dev,
 						"wlf,micd-software-compare");
 
 	pdata->jd_invert = device_property_read_bool(arizona->dev,
 						     "wlf,jd-invert");
 
 	device_property_read_u32(arizona->dev, "wlf,gpsw", &pdata->gpsw);
 
 	pdata->jd_gpio5 = device_property_read_bool(arizona->dev,
 						    "wlf,use-jd2");
 	pdata->jd_gpio5_nopull = device_property_read_bool(arizona->dev,
 						"wlf,use-jd2-nopull");
 
 	ret = arizona_extcon_get_micd_configs(dev, arizona);
 	if (ret < 0)
 		dev_err(arizona->dev, "Failed to read micd configs: %d\n", ret);
 
 	return 0;
 }
 
 static int arizona_extcon_probe(struct platform_device *pdev)
 {
 	struct arizona *arizona = dev_get_drvdata(pdev->dev.parent);
 	struct arizona_pdata *pdata = &arizona->pdata;
 	struct arizona_extcon_info *info;
 	unsigned int val;
 	unsigned int clamp_mode;
 	int jack_irq_fall, jack_irq_rise;
 	int ret, mode, i, j;
 
 	if (!arizona->dapm || !arizona->dapm->card)
 		return -EPROBE_DEFER;
 
 	info = devm_kzalloc(&pdev->dev, sizeof(*info), GFP_KERNEL);
 	if (!info)
 		return -ENOMEM;
 
 	if (!dev_get_platdata(arizona->dev))
 		arizona_extcon_device_get_pdata(&pdev->dev, arizona);
 
 	info->micvdd = devm_regulator_get(&pdev->dev, "MICVDD");
 	if (IS_ERR(info->micvdd)) {
 		ret = PTR_ERR(info->micvdd);
 		dev_err(arizona->dev, "Failed to get MICVDD: %d\n", ret);
 		return ret;
 	}
 
 	mutex_init(&info->lock);
 	info->arizona = arizona;
 	info->dev = &pdev->dev;
 	info->last_jackdet = ~(ARIZONA_MICD_CLAMP_STS | ARIZONA_JD1_STS);
 	INIT_DELAYED_WORK(&info->hpdet_work, arizona_hpdet_work);
 	INIT_DELAYED_WORK(&info->micd_detect_work, arizona_micd_detect);
 	INIT_DELAYED_WORK(&info->micd_timeout_work, arizona_micd_timeout_work);
 	platform_set_drvdata(pdev, info);
 
 	switch (arizona->type) {
 	case WM5102:
 		switch (arizona->rev) {
 		case 0:
 			info->micd_reva = true;
 			break;
 		default:
 			info->micd_clamp = true;
 			info->hpdet_ip_version = 1;
 			break;
 		}
 		break;
 	case WM5110:
 	case WM8280:
 		switch (arizona->rev) {
 		case 0 ... 2:
 			break;
 		default:
 			info->micd_clamp = true;
 			info->hpdet_ip_version = 2;
 			break;
 		}
 		break;
 	case WM8998:
 	case WM1814:
 		info->micd_clamp = true;
 		info->hpdet_ip_version = 2;
 		break;
 	default:
 		break;
 	}
 
 	info->edev = devm_extcon_dev_allocate(&pdev->dev, arizona_cable);
 	if (IS_ERR(info->edev)) {
 		dev_err(&pdev->dev, "failed to allocate extcon device\n");
 		return -ENOMEM;
 	}
 
 	ret = devm_extcon_dev_register(&pdev->dev, info->edev);
 	if (ret < 0) {
 		dev_err(arizona->dev, "extcon_dev_register() failed: %d\n",
 			ret);
 		return ret;
 	}
 
 	info->input = devm_input_allocate_device(&pdev->dev);
 	if (!info->input) {
 		dev_err(arizona->dev, "Can't allocate input dev\n");
 		ret = -ENOMEM;
 		goto err_register;
 	}
 
 	info->input->name = "Headset";
 	info->input->phys = "arizona/extcon";
 
 	if (pdata->num_micd_configs) {
 		info->micd_modes = pdata->micd_configs;
 		info->micd_num_modes = pdata->num_micd_configs;
 	} else {
 		info->micd_modes = micd_default_modes;
 		info->micd_num_modes = ARRAY_SIZE(micd_default_modes);
 	}
 
 	if (arizona->pdata.gpsw > 0)
 		regmap_update_bits(arizona->regmap, ARIZONA_GP_SWITCH_1,
 				ARIZONA_SW1_MODE_MASK, arizona->pdata.gpsw);
 
-	if (arizona->pdata.micd_pol_gpio > 0) {
+	if (pdata->micd_pol_gpio > 0) {
 		if (info->micd_modes[0].gpio)
 			mode = GPIOF_OUT_INIT_HIGH;
 		else
 			mode = GPIOF_OUT_INIT_LOW;
 
-		ret = devm_gpio_request_one(&pdev->dev,
-					    arizona->pdata.micd_pol_gpio,
-					    mode,
-					    "MICD polarity");
+		ret = devm_gpio_request_one(&pdev->dev, pdata->micd_pol_gpio,
+					    mode, "MICD polarity");
 		if (ret != 0) {
 			dev_err(arizona->dev, "Failed to request GPIO%d: %d\n",
-				arizona->pdata.micd_pol_gpio, ret);
+				pdata->micd_pol_gpio, ret);
 			goto err_register;
 		}
+
+		info->micd_pol_gpio = gpio_to_desc(pdata->micd_pol_gpio);
 	} else {
 		if (info->micd_modes[0].gpio)
 			mode = GPIOD_OUT_HIGH;
 		else
 			mode = GPIOD_OUT_LOW;
 
 		/* We can't use devm here because we need to do the get
 		 * against the MFD device, as that is where the of_node
 		 * will reside, but if we devm against that the GPIO
 		 * will not be freed if the extcon driver is unloaded.
 		 */
 		info->micd_pol_gpio = gpiod_get_optional(arizona->dev,
 							 "wlf,micd-pol",
 							 GPIOD_OUT_LOW);
 		if (IS_ERR(info->micd_pol_gpio)) {
 			ret = PTR_ERR(info->micd_pol_gpio);
 			dev_err(arizona->dev,
 				"Failed to get microphone polarity GPIO: %d\n",
 				ret);
 			goto err_register;
 		}
 	}
 
 	if (arizona->pdata.hpdet_id_gpio > 0) {
 		ret = devm_gpio_request_one(&pdev->dev,
 					    arizona->pdata.hpdet_id_gpio,
 					    GPIOF_OUT_INIT_LOW,
 					    "HPDET");
 		if (ret != 0) {
 			dev_err(arizona->dev, "Failed to request GPIO%d: %d\n",
 				arizona->pdata.hpdet_id_gpio, ret);
 			goto err_gpio;
 		}
 	}
 
 	if (arizona->pdata.micd_bias_start_time)
 		regmap_update_bits(arizona->regmap, ARIZONA_MIC_DETECT_1,
 				   ARIZONA_MICD_BIAS_STARTTIME_MASK,
 				   arizona->pdata.micd_bias_start_time
 				   << ARIZONA_MICD_BIAS_STARTTIME_SHIFT);
 
 	if (arizona->pdata.micd_rate)
 		regmap_update_bits(arizona->regmap, ARIZONA_MIC_DETECT_1,
 				   ARIZONA_MICD_RATE_MASK,
 				   arizona->pdata.micd_rate
 				   << ARIZONA_MICD_RATE_SHIFT);
 
 	switch (arizona->pdata.micd_dbtime) {
 	case MICD_DBTIME_FOUR_READINGS:
 		regmap_update_bits(arizona->regmap, ARIZONA_MIC_DETECT_1,
 				   ARIZONA_MICD_DBTIME_MASK,
 				   ARIZONA_MICD_DBTIME);
 		break;
 	case MICD_DBTIME_TWO_READINGS:
 		regmap_update_bits(arizona->regmap, ARIZONA_MIC_DETECT_1,
 				   ARIZONA_MICD_DBTIME_MASK, 0);
 		break;
 	default:
 		break;
 	}
 
 	BUILD_BUG_ON(ARRAY_SIZE(arizona_micd_levels) <
 		     ARIZONA_NUM_MICD_BUTTON_LEVELS);
 
 	if (arizona->pdata.num_micd_ranges) {
 		info->micd_ranges = pdata->micd_ranges;
 		info->num_micd_ranges = pdata->num_micd_ranges;
 	} else {
 		info->micd_ranges = micd_default_ranges;
 		info->num_micd_ranges = ARRAY_SIZE(micd_default_ranges);
 	}
 
 	if (arizona->pdata.num_micd_ranges > ARIZONA_MAX_MICD_RANGE) {
 		dev_err(arizona->dev, "Too many MICD ranges: %d\n",
 			arizona->pdata.num_micd_ranges);
 	}
 
 	if (info->num_micd_ranges > 1) {
 		for (i = 1; i < info->num_micd_ranges; i++) {
 			if (info->micd_ranges[i - 1].max >
 			    info->micd_ranges[i].max) {
 				dev_err(arizona->dev,
 					"MICD ranges must be sorted\n");
 				ret = -EINVAL;
 				goto err_gpio;
 			}
 		}
 	}
 
 	/* Disable all buttons by default */
 	regmap_update_bits(arizona->regmap, ARIZONA_MIC_DETECT_2,
 			   ARIZONA_MICD_LVL_SEL_MASK, 0x81);
 
 	/* Set up all the buttons the user specified */
 	for (i = 0; i < info->num_micd_ranges; i++) {
 		for (j = 0; j < ARIZONA_NUM_MICD_BUTTON_LEVELS; j++)
 			if (arizona_micd_levels[j] >= info->micd_ranges[i].max)
 				break;
 
 		if (j == ARIZONA_NUM_MICD_BUTTON_LEVELS) {
 			dev_err(arizona->dev, "Unsupported MICD level %d\n",
 				info->micd_ranges[i].max);
 			ret = -EINVAL;
 			goto err_gpio;
 		}
 
 		dev_dbg(arizona->dev, "%d ohms for MICD threshold %d\n",
 			arizona_micd_levels[j], i);
 
 		arizona_micd_set_level(arizona, i, j);
 		input_set_capability(info->input, EV_KEY,
 				     info->micd_ranges[i].key);
 
 		/* Enable reporting of that range */
 		regmap_update_bits(arizona->regmap, ARIZONA_MIC_DETECT_2,
 				   1 << i, 1 << i);
 	}
 
 	/* Set all the remaining keys to a maximum */
 	for (; i < ARIZONA_MAX_MICD_RANGE; i++)
 		arizona_micd_set_level(arizona, i, 0x3f);
 
 	/*
 	 * If we have a clamp use it, activating in conjunction with
 	 * GPIO5 if that is connected for jack detect operation.
 	 */
 	if (info->micd_clamp) {
 		if (arizona->pdata.jd_gpio5) {
 			/* Put the GPIO into input mode with optional pull */
 			val = 0xc101;
 			if (arizona->pdata.jd_gpio5_nopull)
 				val &= ~ARIZONA_GPN_PU;
 
 			regmap_write(arizona->regmap, ARIZONA_GPIO5_CTRL,
 				     val);
 
 			if (arizona->pdata.jd_invert)
 				clamp_mode = ARIZONA_MICD_CLAMP_MODE_JDH_GP5H;
 			else
 				clamp_mode = ARIZONA_MICD_CLAMP_MODE_JDL_GP5H;
 		} else {
 			if (arizona->pdata.jd_invert)
 				clamp_mode = ARIZONA_MICD_CLAMP_MODE_JDH;
 			else
 				clamp_mode = ARIZONA_MICD_CLAMP_MODE_JDL;
 		}
 
 		regmap_update_bits(arizona->regmap,
 				   ARIZONA_MICD_CLAMP_CONTROL,
 				   ARIZONA_MICD_CLAMP_MODE_MASK, clamp_mode);
 
 		regmap_update_bits(arizona->regmap,
 				   ARIZONA_JACK_DETECT_DEBOUNCE,
 				   ARIZONA_MICD_CLAMP_DB,
 				   ARIZONA_MICD_CLAMP_DB);
 	}
 
 	arizona_extcon_set_mode(info, 0);
 
 	pm_runtime_enable(&pdev->dev);
 	pm_runtime_idle(&pdev->dev);
 	pm_runtime_get_sync(&pdev->dev);
 
 	if (info->micd_clamp) {
 		jack_irq_rise = ARIZONA_IRQ_MICD_CLAMP_RISE;
 		jack_irq_fall = ARIZONA_IRQ_MICD_CLAMP_FALL;
 	} else {
 		jack_irq_rise = ARIZONA_IRQ_JD_RISE;
 		jack_irq_fall = ARIZONA_IRQ_JD_FALL;
 	}
 
 	ret = arizona_request_irq(arizona, jack_irq_rise,
 				  "JACKDET rise", arizona_jackdet, info);
 	if (ret != 0) {
 		dev_err(&pdev->dev, "Failed to get JACKDET rise IRQ: %d\n",
 			ret);
 		goto err_gpio;
 	}
 
 	ret = arizona_set_irq_wake(arizona, jack_irq_rise, 1);
 	if (ret != 0) {
 		dev_err(&pdev->dev, "Failed to set JD rise IRQ wake: %d\n",
 			ret);
 		goto err_rise;
 	}
 
 	ret = arizona_request_irq(arizona, jack_irq_fall,
 				  "JACKDET fall", arizona_jackdet, info);
 	if (ret != 0) {
 		dev_err(&pdev->dev, "Failed to get JD fall IRQ: %d\n", ret);
 		goto err_rise_wake;
 	}
 
 	ret = arizona_set_irq_wake(arizona, jack_irq_fall, 1);
 	if (ret != 0) {
 		dev_err(&pdev->dev, "Failed to set JD fall IRQ wake: %d\n",
 			ret);
 		goto err_fall;
 	}
 
 	ret = arizona_request_irq(arizona, ARIZONA_IRQ_MICDET,
 				  "MICDET", arizona_micdet, info);
 	if (ret != 0) {
 		dev_err(&pdev->dev, "Failed to get MICDET IRQ: %d\n", ret);
 		goto err_fall_wake;
 	}
 
 	ret = arizona_request_irq(arizona, ARIZONA_IRQ_HPDET,
 				  "HPDET", arizona_hpdet_irq, info);
 	if (ret != 0) {
 		dev_err(&pdev->dev, "Failed to get HPDET IRQ: %d\n", ret);
 		goto err_micdet;
 	}
 
 	arizona_clk32k_enable(arizona);
 	regmap_update_bits(arizona->regmap, ARIZONA_JACK_DETECT_DEBOUNCE,
 			   ARIZONA_JD1_DB, ARIZONA_JD1_DB);
 	regmap_update_bits(arizona->regmap, ARIZONA_JACK_DETECT_ANALOGUE,
 			   ARIZONA_JD1_ENA, ARIZONA_JD1_ENA);
 
 	ret = regulator_allow_bypass(info->micvdd, true);
 	if (ret != 0)
 		dev_warn(arizona->dev, "Failed to set MICVDD to bypass: %d\n",
 			 ret);
 
 	pm_runtime_put(&pdev->dev);
 
 	ret = input_register_device(info->input);
 	if (ret) {
 		dev_err(&pdev->dev, "Can't register input device: %d\n", ret);
 		goto err_hpdet;
 	}
 
 	return 0;
 
 err_hpdet:
 	arizona_free_irq(arizona, ARIZONA_IRQ_HPDET, info);
 err_micdet:
 	arizona_free_irq(arizona, ARIZONA_IRQ_MICDET, info);
 err_fall_wake:
 	arizona_set_irq_wake(arizona, jack_irq_fall, 0);
 err_fall:
 	arizona_free_irq(arizona, jack_irq_fall, info);
 err_rise_wake:
 	arizona_set_irq_wake(arizona, jack_irq_rise, 0);
 err_rise:
 	arizona_free_irq(arizona, jack_irq_rise, info);
 err_gpio:
 	gpiod_put(info->micd_pol_gpio);
 err_register:
 	pm_runtime_disable(&pdev->dev);
 	return ret;
 }
 
 static int arizona_extcon_remove(struct platform_device *pdev)
 {
 	struct arizona_extcon_info *info = platform_get_drvdata(pdev);
 	struct arizona *arizona = info->arizona;
 	int jack_irq_rise, jack_irq_fall;
 
 	gpiod_put(info->micd_pol_gpio);
 
 	pm_runtime_disable(&pdev->dev);
 
 	regmap_update_bits(arizona->regmap,
 			   ARIZONA_MICD_CLAMP_CONTROL,
 			   ARIZONA_MICD_CLAMP_MODE_MASK, 0);
 
 	if (info->micd_clamp) {
 		jack_irq_rise = ARIZONA_IRQ_MICD_CLAMP_RISE;
 		jack_irq_fall = ARIZONA_IRQ_MICD_CLAMP_FALL;
 	} else {
 		jack_irq_rise = ARIZONA_IRQ_JD_RISE;
 		jack_irq_fall = ARIZONA_IRQ_JD_FALL;
 	}
 
 	arizona_set_irq_wake(arizona, jack_irq_rise, 0);
 	arizona_set_irq_wake(arizona, jack_irq_fall, 0);
 	arizona_free_irq(arizona, ARIZONA_IRQ_HPDET, info);
 	arizona_free_irq(arizona, ARIZONA_IRQ_MICDET, info);
 	arizona_free_irq(arizona, jack_irq_rise, info);
 	arizona_free_irq(arizona, jack_irq_fall, info);
 	cancel_delayed_work_sync(&info->hpdet_work);
 	regmap_update_bits(arizona->regmap, ARIZONA_JACK_DETECT_ANALOGUE,
 			   ARIZONA_JD1_ENA, 0);
 	arizona_clk32k_disable(arizona);
 
 	return 0;
 }
 
 static struct platform_driver arizona_extcon_driver = {
 	.driver		= {
 		.name	= "arizona-extcon",
 	},
 	.probe		= arizona_extcon_probe,
 	.remove		= arizona_extcon_remove,
 };
 
 module_platform_driver(arizona_extcon_driver);
 
 MODULE_DESCRIPTION("Arizona Extcon driver");
 MODULE_AUTHOR("Mark Brown <broonie@opensource.wolfsonmicro.com>");
 MODULE_LICENSE("GPL");
 MODULE_ALIAS("platform:extcon-arizona");
diff --git a/drivers/extcon/extcon-axp288.c b/drivers/extcon/extcon-axp288.c
index 42f41e808292..f4fd03e58e37 100644
--- a/drivers/extcon/extcon-axp288.c
+++ b/drivers/extcon/extcon-axp288.c
@@ -1,368 +1,346 @@
 /*
  * extcon-axp288.c - X-Power AXP288 PMIC extcon cable detection driver
  *
  * Copyright (C) 2015 Intel Corporation
  * Author: Ramakrishna Pallala <ramakrishna.pallala@intel.com>
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License version 2 as
  * published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
  */
 
 #include <linux/module.h>
 #include <linux/kernel.h>
 #include <linux/io.h>
 #include <linux/slab.h>
 #include <linux/interrupt.h>
 #include <linux/platform_device.h>
 #include <linux/property.h>
-#include <linux/usb/phy.h>
 #include <linux/notifier.h>
 #include <linux/extcon.h>
 #include <linux/regmap.h>
 #include <linux/gpio.h>
 #include <linux/gpio/consumer.h>
 #include <linux/mfd/axp20x.h>
 
 /* Power source status register */
 #define PS_STAT_VBUS_TRIGGER		BIT(0)
 #define PS_STAT_BAT_CHRG_DIR		BIT(2)
 #define PS_STAT_VBUS_ABOVE_VHOLD	BIT(3)
 #define PS_STAT_VBUS_VALID		BIT(4)
 #define PS_STAT_VBUS_PRESENT		BIT(5)
 
 /* BC module global register */
 #define BC_GLOBAL_RUN			BIT(0)
 #define BC_GLOBAL_DET_STAT		BIT(2)
 #define BC_GLOBAL_DBP_TOUT		BIT(3)
 #define BC_GLOBAL_VLGC_COM_SEL		BIT(4)
 #define BC_GLOBAL_DCD_TOUT_MASK		(BIT(6)|BIT(5))
 #define BC_GLOBAL_DCD_TOUT_300MS	0
 #define BC_GLOBAL_DCD_TOUT_100MS	1
 #define BC_GLOBAL_DCD_TOUT_500MS	2
 #define BC_GLOBAL_DCD_TOUT_900MS	3
 #define BC_GLOBAL_DCD_DET_SEL		BIT(7)
 
 /* BC module vbus control and status register */
 #define VBUS_CNTL_DPDM_PD_EN		BIT(4)
 #define VBUS_CNTL_DPDM_FD_EN		BIT(5)
 #define VBUS_CNTL_FIRST_PO_STAT		BIT(6)
 
 /* BC USB status register */
 #define USB_STAT_BUS_STAT_MASK		(BIT(3)|BIT(2)|BIT(1)|BIT(0))
 #define USB_STAT_BUS_STAT_SHIFT		0
 #define USB_STAT_BUS_STAT_ATHD		0
 #define USB_STAT_BUS_STAT_CONN		1
 #define USB_STAT_BUS_STAT_SUSP		2
 #define USB_STAT_BUS_STAT_CONF		3
 #define USB_STAT_USB_SS_MODE		BIT(4)
 #define USB_STAT_DEAD_BAT_DET		BIT(6)
 #define USB_STAT_DBP_UNCFG		BIT(7)
 
 /* BC detect status register */
 #define DET_STAT_MASK			(BIT(7)|BIT(6)|BIT(5))
 #define DET_STAT_SHIFT			5
 #define DET_STAT_SDP			1
 #define DET_STAT_CDP			2
 #define DET_STAT_DCP			3
 
-/* IRQ enable-1 register */
-#define PWRSRC_IRQ_CFG_MASK		(BIT(4)|BIT(3)|BIT(2))
-
-/* IRQ enable-6 register */
-#define BC12_IRQ_CFG_MASK		BIT(1)
-
 enum axp288_extcon_reg {
 	AXP288_PS_STAT_REG		= 0x00,
 	AXP288_PS_BOOT_REASON_REG	= 0x02,
 	AXP288_BC_GLOBAL_REG		= 0x2c,
 	AXP288_BC_VBUS_CNTL_REG		= 0x2d,
 	AXP288_BC_USB_STAT_REG		= 0x2e,
 	AXP288_BC_DET_STAT_REG		= 0x2f,
-	AXP288_PWRSRC_IRQ_CFG_REG	= 0x40,
-	AXP288_BC12_IRQ_CFG_REG		= 0x45,
 };
 
 enum axp288_mux_select {
 	EXTCON_GPIO_MUX_SEL_PMIC = 0,
 	EXTCON_GPIO_MUX_SEL_SOC,
 };
 
 enum axp288_extcon_irq {
 	VBUS_FALLING_IRQ = 0,
 	VBUS_RISING_IRQ,
 	MV_CHNG_IRQ,
 	BC_USB_CHNG_IRQ,
 	EXTCON_IRQ_END,
 };
 
 static const unsigned int axp288_extcon_cables[] = {
 	EXTCON_CHG_USB_SDP,
 	EXTCON_CHG_USB_CDP,
 	EXTCON_CHG_USB_DCP,
+	EXTCON_USB,
 	EXTCON_NONE,
 };
 
 struct axp288_extcon_info {
 	struct device *dev;
 	struct regmap *regmap;
 	struct regmap_irq_chip_data *regmap_irqc;
-	struct axp288_extcon_pdata *pdata;
+	struct gpio_desc *gpio_mux_cntl;
 	int irq[EXTCON_IRQ_END];
 	struct extcon_dev *edev;
 	struct notifier_block extcon_nb;
-	struct usb_phy *otg;
+	unsigned int previous_cable;
 };
 
 /* Power up/down reason string array */
 static char *axp288_pwr_up_down_info[] = {
 	"Last wake caused by user pressing the power button",
 	"Last wake caused by a charger insertion",
 	"Last wake caused by a battery insertion",
 	"Last wake caused by SOC initiated global reset",
 	"Last wake caused by cold reset",
 	"Last shutdown caused by PMIC UVLO threshold",
 	"Last shutdown caused by SOC initiated cold off",
 	"Last shutdown caused by user pressing the power button",
 	NULL,
 };
 
 /*
  * Decode and log the given "reset source indicator" (rsi)
  * register and then clear it.
  */
 static void axp288_extcon_log_rsi(struct axp288_extcon_info *info)
 {
 	char **rsi;
 	unsigned int val, i, clear_mask = 0;
 	int ret;
 
 	ret = regmap_read(info->regmap, AXP288_PS_BOOT_REASON_REG, &val);
 	for (i = 0, rsi = axp288_pwr_up_down_info; *rsi; rsi++, i++) {
 		if (val & BIT(i)) {
 			dev_dbg(info->dev, "%s\n", *rsi);
 			clear_mask |= BIT(i);
 		}
 	}
 
 	/* Clear the register value for next reboot (write 1 to clear bit) */
 	regmap_write(info->regmap, AXP288_PS_BOOT_REASON_REG, clear_mask);
 }
 
 static int axp288_handle_chrg_det_event(struct axp288_extcon_info *info)
 {
-	static bool notify_otg, notify_charger;
-	static unsigned int cable;
 	int ret, stat, cfg, pwr_stat;
 	u8 chrg_type;
+	unsigned int cable = info->previous_cable;
 	bool vbus_attach = false;
 
 	ret = regmap_read(info->regmap, AXP288_PS_STAT_REG, &pwr_stat);
 	if (ret < 0) {
 		dev_err(info->dev, "failed to read vbus status\n");
 		return ret;
 	}
 
-	vbus_attach = (pwr_stat & PS_STAT_VBUS_PRESENT);
+	vbus_attach = (pwr_stat & PS_STAT_VBUS_VALID);
 	if (!vbus_attach)
-		goto notify_otg;
+		goto no_vbus;
 
 	/* Check charger detection completion status */
 	ret = regmap_read(info->regmap, AXP288_BC_GLOBAL_REG, &cfg);
 	if (ret < 0)
 		goto dev_det_ret;
 	if (cfg & BC_GLOBAL_DET_STAT) {
 		dev_dbg(info->dev, "can't complete the charger detection\n");
 		goto dev_det_ret;
 	}
 
 	ret = regmap_read(info->regmap, AXP288_BC_DET_STAT_REG, &stat);
 	if (ret < 0)
 		goto dev_det_ret;
 
 	chrg_type = (stat & DET_STAT_MASK) >> DET_STAT_SHIFT;
 
 	switch (chrg_type) {
 	case DET_STAT_SDP:
 		dev_dbg(info->dev, "sdp cable is connected\n");
-		notify_otg = true;
-		notify_charger = true;
 		cable = EXTCON_CHG_USB_SDP;
 		break;
 	case DET_STAT_CDP:
 		dev_dbg(info->dev, "cdp cable is connected\n");
-		notify_otg = true;
-		notify_charger = true;
 		cable = EXTCON_CHG_USB_CDP;
 		break;
 	case DET_STAT_DCP:
 		dev_dbg(info->dev, "dcp cable is connected\n");
-		notify_charger = true;
 		cable = EXTCON_CHG_USB_DCP;
 		break;
 	default:
 		dev_warn(info->dev,
 			"disconnect or unknown or ID event\n");
 	}
 
-notify_otg:
-	if (notify_otg) {
-		/*
-		 * If VBUS is absent Connect D+/D- lines to PMIC for BC
-		 * detection. Else connect them to SOC for USB communication.
-		 */
-		if (info->pdata->gpio_mux_cntl)
-			gpiod_set_value(info->pdata->gpio_mux_cntl,
-				vbus_attach ? EXTCON_GPIO_MUX_SEL_SOC
-						: EXTCON_GPIO_MUX_SEL_PMIC);
-
-		atomic_notifier_call_chain(&info->otg->notifier,
-			vbus_attach ? USB_EVENT_VBUS : USB_EVENT_NONE, NULL);
-	}
-
-	if (notify_charger)
+no_vbus:
+	/*
+	 * If VBUS is absent Connect D+/D- lines to PMIC for BC
+	 * detection. Else connect them to SOC for USB communication.
+	 */
+	if (info->gpio_mux_cntl)
+		gpiod_set_value(info->gpio_mux_cntl,
+			vbus_attach ? EXTCON_GPIO_MUX_SEL_SOC
+					: EXTCON_GPIO_MUX_SEL_PMIC);
+
+	extcon_set_state_sync(info->edev, info->previous_cable, false);
+	if (info->previous_cable == EXTCON_CHG_USB_SDP)
+		extcon_set_state_sync(info->edev, EXTCON_USB, false);
+
+	if (vbus_attach) {
 		extcon_set_state_sync(info->edev, cable, vbus_attach);
+		if (cable == EXTCON_CHG_USB_SDP)
+			extcon_set_state_sync(info->edev, EXTCON_USB,
+						vbus_attach);
 
-	/* Clear the flags on disconnect event */
-	if (!vbus_attach)
-		notify_otg = notify_charger = false;
+		info->previous_cable = cable;
+	}
 
 	return 0;
 
 dev_det_ret:
 	if (ret < 0)
 		dev_err(info->dev, "failed to detect BC Mod\n");
 
 	return ret;
 }
 
 static irqreturn_t axp288_extcon_isr(int irq, void *data)
 {
 	struct axp288_extcon_info *info = data;
 	int ret;
 
 	ret = axp288_handle_chrg_det_event(info);
 	if (ret < 0)
 		dev_err(info->dev, "failed to handle the interrupt\n");
 
 	return IRQ_HANDLED;
 }
 
-static void axp288_extcon_enable_irq(struct axp288_extcon_info *info)
+static void axp288_extcon_enable(struct axp288_extcon_info *info)
 {
-	/* Unmask VBUS interrupt */
-	regmap_write(info->regmap, AXP288_PWRSRC_IRQ_CFG_REG,
-						PWRSRC_IRQ_CFG_MASK);
 	regmap_update_bits(info->regmap, AXP288_BC_GLOBAL_REG,
 						BC_GLOBAL_RUN, 0);
-	/* Unmask the BC1.2 complete interrupts */
-	regmap_write(info->regmap, AXP288_BC12_IRQ_CFG_REG, BC12_IRQ_CFG_MASK);
 	/* Enable the charger detection logic */
 	regmap_update_bits(info->regmap, AXP288_BC_GLOBAL_REG,
 					BC_GLOBAL_RUN, BC_GLOBAL_RUN);
 }
 
 static int axp288_extcon_probe(struct platform_device *pdev)
 {
 	struct axp288_extcon_info *info;
 	struct axp20x_dev *axp20x = dev_get_drvdata(pdev->dev.parent);
+	struct axp288_extcon_pdata *pdata = pdev->dev.platform_data;
 	int ret, i, pirq, gpio;
 
 	info = devm_kzalloc(&pdev->dev, sizeof(*info), GFP_KERNEL);
 	if (!info)
 		return -ENOMEM;
 
 	info->dev = &pdev->dev;
 	info->regmap = axp20x->regmap;
 	info->regmap_irqc = axp20x->regmap_irqc;
-	info->pdata = pdev->dev.platform_data;
-
-	if (!info->pdata) {
-		/* Try ACPI provided pdata via device properties */
-		if (!device_property_present(&pdev->dev,
-					"axp288_extcon_data\n"))
-			dev_err(&pdev->dev, "failed to get platform data\n");
-		return -ENODEV;
-	}
+	info->previous_cable = EXTCON_NONE;
+	if (pdata)
+		info->gpio_mux_cntl = pdata->gpio_mux_cntl;
+
 	platform_set_drvdata(pdev, info);
 
 	axp288_extcon_log_rsi(info);
 
 	/* Initialize extcon device */
 	info->edev = devm_extcon_dev_allocate(&pdev->dev,
 					      axp288_extcon_cables);
 	if (IS_ERR(info->edev)) {
 		dev_err(&pdev->dev, "failed to allocate memory for extcon\n");
 		return PTR_ERR(info->edev);
 	}
 
 	/* Register extcon device */
 	ret = devm_extcon_dev_register(&pdev->dev, info->edev);
 	if (ret) {
 		dev_err(&pdev->dev, "failed to register extcon device\n");
 		return ret;
 	}
 
-	/* Get otg transceiver phy */
-	info->otg = devm_usb_get_phy(&pdev->dev, USB_PHY_TYPE_USB2);
-	if (IS_ERR(info->otg)) {
-		dev_err(&pdev->dev, "failed to get otg transceiver\n");
-		return PTR_ERR(info->otg);
-	}
-
 	/* Set up gpio control for USB Mux */
-	if (info->pdata->gpio_mux_cntl) {
-		gpio = desc_to_gpio(info->pdata->gpio_mux_cntl);
+	if (info->gpio_mux_cntl) {
+		gpio = desc_to_gpio(info->gpio_mux_cntl);
 		ret = devm_gpio_request(&pdev->dev, gpio, "USB_MUX");
 		if (ret < 0) {
 			dev_err(&pdev->dev,
 				"failed to request the gpio=%d\n", gpio);
 			return ret;
 		}
-		gpiod_direction_output(info->pdata->gpio_mux_cntl,
+		gpiod_direction_output(info->gpio_mux_cntl,
 						EXTCON_GPIO_MUX_SEL_PMIC);
 	}
 
 	for (i = 0; i < EXTCON_IRQ_END; i++) {
 		pirq = platform_get_irq(pdev, i);
 		info->irq[i] = regmap_irq_get_virq(info->regmap_irqc, pirq);
 		if (info->irq[i] < 0) {
 			dev_err(&pdev->dev,
 				"failed to get virtual interrupt=%d\n", pirq);
 			ret = info->irq[i];
 			return ret;
 		}
 
 		ret = devm_request_threaded_irq(&pdev->dev, info->irq[i],
 				NULL, axp288_extcon_isr,
 				IRQF_ONESHOT | IRQF_NO_SUSPEND,
 				pdev->name, info);
 		if (ret) {
 			dev_err(&pdev->dev, "failed to request interrupt=%d\n",
 							info->irq[i]);
 			return ret;
 		}
 	}
 
-	/* Enable interrupts */
-	axp288_extcon_enable_irq(info);
+	/* Start charger cable type detection */
+	axp288_extcon_enable(info);
 
 	return 0;
 }
 
+static const struct platform_device_id axp288_extcon_table[] = {
+	{ .name = "axp288_extcon" },
+	{},
+};
+MODULE_DEVICE_TABLE(platform, axp288_extcon_table);
+
 static struct platform_driver axp288_extcon_driver = {
 	.probe = axp288_extcon_probe,
+	.id_table = axp288_extcon_table,
 	.driver = {
 		.name = "axp288_extcon",
 	},
 };
 module_platform_driver(axp288_extcon_driver);
 
 MODULE_AUTHOR("Ramakrishna Pallala <ramakrishna.pallala@intel.com>");
 MODULE_DESCRIPTION("X-Powers AXP288 extcon driver");
 MODULE_LICENSE("GPL v2");
diff --git a/drivers/extcon/extcon-intel-int3496.c b/drivers/extcon/extcon-intel-int3496.c
new file mode 100644
index 000000000000..a3131b036de6
--- /dev/null
+++ b/drivers/extcon/extcon-intel-int3496.c
@@ -0,0 +1,179 @@
+/*
+ * Intel INT3496 ACPI device extcon driver
+ *
+ * Copyright (c) 2016 Hans de Goede <hdegoede@redhat.com>
+ *
+ * Based on android x86 kernel code which is:
+ *
+ * Copyright (c) 2014, Intel Corporation.
+ * Author: David Cohen <david.a.cohen@linux.intel.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/acpi.h>
+#include <linux/extcon.h>
+#include <linux/gpio.h>
+#include <linux/interrupt.h>
+#include <linux/module.h>
+#include <linux/platform_device.h>
+
+#define INT3496_GPIO_USB_ID	0
+#define INT3496_GPIO_VBUS_EN	1
+#define INT3496_GPIO_USB_MUX	2
+#define DEBOUNCE_TIME		msecs_to_jiffies(50)
+
+struct int3496_data {
+	struct device *dev;
+	struct extcon_dev *edev;
+	struct delayed_work work;
+	struct gpio_desc *gpio_usb_id;
+	struct gpio_desc *gpio_vbus_en;
+	struct gpio_desc *gpio_usb_mux;
+	int usb_id_irq;
+};
+
+static const unsigned int int3496_cable[] = {
+	EXTCON_USB_HOST,
+	EXTCON_NONE,
+};
+
+static void int3496_do_usb_id(struct work_struct *work)
+{
+	struct int3496_data *data =
+		container_of(work, struct int3496_data, work.work);
+	int id = gpiod_get_value_cansleep(data->gpio_usb_id);
+
+	/* id == 1: PERIPHERAL, id == 0: HOST */
+	dev_dbg(data->dev, "Connected %s cable\n", id ? "PERIPHERAL" : "HOST");
+
+	/*
+	 * Peripheral: set USB mux to peripheral and disable VBUS
+	 * Host: set USB mux to host and enable VBUS
+	 */
+	if (!IS_ERR(data->gpio_usb_mux))
+		gpiod_direction_output(data->gpio_usb_mux, id);
+
+	if (!IS_ERR(data->gpio_vbus_en))
+		gpiod_direction_output(data->gpio_vbus_en, !id);
+
+	extcon_set_state_sync(data->edev, EXTCON_USB_HOST, !id);
+}
+
+static irqreturn_t int3496_thread_isr(int irq, void *priv)
+{
+	struct int3496_data *data = priv;
+
+	/* Let the pin settle before processing it */
+	mod_delayed_work(system_wq, &data->work, DEBOUNCE_TIME);
+
+	return IRQ_HANDLED;
+}
+
+static int int3496_probe(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct int3496_data *data;
+	int ret;
+
+	data = devm_kzalloc(dev, sizeof(*data), GFP_KERNEL);
+	if (!data)
+		return -ENOMEM;
+
+	data->dev = dev;
+	INIT_DELAYED_WORK(&data->work, int3496_do_usb_id);
+
+	data->gpio_usb_id = devm_gpiod_get_index(dev, "id",
+						INT3496_GPIO_USB_ID,
+						GPIOD_IN);
+	if (IS_ERR(data->gpio_usb_id)) {
+		ret = PTR_ERR(data->gpio_usb_id);
+		dev_err(dev, "can't request USB ID GPIO: %d\n", ret);
+		return ret;
+	}
+
+	data->usb_id_irq = gpiod_to_irq(data->gpio_usb_id);
+	if (data->usb_id_irq <= 0) {
+		dev_err(dev, "can't get USB ID IRQ: %d\n", data->usb_id_irq);
+		return -EINVAL;
+	}
+
+	data->gpio_vbus_en = devm_gpiod_get_index(dev, "vbus en",
+						 INT3496_GPIO_VBUS_EN,
+						 GPIOD_ASIS);
+	if (IS_ERR(data->gpio_vbus_en))
+		dev_info(dev, "can't request VBUS EN GPIO\n");
+
+	data->gpio_usb_mux = devm_gpiod_get_index(dev, "usb mux",
+						 INT3496_GPIO_USB_MUX,
+						 GPIOD_ASIS);
+	if (IS_ERR(data->gpio_usb_mux))
+		dev_info(dev, "can't request USB MUX GPIO\n");
+
+	/* register extcon device */
+	data->edev = devm_extcon_dev_allocate(dev, int3496_cable);
+	if (IS_ERR(data->edev))
+		return -ENOMEM;
+
+	ret = devm_extcon_dev_register(dev, data->edev);
+	if (ret < 0) {
+		dev_err(dev, "can't register extcon device: %d\n", ret);
+		return ret;
+	}
+
+	ret = devm_request_threaded_irq(dev, data->usb_id_irq,
+					NULL, int3496_thread_isr,
+					IRQF_SHARED | IRQF_ONESHOT |
+					IRQF_TRIGGER_RISING |
+					IRQF_TRIGGER_FALLING,
+					dev_name(dev), data);
+	if (ret < 0) {
+		dev_err(dev, "can't request IRQ for USB ID GPIO: %d\n", ret);
+		return ret;
+	}
+
+	/* queue initial processing of id-pin */
+	queue_delayed_work(system_wq, &data->work, 0);
+
+	platform_set_drvdata(pdev, data);
+
+	return 0;
+}
+
+static int int3496_remove(struct platform_device *pdev)
+{
+	struct int3496_data *data = platform_get_drvdata(pdev);
+
+	devm_free_irq(&pdev->dev, data->usb_id_irq, data);
+	cancel_delayed_work_sync(&data->work);
+
+	return 0;
+}
+
+static struct acpi_device_id int3496_acpi_match[] = {
+	{ "INT3496" },
+	{ }
+};
+MODULE_DEVICE_TABLE(acpi, int3496_acpi_match);
+
+static struct platform_driver int3496_driver = {
+	.driver = {
+		.name = "intel-int3496",
+		.acpi_match_table = int3496_acpi_match,
+	},
+	.probe = int3496_probe,
+	.remove = int3496_remove,
+};
+
+module_platform_driver(int3496_driver);
+
+MODULE_AUTHOR("Hans de Goede <hdegoede@redhat.com>");
+MODULE_DESCRIPTION("Intel INT3496 ACPI device extcon driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/extcon/extcon-max14577.c b/drivers/extcon/extcon-max14577.c
index 12e26c4e7763..f6414b7fa5bc 100644
--- a/drivers/extcon/extcon-max14577.c
+++ b/drivers/extcon/extcon-max14577.c
@@ -1,796 +1,798 @@
 /*
  * extcon-max14577.c - MAX14577/77836 extcon driver to support MUIC
  *
  * Copyright (C) 2013,2014 Samsung Electronics
  * Chanwoo Choi <cw00.choi@samsung.com>
  * Krzysztof Kozlowski <krzk@kernel.org>
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
  * the Free Software Foundation; either version 2 of the License, or
  * (at your option) any later version.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
  */
 
 #include <linux/kernel.h>
 #include <linux/module.h>
 #include <linux/i2c.h>
 #include <linux/interrupt.h>
 #include <linux/platform_device.h>
 #include <linux/mfd/max14577.h>
 #include <linux/mfd/max14577-private.h>
 #include <linux/extcon.h>
 
 #define	DELAY_MS_DEFAULT		17000		/* unit: millisecond */
 
 enum max14577_muic_adc_debounce_time {
 	ADC_DEBOUNCE_TIME_5MS = 0,
 	ADC_DEBOUNCE_TIME_10MS,
 	ADC_DEBOUNCE_TIME_25MS,
 	ADC_DEBOUNCE_TIME_38_62MS,
 };
 
 enum max14577_muic_status {
 	MAX14577_MUIC_STATUS1 = 0,
 	MAX14577_MUIC_STATUS2 = 1,
 	MAX14577_MUIC_STATUS_END,
 };
 
 /**
  * struct max14577_muic_irq
  * @irq: the index of irq list of MUIC device.
  * @name: the name of irq.
  * @virq: the virtual irq to use irq domain
  */
 struct max14577_muic_irq {
 	unsigned int irq;
 	const char *name;
 	unsigned int virq;
 };
 
 static struct max14577_muic_irq max14577_muic_irqs[] = {
 	{ MAX14577_IRQ_INT1_ADC,	"muic-ADC" },
 	{ MAX14577_IRQ_INT1_ADCLOW,	"muic-ADCLOW" },
 	{ MAX14577_IRQ_INT1_ADCERR,	"muic-ADCError" },
 	{ MAX14577_IRQ_INT2_CHGTYP,	"muic-CHGTYP" },
 	{ MAX14577_IRQ_INT2_CHGDETRUN,	"muic-CHGDETRUN" },
 	{ MAX14577_IRQ_INT2_DCDTMR,	"muic-DCDTMR" },
 	{ MAX14577_IRQ_INT2_DBCHG,	"muic-DBCHG" },
 	{ MAX14577_IRQ_INT2_VBVOLT,	"muic-VBVOLT" },
 };
 
 static struct max14577_muic_irq max77836_muic_irqs[] = {
 	{ MAX14577_IRQ_INT1_ADC,	"muic-ADC" },
 	{ MAX14577_IRQ_INT1_ADCLOW,	"muic-ADCLOW" },
 	{ MAX14577_IRQ_INT1_ADCERR,	"muic-ADCError" },
 	{ MAX77836_IRQ_INT1_ADC1K,	"muic-ADC1K" },
 	{ MAX14577_IRQ_INT2_CHGTYP,	"muic-CHGTYP" },
 	{ MAX14577_IRQ_INT2_CHGDETRUN,	"muic-CHGDETRUN" },
 	{ MAX14577_IRQ_INT2_DCDTMR,	"muic-DCDTMR" },
 	{ MAX14577_IRQ_INT2_DBCHG,	"muic-DBCHG" },
 	{ MAX14577_IRQ_INT2_VBVOLT,	"muic-VBVOLT" },
 	{ MAX77836_IRQ_INT2_VIDRM,	"muic-VIDRM" },
 };
 
 struct max14577_muic_info {
 	struct device *dev;
 	struct max14577 *max14577;
 	struct extcon_dev *edev;
 	int prev_cable_type;
 	int prev_chg_type;
 	u8 status[MAX14577_MUIC_STATUS_END];
 
 	struct max14577_muic_irq *muic_irqs;
 	unsigned int muic_irqs_num;
 	bool irq_adc;
 	bool irq_chg;
 	struct work_struct irq_work;
 	struct mutex mutex;
 
 	/*
 	 * Use delayed workqueue to detect cable state and then
 	 * notify cable state to notifiee/platform through uevent.
 	 * After completing the booting of platform, the extcon provider
 	 * driver should notify cable state to upper layer.
 	 */
 	struct delayed_work wq_detcable;
 
 	/*
 	 * Default usb/uart path whether UART/USB or AUX_UART/AUX_USB
 	 * h/w path of COMP2/COMN1 on CONTROL1 register.
 	 */
 	int path_usb;
 	int path_uart;
 };
 
 enum max14577_muic_cable_group {
 	MAX14577_CABLE_GROUP_ADC = 0,
 	MAX14577_CABLE_GROUP_CHG,
 };
 
 /* Define supported accessory type */
 enum max14577_muic_acc_type {
 	MAX14577_MUIC_ADC_GROUND = 0x0,
 	MAX14577_MUIC_ADC_SEND_END_BUTTON,
 	MAX14577_MUIC_ADC_REMOTE_S1_BUTTON,
 	MAX14577_MUIC_ADC_REMOTE_S2_BUTTON,
 	MAX14577_MUIC_ADC_REMOTE_S3_BUTTON,
 	MAX14577_MUIC_ADC_REMOTE_S4_BUTTON,
 	MAX14577_MUIC_ADC_REMOTE_S5_BUTTON,
 	MAX14577_MUIC_ADC_REMOTE_S6_BUTTON,
 	MAX14577_MUIC_ADC_REMOTE_S7_BUTTON,
 	MAX14577_MUIC_ADC_REMOTE_S8_BUTTON,
 	MAX14577_MUIC_ADC_REMOTE_S9_BUTTON,
 	MAX14577_MUIC_ADC_REMOTE_S10_BUTTON,
 	MAX14577_MUIC_ADC_REMOTE_S11_BUTTON,
 	MAX14577_MUIC_ADC_REMOTE_S12_BUTTON,
 	MAX14577_MUIC_ADC_RESERVED_ACC_1,
 	MAX14577_MUIC_ADC_RESERVED_ACC_2,
 	MAX14577_MUIC_ADC_RESERVED_ACC_3,
 	MAX14577_MUIC_ADC_RESERVED_ACC_4,
 	MAX14577_MUIC_ADC_RESERVED_ACC_5,
 	MAX14577_MUIC_ADC_AUDIO_DEVICE_TYPE2,
 	MAX14577_MUIC_ADC_PHONE_POWERED_DEV,
 	MAX14577_MUIC_ADC_TTY_CONVERTER,
 	MAX14577_MUIC_ADC_UART_CABLE,
 	MAX14577_MUIC_ADC_CEA936A_TYPE1_CHG,
 	MAX14577_MUIC_ADC_FACTORY_MODE_USB_OFF,
 	MAX14577_MUIC_ADC_FACTORY_MODE_USB_ON,
 	MAX14577_MUIC_ADC_AV_CABLE_NOLOAD,
 	MAX14577_MUIC_ADC_CEA936A_TYPE2_CHG,
 	MAX14577_MUIC_ADC_FACTORY_MODE_UART_OFF,
 	MAX14577_MUIC_ADC_FACTORY_MODE_UART_ON,
 	MAX14577_MUIC_ADC_AUDIO_DEVICE_TYPE1, /* with Remote and Simple Ctrl */
 	MAX14577_MUIC_ADC_OPEN,
 };
 
 static const unsigned int max14577_extcon_cable[] = {
 	EXTCON_USB,
 	EXTCON_CHG_USB_SDP,
 	EXTCON_CHG_USB_DCP,
 	EXTCON_CHG_USB_FAST,
 	EXTCON_CHG_USB_SLOW,
 	EXTCON_CHG_USB_CDP,
 	EXTCON_JIG,
 	EXTCON_NONE,
 };
 
 /*
  * max14577_muic_set_debounce_time - Set the debounce time of ADC
  * @info: the instance including private data of max14577 MUIC
  * @time: the debounce time of ADC
  */
 static int max14577_muic_set_debounce_time(struct max14577_muic_info *info,
 		enum max14577_muic_adc_debounce_time time)
 {
 	u8 ret;
 
 	switch (time) {
 	case ADC_DEBOUNCE_TIME_5MS:
 	case ADC_DEBOUNCE_TIME_10MS:
 	case ADC_DEBOUNCE_TIME_25MS:
 	case ADC_DEBOUNCE_TIME_38_62MS:
 		ret = max14577_update_reg(info->max14577->regmap,
 					  MAX14577_MUIC_REG_CONTROL3,
 					  CTRL3_ADCDBSET_MASK,
 					  time << CTRL3_ADCDBSET_SHIFT);
 		if (ret) {
 			dev_err(info->dev, "failed to set ADC debounce time\n");
 			return ret;
 		}
 		break;
 	default:
 		dev_err(info->dev, "invalid ADC debounce time\n");
 		return -EINVAL;
 	}
 
 	return 0;
 };
 
 /*
  * max14577_muic_set_path - Set hardware line according to attached cable
  * @info: the instance including private data of max14577 MUIC
  * @value: the path according to attached cable
  * @attached: the state of cable (true:attached, false:detached)
  *
  * The max14577 MUIC device share outside H/W line among a varity of cables
  * so, this function set internal path of H/W line according to the type of
  * attached cable.
  */
 static int max14577_muic_set_path(struct max14577_muic_info *info,
 		u8 val, bool attached)
 {
 	int ret = 0;
 	u8 ctrl1, ctrl2 = 0;
 
 	/* Set open state to path before changing hw path */
 	ret = max14577_update_reg(info->max14577->regmap,
 				MAX14577_MUIC_REG_CONTROL1,
 				CLEAR_IDBEN_MICEN_MASK, CTRL1_SW_OPEN);
 	if (ret < 0) {
 		dev_err(info->dev, "failed to update MUIC register\n");
 		return ret;
 	}
 
 	if (attached)
 		ctrl1 = val;
 	else
 		ctrl1 = CTRL1_SW_OPEN;
 
 	ret = max14577_update_reg(info->max14577->regmap,
 				MAX14577_MUIC_REG_CONTROL1,
 				CLEAR_IDBEN_MICEN_MASK, ctrl1);
 	if (ret < 0) {
 		dev_err(info->dev, "failed to update MUIC register\n");
 		return ret;
 	}
 
 	if (attached)
 		ctrl2 |= CTRL2_CPEN_MASK;	/* LowPwr=0, CPEn=1 */
 	else
 		ctrl2 |= CTRL2_LOWPWR_MASK;	/* LowPwr=1, CPEn=0 */
 
 	ret = max14577_update_reg(info->max14577->regmap,
 			MAX14577_REG_CONTROL2,
 			CTRL2_LOWPWR_MASK | CTRL2_CPEN_MASK, ctrl2);
 	if (ret < 0) {
 		dev_err(info->dev, "failed to update MUIC register\n");
 		return ret;
 	}
 
 	dev_dbg(info->dev,
 		"CONTROL1 : 0x%02x, CONTROL2 : 0x%02x, state : %s\n",
 		ctrl1, ctrl2, attached ? "attached" : "detached");
 
 	return 0;
 }
 
 /*
  * max14577_muic_get_cable_type - Return cable type and check cable state
  * @info: the instance including private data of max14577 MUIC
  * @group: the path according to attached cable
  * @attached: store cable state and return
  *
  * This function check the cable state either attached or detached,
  * and then divide precise type of cable according to cable group.
  *	- max14577_CABLE_GROUP_ADC
  *	- max14577_CABLE_GROUP_CHG
  */
 static int max14577_muic_get_cable_type(struct max14577_muic_info *info,
 		enum max14577_muic_cable_group group, bool *attached)
 {
 	int cable_type = 0;
 	int adc;
 	int chg_type;
 
 	switch (group) {
 	case MAX14577_CABLE_GROUP_ADC:
 		/*
 		 * Read ADC value to check cable type and decide cable state
 		 * according to cable type
 		 */
 		adc = info->status[MAX14577_MUIC_STATUS1] & STATUS1_ADC_MASK;
 		adc >>= STATUS1_ADC_SHIFT;
 
 		/*
 		 * Check current cable state/cable type and store cable type
 		 * (info->prev_cable_type) for handling cable when cable is
 		 * detached.
 		 */
 		if (adc == MAX14577_MUIC_ADC_OPEN) {
 			*attached = false;
 
 			cable_type = info->prev_cable_type;
 			info->prev_cable_type = MAX14577_MUIC_ADC_OPEN;
 		} else {
 			*attached = true;
 
 			cable_type = info->prev_cable_type = adc;
 		}
 		break;
 	case MAX14577_CABLE_GROUP_CHG:
 		/*
 		 * Read charger type to check cable type and decide cable state
 		 * according to type of charger cable.
 		 */
 		chg_type = info->status[MAX14577_MUIC_STATUS2] &
 			STATUS2_CHGTYP_MASK;
 		chg_type >>= STATUS2_CHGTYP_SHIFT;
 
 		if (chg_type == MAX14577_CHARGER_TYPE_NONE) {
 			*attached = false;
 
 			cable_type = info->prev_chg_type;
 			info->prev_chg_type = MAX14577_CHARGER_TYPE_NONE;
 		} else {
 			*attached = true;
 
 			/*
 			 * Check current cable state/cable type and store cable
 			 * type(info->prev_chg_type) for handling cable when
 			 * charger cable is detached.
 			 */
 			cable_type = info->prev_chg_type = chg_type;
 		}
 
 		break;
 	default:
 		dev_err(info->dev, "Unknown cable group (%d)\n", group);
 		cable_type = -EINVAL;
 		break;
 	}
 
 	return cable_type;
 }
 
 static int max14577_muic_jig_handler(struct max14577_muic_info *info,
 		int cable_type, bool attached)
 {
 	int ret = 0;
 	u8 path = CTRL1_SW_OPEN;
 
 	dev_dbg(info->dev,
 		"external connector is %s (adc:0x%02x)\n",
 		attached ? "attached" : "detached", cable_type);
 
 	switch (cable_type) {
 	case MAX14577_MUIC_ADC_FACTORY_MODE_USB_OFF:	/* ADC_JIG_USB_OFF */
 	case MAX14577_MUIC_ADC_FACTORY_MODE_USB_ON:	/* ADC_JIG_USB_ON */
 		/* PATH:AP_USB */
 		path = CTRL1_SW_USB;
 		break;
 	case MAX14577_MUIC_ADC_FACTORY_MODE_UART_OFF:	/* ADC_JIG_UART_OFF */
 		/* PATH:AP_UART */
 		path = CTRL1_SW_UART;
 		break;
 	default:
 		dev_err(info->dev, "failed to detect %s jig cable\n",
 			attached ? "attached" : "detached");
 		return -EINVAL;
 	}
 
 	ret = max14577_muic_set_path(info, path, attached);
 	if (ret < 0)
 		return ret;
 
 	extcon_set_state_sync(info->edev, EXTCON_JIG, attached);
 
 	return 0;
 }
 
 static int max14577_muic_adc_handler(struct max14577_muic_info *info)
 {
 	int cable_type;
 	bool attached;
 	int ret = 0;
 
 	/* Check accessory state which is either detached or attached */
 	cable_type = max14577_muic_get_cable_type(info,
 				MAX14577_CABLE_GROUP_ADC, &attached);
 
 	dev_dbg(info->dev,
 		"external connector is %s (adc:0x%02x, prev_adc:0x%x)\n",
 		attached ? "attached" : "detached", cable_type,
 		info->prev_cable_type);
 
 	switch (cable_type) {
 	case MAX14577_MUIC_ADC_FACTORY_MODE_USB_OFF:
 	case MAX14577_MUIC_ADC_FACTORY_MODE_USB_ON:
 	case MAX14577_MUIC_ADC_FACTORY_MODE_UART_OFF:
 		/* JIG */
 		ret = max14577_muic_jig_handler(info, cable_type, attached);
 		if (ret < 0)
 			return ret;
 		break;
 	case MAX14577_MUIC_ADC_GROUND:
 	case MAX14577_MUIC_ADC_SEND_END_BUTTON:
 	case MAX14577_MUIC_ADC_REMOTE_S1_BUTTON:
 	case MAX14577_MUIC_ADC_REMOTE_S2_BUTTON:
 	case MAX14577_MUIC_ADC_REMOTE_S3_BUTTON:
 	case MAX14577_MUIC_ADC_REMOTE_S4_BUTTON:
 	case MAX14577_MUIC_ADC_REMOTE_S5_BUTTON:
 	case MAX14577_MUIC_ADC_REMOTE_S6_BUTTON:
 	case MAX14577_MUIC_ADC_REMOTE_S7_BUTTON:
 	case MAX14577_MUIC_ADC_REMOTE_S8_BUTTON:
 	case MAX14577_MUIC_ADC_REMOTE_S9_BUTTON:
 	case MAX14577_MUIC_ADC_REMOTE_S10_BUTTON:
 	case MAX14577_MUIC_ADC_REMOTE_S11_BUTTON:
 	case MAX14577_MUIC_ADC_REMOTE_S12_BUTTON:
 	case MAX14577_MUIC_ADC_RESERVED_ACC_1:
 	case MAX14577_MUIC_ADC_RESERVED_ACC_2:
 	case MAX14577_MUIC_ADC_RESERVED_ACC_3:
 	case MAX14577_MUIC_ADC_RESERVED_ACC_4:
 	case MAX14577_MUIC_ADC_RESERVED_ACC_5:
 	case MAX14577_MUIC_ADC_AUDIO_DEVICE_TYPE2:
 	case MAX14577_MUIC_ADC_PHONE_POWERED_DEV:
 	case MAX14577_MUIC_ADC_TTY_CONVERTER:
 	case MAX14577_MUIC_ADC_UART_CABLE:
 	case MAX14577_MUIC_ADC_CEA936A_TYPE1_CHG:
 	case MAX14577_MUIC_ADC_AV_CABLE_NOLOAD:
 	case MAX14577_MUIC_ADC_CEA936A_TYPE2_CHG:
 	case MAX14577_MUIC_ADC_FACTORY_MODE_UART_ON:
 	case MAX14577_MUIC_ADC_AUDIO_DEVICE_TYPE1:
 		/*
 		 * This accessory isn't used in general case if it is specially
 		 * needed to detect additional accessory, should implement
 		 * proper operation when this accessory is attached/detached.
 		 */
 		dev_info(info->dev,
 			"accessory is %s but it isn't used (adc:0x%x)\n",
 			attached ? "attached" : "detached", cable_type);
 		return -EAGAIN;
 	default:
 		dev_err(info->dev,
 			"failed to detect %s accessory (adc:0x%x)\n",
 			attached ? "attached" : "detached", cable_type);
 		return -EINVAL;
 	}
 
 	return 0;
 }
 
 static int max14577_muic_chg_handler(struct max14577_muic_info *info)
 {
 	int chg_type;
 	bool attached;
 	int ret = 0;
 
 	chg_type = max14577_muic_get_cable_type(info,
 				MAX14577_CABLE_GROUP_CHG, &attached);
 
 	dev_dbg(info->dev,
 		"external connector is %s(chg_type:0x%x, prev_chg_type:0x%x)\n",
 			attached ? "attached" : "detached",
 			chg_type, info->prev_chg_type);
 
 	switch (chg_type) {
 	case MAX14577_CHARGER_TYPE_USB:
 		/* PATH:AP_USB */
 		ret = max14577_muic_set_path(info, info->path_usb, attached);
 		if (ret < 0)
 			return ret;
 
 		extcon_set_state_sync(info->edev, EXTCON_USB, attached);
 		extcon_set_state_sync(info->edev, EXTCON_CHG_USB_SDP,
 					attached);
 		break;
 	case MAX14577_CHARGER_TYPE_DEDICATED_CHG:
 		extcon_set_state_sync(info->edev, EXTCON_CHG_USB_DCP,
 					attached);
 		break;
 	case MAX14577_CHARGER_TYPE_DOWNSTREAM_PORT:
 		extcon_set_state_sync(info->edev, EXTCON_CHG_USB_CDP,
 					attached);
 		break;
 	case MAX14577_CHARGER_TYPE_SPECIAL_500MA:
 		extcon_set_state_sync(info->edev, EXTCON_CHG_USB_SLOW,
 					attached);
 		break;
 	case MAX14577_CHARGER_TYPE_SPECIAL_1A:
 		extcon_set_state_sync(info->edev, EXTCON_CHG_USB_FAST,
 					attached);
 		break;
 	case MAX14577_CHARGER_TYPE_NONE:
 	case MAX14577_CHARGER_TYPE_DEAD_BATTERY:
 		break;
 	default:
 		dev_err(info->dev,
 			"failed to detect %s accessory (chg_type:0x%x)\n",
 			attached ? "attached" : "detached", chg_type);
 		return -EINVAL;
 	}
 
 	return 0;
 }
 
 static void max14577_muic_irq_work(struct work_struct *work)
 {
 	struct max14577_muic_info *info = container_of(work,
 			struct max14577_muic_info, irq_work);
 	int ret = 0;
 
 	if (!info->edev)
 		return;
 
 	mutex_lock(&info->mutex);
 
 	ret = max14577_bulk_read(info->max14577->regmap,
 			MAX14577_MUIC_REG_STATUS1, info->status, 2);
 	if (ret) {
 		dev_err(info->dev, "failed to read MUIC register\n");
 		mutex_unlock(&info->mutex);
 		return;
 	}
 
 	if (info->irq_adc) {
 		ret = max14577_muic_adc_handler(info);
 		info->irq_adc = false;
 	}
 	if (info->irq_chg) {
 		ret = max14577_muic_chg_handler(info);
 		info->irq_chg = false;
 	}
 
 	if (ret < 0)
 		dev_err(info->dev, "failed to handle MUIC interrupt\n");
 
 	mutex_unlock(&info->mutex);
 }
 
 /*
  * Sets irq_adc or irq_chg in max14577_muic_info and returns 1.
  * Returns 0 if irq_type does not match registered IRQ for this device type.
  */
 static int max14577_parse_irq(struct max14577_muic_info *info, int irq_type)
 {
 	switch (irq_type) {
 	case MAX14577_IRQ_INT1_ADC:
 	case MAX14577_IRQ_INT1_ADCLOW:
 	case MAX14577_IRQ_INT1_ADCERR:
-		/* Handle all of accessory except for
-		   type of charger accessory */
+		/*
+		 * Handle all of accessory except for
+		 * type of charger accessory.
+		 */
 		info->irq_adc = true;
 		return 1;
 	case MAX14577_IRQ_INT2_CHGTYP:
 	case MAX14577_IRQ_INT2_CHGDETRUN:
 	case MAX14577_IRQ_INT2_DCDTMR:
 	case MAX14577_IRQ_INT2_DBCHG:
 	case MAX14577_IRQ_INT2_VBVOLT:
 		/* Handle charger accessory */
 		info->irq_chg = true;
 		return 1;
 	default:
 		return 0;
 	}
 }
 
 /*
  * Sets irq_adc or irq_chg in max14577_muic_info and returns 1.
  * Returns 0 if irq_type does not match registered IRQ for this device type.
  */
 static int max77836_parse_irq(struct max14577_muic_info *info, int irq_type)
 {
 	/* First check common max14577 interrupts */
 	if (max14577_parse_irq(info, irq_type))
 		return 1;
 
 	switch (irq_type) {
 	case MAX77836_IRQ_INT1_ADC1K:
 		info->irq_adc = true;
 		return 1;
 	case MAX77836_IRQ_INT2_VIDRM:
 		/* Handle charger accessory */
 		info->irq_chg = true;
 		return 1;
 	default:
 		return 0;
 	}
 }
 
 static irqreturn_t max14577_muic_irq_handler(int irq, void *data)
 {
 	struct max14577_muic_info *info = data;
 	int i, irq_type = -1;
 	bool irq_parsed;
 
 	/*
 	 * We may be called multiple times for different nested IRQ-s.
 	 * Including changes in INT1_ADC and INT2_CGHTYP at once.
 	 * However we only need to know whether it was ADC, charger
 	 * or both interrupts so decode IRQ and turn on proper flags.
 	 */
 	for (i = 0; i < info->muic_irqs_num; i++)
 		if (irq == info->muic_irqs[i].virq)
 			irq_type = info->muic_irqs[i].irq;
 
 	switch (info->max14577->dev_type) {
 	case MAXIM_DEVICE_TYPE_MAX77836:
 		irq_parsed = max77836_parse_irq(info, irq_type);
 		break;
 	case MAXIM_DEVICE_TYPE_MAX14577:
 	default:
 		irq_parsed = max14577_parse_irq(info, irq_type);
 		break;
 	}
 
 	if (!irq_parsed) {
 		dev_err(info->dev, "muic interrupt: irq %d occurred, skipped\n",
 				irq_type);
 		return IRQ_HANDLED;
 	}
 	schedule_work(&info->irq_work);
 
 	return IRQ_HANDLED;
 }
 
 static int max14577_muic_detect_accessory(struct max14577_muic_info *info)
 {
 	int ret = 0;
 	int adc;
 	int chg_type;
 	bool attached;
 
 	mutex_lock(&info->mutex);
 
 	/* Read STATUSx register to detect accessory */
 	ret = max14577_bulk_read(info->max14577->regmap,
 			MAX14577_MUIC_REG_STATUS1, info->status, 2);
 	if (ret) {
 		dev_err(info->dev, "failed to read MUIC register\n");
 		mutex_unlock(&info->mutex);
 		return ret;
 	}
 
 	adc = max14577_muic_get_cable_type(info, MAX14577_CABLE_GROUP_ADC,
 					&attached);
 	if (attached && adc != MAX14577_MUIC_ADC_OPEN) {
 		ret = max14577_muic_adc_handler(info);
 		if (ret < 0) {
 			dev_err(info->dev, "Cannot detect accessory\n");
 			mutex_unlock(&info->mutex);
 			return ret;
 		}
 	}
 
 	chg_type = max14577_muic_get_cable_type(info, MAX14577_CABLE_GROUP_CHG,
 					&attached);
 	if (attached && chg_type != MAX14577_CHARGER_TYPE_NONE) {
 		ret = max14577_muic_chg_handler(info);
 		if (ret < 0) {
 			dev_err(info->dev, "Cannot detect charger accessory\n");
 			mutex_unlock(&info->mutex);
 			return ret;
 		}
 	}
 
 	mutex_unlock(&info->mutex);
 
 	return 0;
 }
 
 static void max14577_muic_detect_cable_wq(struct work_struct *work)
 {
 	struct max14577_muic_info *info = container_of(to_delayed_work(work),
 				struct max14577_muic_info, wq_detcable);
 
 	max14577_muic_detect_accessory(info);
 }
 
 static int max14577_muic_probe(struct platform_device *pdev)
 {
 	struct max14577 *max14577 = dev_get_drvdata(pdev->dev.parent);
 	struct max14577_muic_info *info;
 	int delay_jiffies;
 	int ret;
 	int i;
 	u8 id;
 
 	info = devm_kzalloc(&pdev->dev, sizeof(*info), GFP_KERNEL);
 	if (!info)
 		return -ENOMEM;
 
 	info->dev = &pdev->dev;
 	info->max14577 = max14577;
 
 	platform_set_drvdata(pdev, info);
 	mutex_init(&info->mutex);
 
 	INIT_WORK(&info->irq_work, max14577_muic_irq_work);
 
 	switch (max14577->dev_type) {
 	case MAXIM_DEVICE_TYPE_MAX77836:
 		info->muic_irqs = max77836_muic_irqs;
 		info->muic_irqs_num = ARRAY_SIZE(max77836_muic_irqs);
 		break;
 	case MAXIM_DEVICE_TYPE_MAX14577:
 	default:
 		info->muic_irqs = max14577_muic_irqs;
 		info->muic_irqs_num = ARRAY_SIZE(max14577_muic_irqs);
 	}
 
 	/* Support irq domain for max14577 MUIC device */
 	for (i = 0; i < info->muic_irqs_num; i++) {
 		struct max14577_muic_irq *muic_irq = &info->muic_irqs[i];
 		int virq = 0;
 
 		virq = regmap_irq_get_virq(max14577->irq_data, muic_irq->irq);
 		if (virq <= 0)
 			return -EINVAL;
 		muic_irq->virq = virq;
 
 		ret = devm_request_threaded_irq(&pdev->dev, virq, NULL,
 				max14577_muic_irq_handler,
 				IRQF_NO_SUSPEND,
 				muic_irq->name, info);
 		if (ret) {
 			dev_err(&pdev->dev,
 				"failed: irq request (IRQ: %d, error :%d)\n",
 				muic_irq->irq, ret);
 			return ret;
 		}
 	}
 
 	/* Initialize extcon device */
 	info->edev = devm_extcon_dev_allocate(&pdev->dev,
 					      max14577_extcon_cable);
 	if (IS_ERR(info->edev)) {
 		dev_err(&pdev->dev, "failed to allocate memory for extcon\n");
 		return -ENOMEM;
 	}
 
 	ret = devm_extcon_dev_register(&pdev->dev, info->edev);
 	if (ret) {
 		dev_err(&pdev->dev, "failed to register extcon device\n");
 		return ret;
 	}
 
 	/* Default h/w line path */
 	info->path_usb = CTRL1_SW_USB;
 	info->path_uart = CTRL1_SW_UART;
 	delay_jiffies = msecs_to_jiffies(DELAY_MS_DEFAULT);
 
 	/* Set initial path for UART */
 	max14577_muic_set_path(info, info->path_uart, true);
 
 	/* Check revision number of MUIC device*/
 	ret = max14577_read_reg(info->max14577->regmap,
 			MAX14577_REG_DEVICEID, &id);
 	if (ret < 0) {
 		dev_err(&pdev->dev, "failed to read revision number\n");
 		return ret;
 	}
 	dev_info(info->dev, "device ID : 0x%x\n", id);
 
 	/* Set ADC debounce time */
 	max14577_muic_set_debounce_time(info, ADC_DEBOUNCE_TIME_25MS);
 
 	/*
 	 * Detect accessory after completing the initialization of platform
 	 *
 	 * - Use delayed workqueue to detect cable state and then
 	 * notify cable state to notifiee/platform through uevent.
 	 * After completing the booting of platform, the extcon provider
 	 * driver should notify cable state to upper layer.
 	 */
 	INIT_DELAYED_WORK(&info->wq_detcable, max14577_muic_detect_cable_wq);
 	queue_delayed_work(system_power_efficient_wq, &info->wq_detcable,
 			delay_jiffies);
 
 	return ret;
 }
 
 static int max14577_muic_remove(struct platform_device *pdev)
 {
 	struct max14577_muic_info *info = platform_get_drvdata(pdev);
 
 	cancel_work_sync(&info->irq_work);
 
 	return 0;
 }
 
 static const struct platform_device_id max14577_muic_id[] = {
 	{ "max14577-muic", MAXIM_DEVICE_TYPE_MAX14577, },
 	{ "max77836-muic", MAXIM_DEVICE_TYPE_MAX77836, },
 	{ }
 };
 MODULE_DEVICE_TABLE(platform, max14577_muic_id);
 
 static struct platform_driver max14577_muic_driver = {
 	.driver		= {
 		.name	= "max14577-muic",
 	},
 	.probe		= max14577_muic_probe,
 	.remove		= max14577_muic_remove,
 	.id_table	= max14577_muic_id,
 };
 
 module_platform_driver(max14577_muic_driver);
 
 MODULE_DESCRIPTION("Maxim 14577/77836 Extcon driver");
 MODULE_AUTHOR("Chanwoo Choi <cw00.choi@samsung.com>, Krzysztof Kozlowski <krzk@kernel.org>");
 MODULE_LICENSE("GPL");
 MODULE_ALIAS("platform:extcon-max14577");
diff --git a/drivers/extcon/extcon-max77693.c b/drivers/extcon/extcon-max77693.c
index 68dbcb814b2f..62163468f205 100644
--- a/drivers/extcon/extcon-max77693.c
+++ b/drivers/extcon/extcon-max77693.c
@@ -1,1275 +1,1279 @@
 /*
  * extcon-max77693.c - MAX77693 extcon driver to support MAX77693 MUIC
  *
  * Copyright (C) 2012 Samsung Electrnoics
  * Chanwoo Choi <cw00.choi@samsung.com>
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
  * the Free Software Foundation; either version 2 of the License, or
  * (at your option) any later version.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
  */
 
 #include <linux/kernel.h>
 #include <linux/module.h>
 #include <linux/i2c.h>
 #include <linux/slab.h>
 #include <linux/input.h>
 #include <linux/interrupt.h>
 #include <linux/err.h>
 #include <linux/platform_device.h>
 #include <linux/mfd/max77693.h>
 #include <linux/mfd/max77693-common.h>
 #include <linux/mfd/max77693-private.h>
 #include <linux/extcon.h>
 #include <linux/regmap.h>
 #include <linux/irqdomain.h>
 
 #define	DEV_NAME			"max77693-muic"
 #define	DELAY_MS_DEFAULT		20000		/* unit: millisecond */
 
 /*
  * Default value of MAX77693 register to bring up MUIC device.
  * If user don't set some initial value for MUIC device through platform data,
  * extcon-max77693 driver use 'default_init_data' to bring up base operation
  * of MAX77693 MUIC device.
  */
 static struct max77693_reg_data default_init_data[] = {
 	{
 		/* STATUS2 - [3]ChgDetRun */
 		.addr = MAX77693_MUIC_REG_STATUS2,
 		.data = MAX77693_STATUS2_CHGDETRUN_MASK,
 	}, {
 		/* INTMASK1 - Unmask [3]ADC1KM,[0]ADCM */
 		.addr = MAX77693_MUIC_REG_INTMASK1,
 		.data = INTMASK1_ADC1K_MASK
 			| INTMASK1_ADC_MASK,
 	}, {
 		/* INTMASK2 - Unmask [0]ChgTypM */
 		.addr = MAX77693_MUIC_REG_INTMASK2,
 		.data = INTMASK2_CHGTYP_MASK,
 	}, {
 		/* INTMASK3 - Mask all of interrupts */
 		.addr = MAX77693_MUIC_REG_INTMASK3,
 		.data = 0x0,
 	}, {
 		/* CDETCTRL2 */
 		.addr = MAX77693_MUIC_REG_CDETCTRL2,
 		.data = CDETCTRL2_VIDRMEN_MASK
 			| CDETCTRL2_DXOVPEN_MASK,
 	},
 };
 
 enum max77693_muic_adc_debounce_time {
 	ADC_DEBOUNCE_TIME_5MS = 0,
 	ADC_DEBOUNCE_TIME_10MS,
 	ADC_DEBOUNCE_TIME_25MS,
 	ADC_DEBOUNCE_TIME_38_62MS,
 };
 
 struct max77693_muic_info {
 	struct device *dev;
 	struct max77693_dev *max77693;
 	struct extcon_dev *edev;
 	int prev_cable_type;
 	int prev_cable_type_gnd;
 	int prev_chg_type;
 	int prev_button_type;
 	u8 status[2];
 
 	int irq;
 	struct work_struct irq_work;
 	struct mutex mutex;
 
 	/*
 	 * Use delayed workqueue to detect cable state and then
 	 * notify cable state to notifiee/platform through uevent.
 	 * After completing the booting of platform, the extcon provider
 	 * driver should notify cable state to upper layer.
 	 */
 	struct delayed_work wq_detcable;
 
 	/* Button of dock device */
 	struct input_dev *dock;
 
 	/*
 	 * Default usb/uart path whether UART/USB or AUX_UART/AUX_USB
 	 * h/w path of COMP2/COMN1 on CONTROL1 register.
 	 */
 	int path_usb;
 	int path_uart;
 };
 
 enum max77693_muic_cable_group {
 	MAX77693_CABLE_GROUP_ADC = 0,
 	MAX77693_CABLE_GROUP_ADC_GND,
 	MAX77693_CABLE_GROUP_CHG,
 	MAX77693_CABLE_GROUP_VBVOLT,
 };
 
 enum max77693_muic_charger_type {
 	MAX77693_CHARGER_TYPE_NONE = 0,
 	MAX77693_CHARGER_TYPE_USB,
 	MAX77693_CHARGER_TYPE_DOWNSTREAM_PORT,
 	MAX77693_CHARGER_TYPE_DEDICATED_CHG,
 	MAX77693_CHARGER_TYPE_APPLE_500MA,
 	MAX77693_CHARGER_TYPE_APPLE_1A_2A,
 	MAX77693_CHARGER_TYPE_DEAD_BATTERY = 7,
 };
 
 /**
  * struct max77693_muic_irq
  * @irq: the index of irq list of MUIC device.
  * @name: the name of irq.
  * @virq: the virtual irq to use irq domain
  */
 struct max77693_muic_irq {
 	unsigned int irq;
 	const char *name;
 	unsigned int virq;
 };
 
 static struct max77693_muic_irq muic_irqs[] = {
 	{ MAX77693_MUIC_IRQ_INT1_ADC,		"muic-ADC" },
 	{ MAX77693_MUIC_IRQ_INT1_ADC_LOW,	"muic-ADCLOW" },
 	{ MAX77693_MUIC_IRQ_INT1_ADC_ERR,	"muic-ADCError" },
 	{ MAX77693_MUIC_IRQ_INT1_ADC1K,		"muic-ADC1K" },
 	{ MAX77693_MUIC_IRQ_INT2_CHGTYP,	"muic-CHGTYP" },
 	{ MAX77693_MUIC_IRQ_INT2_CHGDETREUN,	"muic-CHGDETREUN" },
 	{ MAX77693_MUIC_IRQ_INT2_DCDTMR,	"muic-DCDTMR" },
 	{ MAX77693_MUIC_IRQ_INT2_DXOVP,		"muic-DXOVP" },
 	{ MAX77693_MUIC_IRQ_INT2_VBVOLT,	"muic-VBVOLT" },
 	{ MAX77693_MUIC_IRQ_INT2_VIDRM,		"muic-VIDRM" },
 	{ MAX77693_MUIC_IRQ_INT3_EOC,		"muic-EOC" },
 	{ MAX77693_MUIC_IRQ_INT3_CGMBC,		"muic-CGMBC" },
 	{ MAX77693_MUIC_IRQ_INT3_OVP,		"muic-OVP" },
 	{ MAX77693_MUIC_IRQ_INT3_MBCCHG_ERR,	"muic-MBCCHG_ERR" },
 	{ MAX77693_MUIC_IRQ_INT3_CHG_ENABLED,	"muic-CHG_ENABLED" },
 	{ MAX77693_MUIC_IRQ_INT3_BAT_DET,	"muic-BAT_DET" },
 };
 
 /* Define supported accessory type */
 enum max77693_muic_acc_type {
 	MAX77693_MUIC_ADC_GROUND = 0x0,
 	MAX77693_MUIC_ADC_SEND_END_BUTTON,
 	MAX77693_MUIC_ADC_REMOTE_S1_BUTTON,
 	MAX77693_MUIC_ADC_REMOTE_S2_BUTTON,
 	MAX77693_MUIC_ADC_REMOTE_S3_BUTTON,
 	MAX77693_MUIC_ADC_REMOTE_S4_BUTTON,
 	MAX77693_MUIC_ADC_REMOTE_S5_BUTTON,
 	MAX77693_MUIC_ADC_REMOTE_S6_BUTTON,
 	MAX77693_MUIC_ADC_REMOTE_S7_BUTTON,
 	MAX77693_MUIC_ADC_REMOTE_S8_BUTTON,
 	MAX77693_MUIC_ADC_REMOTE_S9_BUTTON,
 	MAX77693_MUIC_ADC_REMOTE_S10_BUTTON,
 	MAX77693_MUIC_ADC_REMOTE_S11_BUTTON,
 	MAX77693_MUIC_ADC_REMOTE_S12_BUTTON,
 	MAX77693_MUIC_ADC_RESERVED_ACC_1,
 	MAX77693_MUIC_ADC_RESERVED_ACC_2,
 	MAX77693_MUIC_ADC_RESERVED_ACC_3,
 	MAX77693_MUIC_ADC_RESERVED_ACC_4,
 	MAX77693_MUIC_ADC_RESERVED_ACC_5,
 	MAX77693_MUIC_ADC_CEA936_AUDIO,
 	MAX77693_MUIC_ADC_PHONE_POWERED_DEV,
 	MAX77693_MUIC_ADC_TTY_CONVERTER,
 	MAX77693_MUIC_ADC_UART_CABLE,
 	MAX77693_MUIC_ADC_CEA936A_TYPE1_CHG,
 	MAX77693_MUIC_ADC_FACTORY_MODE_USB_OFF,
 	MAX77693_MUIC_ADC_FACTORY_MODE_USB_ON,
 	MAX77693_MUIC_ADC_AV_CABLE_NOLOAD,
 	MAX77693_MUIC_ADC_CEA936A_TYPE2_CHG,
 	MAX77693_MUIC_ADC_FACTORY_MODE_UART_OFF,
 	MAX77693_MUIC_ADC_FACTORY_MODE_UART_ON,
 	MAX77693_MUIC_ADC_AUDIO_MODE_REMOTE,
 	MAX77693_MUIC_ADC_OPEN,
 
-	/* The below accessories have same ADC value so ADCLow and
-	   ADC1K bit is used to separate specific accessory */
+	/*
+	 * The below accessories have same ADC value so ADCLow and
+	 * ADC1K bit is used to separate specific accessory.
+	 */
 						/* ADC|VBVolot|ADCLow|ADC1K| */
 	MAX77693_MUIC_GND_USB_HOST = 0x100,	/* 0x0|      0|     0|    0| */
 	MAX77693_MUIC_GND_USB_HOST_VB = 0x104,	/* 0x0|      1|     0|    0| */
 	MAX77693_MUIC_GND_AV_CABLE_LOAD = 0x102,/* 0x0|      0|     1|    0| */
 	MAX77693_MUIC_GND_MHL = 0x103,		/* 0x0|      0|     1|    1| */
 	MAX77693_MUIC_GND_MHL_VB = 0x107,	/* 0x0|      1|     1|    1| */
 };
 
 /*
  * MAX77693 MUIC device support below list of accessories(external connector)
  */
 static const unsigned int max77693_extcon_cable[] = {
 	EXTCON_USB,
 	EXTCON_USB_HOST,
 	EXTCON_CHG_USB_SDP,
 	EXTCON_CHG_USB_DCP,
 	EXTCON_CHG_USB_FAST,
 	EXTCON_CHG_USB_SLOW,
 	EXTCON_CHG_USB_CDP,
 	EXTCON_DISP_MHL,
 	EXTCON_JIG,
 	EXTCON_DOCK,
 	EXTCON_NONE,
 };
 
 /*
  * max77693_muic_set_debounce_time - Set the debounce time of ADC
  * @info: the instance including private data of max77693 MUIC
  * @time: the debounce time of ADC
  */
 static int max77693_muic_set_debounce_time(struct max77693_muic_info *info,
 		enum max77693_muic_adc_debounce_time time)
 {
 	int ret;
 
 	switch (time) {
 	case ADC_DEBOUNCE_TIME_5MS:
 	case ADC_DEBOUNCE_TIME_10MS:
 	case ADC_DEBOUNCE_TIME_25MS:
 	case ADC_DEBOUNCE_TIME_38_62MS:
 		/*
 		 * Don't touch BTLDset, JIGset when you want to change adc
 		 * debounce time. If it writes other than 0 to BTLDset, JIGset
 		 * muic device will be reset and loose current state.
 		 */
 		ret = regmap_write(info->max77693->regmap_muic,
 				  MAX77693_MUIC_REG_CTRL3,
 				  time << MAX77693_CONTROL3_ADCDBSET_SHIFT);
 		if (ret) {
 			dev_err(info->dev, "failed to set ADC debounce time\n");
 			return ret;
 		}
 		break;
 	default:
 		dev_err(info->dev, "invalid ADC debounce time\n");
 		return -EINVAL;
 	}
 
 	return 0;
 };
 
 /*
  * max77693_muic_set_path - Set hardware line according to attached cable
  * @info: the instance including private data of max77693 MUIC
  * @value: the path according to attached cable
  * @attached: the state of cable (true:attached, false:detached)
  *
  * The max77693 MUIC device share outside H/W line among a varity of cables
  * so, this function set internal path of H/W line according to the type of
  * attached cable.
  */
 static int max77693_muic_set_path(struct max77693_muic_info *info,
 		u8 val, bool attached)
 {
 	int ret = 0;
 	unsigned int ctrl1, ctrl2 = 0;
 
 	if (attached)
 		ctrl1 = val;
 	else
 		ctrl1 = MAX77693_CONTROL1_SW_OPEN;
 
 	ret = regmap_update_bits(info->max77693->regmap_muic,
 			MAX77693_MUIC_REG_CTRL1, COMP_SW_MASK, ctrl1);
 	if (ret < 0) {
 		dev_err(info->dev, "failed to update MUIC register\n");
 		return ret;
 	}
 
 	if (attached)
 		ctrl2 |= MAX77693_CONTROL2_CPEN_MASK;	/* LowPwr=0, CPEn=1 */
 	else
 		ctrl2 |= MAX77693_CONTROL2_LOWPWR_MASK;	/* LowPwr=1, CPEn=0 */
 
 	ret = regmap_update_bits(info->max77693->regmap_muic,
 			MAX77693_MUIC_REG_CTRL2,
 			MAX77693_CONTROL2_LOWPWR_MASK | MAX77693_CONTROL2_CPEN_MASK,
 			ctrl2);
 	if (ret < 0) {
 		dev_err(info->dev, "failed to update MUIC register\n");
 		return ret;
 	}
 
 	dev_info(info->dev,
 		"CONTROL1 : 0x%02x, CONTROL2 : 0x%02x, state : %s\n",
 		ctrl1, ctrl2, attached ? "attached" : "detached");
 
 	return 0;
 }
 
 /*
  * max77693_muic_get_cable_type - Return cable type and check cable state
  * @info: the instance including private data of max77693 MUIC
  * @group: the path according to attached cable
  * @attached: store cable state and return
  *
  * This function check the cable state either attached or detached,
  * and then divide precise type of cable according to cable group.
  *	- MAX77693_CABLE_GROUP_ADC
  *	- MAX77693_CABLE_GROUP_ADC_GND
  *	- MAX77693_CABLE_GROUP_CHG
  *	- MAX77693_CABLE_GROUP_VBVOLT
  */
 static int max77693_muic_get_cable_type(struct max77693_muic_info *info,
 		enum max77693_muic_cable_group group, bool *attached)
 {
 	int cable_type = 0;
 	int adc;
 	int adc1k;
 	int adclow;
 	int vbvolt;
 	int chg_type;
 
 	switch (group) {
 	case MAX77693_CABLE_GROUP_ADC:
 		/*
 		 * Read ADC value to check cable type and decide cable state
 		 * according to cable type
 		 */
 		adc = info->status[0] & MAX77693_STATUS1_ADC_MASK;
 		adc >>= MAX77693_STATUS1_ADC_SHIFT;
 
 		/*
 		 * Check current cable state/cable type and store cable type
 		 * (info->prev_cable_type) for handling cable when cable is
 		 * detached.
 		 */
 		if (adc == MAX77693_MUIC_ADC_OPEN) {
 			*attached = false;
 
 			cable_type = info->prev_cable_type;
 			info->prev_cable_type = MAX77693_MUIC_ADC_OPEN;
 		} else {
 			*attached = true;
 
 			cable_type = info->prev_cable_type = adc;
 		}
 		break;
 	case MAX77693_CABLE_GROUP_ADC_GND:
 		/*
 		 * Read ADC value to check cable type and decide cable state
 		 * according to cable type
 		 */
 		adc = info->status[0] & MAX77693_STATUS1_ADC_MASK;
 		adc >>= MAX77693_STATUS1_ADC_SHIFT;
 
 		/*
 		 * Check current cable state/cable type and store cable type
 		 * (info->prev_cable_type/_gnd) for handling cable when cable
 		 * is detached.
 		 */
 		if (adc == MAX77693_MUIC_ADC_OPEN) {
 			*attached = false;
 
 			cable_type = info->prev_cable_type_gnd;
 			info->prev_cable_type_gnd = MAX77693_MUIC_ADC_OPEN;
 		} else {
 			*attached = true;
 
 			adclow = info->status[0] & MAX77693_STATUS1_ADCLOW_MASK;
 			adclow >>= MAX77693_STATUS1_ADCLOW_SHIFT;
 			adc1k = info->status[0] & MAX77693_STATUS1_ADC1K_MASK;
 			adc1k >>= MAX77693_STATUS1_ADC1K_SHIFT;
 
 			vbvolt = info->status[1] & MAX77693_STATUS2_VBVOLT_MASK;
 			vbvolt >>= MAX77693_STATUS2_VBVOLT_SHIFT;
 
 			/**
 			 * [0x1|VBVolt|ADCLow|ADC1K]
 			 * [0x1|     0|     0|    0] USB_HOST
 			 * [0x1|     1|     0|    0] USB_HSOT_VB
 			 * [0x1|     0|     1|    0] Audio Video cable with load
 			 * [0x1|     0|     1|    1] MHL without charging cable
 			 * [0x1|     1|     1|    1] MHL with charging cable
 			 */
 			cable_type = ((0x1 << 8)
 					| (vbvolt << 2)
 					| (adclow << 1)
 					| adc1k);
 
 			info->prev_cable_type = adc;
 			info->prev_cable_type_gnd = cable_type;
 		}
 
 		break;
 	case MAX77693_CABLE_GROUP_CHG:
 		/*
 		 * Read charger type to check cable type and decide cable state
 		 * according to type of charger cable.
 		 */
 		chg_type = info->status[1] & MAX77693_STATUS2_CHGTYP_MASK;
 		chg_type >>= MAX77693_STATUS2_CHGTYP_SHIFT;
 
 		if (chg_type == MAX77693_CHARGER_TYPE_NONE) {
 			*attached = false;
 
 			cable_type = info->prev_chg_type;
 			info->prev_chg_type = MAX77693_CHARGER_TYPE_NONE;
 		} else {
 			*attached = true;
 
 			/*
 			 * Check current cable state/cable type and store cable
 			 * type(info->prev_chg_type) for handling cable when
 			 * charger cable is detached.
 			 */
 			cable_type = info->prev_chg_type = chg_type;
 		}
 
 		break;
 	case MAX77693_CABLE_GROUP_VBVOLT:
 		/*
 		 * Read ADC value to check cable type and decide cable state
 		 * according to cable type
 		 */
 		adc = info->status[0] & MAX77693_STATUS1_ADC_MASK;
 		adc >>= MAX77693_STATUS1_ADC_SHIFT;
 		chg_type = info->status[1] & MAX77693_STATUS2_CHGTYP_MASK;
 		chg_type >>= MAX77693_STATUS2_CHGTYP_SHIFT;
 
 		if (adc == MAX77693_MUIC_ADC_OPEN
 				&& chg_type == MAX77693_CHARGER_TYPE_NONE)
 			*attached = false;
 		else
 			*attached = true;
 
 		/*
 		 * Read vbvolt field, if vbvolt is 1,
 		 * this cable is used for charging.
 		 */
 		vbvolt = info->status[1] & MAX77693_STATUS2_VBVOLT_MASK;
 		vbvolt >>= MAX77693_STATUS2_VBVOLT_SHIFT;
 
 		cable_type = vbvolt;
 		break;
 	default:
 		dev_err(info->dev, "Unknown cable group (%d)\n", group);
 		cable_type = -EINVAL;
 		break;
 	}
 
 	return cable_type;
 }
 
 static int max77693_muic_dock_handler(struct max77693_muic_info *info,
 		int cable_type, bool attached)
 {
 	int ret = 0;
 	int vbvolt;
 	bool cable_attached;
 	unsigned int dock_id;
 
 	dev_info(info->dev,
 		"external connector is %s (adc:0x%02x)\n",
 		attached ? "attached" : "detached", cable_type);
 
 	switch (cable_type) {
 	case MAX77693_MUIC_ADC_RESERVED_ACC_3:		/* Dock-Smart */
 		/*
 		 * Check power cable whether attached or detached state.
 		 * The Dock-Smart device need surely external power supply.
 		 * If power cable(USB/TA) isn't connected to Dock device,
 		 * user can't use Dock-Smart for desktop mode.
 		 */
 		vbvolt = max77693_muic_get_cable_type(info,
 				MAX77693_CABLE_GROUP_VBVOLT, &cable_attached);
 		if (attached && !vbvolt) {
 			dev_warn(info->dev,
 				"Cannot detect external power supply\n");
 			return 0;
 		}
 
 		/*
 		 * Notify Dock/MHL state.
 		 * - Dock device include three type of cable which
 		 * are HDMI, USB for mouse/keyboard and micro-usb port
 		 * for USB/TA cable. Dock device need always exteranl
 		 * power supply(USB/TA cable through micro-usb cable). Dock
 		 * device support screen output of target to separate
 		 * monitor and mouse/keyboard for desktop mode.
 		 *
 		 * Features of 'USB/TA cable with Dock device'
 		 * - Support MHL
 		 * - Support external output feature of audio
 		 * - Support charging through micro-usb port without data
 		 *	     connection if TA cable is connected to target.
 		 * - Support charging and data connection through micro-usb port
 		 *           if USB cable is connected between target and host
 		 *	     device.
 		 * - Support OTG(On-The-Go) device (Ex: Mouse/Keyboard)
 		 */
 		ret = max77693_muic_set_path(info, info->path_usb, attached);
 		if (ret < 0)
 			return ret;
 
 		extcon_set_state_sync(info->edev, EXTCON_DOCK, attached);
 		extcon_set_state_sync(info->edev, EXTCON_DISP_MHL, attached);
 		goto out;
 	case MAX77693_MUIC_ADC_AUDIO_MODE_REMOTE:	/* Dock-Desk */
 		dock_id = EXTCON_DOCK;
 		break;
 	case MAX77693_MUIC_ADC_AV_CABLE_NOLOAD:		/* Dock-Audio */
 		dock_id = EXTCON_DOCK;
 		if (!attached) {
 			extcon_set_state_sync(info->edev, EXTCON_USB, false);
 			extcon_set_state_sync(info->edev, EXTCON_CHG_USB_SDP,
 						false);
 		}
 		break;
 	default:
 		dev_err(info->dev, "failed to detect %s dock device\n",
 			attached ? "attached" : "detached");
 		return -EINVAL;
 	}
 
 	/* Dock-Car/Desk/Audio, PATH:AUDIO */
 	ret = max77693_muic_set_path(info, MAX77693_CONTROL1_SW_AUDIO,
 					attached);
 	if (ret < 0)
 		return ret;
 	extcon_set_state_sync(info->edev, dock_id, attached);
 
 out:
 	return 0;
 }
 
 static int max77693_muic_dock_button_handler(struct max77693_muic_info *info,
 		int button_type, bool attached)
 {
 	struct input_dev *dock = info->dock;
 	unsigned int code;
 
 	switch (button_type) {
 	case MAX77693_MUIC_ADC_REMOTE_S3_BUTTON-1
 		... MAX77693_MUIC_ADC_REMOTE_S3_BUTTON+1:
 		/* DOCK_KEY_PREV */
 		code = KEY_PREVIOUSSONG;
 		break;
 	case MAX77693_MUIC_ADC_REMOTE_S7_BUTTON-1
 		... MAX77693_MUIC_ADC_REMOTE_S7_BUTTON+1:
 		/* DOCK_KEY_NEXT */
 		code = KEY_NEXTSONG;
 		break;
 	case MAX77693_MUIC_ADC_REMOTE_S9_BUTTON:
 		/* DOCK_VOL_DOWN */
 		code = KEY_VOLUMEDOWN;
 		break;
 	case MAX77693_MUIC_ADC_REMOTE_S10_BUTTON:
 		/* DOCK_VOL_UP */
 		code = KEY_VOLUMEUP;
 		break;
 	case MAX77693_MUIC_ADC_REMOTE_S12_BUTTON-1
 		... MAX77693_MUIC_ADC_REMOTE_S12_BUTTON+1:
 		/* DOCK_KEY_PLAY_PAUSE */
 		code = KEY_PLAYPAUSE;
 		break;
 	default:
 		dev_err(info->dev,
 			"failed to detect %s key (adc:0x%x)\n",
 			attached ? "pressed" : "released", button_type);
 		return -EINVAL;
 	}
 
 	input_event(dock, EV_KEY, code, attached);
 	input_sync(dock);
 
 	return 0;
 }
 
 static int max77693_muic_adc_ground_handler(struct max77693_muic_info *info)
 {
 	int cable_type_gnd;
 	int ret = 0;
 	bool attached;
 
 	cable_type_gnd = max77693_muic_get_cable_type(info,
 				MAX77693_CABLE_GROUP_ADC_GND, &attached);
 
 	switch (cable_type_gnd) {
 	case MAX77693_MUIC_GND_USB_HOST:
 	case MAX77693_MUIC_GND_USB_HOST_VB:
 		/* USB_HOST, PATH: AP_USB */
 		ret = max77693_muic_set_path(info, MAX77693_CONTROL1_SW_USB,
 						attached);
 		if (ret < 0)
 			return ret;
 		extcon_set_state_sync(info->edev, EXTCON_USB_HOST, attached);
 		break;
 	case MAX77693_MUIC_GND_AV_CABLE_LOAD:
 		/* Audio Video Cable with load, PATH:AUDIO */
 		ret = max77693_muic_set_path(info, MAX77693_CONTROL1_SW_AUDIO,
 						attached);
 		if (ret < 0)
 			return ret;
 		extcon_set_state_sync(info->edev, EXTCON_USB, attached);
 		extcon_set_state_sync(info->edev, EXTCON_CHG_USB_SDP,
 					attached);
 		break;
 	case MAX77693_MUIC_GND_MHL:
 	case MAX77693_MUIC_GND_MHL_VB:
 		/* MHL or MHL with USB/TA cable */
 		extcon_set_state_sync(info->edev, EXTCON_DISP_MHL, attached);
 		break;
 	default:
 		dev_err(info->dev, "failed to detect %s cable of gnd type\n",
 			attached ? "attached" : "detached");
 		return -EINVAL;
 	}
 
 	return 0;
 }
 
 static int max77693_muic_jig_handler(struct max77693_muic_info *info,
 		int cable_type, bool attached)
 {
 	int ret = 0;
 	u8 path = MAX77693_CONTROL1_SW_OPEN;
 
 	dev_info(info->dev,
 		"external connector is %s (adc:0x%02x)\n",
 		attached ? "attached" : "detached", cable_type);
 
 	switch (cable_type) {
 	case MAX77693_MUIC_ADC_FACTORY_MODE_USB_OFF:	/* ADC_JIG_USB_OFF */
 	case MAX77693_MUIC_ADC_FACTORY_MODE_USB_ON:	/* ADC_JIG_USB_ON */
 		/* PATH:AP_USB */
 		path = MAX77693_CONTROL1_SW_USB;
 		break;
 	case MAX77693_MUIC_ADC_FACTORY_MODE_UART_OFF:	/* ADC_JIG_UART_OFF */
 	case MAX77693_MUIC_ADC_FACTORY_MODE_UART_ON:	/* ADC_JIG_UART_ON */
 		/* PATH:AP_UART */
 		path = MAX77693_CONTROL1_SW_UART;
 		break;
 	default:
 		dev_err(info->dev, "failed to detect %s jig cable\n",
 			attached ? "attached" : "detached");
 		return -EINVAL;
 	}
 
 	ret = max77693_muic_set_path(info, path, attached);
 	if (ret < 0)
 		return ret;
 
 	extcon_set_state_sync(info->edev, EXTCON_JIG, attached);
 
 	return 0;
 }
 
 static int max77693_muic_adc_handler(struct max77693_muic_info *info)
 {
 	int cable_type;
 	int button_type;
 	bool attached;
 	int ret = 0;
 
 	/* Check accessory state which is either detached or attached */
 	cable_type = max77693_muic_get_cable_type(info,
 				MAX77693_CABLE_GROUP_ADC, &attached);
 
 	dev_info(info->dev,
 		"external connector is %s (adc:0x%02x, prev_adc:0x%x)\n",
 		attached ? "attached" : "detached", cable_type,
 		info->prev_cable_type);
 
 	switch (cable_type) {
 	case MAX77693_MUIC_ADC_GROUND:
 		/* USB_HOST/MHL/Audio */
 		max77693_muic_adc_ground_handler(info);
 		break;
 	case MAX77693_MUIC_ADC_FACTORY_MODE_USB_OFF:
 	case MAX77693_MUIC_ADC_FACTORY_MODE_USB_ON:
 	case MAX77693_MUIC_ADC_FACTORY_MODE_UART_OFF:
 	case MAX77693_MUIC_ADC_FACTORY_MODE_UART_ON:
 		/* JIG */
 		ret = max77693_muic_jig_handler(info, cable_type, attached);
 		if (ret < 0)
 			return ret;
 		break;
 	case MAX77693_MUIC_ADC_RESERVED_ACC_3:		/* Dock-Smart */
 	case MAX77693_MUIC_ADC_AUDIO_MODE_REMOTE:	/* Dock-Desk */
 	case MAX77693_MUIC_ADC_AV_CABLE_NOLOAD:		/* Dock-Audio */
 		/*
 		 * DOCK device
 		 *
 		 * The MAX77693 MUIC device can detect total 34 cable type
 		 * except of charger cable and MUIC device didn't define
 		 * specfic role of cable in the range of from 0x01 to 0x12
 		 * of ADC value. So, can use/define cable with no role according
 		 * to schema of hardware board.
 		 */
 		ret = max77693_muic_dock_handler(info, cable_type, attached);
 		if (ret < 0)
 			return ret;
 		break;
 	case MAX77693_MUIC_ADC_REMOTE_S3_BUTTON:      /* DOCK_KEY_PREV */
 	case MAX77693_MUIC_ADC_REMOTE_S7_BUTTON:      /* DOCK_KEY_NEXT */
 	case MAX77693_MUIC_ADC_REMOTE_S9_BUTTON:      /* DOCK_VOL_DOWN */
 	case MAX77693_MUIC_ADC_REMOTE_S10_BUTTON:     /* DOCK_VOL_UP */
 	case MAX77693_MUIC_ADC_REMOTE_S12_BUTTON:     /* DOCK_KEY_PLAY_PAUSE */
 		/*
 		 * Button of DOCK device
 		 * - the Prev/Next/Volume Up/Volume Down/Play-Pause button
 		 *
 		 * The MAX77693 MUIC device can detect total 34 cable type
 		 * except of charger cable and MUIC device didn't define
 		 * specfic role of cable in the range of from 0x01 to 0x12
 		 * of ADC value. So, can use/define cable with no role according
 		 * to schema of hardware board.
 		 */
 		if (attached)
 			button_type = info->prev_button_type = cable_type;
 		else
 			button_type = info->prev_button_type;
 
 		ret = max77693_muic_dock_button_handler(info, button_type,
 							attached);
 		if (ret < 0)
 			return ret;
 		break;
 	case MAX77693_MUIC_ADC_SEND_END_BUTTON:
 	case MAX77693_MUIC_ADC_REMOTE_S1_BUTTON:
 	case MAX77693_MUIC_ADC_REMOTE_S2_BUTTON:
 	case MAX77693_MUIC_ADC_REMOTE_S4_BUTTON:
 	case MAX77693_MUIC_ADC_REMOTE_S5_BUTTON:
 	case MAX77693_MUIC_ADC_REMOTE_S6_BUTTON:
 	case MAX77693_MUIC_ADC_REMOTE_S8_BUTTON:
 	case MAX77693_MUIC_ADC_REMOTE_S11_BUTTON:
 	case MAX77693_MUIC_ADC_RESERVED_ACC_1:
 	case MAX77693_MUIC_ADC_RESERVED_ACC_2:
 	case MAX77693_MUIC_ADC_RESERVED_ACC_4:
 	case MAX77693_MUIC_ADC_RESERVED_ACC_5:
 	case MAX77693_MUIC_ADC_CEA936_AUDIO:
 	case MAX77693_MUIC_ADC_PHONE_POWERED_DEV:
 	case MAX77693_MUIC_ADC_TTY_CONVERTER:
 	case MAX77693_MUIC_ADC_UART_CABLE:
 	case MAX77693_MUIC_ADC_CEA936A_TYPE1_CHG:
 	case MAX77693_MUIC_ADC_CEA936A_TYPE2_CHG:
 		/*
 		 * This accessory isn't used in general case if it is specially
 		 * needed to detect additional accessory, should implement
 		 * proper operation when this accessory is attached/detached.
 		 */
 		dev_info(info->dev,
 			"accessory is %s but it isn't used (adc:0x%x)\n",
 			attached ? "attached" : "detached", cable_type);
 		return -EAGAIN;
 	default:
 		dev_err(info->dev,
 			"failed to detect %s accessory (adc:0x%x)\n",
 			attached ? "attached" : "detached", cable_type);
 		return -EINVAL;
 	}
 
 	return 0;
 }
 
 static int max77693_muic_chg_handler(struct max77693_muic_info *info)
 {
 	int chg_type;
 	int cable_type_gnd;
 	int cable_type;
 	bool attached;
 	bool cable_attached;
 	int ret = 0;
 
 	chg_type = max77693_muic_get_cable_type(info,
 				MAX77693_CABLE_GROUP_CHG, &attached);
 
 	dev_info(info->dev,
 		"external connector is %s(chg_type:0x%x, prev_chg_type:0x%x)\n",
 			attached ? "attached" : "detached",
 			chg_type, info->prev_chg_type);
 
 	switch (chg_type) {
 	case MAX77693_CHARGER_TYPE_USB:
 	case MAX77693_CHARGER_TYPE_DEDICATED_CHG:
 	case MAX77693_CHARGER_TYPE_NONE:
 		/* Check MAX77693_CABLE_GROUP_ADC_GND type */
 		cable_type_gnd = max77693_muic_get_cable_type(info,
 					MAX77693_CABLE_GROUP_ADC_GND,
 					&cable_attached);
 		switch (cable_type_gnd) {
 		case MAX77693_MUIC_GND_MHL:
 		case MAX77693_MUIC_GND_MHL_VB:
 			/*
 			 * MHL cable with USB/TA cable
 			 * - MHL cable include two port(HDMI line and separate
 			 * micro-usb port. When the target connect MHL cable,
 			 * extcon driver check whether USB/TA cable is
 			 * connected. If USB/TA cable is connected, extcon
 			 * driver notify state to notifiee for charging battery.
 			 *
 			 * Features of 'USB/TA with MHL cable'
 			 * - Support MHL
 			 * - Support charging through micro-usb port without
 			 *   data connection
 			 */
 			extcon_set_state_sync(info->edev, EXTCON_CHG_USB_DCP,
 						attached);
 			if (!cable_attached)
 				extcon_set_state_sync(info->edev,
 					EXTCON_DISP_MHL, cable_attached);
 			break;
 		}
 
 		/* Check MAX77693_CABLE_GROUP_ADC type */
 		cable_type = max77693_muic_get_cable_type(info,
 					MAX77693_CABLE_GROUP_ADC,
 					&cable_attached);
 		switch (cable_type) {
 		case MAX77693_MUIC_ADC_AV_CABLE_NOLOAD:		/* Dock-Audio */
 			/*
 			 * Dock-Audio device with USB/TA cable
 			 * - Dock device include two port(Dock-Audio and micro-
 			 * usb port). When the target connect Dock-Audio device,
 			 * extcon driver check whether USB/TA cable is connected
 			 * or not. If USB/TA cable is connected, extcon driver
 			 * notify state to notifiee for charging battery.
 			 *
 			 * Features of 'USB/TA cable with Dock-Audio device'
 			 * - Support external output feature of audio.
 			 * - Support charging through micro-usb port without
 			 *   data connection.
 			 */
 			extcon_set_state_sync(info->edev, EXTCON_USB,
 						attached);
 			extcon_set_state_sync(info->edev, EXTCON_CHG_USB_SDP,
 						attached);
 
 			if (!cable_attached)
 				extcon_set_state_sync(info->edev, EXTCON_DOCK,
 							cable_attached);
 			break;
 		case MAX77693_MUIC_ADC_RESERVED_ACC_3:		/* Dock-Smart */
 			/*
 			 * Dock-Smart device with USB/TA cable
 			 * - Dock-Desk device include three type of cable which
 			 * are HDMI, USB for mouse/keyboard and micro-usb port
 			 * for USB/TA cable. Dock-Smart device need always
 			 * exteranl power supply(USB/TA cable through micro-usb
 			 * cable). Dock-Smart device support screen output of
 			 * target to separate monitor and mouse/keyboard for
 			 * desktop mode.
 			 *
 			 * Features of 'USB/TA cable with Dock-Smart device'
 			 * - Support MHL
 			 * - Support external output feature of audio
 			 * - Support charging through micro-usb port without
 			 *   data connection if TA cable is connected to target.
 			 * - Support charging and data connection through micro-
 			 *   usb port if USB cable is connected between target
 			 *   and host device
 			 * - Support OTG(On-The-Go) device (Ex: Mouse/Keyboard)
 			 */
 			ret = max77693_muic_set_path(info, info->path_usb,
 						    attached);
 			if (ret < 0)
 				return ret;
 
 			extcon_set_state_sync(info->edev, EXTCON_DOCK,
 						attached);
 			extcon_set_state_sync(info->edev, EXTCON_DISP_MHL,
 						attached);
 			break;
 		}
 
 		/* Check MAX77693_CABLE_GROUP_CHG type */
 		switch (chg_type) {
 		case MAX77693_CHARGER_TYPE_NONE:
 			/*
 			 * When MHL(with USB/TA cable) or Dock-Audio with USB/TA
 			 * cable is attached, muic device happen below two irq.
 			 * - 'MAX77693_MUIC_IRQ_INT1_ADC' for detecting
 			 *    MHL/Dock-Audio.
 			 * - 'MAX77693_MUIC_IRQ_INT2_CHGTYP' for detecting
 			 *    USB/TA cable connected to MHL or Dock-Audio.
 			 * Always, happen eariler MAX77693_MUIC_IRQ_INT1_ADC
 			 * irq than MAX77693_MUIC_IRQ_INT2_CHGTYP irq.
 			 *
 			 * If user attach MHL (with USB/TA cable and immediately
 			 * detach MHL with USB/TA cable before MAX77693_MUIC_IRQ
 			 * _INT2_CHGTYP irq is happened, USB/TA cable remain
 			 * connected state to target. But USB/TA cable isn't
 			 * connected to target. The user be face with unusual
 			 * action. So, driver should check this situation in
 			 * spite of, that previous charger type is N/A.
 			 */
 			break;
 		case MAX77693_CHARGER_TYPE_USB:
 			/* Only USB cable, PATH:AP_USB */
 			ret = max77693_muic_set_path(info, info->path_usb,
 						    attached);
 			if (ret < 0)
 				return ret;
 
 			extcon_set_state_sync(info->edev, EXTCON_USB,
 						attached);
 			extcon_set_state_sync(info->edev, EXTCON_CHG_USB_SDP,
 						attached);
 			break;
 		case MAX77693_CHARGER_TYPE_DEDICATED_CHG:
 			/* Only TA cable */
 			extcon_set_state_sync(info->edev, EXTCON_CHG_USB_DCP,
 						attached);
 			break;
 		}
 		break;
 	case MAX77693_CHARGER_TYPE_DOWNSTREAM_PORT:
 		extcon_set_state_sync(info->edev, EXTCON_CHG_USB_CDP,
 					attached);
 		break;
 	case MAX77693_CHARGER_TYPE_APPLE_500MA:
 		extcon_set_state_sync(info->edev, EXTCON_CHG_USB_SLOW,
 					attached);
 		break;
 	case MAX77693_CHARGER_TYPE_APPLE_1A_2A:
 		extcon_set_state_sync(info->edev, EXTCON_CHG_USB_FAST,
 					attached);
 		break;
 	case MAX77693_CHARGER_TYPE_DEAD_BATTERY:
 		break;
 	default:
 		dev_err(info->dev,
 			"failed to detect %s accessory (chg_type:0x%x)\n",
 			attached ? "attached" : "detached", chg_type);
 		return -EINVAL;
 	}
 
 	return 0;
 }
 
 static void max77693_muic_irq_work(struct work_struct *work)
 {
 	struct max77693_muic_info *info = container_of(work,
 			struct max77693_muic_info, irq_work);
 	int irq_type = -1;
 	int i, ret = 0;
 
 	if (!info->edev)
 		return;
 
 	mutex_lock(&info->mutex);
 
 	for (i = 0; i < ARRAY_SIZE(muic_irqs); i++)
 		if (info->irq == muic_irqs[i].virq)
 			irq_type = muic_irqs[i].irq;
 
 	ret = regmap_bulk_read(info->max77693->regmap_muic,
 			MAX77693_MUIC_REG_STATUS1, info->status, 2);
 	if (ret) {
 		dev_err(info->dev, "failed to read MUIC register\n");
 		mutex_unlock(&info->mutex);
 		return;
 	}
 
 	switch (irq_type) {
 	case MAX77693_MUIC_IRQ_INT1_ADC:
 	case MAX77693_MUIC_IRQ_INT1_ADC_LOW:
 	case MAX77693_MUIC_IRQ_INT1_ADC_ERR:
 	case MAX77693_MUIC_IRQ_INT1_ADC1K:
-		/* Handle all of accessory except for
-		   type of charger accessory */
+		/*
+		 * Handle all of accessory except for
+		 * type of charger accessory.
+		 */
 		ret = max77693_muic_adc_handler(info);
 		break;
 	case MAX77693_MUIC_IRQ_INT2_CHGTYP:
 	case MAX77693_MUIC_IRQ_INT2_CHGDETREUN:
 	case MAX77693_MUIC_IRQ_INT2_DCDTMR:
 	case MAX77693_MUIC_IRQ_INT2_DXOVP:
 	case MAX77693_MUIC_IRQ_INT2_VBVOLT:
 	case MAX77693_MUIC_IRQ_INT2_VIDRM:
 		/* Handle charger accessory */
 		ret = max77693_muic_chg_handler(info);
 		break;
 	case MAX77693_MUIC_IRQ_INT3_EOC:
 	case MAX77693_MUIC_IRQ_INT3_CGMBC:
 	case MAX77693_MUIC_IRQ_INT3_OVP:
 	case MAX77693_MUIC_IRQ_INT3_MBCCHG_ERR:
 	case MAX77693_MUIC_IRQ_INT3_CHG_ENABLED:
 	case MAX77693_MUIC_IRQ_INT3_BAT_DET:
 		break;
 	default:
 		dev_err(info->dev, "muic interrupt: irq %d occurred\n",
 				irq_type);
 		mutex_unlock(&info->mutex);
 		return;
 	}
 
 	if (ret < 0)
 		dev_err(info->dev, "failed to handle MUIC interrupt\n");
 
 	mutex_unlock(&info->mutex);
 }
 
 static irqreturn_t max77693_muic_irq_handler(int irq, void *data)
 {
 	struct max77693_muic_info *info = data;
 
 	info->irq = irq;
 	schedule_work(&info->irq_work);
 
 	return IRQ_HANDLED;
 }
 
 static const struct regmap_config max77693_muic_regmap_config = {
 	.reg_bits = 8,
 	.val_bits = 8,
 };
 
 static int max77693_muic_detect_accessory(struct max77693_muic_info *info)
 {
 	int ret = 0;
 	int adc;
 	int chg_type;
 	bool attached;
 
 	mutex_lock(&info->mutex);
 
 	/* Read STATUSx register to detect accessory */
 	ret = regmap_bulk_read(info->max77693->regmap_muic,
 			MAX77693_MUIC_REG_STATUS1, info->status, 2);
 	if (ret) {
 		dev_err(info->dev, "failed to read MUIC register\n");
 		mutex_unlock(&info->mutex);
 		return ret;
 	}
 
 	adc = max77693_muic_get_cable_type(info, MAX77693_CABLE_GROUP_ADC,
 					&attached);
 	if (attached && adc != MAX77693_MUIC_ADC_OPEN) {
 		ret = max77693_muic_adc_handler(info);
 		if (ret < 0) {
 			dev_err(info->dev, "Cannot detect accessory\n");
 			mutex_unlock(&info->mutex);
 			return ret;
 		}
 	}
 
 	chg_type = max77693_muic_get_cable_type(info, MAX77693_CABLE_GROUP_CHG,
 					&attached);
 	if (attached && chg_type != MAX77693_CHARGER_TYPE_NONE) {
 		ret = max77693_muic_chg_handler(info);
 		if (ret < 0) {
 			dev_err(info->dev, "Cannot detect charger accessory\n");
 			mutex_unlock(&info->mutex);
 			return ret;
 		}
 	}
 
 	mutex_unlock(&info->mutex);
 
 	return 0;
 }
 
 static void max77693_muic_detect_cable_wq(struct work_struct *work)
 {
 	struct max77693_muic_info *info = container_of(to_delayed_work(work),
 				struct max77693_muic_info, wq_detcable);
 
 	max77693_muic_detect_accessory(info);
 }
 
 static int max77693_muic_probe(struct platform_device *pdev)
 {
 	struct max77693_dev *max77693 = dev_get_drvdata(pdev->dev.parent);
 	struct max77693_platform_data *pdata = dev_get_platdata(max77693->dev);
 	struct max77693_muic_info *info;
 	struct max77693_reg_data *init_data;
 	int num_init_data;
 	int delay_jiffies;
 	int ret;
 	int i;
 	unsigned int id;
 
 	info = devm_kzalloc(&pdev->dev, sizeof(struct max77693_muic_info),
 				   GFP_KERNEL);
 	if (!info)
 		return -ENOMEM;
 
 	info->dev = &pdev->dev;
 	info->max77693 = max77693;
 	if (info->max77693->regmap_muic) {
 		dev_dbg(&pdev->dev, "allocate register map\n");
 	} else {
 		info->max77693->regmap_muic = devm_regmap_init_i2c(
 						info->max77693->i2c_muic,
 						&max77693_muic_regmap_config);
 		if (IS_ERR(info->max77693->regmap_muic)) {
 			ret = PTR_ERR(info->max77693->regmap_muic);
 			dev_err(max77693->dev,
 				"failed to allocate register map: %d\n", ret);
 			return ret;
 		}
 	}
 
 	/* Register input device for button of dock device */
 	info->dock = devm_input_allocate_device(&pdev->dev);
 	if (!info->dock) {
 		dev_err(&pdev->dev, "%s: failed to allocate input\n", __func__);
 		return -ENOMEM;
 	}
 	info->dock->name = "max77693-muic/dock";
 	info->dock->phys = "max77693-muic/extcon";
 	info->dock->dev.parent = &pdev->dev;
 
 	__set_bit(EV_REP, info->dock->evbit);
 
 	input_set_capability(info->dock, EV_KEY, KEY_VOLUMEUP);
 	input_set_capability(info->dock, EV_KEY, KEY_VOLUMEDOWN);
 	input_set_capability(info->dock, EV_KEY, KEY_PLAYPAUSE);
 	input_set_capability(info->dock, EV_KEY, KEY_PREVIOUSSONG);
 	input_set_capability(info->dock, EV_KEY, KEY_NEXTSONG);
 
 	ret = input_register_device(info->dock);
 	if (ret < 0) {
 		dev_err(&pdev->dev, "Cannot register input device error(%d)\n",
 				ret);
 		return ret;
 	}
 
 	platform_set_drvdata(pdev, info);
 	mutex_init(&info->mutex);
 
 	INIT_WORK(&info->irq_work, max77693_muic_irq_work);
 
 	/* Support irq domain for MAX77693 MUIC device */
 	for (i = 0; i < ARRAY_SIZE(muic_irqs); i++) {
 		struct max77693_muic_irq *muic_irq = &muic_irqs[i];
 		int virq;
 
 		virq = regmap_irq_get_virq(max77693->irq_data_muic,
 					muic_irq->irq);
 		if (virq <= 0)
 			return -EINVAL;
 		muic_irq->virq = virq;
 
 		ret = devm_request_threaded_irq(&pdev->dev, virq, NULL,
 				max77693_muic_irq_handler,
 				IRQF_NO_SUSPEND,
 				muic_irq->name, info);
 		if (ret) {
 			dev_err(&pdev->dev,
 				"failed: irq request (IRQ: %d, error :%d)\n",
 				muic_irq->irq, ret);
 			return ret;
 		}
 	}
 
 	/* Initialize extcon device */
 	info->edev = devm_extcon_dev_allocate(&pdev->dev,
 					      max77693_extcon_cable);
 	if (IS_ERR(info->edev)) {
 		dev_err(&pdev->dev, "failed to allocate memory for extcon\n");
 		return -ENOMEM;
 	}
 
 	ret = devm_extcon_dev_register(&pdev->dev, info->edev);
 	if (ret) {
 		dev_err(&pdev->dev, "failed to register extcon device\n");
 		return ret;
 	}
 
 	/* Initialize MUIC register by using platform data or default data */
 	if (pdata && pdata->muic_data) {
 		init_data = pdata->muic_data->init_data;
 		num_init_data = pdata->muic_data->num_init_data;
 	} else {
 		init_data = default_init_data;
 		num_init_data = ARRAY_SIZE(default_init_data);
 	}
 
 	for (i = 0; i < num_init_data; i++) {
 		regmap_write(info->max77693->regmap_muic,
 				init_data[i].addr,
 				init_data[i].data);
 	}
 
 	if (pdata && pdata->muic_data) {
 		struct max77693_muic_platform_data *muic_pdata
 						   = pdata->muic_data;
 
 		/*
 		 * Default usb/uart path whether UART/USB or AUX_UART/AUX_USB
 		 * h/w path of COMP2/COMN1 on CONTROL1 register.
 		 */
 		if (muic_pdata->path_uart)
 			info->path_uart = muic_pdata->path_uart;
 		else
 			info->path_uart = MAX77693_CONTROL1_SW_UART;
 
 		if (muic_pdata->path_usb)
 			info->path_usb = muic_pdata->path_usb;
 		else
 			info->path_usb = MAX77693_CONTROL1_SW_USB;
 
 		/*
 		 * Default delay time for detecting cable state
 		 * after certain time.
 		 */
 		if (muic_pdata->detcable_delay_ms)
 			delay_jiffies =
 				msecs_to_jiffies(muic_pdata->detcable_delay_ms);
 		else
 			delay_jiffies = msecs_to_jiffies(DELAY_MS_DEFAULT);
 	} else {
 		info->path_usb = MAX77693_CONTROL1_SW_USB;
 		info->path_uart = MAX77693_CONTROL1_SW_UART;
 		delay_jiffies = msecs_to_jiffies(DELAY_MS_DEFAULT);
 	}
 
 	/* Set initial path for UART */
 	 max77693_muic_set_path(info, info->path_uart, true);
 
 	/* Check revision number of MUIC device*/
 	ret = regmap_read(info->max77693->regmap_muic,
 			MAX77693_MUIC_REG_ID, &id);
 	if (ret < 0) {
 		dev_err(&pdev->dev, "failed to read revision number\n");
 		return ret;
 	}
 	dev_info(info->dev, "device ID : 0x%x\n", id);
 
 	/* Set ADC debounce time */
 	max77693_muic_set_debounce_time(info, ADC_DEBOUNCE_TIME_25MS);
 
 	/*
 	 * Detect accessory after completing the initialization of platform
 	 *
 	 * - Use delayed workqueue to detect cable state and then
 	 * notify cable state to notifiee/platform through uevent.
 	 * After completing the booting of platform, the extcon provider
 	 * driver should notify cable state to upper layer.
 	 */
 	INIT_DELAYED_WORK(&info->wq_detcable, max77693_muic_detect_cable_wq);
 	queue_delayed_work(system_power_efficient_wq, &info->wq_detcable,
 			delay_jiffies);
 
 	return ret;
 }
 
 static int max77693_muic_remove(struct platform_device *pdev)
 {
 	struct max77693_muic_info *info = platform_get_drvdata(pdev);
 
 	cancel_work_sync(&info->irq_work);
 	input_unregister_device(info->dock);
 
 	return 0;
 }
 
 static struct platform_driver max77693_muic_driver = {
 	.driver		= {
 		.name	= DEV_NAME,
 	},
 	.probe		= max77693_muic_probe,
 	.remove		= max77693_muic_remove,
 };
 
 module_platform_driver(max77693_muic_driver);
 
 MODULE_DESCRIPTION("Maxim MAX77693 Extcon driver");
 MODULE_AUTHOR("Chanwoo Choi <cw00.choi@samsung.com>");
 MODULE_LICENSE("GPL");
 MODULE_ALIAS("platform:extcon-max77693");
diff --git a/drivers/extcon/extcon-max77843.c b/drivers/extcon/extcon-max77843.c
index 5d11fdf36e94..6e722d552cf1 100644
--- a/drivers/extcon/extcon-max77843.c
+++ b/drivers/extcon/extcon-max77843.c
@@ -1,887 +1,895 @@
 /*
  * extcon-max77843.c - Maxim MAX77843 extcon driver to support
  *			MUIC(Micro USB Interface Controller)
  *
  * Copyright (C) 2015 Samsung Electronics
  * Author: Jaewon Kim <jaewon02.kim@samsung.com>
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
  * the Free Software Foundation; either version 2 of the License, or
  * (at your option) any later version.
  */
 
 #include <linux/extcon.h>
 #include <linux/i2c.h>
 #include <linux/interrupt.h>
 #include <linux/kernel.h>
 #include <linux/mfd/max77693-common.h>
 #include <linux/mfd/max77843-private.h>
 #include <linux/module.h>
 #include <linux/platform_device.h>
 #include <linux/workqueue.h>
 
 #define DELAY_MS_DEFAULT		15000	/* unit: millisecond */
 
 enum max77843_muic_status {
 	MAX77843_MUIC_STATUS1 = 0,
 	MAX77843_MUIC_STATUS2,
 	MAX77843_MUIC_STATUS3,
 
 	MAX77843_MUIC_STATUS_NUM,
 };
 
 struct max77843_muic_info {
 	struct device *dev;
 	struct max77693_dev *max77843;
 	struct extcon_dev *edev;
 
 	struct mutex mutex;
 	struct work_struct irq_work;
 	struct delayed_work wq_detcable;
 
 	u8 status[MAX77843_MUIC_STATUS_NUM];
 	int prev_cable_type;
 	int prev_chg_type;
 	int prev_gnd_type;
 
 	bool irq_adc;
 	bool irq_chg;
 };
 
 enum max77843_muic_cable_group {
 	MAX77843_CABLE_GROUP_ADC = 0,
 	MAX77843_CABLE_GROUP_ADC_GND,
 	MAX77843_CABLE_GROUP_CHG,
 };
 
 enum max77843_muic_adc_debounce_time {
 	MAX77843_DEBOUNCE_TIME_5MS = 0,
 	MAX77843_DEBOUNCE_TIME_10MS,
 	MAX77843_DEBOUNCE_TIME_25MS,
 	MAX77843_DEBOUNCE_TIME_38_62MS,
 };
 
 /* Define accessory cable type */
 enum max77843_muic_accessory_type {
 	MAX77843_MUIC_ADC_GROUND = 0,
 	MAX77843_MUIC_ADC_SEND_END_BUTTON,
 	MAX77843_MUIC_ADC_REMOTE_S1_BUTTON,
 	MAX77843_MUIC_ADC_REMOTE_S2_BUTTON,
 	MAX77843_MUIC_ADC_REMOTE_S3_BUTTON,
 	MAX77843_MUIC_ADC_REMOTE_S4_BUTTON,
 	MAX77843_MUIC_ADC_REMOTE_S5_BUTTON,
 	MAX77843_MUIC_ADC_REMOTE_S6_BUTTON,
 	MAX77843_MUIC_ADC_REMOTE_S7_BUTTON,
 	MAX77843_MUIC_ADC_REMOTE_S8_BUTTON,
 	MAX77843_MUIC_ADC_REMOTE_S9_BUTTON,
 	MAX77843_MUIC_ADC_REMOTE_S10_BUTTON,
 	MAX77843_MUIC_ADC_REMOTE_S11_BUTTON,
 	MAX77843_MUIC_ADC_REMOTE_S12_BUTTON,
 	MAX77843_MUIC_ADC_RESERVED_ACC_1,
 	MAX77843_MUIC_ADC_RESERVED_ACC_2,
 	MAX77843_MUIC_ADC_RESERVED_ACC_3,
 	MAX77843_MUIC_ADC_RESERVED_ACC_4,
 	MAX77843_MUIC_ADC_RESERVED_ACC_5,
 	MAX77843_MUIC_ADC_AUDIO_DEVICE_TYPE2,
 	MAX77843_MUIC_ADC_PHONE_POWERED_DEV,
 	MAX77843_MUIC_ADC_TTY_CONVERTER,
 	MAX77843_MUIC_ADC_UART_CABLE,
 	MAX77843_MUIC_ADC_CEA936A_TYPE1_CHG,
 	MAX77843_MUIC_ADC_FACTORY_MODE_USB_OFF,
 	MAX77843_MUIC_ADC_FACTORY_MODE_USB_ON,
 	MAX77843_MUIC_ADC_AV_CABLE_NOLOAD,
 	MAX77843_MUIC_ADC_CEA936A_TYPE2_CHG,
 	MAX77843_MUIC_ADC_FACTORY_MODE_UART_OFF,
 	MAX77843_MUIC_ADC_FACTORY_MODE_UART_ON,
 	MAX77843_MUIC_ADC_AUDIO_DEVICE_TYPE1,
 	MAX77843_MUIC_ADC_OPEN,
 
-	/* The blow accessories should check
-	   not only ADC value but also ADC1K and VBVolt value. */
+	/*
+	 * The below accessories should check
+	 * not only ADC value but also ADC1K and VBVolt value.
+	 */
 						/* Offset|ADC1K|VBVolt| */
 	MAX77843_MUIC_GND_USB_HOST = 0x100,	/*    0x1|    0|     0| */
 	MAX77843_MUIC_GND_USB_HOST_VB = 0x101,	/*    0x1|    0|     1| */
 	MAX77843_MUIC_GND_MHL = 0x102,		/*    0x1|    1|     0| */
 	MAX77843_MUIC_GND_MHL_VB = 0x103,	/*    0x1|    1|     1| */
 };
 
 /* Define charger cable type */
 enum max77843_muic_charger_type {
 	MAX77843_MUIC_CHG_NONE = 0,
 	MAX77843_MUIC_CHG_USB,
 	MAX77843_MUIC_CHG_DOWNSTREAM,
 	MAX77843_MUIC_CHG_DEDICATED,
 	MAX77843_MUIC_CHG_SPECIAL_500MA,
 	MAX77843_MUIC_CHG_SPECIAL_1A,
 	MAX77843_MUIC_CHG_SPECIAL_BIAS,
 	MAX77843_MUIC_CHG_RESERVED,
 	MAX77843_MUIC_CHG_GND,
 };
 
 static const unsigned int max77843_extcon_cable[] = {
 	EXTCON_USB,
 	EXTCON_USB_HOST,
 	EXTCON_CHG_USB_SDP,
 	EXTCON_CHG_USB_DCP,
 	EXTCON_CHG_USB_CDP,
 	EXTCON_CHG_USB_FAST,
 	EXTCON_CHG_USB_SLOW,
 	EXTCON_DISP_MHL,
 	EXTCON_JIG,
 	EXTCON_NONE,
 };
 
 struct max77843_muic_irq {
 	unsigned int irq;
 	const char *name;
 	unsigned int virq;
 };
 
 static struct max77843_muic_irq max77843_muic_irqs[] = {
 	{ MAX77843_MUIC_IRQ_INT1_ADC,		"MUIC-ADC" },
 	{ MAX77843_MUIC_IRQ_INT1_ADCERROR,	"MUIC-ADC_ERROR" },
 	{ MAX77843_MUIC_IRQ_INT1_ADC1K,		"MUIC-ADC1K" },
 	{ MAX77843_MUIC_IRQ_INT2_CHGTYP,	"MUIC-CHGTYP" },
 	{ MAX77843_MUIC_IRQ_INT2_CHGDETRUN,	"MUIC-CHGDETRUN" },
 	{ MAX77843_MUIC_IRQ_INT2_DCDTMR,	"MUIC-DCDTMR" },
 	{ MAX77843_MUIC_IRQ_INT2_DXOVP,		"MUIC-DXOVP" },
 	{ MAX77843_MUIC_IRQ_INT2_VBVOLT,	"MUIC-VBVOLT" },
 	{ MAX77843_MUIC_IRQ_INT3_VBADC,		"MUIC-VBADC" },
 	{ MAX77843_MUIC_IRQ_INT3_VDNMON,	"MUIC-VDNMON" },
 	{ MAX77843_MUIC_IRQ_INT3_DNRES,		"MUIC-DNRES" },
 	{ MAX77843_MUIC_IRQ_INT3_MPNACK,	"MUIC-MPNACK"},
 	{ MAX77843_MUIC_IRQ_INT3_MRXBUFOW,	"MUIC-MRXBUFOW"},
 	{ MAX77843_MUIC_IRQ_INT3_MRXTRF,	"MUIC-MRXTRF"},
 	{ MAX77843_MUIC_IRQ_INT3_MRXPERR,	"MUIC-MRXPERR"},
 	{ MAX77843_MUIC_IRQ_INT3_MRXRDY,	"MUIC-MRXRDY"},
 };
 
 static const struct regmap_config max77843_muic_regmap_config = {
 	.reg_bits       = 8,
 	.val_bits       = 8,
 	.max_register   = MAX77843_MUIC_REG_END,
 };
 
 static const struct regmap_irq max77843_muic_irq[] = {
 	/* INT1 interrupt */
 	{ .reg_offset = 0, .mask = MAX77843_MUIC_ADC, },
 	{ .reg_offset = 0, .mask = MAX77843_MUIC_ADCERROR, },
 	{ .reg_offset = 0, .mask = MAX77843_MUIC_ADC1K, },
 
 	/* INT2 interrupt */
 	{ .reg_offset = 1, .mask = MAX77843_MUIC_CHGTYP, },
 	{ .reg_offset = 1, .mask = MAX77843_MUIC_CHGDETRUN, },
 	{ .reg_offset = 1, .mask = MAX77843_MUIC_DCDTMR, },
 	{ .reg_offset = 1, .mask = MAX77843_MUIC_DXOVP, },
 	{ .reg_offset = 1, .mask = MAX77843_MUIC_VBVOLT, },
 
 	/* INT3 interrupt */
 	{ .reg_offset = 2, .mask = MAX77843_MUIC_VBADC, },
 	{ .reg_offset = 2, .mask = MAX77843_MUIC_VDNMON, },
 	{ .reg_offset = 2, .mask = MAX77843_MUIC_DNRES, },
 	{ .reg_offset = 2, .mask = MAX77843_MUIC_MPNACK, },
 	{ .reg_offset = 2, .mask = MAX77843_MUIC_MRXBUFOW, },
 	{ .reg_offset = 2, .mask = MAX77843_MUIC_MRXTRF, },
 	{ .reg_offset = 2, .mask = MAX77843_MUIC_MRXPERR, },
 	{ .reg_offset = 2, .mask = MAX77843_MUIC_MRXRDY, },
 };
 
 static const struct regmap_irq_chip max77843_muic_irq_chip = {
 	.name           = "max77843-muic",
 	.status_base    = MAX77843_MUIC_REG_INT1,
 	.mask_base      = MAX77843_MUIC_REG_INTMASK1,
 	.mask_invert    = true,
 	.num_regs       = 3,
 	.irqs           = max77843_muic_irq,
 	.num_irqs       = ARRAY_SIZE(max77843_muic_irq),
 };
 
 static int max77843_muic_set_path(struct max77843_muic_info *info,
 		u8 val, bool attached)
 {
 	struct max77693_dev *max77843 = info->max77843;
 	int ret = 0;
 	unsigned int ctrl1, ctrl2;
 
 	if (attached)
 		ctrl1 = val;
 	else
 		ctrl1 = MAX77843_MUIC_CONTROL1_SW_OPEN;
 
 	ret = regmap_update_bits(max77843->regmap_muic,
 			MAX77843_MUIC_REG_CONTROL1,
 			MAX77843_MUIC_CONTROL1_COM_SW, ctrl1);
 	if (ret < 0) {
 		dev_err(info->dev, "Cannot switch MUIC port\n");
 		return ret;
 	}
 
 	if (attached)
 		ctrl2 = MAX77843_MUIC_CONTROL2_CPEN_MASK;
 	else
 		ctrl2 = MAX77843_MUIC_CONTROL2_LOWPWR_MASK;
 
 	ret = regmap_update_bits(max77843->regmap_muic,
 			MAX77843_MUIC_REG_CONTROL2,
 			MAX77843_MUIC_CONTROL2_LOWPWR_MASK |
 			MAX77843_MUIC_CONTROL2_CPEN_MASK, ctrl2);
 	if (ret < 0) {
 		dev_err(info->dev, "Cannot update lowpower mode\n");
 		return ret;
 	}
 
 	dev_dbg(info->dev,
 		"CONTROL1 : 0x%02x, CONTROL2 : 0x%02x, state : %s\n",
 		ctrl1, ctrl2, attached ? "attached" : "detached");
 
 	return 0;
 }
 
 static int max77843_muic_get_cable_type(struct max77843_muic_info *info,
 		enum max77843_muic_cable_group group, bool *attached)
 {
 	int adc, chg_type, cable_type, gnd_type;
 
 	adc = info->status[MAX77843_MUIC_STATUS1] &
 			MAX77843_MUIC_STATUS1_ADC_MASK;
 	adc >>= MAX77843_MUIC_STATUS1_ADC_SHIFT;
 
 	switch (group) {
 	case MAX77843_CABLE_GROUP_ADC:
 		if (adc == MAX77843_MUIC_ADC_OPEN) {
 			*attached = false;
 			cable_type = info->prev_cable_type;
 			info->prev_cable_type = MAX77843_MUIC_ADC_OPEN;
 		} else {
 			*attached = true;
 			cable_type = info->prev_cable_type = adc;
 		}
 		break;
 	case MAX77843_CABLE_GROUP_CHG:
 		chg_type = info->status[MAX77843_MUIC_STATUS2] &
 				MAX77843_MUIC_STATUS2_CHGTYP_MASK;
 
 		/* Check GROUND accessory with charger cable */
 		if (adc == MAX77843_MUIC_ADC_GROUND) {
 			if (chg_type == MAX77843_MUIC_CHG_NONE) {
-				/* The following state when charger cable is
+				/*
+				 * The following state when charger cable is
 				 * disconnected but the GROUND accessory still
-				 * connected */
+				 * connected.
+				 */
 				*attached = false;
 				cable_type = info->prev_chg_type;
 				info->prev_chg_type = MAX77843_MUIC_CHG_NONE;
 			} else {
 
-				/* The following state when charger cable is
-				 * connected on the GROUND accessory */
+				/*
+				 * The following state when charger cable is
+				 * connected on the GROUND accessory.
+				 */
 				*attached = true;
 				cable_type = MAX77843_MUIC_CHG_GND;
 				info->prev_chg_type = MAX77843_MUIC_CHG_GND;
 			}
 			break;
 		}
 
 		if (chg_type == MAX77843_MUIC_CHG_NONE) {
 			*attached = false;
 			cable_type = info->prev_chg_type;
 			info->prev_chg_type = MAX77843_MUIC_CHG_NONE;
 		} else {
 			*attached = true;
 			cable_type = info->prev_chg_type = chg_type;
 		}
 		break;
 	case MAX77843_CABLE_GROUP_ADC_GND:
 		if (adc == MAX77843_MUIC_ADC_OPEN) {
 			*attached = false;
 			cable_type = info->prev_gnd_type;
 			info->prev_gnd_type = MAX77843_MUIC_ADC_OPEN;
 		} else {
 			*attached = true;
 
-			/* Offset|ADC1K|VBVolt|
+			/*
+			 * Offset|ADC1K|VBVolt|
 			 *    0x1|    0|     0| USB-HOST
 			 *    0x1|    0|     1| USB-HOST with VB
 			 *    0x1|    1|     0| MHL
-			 *    0x1|    1|     1| MHL with VB */
+			 *    0x1|    1|     1| MHL with VB
+			 */
 			/* Get ADC1K register bit */
 			gnd_type = (info->status[MAX77843_MUIC_STATUS1] &
 					MAX77843_MUIC_STATUS1_ADC1K_MASK);
 
 			/* Get VBVolt register bit */
 			gnd_type |= (info->status[MAX77843_MUIC_STATUS2] &
 					MAX77843_MUIC_STATUS2_VBVOLT_MASK);
 			gnd_type >>= MAX77843_MUIC_STATUS2_VBVOLT_SHIFT;
 
 			/* Offset of GND cable */
 			gnd_type |= MAX77843_MUIC_GND_USB_HOST;
 			cable_type = info->prev_gnd_type = gnd_type;
 		}
 		break;
 	default:
 		dev_err(info->dev, "Unknown cable group (%d)\n", group);
 		cable_type = -EINVAL;
 		break;
 	}
 
 	return cable_type;
 }
 
 static int max77843_muic_adc_gnd_handler(struct max77843_muic_info *info)
 {
 	int ret, gnd_cable_type;
 	bool attached;
 
 	gnd_cable_type = max77843_muic_get_cable_type(info,
 			MAX77843_CABLE_GROUP_ADC_GND, &attached);
 	dev_dbg(info->dev, "external connector is %s (gnd:0x%02x)\n",
 			attached ? "attached" : "detached", gnd_cable_type);
 
 	switch (gnd_cable_type) {
 	case MAX77843_MUIC_GND_USB_HOST:
 	case MAX77843_MUIC_GND_USB_HOST_VB:
 		ret = max77843_muic_set_path(info,
 					     MAX77843_MUIC_CONTROL1_SW_USB,
 					     attached);
 		if (ret < 0)
 			return ret;
 
 		extcon_set_state_sync(info->edev, EXTCON_USB_HOST, attached);
 		break;
 	case MAX77843_MUIC_GND_MHL_VB:
 	case MAX77843_MUIC_GND_MHL:
 		ret = max77843_muic_set_path(info,
 					     MAX77843_MUIC_CONTROL1_SW_OPEN,
 					     attached);
 		if (ret < 0)
 			return ret;
 
 		extcon_set_state_sync(info->edev, EXTCON_DISP_MHL, attached);
 		break;
 	default:
 		dev_err(info->dev, "failed to detect %s accessory(gnd:0x%x)\n",
 			attached ? "attached" : "detached", gnd_cable_type);
 		return -EINVAL;
 	}
 
 	return 0;
 }
 
 static int max77843_muic_jig_handler(struct max77843_muic_info *info,
 		int cable_type, bool attached)
 {
 	int ret;
 	u8 path = MAX77843_MUIC_CONTROL1_SW_OPEN;
 
 	dev_dbg(info->dev, "external connector is %s (adc:0x%02x)\n",
 			attached ? "attached" : "detached", cable_type);
 
 	switch (cable_type) {
 	case MAX77843_MUIC_ADC_FACTORY_MODE_USB_OFF:
 	case MAX77843_MUIC_ADC_FACTORY_MODE_USB_ON:
 		path = MAX77843_MUIC_CONTROL1_SW_USB;
 		break;
 	case MAX77843_MUIC_ADC_FACTORY_MODE_UART_OFF:
 		path = MAX77843_MUIC_CONTROL1_SW_UART;
 		break;
 	default:
 		return -EINVAL;
 	}
 
 	ret = max77843_muic_set_path(info, path, attached);
 	if (ret < 0)
 		return ret;
 
 	extcon_set_state_sync(info->edev, EXTCON_JIG, attached);
 
 	return 0;
 }
 
 static int max77843_muic_adc_handler(struct max77843_muic_info *info)
 {
 	int ret, cable_type;
 	bool attached;
 
 	cable_type = max77843_muic_get_cable_type(info,
 			MAX77843_CABLE_GROUP_ADC, &attached);
 
 	dev_dbg(info->dev,
 		"external connector is %s (adc:0x%02x, prev_adc:0x%x)\n",
 		attached ? "attached" : "detached", cable_type,
 		info->prev_cable_type);
 
 	switch (cable_type) {
 	case MAX77843_MUIC_ADC_GROUND:
 		ret = max77843_muic_adc_gnd_handler(info);
 		if (ret < 0)
 			return ret;
 		break;
 	case MAX77843_MUIC_ADC_FACTORY_MODE_USB_OFF:
 	case MAX77843_MUIC_ADC_FACTORY_MODE_USB_ON:
 	case MAX77843_MUIC_ADC_FACTORY_MODE_UART_OFF:
 		ret = max77843_muic_jig_handler(info, cable_type, attached);
 		if (ret < 0)
 			return ret;
 		break;
 	case MAX77843_MUIC_ADC_SEND_END_BUTTON:
 	case MAX77843_MUIC_ADC_REMOTE_S1_BUTTON:
 	case MAX77843_MUIC_ADC_REMOTE_S2_BUTTON:
 	case MAX77843_MUIC_ADC_REMOTE_S3_BUTTON:
 	case MAX77843_MUIC_ADC_REMOTE_S4_BUTTON:
 	case MAX77843_MUIC_ADC_REMOTE_S5_BUTTON:
 	case MAX77843_MUIC_ADC_REMOTE_S6_BUTTON:
 	case MAX77843_MUIC_ADC_REMOTE_S7_BUTTON:
 	case MAX77843_MUIC_ADC_REMOTE_S8_BUTTON:
 	case MAX77843_MUIC_ADC_REMOTE_S9_BUTTON:
 	case MAX77843_MUIC_ADC_REMOTE_S10_BUTTON:
 	case MAX77843_MUIC_ADC_REMOTE_S11_BUTTON:
 	case MAX77843_MUIC_ADC_REMOTE_S12_BUTTON:
 	case MAX77843_MUIC_ADC_RESERVED_ACC_1:
 	case MAX77843_MUIC_ADC_RESERVED_ACC_2:
 	case MAX77843_MUIC_ADC_RESERVED_ACC_3:
 	case MAX77843_MUIC_ADC_RESERVED_ACC_4:
 	case MAX77843_MUIC_ADC_RESERVED_ACC_5:
 	case MAX77843_MUIC_ADC_AUDIO_DEVICE_TYPE2:
 	case MAX77843_MUIC_ADC_PHONE_POWERED_DEV:
 	case MAX77843_MUIC_ADC_TTY_CONVERTER:
 	case MAX77843_MUIC_ADC_UART_CABLE:
 	case MAX77843_MUIC_ADC_CEA936A_TYPE1_CHG:
 	case MAX77843_MUIC_ADC_AV_CABLE_NOLOAD:
 	case MAX77843_MUIC_ADC_CEA936A_TYPE2_CHG:
 	case MAX77843_MUIC_ADC_FACTORY_MODE_UART_ON:
 	case MAX77843_MUIC_ADC_AUDIO_DEVICE_TYPE1:
 	case MAX77843_MUIC_ADC_OPEN:
 		dev_err(info->dev,
 			"accessory is %s but it isn't used (adc:0x%x)\n",
 			attached ? "attached" : "detached", cable_type);
 		return -EAGAIN;
 	default:
 		dev_err(info->dev,
 			"failed to detect %s accessory (adc:0x%x)\n",
 			attached ? "attached" : "detached", cable_type);
 		return -EINVAL;
 	}
 
 	return 0;
 }
 
 static int max77843_muic_chg_handler(struct max77843_muic_info *info)
 {
 	int ret, chg_type, gnd_type;
 	bool attached;
 
 	chg_type = max77843_muic_get_cable_type(info,
 			MAX77843_CABLE_GROUP_CHG, &attached);
 
 	dev_dbg(info->dev,
 		"external connector is %s(chg_type:0x%x, prev_chg_type:0x%x)\n",
 		attached ? "attached" : "detached",
 		chg_type, info->prev_chg_type);
 
 	switch (chg_type) {
 	case MAX77843_MUIC_CHG_USB:
 		ret = max77843_muic_set_path(info,
 					     MAX77843_MUIC_CONTROL1_SW_USB,
 					     attached);
 		if (ret < 0)
 			return ret;
 
 		extcon_set_state_sync(info->edev, EXTCON_USB, attached);
 		extcon_set_state_sync(info->edev, EXTCON_CHG_USB_SDP,
 					attached);
 		break;
 	case MAX77843_MUIC_CHG_DOWNSTREAM:
 		ret = max77843_muic_set_path(info,
 					     MAX77843_MUIC_CONTROL1_SW_OPEN,
 					     attached);
 		if (ret < 0)
 			return ret;
 
 		extcon_set_state_sync(info->edev, EXTCON_CHG_USB_CDP,
 					attached);
 		break;
 	case MAX77843_MUIC_CHG_DEDICATED:
 		ret = max77843_muic_set_path(info,
 					     MAX77843_MUIC_CONTROL1_SW_OPEN,
 					     attached);
 		if (ret < 0)
 			return ret;
 
 		extcon_set_state_sync(info->edev, EXTCON_CHG_USB_DCP,
 					attached);
 		break;
 	case MAX77843_MUIC_CHG_SPECIAL_500MA:
 		ret = max77843_muic_set_path(info,
 					     MAX77843_MUIC_CONTROL1_SW_OPEN,
 					     attached);
 		if (ret < 0)
 			return ret;
 
 		extcon_set_state_sync(info->edev, EXTCON_CHG_USB_SLOW,
 					attached);
 		break;
 	case MAX77843_MUIC_CHG_SPECIAL_1A:
 		ret = max77843_muic_set_path(info,
 					     MAX77843_MUIC_CONTROL1_SW_OPEN,
 					     attached);
 		if (ret < 0)
 			return ret;
 
 		extcon_set_state_sync(info->edev, EXTCON_CHG_USB_FAST,
 					attached);
 		break;
 	case MAX77843_MUIC_CHG_GND:
 		gnd_type = max77843_muic_get_cable_type(info,
 				MAX77843_CABLE_GROUP_ADC_GND, &attached);
 
 		/* Charger cable on MHL accessory is attach or detach */
 		if (gnd_type == MAX77843_MUIC_GND_MHL_VB)
 			extcon_set_state_sync(info->edev, EXTCON_CHG_USB_DCP,
 						true);
 		else if (gnd_type == MAX77843_MUIC_GND_MHL)
 			extcon_set_state_sync(info->edev, EXTCON_CHG_USB_DCP,
 						false);
 		break;
 	case MAX77843_MUIC_CHG_NONE:
 		break;
 	default:
 		dev_err(info->dev,
 			"failed to detect %s accessory (chg_type:0x%x)\n",
 			attached ? "attached" : "detached", chg_type);
 
 		max77843_muic_set_path(info, MAX77843_MUIC_CONTROL1_SW_OPEN,
 				       attached);
 		return -EINVAL;
 	}
 
 	return 0;
 }
 
 static void max77843_muic_irq_work(struct work_struct *work)
 {
 	struct max77843_muic_info *info = container_of(work,
 			struct max77843_muic_info, irq_work);
 	struct max77693_dev *max77843 = info->max77843;
 	int ret = 0;
 
 	mutex_lock(&info->mutex);
 
 	ret = regmap_bulk_read(max77843->regmap_muic,
 			MAX77843_MUIC_REG_STATUS1, info->status,
 			MAX77843_MUIC_STATUS_NUM);
 	if (ret) {
 		dev_err(info->dev, "Cannot read STATUS registers\n");
 		mutex_unlock(&info->mutex);
 		return;
 	}
 
 	if (info->irq_adc) {
 		ret = max77843_muic_adc_handler(info);
 		if (ret)
 			dev_err(info->dev, "Unknown cable type\n");
 		info->irq_adc = false;
 	}
 
 	if (info->irq_chg) {
 		ret = max77843_muic_chg_handler(info);
 		if (ret)
 			dev_err(info->dev, "Unknown charger type\n");
 		info->irq_chg = false;
 	}
 
 	mutex_unlock(&info->mutex);
 }
 
 static irqreturn_t max77843_muic_irq_handler(int irq, void *data)
 {
 	struct max77843_muic_info *info = data;
 	int i, irq_type = -1;
 
 	for (i = 0; i < ARRAY_SIZE(max77843_muic_irqs); i++)
 		if (irq == max77843_muic_irqs[i].virq)
 			irq_type = max77843_muic_irqs[i].irq;
 
 	switch (irq_type) {
 	case MAX77843_MUIC_IRQ_INT1_ADC:
 	case MAX77843_MUIC_IRQ_INT1_ADCERROR:
 	case MAX77843_MUIC_IRQ_INT1_ADC1K:
 		info->irq_adc = true;
 		break;
 	case MAX77843_MUIC_IRQ_INT2_CHGTYP:
 	case MAX77843_MUIC_IRQ_INT2_CHGDETRUN:
 	case MAX77843_MUIC_IRQ_INT2_DCDTMR:
 	case MAX77843_MUIC_IRQ_INT2_DXOVP:
 	case MAX77843_MUIC_IRQ_INT2_VBVOLT:
 		info->irq_chg = true;
 		break;
 	case MAX77843_MUIC_IRQ_INT3_VBADC:
 	case MAX77843_MUIC_IRQ_INT3_VDNMON:
 	case MAX77843_MUIC_IRQ_INT3_DNRES:
 	case MAX77843_MUIC_IRQ_INT3_MPNACK:
 	case MAX77843_MUIC_IRQ_INT3_MRXBUFOW:
 	case MAX77843_MUIC_IRQ_INT3_MRXTRF:
 	case MAX77843_MUIC_IRQ_INT3_MRXPERR:
 	case MAX77843_MUIC_IRQ_INT3_MRXRDY:
 		break;
 	default:
 		dev_err(info->dev, "Cannot recognize IRQ(%d)\n", irq_type);
 		break;
 	}
 
 	schedule_work(&info->irq_work);
 
 	return IRQ_HANDLED;
 }
 
 static void max77843_muic_detect_cable_wq(struct work_struct *work)
 {
 	struct max77843_muic_info *info = container_of(to_delayed_work(work),
 			struct max77843_muic_info, wq_detcable);
 	struct max77693_dev *max77843 = info->max77843;
 	int chg_type, adc, ret;
 	bool attached;
 
 	mutex_lock(&info->mutex);
 
 	ret = regmap_bulk_read(max77843->regmap_muic,
 			MAX77843_MUIC_REG_STATUS1, info->status,
 			MAX77843_MUIC_STATUS_NUM);
 	if (ret) {
 		dev_err(info->dev, "Cannot read STATUS registers\n");
 		goto err_cable_wq;
 	}
 
 	adc = max77843_muic_get_cable_type(info,
 			MAX77843_CABLE_GROUP_ADC, &attached);
 	if (attached && adc != MAX77843_MUIC_ADC_OPEN) {
 		ret = max77843_muic_adc_handler(info);
 		if (ret < 0) {
 			dev_err(info->dev, "Cannot detect accessory\n");
 			goto err_cable_wq;
 		}
 	}
 
 	chg_type = max77843_muic_get_cable_type(info,
 			MAX77843_CABLE_GROUP_CHG, &attached);
 	if (attached && chg_type != MAX77843_MUIC_CHG_NONE) {
 		ret = max77843_muic_chg_handler(info);
 		if (ret < 0) {
 			dev_err(info->dev, "Cannot detect charger accessory\n");
 			goto err_cable_wq;
 		}
 	}
 
 err_cable_wq:
 	mutex_unlock(&info->mutex);
 }
 
 static int max77843_muic_set_debounce_time(struct max77843_muic_info *info,
 		enum max77843_muic_adc_debounce_time time)
 {
 	struct max77693_dev *max77843 = info->max77843;
 	int ret;
 
 	switch (time) {
 	case MAX77843_DEBOUNCE_TIME_5MS:
 	case MAX77843_DEBOUNCE_TIME_10MS:
 	case MAX77843_DEBOUNCE_TIME_25MS:
 	case MAX77843_DEBOUNCE_TIME_38_62MS:
 		ret = regmap_update_bits(max77843->regmap_muic,
 				MAX77843_MUIC_REG_CONTROL4,
 				MAX77843_MUIC_CONTROL4_ADCDBSET_MASK,
 				time << MAX77843_MUIC_CONTROL4_ADCDBSET_SHIFT);
 		if (ret < 0) {
 			dev_err(info->dev, "Cannot write MUIC regmap\n");
 			return ret;
 		}
 		break;
 	default:
 		dev_err(info->dev, "Invalid ADC debounce time\n");
 		return -EINVAL;
 	}
 
 	return 0;
 }
 
 static int max77843_init_muic_regmap(struct max77693_dev *max77843)
 {
 	int ret;
 
 	max77843->i2c_muic = i2c_new_dummy(max77843->i2c->adapter,
 			I2C_ADDR_MUIC);
 	if (!max77843->i2c_muic) {
 		dev_err(&max77843->i2c->dev,
 				"Cannot allocate I2C device for MUIC\n");
 		return -ENOMEM;
 	}
 
 	i2c_set_clientdata(max77843->i2c_muic, max77843);
 
 	max77843->regmap_muic = devm_regmap_init_i2c(max77843->i2c_muic,
 			&max77843_muic_regmap_config);
 	if (IS_ERR(max77843->regmap_muic)) {
 		ret = PTR_ERR(max77843->regmap_muic);
 		goto err_muic_i2c;
 	}
 
 	ret = regmap_add_irq_chip(max77843->regmap_muic, max77843->irq,
 			IRQF_TRIGGER_LOW | IRQF_ONESHOT | IRQF_SHARED,
 			0, &max77843_muic_irq_chip, &max77843->irq_data_muic);
 	if (ret < 0) {
 		dev_err(&max77843->i2c->dev, "Cannot add MUIC IRQ chip\n");
 		goto err_muic_i2c;
 	}
 
 	return 0;
 
 err_muic_i2c:
 	i2c_unregister_device(max77843->i2c_muic);
 
 	return ret;
 }
 
 static int max77843_muic_probe(struct platform_device *pdev)
 {
 	struct max77693_dev *max77843 = dev_get_drvdata(pdev->dev.parent);
 	struct max77843_muic_info *info;
 	unsigned int id;
 	int i, ret;
 
 	info = devm_kzalloc(&pdev->dev, sizeof(*info), GFP_KERNEL);
 	if (!info)
 		return -ENOMEM;
 
 	info->dev = &pdev->dev;
 	info->max77843 = max77843;
 
 	platform_set_drvdata(pdev, info);
 	mutex_init(&info->mutex);
 
 	/* Initialize i2c and regmap */
 	ret = max77843_init_muic_regmap(max77843);
 	if (ret) {
 		dev_err(&pdev->dev, "Failed to init MUIC regmap\n");
 		return ret;
 	}
 
 	/* Turn off auto detection configuration */
 	ret = regmap_update_bits(max77843->regmap_muic,
 			MAX77843_MUIC_REG_CONTROL4,
 			MAX77843_MUIC_CONTROL4_USBAUTO_MASK |
 			MAX77843_MUIC_CONTROL4_FCTAUTO_MASK,
 			CONTROL4_AUTO_DISABLE);
 
 	/* Initialize extcon device */
 	info->edev = devm_extcon_dev_allocate(&pdev->dev,
 			max77843_extcon_cable);
 	if (IS_ERR(info->edev)) {
 		dev_err(&pdev->dev, "Failed to allocate memory for extcon\n");
 		ret = -ENODEV;
 		goto err_muic_irq;
 	}
 
 	ret = devm_extcon_dev_register(&pdev->dev, info->edev);
 	if (ret) {
 		dev_err(&pdev->dev, "Failed to register extcon device\n");
 		goto err_muic_irq;
 	}
 
 	/* Set ADC debounce time */
 	max77843_muic_set_debounce_time(info, MAX77843_DEBOUNCE_TIME_25MS);
 
 	/* Set initial path for UART */
 	max77843_muic_set_path(info, MAX77843_MUIC_CONTROL1_SW_UART, true);
 
 	/* Check revision number of MUIC device */
 	ret = regmap_read(max77843->regmap_muic, MAX77843_MUIC_REG_ID, &id);
 	if (ret < 0) {
 		dev_err(&pdev->dev, "Failed to read revision number\n");
 		goto err_muic_irq;
 	}
 	dev_info(info->dev, "MUIC device ID : 0x%x\n", id);
 
 	/* Support virtual irq domain for max77843 MUIC device */
 	INIT_WORK(&info->irq_work, max77843_muic_irq_work);
 
 	/* Clear IRQ bits before request IRQs */
 	ret = regmap_bulk_read(max77843->regmap_muic,
 			MAX77843_MUIC_REG_INT1, info->status,
 			MAX77843_MUIC_STATUS_NUM);
 	if (ret) {
 		dev_err(&pdev->dev, "Failed to Clear IRQ bits\n");
 		goto err_muic_irq;
 	}
 
 	for (i = 0; i < ARRAY_SIZE(max77843_muic_irqs); i++) {
 		struct max77843_muic_irq *muic_irq = &max77843_muic_irqs[i];
 		int virq = 0;
 
 		virq = regmap_irq_get_virq(max77843->irq_data_muic,
 				muic_irq->irq);
 		if (virq <= 0) {
 			ret = -EINVAL;
 			goto err_muic_irq;
 		}
 		muic_irq->virq = virq;
 
 		ret = devm_request_threaded_irq(&pdev->dev, virq, NULL,
 				max77843_muic_irq_handler, IRQF_NO_SUSPEND,
 				muic_irq->name, info);
 		if (ret) {
 			dev_err(&pdev->dev,
 				"Failed to request irq (IRQ: %d, error: %d)\n",
 				muic_irq->irq, ret);
 			goto err_muic_irq;
 		}
 	}
 
 	/* Detect accessory after completing the initialization of platform */
 	INIT_DELAYED_WORK(&info->wq_detcable, max77843_muic_detect_cable_wq);
 	queue_delayed_work(system_power_efficient_wq,
 			&info->wq_detcable, msecs_to_jiffies(DELAY_MS_DEFAULT));
 
 	return 0;
 
 err_muic_irq:
 	regmap_del_irq_chip(max77843->irq, max77843->irq_data_muic);
 	i2c_unregister_device(max77843->i2c_muic);
 
 	return ret;
 }
 
 static int max77843_muic_remove(struct platform_device *pdev)
 {
 	struct max77843_muic_info *info = platform_get_drvdata(pdev);
 	struct max77693_dev *max77843 = info->max77843;
 
 	cancel_work_sync(&info->irq_work);
 	regmap_del_irq_chip(max77843->irq, max77843->irq_data_muic);
 	i2c_unregister_device(max77843->i2c_muic);
 
 	return 0;
 }
 
 static const struct platform_device_id max77843_muic_id[] = {
 	{ "max77843-muic", },
 	{ /* sentinel */ },
 };
 MODULE_DEVICE_TABLE(platform, max77843_muic_id);
 
 static struct platform_driver max77843_muic_driver = {
 	.driver		= {
 		.name		= "max77843-muic",
 	},
 	.probe		= max77843_muic_probe,
 	.remove		= max77843_muic_remove,
 	.id_table	= max77843_muic_id,
 };
 
 static int __init max77843_muic_init(void)
 {
 	return platform_driver_register(&max77843_muic_driver);
 }
 subsys_initcall(max77843_muic_init);
 
 MODULE_DESCRIPTION("Maxim MAX77843 Extcon driver");
 MODULE_AUTHOR("Jaewon Kim <jaewon02.kim@samsung.com>");
 MODULE_LICENSE("GPL");
diff --git a/drivers/extcon/extcon-palmas.c b/drivers/extcon/extcon-palmas.c
index 634ba70782de..ca904e8b3235 100644
--- a/drivers/extcon/extcon-palmas.c
+++ b/drivers/extcon/extcon-palmas.c
@@ -1,441 +1,446 @@
 /*
  * Palmas USB transceiver driver
  *
  * Copyright (C) 2013 Texas Instruments Incorporated - http://www.ti.com
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
  * the Free Software Foundation; either version 2 of the License, or
  * (at your option) any later version.
  *
  * Author: Graeme Gregory <gg@slimlogic.co.uk>
  * Author: Kishon Vijay Abraham I <kishon@ti.com>
  *
  * Based on twl6030_usb.c
  *
  * Author: Hema HK <hemahk@ti.com>
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
  */
 
 #include <linux/module.h>
 #include <linux/interrupt.h>
 #include <linux/platform_device.h>
 #include <linux/slab.h>
 #include <linux/err.h>
 #include <linux/mfd/palmas.h>
 #include <linux/of.h>
 #include <linux/of_platform.h>
 #include <linux/of_gpio.h>
 #include <linux/gpio/consumer.h>
 #include <linux/workqueue.h>
 
 #define USB_GPIO_DEBOUNCE_MS	20	/* ms */
 
 static const unsigned int palmas_extcon_cable[] = {
 	EXTCON_USB,
 	EXTCON_USB_HOST,
 	EXTCON_NONE,
 };
 
 static void palmas_usb_wakeup(struct palmas *palmas, int enable)
 {
 	if (enable)
 		palmas_write(palmas, PALMAS_USB_OTG_BASE, PALMAS_USB_WAKEUP,
 			PALMAS_USB_WAKEUP_ID_WK_UP_COMP);
 	else
 		palmas_write(palmas, PALMAS_USB_OTG_BASE, PALMAS_USB_WAKEUP, 0);
 }
 
 static irqreturn_t palmas_vbus_irq_handler(int irq, void *_palmas_usb)
 {
 	struct palmas_usb *palmas_usb = _palmas_usb;
 	struct extcon_dev *edev = palmas_usb->edev;
 	unsigned int vbus_line_state;
 
 	palmas_read(palmas_usb->palmas, PALMAS_INTERRUPT_BASE,
 		PALMAS_INT3_LINE_STATE, &vbus_line_state);
 
 	if (vbus_line_state & PALMAS_INT3_LINE_STATE_VBUS) {
 		if (palmas_usb->linkstat != PALMAS_USB_STATE_VBUS) {
 			palmas_usb->linkstat = PALMAS_USB_STATE_VBUS;
 			extcon_set_state_sync(edev, EXTCON_USB, true);
-			dev_info(palmas_usb->dev, "USB cable is attached\n");
+			dev_dbg(palmas_usb->dev, "USB cable is attached\n");
 		} else {
 			dev_dbg(palmas_usb->dev,
 				"Spurious connect event detected\n");
 		}
 	} else if (!(vbus_line_state & PALMAS_INT3_LINE_STATE_VBUS)) {
 		if (palmas_usb->linkstat == PALMAS_USB_STATE_VBUS) {
 			palmas_usb->linkstat = PALMAS_USB_STATE_DISCONNECT;
 			extcon_set_state_sync(edev, EXTCON_USB, false);
-			dev_info(palmas_usb->dev, "USB cable is detached\n");
+			dev_dbg(palmas_usb->dev, "USB cable is detached\n");
 		} else {
 			dev_dbg(palmas_usb->dev,
 				"Spurious disconnect event detected\n");
 		}
 	}
 
 	return IRQ_HANDLED;
 }
 
 static irqreturn_t palmas_id_irq_handler(int irq, void *_palmas_usb)
 {
 	unsigned int set, id_src;
 	struct palmas_usb *palmas_usb = _palmas_usb;
 	struct extcon_dev *edev = palmas_usb->edev;
 
 	palmas_read(palmas_usb->palmas, PALMAS_USB_OTG_BASE,
 		PALMAS_USB_ID_INT_LATCH_SET, &set);
 	palmas_read(palmas_usb->palmas, PALMAS_USB_OTG_BASE,
 		PALMAS_USB_ID_INT_SRC, &id_src);
 
 	if ((set & PALMAS_USB_ID_INT_SRC_ID_GND) &&
 				(id_src & PALMAS_USB_ID_INT_SRC_ID_GND)) {
 		palmas_write(palmas_usb->palmas, PALMAS_USB_OTG_BASE,
 			PALMAS_USB_ID_INT_LATCH_CLR,
 			PALMAS_USB_ID_INT_EN_HI_CLR_ID_GND);
 		palmas_usb->linkstat = PALMAS_USB_STATE_ID;
 		extcon_set_state_sync(edev, EXTCON_USB_HOST, true);
-		dev_info(palmas_usb->dev, "USB-HOST cable is attached\n");
+		dev_dbg(palmas_usb->dev, "USB-HOST cable is attached\n");
 	} else if ((set & PALMAS_USB_ID_INT_SRC_ID_FLOAT) &&
 				(id_src & PALMAS_USB_ID_INT_SRC_ID_FLOAT)) {
 		palmas_write(palmas_usb->palmas, PALMAS_USB_OTG_BASE,
 			PALMAS_USB_ID_INT_LATCH_CLR,
 			PALMAS_USB_ID_INT_EN_HI_CLR_ID_FLOAT);
 		palmas_usb->linkstat = PALMAS_USB_STATE_DISCONNECT;
 		extcon_set_state_sync(edev, EXTCON_USB_HOST, false);
-		dev_info(palmas_usb->dev, "USB-HOST cable is detached\n");
+		dev_dbg(palmas_usb->dev, "USB-HOST cable is detached\n");
 	} else if ((palmas_usb->linkstat == PALMAS_USB_STATE_ID) &&
 				(!(set & PALMAS_USB_ID_INT_SRC_ID_GND))) {
 		palmas_usb->linkstat = PALMAS_USB_STATE_DISCONNECT;
 		extcon_set_state_sync(edev, EXTCON_USB_HOST, false);
-		dev_info(palmas_usb->dev, "USB-HOST cable is detached\n");
+		dev_dbg(palmas_usb->dev, "USB-HOST cable is detached\n");
 	} else if ((palmas_usb->linkstat == PALMAS_USB_STATE_DISCONNECT) &&
 				(id_src & PALMAS_USB_ID_INT_SRC_ID_GND)) {
 		palmas_usb->linkstat = PALMAS_USB_STATE_ID;
 		extcon_set_state_sync(edev, EXTCON_USB_HOST, true);
-		dev_info(palmas_usb->dev, " USB-HOST cable is attached\n");
+		dev_dbg(palmas_usb->dev, " USB-HOST cable is attached\n");
 	}
 
 	return IRQ_HANDLED;
 }
 
 static void palmas_gpio_id_detect(struct work_struct *work)
 {
 	int id;
 	struct palmas_usb *palmas_usb = container_of(to_delayed_work(work),
 						     struct palmas_usb,
 						     wq_detectid);
 	struct extcon_dev *edev = palmas_usb->edev;
 
 	if (!palmas_usb->id_gpiod)
 		return;
 
 	id = gpiod_get_value_cansleep(palmas_usb->id_gpiod);
 
 	if (id) {
 		extcon_set_state_sync(edev, EXTCON_USB_HOST, false);
-		dev_info(palmas_usb->dev, "USB-HOST cable is detached\n");
+		dev_dbg(palmas_usb->dev, "USB-HOST cable is detached\n");
 	} else {
 		extcon_set_state_sync(edev, EXTCON_USB_HOST, true);
-		dev_info(palmas_usb->dev, "USB-HOST cable is attached\n");
+		dev_dbg(palmas_usb->dev, "USB-HOST cable is attached\n");
 	}
 }
 
 static irqreturn_t palmas_gpio_id_irq_handler(int irq, void *_palmas_usb)
 {
 	struct palmas_usb *palmas_usb = _palmas_usb;
 
 	queue_delayed_work(system_power_efficient_wq, &palmas_usb->wq_detectid,
 			   palmas_usb->sw_debounce_jiffies);
 
 	return IRQ_HANDLED;
 }
 
 static void palmas_enable_irq(struct palmas_usb *palmas_usb)
 {
 	palmas_write(palmas_usb->palmas, PALMAS_USB_OTG_BASE,
 		PALMAS_USB_VBUS_CTRL_SET,
 		PALMAS_USB_VBUS_CTRL_SET_VBUS_ACT_COMP);
 
 	if (palmas_usb->enable_id_detection) {
 		palmas_write(palmas_usb->palmas, PALMAS_USB_OTG_BASE,
 			     PALMAS_USB_ID_CTRL_SET,
 			     PALMAS_USB_ID_CTRL_SET_ID_ACT_COMP);
 
 		palmas_write(palmas_usb->palmas, PALMAS_USB_OTG_BASE,
 			     PALMAS_USB_ID_INT_EN_HI_SET,
 			     PALMAS_USB_ID_INT_EN_HI_SET_ID_GND |
 			     PALMAS_USB_ID_INT_EN_HI_SET_ID_FLOAT);
 	}
 
 	if (palmas_usb->enable_vbus_detection)
 		palmas_vbus_irq_handler(palmas_usb->vbus_irq, palmas_usb);
 
 	/* cold plug for host mode needs this delay */
 	if (palmas_usb->enable_id_detection) {
 		msleep(30);
 		palmas_id_irq_handler(palmas_usb->id_irq, palmas_usb);
 	}
 }
 
 static int palmas_usb_probe(struct platform_device *pdev)
 {
 	struct palmas *palmas = dev_get_drvdata(pdev->dev.parent);
 	struct palmas_usb_platform_data	*pdata = dev_get_platdata(&pdev->dev);
 	struct device_node *node = pdev->dev.of_node;
 	struct palmas_usb *palmas_usb;
 	int status;
 
+	if (!palmas) {
+		dev_err(&pdev->dev, "failed to get valid parent\n");
+		return -EINVAL;
+	}
+
 	palmas_usb = devm_kzalloc(&pdev->dev, sizeof(*palmas_usb), GFP_KERNEL);
 	if (!palmas_usb)
 		return -ENOMEM;
 
 	if (node && !pdata) {
 		palmas_usb->wakeup = of_property_read_bool(node, "ti,wakeup");
 		palmas_usb->enable_id_detection = of_property_read_bool(node,
 						"ti,enable-id-detection");
 		palmas_usb->enable_vbus_detection = of_property_read_bool(node,
 						"ti,enable-vbus-detection");
 	} else {
 		palmas_usb->wakeup = true;
 		palmas_usb->enable_id_detection = true;
 		palmas_usb->enable_vbus_detection = true;
 
 		if (pdata)
 			palmas_usb->wakeup = pdata->wakeup;
 	}
 
 	palmas_usb->id_gpiod = devm_gpiod_get_optional(&pdev->dev, "id",
 							GPIOD_IN);
 	if (IS_ERR(palmas_usb->id_gpiod)) {
 		dev_err(&pdev->dev, "failed to get id gpio\n");
 		return PTR_ERR(palmas_usb->id_gpiod);
 	}
 
 	palmas_usb->vbus_gpiod = devm_gpiod_get_optional(&pdev->dev, "vbus",
 							GPIOD_IN);
 	if (IS_ERR(palmas_usb->vbus_gpiod)) {
 		dev_err(&pdev->dev, "failed to get vbus gpio\n");
 		return PTR_ERR(palmas_usb->vbus_gpiod);
 	}
 
 	if (palmas_usb->enable_id_detection && palmas_usb->id_gpiod) {
 		palmas_usb->enable_id_detection = false;
 		palmas_usb->enable_gpio_id_detection = true;
 	}
 
 	if (palmas_usb->enable_vbus_detection && palmas_usb->vbus_gpiod) {
 		palmas_usb->enable_vbus_detection = false;
 		palmas_usb->enable_gpio_vbus_detection = true;
 	}
 
 	if (palmas_usb->enable_gpio_id_detection) {
 		u32 debounce;
 
 		if (of_property_read_u32(node, "debounce-delay-ms", &debounce))
 			debounce = USB_GPIO_DEBOUNCE_MS;
 
 		status = gpiod_set_debounce(palmas_usb->id_gpiod,
 					    debounce * 1000);
 		if (status < 0)
 			palmas_usb->sw_debounce_jiffies = msecs_to_jiffies(debounce);
 	}
 
 	INIT_DELAYED_WORK(&palmas_usb->wq_detectid, palmas_gpio_id_detect);
 
 	palmas->usb = palmas_usb;
 	palmas_usb->palmas = palmas;
 
 	palmas_usb->dev	 = &pdev->dev;
 
 	palmas_usb_wakeup(palmas, palmas_usb->wakeup);
 
 	platform_set_drvdata(pdev, palmas_usb);
 
 	palmas_usb->edev = devm_extcon_dev_allocate(&pdev->dev,
 						    palmas_extcon_cable);
 	if (IS_ERR(palmas_usb->edev)) {
 		dev_err(&pdev->dev, "failed to allocate extcon device\n");
 		return -ENOMEM;
 	}
 
 	status = devm_extcon_dev_register(&pdev->dev, palmas_usb->edev);
 	if (status) {
 		dev_err(&pdev->dev, "failed to register extcon device\n");
 		return status;
 	}
 
 	if (palmas_usb->enable_id_detection) {
 		palmas_usb->id_otg_irq = regmap_irq_get_virq(palmas->irq_data,
 							     PALMAS_ID_OTG_IRQ);
 		palmas_usb->id_irq = regmap_irq_get_virq(palmas->irq_data,
 							 PALMAS_ID_IRQ);
 		status = devm_request_threaded_irq(palmas_usb->dev,
 				palmas_usb->id_irq,
 				NULL, palmas_id_irq_handler,
 				IRQF_TRIGGER_FALLING | IRQF_TRIGGER_RISING |
 				IRQF_ONESHOT,
 				"palmas_usb_id", palmas_usb);
 		if (status < 0) {
 			dev_err(&pdev->dev, "can't get IRQ %d, err %d\n",
 					palmas_usb->id_irq, status);
 			return status;
 		}
 	} else if (palmas_usb->enable_gpio_id_detection) {
 		palmas_usb->gpio_id_irq = gpiod_to_irq(palmas_usb->id_gpiod);
 		if (palmas_usb->gpio_id_irq < 0) {
 			dev_err(&pdev->dev, "failed to get id irq\n");
 			return palmas_usb->gpio_id_irq;
 		}
 		status = devm_request_threaded_irq(&pdev->dev,
 						   palmas_usb->gpio_id_irq,
 						   NULL,
 						   palmas_gpio_id_irq_handler,
 						   IRQF_TRIGGER_RISING |
 						   IRQF_TRIGGER_FALLING |
 						   IRQF_ONESHOT,
 						   "palmas_usb_id",
 						   palmas_usb);
 		if (status < 0) {
 			dev_err(&pdev->dev,
 				"failed to request handler for id irq\n");
 			return status;
 		}
 	}
 
 	if (palmas_usb->enable_vbus_detection) {
 		palmas_usb->vbus_otg_irq = regmap_irq_get_virq(palmas->irq_data,
 						       PALMAS_VBUS_OTG_IRQ);
 		palmas_usb->vbus_irq = regmap_irq_get_virq(palmas->irq_data,
 							   PALMAS_VBUS_IRQ);
 		status = devm_request_threaded_irq(palmas_usb->dev,
 				palmas_usb->vbus_irq, NULL,
 				palmas_vbus_irq_handler,
 				IRQF_TRIGGER_FALLING | IRQF_TRIGGER_RISING |
 				IRQF_ONESHOT,
 				"palmas_usb_vbus", palmas_usb);
 		if (status < 0) {
 			dev_err(&pdev->dev, "can't get IRQ %d, err %d\n",
 					palmas_usb->vbus_irq, status);
 			return status;
 		}
 	} else if (palmas_usb->enable_gpio_vbus_detection) {
 		/* remux GPIO_1 as VBUSDET */
 		status = palmas_update_bits(palmas,
 			PALMAS_PU_PD_OD_BASE,
 			PALMAS_PRIMARY_SECONDARY_PAD1,
 			PALMAS_PRIMARY_SECONDARY_PAD1_GPIO_1_MASK,
 			(1 << PALMAS_PRIMARY_SECONDARY_PAD1_GPIO_1_SHIFT));
 		if (status < 0) {
 			dev_err(&pdev->dev, "can't remux GPIO1\n");
 			return status;
 		}
 
 		palmas_usb->vbus_otg_irq = regmap_irq_get_virq(palmas->irq_data,
 						       PALMAS_VBUS_OTG_IRQ);
 		palmas_usb->gpio_vbus_irq = gpiod_to_irq(palmas_usb->vbus_gpiod);
 		if (palmas_usb->gpio_vbus_irq < 0) {
 			dev_err(&pdev->dev, "failed to get vbus irq\n");
 			return palmas_usb->gpio_vbus_irq;
 		}
 		status = devm_request_threaded_irq(&pdev->dev,
 						palmas_usb->gpio_vbus_irq,
 						NULL,
 						palmas_vbus_irq_handler,
 						IRQF_TRIGGER_FALLING |
 						IRQF_TRIGGER_RISING |
 						IRQF_ONESHOT,
 						"palmas_usb_vbus",
 						palmas_usb);
 		if (status < 0) {
 			dev_err(&pdev->dev,
 				"failed to request handler for vbus irq\n");
 			return status;
 		}
 	}
 
 	palmas_enable_irq(palmas_usb);
 	/* perform initial detection */
 	if (palmas_usb->enable_gpio_vbus_detection)
 		palmas_vbus_irq_handler(palmas_usb->gpio_vbus_irq, palmas_usb);
 	palmas_gpio_id_detect(&palmas_usb->wq_detectid.work);
 	device_set_wakeup_capable(&pdev->dev, true);
 	return 0;
 }
 
 static int palmas_usb_remove(struct platform_device *pdev)
 {
 	struct palmas_usb *palmas_usb = platform_get_drvdata(pdev);
 
 	cancel_delayed_work_sync(&palmas_usb->wq_detectid);
 
 	return 0;
 }
 
 #ifdef CONFIG_PM_SLEEP
 static int palmas_usb_suspend(struct device *dev)
 {
 	struct palmas_usb *palmas_usb = dev_get_drvdata(dev);
 
 	if (device_may_wakeup(dev)) {
 		if (palmas_usb->enable_vbus_detection)
 			enable_irq_wake(palmas_usb->vbus_irq);
 		if (palmas_usb->enable_gpio_vbus_detection)
 			enable_irq_wake(palmas_usb->gpio_vbus_irq);
 		if (palmas_usb->enable_id_detection)
 			enable_irq_wake(palmas_usb->id_irq);
 		if (palmas_usb->enable_gpio_id_detection)
 			enable_irq_wake(palmas_usb->gpio_id_irq);
 	}
 	return 0;
 }
 
 static int palmas_usb_resume(struct device *dev)
 {
 	struct palmas_usb *palmas_usb = dev_get_drvdata(dev);
 
 	if (device_may_wakeup(dev)) {
 		if (palmas_usb->enable_vbus_detection)
 			disable_irq_wake(palmas_usb->vbus_irq);
 		if (palmas_usb->enable_gpio_vbus_detection)
 			disable_irq_wake(palmas_usb->gpio_vbus_irq);
 		if (palmas_usb->enable_id_detection)
 			disable_irq_wake(palmas_usb->id_irq);
 		if (palmas_usb->enable_gpio_id_detection)
 			disable_irq_wake(palmas_usb->gpio_id_irq);
 	}
 	return 0;
 };
 #endif
 
 static SIMPLE_DEV_PM_OPS(palmas_pm_ops, palmas_usb_suspend, palmas_usb_resume);
 
 static const struct of_device_id of_palmas_match_tbl[] = {
 	{ .compatible = "ti,palmas-usb", },
 	{ .compatible = "ti,palmas-usb-vid", },
 	{ .compatible = "ti,twl6035-usb", },
 	{ .compatible = "ti,twl6035-usb-vid", },
 	{ /* end */ }
 };
 
 static struct platform_driver palmas_usb_driver = {
 	.probe = palmas_usb_probe,
 	.remove = palmas_usb_remove,
 	.driver = {
 		.name = "palmas-usb",
 		.of_match_table = of_palmas_match_tbl,
 		.pm = &palmas_pm_ops,
 	},
 };
 
 module_platform_driver(palmas_usb_driver);
 
 MODULE_ALIAS("platform:palmas-usb");
 MODULE_AUTHOR("Graeme Gregory <gg@slimlogic.co.uk>");
 MODULE_DESCRIPTION("Palmas USB transceiver driver");
 MODULE_LICENSE("GPL");
 MODULE_DEVICE_TABLE(of, of_palmas_match_tbl);
diff --git a/drivers/extcon/extcon-rt8973a.c b/drivers/extcon/extcon-rt8973a.c
index 174c388739ea..3e882aa107e8 100644
--- a/drivers/extcon/extcon-rt8973a.c
+++ b/drivers/extcon/extcon-rt8973a.c
@@ -1,717 +1,719 @@
 /*
  * extcon-rt8973a.c - Richtek RT8973A extcon driver to support USB switches
  *
  * Copyright (c) 2014 Samsung Electronics Co., Ltd
  * Author: Chanwoo Choi <cw00.choi@samsung.com>
  *
  * This program is free software; you can redistribute  it and/or modify it
  * under  the terms of  the GNU General  Public License as published by the
  * Free Software Foundation;  either version 2 of the  License, or (at your
  * option) any later version.
  */
 
 #include <linux/err.h>
 #include <linux/i2c.h>
 #include <linux/input.h>
 #include <linux/interrupt.h>
 #include <linux/irqdomain.h>
 #include <linux/kernel.h>
 #include <linux/module.h>
 #include <linux/platform_device.h>
 #include <linux/regmap.h>
 #include <linux/slab.h>
 #include <linux/extcon.h>
 
 #include "extcon-rt8973a.h"
 
 #define	DELAY_MS_DEFAULT		20000	/* unit: millisecond */
 
 struct muic_irq {
 	unsigned int irq;
 	const char *name;
 	unsigned int virq;
 };
 
 struct reg_data {
 	u8 reg;
 	u8 mask;
 	u8 val;
 	bool invert;
 };
 
 struct rt8973a_muic_info {
 	struct device *dev;
 	struct extcon_dev *edev;
 
 	struct i2c_client *i2c;
 	struct regmap *regmap;
 
 	struct regmap_irq_chip_data *irq_data;
 	struct muic_irq *muic_irqs;
 	unsigned int num_muic_irqs;
 	int irq;
 	bool irq_attach;
 	bool irq_detach;
 	bool irq_ovp;
 	bool irq_otp;
 	struct work_struct irq_work;
 
 	struct reg_data *reg_data;
 	unsigned int num_reg_data;
 	bool auto_config;
 
 	struct mutex mutex;
 
 	/*
 	 * Use delayed workqueue to detect cable state and then
 	 * notify cable state to notifiee/platform through uevent.
 	 * After completing the booting of platform, the extcon provider
 	 * driver should notify cable state to upper layer.
 	 */
 	struct delayed_work wq_detcable;
 };
 
 /* Default value of RT8973A register to bring up MUIC device. */
 static struct reg_data rt8973a_reg_data[] = {
 	{
 		.reg = RT8973A_REG_CONTROL1,
 		.mask = RT8973A_REG_CONTROL1_ADC_EN_MASK
 			| RT8973A_REG_CONTROL1_USB_CHD_EN_MASK
 			| RT8973A_REG_CONTROL1_CHGTYP_MASK
 			| RT8973A_REG_CONTROL1_SWITCH_OPEN_MASK
 			| RT8973A_REG_CONTROL1_AUTO_CONFIG_MASK
 			| RT8973A_REG_CONTROL1_INTM_MASK,
 		.val = RT8973A_REG_CONTROL1_ADC_EN_MASK
 			| RT8973A_REG_CONTROL1_USB_CHD_EN_MASK
 			| RT8973A_REG_CONTROL1_CHGTYP_MASK,
 		.invert = false,
 	},
 	{ /* sentinel */ }
 };
 
 /* List of detectable cables */
 static const unsigned int rt8973a_extcon_cable[] = {
 	EXTCON_USB,
 	EXTCON_USB_HOST,
 	EXTCON_CHG_USB_SDP,
 	EXTCON_CHG_USB_DCP,
 	EXTCON_JIG,
 	EXTCON_NONE,
 };
 
 /* Define OVP (Over Voltage Protection), OTP (Over Temperature Protection) */
 enum rt8973a_event_type {
 	RT8973A_EVENT_ATTACH = 1,
 	RT8973A_EVENT_DETACH,
 	RT8973A_EVENT_OVP,
 	RT8973A_EVENT_OTP,
 };
 
 /* Define supported accessory type */
 enum rt8973a_muic_acc_type {
 	RT8973A_MUIC_ADC_OTG = 0x0,
 	RT8973A_MUIC_ADC_AUDIO_SEND_END_BUTTON,
 	RT8973A_MUIC_ADC_AUDIO_REMOTE_S1_BUTTON,
 	RT8973A_MUIC_ADC_AUDIO_REMOTE_S2_BUTTON,
 	RT8973A_MUIC_ADC_AUDIO_REMOTE_S3_BUTTON,
 	RT8973A_MUIC_ADC_AUDIO_REMOTE_S4_BUTTON,
 	RT8973A_MUIC_ADC_AUDIO_REMOTE_S5_BUTTON,
 	RT8973A_MUIC_ADC_AUDIO_REMOTE_S6_BUTTON,
 	RT8973A_MUIC_ADC_AUDIO_REMOTE_S7_BUTTON,
 	RT8973A_MUIC_ADC_AUDIO_REMOTE_S8_BUTTON,
 	RT8973A_MUIC_ADC_AUDIO_REMOTE_S9_BUTTON,
 	RT8973A_MUIC_ADC_AUDIO_REMOTE_S10_BUTTON,
 	RT8973A_MUIC_ADC_AUDIO_REMOTE_S11_BUTTON,
 	RT8973A_MUIC_ADC_AUDIO_REMOTE_S12_BUTTON,
 	RT8973A_MUIC_ADC_RESERVED_ACC_1,
 	RT8973A_MUIC_ADC_RESERVED_ACC_2,
 	RT8973A_MUIC_ADC_RESERVED_ACC_3,
 	RT8973A_MUIC_ADC_RESERVED_ACC_4,
 	RT8973A_MUIC_ADC_RESERVED_ACC_5,
 	RT8973A_MUIC_ADC_AUDIO_TYPE2,
 	RT8973A_MUIC_ADC_PHONE_POWERED_DEV,
 	RT8973A_MUIC_ADC_UNKNOWN_ACC_1,
 	RT8973A_MUIC_ADC_UNKNOWN_ACC_2,
 	RT8973A_MUIC_ADC_TA,
 	RT8973A_MUIC_ADC_FACTORY_MODE_BOOT_OFF_USB,
 	RT8973A_MUIC_ADC_FACTORY_MODE_BOOT_ON_USB,
 	RT8973A_MUIC_ADC_UNKNOWN_ACC_3,
 	RT8973A_MUIC_ADC_UNKNOWN_ACC_4,
 	RT8973A_MUIC_ADC_FACTORY_MODE_BOOT_OFF_UART,
 	RT8973A_MUIC_ADC_FACTORY_MODE_BOOT_ON_UART,
 	RT8973A_MUIC_ADC_UNKNOWN_ACC_5,
 	RT8973A_MUIC_ADC_OPEN = 0x1f,
 
-	/* The below accessories has same ADC value (0x1f).
-	   So, Device type1 is used to separate specific accessory. */
+	/*
+	 * The below accessories has same ADC value (0x1f).
+	 * So, Device type1 is used to separate specific accessory.
+	 */
 					/* |---------|--ADC| */
 					/* |    [7:5]|[4:0]| */
 	RT8973A_MUIC_ADC_USB = 0x3f,	/* |      001|11111| */
 };
 
 /* List of supported interrupt for RT8973A */
 static struct muic_irq rt8973a_muic_irqs[] = {
 	{ RT8973A_INT1_ATTACH,		"muic-attach" },
 	{ RT8973A_INT1_DETACH,		"muic-detach" },
 	{ RT8973A_INT1_CHGDET,		"muic-chgdet" },
 	{ RT8973A_INT1_DCD_T,		"muic-dcd-t" },
 	{ RT8973A_INT1_OVP,		"muic-ovp" },
 	{ RT8973A_INT1_CONNECT,		"muic-connect" },
 	{ RT8973A_INT1_ADC_CHG,		"muic-adc-chg" },
 	{ RT8973A_INT1_OTP,		"muic-otp" },
 	{ RT8973A_INT2_UVLO,		"muic-uvlo" },
 	{ RT8973A_INT2_POR,		"muic-por" },
 	{ RT8973A_INT2_OTP_FET,		"muic-otp-fet" },
 	{ RT8973A_INT2_OVP_FET,		"muic-ovp-fet" },
 	{ RT8973A_INT2_OCP_LATCH,	"muic-ocp-latch" },
 	{ RT8973A_INT2_OCP,		"muic-ocp" },
 	{ RT8973A_INT2_OVP_OCP,		"muic-ovp-ocp" },
 };
 
 /* Define interrupt list of RT8973A to register regmap_irq */
 static const struct regmap_irq rt8973a_irqs[] = {
 	/* INT1 interrupts */
 	{ .reg_offset = 0, .mask = RT8973A_INT1_ATTACH_MASK, },
 	{ .reg_offset = 0, .mask = RT8973A_INT1_DETACH_MASK, },
 	{ .reg_offset = 0, .mask = RT8973A_INT1_CHGDET_MASK, },
 	{ .reg_offset = 0, .mask = RT8973A_INT1_DCD_T_MASK, },
 	{ .reg_offset = 0, .mask = RT8973A_INT1_OVP_MASK, },
 	{ .reg_offset = 0, .mask = RT8973A_INT1_CONNECT_MASK, },
 	{ .reg_offset = 0, .mask = RT8973A_INT1_ADC_CHG_MASK, },
 	{ .reg_offset = 0, .mask = RT8973A_INT1_OTP_MASK, },
 
 	/* INT2 interrupts */
 	{ .reg_offset = 1, .mask = RT8973A_INT2_UVLOT_MASK,},
 	{ .reg_offset = 1, .mask = RT8973A_INT2_POR_MASK, },
 	{ .reg_offset = 1, .mask = RT8973A_INT2_OTP_FET_MASK, },
 	{ .reg_offset = 1, .mask = RT8973A_INT2_OVP_FET_MASK, },
 	{ .reg_offset = 1, .mask = RT8973A_INT2_OCP_LATCH_MASK, },
 	{ .reg_offset = 1, .mask = RT8973A_INT2_OCP_MASK, },
 	{ .reg_offset = 1, .mask = RT8973A_INT2_OVP_OCP_MASK, },
 };
 
 static const struct regmap_irq_chip rt8973a_muic_irq_chip = {
 	.name			= "rt8973a",
 	.status_base		= RT8973A_REG_INT1,
 	.mask_base		= RT8973A_REG_INTM1,
 	.mask_invert		= false,
 	.num_regs		= 2,
 	.irqs			= rt8973a_irqs,
 	.num_irqs		= ARRAY_SIZE(rt8973a_irqs),
 };
 
 /* Define regmap configuration of RT8973A for I2C communication  */
 static bool rt8973a_muic_volatile_reg(struct device *dev, unsigned int reg)
 {
 	switch (reg) {
 	case RT8973A_REG_INTM1:
 	case RT8973A_REG_INTM2:
 		return true;
 	default:
 		break;
 	}
 	return false;
 }
 
 static const struct regmap_config rt8973a_muic_regmap_config = {
 	.reg_bits	= 8,
 	.val_bits	= 8,
 	.volatile_reg	= rt8973a_muic_volatile_reg,
 	.max_register	= RT8973A_REG_END,
 };
 
 /* Change DM_CON/DP_CON/VBUSIN switch according to cable type */
 static int rt8973a_muic_set_path(struct rt8973a_muic_info *info,
 				unsigned int con_sw, bool attached)
 {
 	int ret;
 
 	/*
 	 * Don't need to set h/w path according to cable type
 	 * if Auto-configuration mode of CONTROL1 register is true.
 	 */
 	if (info->auto_config)
 		return 0;
 
 	if (!attached)
 		con_sw	= DM_DP_SWITCH_UART;
 
 	switch (con_sw) {
 	case DM_DP_SWITCH_OPEN:
 	case DM_DP_SWITCH_USB:
 	case DM_DP_SWITCH_UART:
 		ret = regmap_update_bits(info->regmap, RT8973A_REG_MANUAL_SW1,
 					RT8973A_REG_MANUAL_SW1_DP_MASK |
 					RT8973A_REG_MANUAL_SW1_DM_MASK,
 					con_sw);
 		if (ret < 0) {
 			dev_err(info->dev,
 				"cannot update DM_CON/DP_CON switch\n");
 			return ret;
 		}
 		break;
 	default:
 		dev_err(info->dev, "Unknown DM_CON/DP_CON switch type (%d)\n",
 				con_sw);
 		return -EINVAL;
 	}
 
 	return 0;
 }
 
 static int rt8973a_muic_get_cable_type(struct rt8973a_muic_info *info)
 {
 	unsigned int adc, dev1;
 	int ret, cable_type;
 
 	/* Read ADC value according to external cable or button */
 	ret = regmap_read(info->regmap, RT8973A_REG_ADC, &adc);
 	if (ret) {
 		dev_err(info->dev, "failed to read ADC register\n");
 		return ret;
 	}
 	cable_type = adc & RT8973A_REG_ADC_MASK;
 
 	/* Read Device 1 reigster to identify correct cable type */
 	ret = regmap_read(info->regmap, RT8973A_REG_DEV1, &dev1);
 	if (ret) {
 		dev_err(info->dev, "failed to read DEV1 register\n");
 		return ret;
 	}
 
 	switch (adc) {
 	case RT8973A_MUIC_ADC_OPEN:
 		if (dev1 & RT8973A_REG_DEV1_USB_MASK)
 			cable_type = RT8973A_MUIC_ADC_USB;
 		else if (dev1 & RT8973A_REG_DEV1_DCPORT_MASK)
 			cable_type = RT8973A_MUIC_ADC_TA;
 		else
 			cable_type = RT8973A_MUIC_ADC_OPEN;
 		break;
 	default:
 		break;
 	}
 
 	return cable_type;
 }
 
 static int rt8973a_muic_cable_handler(struct rt8973a_muic_info *info,
 					enum rt8973a_event_type event)
 {
 	static unsigned int prev_cable_type;
 	unsigned int con_sw = DM_DP_SWITCH_UART;
 	int ret, cable_type;
 	unsigned int id;
 	bool attached = false;
 
 	switch (event) {
 	case RT8973A_EVENT_ATTACH:
 		cable_type = rt8973a_muic_get_cable_type(info);
 		attached = true;
 		break;
 	case RT8973A_EVENT_DETACH:
 		cable_type = prev_cable_type;
 		attached = false;
 		break;
 	case RT8973A_EVENT_OVP:
 	case RT8973A_EVENT_OTP:
 		dev_warn(info->dev,
 			"happen Over %s issue. Need to disconnect all cables\n",
 			event == RT8973A_EVENT_OVP ? "Voltage" : "Temperature");
 		cable_type = prev_cable_type;
 		attached = false;
 		break;
 	default:
 		dev_err(info->dev,
 			"Cannot handle this event (event:%d)\n", event);
 		return -EINVAL;
 	}
 	prev_cable_type = cable_type;
 
 	switch (cable_type) {
 	case RT8973A_MUIC_ADC_OTG:
 		id = EXTCON_USB_HOST;
 		con_sw = DM_DP_SWITCH_USB;
 		break;
 	case RT8973A_MUIC_ADC_TA:
 		id = EXTCON_CHG_USB_DCP;
 		con_sw = DM_DP_SWITCH_OPEN;
 		break;
 	case RT8973A_MUIC_ADC_FACTORY_MODE_BOOT_OFF_USB:
 	case RT8973A_MUIC_ADC_FACTORY_MODE_BOOT_ON_USB:
 		id = EXTCON_JIG;
 		con_sw = DM_DP_SWITCH_USB;
 		break;
 	case RT8973A_MUIC_ADC_FACTORY_MODE_BOOT_OFF_UART:
 	case RT8973A_MUIC_ADC_FACTORY_MODE_BOOT_ON_UART:
 		id = EXTCON_JIG;
 		con_sw = DM_DP_SWITCH_UART;
 		break;
 	case RT8973A_MUIC_ADC_USB:
 		id = EXTCON_USB;
 		con_sw = DM_DP_SWITCH_USB;
 		break;
 	case RT8973A_MUIC_ADC_OPEN:
 		return 0;
 	case RT8973A_MUIC_ADC_UNKNOWN_ACC_1:
 	case RT8973A_MUIC_ADC_UNKNOWN_ACC_2:
 	case RT8973A_MUIC_ADC_UNKNOWN_ACC_3:
 	case RT8973A_MUIC_ADC_UNKNOWN_ACC_4:
 	case RT8973A_MUIC_ADC_UNKNOWN_ACC_5:
 		dev_warn(info->dev,
 			"Unknown accessory type (adc:0x%x)\n", cable_type);
 		return 0;
 	case RT8973A_MUIC_ADC_AUDIO_SEND_END_BUTTON:
 	case RT8973A_MUIC_ADC_AUDIO_REMOTE_S1_BUTTON:
 	case RT8973A_MUIC_ADC_AUDIO_REMOTE_S2_BUTTON:
 	case RT8973A_MUIC_ADC_AUDIO_REMOTE_S3_BUTTON:
 	case RT8973A_MUIC_ADC_AUDIO_REMOTE_S4_BUTTON:
 	case RT8973A_MUIC_ADC_AUDIO_REMOTE_S5_BUTTON:
 	case RT8973A_MUIC_ADC_AUDIO_REMOTE_S6_BUTTON:
 	case RT8973A_MUIC_ADC_AUDIO_REMOTE_S7_BUTTON:
 	case RT8973A_MUIC_ADC_AUDIO_REMOTE_S8_BUTTON:
 	case RT8973A_MUIC_ADC_AUDIO_REMOTE_S9_BUTTON:
 	case RT8973A_MUIC_ADC_AUDIO_REMOTE_S10_BUTTON:
 	case RT8973A_MUIC_ADC_AUDIO_REMOTE_S11_BUTTON:
 	case RT8973A_MUIC_ADC_AUDIO_REMOTE_S12_BUTTON:
 	case RT8973A_MUIC_ADC_AUDIO_TYPE2:
 		dev_warn(info->dev,
 			"Audio device/button type (adc:0x%x)\n", cable_type);
 		return 0;
 	case RT8973A_MUIC_ADC_RESERVED_ACC_1:
 	case RT8973A_MUIC_ADC_RESERVED_ACC_2:
 	case RT8973A_MUIC_ADC_RESERVED_ACC_3:
 	case RT8973A_MUIC_ADC_RESERVED_ACC_4:
 	case RT8973A_MUIC_ADC_RESERVED_ACC_5:
 	case RT8973A_MUIC_ADC_PHONE_POWERED_DEV:
 		return 0;
 	default:
 		dev_err(info->dev,
 			"Cannot handle this cable_type (adc:0x%x)\n",
 			cable_type);
 		return -EINVAL;
 	}
 
 	/* Change internal hardware path(DM_CON/DP_CON) */
 	ret = rt8973a_muic_set_path(info, con_sw, attached);
 	if (ret < 0)
 		return ret;
 
 	/* Change the state of external accessory */
 	extcon_set_state_sync(info->edev, id, attached);
 	if (id == EXTCON_USB)
 		extcon_set_state_sync(info->edev, EXTCON_CHG_USB_SDP,
 					attached);
 
 	return 0;
 }
 
 static void rt8973a_muic_irq_work(struct work_struct *work)
 {
 	struct rt8973a_muic_info *info = container_of(work,
 			struct rt8973a_muic_info, irq_work);
 	int ret = 0;
 
 	if (!info->edev)
 		return;
 
 	mutex_lock(&info->mutex);
 
 	/* Detect attached or detached cables */
 	if (info->irq_attach) {
 		ret = rt8973a_muic_cable_handler(info, RT8973A_EVENT_ATTACH);
 		info->irq_attach = false;
 	}
 
 	if (info->irq_detach) {
 		ret = rt8973a_muic_cable_handler(info, RT8973A_EVENT_DETACH);
 		info->irq_detach = false;
 	}
 
 	if (info->irq_ovp) {
 		ret = rt8973a_muic_cable_handler(info, RT8973A_EVENT_OVP);
 		info->irq_ovp = false;
 	}
 
 	if (info->irq_otp) {
 		ret = rt8973a_muic_cable_handler(info, RT8973A_EVENT_OTP);
 		info->irq_otp = false;
 	}
 
 	if (ret < 0)
 		dev_err(info->dev, "failed to handle MUIC interrupt\n");
 
 	mutex_unlock(&info->mutex);
 }
 
 static irqreturn_t rt8973a_muic_irq_handler(int irq, void *data)
 {
 	struct rt8973a_muic_info *info = data;
 	int i, irq_type = -1;
 
 	for (i = 0; i < info->num_muic_irqs; i++)
 		if (irq == info->muic_irqs[i].virq)
 			irq_type = info->muic_irqs[i].irq;
 
 	switch (irq_type) {
 	case RT8973A_INT1_ATTACH:
 		info->irq_attach = true;
 		break;
 	case RT8973A_INT1_DETACH:
 		info->irq_detach = true;
 		break;
 	case RT8973A_INT1_OVP:
 		info->irq_ovp = true;
 		break;
 	case RT8973A_INT1_OTP:
 		info->irq_otp = true;
 		break;
 	case RT8973A_INT1_CHGDET:
 	case RT8973A_INT1_DCD_T:
 	case RT8973A_INT1_CONNECT:
 	case RT8973A_INT1_ADC_CHG:
 	case RT8973A_INT2_UVLO:
 	case RT8973A_INT2_POR:
 	case RT8973A_INT2_OTP_FET:
 	case RT8973A_INT2_OVP_FET:
 	case RT8973A_INT2_OCP_LATCH:
 	case RT8973A_INT2_OCP:
 	case RT8973A_INT2_OVP_OCP:
 	default:
 		dev_dbg(info->dev,
 			"Cannot handle this interrupt (%d)\n", irq_type);
 		break;
 	}
 
 	schedule_work(&info->irq_work);
 
 	return IRQ_HANDLED;
 }
 
 static void rt8973a_muic_detect_cable_wq(struct work_struct *work)
 {
 	struct rt8973a_muic_info *info = container_of(to_delayed_work(work),
 				struct rt8973a_muic_info, wq_detcable);
 	int ret;
 
 	/* Notify the state of connector cable or not  */
 	ret = rt8973a_muic_cable_handler(info, RT8973A_EVENT_ATTACH);
 	if (ret < 0)
 		dev_warn(info->dev, "failed to detect cable state\n");
 }
 
 static void rt8973a_init_dev_type(struct rt8973a_muic_info *info)
 {
 	unsigned int data, vendor_id, version_id;
 	int i, ret;
 
 	/* To test I2C, Print version_id and vendor_id of RT8973A */
 	ret = regmap_read(info->regmap, RT8973A_REG_DEVICE_ID, &data);
 	if (ret) {
 		dev_err(info->dev,
 			"failed to read DEVICE_ID register: %d\n", ret);
 		return;
 	}
 
 	vendor_id = ((data & RT8973A_REG_DEVICE_ID_VENDOR_MASK) >>
 				RT8973A_REG_DEVICE_ID_VENDOR_SHIFT);
 	version_id = ((data & RT8973A_REG_DEVICE_ID_VERSION_MASK) >>
 				RT8973A_REG_DEVICE_ID_VERSION_SHIFT);
 
 	dev_info(info->dev, "Device type: version: 0x%x, vendor: 0x%x\n",
 			    version_id, vendor_id);
 
 	/* Initiazle the register of RT8973A device to bring-up */
 	for (i = 0; i < info->num_reg_data; i++) {
 		u8 reg = info->reg_data[i].reg;
 		u8 mask = info->reg_data[i].mask;
 		u8 val = 0;
 
 		if (info->reg_data[i].invert)
 			val = ~info->reg_data[i].val;
 		else
 			val = info->reg_data[i].val;
 
 		regmap_update_bits(info->regmap, reg, mask, val);
 	}
 
 	/* Check whether RT8973A is auto swithcing mode or not */
 	ret = regmap_read(info->regmap, RT8973A_REG_CONTROL1, &data);
 	if (ret) {
 		dev_err(info->dev,
 			"failed to read CONTROL1 register: %d\n", ret);
 		return;
 	}
 
 	data &= RT8973A_REG_CONTROL1_AUTO_CONFIG_MASK;
 	if (data) {
 		info->auto_config = true;
 		dev_info(info->dev,
 			"Enable Auto-configuration for internal path\n");
 	}
 }
 
 static int rt8973a_muic_i2c_probe(struct i2c_client *i2c,
 				 const struct i2c_device_id *id)
 {
 	struct device_node *np = i2c->dev.of_node;
 	struct rt8973a_muic_info *info;
 	int i, ret, irq_flags;
 
 	if (!np)
 		return -EINVAL;
 
 	info = devm_kzalloc(&i2c->dev, sizeof(*info), GFP_KERNEL);
 	if (!info)
 		return -ENOMEM;
 	i2c_set_clientdata(i2c, info);
 
 	info->dev = &i2c->dev;
 	info->i2c = i2c;
 	info->irq = i2c->irq;
 	info->muic_irqs = rt8973a_muic_irqs;
 	info->num_muic_irqs = ARRAY_SIZE(rt8973a_muic_irqs);
 	info->reg_data = rt8973a_reg_data;
 	info->num_reg_data = ARRAY_SIZE(rt8973a_reg_data);
 
 	mutex_init(&info->mutex);
 
 	INIT_WORK(&info->irq_work, rt8973a_muic_irq_work);
 
 	info->regmap = devm_regmap_init_i2c(i2c, &rt8973a_muic_regmap_config);
 	if (IS_ERR(info->regmap)) {
 		ret = PTR_ERR(info->regmap);
 		dev_err(info->dev, "failed to allocate register map: %d\n",
 				   ret);
 		return ret;
 	}
 
 	/* Support irq domain for RT8973A MUIC device */
 	irq_flags = IRQF_TRIGGER_FALLING | IRQF_ONESHOT | IRQF_SHARED;
 	ret = regmap_add_irq_chip(info->regmap, info->irq, irq_flags, 0,
 				  &rt8973a_muic_irq_chip, &info->irq_data);
 	if (ret != 0) {
 		dev_err(info->dev, "failed to add irq_chip (irq:%d, err:%d)\n",
 				    info->irq, ret);
 		return ret;
 	}
 
 	for (i = 0; i < info->num_muic_irqs; i++) {
 		struct muic_irq *muic_irq = &info->muic_irqs[i];
 		int virq = 0;
 
 		virq = regmap_irq_get_virq(info->irq_data, muic_irq->irq);
 		if (virq <= 0)
 			return -EINVAL;
 		muic_irq->virq = virq;
 
 		ret = devm_request_threaded_irq(info->dev, virq, NULL,
 						rt8973a_muic_irq_handler,
 						IRQF_NO_SUSPEND | IRQF_ONESHOT,
 						muic_irq->name, info);
 		if (ret) {
 			dev_err(info->dev,
 				"failed: irq request (IRQ: %d, error :%d)\n",
 				muic_irq->irq, ret);
 			return ret;
 		}
 	}
 
 	/* Allocate extcon device */
 	info->edev = devm_extcon_dev_allocate(info->dev, rt8973a_extcon_cable);
 	if (IS_ERR(info->edev)) {
 		dev_err(info->dev, "failed to allocate memory for extcon\n");
 		return -ENOMEM;
 	}
 
 	/* Register extcon device */
 	ret = devm_extcon_dev_register(info->dev, info->edev);
 	if (ret) {
 		dev_err(info->dev, "failed to register extcon device\n");
 		return ret;
 	}
 
 	/*
 	 * Detect accessory after completing the initialization of platform
 	 *
 	 * - Use delayed workqueue to detect cable state and then
 	 * notify cable state to notifiee/platform through uevent.
 	 * After completing the booting of platform, the extcon provider
 	 * driver should notify cable state to upper layer.
 	 */
 	INIT_DELAYED_WORK(&info->wq_detcable, rt8973a_muic_detect_cable_wq);
 	queue_delayed_work(system_power_efficient_wq, &info->wq_detcable,
 			msecs_to_jiffies(DELAY_MS_DEFAULT));
 
 	/* Initialize RT8973A device and print vendor id and version id */
 	rt8973a_init_dev_type(info);
 
 	return 0;
 }
 
 static int rt8973a_muic_i2c_remove(struct i2c_client *i2c)
 {
 	struct rt8973a_muic_info *info = i2c_get_clientdata(i2c);
 
 	regmap_del_irq_chip(info->irq, info->irq_data);
 
 	return 0;
 }
 
 static const struct of_device_id rt8973a_dt_match[] = {
 	{ .compatible = "richtek,rt8973a-muic" },
 	{ },
 };
 MODULE_DEVICE_TABLE(of, rt8973a_dt_match);
 
 #ifdef CONFIG_PM_SLEEP
 static int rt8973a_muic_suspend(struct device *dev)
 {
 	struct i2c_client *i2c = to_i2c_client(dev);
 	struct rt8973a_muic_info *info = i2c_get_clientdata(i2c);
 
 	enable_irq_wake(info->irq);
 
 	return 0;
 }
 
 static int rt8973a_muic_resume(struct device *dev)
 {
 	struct i2c_client *i2c = to_i2c_client(dev);
 	struct rt8973a_muic_info *info = i2c_get_clientdata(i2c);
 
 	disable_irq_wake(info->irq);
 
 	return 0;
 }
 #endif
 
 static SIMPLE_DEV_PM_OPS(rt8973a_muic_pm_ops,
 			 rt8973a_muic_suspend, rt8973a_muic_resume);
 
 static const struct i2c_device_id rt8973a_i2c_id[] = {
 	{ "rt8973a", TYPE_RT8973A },
 	{ }
 };
 MODULE_DEVICE_TABLE(i2c, rt8973a_i2c_id);
 
 static struct i2c_driver rt8973a_muic_i2c_driver = {
 	.driver		= {
 		.name	= "rt8973a",
 		.pm	= &rt8973a_muic_pm_ops,
 		.of_match_table = rt8973a_dt_match,
 	},
 	.probe	= rt8973a_muic_i2c_probe,
 	.remove	= rt8973a_muic_i2c_remove,
 	.id_table = rt8973a_i2c_id,
 };
 
 static int __init rt8973a_muic_i2c_init(void)
 {
 	return i2c_add_driver(&rt8973a_muic_i2c_driver);
 }
 subsys_initcall(rt8973a_muic_i2c_init);
 
 MODULE_DESCRIPTION("Richtek RT8973A Extcon driver");
 MODULE_AUTHOR("Chanwoo Choi <cw00.choi@samsung.com>");
 MODULE_LICENSE("GPL");
diff --git a/drivers/extcon/extcon-sm5502.c b/drivers/extcon/extcon-sm5502.c
index b22325688503..106ef0297b53 100644
--- a/drivers/extcon/extcon-sm5502.c
+++ b/drivers/extcon/extcon-sm5502.c
@@ -1,709 +1,711 @@
 /*
  * extcon-sm5502.c - Silicon Mitus SM5502 extcon drvier to support USB switches
  *
  * Copyright (c) 2014 Samsung Electronics Co., Ltd
  * Author: Chanwoo Choi <cw00.choi@samsung.com>
  *
  * This program is free software; you can redistribute  it and/or modify it
  * under  the terms of  the GNU General  Public License as published by the
  * Free Software Foundation;  either version 2 of the  License, or (at your
  * option) any later version.
  */
 
 #include <linux/err.h>
 #include <linux/i2c.h>
 #include <linux/interrupt.h>
 #include <linux/irqdomain.h>
 #include <linux/kernel.h>
 #include <linux/module.h>
 #include <linux/platform_device.h>
 #include <linux/regmap.h>
 #include <linux/slab.h>
 #include <linux/extcon.h>
 
 #include "extcon-sm5502.h"
 
 #define	DELAY_MS_DEFAULT		17000	/* unit: millisecond */
 
 struct muic_irq {
 	unsigned int irq;
 	const char *name;
 	unsigned int virq;
 };
 
 struct reg_data {
 	u8 reg;
 	unsigned int val;
 	bool invert;
 };
 
 struct sm5502_muic_info {
 	struct device *dev;
 	struct extcon_dev *edev;
 
 	struct i2c_client *i2c;
 	struct regmap *regmap;
 
 	struct regmap_irq_chip_data *irq_data;
 	struct muic_irq *muic_irqs;
 	unsigned int num_muic_irqs;
 	int irq;
 	bool irq_attach;
 	bool irq_detach;
 	struct work_struct irq_work;
 
 	struct reg_data *reg_data;
 	unsigned int num_reg_data;
 
 	struct mutex mutex;
 
 	/*
 	 * Use delayed workqueue to detect cable state and then
 	 * notify cable state to notifiee/platform through uevent.
 	 * After completing the booting of platform, the extcon provider
 	 * driver should notify cable state to upper layer.
 	 */
 	struct delayed_work wq_detcable;
 };
 
 /* Default value of SM5502 register to bring up MUIC device. */
 static struct reg_data sm5502_reg_data[] = {
 	{
 		.reg = SM5502_REG_CONTROL,
 		.val = SM5502_REG_CONTROL_MASK_INT_MASK,
 		.invert = false,
 	}, {
 		.reg = SM5502_REG_INTMASK1,
 		.val = SM5502_REG_INTM1_KP_MASK
 			| SM5502_REG_INTM1_LKP_MASK
 			| SM5502_REG_INTM1_LKR_MASK,
 		.invert = true,
 	}, {
 		.reg = SM5502_REG_INTMASK2,
 		.val = SM5502_REG_INTM2_VBUS_DET_MASK
 			| SM5502_REG_INTM2_REV_ACCE_MASK
 			| SM5502_REG_INTM2_ADC_CHG_MASK
 			| SM5502_REG_INTM2_STUCK_KEY_MASK
 			| SM5502_REG_INTM2_STUCK_KEY_RCV_MASK
 			| SM5502_REG_INTM2_MHL_MASK,
 		.invert = true,
 	},
 	{ }
 };
 
 /* List of detectable cables */
 static const unsigned int sm5502_extcon_cable[] = {
 	EXTCON_USB,
 	EXTCON_USB_HOST,
 	EXTCON_CHG_USB_SDP,
 	EXTCON_CHG_USB_DCP,
 	EXTCON_NONE,
 };
 
 /* Define supported accessory type */
 enum sm5502_muic_acc_type {
 	SM5502_MUIC_ADC_GROUND = 0x0,
 	SM5502_MUIC_ADC_SEND_END_BUTTON,
 	SM5502_MUIC_ADC_REMOTE_S1_BUTTON,
 	SM5502_MUIC_ADC_REMOTE_S2_BUTTON,
 	SM5502_MUIC_ADC_REMOTE_S3_BUTTON,
 	SM5502_MUIC_ADC_REMOTE_S4_BUTTON,
 	SM5502_MUIC_ADC_REMOTE_S5_BUTTON,
 	SM5502_MUIC_ADC_REMOTE_S6_BUTTON,
 	SM5502_MUIC_ADC_REMOTE_S7_BUTTON,
 	SM5502_MUIC_ADC_REMOTE_S8_BUTTON,
 	SM5502_MUIC_ADC_REMOTE_S9_BUTTON,
 	SM5502_MUIC_ADC_REMOTE_S10_BUTTON,
 	SM5502_MUIC_ADC_REMOTE_S11_BUTTON,
 	SM5502_MUIC_ADC_REMOTE_S12_BUTTON,
 	SM5502_MUIC_ADC_RESERVED_ACC_1,
 	SM5502_MUIC_ADC_RESERVED_ACC_2,
 	SM5502_MUIC_ADC_RESERVED_ACC_3,
 	SM5502_MUIC_ADC_RESERVED_ACC_4,
 	SM5502_MUIC_ADC_RESERVED_ACC_5,
 	SM5502_MUIC_ADC_AUDIO_TYPE2,
 	SM5502_MUIC_ADC_PHONE_POWERED_DEV,
 	SM5502_MUIC_ADC_TTY_CONVERTER,
 	SM5502_MUIC_ADC_UART_CABLE,
 	SM5502_MUIC_ADC_TYPE1_CHARGER,
 	SM5502_MUIC_ADC_FACTORY_MODE_BOOT_OFF_USB,
 	SM5502_MUIC_ADC_FACTORY_MODE_BOOT_ON_USB,
 	SM5502_MUIC_ADC_AUDIO_VIDEO_CABLE,
 	SM5502_MUIC_ADC_TYPE2_CHARGER,
 	SM5502_MUIC_ADC_FACTORY_MODE_BOOT_OFF_UART,
 	SM5502_MUIC_ADC_FACTORY_MODE_BOOT_ON_UART,
 	SM5502_MUIC_ADC_AUDIO_TYPE1,
 	SM5502_MUIC_ADC_OPEN = 0x1f,
 
-	/* The below accessories have same ADC value (0x1f or 0x1e).
-	   So, Device type1 is used to separate specific accessory. */
+	/*
+	 * The below accessories have same ADC value (0x1f or 0x1e).
+	 * So, Device type1 is used to separate specific accessory.
+	 */
 							/* |---------|--ADC| */
 							/* |    [7:5]|[4:0]| */
 	SM5502_MUIC_ADC_AUDIO_TYPE1_FULL_REMOTE = 0x3e,	/* |      001|11110| */
 	SM5502_MUIC_ADC_AUDIO_TYPE1_SEND_END = 0x5e,	/* |      010|11110| */
 							/* |Dev Type1|--ADC| */
 	SM5502_MUIC_ADC_OPEN_USB = 0x5f,		/* |      010|11111| */
 	SM5502_MUIC_ADC_OPEN_TA = 0xdf,			/* |      110|11111| */
 	SM5502_MUIC_ADC_OPEN_USB_OTG = 0xff,		/* |      111|11111| */
 };
 
 /* List of supported interrupt for SM5502 */
 static struct muic_irq sm5502_muic_irqs[] = {
 	{ SM5502_IRQ_INT1_ATTACH,	"muic-attach" },
 	{ SM5502_IRQ_INT1_DETACH,	"muic-detach" },
 	{ SM5502_IRQ_INT1_KP,		"muic-kp" },
 	{ SM5502_IRQ_INT1_LKP,		"muic-lkp" },
 	{ SM5502_IRQ_INT1_LKR,		"muic-lkr" },
 	{ SM5502_IRQ_INT1_OVP_EVENT,	"muic-ovp-event" },
 	{ SM5502_IRQ_INT1_OCP_EVENT,	"muic-ocp-event" },
 	{ SM5502_IRQ_INT1_OVP_OCP_DIS,	"muic-ovp-ocp-dis" },
 	{ SM5502_IRQ_INT2_VBUS_DET,	"muic-vbus-det" },
 	{ SM5502_IRQ_INT2_REV_ACCE,	"muic-rev-acce" },
 	{ SM5502_IRQ_INT2_ADC_CHG,	"muic-adc-chg" },
 	{ SM5502_IRQ_INT2_STUCK_KEY,	"muic-stuck-key" },
 	{ SM5502_IRQ_INT2_STUCK_KEY_RCV, "muic-stuck-key-rcv" },
 	{ SM5502_IRQ_INT2_MHL,		"muic-mhl" },
 };
 
 /* Define interrupt list of SM5502 to register regmap_irq */
 static const struct regmap_irq sm5502_irqs[] = {
 	/* INT1 interrupts */
 	{ .reg_offset = 0, .mask = SM5502_IRQ_INT1_ATTACH_MASK, },
 	{ .reg_offset = 0, .mask = SM5502_IRQ_INT1_DETACH_MASK, },
 	{ .reg_offset = 0, .mask = SM5502_IRQ_INT1_KP_MASK, },
 	{ .reg_offset = 0, .mask = SM5502_IRQ_INT1_LKP_MASK, },
 	{ .reg_offset = 0, .mask = SM5502_IRQ_INT1_LKR_MASK, },
 	{ .reg_offset = 0, .mask = SM5502_IRQ_INT1_OVP_EVENT_MASK, },
 	{ .reg_offset = 0, .mask = SM5502_IRQ_INT1_OCP_EVENT_MASK, },
 	{ .reg_offset = 0, .mask = SM5502_IRQ_INT1_OVP_OCP_DIS_MASK, },
 
 	/* INT2 interrupts */
 	{ .reg_offset = 1, .mask = SM5502_IRQ_INT2_VBUS_DET_MASK,},
 	{ .reg_offset = 1, .mask = SM5502_IRQ_INT2_REV_ACCE_MASK, },
 	{ .reg_offset = 1, .mask = SM5502_IRQ_INT2_ADC_CHG_MASK, },
 	{ .reg_offset = 1, .mask = SM5502_IRQ_INT2_STUCK_KEY_MASK, },
 	{ .reg_offset = 1, .mask = SM5502_IRQ_INT2_STUCK_KEY_RCV_MASK, },
 	{ .reg_offset = 1, .mask = SM5502_IRQ_INT2_MHL_MASK, },
 };
 
 static const struct regmap_irq_chip sm5502_muic_irq_chip = {
 	.name			= "sm5502",
 	.status_base		= SM5502_REG_INT1,
 	.mask_base		= SM5502_REG_INTMASK1,
 	.mask_invert		= false,
 	.num_regs		= 2,
 	.irqs			= sm5502_irqs,
 	.num_irqs		= ARRAY_SIZE(sm5502_irqs),
 };
 
 /* Define regmap configuration of SM5502 for I2C communication  */
 static bool sm5502_muic_volatile_reg(struct device *dev, unsigned int reg)
 {
 	switch (reg) {
 	case SM5502_REG_INTMASK1:
 	case SM5502_REG_INTMASK2:
 		return true;
 	default:
 		break;
 	}
 	return false;
 }
 
 static const struct regmap_config sm5502_muic_regmap_config = {
 	.reg_bits	= 8,
 	.val_bits	= 8,
 	.volatile_reg	= sm5502_muic_volatile_reg,
 	.max_register	= SM5502_REG_END,
 };
 
 /* Change DM_CON/DP_CON/VBUSIN switch according to cable type */
 static int sm5502_muic_set_path(struct sm5502_muic_info *info,
 				unsigned int con_sw, unsigned int vbus_sw,
 				bool attached)
 {
 	int ret;
 
 	if (!attached) {
 		con_sw	= DM_DP_SWITCH_OPEN;
 		vbus_sw	= VBUSIN_SWITCH_OPEN;
 	}
 
 	switch (con_sw) {
 	case DM_DP_SWITCH_OPEN:
 	case DM_DP_SWITCH_USB:
 	case DM_DP_SWITCH_AUDIO:
 	case DM_DP_SWITCH_UART:
 		ret = regmap_update_bits(info->regmap, SM5502_REG_MANUAL_SW1,
 					 SM5502_REG_MANUAL_SW1_DP_MASK |
 					 SM5502_REG_MANUAL_SW1_DM_MASK,
 					 con_sw);
 		if (ret < 0) {
 			dev_err(info->dev,
 				"cannot update DM_CON/DP_CON switch\n");
 			return ret;
 		}
 		break;
 	default:
 		dev_err(info->dev, "Unknown DM_CON/DP_CON switch type (%d)\n",
 				con_sw);
 		return -EINVAL;
 	};
 
 	switch (vbus_sw) {
 	case VBUSIN_SWITCH_OPEN:
 	case VBUSIN_SWITCH_VBUSOUT:
 	case VBUSIN_SWITCH_MIC:
 	case VBUSIN_SWITCH_VBUSOUT_WITH_USB:
 		ret = regmap_update_bits(info->regmap, SM5502_REG_MANUAL_SW1,
 					 SM5502_REG_MANUAL_SW1_VBUSIN_MASK,
 					 vbus_sw);
 		if (ret < 0) {
 			dev_err(info->dev,
 				"cannot update VBUSIN switch\n");
 			return ret;
 		}
 		break;
 	default:
 		dev_err(info->dev, "Unknown VBUS switch type (%d)\n", vbus_sw);
 		return -EINVAL;
 	};
 
 	return 0;
 }
 
 /* Return cable type of attached or detached accessories */
 static unsigned int sm5502_muic_get_cable_type(struct sm5502_muic_info *info)
 {
 	unsigned int cable_type = -1, adc, dev_type1;
 	int ret;
 
 	/* Read ADC value according to external cable or button */
 	ret = regmap_read(info->regmap, SM5502_REG_ADC, &adc);
 	if (ret) {
 		dev_err(info->dev, "failed to read ADC register\n");
 		return ret;
 	}
 
 	/*
 	 * If ADC is SM5502_MUIC_ADC_GROUND(0x0), external cable hasn't
 	 * connected with to MUIC device.
 	 */
 	cable_type = adc & SM5502_REG_ADC_MASK;
 	if (cable_type == SM5502_MUIC_ADC_GROUND)
 		return SM5502_MUIC_ADC_GROUND;
 
 	switch (cable_type) {
 	case SM5502_MUIC_ADC_GROUND:
 	case SM5502_MUIC_ADC_SEND_END_BUTTON:
 	case SM5502_MUIC_ADC_REMOTE_S1_BUTTON:
 	case SM5502_MUIC_ADC_REMOTE_S2_BUTTON:
 	case SM5502_MUIC_ADC_REMOTE_S3_BUTTON:
 	case SM5502_MUIC_ADC_REMOTE_S4_BUTTON:
 	case SM5502_MUIC_ADC_REMOTE_S5_BUTTON:
 	case SM5502_MUIC_ADC_REMOTE_S6_BUTTON:
 	case SM5502_MUIC_ADC_REMOTE_S7_BUTTON:
 	case SM5502_MUIC_ADC_REMOTE_S8_BUTTON:
 	case SM5502_MUIC_ADC_REMOTE_S9_BUTTON:
 	case SM5502_MUIC_ADC_REMOTE_S10_BUTTON:
 	case SM5502_MUIC_ADC_REMOTE_S11_BUTTON:
 	case SM5502_MUIC_ADC_REMOTE_S12_BUTTON:
 	case SM5502_MUIC_ADC_RESERVED_ACC_1:
 	case SM5502_MUIC_ADC_RESERVED_ACC_2:
 	case SM5502_MUIC_ADC_RESERVED_ACC_3:
 	case SM5502_MUIC_ADC_RESERVED_ACC_4:
 	case SM5502_MUIC_ADC_RESERVED_ACC_5:
 	case SM5502_MUIC_ADC_AUDIO_TYPE2:
 	case SM5502_MUIC_ADC_PHONE_POWERED_DEV:
 	case SM5502_MUIC_ADC_TTY_CONVERTER:
 	case SM5502_MUIC_ADC_UART_CABLE:
 	case SM5502_MUIC_ADC_TYPE1_CHARGER:
 	case SM5502_MUIC_ADC_FACTORY_MODE_BOOT_OFF_USB:
 	case SM5502_MUIC_ADC_FACTORY_MODE_BOOT_ON_USB:
 	case SM5502_MUIC_ADC_AUDIO_VIDEO_CABLE:
 	case SM5502_MUIC_ADC_TYPE2_CHARGER:
 	case SM5502_MUIC_ADC_FACTORY_MODE_BOOT_OFF_UART:
 	case SM5502_MUIC_ADC_FACTORY_MODE_BOOT_ON_UART:
 		break;
 	case SM5502_MUIC_ADC_AUDIO_TYPE1:
 		/*
 		 * Check whether cable type is
 		 * SM5502_MUIC_ADC_AUDIO_TYPE1_FULL_REMOTE
 		 * or SM5502_MUIC_ADC_AUDIO_TYPE1_SEND_END
 		 * by using Button event.
 		 */
 		break;
 	case SM5502_MUIC_ADC_OPEN:
 		ret = regmap_read(info->regmap, SM5502_REG_DEV_TYPE1,
 				  &dev_type1);
 		if (ret) {
 			dev_err(info->dev, "failed to read DEV_TYPE1 reg\n");
 			return ret;
 		}
 
 		switch (dev_type1) {
 		case SM5502_REG_DEV_TYPE1_USB_SDP_MASK:
 			cable_type = SM5502_MUIC_ADC_OPEN_USB;
 			break;
 		case SM5502_REG_DEV_TYPE1_DEDICATED_CHG_MASK:
 			cable_type = SM5502_MUIC_ADC_OPEN_TA;
 			break;
 		case SM5502_REG_DEV_TYPE1_USB_OTG_MASK:
 			cable_type = SM5502_MUIC_ADC_OPEN_USB_OTG;
 			break;
 		default:
 			dev_dbg(info->dev,
 				"cannot identify the cable type: adc(0x%x)\n",
 				adc);
 			return -EINVAL;
 		};
 		break;
 	default:
 		dev_err(info->dev,
 			"failed to identify the cable type: adc(0x%x)\n", adc);
 		return -EINVAL;
 	};
 
 	return cable_type;
 }
 
 static int sm5502_muic_cable_handler(struct sm5502_muic_info *info,
 				     bool attached)
 {
 	static unsigned int prev_cable_type = SM5502_MUIC_ADC_GROUND;
 	unsigned int cable_type = SM5502_MUIC_ADC_GROUND;
 	unsigned int con_sw = DM_DP_SWITCH_OPEN;
 	unsigned int vbus_sw = VBUSIN_SWITCH_OPEN;
 	unsigned int id;
 	int ret;
 
 	/* Get the type of attached or detached cable */
 	if (attached)
 		cable_type = sm5502_muic_get_cable_type(info);
 	else
 		cable_type = prev_cable_type;
 	prev_cable_type = cable_type;
 
 	switch (cable_type) {
 	case SM5502_MUIC_ADC_OPEN_USB:
 		id	= EXTCON_USB;
 		con_sw	= DM_DP_SWITCH_USB;
 		vbus_sw	= VBUSIN_SWITCH_VBUSOUT_WITH_USB;
 		break;
 	case SM5502_MUIC_ADC_OPEN_TA:
 		id	= EXTCON_CHG_USB_DCP;
 		con_sw	= DM_DP_SWITCH_OPEN;
 		vbus_sw	= VBUSIN_SWITCH_VBUSOUT;
 		break;
 	case SM5502_MUIC_ADC_OPEN_USB_OTG:
 		id	= EXTCON_USB_HOST;
 		con_sw	= DM_DP_SWITCH_USB;
 		vbus_sw	= VBUSIN_SWITCH_OPEN;
 		break;
 	default:
 		dev_dbg(info->dev,
 			"cannot handle this cable_type (0x%x)\n", cable_type);
 		return 0;
 	};
 
 	/* Change internal hardware path(DM_CON/DP_CON, VBUSIN) */
 	ret = sm5502_muic_set_path(info, con_sw, vbus_sw, attached);
 	if (ret < 0)
 		return ret;
 
 	/* Change the state of external accessory */
 	extcon_set_state_sync(info->edev, id, attached);
 	if (id == EXTCON_USB)
 		extcon_set_state_sync(info->edev, EXTCON_CHG_USB_SDP,
 					attached);
 
 	return 0;
 }
 
 static void sm5502_muic_irq_work(struct work_struct *work)
 {
 	struct sm5502_muic_info *info = container_of(work,
 			struct sm5502_muic_info, irq_work);
 	int ret = 0;
 
 	if (!info->edev)
 		return;
 
 	mutex_lock(&info->mutex);
 
 	/* Detect attached or detached cables */
 	if (info->irq_attach) {
 		ret = sm5502_muic_cable_handler(info, true);
 		info->irq_attach = false;
 	}
 	if (info->irq_detach) {
 		ret = sm5502_muic_cable_handler(info, false);
 		info->irq_detach = false;
 	}
 
 	if (ret < 0)
 		dev_err(info->dev, "failed to handle MUIC interrupt\n");
 
 	mutex_unlock(&info->mutex);
 }
 
 /*
  * Sets irq_attach or irq_detach in sm5502_muic_info and returns 0.
  * Returns -ESRCH if irq_type does not match registered IRQ for this dev type.
  */
 static int sm5502_parse_irq(struct sm5502_muic_info *info, int irq_type)
 {
 	switch (irq_type) {
 	case SM5502_IRQ_INT1_ATTACH:
 		info->irq_attach = true;
 		break;
 	case SM5502_IRQ_INT1_DETACH:
 		info->irq_detach = true;
 		break;
 	case SM5502_IRQ_INT1_KP:
 	case SM5502_IRQ_INT1_LKP:
 	case SM5502_IRQ_INT1_LKR:
 	case SM5502_IRQ_INT1_OVP_EVENT:
 	case SM5502_IRQ_INT1_OCP_EVENT:
 	case SM5502_IRQ_INT1_OVP_OCP_DIS:
 	case SM5502_IRQ_INT2_VBUS_DET:
 	case SM5502_IRQ_INT2_REV_ACCE:
 	case SM5502_IRQ_INT2_ADC_CHG:
 	case SM5502_IRQ_INT2_STUCK_KEY:
 	case SM5502_IRQ_INT2_STUCK_KEY_RCV:
 	case SM5502_IRQ_INT2_MHL:
 	default:
 		break;
 	}
 
 	return 0;
 }
 
 static irqreturn_t sm5502_muic_irq_handler(int irq, void *data)
 {
 	struct sm5502_muic_info *info = data;
 	int i, irq_type = -1, ret;
 
 	for (i = 0; i < info->num_muic_irqs; i++)
 		if (irq == info->muic_irqs[i].virq)
 			irq_type = info->muic_irqs[i].irq;
 
 	ret = sm5502_parse_irq(info, irq_type);
 	if (ret < 0) {
 		dev_warn(info->dev, "cannot handle is interrupt:%d\n",
 				    irq_type);
 		return IRQ_HANDLED;
 	}
 	schedule_work(&info->irq_work);
 
 	return IRQ_HANDLED;
 }
 
 static void sm5502_muic_detect_cable_wq(struct work_struct *work)
 {
 	struct sm5502_muic_info *info = container_of(to_delayed_work(work),
 				struct sm5502_muic_info, wq_detcable);
 	int ret;
 
 	/* Notify the state of connector cable or not  */
 	ret = sm5502_muic_cable_handler(info, true);
 	if (ret < 0)
 		dev_warn(info->dev, "failed to detect cable state\n");
 }
 
 static void sm5502_init_dev_type(struct sm5502_muic_info *info)
 {
 	unsigned int reg_data, vendor_id, version_id;
 	int i, ret;
 
 	/* To test I2C, Print version_id and vendor_id of SM5502 */
 	ret = regmap_read(info->regmap, SM5502_REG_DEVICE_ID, &reg_data);
 	if (ret) {
 		dev_err(info->dev,
 			"failed to read DEVICE_ID register: %d\n", ret);
 		return;
 	}
 
 	vendor_id = ((reg_data & SM5502_REG_DEVICE_ID_VENDOR_MASK) >>
 				SM5502_REG_DEVICE_ID_VENDOR_SHIFT);
 	version_id = ((reg_data & SM5502_REG_DEVICE_ID_VERSION_MASK) >>
 				SM5502_REG_DEVICE_ID_VERSION_SHIFT);
 
 	dev_info(info->dev, "Device type: version: 0x%x, vendor: 0x%x\n",
 			    version_id, vendor_id);
 
 	/* Initiazle the register of SM5502 device to bring-up */
 	for (i = 0; i < info->num_reg_data; i++) {
 		unsigned int val = 0;
 
 		if (!info->reg_data[i].invert)
 			val |= ~info->reg_data[i].val;
 		else
 			val = info->reg_data[i].val;
 		regmap_write(info->regmap, info->reg_data[i].reg, val);
 	}
 }
 
 static int sm5022_muic_i2c_probe(struct i2c_client *i2c,
 				 const struct i2c_device_id *id)
 {
 	struct device_node *np = i2c->dev.of_node;
 	struct sm5502_muic_info *info;
 	int i, ret, irq_flags;
 
 	if (!np)
 		return -EINVAL;
 
 	info = devm_kzalloc(&i2c->dev, sizeof(*info), GFP_KERNEL);
 	if (!info)
 		return -ENOMEM;
 	i2c_set_clientdata(i2c, info);
 
 	info->dev = &i2c->dev;
 	info->i2c = i2c;
 	info->irq = i2c->irq;
 	info->muic_irqs = sm5502_muic_irqs;
 	info->num_muic_irqs = ARRAY_SIZE(sm5502_muic_irqs);
 	info->reg_data = sm5502_reg_data;
 	info->num_reg_data = ARRAY_SIZE(sm5502_reg_data);
 
 	mutex_init(&info->mutex);
 
 	INIT_WORK(&info->irq_work, sm5502_muic_irq_work);
 
 	info->regmap = devm_regmap_init_i2c(i2c, &sm5502_muic_regmap_config);
 	if (IS_ERR(info->regmap)) {
 		ret = PTR_ERR(info->regmap);
 		dev_err(info->dev, "failed to allocate register map: %d\n",
 				   ret);
 		return ret;
 	}
 
 	/* Support irq domain for SM5502 MUIC device */
 	irq_flags = IRQF_TRIGGER_FALLING | IRQF_ONESHOT | IRQF_SHARED;
 	ret = regmap_add_irq_chip(info->regmap, info->irq, irq_flags, 0,
 				  &sm5502_muic_irq_chip, &info->irq_data);
 	if (ret != 0) {
 		dev_err(info->dev, "failed to request IRQ %d: %d\n",
 				    info->irq, ret);
 		return ret;
 	}
 
 	for (i = 0; i < info->num_muic_irqs; i++) {
 		struct muic_irq *muic_irq = &info->muic_irqs[i];
 		int virq = 0;
 
 		virq = regmap_irq_get_virq(info->irq_data, muic_irq->irq);
 		if (virq <= 0)
 			return -EINVAL;
 		muic_irq->virq = virq;
 
 		ret = devm_request_threaded_irq(info->dev, virq, NULL,
 						sm5502_muic_irq_handler,
 						IRQF_NO_SUSPEND,
 						muic_irq->name, info);
 		if (ret) {
 			dev_err(info->dev,
 				"failed: irq request (IRQ: %d, error :%d)\n",
 				muic_irq->irq, ret);
 			return ret;
 		}
 	}
 
 	/* Allocate extcon device */
 	info->edev = devm_extcon_dev_allocate(info->dev, sm5502_extcon_cable);
 	if (IS_ERR(info->edev)) {
 		dev_err(info->dev, "failed to allocate memory for extcon\n");
 		return -ENOMEM;
 	}
 
 	/* Register extcon device */
 	ret = devm_extcon_dev_register(info->dev, info->edev);
 	if (ret) {
 		dev_err(info->dev, "failed to register extcon device\n");
 		return ret;
 	}
 
 	/*
 	 * Detect accessory after completing the initialization of platform
 	 *
 	 * - Use delayed workqueue to detect cable state and then
 	 * notify cable state to notifiee/platform through uevent.
 	 * After completing the booting of platform, the extcon provider
 	 * driver should notify cable state to upper layer.
 	 */
 	INIT_DELAYED_WORK(&info->wq_detcable, sm5502_muic_detect_cable_wq);
 	queue_delayed_work(system_power_efficient_wq, &info->wq_detcable,
 			msecs_to_jiffies(DELAY_MS_DEFAULT));
 
 	/* Initialize SM5502 device and print vendor id and version id */
 	sm5502_init_dev_type(info);
 
 	return 0;
 }
 
 static int sm5502_muic_i2c_remove(struct i2c_client *i2c)
 {
 	struct sm5502_muic_info *info = i2c_get_clientdata(i2c);
 
 	regmap_del_irq_chip(info->irq, info->irq_data);
 
 	return 0;
 }
 
 static const struct of_device_id sm5502_dt_match[] = {
 	{ .compatible = "siliconmitus,sm5502-muic" },
 	{ },
 };
 MODULE_DEVICE_TABLE(of, sm5502_dt_match);
 
 #ifdef CONFIG_PM_SLEEP
 static int sm5502_muic_suspend(struct device *dev)
 {
 	struct i2c_client *i2c = to_i2c_client(dev);
 	struct sm5502_muic_info *info = i2c_get_clientdata(i2c);
 
 	enable_irq_wake(info->irq);
 
 	return 0;
 }
 
 static int sm5502_muic_resume(struct device *dev)
 {
 	struct i2c_client *i2c = to_i2c_client(dev);
 	struct sm5502_muic_info *info = i2c_get_clientdata(i2c);
 
 	disable_irq_wake(info->irq);
 
 	return 0;
 }
 #endif
 
 static SIMPLE_DEV_PM_OPS(sm5502_muic_pm_ops,
 			 sm5502_muic_suspend, sm5502_muic_resume);
 
 static const struct i2c_device_id sm5502_i2c_id[] = {
 	{ "sm5502", TYPE_SM5502 },
 	{ }
 };
 MODULE_DEVICE_TABLE(i2c, sm5502_i2c_id);
 
 static struct i2c_driver sm5502_muic_i2c_driver = {
 	.driver		= {
 		.name	= "sm5502",
 		.pm	= &sm5502_muic_pm_ops,
 		.of_match_table = sm5502_dt_match,
 	},
 	.probe	= sm5022_muic_i2c_probe,
 	.remove	= sm5502_muic_i2c_remove,
 	.id_table = sm5502_i2c_id,
 };
 
 static int __init sm5502_muic_i2c_init(void)
 {
 	return i2c_add_driver(&sm5502_muic_i2c_driver);
 }
 subsys_initcall(sm5502_muic_i2c_init);
 
 MODULE_DESCRIPTION("Silicon Mitus SM5502 Extcon driver");
 MODULE_AUTHOR("Chanwoo Choi <cw00.choi@samsung.com>");
 MODULE_LICENSE("GPL");
diff --git a/drivers/extcon/extcon-usb-gpio.c b/drivers/extcon/extcon-usb-gpio.c
index d589c5feff3d..a5e1882b4ca6 100644
--- a/drivers/extcon/extcon-usb-gpio.c
+++ b/drivers/extcon/extcon-usb-gpio.c
@@ -1,316 +1,323 @@
 /**
  * drivers/extcon/extcon-usb-gpio.c - USB GPIO extcon driver
  *
  * Copyright (C) 2015 Texas Instruments Incorporated - http://www.ti.com
  * Author: Roger Quadros <rogerq@ti.com>
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License version 2 as
  * published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
  */
 
 #include <linux/extcon.h>
 #include <linux/gpio.h>
 #include <linux/gpio/consumer.h>
 #include <linux/init.h>
 #include <linux/interrupt.h>
 #include <linux/irq.h>
 #include <linux/kernel.h>
 #include <linux/module.h>
 #include <linux/of_gpio.h>
 #include <linux/platform_device.h>
 #include <linux/slab.h>
 #include <linux/workqueue.h>
 #include <linux/acpi.h>
+#include <linux/pinctrl/consumer.h>
 
 #define USB_GPIO_DEBOUNCE_MS	20	/* ms */
 
 struct usb_extcon_info {
 	struct device *dev;
 	struct extcon_dev *edev;
 
 	struct gpio_desc *id_gpiod;
 	struct gpio_desc *vbus_gpiod;
 	int id_irq;
 	int vbus_irq;
 
 	unsigned long debounce_jiffies;
 	struct delayed_work wq_detcable;
 };
 
 static const unsigned int usb_extcon_cable[] = {
 	EXTCON_USB,
 	EXTCON_USB_HOST,
 	EXTCON_NONE,
 };
 
 /*
  * "USB" = VBUS and "USB-HOST" = !ID, so we have:
  * Both "USB" and "USB-HOST" can't be set as active at the
  * same time so if "USB-HOST" is active (i.e. ID is 0)  we keep "USB" inactive
  * even if VBUS is on.
  *
  *  State              |    ID   |   VBUS
  * ----------------------------------------
  *  [1] USB            |    H    |    H
  *  [2] none           |    H    |    L
  *  [3] USB-HOST       |    L    |    H
  *  [4] USB-HOST       |    L    |    L
  *
  * In case we have only one of these signals:
  * - VBUS only - we want to distinguish between [1] and [2], so ID is always 1.
  * - ID only - we want to distinguish between [1] and [4], so VBUS = ID.
 */
 static void usb_extcon_detect_cable(struct work_struct *work)
 {
 	int id, vbus;
 	struct usb_extcon_info *info = container_of(to_delayed_work(work),
 						    struct usb_extcon_info,
 						    wq_detcable);
 
 	/* check ID and VBUS and update cable state */
 	id = info->id_gpiod ?
 		gpiod_get_value_cansleep(info->id_gpiod) : 1;
 	vbus = info->vbus_gpiod ?
 		gpiod_get_value_cansleep(info->vbus_gpiod) : id;
 
 	/* at first we clean states which are no longer active */
 	if (id)
 		extcon_set_state_sync(info->edev, EXTCON_USB_HOST, false);
 	if (!vbus)
 		extcon_set_state_sync(info->edev, EXTCON_USB, false);
 
 	if (!id) {
 		extcon_set_state_sync(info->edev, EXTCON_USB_HOST, true);
 	} else {
 		if (vbus)
 			extcon_set_state_sync(info->edev, EXTCON_USB, true);
 	}
 }
 
 static irqreturn_t usb_irq_handler(int irq, void *dev_id)
 {
 	struct usb_extcon_info *info = dev_id;
 
 	queue_delayed_work(system_power_efficient_wq, &info->wq_detcable,
 			   info->debounce_jiffies);
 
 	return IRQ_HANDLED;
 }
 
 static int usb_extcon_probe(struct platform_device *pdev)
 {
 	struct device *dev = &pdev->dev;
 	struct device_node *np = dev->of_node;
 	struct usb_extcon_info *info;
 	int ret;
 
 	if (!np && !ACPI_HANDLE(dev))
 		return -EINVAL;
 
 	info = devm_kzalloc(&pdev->dev, sizeof(*info), GFP_KERNEL);
 	if (!info)
 		return -ENOMEM;
 
 	info->dev = dev;
 	info->id_gpiod = devm_gpiod_get_optional(&pdev->dev, "id", GPIOD_IN);
 	info->vbus_gpiod = devm_gpiod_get_optional(&pdev->dev, "vbus",
 						   GPIOD_IN);
 
 	if (!info->id_gpiod && !info->vbus_gpiod) {
 		dev_err(dev, "failed to get gpios\n");
 		return -ENODEV;
 	}
 
 	if (IS_ERR(info->id_gpiod))
 		return PTR_ERR(info->id_gpiod);
 
 	if (IS_ERR(info->vbus_gpiod))
 		return PTR_ERR(info->vbus_gpiod);
 
 	info->edev = devm_extcon_dev_allocate(dev, usb_extcon_cable);
 	if (IS_ERR(info->edev)) {
 		dev_err(dev, "failed to allocate extcon device\n");
 		return -ENOMEM;
 	}
 
 	ret = devm_extcon_dev_register(dev, info->edev);
 	if (ret < 0) {
 		dev_err(dev, "failed to register extcon device\n");
 		return ret;
 	}
 
 	if (info->id_gpiod)
 		ret = gpiod_set_debounce(info->id_gpiod,
 					 USB_GPIO_DEBOUNCE_MS * 1000);
 	if (!ret && info->vbus_gpiod)
 		ret = gpiod_set_debounce(info->vbus_gpiod,
 					 USB_GPIO_DEBOUNCE_MS * 1000);
 
 	if (ret < 0)
 		info->debounce_jiffies = msecs_to_jiffies(USB_GPIO_DEBOUNCE_MS);
 
 	INIT_DELAYED_WORK(&info->wq_detcable, usb_extcon_detect_cable);
 
 	if (info->id_gpiod) {
 		info->id_irq = gpiod_to_irq(info->id_gpiod);
 		if (info->id_irq < 0) {
 			dev_err(dev, "failed to get ID IRQ\n");
 			return info->id_irq;
 		}
 
 		ret = devm_request_threaded_irq(dev, info->id_irq, NULL,
 						usb_irq_handler,
 						IRQF_TRIGGER_RISING |
 						IRQF_TRIGGER_FALLING | IRQF_ONESHOT,
 						pdev->name, info);
 		if (ret < 0) {
 			dev_err(dev, "failed to request handler for ID IRQ\n");
 			return ret;
 		}
 	}
 
 	if (info->vbus_gpiod) {
 		info->vbus_irq = gpiod_to_irq(info->vbus_gpiod);
 		if (info->vbus_irq < 0) {
 			dev_err(dev, "failed to get VBUS IRQ\n");
 			return info->vbus_irq;
 		}
 
 		ret = devm_request_threaded_irq(dev, info->vbus_irq, NULL,
 						usb_irq_handler,
 						IRQF_TRIGGER_RISING |
 						IRQF_TRIGGER_FALLING | IRQF_ONESHOT,
 						pdev->name, info);
 		if (ret < 0) {
 			dev_err(dev, "failed to request handler for VBUS IRQ\n");
 			return ret;
 		}
 	}
 
 	platform_set_drvdata(pdev, info);
 	device_init_wakeup(dev, true);
 
 	/* Perform initial detection */
 	usb_extcon_detect_cable(&info->wq_detcable.work);
 
 	return 0;
 }
 
 static int usb_extcon_remove(struct platform_device *pdev)
 {
 	struct usb_extcon_info *info = platform_get_drvdata(pdev);
 
 	cancel_delayed_work_sync(&info->wq_detcable);
 	device_init_wakeup(&pdev->dev, false);
 
 	return 0;
 }
 
 #ifdef CONFIG_PM_SLEEP
 static int usb_extcon_suspend(struct device *dev)
 {
 	struct usb_extcon_info *info = dev_get_drvdata(dev);
 	int ret = 0;
 
 	if (device_may_wakeup(dev)) {
 		if (info->id_gpiod) {
 			ret = enable_irq_wake(info->id_irq);
 			if (ret)
 				return ret;
 		}
 		if (info->vbus_gpiod) {
 			ret = enable_irq_wake(info->vbus_irq);
 			if (ret) {
 				if (info->id_gpiod)
 					disable_irq_wake(info->id_irq);
 
 				return ret;
 			}
 		}
 	}
 
 	/*
 	 * We don't want to process any IRQs after this point
 	 * as GPIOs used behind I2C subsystem might not be
 	 * accessible until resume completes. So disable IRQ.
 	 */
 	if (info->id_gpiod)
 		disable_irq(info->id_irq);
 	if (info->vbus_gpiod)
 		disable_irq(info->vbus_irq);
 
+	if (!device_may_wakeup(dev))
+		pinctrl_pm_select_sleep_state(dev);
+
 	return ret;
 }
 
 static int usb_extcon_resume(struct device *dev)
 {
 	struct usb_extcon_info *info = dev_get_drvdata(dev);
 	int ret = 0;
 
+	if (!device_may_wakeup(dev))
+		pinctrl_pm_select_default_state(dev);
+
 	if (device_may_wakeup(dev)) {
 		if (info->id_gpiod) {
 			ret = disable_irq_wake(info->id_irq);
 			if (ret)
 				return ret;
 		}
 		if (info->vbus_gpiod) {
 			ret = disable_irq_wake(info->vbus_irq);
 			if (ret) {
 				if (info->id_gpiod)
 					enable_irq_wake(info->id_irq);
 
 				return ret;
 			}
 		}
 	}
 
 	if (info->id_gpiod)
 		enable_irq(info->id_irq);
 	if (info->vbus_gpiod)
 		enable_irq(info->vbus_irq);
 
 	if (!device_may_wakeup(dev))
 		queue_delayed_work(system_power_efficient_wq,
 				   &info->wq_detcable, 0);
 
 	return ret;
 }
 #endif
 
 static SIMPLE_DEV_PM_OPS(usb_extcon_pm_ops,
 			 usb_extcon_suspend, usb_extcon_resume);
 
 static const struct of_device_id usb_extcon_dt_match[] = {
 	{ .compatible = "linux,extcon-usb-gpio", },
 	{ /* sentinel */ }
 };
 MODULE_DEVICE_TABLE(of, usb_extcon_dt_match);
 
 static const struct platform_device_id usb_extcon_platform_ids[] = {
 	{ .name = "extcon-usb-gpio", },
 	{ /* sentinel */ }
 };
 MODULE_DEVICE_TABLE(platform, usb_extcon_platform_ids);
 
 static struct platform_driver usb_extcon_driver = {
 	.probe		= usb_extcon_probe,
 	.remove		= usb_extcon_remove,
 	.driver		= {
 		.name	= "extcon-usb-gpio",
 		.pm	= &usb_extcon_pm_ops,
 		.of_match_table = usb_extcon_dt_match,
 	},
 	.id_table = usb_extcon_platform_ids,
 };
 
 module_platform_driver(usb_extcon_driver);
 
 MODULE_AUTHOR("Roger Quadros <rogerq@ti.com>");
 MODULE_DESCRIPTION("USB GPIO extcon driver");
 MODULE_LICENSE("GPL v2");
diff --git a/drivers/extcon/extcon.c b/drivers/extcon/extcon.c
index 7c1e3a7b14e0..09ac5e70c2f3 100644
--- a/drivers/extcon/extcon.c
+++ b/drivers/extcon/extcon.c
@@ -1,1386 +1,1373 @@
 /*
  *  drivers/extcon/extcon.c - External Connector (extcon) framework.
  *
  *  External connector (extcon) class driver
  *
  * Copyright (C) 2015 Samsung Electronics
  * Author: Chanwoo Choi <cw00.choi@samsung.com>
  *
  * Copyright (C) 2012 Samsung Electronics
  * Author: Donggeun Kim <dg77.kim@samsung.com>
  * Author: MyungJoo Ham <myungjoo.ham@samsung.com>
  *
  * based on android/drivers/switch/switch_class.c
  * Copyright (C) 2008 Google, Inc.
  * Author: Mike Lockwood <lockwood@android.com>
  *
  * This software is licensed under the terms of the GNU General Public
  * License version 2, as published by the Free Software Foundation, and
  * may be copied, distributed, and modified under those terms.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
  */
 
 #include <linux/module.h>
 #include <linux/types.h>
 #include <linux/init.h>
 #include <linux/device.h>
 #include <linux/fs.h>
 #include <linux/err.h>
-#include <linux/extcon.h>
 #include <linux/of.h>
 #include <linux/slab.h>
 #include <linux/sysfs.h>
 
+#include "extcon.h"
+
 #define SUPPORTED_CABLE_MAX	32
 #define CABLE_NAME_MAX		30
 
 struct __extcon_info {
 	unsigned int type;
 	unsigned int id;
 	const char *name;
 
 } extcon_info[] = {
 	[EXTCON_NONE] = {
 		.type = EXTCON_TYPE_MISC,
 		.id = EXTCON_NONE,
 		.name = "NONE",
 	},
 
 	/* USB external connector */
 	[EXTCON_USB] = {
 		.type = EXTCON_TYPE_USB,
 		.id = EXTCON_USB,
 		.name = "USB",
 	},
 	[EXTCON_USB_HOST] = {
 		.type = EXTCON_TYPE_USB,
 		.id = EXTCON_USB_HOST,
-		.name = "USB_HOST",
+		.name = "USB-HOST",
 	},
 
 	/* Charging external connector */
 	[EXTCON_CHG_USB_SDP] = {
 		.type = EXTCON_TYPE_CHG | EXTCON_TYPE_USB,
 		.id = EXTCON_CHG_USB_SDP,
 		.name = "SDP",
 	},
 	[EXTCON_CHG_USB_DCP] = {
 		.type = EXTCON_TYPE_CHG | EXTCON_TYPE_USB,
 		.id = EXTCON_CHG_USB_DCP,
 		.name = "DCP",
 	},
 	[EXTCON_CHG_USB_CDP] = {
 		.type = EXTCON_TYPE_CHG | EXTCON_TYPE_USB,
 		.id = EXTCON_CHG_USB_CDP,
 		.name = "CDP",
 	},
 	[EXTCON_CHG_USB_ACA] = {
 		.type = EXTCON_TYPE_CHG | EXTCON_TYPE_USB,
 		.id = EXTCON_CHG_USB_ACA,
 		.name = "ACA",
 	},
 	[EXTCON_CHG_USB_FAST] = {
 		.type = EXTCON_TYPE_CHG | EXTCON_TYPE_USB,
 		.id = EXTCON_CHG_USB_FAST,
 		.name = "FAST-CHARGER",
 	},
 	[EXTCON_CHG_USB_SLOW] = {
 		.type = EXTCON_TYPE_CHG | EXTCON_TYPE_USB,
 		.id = EXTCON_CHG_USB_SLOW,
 		.name = "SLOW-CHARGER",
 	},
 	[EXTCON_CHG_WPT] = {
 		.type = EXTCON_TYPE_CHG,
 		.id = EXTCON_CHG_WPT,
 		.name = "WPT",
 	},
+	[EXTCON_CHG_USB_PD] = {
+		.type = EXTCON_TYPE_CHG | EXTCON_TYPE_USB,
+		.id = EXTCON_CHG_USB_PD,
+		.name = "PD",
+	},
 
 	/* Jack external connector */
 	[EXTCON_JACK_MICROPHONE] = {
 		.type = EXTCON_TYPE_JACK,
 		.id = EXTCON_JACK_MICROPHONE,
 		.name = "MICROPHONE",
 	},
 	[EXTCON_JACK_HEADPHONE] = {
 		.type = EXTCON_TYPE_JACK,
 		.id = EXTCON_JACK_HEADPHONE,
 		.name = "HEADPHONE",
 	},
 	[EXTCON_JACK_LINE_IN] = {
 		.type = EXTCON_TYPE_JACK,
 		.id = EXTCON_JACK_LINE_IN,
 		.name = "LINE-IN",
 	},
 	[EXTCON_JACK_LINE_OUT] = {
 		.type = EXTCON_TYPE_JACK,
 		.id = EXTCON_JACK_LINE_OUT,
 		.name = "LINE-OUT",
 	},
 	[EXTCON_JACK_VIDEO_IN] = {
 		.type = EXTCON_TYPE_JACK,
 		.id = EXTCON_JACK_VIDEO_IN,
 		.name = "VIDEO-IN",
 	},
 	[EXTCON_JACK_VIDEO_OUT] = {
 		.type = EXTCON_TYPE_JACK,
 		.id = EXTCON_JACK_VIDEO_OUT,
 		.name = "VIDEO-OUT",
 	},
 	[EXTCON_JACK_SPDIF_IN] = {
 		.type = EXTCON_TYPE_JACK,
 		.id = EXTCON_JACK_SPDIF_IN,
 		.name = "SPDIF-IN",
 	},
 	[EXTCON_JACK_SPDIF_OUT] = {
 		.type = EXTCON_TYPE_JACK,
 		.id = EXTCON_JACK_SPDIF_OUT,
 		.name = "SPDIF-OUT",
 	},
 
 	/* Display external connector */
 	[EXTCON_DISP_HDMI] = {
 		.type = EXTCON_TYPE_DISP,
 		.id = EXTCON_DISP_HDMI,
 		.name = "HDMI",
 	},
 	[EXTCON_DISP_MHL] = {
 		.type = EXTCON_TYPE_DISP,
 		.id = EXTCON_DISP_MHL,
 		.name = "MHL",
 	},
 	[EXTCON_DISP_DVI] = {
 		.type = EXTCON_TYPE_DISP,
 		.id = EXTCON_DISP_DVI,
 		.name = "DVI",
 	},
 	[EXTCON_DISP_VGA] = {
 		.type = EXTCON_TYPE_DISP,
 		.id = EXTCON_DISP_VGA,
 		.name = "VGA",
 	},
 	[EXTCON_DISP_DP] = {
 		.type = EXTCON_TYPE_DISP | EXTCON_TYPE_USB,
 		.id = EXTCON_DISP_DP,
 		.name = "DP",
 	},
 	[EXTCON_DISP_HMD] = {
 		.type = EXTCON_TYPE_DISP | EXTCON_TYPE_USB,
 		.id = EXTCON_DISP_HMD,
 		.name = "HMD",
 	},
 
 	/* Miscellaneous external connector */
 	[EXTCON_DOCK] = {
 		.type = EXTCON_TYPE_MISC,
 		.id = EXTCON_DOCK,
 		.name = "DOCK",
 	},
 	[EXTCON_JIG] = {
 		.type = EXTCON_TYPE_MISC,
 		.id = EXTCON_JIG,
 		.name = "JIG",
 	},
 	[EXTCON_MECHANICAL] = {
 		.type = EXTCON_TYPE_MISC,
 		.id = EXTCON_MECHANICAL,
 		.name = "MECHANICAL",
 	},
 
 	{ /* sentinel */ }
 };
 
 /**
  * struct extcon_cable - An internal data for each cable of extcon device.
  * @edev:		The extcon device
  * @cable_index:	Index of this cable in the edev
  * @attr_g:		Attribute group for the cable
  * @attr_name:		"name" sysfs entry
  * @attr_state:		"state" sysfs entry
  * @attrs:		Array pointing to attr_name and attr_state for attr_g
  */
 struct extcon_cable {
 	struct extcon_dev *edev;
 	int cable_index;
 
 	struct attribute_group attr_g;
 	struct device_attribute attr_name;
 	struct device_attribute attr_state;
 
 	struct attribute *attrs[3]; /* to be fed to attr_g.attrs */
 
 	union extcon_property_value usb_propval[EXTCON_PROP_USB_CNT];
 	union extcon_property_value chg_propval[EXTCON_PROP_CHG_CNT];
 	union extcon_property_value jack_propval[EXTCON_PROP_JACK_CNT];
 	union extcon_property_value disp_propval[EXTCON_PROP_DISP_CNT];
 
 	unsigned long usb_bits[BITS_TO_LONGS(EXTCON_PROP_USB_CNT)];
 	unsigned long chg_bits[BITS_TO_LONGS(EXTCON_PROP_CHG_CNT)];
 	unsigned long jack_bits[BITS_TO_LONGS(EXTCON_PROP_JACK_CNT)];
 	unsigned long disp_bits[BITS_TO_LONGS(EXTCON_PROP_DISP_CNT)];
 };
 
 static struct class *extcon_class;
 #if defined(CONFIG_ANDROID)
 static struct class_compat *switch_class;
 #endif /* CONFIG_ANDROID */
 
 static LIST_HEAD(extcon_dev_list);
 static DEFINE_MUTEX(extcon_dev_list_lock);
 
 /**
  * check_mutually_exclusive - Check if new_state violates mutually_exclusive
  *			      condition.
  * @edev:	the extcon device
  * @new_state:	new cable attach status for @edev
  *
  * Returns 0 if nothing violates. Returns the index + 1 for the first
  * violated condition.
  */
 static int check_mutually_exclusive(struct extcon_dev *edev, u32 new_state)
 {
 	int i = 0;
 
 	if (!edev->mutually_exclusive)
 		return 0;
 
 	for (i = 0; edev->mutually_exclusive[i]; i++) {
 		int weight;
 		u32 correspondants = new_state & edev->mutually_exclusive[i];
 
 		/* calculate the total number of bits set */
 		weight = hweight32(correspondants);
 		if (weight > 1)
 			return i + 1;
 	}
 
 	return 0;
 }
 
 static int find_cable_index_by_id(struct extcon_dev *edev, const unsigned int id)
 {
 	int i;
 
 	/* Find the the index of extcon cable in edev->supported_cable */
 	for (i = 0; i < edev->max_supported; i++) {
 		if (edev->supported_cable[i] == id)
 			return i;
 	}
 
 	return -EINVAL;
 }
 
 static int get_extcon_type(unsigned int prop)
 {
 	switch (prop) {
 	case EXTCON_PROP_USB_MIN ... EXTCON_PROP_USB_MAX:
 		return EXTCON_TYPE_USB;
 	case EXTCON_PROP_CHG_MIN ... EXTCON_PROP_CHG_MAX:
 		return EXTCON_TYPE_CHG;
 	case EXTCON_PROP_JACK_MIN ... EXTCON_PROP_JACK_MAX:
 		return EXTCON_TYPE_JACK;
 	case EXTCON_PROP_DISP_MIN ... EXTCON_PROP_DISP_MAX:
 		return EXTCON_TYPE_DISP;
 	default:
 		return -EINVAL;
 	}
 }
 
 static bool is_extcon_attached(struct extcon_dev *edev, unsigned int index)
 {
 	return !!(edev->state & BIT(index));
 }
 
 static bool is_extcon_changed(struct extcon_dev *edev, int index,
 				bool new_state)
 {
 	int state = !!(edev->state & BIT(index));
 	return (state != new_state);
 }
 
 static bool is_extcon_property_supported(unsigned int id, unsigned int prop)
 {
 	int type;
 
 	/* Check whether the property is supported or not. */
 	type = get_extcon_type(prop);
 	if (type < 0)
 		return false;
 
 	/* Check whether a specific extcon id supports the property or not. */
 	return !!(extcon_info[id].type & type);
 }
 
 static int is_extcon_property_capability(struct extcon_dev *edev,
 				unsigned int id, int index,unsigned int prop)
 {
 	struct extcon_cable *cable;
 	int type, ret;
 
 	/* Check whether the property is supported or not. */
 	type = get_extcon_type(prop);
 	if (type < 0)
 		return type;
 
 	cable = &edev->cables[index];
 
 	switch (type) {
 	case EXTCON_TYPE_USB:
 		ret = test_bit(prop - EXTCON_PROP_USB_MIN, cable->usb_bits);
 		break;
 	case EXTCON_TYPE_CHG:
 		ret = test_bit(prop - EXTCON_PROP_CHG_MIN, cable->chg_bits);
 		break;
 	case EXTCON_TYPE_JACK:
 		ret = test_bit(prop - EXTCON_PROP_JACK_MIN, cable->jack_bits);
 		break;
 	case EXTCON_TYPE_DISP:
 		ret = test_bit(prop - EXTCON_PROP_DISP_MIN, cable->disp_bits);
 		break;
 	default:
 		ret = -EINVAL;
 	}
 
 	return ret;
 }
 
 static void init_property(struct extcon_dev *edev, unsigned int id, int index)
 {
 	unsigned int type = extcon_info[id].type;
 	struct extcon_cable *cable = &edev->cables[index];
 
 	if (EXTCON_TYPE_USB & type)
 		memset(cable->usb_propval, 0, sizeof(cable->usb_propval));
 	if (EXTCON_TYPE_CHG & type)
 		memset(cable->chg_propval, 0, sizeof(cable->chg_propval));
 	if (EXTCON_TYPE_JACK & type)
 		memset(cable->jack_propval, 0, sizeof(cable->jack_propval));
 	if (EXTCON_TYPE_DISP & type)
 		memset(cable->disp_propval, 0, sizeof(cable->disp_propval));
 }
 
 static ssize_t state_show(struct device *dev, struct device_attribute *attr,
 			  char *buf)
 {
 	int i, count = 0;
 	struct extcon_dev *edev = dev_get_drvdata(dev);
 
 	if (edev->max_supported == 0)
 		return sprintf(buf, "%u\n", edev->state);
 
 	for (i = 0; i < edev->max_supported; i++) {
 		count += sprintf(buf + count, "%s=%d\n",
 				extcon_info[edev->supported_cable[i]].name,
 				 !!(edev->state & (1 << i)));
 	}
 
 	return count;
 }
 static DEVICE_ATTR_RO(state);
 
 static ssize_t name_show(struct device *dev, struct device_attribute *attr,
 		char *buf)
 {
 	struct extcon_dev *edev = dev_get_drvdata(dev);
 
 	return sprintf(buf, "%s\n", edev->name);
 }
 static DEVICE_ATTR_RO(name);
 
 static ssize_t cable_name_show(struct device *dev,
 			       struct device_attribute *attr, char *buf)
 {
 	struct extcon_cable *cable = container_of(attr, struct extcon_cable,
 						  attr_name);
 	int i = cable->cable_index;
 
 	return sprintf(buf, "%s\n",
 			extcon_info[cable->edev->supported_cable[i]].name);
 }
 
 static ssize_t cable_state_show(struct device *dev,
 				struct device_attribute *attr, char *buf)
 {
 	struct extcon_cable *cable = container_of(attr, struct extcon_cable,
 						  attr_state);
 
 	int i = cable->cable_index;
 
 	return sprintf(buf, "%d\n",
 		extcon_get_state(cable->edev, cable->edev->supported_cable[i]));
 }
 
 /**
  * extcon_sync()	- Synchronize the states for both the attached/detached
  * @edev:		the extcon device that has the cable.
  *
  * This function send a notification to synchronize the all states of a
  * specific external connector
  */
 int extcon_sync(struct extcon_dev *edev, unsigned int id)
 {
 	char name_buf[120];
 	char state_buf[120];
 	char *prop_buf;
 	char *envp[3];
 	int env_offset = 0;
 	int length;
 	int index;
 	int state;
 	unsigned long flags;
 
 	if (!edev)
 		return -EINVAL;
 
 	index = find_cable_index_by_id(edev, id);
 	if (index < 0)
 		return index;
 
 	spin_lock_irqsave(&edev->lock, flags);
 
 	state = !!(edev->state & BIT(index));
 	raw_notifier_call_chain(&edev->nh[index], state, edev);
 
 	/* This could be in interrupt handler */
 	prop_buf = (char *)get_zeroed_page(GFP_ATOMIC);
 	if (!prop_buf) {
 		/* Unlock early before uevent */
 		spin_unlock_irqrestore(&edev->lock, flags);
 
 		dev_err(&edev->dev, "out of memory in extcon_set_state\n");
 		kobject_uevent(&edev->dev.kobj, KOBJ_CHANGE);
 
 		return -ENOMEM;
 	}
 
 	length = name_show(&edev->dev, NULL, prop_buf);
 	if (length > 0) {
 		if (prop_buf[length - 1] == '\n')
 			prop_buf[length - 1] = 0;
 		snprintf(name_buf, sizeof(name_buf), "NAME=%s", prop_buf);
 		envp[env_offset++] = name_buf;
 	}
 
 	length = state_show(&edev->dev, NULL, prop_buf);
 	if (length > 0) {
 		if (prop_buf[length - 1] == '\n')
 			prop_buf[length - 1] = 0;
 		snprintf(state_buf, sizeof(state_buf), "STATE=%s", prop_buf);
 		envp[env_offset++] = state_buf;
 	}
 	envp[env_offset] = NULL;
 
 	/* Unlock early before uevent */
 	spin_unlock_irqrestore(&edev->lock, flags);
 	kobject_uevent_env(&edev->dev.kobj, KOBJ_CHANGE, envp);
 	free_page((unsigned long)prop_buf);
 
 	return 0;
 }
 EXPORT_SYMBOL_GPL(extcon_sync);
 
 /**
  * extcon_get_state() - Get the state of a external connector.
  * @edev:	the extcon device that has the cable.
  * @id:		the unique id of each external connector in extcon enumeration.
  */
 int extcon_get_state(struct extcon_dev *edev, const unsigned int id)
 {
 	int index, state;
 	unsigned long flags;
 
 	if (!edev)
 		return -EINVAL;
 
 	index = find_cable_index_by_id(edev, id);
 	if (index < 0)
 		return index;
 
 	spin_lock_irqsave(&edev->lock, flags);
 	state = is_extcon_attached(edev, index);
 	spin_unlock_irqrestore(&edev->lock, flags);
 
 	return state;
 }
 EXPORT_SYMBOL_GPL(extcon_get_state);
 
 /**
  * extcon_set_state() - Set the state of a external connector.
  *			without a notification.
  * @edev:		the extcon device that has the cable.
  * @id:			the unique id of each external connector
  *			in extcon enumeration.
  * @state:		the new cable status. The default semantics is
  *			true: attached / false: detached.
  *
  * This function only set the state of a external connector without
  * a notification. To synchronize the data of a external connector,
  * use extcon_set_state_sync() and extcon_sync().
  */
 int extcon_set_state(struct extcon_dev *edev, unsigned int id,
 				bool cable_state)
 {
 	unsigned long flags;
 	int index, ret = 0;
 
 	if (!edev)
 		return -EINVAL;
 
 	index = find_cable_index_by_id(edev, id);
 	if (index < 0)
 		return index;
 
 	spin_lock_irqsave(&edev->lock, flags);
 
 	/* Check whether the external connector's state is changed. */
 	if (!is_extcon_changed(edev, index, cable_state))
 		goto out;
 
 	if (check_mutually_exclusive(edev,
 		(edev->state & ~BIT(index)) | (cable_state & BIT(index)))) {
 		ret = -EPERM;
 		goto out;
 	}
 
 	/*
 	 * Initialize the value of extcon property before setting
 	 * the detached state for an external connector.
 	 */
 	if (!cable_state)
 		init_property(edev, id, index);
 
 	/* Update the state for a external connector. */
 	if (cable_state)
 		edev->state |= BIT(index);
 	else
 		edev->state &= ~(BIT(index));
 out:
 	spin_unlock_irqrestore(&edev->lock, flags);
 
 	return ret;
 }
 EXPORT_SYMBOL_GPL(extcon_set_state);
 
 /**
  * extcon_set_state_sync() - Set the state of a external connector
  *			with a notification.
  * @edev:		the extcon device that has the cable.
  * @id:			the unique id of each external connector
  *			in extcon enumeration.
  * @state:		the new cable status. The default semantics is
  *			true: attached / false: detached.
  *
  * This function set the state of external connector and synchronize the data
  * by usning a notification.
  */
 int extcon_set_state_sync(struct extcon_dev *edev, unsigned int id,
 				bool cable_state)
 {
 	int ret, index;
 	unsigned long flags;
 
 	index = find_cable_index_by_id(edev, id);
 	if (index < 0)
 		return index;
 
 	/* Check whether the external connector's state is changed. */
 	spin_lock_irqsave(&edev->lock, flags);
 	ret = is_extcon_changed(edev, index, cable_state);
 	spin_unlock_irqrestore(&edev->lock, flags);
 	if (!ret)
 		return 0;
 
 	ret = extcon_set_state(edev, id, cable_state);
 	if (ret < 0)
 		return ret;
 
 	return extcon_sync(edev, id);
 }
 EXPORT_SYMBOL_GPL(extcon_set_state_sync);
 
 /**
  * extcon_get_property() - Get the property value of a specific cable.
  * @edev:		the extcon device that has the cable.
  * @id:			the unique id of each external connector
  *			in extcon enumeration.
  * @prop:		the property id among enum extcon_property.
  * @prop_val:		the pointer which store the value of property.
  *
  * When getting the property value of external connector, the external connector
  * should be attached. If detached state, function just return 0 without
  * property value. Also, the each property should be included in the list of
  * supported properties according to the type of external connectors.
  *
  * Returns 0 if success or error number if fail
  */
 int extcon_get_property(struct extcon_dev *edev, unsigned int id,
 				unsigned int prop,
 				union extcon_property_value *prop_val)
 {
 	struct extcon_cable *cable;
 	unsigned long flags;
 	int index, ret = 0;
 
 	*prop_val = (union extcon_property_value)(0);
 
 	if (!edev)
 		return -EINVAL;
 
 	/* Check whether the property is supported or not */
 	if (!is_extcon_property_supported(id, prop))
 		return -EINVAL;
 
 	/* Find the cable index of external connector by using id */
 	index = find_cable_index_by_id(edev, id);
 	if (index < 0)
 		return index;
 
 	spin_lock_irqsave(&edev->lock, flags);
 
 	/* Check whether the property is available or not. */
 	if (!is_extcon_property_capability(edev, id, index, prop)) {
 		spin_unlock_irqrestore(&edev->lock, flags);
 		return -EPERM;
 	}
 
 	/*
 	 * Check whether the external connector is attached.
 	 * If external connector is detached, the user can not
 	 * get the property value.
 	 */
 	if (!is_extcon_attached(edev, index)) {
 		spin_unlock_irqrestore(&edev->lock, flags);
 		return 0;
 	}
 
 	cable = &edev->cables[index];
 
 	/* Get the property value according to extcon type */
 	switch (prop) {
 	case EXTCON_PROP_USB_MIN ... EXTCON_PROP_USB_MAX:
 		*prop_val = cable->usb_propval[prop - EXTCON_PROP_USB_MIN];
 		break;
 	case EXTCON_PROP_CHG_MIN ... EXTCON_PROP_CHG_MAX:
 		*prop_val = cable->chg_propval[prop - EXTCON_PROP_CHG_MIN];
 		break;
 	case EXTCON_PROP_JACK_MIN ... EXTCON_PROP_JACK_MAX:
 		*prop_val = cable->jack_propval[prop - EXTCON_PROP_JACK_MIN];
 		break;
 	case EXTCON_PROP_DISP_MIN ... EXTCON_PROP_DISP_MAX:
 		*prop_val = cable->disp_propval[prop - EXTCON_PROP_DISP_MIN];
 		break;
 	default:
 		ret = -EINVAL;
 		break;
 	}
 
 	spin_unlock_irqrestore(&edev->lock, flags);
 
 	return ret;
 }
 EXPORT_SYMBOL_GPL(extcon_get_property);
 
 /**
  * extcon_set_property() - Set the property value of a specific cable.
  * @edev:		the extcon device that has the cable.
  * @id:			the unique id of each external connector
  *			in extcon enumeration.
  * @prop:		the property id among enum extcon_property.
  * @prop_val:		the pointer including the new value of property.
  *
  * The each property should be included in the list of supported properties
  * according to the type of external connectors.
  *
  * Returns 0 if success or error number if fail
  */
 int extcon_set_property(struct extcon_dev *edev, unsigned int id,
 				unsigned int prop,
 				union extcon_property_value prop_val)
 {
 	struct extcon_cable *cable;
 	unsigned long flags;
 	int index, ret = 0;
 
 	if (!edev)
 		return -EINVAL;
 
 	/* Check whether the property is supported or not */
 	if (!is_extcon_property_supported(id, prop))
 		return -EINVAL;
 
 	/* Find the cable index of external connector by using id */
 	index = find_cable_index_by_id(edev, id);
 	if (index < 0)
 		return index;
 
 	spin_lock_irqsave(&edev->lock, flags);
 
 	/* Check whether the property is available or not. */
 	if (!is_extcon_property_capability(edev, id, index, prop)) {
 		spin_unlock_irqrestore(&edev->lock, flags);
 		return -EPERM;
 	}
 
 	cable = &edev->cables[index];
 
 	/* Set the property value according to extcon type */
 	switch (prop) {
 	case EXTCON_PROP_USB_MIN ... EXTCON_PROP_USB_MAX:
 		cable->usb_propval[prop - EXTCON_PROP_USB_MIN] = prop_val;
 		break;
 	case EXTCON_PROP_CHG_MIN ... EXTCON_PROP_CHG_MAX:
 		cable->chg_propval[prop - EXTCON_PROP_CHG_MIN] = prop_val;
 		break;
 	case EXTCON_PROP_JACK_MIN ... EXTCON_PROP_JACK_MAX:
 		cable->jack_propval[prop - EXTCON_PROP_JACK_MIN] = prop_val;
 		break;
 	case EXTCON_PROP_DISP_MIN ... EXTCON_PROP_DISP_MAX:
 		cable->disp_propval[prop - EXTCON_PROP_DISP_MIN] = prop_val;
 		break;
 	default:
 		ret = -EINVAL;
 		break;
 	}
 
 	spin_unlock_irqrestore(&edev->lock, flags);
 
 	return ret;
 }
 EXPORT_SYMBOL_GPL(extcon_set_property);
 
 /**
  * extcon_set_property_sync() - Set the property value of a specific cable
 			with a notification.
  * @prop_val:		the pointer including the new value of property.
  *
  * When setting the property value of external connector, the external connector
  * should be attached. The each property should be included in the list of
  * supported properties according to the type of external connectors.
  *
  * Returns 0 if success or error number if fail
  */
 int extcon_set_property_sync(struct extcon_dev *edev, unsigned int id,
 				unsigned int prop,
 				union extcon_property_value prop_val)
 {
 	int ret;
 
 	ret = extcon_set_property(edev, id, prop, prop_val);
 	if (ret < 0)
 		return ret;
 
 	return extcon_sync(edev, id);
 }
 EXPORT_SYMBOL_GPL(extcon_set_property_sync);
 
 /**
  * extcon_get_property_capability() - Get the capability of property
  *			of an external connector.
  * @edev:		the extcon device that has the cable.
  * @id:			the unique id of each external connector
  *			in extcon enumeration.
  * @prop:		the property id among enum extcon_property.
  *
  * Returns 1 if the property is available or 0 if not available.
  */
 int extcon_get_property_capability(struct extcon_dev *edev, unsigned int id,
 					unsigned int prop)
 {
 	int index;
 
 	if (!edev)
 		return -EINVAL;
 
 	/* Check whether the property is supported or not */
 	if (!is_extcon_property_supported(id, prop))
 		return -EINVAL;
 
 	/* Find the cable index of external connector by using id */
 	index = find_cable_index_by_id(edev, id);
 	if (index < 0)
 		return index;
 
 	return is_extcon_property_capability(edev, id, index, prop);
 }
 EXPORT_SYMBOL_GPL(extcon_get_property_capability);
 
 /**
  * extcon_set_property_capability() - Set the capability of a property
  *			of an external connector.
  * @edev:		the extcon device that has the cable.
  * @id:			the unique id of each external connector
  *			in extcon enumeration.
  * @prop:		the property id among enum extcon_property.
  *
  * This function set the capability of a property for an external connector
  * to mark the bit in capability bitmap which mean the available state of
  * a property.
  *
  * Returns 0 if success or error number if fail
  */
 int extcon_set_property_capability(struct extcon_dev *edev, unsigned int id,
 					unsigned int prop)
 {
 	struct extcon_cable *cable;
 	int index, type, ret = 0;
 
 	if (!edev)
 		return -EINVAL;
 
 	/* Check whether the property is supported or not. */
 	if (!is_extcon_property_supported(id, prop))
 		return -EINVAL;
 
 	/* Find the cable index of external connector by using id. */
 	index = find_cable_index_by_id(edev, id);
 	if (index < 0)
 		return index;
 
 	type = get_extcon_type(prop);
 	if (type < 0)
 		return type;
 
 	cable = &edev->cables[index];
 
 	switch (type) {
 	case EXTCON_TYPE_USB:
 		__set_bit(prop - EXTCON_PROP_USB_MIN, cable->usb_bits);
 		break;
 	case EXTCON_TYPE_CHG:
 		__set_bit(prop - EXTCON_PROP_CHG_MIN, cable->chg_bits);
 		break;
 	case EXTCON_TYPE_JACK:
 		__set_bit(prop - EXTCON_PROP_JACK_MIN, cable->jack_bits);
 		break;
 	case EXTCON_TYPE_DISP:
 		__set_bit(prop - EXTCON_PROP_DISP_MIN, cable->disp_bits);
 		break;
 	default:
 		ret = -EINVAL;
 	}
 
 	return ret;
 }
 EXPORT_SYMBOL_GPL(extcon_set_property_capability);
 
 /**
  * extcon_get_extcon_dev() - Get the extcon device instance from the name
  * @extcon_name:	The extcon name provided with extcon_dev_register()
  */
 struct extcon_dev *extcon_get_extcon_dev(const char *extcon_name)
 {
 	struct extcon_dev *sd;
 
 	if (!extcon_name)
 		return ERR_PTR(-EINVAL);
 
 	mutex_lock(&extcon_dev_list_lock);
 	list_for_each_entry(sd, &extcon_dev_list, entry) {
 		if (!strcmp(sd->name, extcon_name))
 			goto out;
 	}
 	sd = NULL;
 out:
 	mutex_unlock(&extcon_dev_list_lock);
 	return sd;
 }
 EXPORT_SYMBOL_GPL(extcon_get_extcon_dev);
 
 /**
  * extcon_register_notifier() - Register a notifiee to get notified by
  *				any attach status changes from the extcon.
  * @edev:	the extcon device that has the external connecotr.
  * @id:		the unique id of each external connector in extcon enumeration.
  * @nb:		a notifier block to be registered.
  *
  * Note that the second parameter given to the callback of nb (val) is
  * "old_state", not the current state. The current state can be retrieved
  * by looking at the third pameter (edev pointer)'s state value.
  */
 int extcon_register_notifier(struct extcon_dev *edev, unsigned int id,
 			     struct notifier_block *nb)
 {
 	unsigned long flags;
 	int ret, idx = -EINVAL;
 
-	if (!nb)
+	if (!edev || !nb)
 		return -EINVAL;
 
-	if (edev) {
-		idx = find_cable_index_by_id(edev, id);
-		if (idx < 0)
-			return idx;
-
-		spin_lock_irqsave(&edev->lock, flags);
-		ret = raw_notifier_chain_register(&edev->nh[idx], nb);
-		spin_unlock_irqrestore(&edev->lock, flags);
-	} else {
-		struct extcon_dev *extd;
-
-		mutex_lock(&extcon_dev_list_lock);
-		list_for_each_entry(extd, &extcon_dev_list, entry) {
-			idx = find_cable_index_by_id(extd, id);
-			if (idx >= 0)
-				break;
-		}
-		mutex_unlock(&extcon_dev_list_lock);
+	idx = find_cable_index_by_id(edev, id);
+	if (idx < 0)
+		return idx;
 
-		if (idx >= 0) {
-			edev = extd;
-			return extcon_register_notifier(extd, id, nb);
-		} else {
-			ret = -ENODEV;
-		}
-	}
+	spin_lock_irqsave(&edev->lock, flags);
+	ret = raw_notifier_chain_register(&edev->nh[idx], nb);
+	spin_unlock_irqrestore(&edev->lock, flags);
 
 	return ret;
 }
 EXPORT_SYMBOL_GPL(extcon_register_notifier);
 
 /**
  * extcon_unregister_notifier() - Unregister a notifiee from the extcon device.
  * @edev:	the extcon device that has the external connecotr.
  * @id:		the unique id of each external connector in extcon enumeration.
  * @nb:		a notifier block to be registered.
  */
 int extcon_unregister_notifier(struct extcon_dev *edev, unsigned int id,
 				struct notifier_block *nb)
 {
 	unsigned long flags;
 	int ret, idx;
 
 	if (!edev || !nb)
 		return -EINVAL;
 
 	idx = find_cable_index_by_id(edev, id);
 	if (idx < 0)
 		return idx;
 
 	spin_lock_irqsave(&edev->lock, flags);
 	ret = raw_notifier_chain_unregister(&edev->nh[idx], nb);
 	spin_unlock_irqrestore(&edev->lock, flags);
 
 	return ret;
 }
 EXPORT_SYMBOL_GPL(extcon_unregister_notifier);
 
 static struct attribute *extcon_attrs[] = {
 	&dev_attr_state.attr,
 	&dev_attr_name.attr,
 	NULL,
 };
 ATTRIBUTE_GROUPS(extcon);
 
 static int create_extcon_class(void)
 {
 	if (!extcon_class) {
 		extcon_class = class_create(THIS_MODULE, "extcon");
 		if (IS_ERR(extcon_class))
 			return PTR_ERR(extcon_class);
 		extcon_class->dev_groups = extcon_groups;
 
 #if defined(CONFIG_ANDROID)
 		switch_class = class_compat_register("switch");
 		if (WARN(!switch_class, "cannot allocate"))
 			return -ENOMEM;
 #endif /* CONFIG_ANDROID */
 	}
 
 	return 0;
 }
 
 static void extcon_dev_release(struct device *dev)
 {
 }
 
 static const char *muex_name = "mutually_exclusive";
 static void dummy_sysfs_dev_release(struct device *dev)
 {
 }
 
 /*
  * extcon_dev_allocate() - Allocate the memory of extcon device.
  * @supported_cable:	Array of supported extcon ending with EXTCON_NONE.
  *			If supported_cable is NULL, cable name related APIs
  *			are disabled.
  *
  * This function allocates the memory for extcon device without allocating
  * memory in each extcon provider driver and initialize default setting for
  * extcon device.
  *
  * Return the pointer of extcon device if success or ERR_PTR(err) if fail
  */
 struct extcon_dev *extcon_dev_allocate(const unsigned int *supported_cable)
 {
 	struct extcon_dev *edev;
 
 	if (!supported_cable)
 		return ERR_PTR(-EINVAL);
 
 	edev = kzalloc(sizeof(*edev), GFP_KERNEL);
 	if (!edev)
 		return ERR_PTR(-ENOMEM);
 
 	edev->max_supported = 0;
 	edev->supported_cable = supported_cable;
 
 	return edev;
 }
 
 /*
  * extcon_dev_free() - Free the memory of extcon device.
  * @edev:	the extcon device to free
  */
 void extcon_dev_free(struct extcon_dev *edev)
 {
 	kfree(edev);
 }
 EXPORT_SYMBOL_GPL(extcon_dev_free);
 
 /**
  * extcon_dev_register() - Register a new extcon device
  * @edev	: the new extcon device (should be allocated before calling)
  *
  * Among the members of edev struct, please set the "user initializing data"
  * in any case and set the "optional callbacks" if required. However, please
  * do not set the values of "internal data", which are initialized by
  * this function.
  */
 int extcon_dev_register(struct extcon_dev *edev)
 {
 	int ret, index = 0;
 	static atomic_t edev_no = ATOMIC_INIT(-1);
 
 	if (!extcon_class) {
 		ret = create_extcon_class();
 		if (ret < 0)
 			return ret;
 	}
 
 	if (!edev || !edev->supported_cable)
 		return -EINVAL;
 
 	for (; edev->supported_cable[index] != EXTCON_NONE; index++);
 
 	edev->max_supported = index;
 	if (index > SUPPORTED_CABLE_MAX) {
 		dev_err(&edev->dev,
 			"exceed the maximum number of supported cables\n");
 		return -EINVAL;
 	}
 
 	edev->dev.class = extcon_class;
 	edev->dev.release = extcon_dev_release;
 
 	edev->name = dev_name(edev->dev.parent);
 	if (IS_ERR_OR_NULL(edev->name)) {
 		dev_err(&edev->dev,
 			"extcon device name is null\n");
 		return -EINVAL;
 	}
 	dev_set_name(&edev->dev, "extcon%lu",
 			(unsigned long)atomic_inc_return(&edev_no));
 
 	if (edev->max_supported) {
 		char buf[10];
 		char *str;
 		struct extcon_cable *cable;
 
 		edev->cables = kzalloc(sizeof(struct extcon_cable) *
 				       edev->max_supported, GFP_KERNEL);
 		if (!edev->cables) {
 			ret = -ENOMEM;
 			goto err_sysfs_alloc;
 		}
 		for (index = 0; index < edev->max_supported; index++) {
 			cable = &edev->cables[index];
 
 			snprintf(buf, 10, "cable.%d", index);
 			str = kzalloc(sizeof(char) * (strlen(buf) + 1),
 				      GFP_KERNEL);
 			if (!str) {
 				for (index--; index >= 0; index--) {
 					cable = &edev->cables[index];
 					kfree(cable->attr_g.name);
 				}
 				ret = -ENOMEM;
 
 				goto err_alloc_cables;
 			}
 			strcpy(str, buf);
 
 			cable->edev = edev;
 			cable->cable_index = index;
 			cable->attrs[0] = &cable->attr_name.attr;
 			cable->attrs[1] = &cable->attr_state.attr;
 			cable->attrs[2] = NULL;
 			cable->attr_g.name = str;
 			cable->attr_g.attrs = cable->attrs;
 
 			sysfs_attr_init(&cable->attr_name.attr);
 			cable->attr_name.attr.name = "name";
 			cable->attr_name.attr.mode = 0444;
 			cable->attr_name.show = cable_name_show;
 
 			sysfs_attr_init(&cable->attr_state.attr);
 			cable->attr_state.attr.name = "state";
 			cable->attr_state.attr.mode = 0444;
 			cable->attr_state.show = cable_state_show;
 		}
 	}
 
 	if (edev->max_supported && edev->mutually_exclusive) {
 		char buf[80];
 		char *name;
 
 		/* Count the size of mutually_exclusive array */
 		for (index = 0; edev->mutually_exclusive[index]; index++)
 			;
 
 		edev->attrs_muex = kzalloc(sizeof(struct attribute *) *
 					   (index + 1), GFP_KERNEL);
 		if (!edev->attrs_muex) {
 			ret = -ENOMEM;
 			goto err_muex;
 		}
 
 		edev->d_attrs_muex = kzalloc(sizeof(struct device_attribute) *
 					     index, GFP_KERNEL);
 		if (!edev->d_attrs_muex) {
 			ret = -ENOMEM;
 			kfree(edev->attrs_muex);
 			goto err_muex;
 		}
 
 		for (index = 0; edev->mutually_exclusive[index]; index++) {
 			sprintf(buf, "0x%x", edev->mutually_exclusive[index]);
 			name = kzalloc(sizeof(char) * (strlen(buf) + 1),
 				       GFP_KERNEL);
 			if (!name) {
 				for (index--; index >= 0; index--) {
 					kfree(edev->d_attrs_muex[index].attr.
 					      name);
 				}
 				kfree(edev->d_attrs_muex);
 				kfree(edev->attrs_muex);
 				ret = -ENOMEM;
 				goto err_muex;
 			}
 			strcpy(name, buf);
 			sysfs_attr_init(&edev->d_attrs_muex[index].attr);
 			edev->d_attrs_muex[index].attr.name = name;
 			edev->d_attrs_muex[index].attr.mode = 0000;
 			edev->attrs_muex[index] = &edev->d_attrs_muex[index]
 							.attr;
 		}
 		edev->attr_g_muex.name = muex_name;
 		edev->attr_g_muex.attrs = edev->attrs_muex;
 
 	}
 
 	if (edev->max_supported) {
 		edev->extcon_dev_type.groups =
 			kzalloc(sizeof(struct attribute_group *) *
 				(edev->max_supported + 2), GFP_KERNEL);
 		if (!edev->extcon_dev_type.groups) {
 			ret = -ENOMEM;
 			goto err_alloc_groups;
 		}
 
 		edev->extcon_dev_type.name = dev_name(&edev->dev);
 		edev->extcon_dev_type.release = dummy_sysfs_dev_release;
 
 		for (index = 0; index < edev->max_supported; index++)
 			edev->extcon_dev_type.groups[index] =
 				&edev->cables[index].attr_g;
 		if (edev->mutually_exclusive)
 			edev->extcon_dev_type.groups[index] =
 				&edev->attr_g_muex;
 
 		edev->dev.type = &edev->extcon_dev_type;
 	}
 
 	ret = device_register(&edev->dev);
 	if (ret) {
 		put_device(&edev->dev);
 		goto err_dev;
 	}
 #if defined(CONFIG_ANDROID)
 	if (switch_class)
 		ret = class_compat_create_link(switch_class, &edev->dev, NULL);
 #endif /* CONFIG_ANDROID */
 
 	spin_lock_init(&edev->lock);
 
 	edev->nh = devm_kzalloc(&edev->dev,
 			sizeof(*edev->nh) * edev->max_supported, GFP_KERNEL);
 	if (!edev->nh) {
 		ret = -ENOMEM;
 		goto err_dev;
 	}
 
 	for (index = 0; index < edev->max_supported; index++)
 		RAW_INIT_NOTIFIER_HEAD(&edev->nh[index]);
 
 	dev_set_drvdata(&edev->dev, edev);
 	edev->state = 0;
 
 	mutex_lock(&extcon_dev_list_lock);
 	list_add(&edev->entry, &extcon_dev_list);
 	mutex_unlock(&extcon_dev_list_lock);
 
 	return 0;
 
 err_dev:
 	if (edev->max_supported)
 		kfree(edev->extcon_dev_type.groups);
 err_alloc_groups:
 	if (edev->max_supported && edev->mutually_exclusive) {
 		for (index = 0; edev->mutually_exclusive[index]; index++)
 			kfree(edev->d_attrs_muex[index].attr.name);
 		kfree(edev->d_attrs_muex);
 		kfree(edev->attrs_muex);
 	}
 err_muex:
 	for (index = 0; index < edev->max_supported; index++)
 		kfree(edev->cables[index].attr_g.name);
 err_alloc_cables:
 	if (edev->max_supported)
 		kfree(edev->cables);
 err_sysfs_alloc:
 	return ret;
 }
 EXPORT_SYMBOL_GPL(extcon_dev_register);
 
 /**
  * extcon_dev_unregister() - Unregister the extcon device.
  * @edev:	the extcon device instance to be unregistered.
  *
  * Note that this does not call kfree(edev) because edev was not allocated
  * by this class.
  */
 void extcon_dev_unregister(struct extcon_dev *edev)
 {
 	int index;
 
 	if (!edev)
 		return;
 
 	mutex_lock(&extcon_dev_list_lock);
 	list_del(&edev->entry);
 	mutex_unlock(&extcon_dev_list_lock);
 
 	if (IS_ERR_OR_NULL(get_device(&edev->dev))) {
 		dev_err(&edev->dev, "Failed to unregister extcon_dev (%s)\n",
 				dev_name(&edev->dev));
 		return;
 	}
 
 	device_unregister(&edev->dev);
 
 	if (edev->mutually_exclusive && edev->max_supported) {
 		for (index = 0; edev->mutually_exclusive[index];
 				index++)
 			kfree(edev->d_attrs_muex[index].attr.name);
 		kfree(edev->d_attrs_muex);
 		kfree(edev->attrs_muex);
 	}
 
 	for (index = 0; index < edev->max_supported; index++)
 		kfree(edev->cables[index].attr_g.name);
 
 	if (edev->max_supported) {
 		kfree(edev->extcon_dev_type.groups);
 		kfree(edev->cables);
 	}
 
 #if defined(CONFIG_ANDROID)
 	if (switch_class)
 		class_compat_remove_link(switch_class, &edev->dev, NULL);
 #endif
 	put_device(&edev->dev);
 }
 EXPORT_SYMBOL_GPL(extcon_dev_unregister);
 
 #ifdef CONFIG_OF
 /*
  * extcon_get_edev_by_phandle - Get the extcon device from devicetree
  * @dev - instance to the given device
  * @index - index into list of extcon_dev
  *
  * return the instance of extcon device
  */
 struct extcon_dev *extcon_get_edev_by_phandle(struct device *dev, int index)
 {
 	struct device_node *node;
 	struct extcon_dev *edev;
 
 	if (!dev)
 		return ERR_PTR(-EINVAL);
 
 	if (!dev->of_node) {
 		dev_dbg(dev, "device does not have a device node entry\n");
 		return ERR_PTR(-EINVAL);
 	}
 
 	node = of_parse_phandle(dev->of_node, "extcon", index);
 	if (!node) {
 		dev_dbg(dev, "failed to get phandle in %s node\n",
 			dev->of_node->full_name);
 		return ERR_PTR(-ENODEV);
 	}
 
 	mutex_lock(&extcon_dev_list_lock);
 	list_for_each_entry(edev, &extcon_dev_list, entry) {
 		if (edev->dev.parent && edev->dev.parent->of_node == node) {
 			mutex_unlock(&extcon_dev_list_lock);
 			of_node_put(node);
 			return edev;
 		}
 	}
 	mutex_unlock(&extcon_dev_list_lock);
 	of_node_put(node);
 
 	return ERR_PTR(-EPROBE_DEFER);
 }
 #else
 struct extcon_dev *extcon_get_edev_by_phandle(struct device *dev, int index)
 {
 	return ERR_PTR(-ENOSYS);
 }
 #endif /* CONFIG_OF */
 EXPORT_SYMBOL_GPL(extcon_get_edev_by_phandle);
 
 /**
  * extcon_get_edev_name() - Get the name of the extcon device.
  * @edev:	the extcon device
  */
 const char *extcon_get_edev_name(struct extcon_dev *edev)
 {
 	return !edev ? NULL : edev->name;
 }
 
 static int __init extcon_class_init(void)
 {
 	return create_extcon_class();
 }
 module_init(extcon_class_init);
 
 static void __exit extcon_class_exit(void)
 {
 #if defined(CONFIG_ANDROID)
 	class_compat_unregister(switch_class);
 #endif
 	class_destroy(extcon_class);
 }
 module_exit(extcon_class_exit);
 
 MODULE_AUTHOR("Chanwoo Choi <cw00.choi@samsung.com>");
 MODULE_AUTHOR("Mike Lockwood <lockwood@android.com>");
 MODULE_AUTHOR("Donggeun Kim <dg77.kim@samsung.com>");
 MODULE_AUTHOR("MyungJoo Ham <myungjoo.ham@samsung.com>");
 MODULE_DESCRIPTION("External connector (extcon) class driver");
 MODULE_LICENSE("GPL");
diff --git a/drivers/extcon/extcon.h b/drivers/extcon/extcon.h
new file mode 100644
index 000000000000..993ddccafe11
--- /dev/null
+++ b/drivers/extcon/extcon.h
@@ -0,0 +1,62 @@
+#ifndef __LINUX_EXTCON_INTERNAL_H__
+#define __LINUX_EXTCON_INTERNAL_H__
+
+#include <linux/extcon.h>
+
+/**
+ * struct extcon_dev - An extcon device represents one external connector.
+ * @name:		The name of this extcon device. Parent device name is
+ *			used if NULL.
+ * @supported_cable:	Array of supported cable names ending with EXTCON_NONE.
+ *			If supported_cable is NULL, cable name related APIs
+ *			are disabled.
+ * @mutually_exclusive:	Array of mutually exclusive set of cables that cannot
+ *			be attached simultaneously. The array should be
+ *			ending with NULL or be NULL (no mutually exclusive
+ *			cables). For example, if it is { 0x7, 0x30, 0}, then,
+ *			{0, 1}, {0, 1, 2}, {0, 2}, {1, 2}, or {4, 5} cannot
+ *			be attached simulataneously. {0x7, 0} is equivalent to
+ *			{0x3, 0x6, 0x5, 0}. If it is {0xFFFFFFFF, 0}, there
+ *			can be no simultaneous connections.
+ * @dev:		Device of this extcon.
+ * @state:		Attach/detach state of this extcon. Do not provide at
+ *			register-time.
+ * @nh:			Notifier for the state change events from this extcon
+ * @entry:		To support list of extcon devices so that users can
+ *			search for extcon devices based on the extcon name.
+ * @lock:
+ * @max_supported:	Internal value to store the number of cables.
+ * @extcon_dev_type:	Device_type struct to provide attribute_groups
+ *			customized for each extcon device.
+ * @cables:		Sysfs subdirectories. Each represents one cable.
+ *
+ * In most cases, users only need to provide "User initializing data" of
+ * this struct when registering an extcon. In some exceptional cases,
+ * optional callbacks may be needed. However, the values in "internal data"
+ * are overwritten by register function.
+ */
+struct extcon_dev {
+	/* Optional user initializing data */
+	const char *name;
+	const unsigned int *supported_cable;
+	const u32 *mutually_exclusive;
+
+	/* Internal data. Please do not set. */
+	struct device dev;
+	struct raw_notifier_head *nh;
+	struct list_head entry;
+	int max_supported;
+	spinlock_t lock;	/* could be called by irq handler */
+	u32 state;
+
+	/* /sys/class/extcon/.../cable.n/... */
+	struct device_type extcon_dev_type;
+	struct extcon_cable *cables;
+
+	/* /sys/class/extcon/.../mutually_exclusive/... */
+	struct attribute_group attr_g_muex;
+	struct attribute **attrs_muex;
+	struct device_attribute *d_attrs_muex;
+};
+
+#endif /* __LINUX_EXTCON_INTERNAL_H__ */
diff --git a/drivers/fpga/fpga-mgr.c b/drivers/fpga/fpga-mgr.c
index f0a69d3e60a5..86d2cb203533 100644
--- a/drivers/fpga/fpga-mgr.c
+++ b/drivers/fpga/fpga-mgr.c
@@ -1,410 +1,586 @@
 /*
  * FPGA Manager Core
  *
  *  Copyright (C) 2013-2015 Altera Corporation
  *
  * With code from the mailing list:
  * Copyright (C) 2013 Xilinx, Inc.
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms and conditions of the GNU General Public License,
  * version 2, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope it will be useful, but WITHOUT
  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
  * more details.
  *
  * You should have received a copy of the GNU General Public License along with
  * this program.  If not, see <http://www.gnu.org/licenses/>.
  */
 #include <linux/firmware.h>
 #include <linux/fpga/fpga-mgr.h>
 #include <linux/idr.h>
 #include <linux/module.h>
 #include <linux/of.h>
 #include <linux/mutex.h>
 #include <linux/slab.h>
+#include <linux/scatterlist.h>
+#include <linux/highmem.h>
 
 static DEFINE_IDA(fpga_mgr_ida);
 static struct class *fpga_mgr_class;
 
+/*
+ * Call the low level driver's write_init function.  This will do the
+ * device-specific things to get the FPGA into the state where it is ready to
+ * receive an FPGA image. The low level driver only gets to see the first
+ * initial_header_size bytes in the buffer.
+ */
+static int fpga_mgr_write_init_buf(struct fpga_manager *mgr,
+				   struct fpga_image_info *info,
+				   const char *buf, size_t count)
+{
+	int ret;
+
+	mgr->state = FPGA_MGR_STATE_WRITE_INIT;
+	if (!mgr->mops->initial_header_size)
+		ret = mgr->mops->write_init(mgr, info, NULL, 0);
+	else
+		ret = mgr->mops->write_init(
+		    mgr, info, buf, min(mgr->mops->initial_header_size, count));
+
+	if (ret) {
+		dev_err(&mgr->dev, "Error preparing FPGA for writing\n");
+		mgr->state = FPGA_MGR_STATE_WRITE_INIT_ERR;
+		return ret;
+	}
+
+	return 0;
+}
+
+static int fpga_mgr_write_init_sg(struct fpga_manager *mgr,
+				  struct fpga_image_info *info,
+				  struct sg_table *sgt)
+{
+	struct sg_mapping_iter miter;
+	size_t len;
+	char *buf;
+	int ret;
+
+	if (!mgr->mops->initial_header_size)
+		return fpga_mgr_write_init_buf(mgr, info, NULL, 0);
+
+	/*
+	 * First try to use miter to map the first fragment to access the
+	 * header, this is the typical path.
+	 */
+	sg_miter_start(&miter, sgt->sgl, sgt->nents, SG_MITER_FROM_SG);
+	if (sg_miter_next(&miter) &&
+	    miter.length >= mgr->mops->initial_header_size) {
+		ret = fpga_mgr_write_init_buf(mgr, info, miter.addr,
+					      miter.length);
+		sg_miter_stop(&miter);
+		return ret;
+	}
+	sg_miter_stop(&miter);
+
+	/* Otherwise copy the fragments into temporary memory. */
+	buf = kmalloc(mgr->mops->initial_header_size, GFP_KERNEL);
+	if (!buf)
+		return -ENOMEM;
+
+	len = sg_copy_to_buffer(sgt->sgl, sgt->nents, buf,
+				mgr->mops->initial_header_size);
+	ret = fpga_mgr_write_init_buf(mgr, info, buf, len);
+
+	kfree(buf);
+
+	return ret;
+}
+
+/*
+ * After all the FPGA image has been written, do the device specific steps to
+ * finish and set the FPGA into operating mode.
+ */
+static int fpga_mgr_write_complete(struct fpga_manager *mgr,
+				   struct fpga_image_info *info)
+{
+	int ret;
+
+	mgr->state = FPGA_MGR_STATE_WRITE_COMPLETE;
+	ret = mgr->mops->write_complete(mgr, info);
+	if (ret) {
+		dev_err(&mgr->dev, "Error after writing image data to FPGA\n");
+		mgr->state = FPGA_MGR_STATE_WRITE_COMPLETE_ERR;
+		return ret;
+	}
+	mgr->state = FPGA_MGR_STATE_OPERATING;
+
+	return 0;
+}
+
 /**
- * fpga_mgr_buf_load - load fpga from image in buffer
+ * fpga_mgr_buf_load_sg - load fpga from image in buffer from a scatter list
  * @mgr:	fpga manager
  * @info:	fpga image specific information
- * @buf:	buffer contain fpga image
- * @count:	byte count of buf
+ * @sgt:	scatterlist table
  *
  * Step the low level fpga manager through the device-specific steps of getting
  * an FPGA ready to be configured, writing the image to it, then doing whatever
  * post-configuration steps necessary.  This code assumes the caller got the
  * mgr pointer from of_fpga_mgr_get() or fpga_mgr_get() and checked that it is
  * not an error code.
  *
+ * This is the preferred entry point for FPGA programming, it does not require
+ * any contiguous kernel memory.
+ *
  * Return: 0 on success, negative error code otherwise.
  */
-int fpga_mgr_buf_load(struct fpga_manager *mgr, struct fpga_image_info *info,
-		      const char *buf, size_t count)
+int fpga_mgr_buf_load_sg(struct fpga_manager *mgr, struct fpga_image_info *info,
+			 struct sg_table *sgt)
 {
-	struct device *dev = &mgr->dev;
 	int ret;
 
-	/*
-	 * Call the low level driver's write_init function.  This will do the
-	 * device-specific things to get the FPGA into the state where it is
-	 * ready to receive an FPGA image. The low level driver only gets to
-	 * see the first initial_header_size bytes in the buffer.
-	 */
-	mgr->state = FPGA_MGR_STATE_WRITE_INIT;
-	ret = mgr->mops->write_init(mgr, info, buf,
-				    min(mgr->mops->initial_header_size, count));
+	ret = fpga_mgr_write_init_sg(mgr, info, sgt);
+	if (ret)
+		return ret;
+
+	/* Write the FPGA image to the FPGA. */
+	mgr->state = FPGA_MGR_STATE_WRITE;
+	if (mgr->mops->write_sg) {
+		ret = mgr->mops->write_sg(mgr, sgt);
+	} else {
+		struct sg_mapping_iter miter;
+
+		sg_miter_start(&miter, sgt->sgl, sgt->nents, SG_MITER_FROM_SG);
+		while (sg_miter_next(&miter)) {
+			ret = mgr->mops->write(mgr, miter.addr, miter.length);
+			if (ret)
+				break;
+		}
+		sg_miter_stop(&miter);
+	}
+
 	if (ret) {
-		dev_err(dev, "Error preparing FPGA for writing\n");
-		mgr->state = FPGA_MGR_STATE_WRITE_INIT_ERR;
+		dev_err(&mgr->dev, "Error while writing image data to FPGA\n");
+		mgr->state = FPGA_MGR_STATE_WRITE_ERR;
 		return ret;
 	}
 
+	return fpga_mgr_write_complete(mgr, info);
+}
+EXPORT_SYMBOL_GPL(fpga_mgr_buf_load_sg);
+
+static int fpga_mgr_buf_load_mapped(struct fpga_manager *mgr,
+				    struct fpga_image_info *info,
+				    const char *buf, size_t count)
+{
+	int ret;
+
+	ret = fpga_mgr_write_init_buf(mgr, info, buf, count);
+	if (ret)
+		return ret;
+
 	/*
 	 * Write the FPGA image to the FPGA.
 	 */
 	mgr->state = FPGA_MGR_STATE_WRITE;
 	ret = mgr->mops->write(mgr, buf, count);
 	if (ret) {
-		dev_err(dev, "Error while writing image data to FPGA\n");
+		dev_err(&mgr->dev, "Error while writing image data to FPGA\n");
 		mgr->state = FPGA_MGR_STATE_WRITE_ERR;
 		return ret;
 	}
 
+	return fpga_mgr_write_complete(mgr, info);
+}
+
+/**
+ * fpga_mgr_buf_load - load fpga from image in buffer
+ * @mgr:	fpga manager
+ * @flags:	flags setting fpga confuration modes
+ * @buf:	buffer contain fpga image
+ * @count:	byte count of buf
+ *
+ * Step the low level fpga manager through the device-specific steps of getting
+ * an FPGA ready to be configured, writing the image to it, then doing whatever
+ * post-configuration steps necessary.  This code assumes the caller got the
+ * mgr pointer from of_fpga_mgr_get() and checked that it is not an error code.
+ *
+ * Return: 0 on success, negative error code otherwise.
+ */
+int fpga_mgr_buf_load(struct fpga_manager *mgr, struct fpga_image_info *info,
+		      const char *buf, size_t count)
+{
+	struct page **pages;
+	struct sg_table sgt;
+	const void *p;
+	int nr_pages;
+	int index;
+	int rc;
+
 	/*
-	 * After all the FPGA image has been written, do the device specific
-	 * steps to finish and set the FPGA into operating mode.
+	 * This is just a fast path if the caller has already created a
+	 * contiguous kernel buffer and the driver doesn't require SG, non-SG
+	 * drivers will still work on the slow path.
 	 */
-	mgr->state = FPGA_MGR_STATE_WRITE_COMPLETE;
-	ret = mgr->mops->write_complete(mgr, info);
-	if (ret) {
-		dev_err(dev, "Error after writing image data to FPGA\n");
-		mgr->state = FPGA_MGR_STATE_WRITE_COMPLETE_ERR;
-		return ret;
+	if (mgr->mops->write)
+		return fpga_mgr_buf_load_mapped(mgr, info, buf, count);
+
+	/*
+	 * Convert the linear kernel pointer into a sg_table of pages for use
+	 * by the driver.
+	 */
+	nr_pages = DIV_ROUND_UP((unsigned long)buf + count, PAGE_SIZE) -
+		   (unsigned long)buf / PAGE_SIZE;
+	pages = kmalloc_array(nr_pages, sizeof(struct page *), GFP_KERNEL);
+	if (!pages)
+		return -ENOMEM;
+
+	p = buf - offset_in_page(buf);
+	for (index = 0; index < nr_pages; index++) {
+		if (is_vmalloc_addr(p))
+			pages[index] = vmalloc_to_page(p);
+		else
+			pages[index] = kmap_to_page((void *)p);
+		if (!pages[index]) {
+			kfree(pages);
+			return -EFAULT;
+		}
+		p += PAGE_SIZE;
 	}
-	mgr->state = FPGA_MGR_STATE_OPERATING;
 
-	return 0;
+	/*
+	 * The temporary pages list is used to code share the merging algorithm
+	 * in sg_alloc_table_from_pages
+	 */
+	rc = sg_alloc_table_from_pages(&sgt, pages, index, offset_in_page(buf),
+				       count, GFP_KERNEL);
+	kfree(pages);
+	if (rc)
+		return rc;
+
+	rc = fpga_mgr_buf_load_sg(mgr, info, &sgt);
+	sg_free_table(&sgt);
+
+	return rc;
 }
 EXPORT_SYMBOL_GPL(fpga_mgr_buf_load);
 
 /**
  * fpga_mgr_firmware_load - request firmware and load to fpga
  * @mgr:	fpga manager
  * @info:	fpga image specific information
  * @image_name:	name of image file on the firmware search path
  *
  * Request an FPGA image using the firmware class, then write out to the FPGA.
  * Update the state before each step to provide info on what step failed if
  * there is a failure.  This code assumes the caller got the mgr pointer
  * from of_fpga_mgr_get() or fpga_mgr_get() and checked that it is not an error
  * code.
  *
  * Return: 0 on success, negative error code otherwise.
  */
 int fpga_mgr_firmware_load(struct fpga_manager *mgr,
 			   struct fpga_image_info *info,
 			   const char *image_name)
 {
 	struct device *dev = &mgr->dev;
 	const struct firmware *fw;
 	int ret;
 
 	dev_info(dev, "writing %s to %s\n", image_name, mgr->name);
 
 	mgr->state = FPGA_MGR_STATE_FIRMWARE_REQ;
 
 	ret = request_firmware(&fw, image_name, dev);
 	if (ret) {
 		mgr->state = FPGA_MGR_STATE_FIRMWARE_REQ_ERR;
 		dev_err(dev, "Error requesting firmware %s\n", image_name);
 		return ret;
 	}
 
 	ret = fpga_mgr_buf_load(mgr, info, fw->data, fw->size);
 
 	release_firmware(fw);
 
 	return ret;
 }
 EXPORT_SYMBOL_GPL(fpga_mgr_firmware_load);
 
 static const char * const state_str[] = {
 	[FPGA_MGR_STATE_UNKNOWN] =		"unknown",
 	[FPGA_MGR_STATE_POWER_OFF] =		"power off",
 	[FPGA_MGR_STATE_POWER_UP] =		"power up",
 	[FPGA_MGR_STATE_RESET] =		"reset",
 
 	/* requesting FPGA image from firmware */
 	[FPGA_MGR_STATE_FIRMWARE_REQ] =		"firmware request",
 	[FPGA_MGR_STATE_FIRMWARE_REQ_ERR] =	"firmware request error",
 
 	/* Preparing FPGA to receive image */
 	[FPGA_MGR_STATE_WRITE_INIT] =		"write init",
 	[FPGA_MGR_STATE_WRITE_INIT_ERR] =	"write init error",
 
 	/* Writing image to FPGA */
 	[FPGA_MGR_STATE_WRITE] =		"write",
 	[FPGA_MGR_STATE_WRITE_ERR] =		"write error",
 
 	/* Finishing configuration after image has been written */
 	[FPGA_MGR_STATE_WRITE_COMPLETE] =	"write complete",
 	[FPGA_MGR_STATE_WRITE_COMPLETE_ERR] =	"write complete error",
 
 	/* FPGA reports to be in normal operating mode */
 	[FPGA_MGR_STATE_OPERATING] =		"operating",
 };
 
 static ssize_t name_show(struct device *dev,
 			 struct device_attribute *attr, char *buf)
 {
 	struct fpga_manager *mgr = to_fpga_manager(dev);
 
 	return sprintf(buf, "%s\n", mgr->name);
 }
 
 static ssize_t state_show(struct device *dev,
 			  struct device_attribute *attr, char *buf)
 {
 	struct fpga_manager *mgr = to_fpga_manager(dev);
 
 	return sprintf(buf, "%s\n", state_str[mgr->state]);
 }
 
 static DEVICE_ATTR_RO(name);
 static DEVICE_ATTR_RO(state);
 
 static struct attribute *fpga_mgr_attrs[] = {
 	&dev_attr_name.attr,
 	&dev_attr_state.attr,
 	NULL,
 };
 ATTRIBUTE_GROUPS(fpga_mgr);
 
 struct fpga_manager *__fpga_mgr_get(struct device *dev)
 {
 	struct fpga_manager *mgr;
 	int ret = -ENODEV;
 
 	mgr = to_fpga_manager(dev);
 	if (!mgr)
 		goto err_dev;
 
 	/* Get exclusive use of fpga manager */
 	if (!mutex_trylock(&mgr->ref_mutex)) {
 		ret = -EBUSY;
 		goto err_dev;
 	}
 
 	if (!try_module_get(dev->parent->driver->owner))
 		goto err_ll_mod;
 
 	return mgr;
 
 err_ll_mod:
 	mutex_unlock(&mgr->ref_mutex);
 err_dev:
 	put_device(dev);
 	return ERR_PTR(ret);
 }
 
 static int fpga_mgr_dev_match(struct device *dev, const void *data)
 {
 	return dev->parent == data;
 }
 
 /**
  * fpga_mgr_get - get an exclusive reference to a fpga mgr
  * @dev:	parent device that fpga mgr was registered with
  *
  * Given a device, get an exclusive reference to a fpga mgr.
  *
  * Return: fpga manager struct or IS_ERR() condition containing error code.
  */
 struct fpga_manager *fpga_mgr_get(struct device *dev)
 {
 	struct device *mgr_dev = class_find_device(fpga_mgr_class, NULL, dev,
 						   fpga_mgr_dev_match);
 	if (!mgr_dev)
 		return ERR_PTR(-ENODEV);
 
 	return __fpga_mgr_get(mgr_dev);
 }
 EXPORT_SYMBOL_GPL(fpga_mgr_get);
 
 static int fpga_mgr_of_node_match(struct device *dev, const void *data)
 {
 	return dev->of_node == data;
 }
 
 /**
  * of_fpga_mgr_get - get an exclusive reference to a fpga mgr
  * @node:	device node
  *
  * Given a device node, get an exclusive reference to a fpga mgr.
  *
  * Return: fpga manager struct or IS_ERR() condition containing error code.
  */
 struct fpga_manager *of_fpga_mgr_get(struct device_node *node)
 {
 	struct device *dev;
 
 	dev = class_find_device(fpga_mgr_class, NULL, node,
 				fpga_mgr_of_node_match);
 	if (!dev)
 		return ERR_PTR(-ENODEV);
 
 	return __fpga_mgr_get(dev);
 }
 EXPORT_SYMBOL_GPL(of_fpga_mgr_get);
 
 /**
  * fpga_mgr_put - release a reference to a fpga manager
  * @mgr:	fpga manager structure
  */
 void fpga_mgr_put(struct fpga_manager *mgr)
 {
 	module_put(mgr->dev.parent->driver->owner);
 	mutex_unlock(&mgr->ref_mutex);
 	put_device(&mgr->dev);
 }
 EXPORT_SYMBOL_GPL(fpga_mgr_put);
 
 /**
  * fpga_mgr_register - register a low level fpga manager driver
  * @dev:	fpga manager device from pdev
  * @name:	fpga manager name
  * @mops:	pointer to structure of fpga manager ops
  * @priv:	fpga manager private data
  *
  * Return: 0 on success, negative error code otherwise.
  */
 int fpga_mgr_register(struct device *dev, const char *name,
 		      const struct fpga_manager_ops *mops,
 		      void *priv)
 {
 	struct fpga_manager *mgr;
 	int id, ret;
 
-	if (!mops || !mops->write_init || !mops->write ||
-	    !mops->write_complete || !mops->state) {
+	if (!mops || !mops->write_complete || !mops->state ||
+	    !mops->write_init || (!mops->write && !mops->write_sg) ||
+	    (mops->write && mops->write_sg)) {
 		dev_err(dev, "Attempt to register without fpga_manager_ops\n");
 		return -EINVAL;
 	}
 
 	if (!name || !strlen(name)) {
 		dev_err(dev, "Attempt to register with no name!\n");
 		return -EINVAL;
 	}
 
 	mgr = kzalloc(sizeof(*mgr), GFP_KERNEL);
 	if (!mgr)
 		return -ENOMEM;
 
 	id = ida_simple_get(&fpga_mgr_ida, 0, 0, GFP_KERNEL);
 	if (id < 0) {
 		ret = id;
 		goto error_kfree;
 	}
 
 	mutex_init(&mgr->ref_mutex);
 
 	mgr->name = name;
 	mgr->mops = mops;
 	mgr->priv = priv;
 
 	/*
 	 * Initialize framework state by requesting low level driver read state
 	 * from device.  FPGA may be in reset mode or may have been programmed
 	 * by bootloader or EEPROM.
 	 */
 	mgr->state = mgr->mops->state(mgr);
 
 	device_initialize(&mgr->dev);
 	mgr->dev.class = fpga_mgr_class;
 	mgr->dev.parent = dev;
 	mgr->dev.of_node = dev->of_node;
 	mgr->dev.id = id;
 	dev_set_drvdata(dev, mgr);
 
 	ret = dev_set_name(&mgr->dev, "fpga%d", id);
 	if (ret)
 		goto error_device;
 
 	ret = device_add(&mgr->dev);
 	if (ret)
 		goto error_device;
 
 	dev_info(&mgr->dev, "%s registered\n", mgr->name);
 
 	return 0;
 
 error_device:
 	ida_simple_remove(&fpga_mgr_ida, id);
 error_kfree:
 	kfree(mgr);
 
 	return ret;
 }
 EXPORT_SYMBOL_GPL(fpga_mgr_register);
 
 /**
  * fpga_mgr_unregister - unregister a low level fpga manager driver
  * @dev:	fpga manager device from pdev
  */
 void fpga_mgr_unregister(struct device *dev)
 {
 	struct fpga_manager *mgr = dev_get_drvdata(dev);
 
 	dev_info(&mgr->dev, "%s %s\n", __func__, mgr->name);
 
 	/*
 	 * If the low level driver provides a method for putting fpga into
 	 * a desired state upon unregister, do it.
 	 */
 	if (mgr->mops->fpga_remove)
 		mgr->mops->fpga_remove(mgr);
 
 	device_unregister(&mgr->dev);
 }
 EXPORT_SYMBOL_GPL(fpga_mgr_unregister);
 
 static void fpga_mgr_dev_release(struct device *dev)
 {
 	struct fpga_manager *mgr = to_fpga_manager(dev);
 
 	ida_simple_remove(&fpga_mgr_ida, mgr->dev.id);
 	kfree(mgr);
 }
 
 static int __init fpga_mgr_class_init(void)
 {
 	pr_info("FPGA manager framework\n");
 
 	fpga_mgr_class = class_create(THIS_MODULE, "fpga_manager");
 	if (IS_ERR(fpga_mgr_class))
 		return PTR_ERR(fpga_mgr_class);
 
 	fpga_mgr_class->dev_groups = fpga_mgr_groups;
 	fpga_mgr_class->dev_release = fpga_mgr_dev_release;
 
 	return 0;
 }
 
 static void __exit fpga_mgr_class_exit(void)
 {
 	class_destroy(fpga_mgr_class);
 	ida_destroy(&fpga_mgr_ida);
 }
 
 MODULE_AUTHOR("Alan Tull <atull@opensource.altera.com>");
 MODULE_DESCRIPTION("FPGA manager framework");
 MODULE_LICENSE("GPL v2");
 
 subsys_initcall(fpga_mgr_class_init);
 module_exit(fpga_mgr_class_exit);
diff --git a/drivers/fpga/zynq-fpga.c b/drivers/fpga/zynq-fpga.c
index 1812bf7614e1..34cb98139442 100644
--- a/drivers/fpga/zynq-fpga.c
+++ b/drivers/fpga/zynq-fpga.c
@@ -1,516 +1,643 @@
 /*
  * Copyright (c) 2011-2015 Xilinx Inc.
  * Copyright (c) 2015, National Instruments Corp.
  *
  * FPGA Manager Driver for Xilinx Zynq, heavily based on xdevcfg driver
  * in their vendor tree.
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
  * the Free Software Foundation; version 2 of the License.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
  * GNU General Public License for more details.
  */
 
 #include <linux/clk.h>
 #include <linux/completion.h>
 #include <linux/delay.h>
 #include <linux/dma-mapping.h>
 #include <linux/fpga/fpga-mgr.h>
 #include <linux/interrupt.h>
 #include <linux/io.h>
 #include <linux/iopoll.h>
 #include <linux/module.h>
 #include <linux/mfd/syscon.h>
 #include <linux/of_address.h>
 #include <linux/of_irq.h>
 #include <linux/pm.h>
 #include <linux/regmap.h>
 #include <linux/string.h>
+#include <linux/scatterlist.h>
 
 /* Offsets into SLCR regmap */
 
 /* FPGA Software Reset Control */
 #define SLCR_FPGA_RST_CTRL_OFFSET	0x240
 /* Level Shifters Enable */
 #define SLCR_LVL_SHFTR_EN_OFFSET	0x900
 
 /* Constant Definitions */
 
 /* Control Register */
 #define CTRL_OFFSET			0x00
 /* Lock Register */
 #define LOCK_OFFSET			0x04
 /* Interrupt Status Register */
 #define INT_STS_OFFSET			0x0c
 /* Interrupt Mask Register */
 #define INT_MASK_OFFSET			0x10
 /* Status Register */
 #define STATUS_OFFSET			0x14
 /* DMA Source Address Register */
 #define DMA_SRC_ADDR_OFFSET		0x18
 /* DMA Destination Address Reg */
 #define DMA_DST_ADDR_OFFSET		0x1c
 /* DMA Source Transfer Length */
 #define DMA_SRC_LEN_OFFSET		0x20
 /* DMA Destination Transfer */
 #define DMA_DEST_LEN_OFFSET		0x24
 /* Unlock Register */
 #define UNLOCK_OFFSET			0x34
 /* Misc. Control Register */
 #define MCTRL_OFFSET			0x80
 
 /* Control Register Bit definitions */
 
 /* Signal to reset FPGA */
 #define CTRL_PCFG_PROG_B_MASK		BIT(30)
 /* Enable PCAP for PR */
 #define CTRL_PCAP_PR_MASK		BIT(27)
 /* Enable PCAP */
 #define CTRL_PCAP_MODE_MASK		BIT(26)
 
 /* Miscellaneous Control Register bit definitions */
 /* Internal PCAP loopback */
 #define MCTRL_PCAP_LPBK_MASK		BIT(4)
 
 /* Status register bit definitions */
 
 /* FPGA init status */
 #define STATUS_DMA_Q_F			BIT(31)
+#define STATUS_DMA_Q_E			BIT(30)
 #define STATUS_PCFG_INIT_MASK		BIT(4)
 
 /* Interrupt Status/Mask Register Bit definitions */
 /* DMA command done */
 #define IXR_DMA_DONE_MASK		BIT(13)
 /* DMA and PCAP cmd done */
 #define IXR_D_P_DONE_MASK		BIT(12)
  /* FPGA programmed */
 #define IXR_PCFG_DONE_MASK		BIT(2)
-#define IXR_ERROR_FLAGS_MASK		0x00F0F860
+#define IXR_ERROR_FLAGS_MASK		0x00F0C860
 #define IXR_ALL_MASK			0xF8F7F87F
 
 /* Miscellaneous constant values */
 
 /* Invalid DMA addr */
 #define DMA_INVALID_ADDRESS		GENMASK(31, 0)
 /* Used to unlock the dev */
 #define UNLOCK_MASK			0x757bdf0d
-/* Timeout for DMA to complete */
-#define DMA_DONE_TIMEOUT		msecs_to_jiffies(1000)
 /* Timeout for polling reset bits */
 #define INIT_POLL_TIMEOUT		2500000
 /* Delay for polling reset bits */
 #define INIT_POLL_DELAY			20
+/* Signal this is the last DMA transfer, wait for the AXI and PCAP before
+ * interrupting
+ */
+#define DMA_SRC_LAST_TRANSFER		1
+/* Timeout for DMA completion */
+#define DMA_TIMEOUT_MS			5000
 
 /* Masks for controlling stuff in SLCR */
 /* Disable all Level shifters */
 #define LVL_SHFTR_DISABLE_ALL_MASK	0x0
 /* Enable Level shifters from PS to PL */
 #define LVL_SHFTR_ENABLE_PS_TO_PL	0xa
 /* Enable Level shifters from PL to PS */
 #define LVL_SHFTR_ENABLE_PL_TO_PS	0xf
 /* Enable global resets */
 #define FPGA_RST_ALL_MASK		0xf
 /* Disable global resets */
 #define FPGA_RST_NONE_MASK		0x0
 
 struct zynq_fpga_priv {
 	int irq;
 	struct clk *clk;
 
 	void __iomem *io_base;
 	struct regmap *slcr;
 
+	spinlock_t dma_lock;
+	unsigned int dma_elm;
+	unsigned int dma_nelms;
+	struct scatterlist *cur_sg;
+
 	struct completion dma_done;
 };
 
 static inline void zynq_fpga_write(struct zynq_fpga_priv *priv, u32 offset,
 				   u32 val)
 {
 	writel(val, priv->io_base + offset);
 }
 
 static inline u32 zynq_fpga_read(const struct zynq_fpga_priv *priv,
 				 u32 offset)
 {
 	return readl(priv->io_base + offset);
 }
 
 #define zynq_fpga_poll_timeout(priv, addr, val, cond, sleep_us, timeout_us) \
 	readl_poll_timeout(priv->io_base + addr, val, cond, sleep_us, \
 			   timeout_us)
 
-static void zynq_fpga_mask_irqs(struct zynq_fpga_priv *priv)
+/* Cause the specified irq mask bits to generate IRQs */
+static inline void zynq_fpga_set_irq(struct zynq_fpga_priv *priv, u32 enable)
 {
-	u32 intr_mask;
-
-	intr_mask = zynq_fpga_read(priv, INT_MASK_OFFSET);
-	zynq_fpga_write(priv, INT_MASK_OFFSET,
-			intr_mask | IXR_DMA_DONE_MASK | IXR_ERROR_FLAGS_MASK);
+	zynq_fpga_write(priv, INT_MASK_OFFSET, ~enable);
 }
 
-static void zynq_fpga_unmask_irqs(struct zynq_fpga_priv *priv)
+/* Must be called with dma_lock held */
+static void zynq_step_dma(struct zynq_fpga_priv *priv)
 {
-	u32 intr_mask;
+	u32 addr;
+	u32 len;
+	bool first;
+
+	first = priv->dma_elm == 0;
+	while (priv->cur_sg) {
+		/* Feed the DMA queue until it is full. */
+		if (zynq_fpga_read(priv, STATUS_OFFSET) & STATUS_DMA_Q_F)
+			break;
+
+		addr = sg_dma_address(priv->cur_sg);
+		len = sg_dma_len(priv->cur_sg);
+		if (priv->dma_elm + 1 == priv->dma_nelms) {
+			/* The last transfer waits for the PCAP to finish too,
+			 * notice this also changes the irq_mask to ignore
+			 * IXR_DMA_DONE_MASK which ensures we do not trigger
+			 * the completion too early.
+			 */
+			addr |= DMA_SRC_LAST_TRANSFER;
+			priv->cur_sg = NULL;
+		} else {
+			priv->cur_sg = sg_next(priv->cur_sg);
+			priv->dma_elm++;
+		}
 
-	intr_mask = zynq_fpga_read(priv, INT_MASK_OFFSET);
-	zynq_fpga_write(priv, INT_MASK_OFFSET,
-			intr_mask
-			& ~(IXR_D_P_DONE_MASK | IXR_ERROR_FLAGS_MASK));
+		zynq_fpga_write(priv, DMA_SRC_ADDR_OFFSET, addr);
+		zynq_fpga_write(priv, DMA_DST_ADDR_OFFSET, DMA_INVALID_ADDRESS);
+		zynq_fpga_write(priv, DMA_SRC_LEN_OFFSET, len / 4);
+		zynq_fpga_write(priv, DMA_DEST_LEN_OFFSET, 0);
+	}
+
+	/* Once the first transfer is queued we can turn on the ISR, future
+	 * calls to zynq_step_dma will happen from the ISR context. The
+	 * dma_lock spinlock guarentees this handover is done coherently, the
+	 * ISR enable is put at the end to avoid another CPU spinning in the
+	 * ISR on this lock.
+	 */
+	if (first && priv->cur_sg) {
+		zynq_fpga_set_irq(priv,
+				  IXR_DMA_DONE_MASK | IXR_ERROR_FLAGS_MASK);
+	} else if (!priv->cur_sg) {
+		/* The last transfer changes to DMA & PCAP mode since we do
+		 * not want to continue until everything has been flushed into
+		 * the PCAP.
+		 */
+		zynq_fpga_set_irq(priv,
+				  IXR_D_P_DONE_MASK | IXR_ERROR_FLAGS_MASK);
+	}
 }
 
 static irqreturn_t zynq_fpga_isr(int irq, void *data)
 {
 	struct zynq_fpga_priv *priv = data;
+	u32 intr_status;
 
-	/* disable DMA and error IRQs */
-	zynq_fpga_mask_irqs(priv);
+	/* If anything other than DMA completion is reported stop and hand
+	 * control back to zynq_fpga_ops_write, something went wrong,
+	 * otherwise progress the DMA.
+	 */
+	spin_lock(&priv->dma_lock);
+	intr_status = zynq_fpga_read(priv, INT_STS_OFFSET);
+	if (!(intr_status & IXR_ERROR_FLAGS_MASK) &&
+	    (intr_status & IXR_DMA_DONE_MASK) && priv->cur_sg) {
+		zynq_fpga_write(priv, INT_STS_OFFSET, IXR_DMA_DONE_MASK);
+		zynq_step_dma(priv);
+		spin_unlock(&priv->dma_lock);
+		return IRQ_HANDLED;
+	}
+	spin_unlock(&priv->dma_lock);
 
+	zynq_fpga_set_irq(priv, 0);
 	complete(&priv->dma_done);
 
 	return IRQ_HANDLED;
 }
 
+/* Sanity check the proposed bitstream. It must start with the sync word in
+ * the correct byte order, and be dword aligned. The input is a Xilinx .bin
+ * file with every 32 bit quantity swapped.
+ */
+static bool zynq_fpga_has_sync(const u8 *buf, size_t count)
+{
+	for (; count >= 4; buf += 4, count -= 4)
+		if (buf[0] == 0x66 && buf[1] == 0x55 && buf[2] == 0x99 &&
+		    buf[3] == 0xaa)
+			return true;
+	return false;
+}
+
 static int zynq_fpga_ops_write_init(struct fpga_manager *mgr,
 				    struct fpga_image_info *info,
 				    const char *buf, size_t count)
 {
 	struct zynq_fpga_priv *priv;
 	u32 ctrl, status;
 	int err;
 
 	priv = mgr->priv;
 
 	err = clk_enable(priv->clk);
 	if (err)
 		return err;
 
 	/* don't globally reset PL if we're doing partial reconfig */
 	if (!(info->flags & FPGA_MGR_PARTIAL_RECONFIG)) {
+		if (!zynq_fpga_has_sync(buf, count)) {
+			dev_err(&mgr->dev,
+				"Invalid bitstream, could not find a sync word. Bitstream must be a byte swapped .bin file\n");
+			err = -EINVAL;
+			goto out_err;
+		}
+
 		/* assert AXI interface resets */
 		regmap_write(priv->slcr, SLCR_FPGA_RST_CTRL_OFFSET,
 			     FPGA_RST_ALL_MASK);
 
 		/* disable all level shifters */
 		regmap_write(priv->slcr, SLCR_LVL_SHFTR_EN_OFFSET,
 			     LVL_SHFTR_DISABLE_ALL_MASK);
 		/* enable level shifters from PS to PL */
 		regmap_write(priv->slcr, SLCR_LVL_SHFTR_EN_OFFSET,
 			     LVL_SHFTR_ENABLE_PS_TO_PL);
 
 		/* create a rising edge on PCFG_INIT. PCFG_INIT follows
 		 * PCFG_PROG_B, so we need to poll it after setting PCFG_PROG_B
 		 * to make sure the rising edge actually happens.
 		 * Note: PCFG_PROG_B is low active, sequence as described in
 		 * UG585 v1.10 page 211
 		 */
 		ctrl = zynq_fpga_read(priv, CTRL_OFFSET);
 		ctrl |= CTRL_PCFG_PROG_B_MASK;
 
 		zynq_fpga_write(priv, CTRL_OFFSET, ctrl);
 
 		err = zynq_fpga_poll_timeout(priv, STATUS_OFFSET, status,
 					     status & STATUS_PCFG_INIT_MASK,
 					     INIT_POLL_DELAY,
 					     INIT_POLL_TIMEOUT);
 		if (err) {
 			dev_err(&mgr->dev, "Timeout waiting for PCFG_INIT\n");
 			goto out_err;
 		}
 
 		ctrl = zynq_fpga_read(priv, CTRL_OFFSET);
 		ctrl &= ~CTRL_PCFG_PROG_B_MASK;
 
 		zynq_fpga_write(priv, CTRL_OFFSET, ctrl);
 
 		err = zynq_fpga_poll_timeout(priv, STATUS_OFFSET, status,
 					     !(status & STATUS_PCFG_INIT_MASK),
 					     INIT_POLL_DELAY,
 					     INIT_POLL_TIMEOUT);
 		if (err) {
 			dev_err(&mgr->dev, "Timeout waiting for !PCFG_INIT\n");
 			goto out_err;
 		}
 
 		ctrl = zynq_fpga_read(priv, CTRL_OFFSET);
 		ctrl |= CTRL_PCFG_PROG_B_MASK;
 
 		zynq_fpga_write(priv, CTRL_OFFSET, ctrl);
 
 		err = zynq_fpga_poll_timeout(priv, STATUS_OFFSET, status,
 					     status & STATUS_PCFG_INIT_MASK,
 					     INIT_POLL_DELAY,
 					     INIT_POLL_TIMEOUT);
 		if (err) {
 			dev_err(&mgr->dev, "Timeout waiting for PCFG_INIT\n");
 			goto out_err;
 		}
 	}
 
 	/* set configuration register with following options:
 	 * - enable PCAP interface
 	 * - set throughput for maximum speed
 	 * - set CPU in user mode
 	 */
 	ctrl = zynq_fpga_read(priv, CTRL_OFFSET);
 	zynq_fpga_write(priv, CTRL_OFFSET,
 			(CTRL_PCAP_PR_MASK | CTRL_PCAP_MODE_MASK | ctrl));
 
-	/* check that we have room in the command queue */
+	/* We expect that the command queue is empty right now. */
 	status = zynq_fpga_read(priv, STATUS_OFFSET);
-	if (status & STATUS_DMA_Q_F) {
-		dev_err(&mgr->dev, "DMA command queue full\n");
+	if ((status & STATUS_DMA_Q_F) ||
+	    (status & STATUS_DMA_Q_E) != STATUS_DMA_Q_E) {
+		dev_err(&mgr->dev, "DMA command queue not right\n");
 		err = -EBUSY;
 		goto out_err;
 	}
 
 	/* ensure internal PCAP loopback is disabled */
 	ctrl = zynq_fpga_read(priv, MCTRL_OFFSET);
 	zynq_fpga_write(priv, MCTRL_OFFSET, (~MCTRL_PCAP_LPBK_MASK & ctrl));
 
 	clk_disable(priv->clk);
 
 	return 0;
 
 out_err:
 	clk_disable(priv->clk);
 
 	return err;
 }
 
-static int zynq_fpga_ops_write(struct fpga_manager *mgr,
-			       const char *buf, size_t count)
+static int zynq_fpga_ops_write(struct fpga_manager *mgr, struct sg_table *sgt)
 {
 	struct zynq_fpga_priv *priv;
+	const char *why;
 	int err;
-	char *kbuf;
-	size_t in_count;
-	dma_addr_t dma_addr;
-	u32 transfer_length;
 	u32 intr_status;
+	unsigned long timeout;
+	unsigned long flags;
+	struct scatterlist *sg;
+	int i;
 
-	in_count = count;
 	priv = mgr->priv;
 
-	kbuf =
-	    dma_alloc_coherent(mgr->dev.parent, count, &dma_addr, GFP_KERNEL);
-	if (!kbuf)
-		return -ENOMEM;
+	/* The hardware can only DMA multiples of 4 bytes, and it requires the
+	 * starting addresses to be aligned to 64 bits (UG585 pg 212).
+	 */
+	for_each_sg(sgt->sgl, sg, sgt->nents, i) {
+		if ((sg->offset % 8) || (sg->length % 4)) {
+			dev_err(&mgr->dev,
+			    "Invalid bitstream, chunks must be aligned\n");
+			return -EINVAL;
+		}
+	}
 
-	memcpy(kbuf, buf, count);
+	priv->dma_nelms =
+	    dma_map_sg(mgr->dev.parent, sgt->sgl, sgt->nents, DMA_TO_DEVICE);
+	if (priv->dma_nelms == 0) {
+		dev_err(&mgr->dev, "Unable to DMA map (TO_DEVICE)\n");
+		return -ENOMEM;
+	}
 
 	/* enable clock */
 	err = clk_enable(priv->clk);
 	if (err)
 		goto out_free;
 
 	zynq_fpga_write(priv, INT_STS_OFFSET, IXR_ALL_MASK);
-
 	reinit_completion(&priv->dma_done);
 
-	/* enable DMA and error IRQs */
-	zynq_fpga_unmask_irqs(priv);
+	/* zynq_step_dma will turn on interrupts */
+	spin_lock_irqsave(&priv->dma_lock, flags);
+	priv->dma_elm = 0;
+	priv->cur_sg = sgt->sgl;
+	zynq_step_dma(priv);
+	spin_unlock_irqrestore(&priv->dma_lock, flags);
 
-	/* the +1 in the src addr is used to hold off on DMA_DONE IRQ
-	 * until both AXI and PCAP are done ...
-	 */
-	zynq_fpga_write(priv, DMA_SRC_ADDR_OFFSET, (u32)(dma_addr) + 1);
-	zynq_fpga_write(priv, DMA_DST_ADDR_OFFSET, (u32)DMA_INVALID_ADDRESS);
+	timeout = wait_for_completion_timeout(&priv->dma_done,
+					      msecs_to_jiffies(DMA_TIMEOUT_MS));
 
-	/* convert #bytes to #words */
-	transfer_length = (count + 3) / 4;
+	spin_lock_irqsave(&priv->dma_lock, flags);
+	zynq_fpga_set_irq(priv, 0);
+	priv->cur_sg = NULL;
+	spin_unlock_irqrestore(&priv->dma_lock, flags);
 
-	zynq_fpga_write(priv, DMA_SRC_LEN_OFFSET, transfer_length);
-	zynq_fpga_write(priv, DMA_DEST_LEN_OFFSET, 0);
+	intr_status = zynq_fpga_read(priv, INT_STS_OFFSET);
+	zynq_fpga_write(priv, INT_STS_OFFSET, IXR_ALL_MASK);
 
-	wait_for_completion(&priv->dma_done);
+	/* There doesn't seem to be a way to force cancel any DMA, so if
+	 * something went wrong we are relying on the hardware to have halted
+	 * the DMA before we get here, if there was we could use
+	 * wait_for_completion_interruptible too.
+	 */
 
-	intr_status = zynq_fpga_read(priv, INT_STS_OFFSET);
-	zynq_fpga_write(priv, INT_STS_OFFSET, intr_status);
+	if (intr_status & IXR_ERROR_FLAGS_MASK) {
+		why = "DMA reported error";
+		err = -EIO;
+		goto out_report;
+	}
 
-	if (!((intr_status & IXR_D_P_DONE_MASK) == IXR_D_P_DONE_MASK)) {
-		dev_err(&mgr->dev, "Error configuring FPGA\n");
-		err = -EFAULT;
+	if (priv->cur_sg ||
+	    !((intr_status & IXR_D_P_DONE_MASK) == IXR_D_P_DONE_MASK)) {
+		if (timeout == 0)
+			why = "DMA timed out";
+		else
+			why = "DMA did not complete";
+		err = -EIO;
+		goto out_report;
 	}
 
+	err = 0;
+	goto out_clk;
+
+out_report:
+	dev_err(&mgr->dev,
+		"%s: INT_STS:0x%x CTRL:0x%x LOCK:0x%x INT_MASK:0x%x STATUS:0x%x MCTRL:0x%x\n",
+		why,
+		intr_status,
+		zynq_fpga_read(priv, CTRL_OFFSET),
+		zynq_fpga_read(priv, LOCK_OFFSET),
+		zynq_fpga_read(priv, INT_MASK_OFFSET),
+		zynq_fpga_read(priv, STATUS_OFFSET),
+		zynq_fpga_read(priv, MCTRL_OFFSET));
+
+out_clk:
 	clk_disable(priv->clk);
 
 out_free:
-	dma_free_coherent(mgr->dev.parent, count, kbuf, dma_addr);
+	dma_unmap_sg(mgr->dev.parent, sgt->sgl, sgt->nents, DMA_TO_DEVICE);
 	return err;
 }
 
 static int zynq_fpga_ops_write_complete(struct fpga_manager *mgr,
 					struct fpga_image_info *info)
 {
 	struct zynq_fpga_priv *priv = mgr->priv;
 	int err;
 	u32 intr_status;
 
 	err = clk_enable(priv->clk);
 	if (err)
 		return err;
 
 	err = zynq_fpga_poll_timeout(priv, INT_STS_OFFSET, intr_status,
 				     intr_status & IXR_PCFG_DONE_MASK,
 				     INIT_POLL_DELAY,
 				     INIT_POLL_TIMEOUT);
 
 	clk_disable(priv->clk);
 
 	if (err)
 		return err;
 
 	/* for the partial reconfig case we didn't touch the level shifters */
 	if (!(info->flags & FPGA_MGR_PARTIAL_RECONFIG)) {
 		/* enable level shifters from PL to PS */
 		regmap_write(priv->slcr, SLCR_LVL_SHFTR_EN_OFFSET,
 			     LVL_SHFTR_ENABLE_PL_TO_PS);
 
 		/* deassert AXI interface resets */
 		regmap_write(priv->slcr, SLCR_FPGA_RST_CTRL_OFFSET,
 			     FPGA_RST_NONE_MASK);
 	}
 
 	return 0;
 }
 
 static enum fpga_mgr_states zynq_fpga_ops_state(struct fpga_manager *mgr)
 {
 	int err;
 	u32 intr_status;
 	struct zynq_fpga_priv *priv;
 
 	priv = mgr->priv;
 
 	err = clk_enable(priv->clk);
 	if (err)
 		return FPGA_MGR_STATE_UNKNOWN;
 
 	intr_status = zynq_fpga_read(priv, INT_STS_OFFSET);
 	clk_disable(priv->clk);
 
 	if (intr_status & IXR_PCFG_DONE_MASK)
 		return FPGA_MGR_STATE_OPERATING;
 
 	return FPGA_MGR_STATE_UNKNOWN;
 }
 
 static const struct fpga_manager_ops zynq_fpga_ops = {
+	.initial_header_size = 128,
 	.state = zynq_fpga_ops_state,
 	.write_init = zynq_fpga_ops_write_init,
-	.write = zynq_fpga_ops_write,
+	.write_sg = zynq_fpga_ops_write,
 	.write_complete = zynq_fpga_ops_write_complete,
 };
 
 static int zynq_fpga_probe(struct platform_device *pdev)
 {
 	struct device *dev = &pdev->dev;
 	struct zynq_fpga_priv *priv;
 	struct resource *res;
 	int err;
 
 	priv = devm_kzalloc(dev, sizeof(*priv), GFP_KERNEL);
 	if (!priv)
 		return -ENOMEM;
+	spin_lock_init(&priv->dma_lock);
 
 	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
 	priv->io_base = devm_ioremap_resource(dev, res);
 	if (IS_ERR(priv->io_base))
 		return PTR_ERR(priv->io_base);
 
 	priv->slcr = syscon_regmap_lookup_by_phandle(dev->of_node,
 		"syscon");
 	if (IS_ERR(priv->slcr)) {
 		dev_err(dev, "unable to get zynq-slcr regmap\n");
 		return PTR_ERR(priv->slcr);
 	}
 
 	init_completion(&priv->dma_done);
 
 	priv->irq = platform_get_irq(pdev, 0);
 	if (priv->irq < 0) {
 		dev_err(dev, "No IRQ available\n");
 		return priv->irq;
 	}
 
 	priv->clk = devm_clk_get(dev, "ref_clk");
 	if (IS_ERR(priv->clk)) {
 		dev_err(dev, "input clock not found\n");
 		return PTR_ERR(priv->clk);
 	}
 
 	err = clk_prepare_enable(priv->clk);
 	if (err) {
 		dev_err(dev, "unable to enable clock\n");
 		return err;
 	}
 
 	/* unlock the device */
 	zynq_fpga_write(priv, UNLOCK_OFFSET, UNLOCK_MASK);
 
-	zynq_fpga_write(priv, INT_MASK_OFFSET, 0xFFFFFFFF);
+	zynq_fpga_set_irq(priv, 0);
 	zynq_fpga_write(priv, INT_STS_OFFSET, IXR_ALL_MASK);
 	err = devm_request_irq(dev, priv->irq, zynq_fpga_isr, 0, dev_name(dev),
 			       priv);
 	if (err) {
 		dev_err(dev, "unable to request IRQ\n");
 		clk_disable_unprepare(priv->clk);
 		return err;
 	}
 
 	clk_disable(priv->clk);
 
 	err = fpga_mgr_register(dev, "Xilinx Zynq FPGA Manager",
 				&zynq_fpga_ops, priv);
 	if (err) {
 		dev_err(dev, "unable to register FPGA manager\n");
 		clk_unprepare(priv->clk);
 		return err;
 	}
 
 	return 0;
 }
 
 static int zynq_fpga_remove(struct platform_device *pdev)
 {
 	struct zynq_fpga_priv *priv;
 	struct fpga_manager *mgr;
 
 	mgr = platform_get_drvdata(pdev);
 	priv = mgr->priv;
 
 	fpga_mgr_unregister(&pdev->dev);
 
 	clk_unprepare(priv->clk);
 
 	return 0;
 }
 
 #ifdef CONFIG_OF
 static const struct of_device_id zynq_fpga_of_match[] = {
 	{ .compatible = "xlnx,zynq-devcfg-1.0", },
 	{},
 };
 
 MODULE_DEVICE_TABLE(of, zynq_fpga_of_match);
 #endif
 
 static struct platform_driver zynq_fpga_driver = {
 	.probe = zynq_fpga_probe,
 	.remove = zynq_fpga_remove,
 	.driver = {
 		.name = "zynq_fpga_manager",
 		.of_match_table = of_match_ptr(zynq_fpga_of_match),
 	},
 };
 
 module_platform_driver(zynq_fpga_driver);
 
 MODULE_AUTHOR("Moritz Fischer <moritz.fischer@ettus.com>");
 MODULE_AUTHOR("Michal Simek <michal.simek@xilinx.com>");
 MODULE_DESCRIPTION("Xilinx Zynq FPGA Manager");
 MODULE_LICENSE("GPL v2");
diff --git a/drivers/fsi/Kconfig b/drivers/fsi/Kconfig
new file mode 100644
index 000000000000..04c1a0efa7a7
--- /dev/null
+++ b/drivers/fsi/Kconfig
@@ -0,0 +1,12 @@
+#
+# FSI subsystem
+#
+
+menu "FSI support"
+
+config FSI
+	tristate "FSI support"
+	---help---
+	  FSI - the FRU Support Interface - is a simple bus for low-level
+	  access to POWER-based hardware.
+endmenu
diff --git a/drivers/fsi/Makefile b/drivers/fsi/Makefile
new file mode 100644
index 000000000000..db0e5e7c1655
--- /dev/null
+++ b/drivers/fsi/Makefile
@@ -0,0 +1,2 @@
+
+obj-$(CONFIG_FSI) += fsi-core.o
diff --git a/drivers/fsi/fsi-core.c b/drivers/fsi/fsi-core.c
new file mode 100644
index 000000000000..3d55bd547178
--- /dev/null
+++ b/drivers/fsi/fsi-core.c
@@ -0,0 +1,59 @@
+/*
+ * FSI core driver
+ *
+ * Copyright (C) IBM Corporation 2016
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/device.h>
+#include <linux/fsi.h>
+#include <linux/module.h>
+
+/* FSI core & Linux bus type definitions */
+
+static int fsi_bus_match(struct device *dev, struct device_driver *drv)
+{
+	struct fsi_device *fsi_dev = to_fsi_dev(dev);
+	struct fsi_driver *fsi_drv = to_fsi_drv(drv);
+	const struct fsi_device_id *id;
+
+	if (!fsi_drv->id_table)
+		return 0;
+
+	for (id = fsi_drv->id_table; id->engine_type; id++) {
+		if (id->engine_type != fsi_dev->engine_type)
+			continue;
+		if (id->version == FSI_VERSION_ANY ||
+				id->version == fsi_dev->version)
+			return 1;
+	}
+
+	return 0;
+}
+
+struct bus_type fsi_bus_type = {
+	.name		= "fsi",
+	.match		= fsi_bus_match,
+};
+EXPORT_SYMBOL_GPL(fsi_bus_type);
+
+static int fsi_init(void)
+{
+	return bus_register(&fsi_bus_type);
+}
+
+static void fsi_exit(void)
+{
+	bus_unregister(&fsi_bus_type);
+}
+
+module_init(fsi_init);
+module_exit(fsi_exit);
diff --git a/drivers/hv/channel.c b/drivers/hv/channel.c
index 5fb4c6d9209b..81a80c82f1bd 100644
--- a/drivers/hv/channel.c
+++ b/drivers/hv/channel.c
@@ -1,906 +1,910 @@
 /*
  * Copyright (c) 2009, Microsoft Corporation.
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms and conditions of the GNU General Public License,
  * version 2, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope it will be useful, but WITHOUT
  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
  * more details.
  *
  * You should have received a copy of the GNU General Public License along with
  * this program; if not, write to the Free Software Foundation, Inc., 59 Temple
  * Place - Suite 330, Boston, MA 02111-1307 USA.
  *
  * Authors:
  *   Haiyang Zhang <haiyangz@microsoft.com>
  *   Hank Janssen  <hjanssen@microsoft.com>
  */
 #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
 
 #include <linux/kernel.h>
 #include <linux/sched.h>
 #include <linux/wait.h>
 #include <linux/mm.h>
 #include <linux/slab.h>
 #include <linux/module.h>
 #include <linux/hyperv.h>
 #include <linux/uio.h>
 #include <linux/interrupt.h>
 
 #include "hyperv_vmbus.h"
 
 #define NUM_PAGES_SPANNED(addr, len) \
 ((PAGE_ALIGN(addr + len) >> PAGE_SHIFT) - (addr >> PAGE_SHIFT))
 
 /*
  * vmbus_setevent- Trigger an event notification on the specified
  * channel.
  */
 void vmbus_setevent(struct vmbus_channel *channel)
 {
 	struct hv_monitor_page *monitorpage;
 
 	/*
 	 * For channels marked as in "low latency" mode
 	 * bypass the monitor page mechanism.
 	 */
-	if ((channel->offermsg.monitor_allocated) &&
-	    (!channel->low_latency)) {
-		/* Each u32 represents 32 channels */
-		sync_set_bit(channel->offermsg.child_relid & 31,
-			(unsigned long *) vmbus_connection.send_int_page +
-			(channel->offermsg.child_relid >> 5));
+	if (channel->offermsg.monitor_allocated && !channel->low_latency) {
+		vmbus_send_interrupt(channel->offermsg.child_relid);
 
 		/* Get the child to parent monitor page */
 		monitorpage = vmbus_connection.monitor_pages[1];
 
 		sync_set_bit(channel->monitor_bit,
 			(unsigned long *)&monitorpage->trigger_group
 					[channel->monitor_grp].pending);
 
 	} else {
 		vmbus_set_event(channel);
 	}
 }
 EXPORT_SYMBOL_GPL(vmbus_setevent);
 
 /*
  * vmbus_open - Open the specified channel.
  */
 int vmbus_open(struct vmbus_channel *newchannel, u32 send_ringbuffer_size,
 		     u32 recv_ringbuffer_size, void *userdata, u32 userdatalen,
 		     void (*onchannelcallback)(void *context), void *context)
 {
 	struct vmbus_channel_open_channel *open_msg;
 	struct vmbus_channel_msginfo *open_info = NULL;
 	unsigned long flags;
 	int ret, err = 0;
 	struct page *page;
 
 	if (send_ringbuffer_size % PAGE_SIZE ||
 	    recv_ringbuffer_size % PAGE_SIZE)
 		return -EINVAL;
 
 	spin_lock_irqsave(&newchannel->lock, flags);
 	if (newchannel->state == CHANNEL_OPEN_STATE) {
 		newchannel->state = CHANNEL_OPENING_STATE;
 	} else {
 		spin_unlock_irqrestore(&newchannel->lock, flags);
 		return -EINVAL;
 	}
 	spin_unlock_irqrestore(&newchannel->lock, flags);
 
 	newchannel->onchannel_callback = onchannelcallback;
 	newchannel->channel_callback_context = context;
 
 	/* Allocate the ring buffer */
 	page = alloc_pages_node(cpu_to_node(newchannel->target_cpu),
 				GFP_KERNEL|__GFP_ZERO,
 				get_order(send_ringbuffer_size +
 				recv_ringbuffer_size));
 
 	if (!page)
 		page = alloc_pages(GFP_KERNEL|__GFP_ZERO,
 				   get_order(send_ringbuffer_size +
 					     recv_ringbuffer_size));
 
 	if (!page) {
 		err = -ENOMEM;
 		goto error_set_chnstate;
 	}
 
 	newchannel->ringbuffer_pages = page_address(page);
 	newchannel->ringbuffer_pagecount = (send_ringbuffer_size +
 					   recv_ringbuffer_size) >> PAGE_SHIFT;
 
 	ret = hv_ringbuffer_init(&newchannel->outbound, page,
 				 send_ringbuffer_size >> PAGE_SHIFT);
 
 	if (ret != 0) {
 		err = ret;
 		goto error_free_pages;
 	}
 
 	ret = hv_ringbuffer_init(&newchannel->inbound,
 				 &page[send_ringbuffer_size >> PAGE_SHIFT],
 				 recv_ringbuffer_size >> PAGE_SHIFT);
 	if (ret != 0) {
 		err = ret;
 		goto error_free_pages;
 	}
 
 
 	/* Establish the gpadl for the ring buffer */
 	newchannel->ringbuffer_gpadlhandle = 0;
 
 	ret = vmbus_establish_gpadl(newchannel,
 				    page_address(page),
 				    send_ringbuffer_size +
 				    recv_ringbuffer_size,
 				    &newchannel->ringbuffer_gpadlhandle);
 
 	if (ret != 0) {
 		err = ret;
 		goto error_free_pages;
 	}
 
 	/* Create and init the channel open message */
 	open_info = kmalloc(sizeof(*open_info) +
 			   sizeof(struct vmbus_channel_open_channel),
 			   GFP_KERNEL);
 	if (!open_info) {
 		err = -ENOMEM;
 		goto error_free_gpadl;
 	}
 
 	init_completion(&open_info->waitevent);
+	open_info->waiting_channel = newchannel;
 
 	open_msg = (struct vmbus_channel_open_channel *)open_info->msg;
 	open_msg->header.msgtype = CHANNELMSG_OPENCHANNEL;
 	open_msg->openid = newchannel->offermsg.child_relid;
 	open_msg->child_relid = newchannel->offermsg.child_relid;
 	open_msg->ringbuffer_gpadlhandle = newchannel->ringbuffer_gpadlhandle;
 	open_msg->downstream_ringbuffer_pageoffset = send_ringbuffer_size >>
 						  PAGE_SHIFT;
 	open_msg->target_vp = newchannel->target_vp;
 
 	if (userdatalen > MAX_USER_DEFINED_BYTES) {
 		err = -EINVAL;
 		goto error_free_gpadl;
 	}
 
 	if (userdatalen)
 		memcpy(open_msg->userdata, userdata, userdatalen);
 
 	spin_lock_irqsave(&vmbus_connection.channelmsg_lock, flags);
 	list_add_tail(&open_info->msglistentry,
 		      &vmbus_connection.chn_msg_list);
 	spin_unlock_irqrestore(&vmbus_connection.channelmsg_lock, flags);
 
 	ret = vmbus_post_msg(open_msg,
-			       sizeof(struct vmbus_channel_open_channel));
+			     sizeof(struct vmbus_channel_open_channel), true);
 
 	if (ret != 0) {
 		err = ret;
 		goto error_clean_msglist;
 	}
 
 	wait_for_completion(&open_info->waitevent);
 
 	spin_lock_irqsave(&vmbus_connection.channelmsg_lock, flags);
 	list_del(&open_info->msglistentry);
 	spin_unlock_irqrestore(&vmbus_connection.channelmsg_lock, flags);
 
+	if (newchannel->rescind) {
+		err = -ENODEV;
+		goto error_free_gpadl;
+	}
+
 	if (open_info->response.open_result.status) {
 		err = -EAGAIN;
 		goto error_free_gpadl;
 	}
 
 	newchannel->state = CHANNEL_OPENED_STATE;
 	kfree(open_info);
 	return 0;
 
 error_clean_msglist:
 	spin_lock_irqsave(&vmbus_connection.channelmsg_lock, flags);
 	list_del(&open_info->msglistentry);
 	spin_unlock_irqrestore(&vmbus_connection.channelmsg_lock, flags);
 
 error_free_gpadl:
 	vmbus_teardown_gpadl(newchannel, newchannel->ringbuffer_gpadlhandle);
 	kfree(open_info);
 error_free_pages:
 	hv_ringbuffer_cleanup(&newchannel->outbound);
 	hv_ringbuffer_cleanup(&newchannel->inbound);
 	__free_pages(page,
 		     get_order(send_ringbuffer_size + recv_ringbuffer_size));
 error_set_chnstate:
 	newchannel->state = CHANNEL_OPEN_STATE;
 	return err;
 }
 EXPORT_SYMBOL_GPL(vmbus_open);
 
 /* Used for Hyper-V Socket: a guest client's connect() to the host */
 int vmbus_send_tl_connect_request(const uuid_le *shv_guest_servie_id,
 				  const uuid_le *shv_host_servie_id)
 {
 	struct vmbus_channel_tl_connect_request conn_msg;
 
 	memset(&conn_msg, 0, sizeof(conn_msg));
 	conn_msg.header.msgtype = CHANNELMSG_TL_CONNECT_REQUEST;
 	conn_msg.guest_endpoint_id = *shv_guest_servie_id;
 	conn_msg.host_service_id = *shv_host_servie_id;
 
-	return vmbus_post_msg(&conn_msg, sizeof(conn_msg));
+	return vmbus_post_msg(&conn_msg, sizeof(conn_msg), true);
 }
 EXPORT_SYMBOL_GPL(vmbus_send_tl_connect_request);
 
 /*
  * create_gpadl_header - Creates a gpadl for the specified buffer
  */
 static int create_gpadl_header(void *kbuffer, u32 size,
 			       struct vmbus_channel_msginfo **msginfo)
 {
 	int i;
 	int pagecount;
 	struct vmbus_channel_gpadl_header *gpadl_header;
 	struct vmbus_channel_gpadl_body *gpadl_body;
 	struct vmbus_channel_msginfo *msgheader;
 	struct vmbus_channel_msginfo *msgbody = NULL;
 	u32 msgsize;
 
 	int pfnsum, pfncount, pfnleft, pfncurr, pfnsize;
 
 	pagecount = size >> PAGE_SHIFT;
 
 	/* do we need a gpadl body msg */
 	pfnsize = MAX_SIZE_CHANNEL_MESSAGE -
 		  sizeof(struct vmbus_channel_gpadl_header) -
 		  sizeof(struct gpa_range);
 	pfncount = pfnsize / sizeof(u64);
 
 	if (pagecount > pfncount) {
 		/* we need a gpadl body */
 		/* fill in the header */
 		msgsize = sizeof(struct vmbus_channel_msginfo) +
 			  sizeof(struct vmbus_channel_gpadl_header) +
 			  sizeof(struct gpa_range) + pfncount * sizeof(u64);
 		msgheader =  kzalloc(msgsize, GFP_KERNEL);
 		if (!msgheader)
 			goto nomem;
 
 		INIT_LIST_HEAD(&msgheader->submsglist);
 		msgheader->msgsize = msgsize;
 
 		gpadl_header = (struct vmbus_channel_gpadl_header *)
 			msgheader->msg;
 		gpadl_header->rangecount = 1;
 		gpadl_header->range_buflen = sizeof(struct gpa_range) +
 					 pagecount * sizeof(u64);
 		gpadl_header->range[0].byte_offset = 0;
 		gpadl_header->range[0].byte_count = size;
 		for (i = 0; i < pfncount; i++)
 			gpadl_header->range[0].pfn_array[i] = slow_virt_to_phys(
 				kbuffer + PAGE_SIZE * i) >> PAGE_SHIFT;
 		*msginfo = msgheader;
 
 		pfnsum = pfncount;
 		pfnleft = pagecount - pfncount;
 
 		/* how many pfns can we fit */
 		pfnsize = MAX_SIZE_CHANNEL_MESSAGE -
 			  sizeof(struct vmbus_channel_gpadl_body);
 		pfncount = pfnsize / sizeof(u64);
 
 		/* fill in the body */
 		while (pfnleft) {
 			if (pfnleft > pfncount)
 				pfncurr = pfncount;
 			else
 				pfncurr = pfnleft;
 
 			msgsize = sizeof(struct vmbus_channel_msginfo) +
 				  sizeof(struct vmbus_channel_gpadl_body) +
 				  pfncurr * sizeof(u64);
 			msgbody = kzalloc(msgsize, GFP_KERNEL);
 
 			if (!msgbody) {
 				struct vmbus_channel_msginfo *pos = NULL;
 				struct vmbus_channel_msginfo *tmp = NULL;
 				/*
 				 * Free up all the allocated messages.
 				 */
 				list_for_each_entry_safe(pos, tmp,
 					&msgheader->submsglist,
 					msglistentry) {
 
 					list_del(&pos->msglistentry);
 					kfree(pos);
 				}
 
 				goto nomem;
 			}
 
 			msgbody->msgsize = msgsize;
 			gpadl_body =
 				(struct vmbus_channel_gpadl_body *)msgbody->msg;
 
 			/*
 			 * Gpadl is u32 and we are using a pointer which could
 			 * be 64-bit
 			 * This is governed by the guest/host protocol and
 			 * so the hypervisor gurantees that this is ok.
 			 */
 			for (i = 0; i < pfncurr; i++)
 				gpadl_body->pfn[i] = slow_virt_to_phys(
 					kbuffer + PAGE_SIZE * (pfnsum + i)) >>
 					PAGE_SHIFT;
 
 			/* add to msg header */
 			list_add_tail(&msgbody->msglistentry,
 				      &msgheader->submsglist);
 			pfnsum += pfncurr;
 			pfnleft -= pfncurr;
 		}
 	} else {
 		/* everything fits in a header */
 		msgsize = sizeof(struct vmbus_channel_msginfo) +
 			  sizeof(struct vmbus_channel_gpadl_header) +
 			  sizeof(struct gpa_range) + pagecount * sizeof(u64);
 		msgheader = kzalloc(msgsize, GFP_KERNEL);
 		if (msgheader == NULL)
 			goto nomem;
 
 		INIT_LIST_HEAD(&msgheader->submsglist);
 		msgheader->msgsize = msgsize;
 
 		gpadl_header = (struct vmbus_channel_gpadl_header *)
 			msgheader->msg;
 		gpadl_header->rangecount = 1;
 		gpadl_header->range_buflen = sizeof(struct gpa_range) +
 					 pagecount * sizeof(u64);
 		gpadl_header->range[0].byte_offset = 0;
 		gpadl_header->range[0].byte_count = size;
 		for (i = 0; i < pagecount; i++)
 			gpadl_header->range[0].pfn_array[i] = slow_virt_to_phys(
 				kbuffer + PAGE_SIZE * i) >> PAGE_SHIFT;
 
 		*msginfo = msgheader;
 	}
 
 	return 0;
 nomem:
 	kfree(msgheader);
 	kfree(msgbody);
 	return -ENOMEM;
 }
 
 /*
  * vmbus_establish_gpadl - Estabish a GPADL for the specified buffer
  *
  * @channel: a channel
  * @kbuffer: from kmalloc or vmalloc
  * @size: page-size multiple
  * @gpadl_handle: some funky thing
  */
 int vmbus_establish_gpadl(struct vmbus_channel *channel, void *kbuffer,
 			       u32 size, u32 *gpadl_handle)
 {
 	struct vmbus_channel_gpadl_header *gpadlmsg;
 	struct vmbus_channel_gpadl_body *gpadl_body;
 	struct vmbus_channel_msginfo *msginfo = NULL;
 	struct vmbus_channel_msginfo *submsginfo, *tmp;
 	struct list_head *curr;
 	u32 next_gpadl_handle;
 	unsigned long flags;
 	int ret = 0;
 
 	next_gpadl_handle =
 		(atomic_inc_return(&vmbus_connection.next_gpadl_handle) - 1);
 
 	ret = create_gpadl_header(kbuffer, size, &msginfo);
 	if (ret)
 		return ret;
 
 	init_completion(&msginfo->waitevent);
+	msginfo->waiting_channel = channel;
 
 	gpadlmsg = (struct vmbus_channel_gpadl_header *)msginfo->msg;
 	gpadlmsg->header.msgtype = CHANNELMSG_GPADL_HEADER;
 	gpadlmsg->child_relid = channel->offermsg.child_relid;
 	gpadlmsg->gpadl = next_gpadl_handle;
 
 
 	spin_lock_irqsave(&vmbus_connection.channelmsg_lock, flags);
 	list_add_tail(&msginfo->msglistentry,
 		      &vmbus_connection.chn_msg_list);
 
 	spin_unlock_irqrestore(&vmbus_connection.channelmsg_lock, flags);
 
 	ret = vmbus_post_msg(gpadlmsg, msginfo->msgsize -
-			       sizeof(*msginfo));
+			     sizeof(*msginfo), true);
 	if (ret != 0)
 		goto cleanup;
 
 	list_for_each(curr, &msginfo->submsglist) {
 		submsginfo = (struct vmbus_channel_msginfo *)curr;
 		gpadl_body =
 			(struct vmbus_channel_gpadl_body *)submsginfo->msg;
 
 		gpadl_body->header.msgtype =
 			CHANNELMSG_GPADL_BODY;
 		gpadl_body->gpadl = next_gpadl_handle;
 
 		ret = vmbus_post_msg(gpadl_body,
-				     submsginfo->msgsize -
-				     sizeof(*submsginfo));
+				     submsginfo->msgsize - sizeof(*submsginfo),
+				     true);
 		if (ret != 0)
 			goto cleanup;
 
 	}
 	wait_for_completion(&msginfo->waitevent);
 
+	if (channel->rescind) {
+		ret = -ENODEV;
+		goto cleanup;
+	}
+
 	/* At this point, we received the gpadl created msg */
 	*gpadl_handle = gpadlmsg->gpadl;
 
 cleanup:
 	spin_lock_irqsave(&vmbus_connection.channelmsg_lock, flags);
 	list_del(&msginfo->msglistentry);
 	spin_unlock_irqrestore(&vmbus_connection.channelmsg_lock, flags);
 	list_for_each_entry_safe(submsginfo, tmp, &msginfo->submsglist,
 				 msglistentry) {
 		kfree(submsginfo);
 	}
 
 	kfree(msginfo);
 	return ret;
 }
 EXPORT_SYMBOL_GPL(vmbus_establish_gpadl);
 
 /*
  * vmbus_teardown_gpadl -Teardown the specified GPADL handle
  */
 int vmbus_teardown_gpadl(struct vmbus_channel *channel, u32 gpadl_handle)
 {
 	struct vmbus_channel_gpadl_teardown *msg;
 	struct vmbus_channel_msginfo *info;
 	unsigned long flags;
 	int ret;
 
 	info = kmalloc(sizeof(*info) +
 		       sizeof(struct vmbus_channel_gpadl_teardown), GFP_KERNEL);
 	if (!info)
 		return -ENOMEM;
 
 	init_completion(&info->waitevent);
+	info->waiting_channel = channel;
 
 	msg = (struct vmbus_channel_gpadl_teardown *)info->msg;
 
 	msg->header.msgtype = CHANNELMSG_GPADL_TEARDOWN;
 	msg->child_relid = channel->offermsg.child_relid;
 	msg->gpadl = gpadl_handle;
 
 	spin_lock_irqsave(&vmbus_connection.channelmsg_lock, flags);
 	list_add_tail(&info->msglistentry,
 		      &vmbus_connection.chn_msg_list);
 	spin_unlock_irqrestore(&vmbus_connection.channelmsg_lock, flags);
-	ret = vmbus_post_msg(msg,
-			       sizeof(struct vmbus_channel_gpadl_teardown));
+	ret = vmbus_post_msg(msg, sizeof(struct vmbus_channel_gpadl_teardown),
+			     true);
 
 	if (ret)
 		goto post_msg_err;
 
 	wait_for_completion(&info->waitevent);
 
+	if (channel->rescind) {
+		ret = -ENODEV;
+		goto post_msg_err;
+	}
+
 post_msg_err:
 	spin_lock_irqsave(&vmbus_connection.channelmsg_lock, flags);
 	list_del(&info->msglistentry);
 	spin_unlock_irqrestore(&vmbus_connection.channelmsg_lock, flags);
 
 	kfree(info);
 	return ret;
 }
 EXPORT_SYMBOL_GPL(vmbus_teardown_gpadl);
 
 static void reset_channel_cb(void *arg)
 {
 	struct vmbus_channel *channel = arg;
 
 	channel->onchannel_callback = NULL;
 }
 
 static int vmbus_close_internal(struct vmbus_channel *channel)
 {
 	struct vmbus_channel_close_channel *msg;
 	int ret;
 
 	/*
-	 * process_chn_event(), running in the tasklet, can race
+	 * vmbus_on_event(), running in the tasklet, can race
 	 * with vmbus_close_internal() in the case of SMP guest, e.g., when
 	 * the former is accessing channel->inbound.ring_buffer, the latter
 	 * could be freeing the ring_buffer pages.
 	 *
 	 * To resolve the race, we can serialize them by disabling the
 	 * tasklet when the latter is running here.
 	 */
 	hv_event_tasklet_disable(channel);
 
 	/*
 	 * In case a device driver's probe() fails (e.g.,
 	 * util_probe() -> vmbus_open() returns -ENOMEM) and the device is
 	 * rescinded later (e.g., we dynamically disble an Integrated Service
 	 * in Hyper-V Manager), the driver's remove() invokes vmbus_close():
 	 * here we should skip most of the below cleanup work.
 	 */
 	if (channel->state != CHANNEL_OPENED_STATE) {
 		ret = -EINVAL;
 		goto out;
 	}
 
 	channel->state = CHANNEL_OPEN_STATE;
 	channel->sc_creation_callback = NULL;
 	/* Stop callback and cancel the timer asap */
 	if (channel->target_cpu != get_cpu()) {
 		put_cpu();
 		smp_call_function_single(channel->target_cpu, reset_channel_cb,
 					 channel, true);
 	} else {
 		reset_channel_cb(channel);
 		put_cpu();
 	}
 
 	/* Send a closing message */
 
 	msg = &channel->close_msg.msg;
 
 	msg->header.msgtype = CHANNELMSG_CLOSECHANNEL;
 	msg->child_relid = channel->offermsg.child_relid;
 
-	ret = vmbus_post_msg(msg, sizeof(struct vmbus_channel_close_channel));
+	ret = vmbus_post_msg(msg, sizeof(struct vmbus_channel_close_channel),
+			     true);
 
 	if (ret) {
 		pr_err("Close failed: close post msg return is %d\n", ret);
 		/*
 		 * If we failed to post the close msg,
 		 * it is perhaps better to leak memory.
 		 */
 		goto out;
 	}
 
 	/* Tear down the gpadl for the channel's ring buffer */
 	if (channel->ringbuffer_gpadlhandle) {
 		ret = vmbus_teardown_gpadl(channel,
 					   channel->ringbuffer_gpadlhandle);
 		if (ret) {
 			pr_err("Close failed: teardown gpadl return %d\n", ret);
 			/*
 			 * If we failed to teardown gpadl,
 			 * it is perhaps better to leak memory.
 			 */
 			goto out;
 		}
 	}
 
 	/* Cleanup the ring buffers for this channel */
 	hv_ringbuffer_cleanup(&channel->outbound);
 	hv_ringbuffer_cleanup(&channel->inbound);
 
 	free_pages((unsigned long)channel->ringbuffer_pages,
 		get_order(channel->ringbuffer_pagecount * PAGE_SIZE));
 
 out:
 	hv_event_tasklet_enable(channel);
 
 	return ret;
 }
 
 /*
  * vmbus_close - Close the specified channel
  */
 void vmbus_close(struct vmbus_channel *channel)
 {
 	struct list_head *cur, *tmp;
 	struct vmbus_channel *cur_channel;
 
 	if (channel->primary_channel != NULL) {
 		/*
 		 * We will only close sub-channels when
 		 * the primary is closed.
 		 */
 		return;
 	}
 	/*
 	 * Close all the sub-channels first and then close the
 	 * primary channel.
 	 */
 	list_for_each_safe(cur, tmp, &channel->sc_list) {
 		cur_channel = list_entry(cur, struct vmbus_channel, sc_list);
 		if (cur_channel->state != CHANNEL_OPENED_STATE)
 			continue;
 		vmbus_close_internal(cur_channel);
 	}
 	/*
 	 * Now close the primary.
 	 */
 	vmbus_close_internal(channel);
 }
 EXPORT_SYMBOL_GPL(vmbus_close);
 
 int vmbus_sendpacket_ctl(struct vmbus_channel *channel, void *buffer,
-			   u32 bufferlen, u64 requestid,
-			   enum vmbus_packet_type type, u32 flags, bool kick_q)
+			 u32 bufferlen, u64 requestid,
+			 enum vmbus_packet_type type, u32 flags)
 {
 	struct vmpacket_descriptor desc;
 	u32 packetlen = sizeof(struct vmpacket_descriptor) + bufferlen;
 	u32 packetlen_aligned = ALIGN(packetlen, sizeof(u64));
 	struct kvec bufferlist[3];
 	u64 aligned_data = 0;
-	bool lock = channel->acquire_ring_lock;
 	int num_vecs = ((bufferlen != 0) ? 3 : 1);
 
 
 	/* Setup the descriptor */
 	desc.type = type; /* VmbusPacketTypeDataInBand; */
 	desc.flags = flags; /* VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED; */
 	/* in 8-bytes granularity */
 	desc.offset8 = sizeof(struct vmpacket_descriptor) >> 3;
 	desc.len8 = (u16)(packetlen_aligned >> 3);
 	desc.trans_id = requestid;
 
 	bufferlist[0].iov_base = &desc;
 	bufferlist[0].iov_len = sizeof(struct vmpacket_descriptor);
 	bufferlist[1].iov_base = buffer;
 	bufferlist[1].iov_len = bufferlen;
 	bufferlist[2].iov_base = &aligned_data;
 	bufferlist[2].iov_len = (packetlen_aligned - packetlen);
 
-	return hv_ringbuffer_write(channel, bufferlist, num_vecs,
-				   lock, kick_q);
-
+	return hv_ringbuffer_write(channel, bufferlist, num_vecs);
 }
 EXPORT_SYMBOL(vmbus_sendpacket_ctl);
 
 /**
  * vmbus_sendpacket() - Send the specified buffer on the given channel
  * @channel: Pointer to vmbus_channel structure.
  * @buffer: Pointer to the buffer you want to receive the data into.
  * @bufferlen: Maximum size of what the the buffer will hold
  * @requestid: Identifier of the request
  * @type: Type of packet that is being send e.g. negotiate, time
  * packet etc.
  *
  * Sends data in @buffer directly to hyper-v via the vmbus
  * This will send the data unparsed to hyper-v.
  *
  * Mainly used by Hyper-V drivers.
  */
 int vmbus_sendpacket(struct vmbus_channel *channel, void *buffer,
 			   u32 bufferlen, u64 requestid,
 			   enum vmbus_packet_type type, u32 flags)
 {
 	return vmbus_sendpacket_ctl(channel, buffer, bufferlen, requestid,
-				    type, flags, true);
+				    type, flags);
 }
 EXPORT_SYMBOL(vmbus_sendpacket);
 
 /*
  * vmbus_sendpacket_pagebuffer_ctl - Send a range of single-page buffer
  * packets using a GPADL Direct packet type. This interface allows you
  * to control notifying the host. This will be useful for sending
  * batched data. Also the sender can control the send flags
  * explicitly.
  */
 int vmbus_sendpacket_pagebuffer_ctl(struct vmbus_channel *channel,
-				     struct hv_page_buffer pagebuffers[],
-				     u32 pagecount, void *buffer, u32 bufferlen,
-				     u64 requestid,
-				     u32 flags,
-				     bool kick_q)
+				    struct hv_page_buffer pagebuffers[],
+				    u32 pagecount, void *buffer, u32 bufferlen,
+				    u64 requestid, u32 flags)
 {
 	int i;
 	struct vmbus_channel_packet_page_buffer desc;
 	u32 descsize;
 	u32 packetlen;
 	u32 packetlen_aligned;
 	struct kvec bufferlist[3];
 	u64 aligned_data = 0;
-	bool lock = channel->acquire_ring_lock;
 
 	if (pagecount > MAX_PAGE_BUFFER_COUNT)
 		return -EINVAL;
 
-
 	/*
 	 * Adjust the size down since vmbus_channel_packet_page_buffer is the
 	 * largest size we support
 	 */
 	descsize = sizeof(struct vmbus_channel_packet_page_buffer) -
 			  ((MAX_PAGE_BUFFER_COUNT - pagecount) *
 			  sizeof(struct hv_page_buffer));
 	packetlen = descsize + bufferlen;
 	packetlen_aligned = ALIGN(packetlen, sizeof(u64));
 
 	/* Setup the descriptor */
 	desc.type = VM_PKT_DATA_USING_GPA_DIRECT;
 	desc.flags = flags;
 	desc.dataoffset8 = descsize >> 3; /* in 8-bytes grandularity */
 	desc.length8 = (u16)(packetlen_aligned >> 3);
 	desc.transactionid = requestid;
 	desc.rangecount = pagecount;
 
 	for (i = 0; i < pagecount; i++) {
 		desc.range[i].len = pagebuffers[i].len;
 		desc.range[i].offset = pagebuffers[i].offset;
 		desc.range[i].pfn	 = pagebuffers[i].pfn;
 	}
 
 	bufferlist[0].iov_base = &desc;
 	bufferlist[0].iov_len = descsize;
 	bufferlist[1].iov_base = buffer;
 	bufferlist[1].iov_len = bufferlen;
 	bufferlist[2].iov_base = &aligned_data;
 	bufferlist[2].iov_len = (packetlen_aligned - packetlen);
 
-	return hv_ringbuffer_write(channel, bufferlist, 3,
-				   lock, kick_q);
+	return hv_ringbuffer_write(channel, bufferlist, 3);
 }
 EXPORT_SYMBOL_GPL(vmbus_sendpacket_pagebuffer_ctl);
 
 /*
  * vmbus_sendpacket_pagebuffer - Send a range of single-page buffer
  * packets using a GPADL Direct packet type.
  */
 int vmbus_sendpacket_pagebuffer(struct vmbus_channel *channel,
 				     struct hv_page_buffer pagebuffers[],
 				     u32 pagecount, void *buffer, u32 bufferlen,
 				     u64 requestid)
 {
 	u32 flags = VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED;
+
 	return vmbus_sendpacket_pagebuffer_ctl(channel, pagebuffers, pagecount,
-					       buffer, bufferlen, requestid,
-					       flags, true);
+					       buffer, bufferlen,
+					       requestid, flags);
 
 }
 EXPORT_SYMBOL_GPL(vmbus_sendpacket_pagebuffer);
 
 /*
  * vmbus_sendpacket_multipagebuffer - Send a multi-page buffer packet
  * using a GPADL Direct packet type.
  * The buffer includes the vmbus descriptor.
  */
 int vmbus_sendpacket_mpb_desc(struct vmbus_channel *channel,
 			      struct vmbus_packet_mpb_array *desc,
 			      u32 desc_size,
 			      void *buffer, u32 bufferlen, u64 requestid)
 {
 	u32 packetlen;
 	u32 packetlen_aligned;
 	struct kvec bufferlist[3];
 	u64 aligned_data = 0;
-	bool lock = channel->acquire_ring_lock;
 
 	packetlen = desc_size + bufferlen;
 	packetlen_aligned = ALIGN(packetlen, sizeof(u64));
 
 	/* Setup the descriptor */
 	desc->type = VM_PKT_DATA_USING_GPA_DIRECT;
 	desc->flags = VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED;
 	desc->dataoffset8 = desc_size >> 3; /* in 8-bytes grandularity */
 	desc->length8 = (u16)(packetlen_aligned >> 3);
 	desc->transactionid = requestid;
 	desc->rangecount = 1;
 
 	bufferlist[0].iov_base = desc;
 	bufferlist[0].iov_len = desc_size;
 	bufferlist[1].iov_base = buffer;
 	bufferlist[1].iov_len = bufferlen;
 	bufferlist[2].iov_base = &aligned_data;
 	bufferlist[2].iov_len = (packetlen_aligned - packetlen);
 
-	return hv_ringbuffer_write(channel, bufferlist, 3,
-				   lock, true);
+	return hv_ringbuffer_write(channel, bufferlist, 3);
 }
 EXPORT_SYMBOL_GPL(vmbus_sendpacket_mpb_desc);
 
 /*
  * vmbus_sendpacket_multipagebuffer - Send a multi-page buffer packet
  * using a GPADL Direct packet type.
  */
 int vmbus_sendpacket_multipagebuffer(struct vmbus_channel *channel,
 				struct hv_multipage_buffer *multi_pagebuffer,
 				void *buffer, u32 bufferlen, u64 requestid)
 {
 	struct vmbus_channel_packet_multipage_buffer desc;
 	u32 descsize;
 	u32 packetlen;
 	u32 packetlen_aligned;
 	struct kvec bufferlist[3];
 	u64 aligned_data = 0;
-	bool lock = channel->acquire_ring_lock;
 	u32 pfncount = NUM_PAGES_SPANNED(multi_pagebuffer->offset,
 					 multi_pagebuffer->len);
 
 	if (pfncount > MAX_MULTIPAGE_BUFFER_COUNT)
 		return -EINVAL;
 
 	/*
 	 * Adjust the size down since vmbus_channel_packet_multipage_buffer is
 	 * the largest size we support
 	 */
 	descsize = sizeof(struct vmbus_channel_packet_multipage_buffer) -
 			  ((MAX_MULTIPAGE_BUFFER_COUNT - pfncount) *
 			  sizeof(u64));
 	packetlen = descsize + bufferlen;
 	packetlen_aligned = ALIGN(packetlen, sizeof(u64));
 
 
 	/* Setup the descriptor */
 	desc.type = VM_PKT_DATA_USING_GPA_DIRECT;
 	desc.flags = VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED;
 	desc.dataoffset8 = descsize >> 3; /* in 8-bytes grandularity */
 	desc.length8 = (u16)(packetlen_aligned >> 3);
 	desc.transactionid = requestid;
 	desc.rangecount = 1;
 
 	desc.range.len = multi_pagebuffer->len;
 	desc.range.offset = multi_pagebuffer->offset;
 
 	memcpy(desc.range.pfn_array, multi_pagebuffer->pfn_array,
 	       pfncount * sizeof(u64));
 
 	bufferlist[0].iov_base = &desc;
 	bufferlist[0].iov_len = descsize;
 	bufferlist[1].iov_base = buffer;
 	bufferlist[1].iov_len = bufferlen;
 	bufferlist[2].iov_base = &aligned_data;
 	bufferlist[2].iov_len = (packetlen_aligned - packetlen);
 
-	return hv_ringbuffer_write(channel, bufferlist, 3,
-				   lock, true);
+	return hv_ringbuffer_write(channel, bufferlist, 3);
 }
 EXPORT_SYMBOL_GPL(vmbus_sendpacket_multipagebuffer);
 
 /**
  * vmbus_recvpacket() - Retrieve the user packet on the specified channel
  * @channel: Pointer to vmbus_channel structure.
  * @buffer: Pointer to the buffer you want to receive the data into.
  * @bufferlen: Maximum size of what the the buffer will hold
  * @buffer_actual_len: The actual size of the data after it was received
  * @requestid: Identifier of the request
  *
  * Receives directly from the hyper-v vmbus and puts the data it received
  * into Buffer. This will receive the data unparsed from hyper-v.
  *
  * Mainly used by Hyper-V drivers.
  */
 static inline int
 __vmbus_recvpacket(struct vmbus_channel *channel, void *buffer,
 		   u32 bufferlen, u32 *buffer_actual_len, u64 *requestid,
 		   bool raw)
 {
 	return hv_ringbuffer_read(channel, buffer, bufferlen,
 				  buffer_actual_len, requestid, raw);
 
 }
 
 int vmbus_recvpacket(struct vmbus_channel *channel, void *buffer,
 		     u32 bufferlen, u32 *buffer_actual_len,
 		     u64 *requestid)
 {
 	return __vmbus_recvpacket(channel, buffer, bufferlen,
 				  buffer_actual_len, requestid, false);
 }
 EXPORT_SYMBOL(vmbus_recvpacket);
 
 /*
  * vmbus_recvpacket_raw - Retrieve the raw packet on the specified channel
  */
 int vmbus_recvpacket_raw(struct vmbus_channel *channel, void *buffer,
 			      u32 bufferlen, u32 *buffer_actual_len,
 			      u64 *requestid)
 {
 	return __vmbus_recvpacket(channel, buffer, bufferlen,
 				  buffer_actual_len, requestid, true);
 }
 EXPORT_SYMBOL_GPL(vmbus_recvpacket_raw);
diff --git a/drivers/hv/channel_mgmt.c b/drivers/hv/channel_mgmt.c
index 26b419203f16..f33465d78a02 100644
--- a/drivers/hv/channel_mgmt.c
+++ b/drivers/hv/channel_mgmt.c
@@ -1,1223 +1,1278 @@
 /*
  * Copyright (c) 2009, Microsoft Corporation.
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms and conditions of the GNU General Public License,
  * version 2, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope it will be useful, but WITHOUT
  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
  * more details.
  *
  * You should have received a copy of the GNU General Public License along with
  * this program; if not, write to the Free Software Foundation, Inc., 59 Temple
  * Place - Suite 330, Boston, MA 02111-1307 USA.
  *
  * Authors:
  *   Haiyang Zhang <haiyangz@microsoft.com>
  *   Hank Janssen  <hjanssen@microsoft.com>
  */
 #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
 
 #include <linux/kernel.h>
 #include <linux/interrupt.h>
 #include <linux/sched.h>
 #include <linux/wait.h>
 #include <linux/mm.h>
 #include <linux/slab.h>
 #include <linux/list.h>
 #include <linux/module.h>
 #include <linux/completion.h>
 #include <linux/delay.h>
 #include <linux/hyperv.h>
+#include <asm/mshyperv.h>
 
 #include "hyperv_vmbus.h"
 
 static void init_vp_index(struct vmbus_channel *channel, u16 dev_type);
 
 static const struct vmbus_device vmbus_devs[] = {
 	/* IDE */
 	{ .dev_type = HV_IDE,
 	  HV_IDE_GUID,
 	  .perf_device = true,
 	},
 
 	/* SCSI */
 	{ .dev_type = HV_SCSI,
 	  HV_SCSI_GUID,
 	  .perf_device = true,
 	},
 
 	/* Fibre Channel */
 	{ .dev_type = HV_FC,
 	  HV_SYNTHFC_GUID,
 	  .perf_device = true,
 	},
 
 	/* Synthetic NIC */
 	{ .dev_type = HV_NIC,
 	  HV_NIC_GUID,
 	  .perf_device = true,
 	},
 
 	/* Network Direct */
 	{ .dev_type = HV_ND,
 	  HV_ND_GUID,
 	  .perf_device = true,
 	},
 
 	/* PCIE */
 	{ .dev_type = HV_PCIE,
 	  HV_PCIE_GUID,
 	  .perf_device = true,
 	},
 
 	/* Synthetic Frame Buffer */
 	{ .dev_type = HV_FB,
 	  HV_SYNTHVID_GUID,
 	  .perf_device = false,
 	},
 
 	/* Synthetic Keyboard */
 	{ .dev_type = HV_KBD,
 	  HV_KBD_GUID,
 	  .perf_device = false,
 	},
 
 	/* Synthetic MOUSE */
 	{ .dev_type = HV_MOUSE,
 	  HV_MOUSE_GUID,
 	  .perf_device = false,
 	},
 
 	/* KVP */
 	{ .dev_type = HV_KVP,
 	  HV_KVP_GUID,
 	  .perf_device = false,
 	},
 
 	/* Time Synch */
 	{ .dev_type = HV_TS,
 	  HV_TS_GUID,
 	  .perf_device = false,
 	},
 
 	/* Heartbeat */
 	{ .dev_type = HV_HB,
 	  HV_HEART_BEAT_GUID,
 	  .perf_device = false,
 	},
 
 	/* Shutdown */
 	{ .dev_type = HV_SHUTDOWN,
 	  HV_SHUTDOWN_GUID,
 	  .perf_device = false,
 	},
 
 	/* File copy */
 	{ .dev_type = HV_FCOPY,
 	  HV_FCOPY_GUID,
 	  .perf_device = false,
 	},
 
 	/* Backup */
 	{ .dev_type = HV_BACKUP,
 	  HV_VSS_GUID,
 	  .perf_device = false,
 	},
 
 	/* Dynamic Memory */
 	{ .dev_type = HV_DM,
 	  HV_DM_GUID,
 	  .perf_device = false,
 	},
 
 	/* Unknown GUID */
 	{ .dev_type = HV_UNKNOWN,
 	  .perf_device = false,
 	},
 };
 
 static const struct {
 	uuid_le guid;
 } vmbus_unsupported_devs[] = {
 	{ HV_AVMA1_GUID },
 	{ HV_AVMA2_GUID },
 	{ HV_RDV_GUID	},
 };
 
+/*
+ * The rescinded channel may be blocked waiting for a response from the host;
+ * take care of that.
+ */
+static void vmbus_rescind_cleanup(struct vmbus_channel *channel)
+{
+	struct vmbus_channel_msginfo *msginfo;
+	unsigned long flags;
+
+
+	spin_lock_irqsave(&vmbus_connection.channelmsg_lock, flags);
+
+	list_for_each_entry(msginfo, &vmbus_connection.chn_msg_list,
+				msglistentry) {
+
+		if (msginfo->waiting_channel == channel) {
+			complete(&msginfo->waitevent);
+			break;
+		}
+	}
+	spin_unlock_irqrestore(&vmbus_connection.channelmsg_lock, flags);
+}
+
 static bool is_unsupported_vmbus_devs(const uuid_le *guid)
 {
 	int i;
 
 	for (i = 0; i < ARRAY_SIZE(vmbus_unsupported_devs); i++)
 		if (!uuid_le_cmp(*guid, vmbus_unsupported_devs[i].guid))
 			return true;
 	return false;
 }
 
 static u16 hv_get_dev_type(const struct vmbus_channel *channel)
 {
 	const uuid_le *guid = &channel->offermsg.offer.if_type;
 	u16 i;
 
 	if (is_hvsock_channel(channel) || is_unsupported_vmbus_devs(guid))
 		return HV_UNKNOWN;
 
 	for (i = HV_IDE; i < HV_UNKNOWN; i++) {
 		if (!uuid_le_cmp(*guid, vmbus_devs[i].guid))
 			return i;
 	}
 	pr_info("Unknown GUID: %pUl\n", guid);
 	return i;
 }
 
 /**
  * vmbus_prep_negotiate_resp() - Create default response for Hyper-V Negotiate message
  * @icmsghdrp: Pointer to msg header structure
  * @icmsg_negotiate: Pointer to negotiate message structure
  * @buf: Raw buffer channel data
  *
  * @icmsghdrp is of type &struct icmsg_hdr.
- * @negop is of type &struct icmsg_negotiate.
  * Set up and fill in default negotiate response message.
  *
- * The fw_version specifies the  framework version that
- * we can support and srv_version specifies the service
- * version we can support.
+ * The fw_version and fw_vercnt specifies the framework version that
+ * we can support.
+ *
+ * The srv_version and srv_vercnt specifies the service
+ * versions we can support.
+ *
+ * Versions are given in decreasing order.
+ *
+ * nego_fw_version and nego_srv_version store the selected protocol versions.
  *
  * Mainly used by Hyper-V drivers.
  */
 bool vmbus_prep_negotiate_resp(struct icmsg_hdr *icmsghdrp,
-				struct icmsg_negotiate *negop, u8 *buf,
-				int fw_version, int srv_version)
+				u8 *buf, const int *fw_version, int fw_vercnt,
+				const int *srv_version, int srv_vercnt,
+				int *nego_fw_version, int *nego_srv_version)
 {
 	int icframe_major, icframe_minor;
 	int icmsg_major, icmsg_minor;
 	int fw_major, fw_minor;
 	int srv_major, srv_minor;
-	int i;
+	int i, j;
 	bool found_match = false;
+	struct icmsg_negotiate *negop;
 
 	icmsghdrp->icmsgsize = 0x10;
-	fw_major = (fw_version >> 16);
-	fw_minor = (fw_version & 0xFFFF);
-
-	srv_major = (srv_version >> 16);
-	srv_minor = (srv_version & 0xFFFF);
-
 	negop = (struct icmsg_negotiate *)&buf[
 		sizeof(struct vmbuspipe_hdr) +
 		sizeof(struct icmsg_hdr)];
 
 	icframe_major = negop->icframe_vercnt;
 	icframe_minor = 0;
 
 	icmsg_major = negop->icmsg_vercnt;
 	icmsg_minor = 0;
 
 	/*
 	 * Select the framework version number we will
 	 * support.
 	 */
 
-	for (i = 0; i < negop->icframe_vercnt; i++) {
-		if ((negop->icversion_data[i].major == fw_major) &&
-		   (negop->icversion_data[i].minor == fw_minor)) {
-			icframe_major = negop->icversion_data[i].major;
-			icframe_minor = negop->icversion_data[i].minor;
-			found_match = true;
+	for (i = 0; i < fw_vercnt; i++) {
+		fw_major = (fw_version[i] >> 16);
+		fw_minor = (fw_version[i] & 0xFFFF);
+
+		for (j = 0; j < negop->icframe_vercnt; j++) {
+			if ((negop->icversion_data[j].major == fw_major) &&
+			    (negop->icversion_data[j].minor == fw_minor)) {
+				icframe_major = negop->icversion_data[j].major;
+				icframe_minor = negop->icversion_data[j].minor;
+				found_match = true;
+				break;
+			}
 		}
+
+		if (found_match)
+			break;
 	}
 
 	if (!found_match)
 		goto fw_error;
 
 	found_match = false;
 
-	for (i = negop->icframe_vercnt;
-		 (i < negop->icframe_vercnt + negop->icmsg_vercnt); i++) {
-		if ((negop->icversion_data[i].major == srv_major) &&
-		   (negop->icversion_data[i].minor == srv_minor)) {
-			icmsg_major = negop->icversion_data[i].major;
-			icmsg_minor = negop->icversion_data[i].minor;
-			found_match = true;
+	for (i = 0; i < srv_vercnt; i++) {
+		srv_major = (srv_version[i] >> 16);
+		srv_minor = (srv_version[i] & 0xFFFF);
+
+		for (j = negop->icframe_vercnt;
+			(j < negop->icframe_vercnt + negop->icmsg_vercnt);
+			j++) {
+
+			if ((negop->icversion_data[j].major == srv_major) &&
+				(negop->icversion_data[j].minor == srv_minor)) {
+
+				icmsg_major = negop->icversion_data[j].major;
+				icmsg_minor = negop->icversion_data[j].minor;
+				found_match = true;
+				break;
+			}
 		}
+
+		if (found_match)
+			break;
 	}
 
 	/*
 	 * Respond with the framework and service
 	 * version numbers we can support.
 	 */
 
 fw_error:
 	if (!found_match) {
 		negop->icframe_vercnt = 0;
 		negop->icmsg_vercnt = 0;
 	} else {
 		negop->icframe_vercnt = 1;
 		negop->icmsg_vercnt = 1;
 	}
 
+	if (nego_fw_version)
+		*nego_fw_version = (icframe_major << 16) | icframe_minor;
+
+	if (nego_srv_version)
+		*nego_srv_version = (icmsg_major << 16) | icmsg_minor;
+
 	negop->icversion_data[0].major = icframe_major;
 	negop->icversion_data[0].minor = icframe_minor;
 	negop->icversion_data[1].major = icmsg_major;
 	negop->icversion_data[1].minor = icmsg_minor;
 	return found_match;
 }
 
 EXPORT_SYMBOL_GPL(vmbus_prep_negotiate_resp);
 
 /*
  * alloc_channel - Allocate and initialize a vmbus channel object
  */
 static struct vmbus_channel *alloc_channel(void)
 {
 	struct vmbus_channel *channel;
 
 	channel = kzalloc(sizeof(*channel), GFP_ATOMIC);
 	if (!channel)
 		return NULL;
 
-	channel->acquire_ring_lock = true;
 	spin_lock_init(&channel->inbound_lock);
 	spin_lock_init(&channel->lock);
 
 	INIT_LIST_HEAD(&channel->sc_list);
 	INIT_LIST_HEAD(&channel->percpu_list);
 
+	tasklet_init(&channel->callback_event,
+		     vmbus_on_event, (unsigned long)channel);
+
 	return channel;
 }
 
 /*
  * free_channel - Release the resources used by the vmbus channel object
  */
 static void free_channel(struct vmbus_channel *channel)
 {
+	tasklet_kill(&channel->callback_event);
 	kfree(channel);
 }
 
 static void percpu_channel_enq(void *arg)
 {
 	struct vmbus_channel *channel = arg;
-	int cpu = smp_processor_id();
+	struct hv_per_cpu_context *hv_cpu
+		= this_cpu_ptr(hv_context.cpu_context);
 
-	list_add_tail(&channel->percpu_list, &hv_context.percpu_list[cpu]);
+	list_add_tail(&channel->percpu_list, &hv_cpu->chan_list);
 }
 
 static void percpu_channel_deq(void *arg)
 {
 	struct vmbus_channel *channel = arg;
 
 	list_del(&channel->percpu_list);
 }
 
 
 static void vmbus_release_relid(u32 relid)
 {
 	struct vmbus_channel_relid_released msg;
 
 	memset(&msg, 0, sizeof(struct vmbus_channel_relid_released));
 	msg.child_relid = relid;
 	msg.header.msgtype = CHANNELMSG_RELID_RELEASED;
-	vmbus_post_msg(&msg, sizeof(struct vmbus_channel_relid_released));
+	vmbus_post_msg(&msg, sizeof(struct vmbus_channel_relid_released),
+		       true);
 }
 
 void hv_event_tasklet_disable(struct vmbus_channel *channel)
 {
-	struct tasklet_struct *tasklet;
-	tasklet = hv_context.event_dpc[channel->target_cpu];
-	tasklet_disable(tasklet);
+	tasklet_disable(&channel->callback_event);
 }
 
 void hv_event_tasklet_enable(struct vmbus_channel *channel)
 {
-	struct tasklet_struct *tasklet;
-	tasklet = hv_context.event_dpc[channel->target_cpu];
-	tasklet_enable(tasklet);
+	tasklet_enable(&channel->callback_event);
 
 	/* In case there is any pending event */
-	tasklet_schedule(tasklet);
+	tasklet_schedule(&channel->callback_event);
 }
 
 void hv_process_channel_removal(struct vmbus_channel *channel, u32 relid)
 {
 	unsigned long flags;
 	struct vmbus_channel *primary_channel;
 
 	BUG_ON(!channel->rescind);
 	BUG_ON(!mutex_is_locked(&vmbus_connection.channel_mutex));
 
 	hv_event_tasklet_disable(channel);
 	if (channel->target_cpu != get_cpu()) {
 		put_cpu();
 		smp_call_function_single(channel->target_cpu,
 					 percpu_channel_deq, channel, true);
 	} else {
 		percpu_channel_deq(channel);
 		put_cpu();
 	}
 	hv_event_tasklet_enable(channel);
 
 	if (channel->primary_channel == NULL) {
 		list_del(&channel->listentry);
 
 		primary_channel = channel;
 	} else {
 		primary_channel = channel->primary_channel;
 		spin_lock_irqsave(&primary_channel->lock, flags);
 		list_del(&channel->sc_list);
 		primary_channel->num_sc--;
 		spin_unlock_irqrestore(&primary_channel->lock, flags);
 	}
 
 	/*
 	 * We need to free the bit for init_vp_index() to work in the case
 	 * of sub-channel, when we reload drivers like hv_netvsc.
 	 */
 	if (channel->affinity_policy == HV_LOCALIZED)
 		cpumask_clear_cpu(channel->target_cpu,
 				  &primary_channel->alloced_cpus_in_node);
 
 	vmbus_release_relid(relid);
 
 	free_channel(channel);
 }
 
 void vmbus_free_channels(void)
 {
 	struct vmbus_channel *channel, *tmp;
 
 	mutex_lock(&vmbus_connection.channel_mutex);
 	list_for_each_entry_safe(channel, tmp, &vmbus_connection.chn_list,
 		listentry) {
 		/* hv_process_channel_removal() needs this */
 		channel->rescind = true;
 
 		vmbus_device_unregister(channel->device_obj);
 	}
 	mutex_unlock(&vmbus_connection.channel_mutex);
 }
 
 /*
  * vmbus_process_offer - Process the offer by creating a channel/device
  * associated with this offer
  */
 static void vmbus_process_offer(struct vmbus_channel *newchannel)
 {
 	struct vmbus_channel *channel;
 	bool fnew = true;
 	unsigned long flags;
 	u16 dev_type;
 	int ret;
 
 	/* Make sure this is a new offer */
 	mutex_lock(&vmbus_connection.channel_mutex);
 
 	list_for_each_entry(channel, &vmbus_connection.chn_list, listentry) {
 		if (!uuid_le_cmp(channel->offermsg.offer.if_type,
 			newchannel->offermsg.offer.if_type) &&
 			!uuid_le_cmp(channel->offermsg.offer.if_instance,
 				newchannel->offermsg.offer.if_instance)) {
 			fnew = false;
 			break;
 		}
 	}
 
 	if (fnew)
 		list_add_tail(&newchannel->listentry,
 			      &vmbus_connection.chn_list);
 
 	mutex_unlock(&vmbus_connection.channel_mutex);
 
 	if (!fnew) {
 		/*
 		 * Check to see if this is a sub-channel.
 		 */
 		if (newchannel->offermsg.offer.sub_channel_index != 0) {
 			/*
 			 * Process the sub-channel.
 			 */
 			newchannel->primary_channel = channel;
 			spin_lock_irqsave(&channel->lock, flags);
 			list_add_tail(&newchannel->sc_list, &channel->sc_list);
 			channel->num_sc++;
 			spin_unlock_irqrestore(&channel->lock, flags);
 		} else
 			goto err_free_chan;
 	}
 
 	dev_type = hv_get_dev_type(newchannel);
 
 	init_vp_index(newchannel, dev_type);
 
 	hv_event_tasklet_disable(newchannel);
 	if (newchannel->target_cpu != get_cpu()) {
 		put_cpu();
 		smp_call_function_single(newchannel->target_cpu,
 					 percpu_channel_enq,
 					 newchannel, true);
 	} else {
 		percpu_channel_enq(newchannel);
 		put_cpu();
 	}
 	hv_event_tasklet_enable(newchannel);
 
 	/*
 	 * This state is used to indicate a successful open
 	 * so that when we do close the channel normally, we
 	 * can cleanup properly
 	 */
 	newchannel->state = CHANNEL_OPEN_STATE;
 
 	if (!fnew) {
 		if (channel->sc_creation_callback != NULL)
 			channel->sc_creation_callback(newchannel);
 		return;
 	}
 
 	/*
 	 * Start the process of binding this offer to the driver
 	 * We need to set the DeviceObject field before calling
 	 * vmbus_child_dev_add()
 	 */
 	newchannel->device_obj = vmbus_device_create(
 		&newchannel->offermsg.offer.if_type,
 		&newchannel->offermsg.offer.if_instance,
 		newchannel);
 	if (!newchannel->device_obj)
 		goto err_deq_chan;
 
 	newchannel->device_obj->device_id = dev_type;
 	/*
 	 * Add the new device to the bus. This will kick off device-driver
 	 * binding which eventually invokes the device driver's AddDevice()
 	 * method.
 	 */
 	mutex_lock(&vmbus_connection.channel_mutex);
 	ret = vmbus_device_register(newchannel->device_obj);
 	mutex_unlock(&vmbus_connection.channel_mutex);
 
 	if (ret != 0) {
 		pr_err("unable to add child device object (relid %d)\n",
 			newchannel->offermsg.child_relid);
 		kfree(newchannel->device_obj);
 		goto err_deq_chan;
 	}
 	return;
 
 err_deq_chan:
 	mutex_lock(&vmbus_connection.channel_mutex);
 	list_del(&newchannel->listentry);
 	mutex_unlock(&vmbus_connection.channel_mutex);
 
 	hv_event_tasklet_disable(newchannel);
 	if (newchannel->target_cpu != get_cpu()) {
 		put_cpu();
 		smp_call_function_single(newchannel->target_cpu,
 					 percpu_channel_deq, newchannel, true);
 	} else {
 		percpu_channel_deq(newchannel);
 		put_cpu();
 	}
 	hv_event_tasklet_enable(newchannel);
 
 	vmbus_release_relid(newchannel->offermsg.child_relid);
 
 err_free_chan:
 	free_channel(newchannel);
 }
 
 /*
  * We use this state to statically distribute the channel interrupt load.
  */
 static int next_numa_node_id;
 
 /*
  * Starting with Win8, we can statically distribute the incoming
  * channel interrupt load by binding a channel to VCPU.
  * We do this in a hierarchical fashion:
  * First distribute the primary channels across available NUMA nodes
  * and then distribute the subchannels amongst the CPUs in the NUMA
  * node assigned to the primary channel.
  *
  * For pre-win8 hosts or non-performance critical channels we assign the
  * first CPU in the first NUMA node.
  */
 static void init_vp_index(struct vmbus_channel *channel, u16 dev_type)
 {
 	u32 cur_cpu;
 	bool perf_chn = vmbus_devs[dev_type].perf_device;
 	struct vmbus_channel *primary = channel->primary_channel;
 	int next_node;
 	struct cpumask available_mask;
 	struct cpumask *alloced_mask;
 
 	if ((vmbus_proto_version == VERSION_WS2008) ||
 	    (vmbus_proto_version == VERSION_WIN7) || (!perf_chn)) {
 		/*
 		 * Prior to win8, all channel interrupts are
 		 * delivered on cpu 0.
 		 * Also if the channel is not a performance critical
 		 * channel, bind it to cpu 0.
 		 */
 		channel->numa_node = 0;
 		channel->target_cpu = 0;
 		channel->target_vp = hv_context.vp_index[0];
 		return;
 	}
 
 	/*
 	 * Based on the channel affinity policy, we will assign the NUMA
 	 * nodes.
 	 */
 
 	if ((channel->affinity_policy == HV_BALANCED) || (!primary)) {
 		while (true) {
 			next_node = next_numa_node_id++;
 			if (next_node == nr_node_ids) {
 				next_node = next_numa_node_id = 0;
 				continue;
 			}
 			if (cpumask_empty(cpumask_of_node(next_node)))
 				continue;
 			break;
 		}
 		channel->numa_node = next_node;
 		primary = channel;
 	}
 	alloced_mask = &hv_context.hv_numa_map[primary->numa_node];
 
 	if (cpumask_weight(alloced_mask) ==
 	    cpumask_weight(cpumask_of_node(primary->numa_node))) {
 		/*
 		 * We have cycled through all the CPUs in the node;
 		 * reset the alloced map.
 		 */
 		cpumask_clear(alloced_mask);
 	}
 
 	cpumask_xor(&available_mask, alloced_mask,
 		    cpumask_of_node(primary->numa_node));
 
 	cur_cpu = -1;
 
 	if (primary->affinity_policy == HV_LOCALIZED) {
 		/*
 		 * Normally Hyper-V host doesn't create more subchannels
 		 * than there are VCPUs on the node but it is possible when not
 		 * all present VCPUs on the node are initialized by guest.
 		 * Clear the alloced_cpus_in_node to start over.
 		 */
 		if (cpumask_equal(&primary->alloced_cpus_in_node,
 				  cpumask_of_node(primary->numa_node)))
 			cpumask_clear(&primary->alloced_cpus_in_node);
 	}
 
 	while (true) {
 		cur_cpu = cpumask_next(cur_cpu, &available_mask);
 		if (cur_cpu >= nr_cpu_ids) {
 			cur_cpu = -1;
 			cpumask_copy(&available_mask,
 				     cpumask_of_node(primary->numa_node));
 			continue;
 		}
 
 		if (primary->affinity_policy == HV_LOCALIZED) {
 			/*
 			 * NOTE: in the case of sub-channel, we clear the
 			 * sub-channel related bit(s) in
 			 * primary->alloced_cpus_in_node in
 			 * hv_process_channel_removal(), so when we
 			 * reload drivers like hv_netvsc in SMP guest, here
 			 * we're able to re-allocate
 			 * bit from primary->alloced_cpus_in_node.
 			 */
 			if (!cpumask_test_cpu(cur_cpu,
 					      &primary->alloced_cpus_in_node)) {
 				cpumask_set_cpu(cur_cpu,
 						&primary->alloced_cpus_in_node);
 				cpumask_set_cpu(cur_cpu, alloced_mask);
 				break;
 			}
 		} else {
 			cpumask_set_cpu(cur_cpu, alloced_mask);
 			break;
 		}
 	}
 
 	channel->target_cpu = cur_cpu;
 	channel->target_vp = hv_context.vp_index[cur_cpu];
 }
 
 static void vmbus_wait_for_unload(void)
 {
 	int cpu;
 	void *page_addr;
 	struct hv_message *msg;
 	struct vmbus_channel_message_header *hdr;
 	u32 message_type;
 
 	/*
 	 * CHANNELMSG_UNLOAD_RESPONSE is always delivered to the CPU which was
 	 * used for initial contact or to CPU0 depending on host version. When
 	 * we're crashing on a different CPU let's hope that IRQ handler on
 	 * the cpu which receives CHANNELMSG_UNLOAD_RESPONSE is still
 	 * functional and vmbus_unload_response() will complete
 	 * vmbus_connection.unload_event. If not, the last thing we can do is
 	 * read message pages for all CPUs directly.
 	 */
 	while (1) {
 		if (completion_done(&vmbus_connection.unload_event))
 			break;
 
 		for_each_online_cpu(cpu) {
-			page_addr = hv_context.synic_message_page[cpu];
-			msg = (struct hv_message *)page_addr +
-				VMBUS_MESSAGE_SINT;
+			struct hv_per_cpu_context *hv_cpu
+				= per_cpu_ptr(hv_context.cpu_context, cpu);
+
+			page_addr = hv_cpu->synic_message_page;
+			msg = (struct hv_message *)page_addr
+				+ VMBUS_MESSAGE_SINT;
 
 			message_type = READ_ONCE(msg->header.message_type);
 			if (message_type == HVMSG_NONE)
 				continue;
 
 			hdr = (struct vmbus_channel_message_header *)
 				msg->u.payload;
 
 			if (hdr->msgtype == CHANNELMSG_UNLOAD_RESPONSE)
 				complete(&vmbus_connection.unload_event);
 
 			vmbus_signal_eom(msg, message_type);
 		}
 
 		mdelay(10);
 	}
 
 	/*
 	 * We're crashing and already got the UNLOAD_RESPONSE, cleanup all
 	 * maybe-pending messages on all CPUs to be able to receive new
 	 * messages after we reconnect.
 	 */
 	for_each_online_cpu(cpu) {
-		page_addr = hv_context.synic_message_page[cpu];
+		struct hv_per_cpu_context *hv_cpu
+			= per_cpu_ptr(hv_context.cpu_context, cpu);
+
+		page_addr = hv_cpu->synic_message_page;
 		msg = (struct hv_message *)page_addr + VMBUS_MESSAGE_SINT;
 		msg->header.message_type = HVMSG_NONE;
 	}
 }
 
 /*
  * vmbus_unload_response - Handler for the unload response.
  */
 static void vmbus_unload_response(struct vmbus_channel_message_header *hdr)
 {
 	/*
 	 * This is a global event; just wakeup the waiting thread.
 	 * Once we successfully unload, we can cleanup the monitor state.
 	 */
 	complete(&vmbus_connection.unload_event);
 }
 
 void vmbus_initiate_unload(bool crash)
 {
 	struct vmbus_channel_message_header hdr;
 
 	/* Pre-Win2012R2 hosts don't support reconnect */
 	if (vmbus_proto_version < VERSION_WIN8_1)
 		return;
 
 	init_completion(&vmbus_connection.unload_event);
 	memset(&hdr, 0, sizeof(struct vmbus_channel_message_header));
 	hdr.msgtype = CHANNELMSG_UNLOAD;
-	vmbus_post_msg(&hdr, sizeof(struct vmbus_channel_message_header));
+	vmbus_post_msg(&hdr, sizeof(struct vmbus_channel_message_header),
+		       !crash);
 
 	/*
 	 * vmbus_initiate_unload() is also called on crash and the crash can be
 	 * happening in an interrupt context, where scheduling is impossible.
 	 */
 	if (!crash)
 		wait_for_completion(&vmbus_connection.unload_event);
 	else
 		vmbus_wait_for_unload();
 }
 
 /*
  * vmbus_onoffer - Handler for channel offers from vmbus in parent partition.
  *
  */
 static void vmbus_onoffer(struct vmbus_channel_message_header *hdr)
 {
 	struct vmbus_channel_offer_channel *offer;
 	struct vmbus_channel *newchannel;
 
 	offer = (struct vmbus_channel_offer_channel *)hdr;
 
 	/* Allocate the channel object and save this offer. */
 	newchannel = alloc_channel();
 	if (!newchannel) {
 		pr_err("Unable to allocate channel object\n");
 		return;
 	}
 
-	/*
-	 * By default we setup state to enable batched
-	 * reading. A specific service can choose to
-	 * disable this prior to opening the channel.
-	 */
-	newchannel->batched_reading = true;
-
 	/*
 	 * Setup state for signalling the host.
 	 */
 	newchannel->sig_event = (struct hv_input_signal_event *)
 				(ALIGN((unsigned long)
 				&newchannel->sig_buf,
 				HV_HYPERCALL_PARAM_ALIGN));
 
 	newchannel->sig_event->connectionid.asu32 = 0;
 	newchannel->sig_event->connectionid.u.id = VMBUS_EVENT_CONNECTION_ID;
 	newchannel->sig_event->flag_number = 0;
 	newchannel->sig_event->rsvdz = 0;
 
 	if (vmbus_proto_version != VERSION_WS2008) {
 		newchannel->is_dedicated_interrupt =
 				(offer->is_dedicated_interrupt != 0);
 		newchannel->sig_event->connectionid.u.id =
 				offer->connection_id;
 	}
 
 	memcpy(&newchannel->offermsg, offer,
 	       sizeof(struct vmbus_channel_offer_channel));
 	newchannel->monitor_grp = (u8)offer->monitorid / 32;
 	newchannel->monitor_bit = (u8)offer->monitorid % 32;
 
 	vmbus_process_offer(newchannel);
 }
 
 /*
  * vmbus_onoffer_rescind - Rescind offer handler.
  *
  * We queue a work item to process this offer synchronously
  */
 static void vmbus_onoffer_rescind(struct vmbus_channel_message_header *hdr)
 {
 	struct vmbus_channel_rescind_offer *rescind;
 	struct vmbus_channel *channel;
 	unsigned long flags;
 	struct device *dev;
 
 	rescind = (struct vmbus_channel_rescind_offer *)hdr;
 
 	mutex_lock(&vmbus_connection.channel_mutex);
 	channel = relid2channel(rescind->child_relid);
 
 	if (channel == NULL) {
 		/*
 		 * This is very impossible, because in
 		 * vmbus_process_offer(), we have already invoked
 		 * vmbus_release_relid() on error.
 		 */
 		goto out;
 	}
 
 	spin_lock_irqsave(&channel->lock, flags);
 	channel->rescind = true;
 	spin_unlock_irqrestore(&channel->lock, flags);
 
+	vmbus_rescind_cleanup(channel);
+
 	if (channel->device_obj) {
 		if (channel->chn_rescind_callback) {
 			channel->chn_rescind_callback(channel);
 			goto out;
 		}
 		/*
 		 * We will have to unregister this device from the
 		 * driver core.
 		 */
 		dev = get_device(&channel->device_obj->device);
 		if (dev) {
 			vmbus_device_unregister(channel->device_obj);
 			put_device(dev);
 		}
 	} else {
 		hv_process_channel_removal(channel,
 			channel->offermsg.child_relid);
 	}
 
 out:
 	mutex_unlock(&vmbus_connection.channel_mutex);
 }
 
 void vmbus_hvsock_device_unregister(struct vmbus_channel *channel)
 {
 	mutex_lock(&vmbus_connection.channel_mutex);
 
 	BUG_ON(!is_hvsock_channel(channel));
 
 	channel->rescind = true;
 	vmbus_device_unregister(channel->device_obj);
 
 	mutex_unlock(&vmbus_connection.channel_mutex);
 }
 EXPORT_SYMBOL_GPL(vmbus_hvsock_device_unregister);
 
 
 /*
  * vmbus_onoffers_delivered -
  * This is invoked when all offers have been delivered.
  *
  * Nothing to do here.
  */
 static void vmbus_onoffers_delivered(
 			struct vmbus_channel_message_header *hdr)
 {
 }
 
 /*
  * vmbus_onopen_result - Open result handler.
  *
  * This is invoked when we received a response to our channel open request.
  * Find the matching request, copy the response and signal the requesting
  * thread.
  */
 static void vmbus_onopen_result(struct vmbus_channel_message_header *hdr)
 {
 	struct vmbus_channel_open_result *result;
 	struct vmbus_channel_msginfo *msginfo;
 	struct vmbus_channel_message_header *requestheader;
 	struct vmbus_channel_open_channel *openmsg;
 	unsigned long flags;
 
 	result = (struct vmbus_channel_open_result *)hdr;
 
 	/*
 	 * Find the open msg, copy the result and signal/unblock the wait event
 	 */
 	spin_lock_irqsave(&vmbus_connection.channelmsg_lock, flags);
 
 	list_for_each_entry(msginfo, &vmbus_connection.chn_msg_list,
 				msglistentry) {
 		requestheader =
 			(struct vmbus_channel_message_header *)msginfo->msg;
 
 		if (requestheader->msgtype == CHANNELMSG_OPENCHANNEL) {
 			openmsg =
 			(struct vmbus_channel_open_channel *)msginfo->msg;
 			if (openmsg->child_relid == result->child_relid &&
 			    openmsg->openid == result->openid) {
 				memcpy(&msginfo->response.open_result,
 				       result,
 				       sizeof(
 					struct vmbus_channel_open_result));
 				complete(&msginfo->waitevent);
 				break;
 			}
 		}
 	}
 	spin_unlock_irqrestore(&vmbus_connection.channelmsg_lock, flags);
 }
 
 /*
  * vmbus_ongpadl_created - GPADL created handler.
  *
  * This is invoked when we received a response to our gpadl create request.
  * Find the matching request, copy the response and signal the requesting
  * thread.
  */
 static void vmbus_ongpadl_created(struct vmbus_channel_message_header *hdr)
 {
 	struct vmbus_channel_gpadl_created *gpadlcreated;
 	struct vmbus_channel_msginfo *msginfo;
 	struct vmbus_channel_message_header *requestheader;
 	struct vmbus_channel_gpadl_header *gpadlheader;
 	unsigned long flags;
 
 	gpadlcreated = (struct vmbus_channel_gpadl_created *)hdr;
 
 	/*
 	 * Find the establish msg, copy the result and signal/unblock the wait
 	 * event
 	 */
 	spin_lock_irqsave(&vmbus_connection.channelmsg_lock, flags);
 
 	list_for_each_entry(msginfo, &vmbus_connection.chn_msg_list,
 				msglistentry) {
 		requestheader =
 			(struct vmbus_channel_message_header *)msginfo->msg;
 
 		if (requestheader->msgtype == CHANNELMSG_GPADL_HEADER) {
 			gpadlheader =
 			(struct vmbus_channel_gpadl_header *)requestheader;
 
 			if ((gpadlcreated->child_relid ==
 			     gpadlheader->child_relid) &&
 			    (gpadlcreated->gpadl == gpadlheader->gpadl)) {
 				memcpy(&msginfo->response.gpadl_created,
 				       gpadlcreated,
 				       sizeof(
 					struct vmbus_channel_gpadl_created));
 				complete(&msginfo->waitevent);
 				break;
 			}
 		}
 	}
 	spin_unlock_irqrestore(&vmbus_connection.channelmsg_lock, flags);
 }
 
 /*
  * vmbus_ongpadl_torndown - GPADL torndown handler.
  *
  * This is invoked when we received a response to our gpadl teardown request.
  * Find the matching request, copy the response and signal the requesting
  * thread.
  */
 static void vmbus_ongpadl_torndown(
 			struct vmbus_channel_message_header *hdr)
 {
 	struct vmbus_channel_gpadl_torndown *gpadl_torndown;
 	struct vmbus_channel_msginfo *msginfo;
 	struct vmbus_channel_message_header *requestheader;
 	struct vmbus_channel_gpadl_teardown *gpadl_teardown;
 	unsigned long flags;
 
 	gpadl_torndown = (struct vmbus_channel_gpadl_torndown *)hdr;
 
 	/*
 	 * Find the open msg, copy the result and signal/unblock the wait event
 	 */
 	spin_lock_irqsave(&vmbus_connection.channelmsg_lock, flags);
 
 	list_for_each_entry(msginfo, &vmbus_connection.chn_msg_list,
 				msglistentry) {
 		requestheader =
 			(struct vmbus_channel_message_header *)msginfo->msg;
 
 		if (requestheader->msgtype == CHANNELMSG_GPADL_TEARDOWN) {
 			gpadl_teardown =
 			(struct vmbus_channel_gpadl_teardown *)requestheader;
 
 			if (gpadl_torndown->gpadl == gpadl_teardown->gpadl) {
 				memcpy(&msginfo->response.gpadl_torndown,
 				       gpadl_torndown,
 				       sizeof(
 					struct vmbus_channel_gpadl_torndown));
 				complete(&msginfo->waitevent);
 				break;
 			}
 		}
 	}
 	spin_unlock_irqrestore(&vmbus_connection.channelmsg_lock, flags);
 }
 
 /*
  * vmbus_onversion_response - Version response handler
  *
  * This is invoked when we received a response to our initiate contact request.
  * Find the matching request, copy the response and signal the requesting
  * thread.
  */
 static void vmbus_onversion_response(
 		struct vmbus_channel_message_header *hdr)
 {
 	struct vmbus_channel_msginfo *msginfo;
 	struct vmbus_channel_message_header *requestheader;
 	struct vmbus_channel_version_response *version_response;
 	unsigned long flags;
 
 	version_response = (struct vmbus_channel_version_response *)hdr;
 	spin_lock_irqsave(&vmbus_connection.channelmsg_lock, flags);
 
 	list_for_each_entry(msginfo, &vmbus_connection.chn_msg_list,
 				msglistentry) {
 		requestheader =
 			(struct vmbus_channel_message_header *)msginfo->msg;
 
 		if (requestheader->msgtype ==
 		    CHANNELMSG_INITIATE_CONTACT) {
 			memcpy(&msginfo->response.version_response,
 			      version_response,
 			      sizeof(struct vmbus_channel_version_response));
 			complete(&msginfo->waitevent);
 		}
 	}
 	spin_unlock_irqrestore(&vmbus_connection.channelmsg_lock, flags);
 }
 
 /* Channel message dispatch table */
 struct vmbus_channel_message_table_entry
 	channel_message_table[CHANNELMSG_COUNT] = {
 	{CHANNELMSG_INVALID,			0, NULL},
 	{CHANNELMSG_OFFERCHANNEL,		0, vmbus_onoffer},
 	{CHANNELMSG_RESCIND_CHANNELOFFER,	0, vmbus_onoffer_rescind},
 	{CHANNELMSG_REQUESTOFFERS,		0, NULL},
 	{CHANNELMSG_ALLOFFERS_DELIVERED,	1, vmbus_onoffers_delivered},
 	{CHANNELMSG_OPENCHANNEL,		0, NULL},
 	{CHANNELMSG_OPENCHANNEL_RESULT,		1, vmbus_onopen_result},
 	{CHANNELMSG_CLOSECHANNEL,		0, NULL},
 	{CHANNELMSG_GPADL_HEADER,		0, NULL},
 	{CHANNELMSG_GPADL_BODY,			0, NULL},
 	{CHANNELMSG_GPADL_CREATED,		1, vmbus_ongpadl_created},
 	{CHANNELMSG_GPADL_TEARDOWN,		0, NULL},
 	{CHANNELMSG_GPADL_TORNDOWN,		1, vmbus_ongpadl_torndown},
 	{CHANNELMSG_RELID_RELEASED,		0, NULL},
 	{CHANNELMSG_INITIATE_CONTACT,		0, NULL},
 	{CHANNELMSG_VERSION_RESPONSE,		1, vmbus_onversion_response},
 	{CHANNELMSG_UNLOAD,			0, NULL},
 	{CHANNELMSG_UNLOAD_RESPONSE,		1, vmbus_unload_response},
 	{CHANNELMSG_18,				0, NULL},
 	{CHANNELMSG_19,				0, NULL},
 	{CHANNELMSG_20,				0, NULL},
 	{CHANNELMSG_TL_CONNECT_REQUEST,		0, NULL},
 };
 
 /*
  * vmbus_onmessage - Handler for channel protocol messages.
  *
  * This is invoked in the vmbus worker thread context.
  */
 void vmbus_onmessage(void *context)
 {
 	struct hv_message *msg = context;
 	struct vmbus_channel_message_header *hdr;
 	int size;
 
 	hdr = (struct vmbus_channel_message_header *)msg->u.payload;
 	size = msg->header.payload_size;
 
 	if (hdr->msgtype >= CHANNELMSG_COUNT) {
 		pr_err("Received invalid channel message type %d size %d\n",
 			   hdr->msgtype, size);
 		print_hex_dump_bytes("", DUMP_PREFIX_NONE,
 				     (unsigned char *)msg->u.payload, size);
 		return;
 	}
 
 	if (channel_message_table[hdr->msgtype].message_handler)
 		channel_message_table[hdr->msgtype].message_handler(hdr);
 	else
 		pr_err("Unhandled channel message type %d\n", hdr->msgtype);
 }
 
 /*
  * vmbus_request_offers - Send a request to get all our pending offers.
  */
 int vmbus_request_offers(void)
 {
 	struct vmbus_channel_message_header *msg;
 	struct vmbus_channel_msginfo *msginfo;
 	int ret;
 
 	msginfo = kmalloc(sizeof(*msginfo) +
 			  sizeof(struct vmbus_channel_message_header),
 			  GFP_KERNEL);
 	if (!msginfo)
 		return -ENOMEM;
 
 	msg = (struct vmbus_channel_message_header *)msginfo->msg;
 
 	msg->msgtype = CHANNELMSG_REQUESTOFFERS;
 
 
-	ret = vmbus_post_msg(msg,
-			       sizeof(struct vmbus_channel_message_header));
+	ret = vmbus_post_msg(msg, sizeof(struct vmbus_channel_message_header),
+			     true);
 	if (ret != 0) {
 		pr_err("Unable to request offers - %d\n", ret);
 
 		goto cleanup;
 	}
 
 cleanup:
 	kfree(msginfo);
 
 	return ret;
 }
 
 /*
  * Retrieve the (sub) channel on which to send an outgoing request.
  * When a primary channel has multiple sub-channels, we try to
  * distribute the load equally amongst all available channels.
  */
 struct vmbus_channel *vmbus_get_outgoing_channel(struct vmbus_channel *primary)
 {
 	struct list_head *cur, *tmp;
 	int cur_cpu;
 	struct vmbus_channel *cur_channel;
 	struct vmbus_channel *outgoing_channel = primary;
 	int next_channel;
 	int i = 1;
 
 	if (list_empty(&primary->sc_list))
 		return outgoing_channel;
 
 	next_channel = primary->next_oc++;
 
 	if (next_channel > (primary->num_sc)) {
 		primary->next_oc = 0;
 		return outgoing_channel;
 	}
 
 	cur_cpu = hv_context.vp_index[get_cpu()];
 	put_cpu();
 	list_for_each_safe(cur, tmp, &primary->sc_list) {
 		cur_channel = list_entry(cur, struct vmbus_channel, sc_list);
 		if (cur_channel->state != CHANNEL_OPENED_STATE)
 			continue;
 
 		if (cur_channel->target_vp == cur_cpu)
 			return cur_channel;
 
 		if (i == next_channel)
 			return cur_channel;
 
 		i++;
 	}
 
 	return outgoing_channel;
 }
 EXPORT_SYMBOL_GPL(vmbus_get_outgoing_channel);
 
 static void invoke_sc_cb(struct vmbus_channel *primary_channel)
 {
 	struct list_head *cur, *tmp;
 	struct vmbus_channel *cur_channel;
 
 	if (primary_channel->sc_creation_callback == NULL)
 		return;
 
 	list_for_each_safe(cur, tmp, &primary_channel->sc_list) {
 		cur_channel = list_entry(cur, struct vmbus_channel, sc_list);
 
 		primary_channel->sc_creation_callback(cur_channel);
 	}
 }
 
 void vmbus_set_sc_create_callback(struct vmbus_channel *primary_channel,
 				void (*sc_cr_cb)(struct vmbus_channel *new_sc))
 {
 	primary_channel->sc_creation_callback = sc_cr_cb;
 }
 EXPORT_SYMBOL_GPL(vmbus_set_sc_create_callback);
 
 bool vmbus_are_subchannels_present(struct vmbus_channel *primary)
 {
 	bool ret;
 
 	ret = !list_empty(&primary->sc_list);
 
 	if (ret) {
 		/*
 		 * Invoke the callback on sub-channel creation.
 		 * This will present a uniform interface to the
 		 * clients.
 		 */
 		invoke_sc_cb(primary);
 	}
 
 	return ret;
 }
 EXPORT_SYMBOL_GPL(vmbus_are_subchannels_present);
 
 void vmbus_set_chn_rescind_callback(struct vmbus_channel *channel,
 		void (*chn_rescind_cb)(struct vmbus_channel *))
 {
 	channel->chn_rescind_callback = chn_rescind_cb;
 }
 EXPORT_SYMBOL_GPL(vmbus_set_chn_rescind_callback);
diff --git a/drivers/hv/connection.c b/drivers/hv/connection.c
index 6ce8b874e833..a8366fec1458 100644
--- a/drivers/hv/connection.c
+++ b/drivers/hv/connection.c
@@ -1,499 +1,405 @@
 /*
  *
  * Copyright (c) 2009, Microsoft Corporation.
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms and conditions of the GNU General Public License,
  * version 2, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope it will be useful, but WITHOUT
  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
  * more details.
  *
  * You should have received a copy of the GNU General Public License along with
  * this program; if not, write to the Free Software Foundation, Inc., 59 Temple
  * Place - Suite 330, Boston, MA 02111-1307 USA.
  *
  * Authors:
  *   Haiyang Zhang <haiyangz@microsoft.com>
  *   Hank Janssen  <hjanssen@microsoft.com>
  *
  */
 #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
 
 #include <linux/kernel.h>
 #include <linux/sched.h>
 #include <linux/wait.h>
 #include <linux/delay.h>
 #include <linux/mm.h>
 #include <linux/slab.h>
 #include <linux/vmalloc.h>
 #include <linux/hyperv.h>
 #include <linux/export.h>
 #include <asm/hyperv.h>
 #include "hyperv_vmbus.h"
 
 
 struct vmbus_connection vmbus_connection = {
 	.conn_state		= DISCONNECTED,
 	.next_gpadl_handle	= ATOMIC_INIT(0xE1E10),
 };
 EXPORT_SYMBOL_GPL(vmbus_connection);
 
 /*
  * Negotiated protocol version with the host.
  */
 __u32 vmbus_proto_version;
 EXPORT_SYMBOL_GPL(vmbus_proto_version);
 
 static __u32 vmbus_get_next_version(__u32 current_version)
 {
 	switch (current_version) {
 	case (VERSION_WIN7):
 		return VERSION_WS2008;
 
 	case (VERSION_WIN8):
 		return VERSION_WIN7;
 
 	case (VERSION_WIN8_1):
 		return VERSION_WIN8;
 
 	case (VERSION_WIN10):
 		return VERSION_WIN8_1;
 
 	case (VERSION_WS2008):
 	default:
 		return VERSION_INVAL;
 	}
 }
 
 static int vmbus_negotiate_version(struct vmbus_channel_msginfo *msginfo,
 					__u32 version)
 {
 	int ret = 0;
 	struct vmbus_channel_initiate_contact *msg;
 	unsigned long flags;
 
 	init_completion(&msginfo->waitevent);
 
 	msg = (struct vmbus_channel_initiate_contact *)msginfo->msg;
 
 	msg->header.msgtype = CHANNELMSG_INITIATE_CONTACT;
 	msg->vmbus_version_requested = version;
 	msg->interrupt_page = virt_to_phys(vmbus_connection.int_page);
 	msg->monitor_page1 = virt_to_phys(vmbus_connection.monitor_pages[0]);
 	msg->monitor_page2 = virt_to_phys(vmbus_connection.monitor_pages[1]);
 	/*
 	 * We want all channel messages to be delivered on CPU 0.
 	 * This has been the behavior pre-win8. This is not
 	 * perf issue and having all channel messages delivered on CPU 0
 	 * would be ok.
 	 * For post win8 hosts, we support receiving channel messagges on
 	 * all the CPUs. This is needed for kexec to work correctly where
 	 * the CPU attempting to connect may not be CPU 0.
 	 */
-	if (version >= VERSION_WIN8_1) {
-		msg->target_vcpu = hv_context.vp_index[get_cpu()];
-		put_cpu();
-	} else {
+	if (version >= VERSION_WIN8_1)
+		msg->target_vcpu = hv_context.vp_index[smp_processor_id()];
+	else
 		msg->target_vcpu = 0;
-	}
 
 	/*
 	 * Add to list before we send the request since we may
 	 * receive the response before returning from this routine
 	 */
 	spin_lock_irqsave(&vmbus_connection.channelmsg_lock, flags);
 	list_add_tail(&msginfo->msglistentry,
 		      &vmbus_connection.chn_msg_list);
 
 	spin_unlock_irqrestore(&vmbus_connection.channelmsg_lock, flags);
 
 	ret = vmbus_post_msg(msg,
-			       sizeof(struct vmbus_channel_initiate_contact));
+			     sizeof(struct vmbus_channel_initiate_contact),
+			     true);
 	if (ret != 0) {
 		spin_lock_irqsave(&vmbus_connection.channelmsg_lock, flags);
 		list_del(&msginfo->msglistentry);
 		spin_unlock_irqrestore(&vmbus_connection.channelmsg_lock,
 					flags);
 		return ret;
 	}
 
 	/* Wait for the connection response */
 	wait_for_completion(&msginfo->waitevent);
 
 	spin_lock_irqsave(&vmbus_connection.channelmsg_lock, flags);
 	list_del(&msginfo->msglistentry);
 	spin_unlock_irqrestore(&vmbus_connection.channelmsg_lock, flags);
 
 	/* Check if successful */
 	if (msginfo->response.version_response.version_supported) {
 		vmbus_connection.conn_state = CONNECTED;
 	} else {
 		return -ECONNREFUSED;
 	}
 
 	return ret;
 }
 
 /*
  * vmbus_connect - Sends a connect request on the partition service connection
  */
 int vmbus_connect(void)
 {
 	int ret = 0;
 	struct vmbus_channel_msginfo *msginfo = NULL;
 	__u32 version;
 
 	/* Initialize the vmbus connection */
 	vmbus_connection.conn_state = CONNECTING;
 	vmbus_connection.work_queue = create_workqueue("hv_vmbus_con");
 	if (!vmbus_connection.work_queue) {
 		ret = -ENOMEM;
 		goto cleanup;
 	}
 
 	INIT_LIST_HEAD(&vmbus_connection.chn_msg_list);
 	spin_lock_init(&vmbus_connection.channelmsg_lock);
 
 	INIT_LIST_HEAD(&vmbus_connection.chn_list);
 	mutex_init(&vmbus_connection.channel_mutex);
 
 	/*
 	 * Setup the vmbus event connection for channel interrupt
 	 * abstraction stuff
 	 */
 	vmbus_connection.int_page =
 	(void *)__get_free_pages(GFP_KERNEL|__GFP_ZERO, 0);
 	if (vmbus_connection.int_page == NULL) {
 		ret = -ENOMEM;
 		goto cleanup;
 	}
 
 	vmbus_connection.recv_int_page = vmbus_connection.int_page;
 	vmbus_connection.send_int_page =
 		(void *)((unsigned long)vmbus_connection.int_page +
 			(PAGE_SIZE >> 1));
 
 	/*
 	 * Setup the monitor notification facility. The 1st page for
 	 * parent->child and the 2nd page for child->parent
 	 */
 	vmbus_connection.monitor_pages[0] = (void *)__get_free_pages((GFP_KERNEL|__GFP_ZERO), 0);
 	vmbus_connection.monitor_pages[1] = (void *)__get_free_pages((GFP_KERNEL|__GFP_ZERO), 0);
 	if ((vmbus_connection.monitor_pages[0] == NULL) ||
 	    (vmbus_connection.monitor_pages[1] == NULL)) {
 		ret = -ENOMEM;
 		goto cleanup;
 	}
 
 	msginfo = kzalloc(sizeof(*msginfo) +
 			  sizeof(struct vmbus_channel_initiate_contact),
 			  GFP_KERNEL);
 	if (msginfo == NULL) {
 		ret = -ENOMEM;
 		goto cleanup;
 	}
 
 	/*
 	 * Negotiate a compatible VMBUS version number with the
 	 * host. We start with the highest number we can support
 	 * and work our way down until we negotiate a compatible
 	 * version.
 	 */
 
 	version = VERSION_CURRENT;
 
 	do {
 		ret = vmbus_negotiate_version(msginfo, version);
 		if (ret == -ETIMEDOUT)
 			goto cleanup;
 
 		if (vmbus_connection.conn_state == CONNECTED)
 			break;
 
 		version = vmbus_get_next_version(version);
 	} while (version != VERSION_INVAL);
 
 	if (version == VERSION_INVAL)
 		goto cleanup;
 
 	vmbus_proto_version = version;
-	pr_info("Hyper-V Host Build:%d-%d.%d-%d-%d.%d; Vmbus version:%d.%d\n",
-		    host_info_eax, host_info_ebx >> 16,
-		    host_info_ebx & 0xFFFF, host_info_ecx,
-		    host_info_edx >> 24, host_info_edx & 0xFFFFFF,
-		    version >> 16, version & 0xFFFF);
+	pr_info("Vmbus version:%d.%d\n",
+		version >> 16, version & 0xFFFF);
 
 	kfree(msginfo);
 	return 0;
 
 cleanup:
 	pr_err("Unable to connect to host\n");
 
 	vmbus_connection.conn_state = DISCONNECTED;
 	vmbus_disconnect();
 
 	kfree(msginfo);
 
 	return ret;
 }
 
 void vmbus_disconnect(void)
 {
 	/*
 	 * First send the unload request to the host.
 	 */
 	vmbus_initiate_unload(false);
 
 	if (vmbus_connection.work_queue) {
 		drain_workqueue(vmbus_connection.work_queue);
 		destroy_workqueue(vmbus_connection.work_queue);
 	}
 
 	if (vmbus_connection.int_page) {
 		free_pages((unsigned long)vmbus_connection.int_page, 0);
 		vmbus_connection.int_page = NULL;
 	}
 
 	free_pages((unsigned long)vmbus_connection.monitor_pages[0], 0);
 	free_pages((unsigned long)vmbus_connection.monitor_pages[1], 0);
 	vmbus_connection.monitor_pages[0] = NULL;
 	vmbus_connection.monitor_pages[1] = NULL;
 }
 
-/*
- * Map the given relid to the corresponding channel based on the
- * per-cpu list of channels that have been affinitized to this CPU.
- * This will be used in the channel callback path as we can do this
- * mapping in a lock-free fashion.
- */
-static struct vmbus_channel *pcpu_relid2channel(u32 relid)
-{
-	struct vmbus_channel *channel;
-	struct vmbus_channel *found_channel  = NULL;
-	int cpu = smp_processor_id();
-	struct list_head *pcpu_head = &hv_context.percpu_list[cpu];
-
-	list_for_each_entry(channel, pcpu_head, percpu_list) {
-		if (channel->offermsg.child_relid == relid) {
-			found_channel = channel;
-			break;
-		}
-	}
-
-	return found_channel;
-}
-
 /*
  * relid2channel - Get the channel object given its
  * child relative id (ie channel id)
  */
 struct vmbus_channel *relid2channel(u32 relid)
 {
 	struct vmbus_channel *channel;
 	struct vmbus_channel *found_channel  = NULL;
 	struct list_head *cur, *tmp;
 	struct vmbus_channel *cur_sc;
 
 	BUG_ON(!mutex_is_locked(&vmbus_connection.channel_mutex));
 
 	list_for_each_entry(channel, &vmbus_connection.chn_list, listentry) {
 		if (channel->offermsg.child_relid == relid) {
 			found_channel = channel;
 			break;
 		} else if (!list_empty(&channel->sc_list)) {
 			/*
 			 * Deal with sub-channels.
 			 */
 			list_for_each_safe(cur, tmp, &channel->sc_list) {
 				cur_sc = list_entry(cur, struct vmbus_channel,
 							sc_list);
 				if (cur_sc->offermsg.child_relid == relid) {
 					found_channel = cur_sc;
 					break;
 				}
 			}
 		}
 	}
 
 	return found_channel;
 }
 
 /*
- * process_chn_event - Process a channel event notification
+ * vmbus_on_event - Process a channel event notification
  */
-static void process_chn_event(u32 relid)
+void vmbus_on_event(unsigned long data)
 {
-	struct vmbus_channel *channel;
-	void *arg;
-	bool read_state;
-	u32 bytes_to_read;
-
-	/*
-	 * Find the channel based on this relid and invokes the
-	 * channel callback to process the event
-	 */
-	channel = pcpu_relid2channel(relid);
-
-	if (!channel)
-		return;
+	struct vmbus_channel *channel = (void *) data;
+	void (*callback_fn)(void *);
 
 	/*
 	 * A channel once created is persistent even when there
 	 * is no driver handling the device. An unloading driver
 	 * sets the onchannel_callback to NULL on the same CPU
 	 * as where this interrupt is handled (in an interrupt context).
 	 * Thus, checking and invoking the driver specific callback takes
 	 * care of orderly unloading of the driver.
 	 */
+	callback_fn = READ_ONCE(channel->onchannel_callback);
+	if (unlikely(callback_fn == NULL))
+		return;
 
-	if (channel->onchannel_callback != NULL) {
-		arg = channel->channel_callback_context;
-		read_state = channel->batched_reading;
+	(*callback_fn)(channel->channel_callback_context);
+
+	if (channel->callback_mode == HV_CALL_BATCHED) {
 		/*
 		 * This callback reads the messages sent by the host.
 		 * We can optimize host to guest signaling by ensuring:
 		 * 1. While reading the channel, we disable interrupts from
 		 *    host.
 		 * 2. Ensure that we process all posted messages from the host
 		 *    before returning from this callback.
 		 * 3. Once we return, enable signaling from the host. Once this
 		 *    state is set we check to see if additional packets are
 		 *    available to read. In this case we repeat the process.
 		 */
+		if (hv_end_read(&channel->inbound) != 0) {
+			hv_begin_read(&channel->inbound);
 
-		do {
-			if (read_state)
-				hv_begin_read(&channel->inbound);
-			channel->onchannel_callback(arg);
-			if (read_state)
-				bytes_to_read = hv_end_read(&channel->inbound);
-			else
-				bytes_to_read = 0;
-		} while (read_state && (bytes_to_read != 0));
-	}
-}
-
-/*
- * vmbus_on_event - Handler for events
- */
-void vmbus_on_event(unsigned long data)
-{
-	u32 dword;
-	u32 maxdword;
-	int bit;
-	u32 relid;
-	u32 *recv_int_page = NULL;
-	void *page_addr;
-	int cpu = smp_processor_id();
-	union hv_synic_event_flags *event;
-
-	if (vmbus_proto_version < VERSION_WIN8) {
-		maxdword = MAX_NUM_CHANNELS_SUPPORTED >> 5;
-		recv_int_page = vmbus_connection.recv_int_page;
-	} else {
-		/*
-		 * When the host is win8 and beyond, the event page
-		 * can be directly checked to get the id of the channel
-		 * that has the interrupt pending.
-		 */
-		maxdword = HV_EVENT_FLAGS_DWORD_COUNT;
-		page_addr = hv_context.synic_event_page[cpu];
-		event = (union hv_synic_event_flags *)page_addr +
-						 VMBUS_MESSAGE_SINT;
-		recv_int_page = event->flags32;
-	}
-
-
-
-	/* Check events */
-	if (!recv_int_page)
-		return;
-	for (dword = 0; dword < maxdword; dword++) {
-		if (!recv_int_page[dword])
-			continue;
-		for (bit = 0; bit < 32; bit++) {
-			if (sync_test_and_clear_bit(bit,
-				(unsigned long *)&recv_int_page[dword])) {
-				relid = (dword << 5) + bit;
-
-				if (relid == 0)
-					/*
-					 * Special case - vmbus
-					 * channel protocol msg
-					 */
-					continue;
-
-				process_chn_event(relid);
-			}
+			tasklet_schedule(&channel->callback_event);
 		}
 	}
 }
 
 /*
  * vmbus_post_msg - Send a msg on the vmbus's message connection
  */
-int vmbus_post_msg(void *buffer, size_t buflen)
+int vmbus_post_msg(void *buffer, size_t buflen, bool can_sleep)
 {
 	union hv_connection_id conn_id;
 	int ret = 0;
 	int retries = 0;
 	u32 usec = 1;
 
 	conn_id.asu32 = 0;
 	conn_id.u.id = VMBUS_MESSAGE_CONNECTION_ID;
 
 	/*
 	 * hv_post_message() can have transient failures because of
 	 * insufficient resources. Retry the operation a couple of
 	 * times before giving up.
 	 */
-	while (retries < 20) {
+	while (retries < 100) {
 		ret = hv_post_message(conn_id, 1, buffer, buflen);
 
 		switch (ret) {
 		case HV_STATUS_INVALID_CONNECTION_ID:
 			/*
 			 * We could get this if we send messages too
 			 * frequently.
 			 */
 			ret = -EAGAIN;
 			break;
 		case HV_STATUS_INSUFFICIENT_MEMORY:
 		case HV_STATUS_INSUFFICIENT_BUFFERS:
 			ret = -ENOMEM;
 			break;
 		case HV_STATUS_SUCCESS:
 			return ret;
 		default:
 			pr_err("hv_post_msg() failed; error code:%d\n", ret);
 			return -EINVAL;
 		}
 
 		retries++;
-		udelay(usec);
-		if (usec < 2048)
+		if (can_sleep && usec > 1000)
+			msleep(usec / 1000);
+		else if (usec < MAX_UDELAY_MS * 1000)
+			udelay(usec);
+		else
+			mdelay(usec / 1000);
+
+		if (usec < 256000)
 			usec *= 2;
 	}
 	return ret;
 }
 
 /*
  * vmbus_set_event - Send an event notification to the parent
  */
 void vmbus_set_event(struct vmbus_channel *channel)
 {
 	u32 child_relid = channel->offermsg.child_relid;
 
-	if (!channel->is_dedicated_interrupt) {
-		/* Each u32 represents 32 channels */
-		sync_set_bit(child_relid & 31,
-			(unsigned long *)vmbus_connection.send_int_page +
-			(child_relid >> 5));
-	}
+	if (!channel->is_dedicated_interrupt)
+		vmbus_send_interrupt(child_relid);
 
 	hv_do_hypercall(HVCALL_SIGNAL_EVENT, channel->sig_event, NULL);
 }
 EXPORT_SYMBOL_GPL(vmbus_set_event);
diff --git a/drivers/hv/hv.c b/drivers/hv/hv.c
index b44b32f21e61..665a64f1611e 100644
--- a/drivers/hv/hv.c
+++ b/drivers/hv/hv.c
@@ -1,626 +1,389 @@
 /*
  * Copyright (c) 2009, Microsoft Corporation.
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms and conditions of the GNU General Public License,
  * version 2, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope it will be useful, but WITHOUT
  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
  * more details.
  *
  * You should have received a copy of the GNU General Public License along with
  * this program; if not, write to the Free Software Foundation, Inc., 59 Temple
  * Place - Suite 330, Boston, MA 02111-1307 USA.
  *
  * Authors:
  *   Haiyang Zhang <haiyangz@microsoft.com>
  *   Hank Janssen  <hjanssen@microsoft.com>
  *
  */
 #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
 
 #include <linux/kernel.h>
 #include <linux/mm.h>
 #include <linux/slab.h>
 #include <linux/vmalloc.h>
 #include <linux/hyperv.h>
 #include <linux/version.h>
 #include <linux/interrupt.h>
 #include <linux/clockchips.h>
 #include <asm/hyperv.h>
 #include <asm/mshyperv.h>
 #include "hyperv_vmbus.h"
 
 /* The one and only */
 struct hv_context hv_context = {
 	.synic_initialized	= false,
-	.hypercall_page		= NULL,
 };
 
 #define HV_TIMER_FREQUENCY (10 * 1000 * 1000) /* 100ns period */
 #define HV_MAX_MAX_DELTA_TICKS 0xffffffff
 #define HV_MIN_DELTA_TICKS 1
 
-/*
- * query_hypervisor_info - Get version info of the windows hypervisor
- */
-unsigned int host_info_eax;
-unsigned int host_info_ebx;
-unsigned int host_info_ecx;
-unsigned int host_info_edx;
-
-static int query_hypervisor_info(void)
-{
-	unsigned int eax;
-	unsigned int ebx;
-	unsigned int ecx;
-	unsigned int edx;
-	unsigned int max_leaf;
-	unsigned int op;
-
-	/*
-	* Its assumed that this is called after confirming that Viridian
-	* is present. Query id and revision.
-	*/
-	eax = 0;
-	ebx = 0;
-	ecx = 0;
-	edx = 0;
-	op = HVCPUID_VENDOR_MAXFUNCTION;
-	cpuid(op, &eax, &ebx, &ecx, &edx);
-
-	max_leaf = eax;
-
-	if (max_leaf >= HVCPUID_VERSION) {
-		eax = 0;
-		ebx = 0;
-		ecx = 0;
-		edx = 0;
-		op = HVCPUID_VERSION;
-		cpuid(op, &eax, &ebx, &ecx, &edx);
-		host_info_eax = eax;
-		host_info_ebx = ebx;
-		host_info_ecx = ecx;
-		host_info_edx = edx;
-	}
-	return max_leaf;
-}
-
-/*
- * hv_do_hypercall- Invoke the specified hypercall
- */
-u64 hv_do_hypercall(u64 control, void *input, void *output)
-{
-	u64 input_address = (input) ? virt_to_phys(input) : 0;
-	u64 output_address = (output) ? virt_to_phys(output) : 0;
-	void *hypercall_page = hv_context.hypercall_page;
-#ifdef CONFIG_X86_64
-	u64 hv_status = 0;
-
-	if (!hypercall_page)
-		return (u64)ULLONG_MAX;
-
-	__asm__ __volatile__("mov %0, %%r8" : : "r" (output_address) : "r8");
-	__asm__ __volatile__("call *%3" : "=a" (hv_status) :
-			     "c" (control), "d" (input_address),
-			     "m" (hypercall_page));
-
-	return hv_status;
-
-#else
-
-	u32 control_hi = control >> 32;
-	u32 control_lo = control & 0xFFFFFFFF;
-	u32 hv_status_hi = 1;
-	u32 hv_status_lo = 1;
-	u32 input_address_hi = input_address >> 32;
-	u32 input_address_lo = input_address & 0xFFFFFFFF;
-	u32 output_address_hi = output_address >> 32;
-	u32 output_address_lo = output_address & 0xFFFFFFFF;
-
-	if (!hypercall_page)
-		return (u64)ULLONG_MAX;
-
-	__asm__ __volatile__ ("call *%8" : "=d"(hv_status_hi),
-			      "=a"(hv_status_lo) : "d" (control_hi),
-			      "a" (control_lo), "b" (input_address_hi),
-			      "c" (input_address_lo), "D"(output_address_hi),
-			      "S"(output_address_lo), "m" (hypercall_page));
-
-	return hv_status_lo | ((u64)hv_status_hi << 32);
-#endif /* !x86_64 */
-}
-EXPORT_SYMBOL_GPL(hv_do_hypercall);
-
-#ifdef CONFIG_X86_64
-static u64 read_hv_clock_tsc(struct clocksource *arg)
-{
-	u64 current_tick;
-	struct ms_hyperv_tsc_page *tsc_pg = hv_context.tsc_page;
-
-	if (tsc_pg->tsc_sequence != 0) {
-		/*
-		 * Use the tsc page to compute the value.
-		 */
-
-		while (1) {
-			u64 tmp;
-			u32 sequence = tsc_pg->tsc_sequence;
-			u64 cur_tsc;
-			u64 scale = tsc_pg->tsc_scale;
-			s64 offset = tsc_pg->tsc_offset;
-
-			rdtscll(cur_tsc);
-			/* current_tick = ((cur_tsc *scale) >> 64) + offset */
-			asm("mulq %3"
-				: "=d" (current_tick), "=a" (tmp)
-				: "a" (cur_tsc), "r" (scale));
-
-			current_tick += offset;
-			if (tsc_pg->tsc_sequence == sequence)
-				return current_tick;
-
-			if (tsc_pg->tsc_sequence != 0)
-				continue;
-			/*
-			 * Fallback using MSR method.
-			 */
-			break;
-		}
-	}
-	rdmsrl(HV_X64_MSR_TIME_REF_COUNT, current_tick);
-	return current_tick;
-}
-
-static struct clocksource hyperv_cs_tsc = {
-		.name           = "hyperv_clocksource_tsc_page",
-		.rating         = 425,
-		.read           = read_hv_clock_tsc,
-		.mask           = CLOCKSOURCE_MASK(64),
-		.flags          = CLOCK_SOURCE_IS_CONTINUOUS,
-};
-#endif
-
-
 /*
  * hv_init - Main initialization routine.
  *
  * This routine must be called before any other routines in here are called
  */
 int hv_init(void)
 {
-	int max_leaf;
-	union hv_x64_msr_hypercall_contents hypercall_msr;
-	void *virtaddr = NULL;
-
-	memset(hv_context.synic_event_page, 0, sizeof(void *) * NR_CPUS);
-	memset(hv_context.synic_message_page, 0,
-	       sizeof(void *) * NR_CPUS);
-	memset(hv_context.post_msg_page, 0,
-	       sizeof(void *) * NR_CPUS);
-	memset(hv_context.vp_index, 0,
-	       sizeof(int) * NR_CPUS);
-	memset(hv_context.event_dpc, 0,
-	       sizeof(void *) * NR_CPUS);
-	memset(hv_context.msg_dpc, 0,
-	       sizeof(void *) * NR_CPUS);
-	memset(hv_context.clk_evt, 0,
-	       sizeof(void *) * NR_CPUS);
-
-	max_leaf = query_hypervisor_info();
+	if (!hv_is_hypercall_page_setup())
+		return -ENOTSUPP;
 
-	/*
-	 * Write our OS ID.
-	 */
-	hv_context.guestid = generate_guest_id(0, LINUX_VERSION_CODE, 0);
-	wrmsrl(HV_X64_MSR_GUEST_OS_ID, hv_context.guestid);
-
-	/* See if the hypercall page is already set */
-	rdmsrl(HV_X64_MSR_HYPERCALL, hypercall_msr.as_uint64);
-
-	virtaddr = __vmalloc(PAGE_SIZE, GFP_KERNEL, PAGE_KERNEL_EXEC);
-
-	if (!virtaddr)
-		goto cleanup;
-
-	hypercall_msr.enable = 1;
-
-	hypercall_msr.guest_physical_address = vmalloc_to_pfn(virtaddr);
-	wrmsrl(HV_X64_MSR_HYPERCALL, hypercall_msr.as_uint64);
-
-	/* Confirm that hypercall page did get setup. */
-	hypercall_msr.as_uint64 = 0;
-	rdmsrl(HV_X64_MSR_HYPERCALL, hypercall_msr.as_uint64);
-
-	if (!hypercall_msr.enable)
-		goto cleanup;
-
-	hv_context.hypercall_page = virtaddr;
-
-#ifdef CONFIG_X86_64
-	if (ms_hyperv.features & HV_X64_MSR_REFERENCE_TSC_AVAILABLE) {
-		union hv_x64_msr_hypercall_contents tsc_msr;
-		void *va_tsc;
-
-		va_tsc = __vmalloc(PAGE_SIZE, GFP_KERNEL, PAGE_KERNEL);
-		if (!va_tsc)
-			goto cleanup;
-		hv_context.tsc_page = va_tsc;
-
-		rdmsrl(HV_X64_MSR_REFERENCE_TSC, tsc_msr.as_uint64);
+	hv_context.cpu_context = alloc_percpu(struct hv_per_cpu_context);
+	if (!hv_context.cpu_context)
+		return -ENOMEM;
 
-		tsc_msr.enable = 1;
-		tsc_msr.guest_physical_address = vmalloc_to_pfn(va_tsc);
-
-		wrmsrl(HV_X64_MSR_REFERENCE_TSC, tsc_msr.as_uint64);
-		clocksource_register_hz(&hyperv_cs_tsc, NSEC_PER_SEC/100);
-	}
-#endif
 	return 0;
-
-cleanup:
-	if (virtaddr) {
-		if (hypercall_msr.enable) {
-			hypercall_msr.as_uint64 = 0;
-			wrmsrl(HV_X64_MSR_HYPERCALL, hypercall_msr.as_uint64);
-		}
-
-		vfree(virtaddr);
-	}
-
-	return -ENOTSUPP;
-}
-
-/*
- * hv_cleanup - Cleanup routine.
- *
- * This routine is called normally during driver unloading or exiting.
- */
-void hv_cleanup(bool crash)
-{
-	union hv_x64_msr_hypercall_contents hypercall_msr;
-
-	/* Reset our OS id */
-	wrmsrl(HV_X64_MSR_GUEST_OS_ID, 0);
-
-	if (hv_context.hypercall_page) {
-		hypercall_msr.as_uint64 = 0;
-		wrmsrl(HV_X64_MSR_HYPERCALL, hypercall_msr.as_uint64);
-		if (!crash)
-			vfree(hv_context.hypercall_page);
-		hv_context.hypercall_page = NULL;
-	}
-
-#ifdef CONFIG_X86_64
-	/*
-	 * Cleanup the TSC page based CS.
-	 */
-	if (ms_hyperv.features & HV_X64_MSR_REFERENCE_TSC_AVAILABLE) {
-		/*
-		 * Crash can happen in an interrupt context and unregistering
-		 * a clocksource is impossible and redundant in this case.
-		 */
-		if (!oops_in_progress) {
-			clocksource_change_rating(&hyperv_cs_tsc, 10);
-			clocksource_unregister(&hyperv_cs_tsc);
-		}
-
-		hypercall_msr.as_uint64 = 0;
-		wrmsrl(HV_X64_MSR_REFERENCE_TSC, hypercall_msr.as_uint64);
-		if (!crash)
-			vfree(hv_context.tsc_page);
-		hv_context.tsc_page = NULL;
-	}
-#endif
 }
 
 /*
  * hv_post_message - Post a message using the hypervisor message IPC.
  *
  * This involves a hypercall.
  */
 int hv_post_message(union hv_connection_id connection_id,
 		  enum hv_message_type message_type,
 		  void *payload, size_t payload_size)
 {
-
 	struct hv_input_post_message *aligned_msg;
+	struct hv_per_cpu_context *hv_cpu;
 	u64 status;
 
 	if (payload_size > HV_MESSAGE_PAYLOAD_BYTE_COUNT)
 		return -EMSGSIZE;
 
-	aligned_msg = (struct hv_input_post_message *)
-			hv_context.post_msg_page[get_cpu()];
-
+	hv_cpu = get_cpu_ptr(hv_context.cpu_context);
+	aligned_msg = hv_cpu->post_msg_page;
 	aligned_msg->connectionid = connection_id;
 	aligned_msg->reserved = 0;
 	aligned_msg->message_type = message_type;
 	aligned_msg->payload_size = payload_size;
 	memcpy((void *)aligned_msg->payload, payload, payload_size);
+	put_cpu_ptr(hv_cpu);
 
 	status = hv_do_hypercall(HVCALL_POST_MESSAGE, aligned_msg, NULL);
 
-	put_cpu();
 	return status & 0xFFFF;
 }
 
 static int hv_ce_set_next_event(unsigned long delta,
 				struct clock_event_device *evt)
 {
 	u64 current_tick;
 
 	WARN_ON(!clockevent_state_oneshot(evt));
 
-	rdmsrl(HV_X64_MSR_TIME_REF_COUNT, current_tick);
+	hv_get_current_tick(current_tick);
 	current_tick += delta;
-	wrmsrl(HV_X64_MSR_STIMER0_COUNT, current_tick);
+	hv_init_timer(HV_X64_MSR_STIMER0_COUNT, current_tick);
 	return 0;
 }
 
 static int hv_ce_shutdown(struct clock_event_device *evt)
 {
-	wrmsrl(HV_X64_MSR_STIMER0_COUNT, 0);
-	wrmsrl(HV_X64_MSR_STIMER0_CONFIG, 0);
+	hv_init_timer(HV_X64_MSR_STIMER0_COUNT, 0);
+	hv_init_timer_config(HV_X64_MSR_STIMER0_CONFIG, 0);
 
 	return 0;
 }
 
 static int hv_ce_set_oneshot(struct clock_event_device *evt)
 {
 	union hv_timer_config timer_cfg;
 
 	timer_cfg.enable = 1;
 	timer_cfg.auto_enable = 1;
 	timer_cfg.sintx = VMBUS_MESSAGE_SINT;
-	wrmsrl(HV_X64_MSR_STIMER0_CONFIG, timer_cfg.as_uint64);
+	hv_init_timer_config(HV_X64_MSR_STIMER0_CONFIG, timer_cfg.as_uint64);
 
 	return 0;
 }
 
 static void hv_init_clockevent_device(struct clock_event_device *dev, int cpu)
 {
 	dev->name = "Hyper-V clockevent";
 	dev->features = CLOCK_EVT_FEAT_ONESHOT;
 	dev->cpumask = cpumask_of(cpu);
 	dev->rating = 1000;
 	/*
 	 * Avoid settint dev->owner = THIS_MODULE deliberately as doing so will
 	 * result in clockevents_config_and_register() taking additional
 	 * references to the hv_vmbus module making it impossible to unload.
 	 */
 
 	dev->set_state_shutdown = hv_ce_shutdown;
 	dev->set_state_oneshot = hv_ce_set_oneshot;
 	dev->set_next_event = hv_ce_set_next_event;
 }
 
 
 int hv_synic_alloc(void)
 {
-	size_t size = sizeof(struct tasklet_struct);
-	size_t ced_size = sizeof(struct clock_event_device);
 	int cpu;
 
 	hv_context.hv_numa_map = kzalloc(sizeof(struct cpumask) * nr_node_ids,
 					 GFP_ATOMIC);
 	if (hv_context.hv_numa_map == NULL) {
 		pr_err("Unable to allocate NUMA map\n");
 		goto err;
 	}
 
-	for_each_online_cpu(cpu) {
-		hv_context.event_dpc[cpu] = kmalloc(size, GFP_ATOMIC);
-		if (hv_context.event_dpc[cpu] == NULL) {
-			pr_err("Unable to allocate event dpc\n");
-			goto err;
-		}
-		tasklet_init(hv_context.event_dpc[cpu], vmbus_on_event, cpu);
+	for_each_present_cpu(cpu) {
+		struct hv_per_cpu_context *hv_cpu
+			= per_cpu_ptr(hv_context.cpu_context, cpu);
 
-		hv_context.msg_dpc[cpu] = kmalloc(size, GFP_ATOMIC);
-		if (hv_context.msg_dpc[cpu] == NULL) {
-			pr_err("Unable to allocate event dpc\n");
-			goto err;
-		}
-		tasklet_init(hv_context.msg_dpc[cpu], vmbus_on_msg_dpc, cpu);
+		memset(hv_cpu, 0, sizeof(*hv_cpu));
+		tasklet_init(&hv_cpu->msg_dpc,
+			     vmbus_on_msg_dpc, (unsigned long) hv_cpu);
 
-		hv_context.clk_evt[cpu] = kzalloc(ced_size, GFP_ATOMIC);
-		if (hv_context.clk_evt[cpu] == NULL) {
+		hv_cpu->clk_evt = kzalloc(sizeof(struct clock_event_device),
+					  GFP_KERNEL);
+		if (hv_cpu->clk_evt == NULL) {
 			pr_err("Unable to allocate clock event device\n");
 			goto err;
 		}
+		hv_init_clockevent_device(hv_cpu->clk_evt, cpu);
 
-		hv_init_clockevent_device(hv_context.clk_evt[cpu], cpu);
-
-		hv_context.synic_message_page[cpu] =
+		hv_cpu->synic_message_page =
 			(void *)get_zeroed_page(GFP_ATOMIC);
-
-		if (hv_context.synic_message_page[cpu] == NULL) {
+		if (hv_cpu->synic_message_page == NULL) {
 			pr_err("Unable to allocate SYNIC message page\n");
 			goto err;
 		}
 
-		hv_context.synic_event_page[cpu] =
-			(void *)get_zeroed_page(GFP_ATOMIC);
-
-		if (hv_context.synic_event_page[cpu] == NULL) {
+		hv_cpu->synic_event_page = (void *)get_zeroed_page(GFP_ATOMIC);
+		if (hv_cpu->synic_event_page == NULL) {
 			pr_err("Unable to allocate SYNIC event page\n");
 			goto err;
 		}
 
-		hv_context.post_msg_page[cpu] =
-			(void *)get_zeroed_page(GFP_ATOMIC);
-
-		if (hv_context.post_msg_page[cpu] == NULL) {
+		hv_cpu->post_msg_page = (void *)get_zeroed_page(GFP_ATOMIC);
+		if (hv_cpu->post_msg_page == NULL) {
 			pr_err("Unable to allocate post msg page\n");
 			goto err;
 		}
+
+		INIT_LIST_HEAD(&hv_cpu->chan_list);
 	}
 
 	return 0;
 err:
 	return -ENOMEM;
 }
 
-static void hv_synic_free_cpu(int cpu)
-{
-	kfree(hv_context.event_dpc[cpu]);
-	kfree(hv_context.msg_dpc[cpu]);
-	kfree(hv_context.clk_evt[cpu]);
-	if (hv_context.synic_event_page[cpu])
-		free_page((unsigned long)hv_context.synic_event_page[cpu]);
-	if (hv_context.synic_message_page[cpu])
-		free_page((unsigned long)hv_context.synic_message_page[cpu]);
-	if (hv_context.post_msg_page[cpu])
-		free_page((unsigned long)hv_context.post_msg_page[cpu]);
-}
 
 void hv_synic_free(void)
 {
 	int cpu;
 
+	for_each_present_cpu(cpu) {
+		struct hv_per_cpu_context *hv_cpu
+			= per_cpu_ptr(hv_context.cpu_context, cpu);
+
+		if (hv_cpu->synic_event_page)
+			free_page((unsigned long)hv_cpu->synic_event_page);
+		if (hv_cpu->synic_message_page)
+			free_page((unsigned long)hv_cpu->synic_message_page);
+		if (hv_cpu->post_msg_page)
+			free_page((unsigned long)hv_cpu->post_msg_page);
+	}
+
 	kfree(hv_context.hv_numa_map);
-	for_each_online_cpu(cpu)
-		hv_synic_free_cpu(cpu);
 }
 
 /*
  * hv_synic_init - Initialize the Synthethic Interrupt Controller.
  *
  * If it is already initialized by another entity (ie x2v shim), we need to
  * retrieve the initialized message and event pages.  Otherwise, we create and
  * initialize the message and event pages.
  */
-void hv_synic_init(void *arg)
+int hv_synic_init(unsigned int cpu)
 {
-	u64 version;
+	struct hv_per_cpu_context *hv_cpu
+		= per_cpu_ptr(hv_context.cpu_context, cpu);
 	union hv_synic_simp simp;
 	union hv_synic_siefp siefp;
 	union hv_synic_sint shared_sint;
 	union hv_synic_scontrol sctrl;
 	u64 vp_index;
 
-	int cpu = smp_processor_id();
-
-	if (!hv_context.hypercall_page)
-		return;
-
-	/* Check the version */
-	rdmsrl(HV_X64_MSR_SVERSION, version);
-
 	/* Setup the Synic's message page */
-	rdmsrl(HV_X64_MSR_SIMP, simp.as_uint64);
+	hv_get_simp(simp.as_uint64);
 	simp.simp_enabled = 1;
-	simp.base_simp_gpa = virt_to_phys(hv_context.synic_message_page[cpu])
+	simp.base_simp_gpa = virt_to_phys(hv_cpu->synic_message_page)
 		>> PAGE_SHIFT;
 
-	wrmsrl(HV_X64_MSR_SIMP, simp.as_uint64);
+	hv_set_simp(simp.as_uint64);
 
 	/* Setup the Synic's event page */
-	rdmsrl(HV_X64_MSR_SIEFP, siefp.as_uint64);
+	hv_get_siefp(siefp.as_uint64);
 	siefp.siefp_enabled = 1;
-	siefp.base_siefp_gpa = virt_to_phys(hv_context.synic_event_page[cpu])
+	siefp.base_siefp_gpa = virt_to_phys(hv_cpu->synic_event_page)
 		>> PAGE_SHIFT;
 
-	wrmsrl(HV_X64_MSR_SIEFP, siefp.as_uint64);
+	hv_set_siefp(siefp.as_uint64);
 
 	/* Setup the shared SINT. */
-	rdmsrl(HV_X64_MSR_SINT0 + VMBUS_MESSAGE_SINT, shared_sint.as_uint64);
+	hv_get_synint_state(HV_X64_MSR_SINT0 + VMBUS_MESSAGE_SINT,
+			    shared_sint.as_uint64);
 
 	shared_sint.as_uint64 = 0;
 	shared_sint.vector = HYPERVISOR_CALLBACK_VECTOR;
 	shared_sint.masked = false;
 	shared_sint.auto_eoi = true;
 
-	wrmsrl(HV_X64_MSR_SINT0 + VMBUS_MESSAGE_SINT, shared_sint.as_uint64);
+	hv_set_synint_state(HV_X64_MSR_SINT0 + VMBUS_MESSAGE_SINT,
+			    shared_sint.as_uint64);
 
 	/* Enable the global synic bit */
-	rdmsrl(HV_X64_MSR_SCONTROL, sctrl.as_uint64);
+	hv_get_synic_state(sctrl.as_uint64);
 	sctrl.enable = 1;
 
-	wrmsrl(HV_X64_MSR_SCONTROL, sctrl.as_uint64);
+	hv_set_synic_state(sctrl.as_uint64);
 
 	hv_context.synic_initialized = true;
 
 	/*
 	 * Setup the mapping between Hyper-V's notion
 	 * of cpuid and Linux' notion of cpuid.
 	 * This array will be indexed using Linux cpuid.
 	 */
-	rdmsrl(HV_X64_MSR_VP_INDEX, vp_index);
+	hv_get_vp_index(vp_index);
 	hv_context.vp_index[cpu] = (u32)vp_index;
 
-	INIT_LIST_HEAD(&hv_context.percpu_list[cpu]);
-
 	/*
 	 * Register the per-cpu clockevent source.
 	 */
 	if (ms_hyperv.features & HV_X64_MSR_SYNTIMER_AVAILABLE)
-		clockevents_config_and_register(hv_context.clk_evt[cpu],
+		clockevents_config_and_register(hv_cpu->clk_evt,
 						HV_TIMER_FREQUENCY,
 						HV_MIN_DELTA_TICKS,
 						HV_MAX_MAX_DELTA_TICKS);
-	return;
+	return 0;
 }
 
 /*
  * hv_synic_clockevents_cleanup - Cleanup clockevent devices
  */
 void hv_synic_clockevents_cleanup(void)
 {
 	int cpu;
 
 	if (!(ms_hyperv.features & HV_X64_MSR_SYNTIMER_AVAILABLE))
 		return;
 
-	for_each_present_cpu(cpu)
-		clockevents_unbind_device(hv_context.clk_evt[cpu], cpu);
+	for_each_present_cpu(cpu) {
+		struct hv_per_cpu_context *hv_cpu
+			= per_cpu_ptr(hv_context.cpu_context, cpu);
+
+		clockevents_unbind_device(hv_cpu->clk_evt, cpu);
+	}
 }
 
 /*
  * hv_synic_cleanup - Cleanup routine for hv_synic_init().
  */
-void hv_synic_cleanup(void *arg)
+int hv_synic_cleanup(unsigned int cpu)
 {
 	union hv_synic_sint shared_sint;
 	union hv_synic_simp simp;
 	union hv_synic_siefp siefp;
 	union hv_synic_scontrol sctrl;
-	int cpu = smp_processor_id();
+	struct vmbus_channel *channel, *sc;
+	bool channel_found = false;
+	unsigned long flags;
 
 	if (!hv_context.synic_initialized)
-		return;
+		return -EFAULT;
+
+	/*
+	 * Search for channels which are bound to the CPU we're about to
+	 * cleanup. In case we find one and vmbus is still connected we need to
+	 * fail, this will effectively prevent CPU offlining. There is no way
+	 * we can re-bind channels to different CPUs for now.
+	 */
+	mutex_lock(&vmbus_connection.channel_mutex);
+	list_for_each_entry(channel, &vmbus_connection.chn_list, listentry) {
+		if (channel->target_cpu == cpu) {
+			channel_found = true;
+			break;
+		}
+		spin_lock_irqsave(&channel->lock, flags);
+		list_for_each_entry(sc, &channel->sc_list, sc_list) {
+			if (sc->target_cpu == cpu) {
+				channel_found = true;
+				break;
+			}
+		}
+		spin_unlock_irqrestore(&channel->lock, flags);
+		if (channel_found)
+			break;
+	}
+	mutex_unlock(&vmbus_connection.channel_mutex);
+
+	if (channel_found && vmbus_connection.conn_state == CONNECTED)
+		return -EBUSY;
 
 	/* Turn off clockevent device */
 	if (ms_hyperv.features & HV_X64_MSR_SYNTIMER_AVAILABLE) {
-		clockevents_unbind_device(hv_context.clk_evt[cpu], cpu);
-		hv_ce_shutdown(hv_context.clk_evt[cpu]);
+		struct hv_per_cpu_context *hv_cpu
+			= this_cpu_ptr(hv_context.cpu_context);
+
+		clockevents_unbind_device(hv_cpu->clk_evt, cpu);
+		hv_ce_shutdown(hv_cpu->clk_evt);
+		put_cpu_ptr(hv_cpu);
 	}
 
-	rdmsrl(HV_X64_MSR_SINT0 + VMBUS_MESSAGE_SINT, shared_sint.as_uint64);
+	hv_get_synint_state(HV_X64_MSR_SINT0 + VMBUS_MESSAGE_SINT,
+			    shared_sint.as_uint64);
 
 	shared_sint.masked = 1;
 
 	/* Need to correctly cleanup in the case of SMP!!! */
 	/* Disable the interrupt */
-	wrmsrl(HV_X64_MSR_SINT0 + VMBUS_MESSAGE_SINT, shared_sint.as_uint64);
+	hv_set_synint_state(HV_X64_MSR_SINT0 + VMBUS_MESSAGE_SINT,
+			    shared_sint.as_uint64);
 
-	rdmsrl(HV_X64_MSR_SIMP, simp.as_uint64);
+	hv_get_simp(simp.as_uint64);
 	simp.simp_enabled = 0;
 	simp.base_simp_gpa = 0;
 
-	wrmsrl(HV_X64_MSR_SIMP, simp.as_uint64);
+	hv_set_simp(simp.as_uint64);
 
-	rdmsrl(HV_X64_MSR_SIEFP, siefp.as_uint64);
+	hv_get_siefp(siefp.as_uint64);
 	siefp.siefp_enabled = 0;
 	siefp.base_siefp_gpa = 0;
 
-	wrmsrl(HV_X64_MSR_SIEFP, siefp.as_uint64);
+	hv_set_siefp(siefp.as_uint64);
 
 	/* Disable the global synic bit */
-	rdmsrl(HV_X64_MSR_SCONTROL, sctrl.as_uint64);
+	hv_get_synic_state(sctrl.as_uint64);
 	sctrl.enable = 0;
-	wrmsrl(HV_X64_MSR_SCONTROL, sctrl.as_uint64);
+	hv_set_synic_state(sctrl.as_uint64);
+
+	return 0;
 }
diff --git a/drivers/hv/hv_balloon.c b/drivers/hv/hv_balloon.c
index 14c3dc4bd23c..5fd03e59cee5 100644
--- a/drivers/hv/hv_balloon.c
+++ b/drivers/hv/hv_balloon.c
@@ -1,1735 +1,1736 @@
 /*
  * Copyright (c) 2012, Microsoft Corporation.
  *
  * Author:
  *   K. Y. Srinivasan <kys@microsoft.com>
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 as published
  * by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful, but
  * WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, GOOD TITLE or
  * NON INFRINGEMENT.  See the GNU General Public License for more
  * details.
  *
  */
 
 #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
 
 #include <linux/kernel.h>
 #include <linux/jiffies.h>
 #include <linux/mman.h>
 #include <linux/delay.h>
 #include <linux/init.h>
 #include <linux/module.h>
 #include <linux/slab.h>
 #include <linux/kthread.h>
 #include <linux/completion.h>
 #include <linux/memory_hotplug.h>
 #include <linux/memory.h>
 #include <linux/notifier.h>
 #include <linux/percpu_counter.h>
 
 #include <linux/hyperv.h>
 
 /*
  * We begin with definitions supporting the Dynamic Memory protocol
  * with the host.
  *
  * Begin protocol definitions.
  */
 
 
 
 /*
  * Protocol versions. The low word is the minor version, the high word the major
  * version.
  *
  * History:
  * Initial version 1.0
  * Changed to 0.1 on 2009/03/25
  * Changes to 0.2 on 2009/05/14
  * Changes to 0.3 on 2009/12/03
  * Changed to 1.0 on 2011/04/05
  */
 
 #define DYNMEM_MAKE_VERSION(Major, Minor) ((__u32)(((Major) << 16) | (Minor)))
 #define DYNMEM_MAJOR_VERSION(Version) ((__u32)(Version) >> 16)
 #define DYNMEM_MINOR_VERSION(Version) ((__u32)(Version) & 0xff)
 
 enum {
 	DYNMEM_PROTOCOL_VERSION_1 = DYNMEM_MAKE_VERSION(0, 3),
 	DYNMEM_PROTOCOL_VERSION_2 = DYNMEM_MAKE_VERSION(1, 0),
 	DYNMEM_PROTOCOL_VERSION_3 = DYNMEM_MAKE_VERSION(2, 0),
 
 	DYNMEM_PROTOCOL_VERSION_WIN7 = DYNMEM_PROTOCOL_VERSION_1,
 	DYNMEM_PROTOCOL_VERSION_WIN8 = DYNMEM_PROTOCOL_VERSION_2,
 	DYNMEM_PROTOCOL_VERSION_WIN10 = DYNMEM_PROTOCOL_VERSION_3,
 
 	DYNMEM_PROTOCOL_VERSION_CURRENT = DYNMEM_PROTOCOL_VERSION_WIN10
 };
 
 
 
 /*
  * Message Types
  */
 
 enum dm_message_type {
 	/*
 	 * Version 0.3
 	 */
 	DM_ERROR			= 0,
 	DM_VERSION_REQUEST		= 1,
 	DM_VERSION_RESPONSE		= 2,
 	DM_CAPABILITIES_REPORT		= 3,
 	DM_CAPABILITIES_RESPONSE	= 4,
 	DM_STATUS_REPORT		= 5,
 	DM_BALLOON_REQUEST		= 6,
 	DM_BALLOON_RESPONSE		= 7,
 	DM_UNBALLOON_REQUEST		= 8,
 	DM_UNBALLOON_RESPONSE		= 9,
 	DM_MEM_HOT_ADD_REQUEST		= 10,
 	DM_MEM_HOT_ADD_RESPONSE		= 11,
 	DM_VERSION_03_MAX		= 11,
 	/*
 	 * Version 1.0.
 	 */
 	DM_INFO_MESSAGE			= 12,
 	DM_VERSION_1_MAX		= 12
 };
 
 
 /*
  * Structures defining the dynamic memory management
  * protocol.
  */
 
 union dm_version {
 	struct {
 		__u16 minor_version;
 		__u16 major_version;
 	};
 	__u32 version;
 } __packed;
 
 
 union dm_caps {
 	struct {
 		__u64 balloon:1;
 		__u64 hot_add:1;
 		/*
 		 * To support guests that may have alignment
 		 * limitations on hot-add, the guest can specify
 		 * its alignment requirements; a value of n
 		 * represents an alignment of 2^n in mega bytes.
 		 */
 		__u64 hot_add_alignment:4;
 		__u64 reservedz:58;
 	} cap_bits;
 	__u64 caps;
 } __packed;
 
 union dm_mem_page_range {
 	struct  {
 		/*
 		 * The PFN number of the first page in the range.
 		 * 40 bits is the architectural limit of a PFN
 		 * number for AMD64.
 		 */
 		__u64 start_page:40;
 		/*
 		 * The number of pages in the range.
 		 */
 		__u64 page_cnt:24;
 	} finfo;
 	__u64  page_range;
 } __packed;
 
 
 
 /*
  * The header for all dynamic memory messages:
  *
  * type: Type of the message.
  * size: Size of the message in bytes; including the header.
  * trans_id: The guest is responsible for manufacturing this ID.
  */
 
 struct dm_header {
 	__u16 type;
 	__u16 size;
 	__u32 trans_id;
 } __packed;
 
 /*
  * A generic message format for dynamic memory.
  * Specific message formats are defined later in the file.
  */
 
 struct dm_message {
 	struct dm_header hdr;
 	__u8 data[]; /* enclosed message */
 } __packed;
 
 
 /*
  * Specific message types supporting the dynamic memory protocol.
  */
 
 /*
  * Version negotiation message. Sent from the guest to the host.
  * The guest is free to try different versions until the host
  * accepts the version.
  *
  * dm_version: The protocol version requested.
  * is_last_attempt: If TRUE, this is the last version guest will request.
  * reservedz: Reserved field, set to zero.
  */
 
 struct dm_version_request {
 	struct dm_header hdr;
 	union dm_version version;
 	__u32 is_last_attempt:1;
 	__u32 reservedz:31;
 } __packed;
 
 /*
  * Version response message; Host to Guest and indicates
  * if the host has accepted the version sent by the guest.
  *
  * is_accepted: If TRUE, host has accepted the version and the guest
  * should proceed to the next stage of the protocol. FALSE indicates that
  * guest should re-try with a different version.
  *
  * reservedz: Reserved field, set to zero.
  */
 
 struct dm_version_response {
 	struct dm_header hdr;
 	__u64 is_accepted:1;
 	__u64 reservedz:63;
 } __packed;
 
 /*
  * Message reporting capabilities. This is sent from the guest to the
  * host.
  */
 
 struct dm_capabilities {
 	struct dm_header hdr;
 	union dm_caps caps;
 	__u64 min_page_cnt;
 	__u64 max_page_number;
 } __packed;
 
 /*
  * Response to the capabilities message. This is sent from the host to the
  * guest. This message notifies if the host has accepted the guest's
  * capabilities. If the host has not accepted, the guest must shutdown
  * the service.
  *
  * is_accepted: Indicates if the host has accepted guest's capabilities.
  * reservedz: Must be 0.
  */
 
 struct dm_capabilities_resp_msg {
 	struct dm_header hdr;
 	__u64 is_accepted:1;
 	__u64 reservedz:63;
 } __packed;
 
 /*
  * This message is used to report memory pressure from the guest.
  * This message is not part of any transaction and there is no
  * response to this message.
  *
  * num_avail: Available memory in pages.
  * num_committed: Committed memory in pages.
  * page_file_size: The accumulated size of all page files
  *		   in the system in pages.
  * zero_free: The nunber of zero and free pages.
  * page_file_writes: The writes to the page file in pages.
  * io_diff: An indicator of file cache efficiency or page file activity,
  *	    calculated as File Cache Page Fault Count - Page Read Count.
  *	    This value is in pages.
  *
  * Some of these metrics are Windows specific and fortunately
  * the algorithm on the host side that computes the guest memory
  * pressure only uses num_committed value.
  */
 
 struct dm_status {
 	struct dm_header hdr;
 	__u64 num_avail;
 	__u64 num_committed;
 	__u64 page_file_size;
 	__u64 zero_free;
 	__u32 page_file_writes;
 	__u32 io_diff;
 } __packed;
 
 
 /*
  * Message to ask the guest to allocate memory - balloon up message.
  * This message is sent from the host to the guest. The guest may not be
  * able to allocate as much memory as requested.
  *
  * num_pages: number of pages to allocate.
  */
 
 struct dm_balloon {
 	struct dm_header hdr;
 	__u32 num_pages;
 	__u32 reservedz;
 } __packed;
 
 
 /*
  * Balloon response message; this message is sent from the guest
  * to the host in response to the balloon message.
  *
  * reservedz: Reserved; must be set to zero.
  * more_pages: If FALSE, this is the last message of the transaction.
  * if TRUE there will atleast one more message from the guest.
  *
  * range_count: The number of ranges in the range array.
  *
  * range_array: An array of page ranges returned to the host.
  *
  */
 
 struct dm_balloon_response {
 	struct dm_header hdr;
 	__u32 reservedz;
 	__u32 more_pages:1;
 	__u32 range_count:31;
 	union dm_mem_page_range range_array[];
 } __packed;
 
 /*
  * Un-balloon message; this message is sent from the host
  * to the guest to give guest more memory.
  *
  * more_pages: If FALSE, this is the last message of the transaction.
  * if TRUE there will atleast one more message from the guest.
  *
  * reservedz: Reserved; must be set to zero.
  *
  * range_count: The number of ranges in the range array.
  *
  * range_array: An array of page ranges returned to the host.
  *
  */
 
 struct dm_unballoon_request {
 	struct dm_header hdr;
 	__u32 more_pages:1;
 	__u32 reservedz:31;
 	__u32 range_count;
 	union dm_mem_page_range range_array[];
 } __packed;
 
 /*
  * Un-balloon response message; this message is sent from the guest
  * to the host in response to an unballoon request.
  *
  */
 
 struct dm_unballoon_response {
 	struct dm_header hdr;
 } __packed;
 
 
 /*
  * Hot add request message. Message sent from the host to the guest.
  *
  * mem_range: Memory range to hot add.
  *
  * On Linux we currently don't support this since we cannot hot add
  * arbitrary granularity of memory.
  */
 
 struct dm_hot_add {
 	struct dm_header hdr;
 	union dm_mem_page_range range;
 } __packed;
 
 /*
  * Hot add response message.
  * This message is sent by the guest to report the status of a hot add request.
  * If page_count is less than the requested page count, then the host should
  * assume all further hot add requests will fail, since this indicates that
  * the guest has hit an upper physical memory barrier.
  *
  * Hot adds may also fail due to low resources; in this case, the guest must
  * not complete this message until the hot add can succeed, and the host must
  * not send a new hot add request until the response is sent.
  * If VSC fails to hot add memory DYNMEM_NUMBER_OF_UNSUCCESSFUL_HOTADD_ATTEMPTS
  * times it fails the request.
  *
  *
  * page_count: number of pages that were successfully hot added.
  *
  * result: result of the operation 1: success, 0: failure.
  *
  */
 
 struct dm_hot_add_response {
 	struct dm_header hdr;
 	__u32 page_count;
 	__u32 result;
 } __packed;
 
 /*
  * Types of information sent from host to the guest.
  */
 
 enum dm_info_type {
 	INFO_TYPE_MAX_PAGE_CNT = 0,
 	MAX_INFO_TYPE
 };
 
 
 /*
  * Header for the information message.
  */
 
 struct dm_info_header {
 	enum dm_info_type type;
 	__u32 data_size;
 } __packed;
 
 /*
  * This message is sent from the host to the guest to pass
  * some relevant information (win8 addition).
  *
  * reserved: no used.
  * info_size: size of the information blob.
  * info: information blob.
  */
 
 struct dm_info_msg {
 	struct dm_header hdr;
 	__u32 reserved;
 	__u32 info_size;
 	__u8  info[];
 };
 
 /*
  * End protocol definitions.
  */
 
 /*
  * State to manage hot adding memory into the guest.
  * The range start_pfn : end_pfn specifies the range
  * that the host has asked us to hot add. The range
  * start_pfn : ha_end_pfn specifies the range that we have
  * currently hot added. We hot add in multiples of 128M
  * chunks; it is possible that we may not be able to bring
  * online all the pages in the region. The range
  * covered_start_pfn:covered_end_pfn defines the pages that can
  * be brough online.
  */
 
 struct hv_hotadd_state {
 	struct list_head list;
 	unsigned long start_pfn;
 	unsigned long covered_start_pfn;
 	unsigned long covered_end_pfn;
 	unsigned long ha_end_pfn;
 	unsigned long end_pfn;
 	/*
 	 * A list of gaps.
 	 */
 	struct list_head gap_list;
 };
 
 struct hv_hotadd_gap {
 	struct list_head list;
 	unsigned long start_pfn;
 	unsigned long end_pfn;
 };
 
 struct balloon_state {
 	__u32 num_pages;
 	struct work_struct wrk;
 };
 
 struct hot_add_wrk {
 	union dm_mem_page_range ha_page_range;
 	union dm_mem_page_range ha_region_range;
 	struct work_struct wrk;
 };
 
 static bool hot_add = true;
 static bool do_hot_add;
 /*
  * Delay reporting memory pressure by
  * the specified number of seconds.
  */
 static uint pressure_report_delay = 45;
 
 /*
  * The last time we posted a pressure report to host.
  */
 static unsigned long last_post_time;
 
 module_param(hot_add, bool, (S_IRUGO | S_IWUSR));
 MODULE_PARM_DESC(hot_add, "If set attempt memory hot_add");
 
 module_param(pressure_report_delay, uint, (S_IRUGO | S_IWUSR));
 MODULE_PARM_DESC(pressure_report_delay, "Delay in secs in reporting pressure");
 static atomic_t trans_id = ATOMIC_INIT(0);
 
 static int dm_ring_size = (5 * PAGE_SIZE);
 
 /*
  * Driver specific state.
  */
 
 enum hv_dm_state {
 	DM_INITIALIZING = 0,
 	DM_INITIALIZED,
 	DM_BALLOON_UP,
 	DM_BALLOON_DOWN,
 	DM_HOT_ADD,
 	DM_INIT_ERROR
 };
 
 
 static __u8 recv_buffer[PAGE_SIZE];
 static __u8 *send_buffer;
 #define PAGES_IN_2M	512
 #define HA_CHUNK (32 * 1024)
 
 struct hv_dynmem_device {
 	struct hv_device *dev;
 	enum hv_dm_state state;
 	struct completion host_event;
 	struct completion config_event;
 
 	/*
 	 * Number of pages we have currently ballooned out.
 	 */
 	unsigned int num_pages_ballooned;
 	unsigned int num_pages_onlined;
 	unsigned int num_pages_added;
 
 	/*
 	 * State to manage the ballooning (up) operation.
 	 */
 	struct balloon_state balloon_wrk;
 
 	/*
 	 * State to execute the "hot-add" operation.
 	 */
 	struct hot_add_wrk ha_wrk;
 
 	/*
 	 * This state tracks if the host has specified a hot-add
 	 * region.
 	 */
 	bool host_specified_ha_region;
 
 	/*
 	 * State to synchronize hot-add.
 	 */
 	struct completion  ol_waitevent;
 	bool ha_waiting;
 	/*
 	 * This thread handles hot-add
 	 * requests from the host as well as notifying
 	 * the host with regards to memory pressure in
 	 * the guest.
 	 */
 	struct task_struct *thread;
 
 	/*
 	 * Protects ha_region_list, num_pages_onlined counter and individual
 	 * regions from ha_region_list.
 	 */
 	spinlock_t ha_lock;
 
 	/*
 	 * A list of hot-add regions.
 	 */
 	struct list_head ha_region_list;
 
 	/*
 	 * We start with the highest version we can support
 	 * and downgrade based on the host; we save here the
 	 * next version to try.
 	 */
 	__u32 next_version;
 
 	/*
 	 * The negotiated version agreed by host.
 	 */
 	__u32 version;
 };
 
 static struct hv_dynmem_device dm_device;
 
 static void post_status(struct hv_dynmem_device *dm);
 
 #ifdef CONFIG_MEMORY_HOTPLUG
 static int hv_memory_notifier(struct notifier_block *nb, unsigned long val,
 			      void *v)
 {
 	struct memory_notify *mem = (struct memory_notify *)v;
 	unsigned long flags;
 
 	switch (val) {
 	case MEM_ONLINE:
 		spin_lock_irqsave(&dm_device.ha_lock, flags);
 		dm_device.num_pages_onlined += mem->nr_pages;
 		spin_unlock_irqrestore(&dm_device.ha_lock, flags);
+		/* Fall through */
 	case MEM_CANCEL_ONLINE:
 		if (dm_device.ha_waiting) {
 			dm_device.ha_waiting = false;
 			complete(&dm_device.ol_waitevent);
 		}
 		break;
 
 	case MEM_OFFLINE:
 		spin_lock_irqsave(&dm_device.ha_lock, flags);
 		dm_device.num_pages_onlined -= mem->nr_pages;
 		spin_unlock_irqrestore(&dm_device.ha_lock, flags);
 		break;
 	case MEM_GOING_ONLINE:
 	case MEM_GOING_OFFLINE:
 	case MEM_CANCEL_OFFLINE:
 		break;
 	}
 	return NOTIFY_OK;
 }
 
 static struct notifier_block hv_memory_nb = {
 	.notifier_call = hv_memory_notifier,
 	.priority = 0
 };
 
 /* Check if the particular page is backed and can be onlined and online it. */
 static void hv_page_online_one(struct hv_hotadd_state *has, struct page *pg)
 {
 	unsigned long cur_start_pgp;
 	unsigned long cur_end_pgp;
 	struct hv_hotadd_gap *gap;
 
 	cur_start_pgp = (unsigned long)pfn_to_page(has->covered_start_pfn);
 	cur_end_pgp = (unsigned long)pfn_to_page(has->covered_end_pfn);
 
 	/* The page is not backed. */
 	if (((unsigned long)pg < cur_start_pgp) ||
 	    ((unsigned long)pg >= cur_end_pgp))
 		return;
 
 	/* Check for gaps. */
 	list_for_each_entry(gap, &has->gap_list, list) {
 		cur_start_pgp = (unsigned long)
 			pfn_to_page(gap->start_pfn);
 		cur_end_pgp = (unsigned long)
 			pfn_to_page(gap->end_pfn);
 		if (((unsigned long)pg >= cur_start_pgp) &&
 		    ((unsigned long)pg < cur_end_pgp)) {
 			return;
 		}
 	}
 
 	/* This frame is currently backed; online the page. */
 	__online_page_set_limits(pg);
 	__online_page_increment_counters(pg);
 	__online_page_free(pg);
 }
 
 static void hv_bring_pgs_online(struct hv_hotadd_state *has,
 				unsigned long start_pfn, unsigned long size)
 {
 	int i;
 
 	pr_debug("Online %lu pages starting at pfn 0x%lx\n", size, start_pfn);
 	for (i = 0; i < size; i++)
 		hv_page_online_one(has, pfn_to_page(start_pfn + i));
 }
 
 static void hv_mem_hot_add(unsigned long start, unsigned long size,
 				unsigned long pfn_count,
 				struct hv_hotadd_state *has)
 {
 	int ret = 0;
 	int i, nid;
 	unsigned long start_pfn;
 	unsigned long processed_pfn;
 	unsigned long total_pfn = pfn_count;
 	unsigned long flags;
 
 	for (i = 0; i < (size/HA_CHUNK); i++) {
 		start_pfn = start + (i * HA_CHUNK);
 
 		spin_lock_irqsave(&dm_device.ha_lock, flags);
 		has->ha_end_pfn +=  HA_CHUNK;
 
 		if (total_pfn > HA_CHUNK) {
 			processed_pfn = HA_CHUNK;
 			total_pfn -= HA_CHUNK;
 		} else {
 			processed_pfn = total_pfn;
 			total_pfn = 0;
 		}
 
 		has->covered_end_pfn +=  processed_pfn;
 		spin_unlock_irqrestore(&dm_device.ha_lock, flags);
 
 		init_completion(&dm_device.ol_waitevent);
 		dm_device.ha_waiting = !memhp_auto_online;
 
 		nid = memory_add_physaddr_to_nid(PFN_PHYS(start_pfn));
 		ret = add_memory(nid, PFN_PHYS((start_pfn)),
 				(HA_CHUNK << PAGE_SHIFT));
 
 		if (ret) {
 			pr_warn("hot_add memory failed error is %d\n", ret);
 			if (ret == -EEXIST) {
 				/*
 				 * This error indicates that the error
 				 * is not a transient failure. This is the
 				 * case where the guest's physical address map
 				 * precludes hot adding memory. Stop all further
 				 * memory hot-add.
 				 */
 				do_hot_add = false;
 			}
 			spin_lock_irqsave(&dm_device.ha_lock, flags);
 			has->ha_end_pfn -= HA_CHUNK;
 			has->covered_end_pfn -=  processed_pfn;
 			spin_unlock_irqrestore(&dm_device.ha_lock, flags);
 			break;
 		}
 
 		/*
 		 * Wait for the memory block to be onlined when memory onlining
 		 * is done outside of kernel (memhp_auto_online). Since the hot
 		 * add has succeeded, it is ok to proceed even if the pages in
 		 * the hot added region have not been "onlined" within the
 		 * allowed time.
 		 */
 		if (dm_device.ha_waiting)
 			wait_for_completion_timeout(&dm_device.ol_waitevent,
 						    5*HZ);
 		post_status(&dm_device);
 	}
 
 	return;
 }
 
 static void hv_online_page(struct page *pg)
 {
 	struct hv_hotadd_state *has;
 	unsigned long cur_start_pgp;
 	unsigned long cur_end_pgp;
 	unsigned long flags;
 
 	spin_lock_irqsave(&dm_device.ha_lock, flags);
 	list_for_each_entry(has, &dm_device.ha_region_list, list) {
 		cur_start_pgp = (unsigned long)
 			pfn_to_page(has->start_pfn);
 		cur_end_pgp = (unsigned long)pfn_to_page(has->end_pfn);
 
 		/* The page belongs to a different HAS. */
 		if (((unsigned long)pg < cur_start_pgp) ||
 		    ((unsigned long)pg >= cur_end_pgp))
 			continue;
 
 		hv_page_online_one(has, pg);
 		break;
 	}
 	spin_unlock_irqrestore(&dm_device.ha_lock, flags);
 }
 
 static int pfn_covered(unsigned long start_pfn, unsigned long pfn_cnt)
 {
 	struct hv_hotadd_state *has;
 	struct hv_hotadd_gap *gap;
 	unsigned long residual, new_inc;
 	int ret = 0;
 	unsigned long flags;
 
 	spin_lock_irqsave(&dm_device.ha_lock, flags);
 	list_for_each_entry(has, &dm_device.ha_region_list, list) {
 		/*
 		 * If the pfn range we are dealing with is not in the current
 		 * "hot add block", move on.
 		 */
 		if (start_pfn < has->start_pfn || start_pfn >= has->end_pfn)
 			continue;
 
 		/*
 		 * If the current start pfn is not where the covered_end
 		 * is, create a gap and update covered_end_pfn.
 		 */
 		if (has->covered_end_pfn != start_pfn) {
 			gap = kzalloc(sizeof(struct hv_hotadd_gap), GFP_ATOMIC);
 			if (!gap) {
 				ret = -ENOMEM;
 				break;
 			}
 
 			INIT_LIST_HEAD(&gap->list);
 			gap->start_pfn = has->covered_end_pfn;
 			gap->end_pfn = start_pfn;
 			list_add_tail(&gap->list, &has->gap_list);
 
 			has->covered_end_pfn = start_pfn;
 		}
 
 		/*
 		 * If the current hot add-request extends beyond
 		 * our current limit; extend it.
 		 */
 		if ((start_pfn + pfn_cnt) > has->end_pfn) {
 			residual = (start_pfn + pfn_cnt - has->end_pfn);
 			/*
 			 * Extend the region by multiples of HA_CHUNK.
 			 */
 			new_inc = (residual / HA_CHUNK) * HA_CHUNK;
 			if (residual % HA_CHUNK)
 				new_inc += HA_CHUNK;
 
 			has->end_pfn += new_inc;
 		}
 
 		ret = 1;
 		break;
 	}
 	spin_unlock_irqrestore(&dm_device.ha_lock, flags);
 
 	return ret;
 }
 
 static unsigned long handle_pg_range(unsigned long pg_start,
 					unsigned long pg_count)
 {
 	unsigned long start_pfn = pg_start;
 	unsigned long pfn_cnt = pg_count;
 	unsigned long size;
 	struct hv_hotadd_state *has;
 	unsigned long pgs_ol = 0;
 	unsigned long old_covered_state;
 	unsigned long res = 0, flags;
 
 	pr_debug("Hot adding %lu pages starting at pfn 0x%lx.\n", pg_count,
 		pg_start);
 
 	spin_lock_irqsave(&dm_device.ha_lock, flags);
 	list_for_each_entry(has, &dm_device.ha_region_list, list) {
 		/*
 		 * If the pfn range we are dealing with is not in the current
 		 * "hot add block", move on.
 		 */
 		if (start_pfn < has->start_pfn || start_pfn >= has->end_pfn)
 			continue;
 
 		old_covered_state = has->covered_end_pfn;
 
 		if (start_pfn < has->ha_end_pfn) {
 			/*
 			 * This is the case where we are backing pages
 			 * in an already hot added region. Bring
 			 * these pages online first.
 			 */
 			pgs_ol = has->ha_end_pfn - start_pfn;
 			if (pgs_ol > pfn_cnt)
 				pgs_ol = pfn_cnt;
 
 			has->covered_end_pfn +=  pgs_ol;
 			pfn_cnt -= pgs_ol;
 			/*
 			 * Check if the corresponding memory block is already
 			 * online by checking its last previously backed page.
 			 * In case it is we need to bring rest (which was not
 			 * backed previously) online too.
 			 */
 			if (start_pfn > has->start_pfn &&
 			    !PageReserved(pfn_to_page(start_pfn - 1)))
 				hv_bring_pgs_online(has, start_pfn, pgs_ol);
 
 		}
 
 		if ((has->ha_end_pfn < has->end_pfn) && (pfn_cnt > 0)) {
 			/*
 			 * We have some residual hot add range
 			 * that needs to be hot added; hot add
 			 * it now. Hot add a multiple of
 			 * of HA_CHUNK that fully covers the pages
 			 * we have.
 			 */
 			size = (has->end_pfn - has->ha_end_pfn);
 			if (pfn_cnt <= size) {
 				size = ((pfn_cnt / HA_CHUNK) * HA_CHUNK);
 				if (pfn_cnt % HA_CHUNK)
 					size += HA_CHUNK;
 			} else {
 				pfn_cnt = size;
 			}
 			spin_unlock_irqrestore(&dm_device.ha_lock, flags);
 			hv_mem_hot_add(has->ha_end_pfn, size, pfn_cnt, has);
 			spin_lock_irqsave(&dm_device.ha_lock, flags);
 		}
 		/*
 		 * If we managed to online any pages that were given to us,
 		 * we declare success.
 		 */
 		res = has->covered_end_pfn - old_covered_state;
 		break;
 	}
 	spin_unlock_irqrestore(&dm_device.ha_lock, flags);
 
 	return res;
 }
 
 static unsigned long process_hot_add(unsigned long pg_start,
 					unsigned long pfn_cnt,
 					unsigned long rg_start,
 					unsigned long rg_size)
 {
 	struct hv_hotadd_state *ha_region = NULL;
 	int covered;
 	unsigned long flags;
 
 	if (pfn_cnt == 0)
 		return 0;
 
 	if (!dm_device.host_specified_ha_region) {
 		covered = pfn_covered(pg_start, pfn_cnt);
 		if (covered < 0)
 			return 0;
 
 		if (covered)
 			goto do_pg_range;
 	}
 
 	/*
 	 * If the host has specified a hot-add range; deal with it first.
 	 */
 
 	if (rg_size != 0) {
 		ha_region = kzalloc(sizeof(struct hv_hotadd_state), GFP_KERNEL);
 		if (!ha_region)
 			return 0;
 
 		INIT_LIST_HEAD(&ha_region->list);
 		INIT_LIST_HEAD(&ha_region->gap_list);
 
 		ha_region->start_pfn = rg_start;
 		ha_region->ha_end_pfn = rg_start;
 		ha_region->covered_start_pfn = pg_start;
 		ha_region->covered_end_pfn = pg_start;
 		ha_region->end_pfn = rg_start + rg_size;
 
 		spin_lock_irqsave(&dm_device.ha_lock, flags);
 		list_add_tail(&ha_region->list, &dm_device.ha_region_list);
 		spin_unlock_irqrestore(&dm_device.ha_lock, flags);
 	}
 
 do_pg_range:
 	/*
 	 * Process the page range specified; bringing them
 	 * online if possible.
 	 */
 	return handle_pg_range(pg_start, pfn_cnt);
 }
 
 #endif
 
 static void hot_add_req(struct work_struct *dummy)
 {
 	struct dm_hot_add_response resp;
 #ifdef CONFIG_MEMORY_HOTPLUG
 	unsigned long pg_start, pfn_cnt;
 	unsigned long rg_start, rg_sz;
 #endif
 	struct hv_dynmem_device *dm = &dm_device;
 
 	memset(&resp, 0, sizeof(struct dm_hot_add_response));
 	resp.hdr.type = DM_MEM_HOT_ADD_RESPONSE;
 	resp.hdr.size = sizeof(struct dm_hot_add_response);
 
 #ifdef CONFIG_MEMORY_HOTPLUG
 	pg_start = dm->ha_wrk.ha_page_range.finfo.start_page;
 	pfn_cnt = dm->ha_wrk.ha_page_range.finfo.page_cnt;
 
 	rg_start = dm->ha_wrk.ha_region_range.finfo.start_page;
 	rg_sz = dm->ha_wrk.ha_region_range.finfo.page_cnt;
 
 	if ((rg_start == 0) && (!dm->host_specified_ha_region)) {
 		unsigned long region_size;
 		unsigned long region_start;
 
 		/*
 		 * The host has not specified the hot-add region.
 		 * Based on the hot-add page range being specified,
 		 * compute a hot-add region that can cover the pages
 		 * that need to be hot-added while ensuring the alignment
 		 * and size requirements of Linux as it relates to hot-add.
 		 */
 		region_start = pg_start;
 		region_size = (pfn_cnt / HA_CHUNK) * HA_CHUNK;
 		if (pfn_cnt % HA_CHUNK)
 			region_size += HA_CHUNK;
 
 		region_start = (pg_start / HA_CHUNK) * HA_CHUNK;
 
 		rg_start = region_start;
 		rg_sz = region_size;
 	}
 
 	if (do_hot_add)
 		resp.page_count = process_hot_add(pg_start, pfn_cnt,
 						rg_start, rg_sz);
 
 	dm->num_pages_added += resp.page_count;
 #endif
 	/*
 	 * The result field of the response structure has the
 	 * following semantics:
 	 *
 	 * 1. If all or some pages hot-added: Guest should return success.
 	 *
 	 * 2. If no pages could be hot-added:
 	 *
 	 * If the guest returns success, then the host
 	 * will not attempt any further hot-add operations. This
 	 * signifies a permanent failure.
 	 *
 	 * If the guest returns failure, then this failure will be
 	 * treated as a transient failure and the host may retry the
 	 * hot-add operation after some delay.
 	 */
 	if (resp.page_count > 0)
 		resp.result = 1;
 	else if (!do_hot_add)
 		resp.result = 1;
 	else
 		resp.result = 0;
 
 	if (!do_hot_add || (resp.page_count == 0))
 		pr_info("Memory hot add failed\n");
 
 	dm->state = DM_INITIALIZED;
 	resp.hdr.trans_id = atomic_inc_return(&trans_id);
 	vmbus_sendpacket(dm->dev->channel, &resp,
 			sizeof(struct dm_hot_add_response),
 			(unsigned long)NULL,
 			VM_PKT_DATA_INBAND, 0);
 }
 
 static void process_info(struct hv_dynmem_device *dm, struct dm_info_msg *msg)
 {
 	struct dm_info_header *info_hdr;
 
 	info_hdr = (struct dm_info_header *)msg->info;
 
 	switch (info_hdr->type) {
 	case INFO_TYPE_MAX_PAGE_CNT:
 		if (info_hdr->data_size == sizeof(__u64)) {
 			__u64 *max_page_count = (__u64 *)&info_hdr[1];
 
 			pr_info("INFO_TYPE_MAX_PAGE_CNT = %llu\n",
 				*max_page_count);
 		}
 
 		break;
 	default:
 		pr_info("Received Unknown type: %d\n", info_hdr->type);
 	}
 }
 
 static unsigned long compute_balloon_floor(void)
 {
 	unsigned long min_pages;
 #define MB2PAGES(mb) ((mb) << (20 - PAGE_SHIFT))
 	/* Simple continuous piecewiese linear function:
 	 *  max MiB -> min MiB  gradient
 	 *       0         0
 	 *      16        16
 	 *      32        24
 	 *     128        72    (1/2)
 	 *     512       168    (1/4)
 	 *    2048       360    (1/8)
 	 *    8192       744    (1/16)
 	 *   32768      1512	(1/32)
 	 */
 	if (totalram_pages < MB2PAGES(128))
 		min_pages = MB2PAGES(8) + (totalram_pages >> 1);
 	else if (totalram_pages < MB2PAGES(512))
 		min_pages = MB2PAGES(40) + (totalram_pages >> 2);
 	else if (totalram_pages < MB2PAGES(2048))
 		min_pages = MB2PAGES(104) + (totalram_pages >> 3);
 	else if (totalram_pages < MB2PAGES(8192))
 		min_pages = MB2PAGES(232) + (totalram_pages >> 4);
 	else
 		min_pages = MB2PAGES(488) + (totalram_pages >> 5);
 #undef MB2PAGES
 	return min_pages;
 }
 
 /*
  * Post our status as it relates memory pressure to the
  * host. Host expects the guests to post this status
  * periodically at 1 second intervals.
  *
  * The metrics specified in this protocol are very Windows
  * specific and so we cook up numbers here to convey our memory
  * pressure.
  */
 
 static void post_status(struct hv_dynmem_device *dm)
 {
 	struct dm_status status;
 	unsigned long now = jiffies;
 	unsigned long last_post = last_post_time;
 
 	if (pressure_report_delay > 0) {
 		--pressure_report_delay;
 		return;
 	}
 
 	if (!time_after(now, (last_post_time + HZ)))
 		return;
 
 	memset(&status, 0, sizeof(struct dm_status));
 	status.hdr.type = DM_STATUS_REPORT;
 	status.hdr.size = sizeof(struct dm_status);
 	status.hdr.trans_id = atomic_inc_return(&trans_id);
 
 	/*
 	 * The host expects the guest to report free and committed memory.
 	 * Furthermore, the host expects the pressure information to include
 	 * the ballooned out pages. For a given amount of memory that we are
 	 * managing we need to compute a floor below which we should not
 	 * balloon. Compute this and add it to the pressure report.
 	 * We also need to report all offline pages (num_pages_added -
 	 * num_pages_onlined) as committed to the host, otherwise it can try
 	 * asking us to balloon them out.
 	 */
 	status.num_avail = si_mem_available();
 	status.num_committed = vm_memory_committed() +
 		dm->num_pages_ballooned +
 		(dm->num_pages_added > dm->num_pages_onlined ?
 		 dm->num_pages_added - dm->num_pages_onlined : 0) +
 		compute_balloon_floor();
 
 	/*
 	 * If our transaction ID is no longer current, just don't
 	 * send the status. This can happen if we were interrupted
 	 * after we picked our transaction ID.
 	 */
 	if (status.hdr.trans_id != atomic_read(&trans_id))
 		return;
 
 	/*
 	 * If the last post time that we sampled has changed,
 	 * we have raced, don't post the status.
 	 */
 	if (last_post != last_post_time)
 		return;
 
 	last_post_time = jiffies;
 	vmbus_sendpacket(dm->dev->channel, &status,
 				sizeof(struct dm_status),
 				(unsigned long)NULL,
 				VM_PKT_DATA_INBAND, 0);
 
 }
 
 static void free_balloon_pages(struct hv_dynmem_device *dm,
 			 union dm_mem_page_range *range_array)
 {
 	int num_pages = range_array->finfo.page_cnt;
 	__u64 start_frame = range_array->finfo.start_page;
 	struct page *pg;
 	int i;
 
 	for (i = 0; i < num_pages; i++) {
 		pg = pfn_to_page(i + start_frame);
 		__free_page(pg);
 		dm->num_pages_ballooned--;
 	}
 }
 
 
 
 static unsigned int alloc_balloon_pages(struct hv_dynmem_device *dm,
 					unsigned int num_pages,
 					struct dm_balloon_response *bl_resp,
 					int alloc_unit)
 {
 	unsigned int i = 0;
 	struct page *pg;
 
 	if (num_pages < alloc_unit)
 		return 0;
 
 	for (i = 0; (i * alloc_unit) < num_pages; i++) {
 		if (bl_resp->hdr.size + sizeof(union dm_mem_page_range) >
 			PAGE_SIZE)
 			return i * alloc_unit;
 
 		/*
 		 * We execute this code in a thread context. Furthermore,
 		 * we don't want the kernel to try too hard.
 		 */
 		pg = alloc_pages(GFP_HIGHUSER | __GFP_NORETRY |
 				__GFP_NOMEMALLOC | __GFP_NOWARN,
 				get_order(alloc_unit << PAGE_SHIFT));
 
 		if (!pg)
 			return i * alloc_unit;
 
 		dm->num_pages_ballooned += alloc_unit;
 
 		/*
 		 * If we allocatted 2M pages; split them so we
 		 * can free them in any order we get.
 		 */
 
 		if (alloc_unit != 1)
 			split_page(pg, get_order(alloc_unit << PAGE_SHIFT));
 
 		bl_resp->range_count++;
 		bl_resp->range_array[i].finfo.start_page =
 			page_to_pfn(pg);
 		bl_resp->range_array[i].finfo.page_cnt = alloc_unit;
 		bl_resp->hdr.size += sizeof(union dm_mem_page_range);
 
 	}
 
 	return num_pages;
 }
 
 static void balloon_up(struct work_struct *dummy)
 {
 	unsigned int num_pages = dm_device.balloon_wrk.num_pages;
 	unsigned int num_ballooned = 0;
 	struct dm_balloon_response *bl_resp;
 	int alloc_unit;
 	int ret;
 	bool done = false;
 	int i;
 	long avail_pages;
 	unsigned long floor;
 
 	/* The host balloons pages in 2M granularity. */
 	WARN_ON_ONCE(num_pages % PAGES_IN_2M != 0);
 
 	/*
 	 * We will attempt 2M allocations. However, if we fail to
 	 * allocate 2M chunks, we will go back to 4k allocations.
 	 */
 	alloc_unit = 512;
 
 	avail_pages = si_mem_available();
 	floor = compute_balloon_floor();
 
 	/* Refuse to balloon below the floor, keep the 2M granularity. */
 	if (avail_pages < num_pages || avail_pages - num_pages < floor) {
 		pr_warn("Balloon request will be partially fulfilled. %s\n",
 			avail_pages < num_pages ? "Not enough memory." :
 			"Balloon floor reached.");
 
 		num_pages = avail_pages > floor ? (avail_pages - floor) : 0;
 		num_pages -= num_pages % PAGES_IN_2M;
 	}
 
 	while (!done) {
 		bl_resp = (struct dm_balloon_response *)send_buffer;
 		memset(send_buffer, 0, PAGE_SIZE);
 		bl_resp->hdr.type = DM_BALLOON_RESPONSE;
 		bl_resp->hdr.size = sizeof(struct dm_balloon_response);
 		bl_resp->more_pages = 1;
 
 		num_pages -= num_ballooned;
 		num_ballooned = alloc_balloon_pages(&dm_device, num_pages,
 						    bl_resp, alloc_unit);
 
 		if (alloc_unit != 1 && num_ballooned == 0) {
 			alloc_unit = 1;
 			continue;
 		}
 
 		if (num_ballooned == 0 || num_ballooned == num_pages) {
 			pr_debug("Ballooned %u out of %u requested pages.\n",
 				num_pages, dm_device.balloon_wrk.num_pages);
 
 			bl_resp->more_pages = 0;
 			done = true;
 			dm_device.state = DM_INITIALIZED;
 		}
 
 		/*
 		 * We are pushing a lot of data through the channel;
 		 * deal with transient failures caused because of the
 		 * lack of space in the ring buffer.
 		 */
 
 		do {
 			bl_resp->hdr.trans_id = atomic_inc_return(&trans_id);
 			ret = vmbus_sendpacket(dm_device.dev->channel,
 						bl_resp,
 						bl_resp->hdr.size,
 						(unsigned long)NULL,
 						VM_PKT_DATA_INBAND, 0);
 
 			if (ret == -EAGAIN)
 				msleep(20);
 			post_status(&dm_device);
 		} while (ret == -EAGAIN);
 
 		if (ret) {
 			/*
 			 * Free up the memory we allocatted.
 			 */
 			pr_info("Balloon response failed\n");
 
 			for (i = 0; i < bl_resp->range_count; i++)
 				free_balloon_pages(&dm_device,
 						 &bl_resp->range_array[i]);
 
 			done = true;
 		}
 	}
 
 }
 
 static void balloon_down(struct hv_dynmem_device *dm,
 			struct dm_unballoon_request *req)
 {
 	union dm_mem_page_range *range_array = req->range_array;
 	int range_count = req->range_count;
 	struct dm_unballoon_response resp;
 	int i;
 	unsigned int prev_pages_ballooned = dm->num_pages_ballooned;
 
 	for (i = 0; i < range_count; i++) {
 		free_balloon_pages(dm, &range_array[i]);
 		complete(&dm_device.config_event);
 	}
 
 	pr_debug("Freed %u ballooned pages.\n",
 		prev_pages_ballooned - dm->num_pages_ballooned);
 
 	if (req->more_pages == 1)
 		return;
 
 	memset(&resp, 0, sizeof(struct dm_unballoon_response));
 	resp.hdr.type = DM_UNBALLOON_RESPONSE;
 	resp.hdr.trans_id = atomic_inc_return(&trans_id);
 	resp.hdr.size = sizeof(struct dm_unballoon_response);
 
 	vmbus_sendpacket(dm_device.dev->channel, &resp,
 				sizeof(struct dm_unballoon_response),
 				(unsigned long)NULL,
 				VM_PKT_DATA_INBAND, 0);
 
 	dm->state = DM_INITIALIZED;
 }
 
 static void balloon_onchannelcallback(void *context);
 
 static int dm_thread_func(void *dm_dev)
 {
 	struct hv_dynmem_device *dm = dm_dev;
 
 	while (!kthread_should_stop()) {
 		wait_for_completion_interruptible_timeout(
 						&dm_device.config_event, 1*HZ);
 		/*
 		 * The host expects us to post information on the memory
 		 * pressure every second.
 		 */
 		reinit_completion(&dm_device.config_event);
 		post_status(dm);
 	}
 
 	return 0;
 }
 
 
 static void version_resp(struct hv_dynmem_device *dm,
 			struct dm_version_response *vresp)
 {
 	struct dm_version_request version_req;
 	int ret;
 
 	if (vresp->is_accepted) {
 		/*
 		 * We are done; wakeup the
 		 * context waiting for version
 		 * negotiation.
 		 */
 		complete(&dm->host_event);
 		return;
 	}
 	/*
 	 * If there are more versions to try, continue
 	 * with negotiations; if not
 	 * shutdown the service since we are not able
 	 * to negotiate a suitable version number
 	 * with the host.
 	 */
 	if (dm->next_version == 0)
 		goto version_error;
 
 	memset(&version_req, 0, sizeof(struct dm_version_request));
 	version_req.hdr.type = DM_VERSION_REQUEST;
 	version_req.hdr.size = sizeof(struct dm_version_request);
 	version_req.hdr.trans_id = atomic_inc_return(&trans_id);
 	version_req.version.version = dm->next_version;
 	dm->version = version_req.version.version;
 
 	/*
 	 * Set the next version to try in case current version fails.
 	 * Win7 protocol ought to be the last one to try.
 	 */
 	switch (version_req.version.version) {
 	case DYNMEM_PROTOCOL_VERSION_WIN8:
 		dm->next_version = DYNMEM_PROTOCOL_VERSION_WIN7;
 		version_req.is_last_attempt = 0;
 		break;
 	default:
 		dm->next_version = 0;
 		version_req.is_last_attempt = 1;
 	}
 
 	ret = vmbus_sendpacket(dm->dev->channel, &version_req,
 				sizeof(struct dm_version_request),
 				(unsigned long)NULL,
 				VM_PKT_DATA_INBAND, 0);
 
 	if (ret)
 		goto version_error;
 
 	return;
 
 version_error:
 	dm->state = DM_INIT_ERROR;
 	complete(&dm->host_event);
 }
 
 static void cap_resp(struct hv_dynmem_device *dm,
 			struct dm_capabilities_resp_msg *cap_resp)
 {
 	if (!cap_resp->is_accepted) {
 		pr_info("Capabilities not accepted by host\n");
 		dm->state = DM_INIT_ERROR;
 	}
 	complete(&dm->host_event);
 }
 
 static void balloon_onchannelcallback(void *context)
 {
 	struct hv_device *dev = context;
 	u32 recvlen;
 	u64 requestid;
 	struct dm_message *dm_msg;
 	struct dm_header *dm_hdr;
 	struct hv_dynmem_device *dm = hv_get_drvdata(dev);
 	struct dm_balloon *bal_msg;
 	struct dm_hot_add *ha_msg;
 	union dm_mem_page_range *ha_pg_range;
 	union dm_mem_page_range *ha_region;
 
 	memset(recv_buffer, 0, sizeof(recv_buffer));
 	vmbus_recvpacket(dev->channel, recv_buffer,
 			 PAGE_SIZE, &recvlen, &requestid);
 
 	if (recvlen > 0) {
 		dm_msg = (struct dm_message *)recv_buffer;
 		dm_hdr = &dm_msg->hdr;
 
 		switch (dm_hdr->type) {
 		case DM_VERSION_RESPONSE:
 			version_resp(dm,
 				 (struct dm_version_response *)dm_msg);
 			break;
 
 		case DM_CAPABILITIES_RESPONSE:
 			cap_resp(dm,
 				 (struct dm_capabilities_resp_msg *)dm_msg);
 			break;
 
 		case DM_BALLOON_REQUEST:
 			if (dm->state == DM_BALLOON_UP)
 				pr_warn("Currently ballooning\n");
 			bal_msg = (struct dm_balloon *)recv_buffer;
 			dm->state = DM_BALLOON_UP;
 			dm_device.balloon_wrk.num_pages = bal_msg->num_pages;
 			schedule_work(&dm_device.balloon_wrk.wrk);
 			break;
 
 		case DM_UNBALLOON_REQUEST:
 			dm->state = DM_BALLOON_DOWN;
 			balloon_down(dm,
 				 (struct dm_unballoon_request *)recv_buffer);
 			break;
 
 		case DM_MEM_HOT_ADD_REQUEST:
 			if (dm->state == DM_HOT_ADD)
 				pr_warn("Currently hot-adding\n");
 			dm->state = DM_HOT_ADD;
 			ha_msg = (struct dm_hot_add *)recv_buffer;
 			if (ha_msg->hdr.size == sizeof(struct dm_hot_add)) {
 				/*
 				 * This is a normal hot-add request specifying
 				 * hot-add memory.
 				 */
 				dm->host_specified_ha_region = false;
 				ha_pg_range = &ha_msg->range;
 				dm->ha_wrk.ha_page_range = *ha_pg_range;
 				dm->ha_wrk.ha_region_range.page_range = 0;
 			} else {
 				/*
 				 * Host is specifying that we first hot-add
 				 * a region and then partially populate this
 				 * region.
 				 */
 				dm->host_specified_ha_region = true;
 				ha_pg_range = &ha_msg->range;
 				ha_region = &ha_pg_range[1];
 				dm->ha_wrk.ha_page_range = *ha_pg_range;
 				dm->ha_wrk.ha_region_range = *ha_region;
 			}
 			schedule_work(&dm_device.ha_wrk.wrk);
 			break;
 
 		case DM_INFO_MESSAGE:
 			process_info(dm, (struct dm_info_msg *)dm_msg);
 			break;
 
 		default:
 			pr_err("Unhandled message: type: %d\n", dm_hdr->type);
 
 		}
 	}
 
 }
 
 static int balloon_probe(struct hv_device *dev,
 			const struct hv_vmbus_device_id *dev_id)
 {
 	int ret;
 	unsigned long t;
 	struct dm_version_request version_req;
 	struct dm_capabilities cap_msg;
 
 #ifdef CONFIG_MEMORY_HOTPLUG
 	do_hot_add = hot_add;
 #else
 	do_hot_add = false;
 #endif
 
 	/*
 	 * First allocate a send buffer.
 	 */
 
 	send_buffer = kmalloc(PAGE_SIZE, GFP_KERNEL);
 	if (!send_buffer)
 		return -ENOMEM;
 
 	ret = vmbus_open(dev->channel, dm_ring_size, dm_ring_size, NULL, 0,
 			balloon_onchannelcallback, dev);
 
 	if (ret)
 		goto probe_error0;
 
 	dm_device.dev = dev;
 	dm_device.state = DM_INITIALIZING;
 	dm_device.next_version = DYNMEM_PROTOCOL_VERSION_WIN8;
 	init_completion(&dm_device.host_event);
 	init_completion(&dm_device.config_event);
 	INIT_LIST_HEAD(&dm_device.ha_region_list);
 	spin_lock_init(&dm_device.ha_lock);
 	INIT_WORK(&dm_device.balloon_wrk.wrk, balloon_up);
 	INIT_WORK(&dm_device.ha_wrk.wrk, hot_add_req);
 	dm_device.host_specified_ha_region = false;
 
 	dm_device.thread =
 		 kthread_run(dm_thread_func, &dm_device, "hv_balloon");
 	if (IS_ERR(dm_device.thread)) {
 		ret = PTR_ERR(dm_device.thread);
 		goto probe_error1;
 	}
 
 #ifdef CONFIG_MEMORY_HOTPLUG
 	set_online_page_callback(&hv_online_page);
 	register_memory_notifier(&hv_memory_nb);
 #endif
 
 	hv_set_drvdata(dev, &dm_device);
 	/*
 	 * Initiate the hand shake with the host and negotiate
 	 * a version that the host can support. We start with the
 	 * highest version number and go down if the host cannot
 	 * support it.
 	 */
 	memset(&version_req, 0, sizeof(struct dm_version_request));
 	version_req.hdr.type = DM_VERSION_REQUEST;
 	version_req.hdr.size = sizeof(struct dm_version_request);
 	version_req.hdr.trans_id = atomic_inc_return(&trans_id);
 	version_req.version.version = DYNMEM_PROTOCOL_VERSION_WIN10;
 	version_req.is_last_attempt = 0;
 	dm_device.version = version_req.version.version;
 
 	ret = vmbus_sendpacket(dev->channel, &version_req,
 				sizeof(struct dm_version_request),
 				(unsigned long)NULL,
 				VM_PKT_DATA_INBAND, 0);
 	if (ret)
 		goto probe_error2;
 
 	t = wait_for_completion_timeout(&dm_device.host_event, 5*HZ);
 	if (t == 0) {
 		ret = -ETIMEDOUT;
 		goto probe_error2;
 	}
 
 	/*
 	 * If we could not negotiate a compatible version with the host
 	 * fail the probe function.
 	 */
 	if (dm_device.state == DM_INIT_ERROR) {
 		ret = -ETIMEDOUT;
 		goto probe_error2;
 	}
 
 	pr_info("Using Dynamic Memory protocol version %u.%u\n",
 		DYNMEM_MAJOR_VERSION(dm_device.version),
 		DYNMEM_MINOR_VERSION(dm_device.version));
 
 	/*
 	 * Now submit our capabilities to the host.
 	 */
 	memset(&cap_msg, 0, sizeof(struct dm_capabilities));
 	cap_msg.hdr.type = DM_CAPABILITIES_REPORT;
 	cap_msg.hdr.size = sizeof(struct dm_capabilities);
 	cap_msg.hdr.trans_id = atomic_inc_return(&trans_id);
 
 	cap_msg.caps.cap_bits.balloon = 1;
 	cap_msg.caps.cap_bits.hot_add = 1;
 
 	/*
 	 * Specify our alignment requirements as it relates
 	 * memory hot-add. Specify 128MB alignment.
 	 */
 	cap_msg.caps.cap_bits.hot_add_alignment = 7;
 
 	/*
 	 * Currently the host does not use these
 	 * values and we set them to what is done in the
 	 * Windows driver.
 	 */
 	cap_msg.min_page_cnt = 0;
 	cap_msg.max_page_number = -1;
 
 	ret = vmbus_sendpacket(dev->channel, &cap_msg,
 				sizeof(struct dm_capabilities),
 				(unsigned long)NULL,
 				VM_PKT_DATA_INBAND, 0);
 	if (ret)
 		goto probe_error2;
 
 	t = wait_for_completion_timeout(&dm_device.host_event, 5*HZ);
 	if (t == 0) {
 		ret = -ETIMEDOUT;
 		goto probe_error2;
 	}
 
 	/*
 	 * If the host does not like our capabilities,
 	 * fail the probe function.
 	 */
 	if (dm_device.state == DM_INIT_ERROR) {
 		ret = -ETIMEDOUT;
 		goto probe_error2;
 	}
 
 	dm_device.state = DM_INITIALIZED;
 
 	return 0;
 
 probe_error2:
 #ifdef CONFIG_MEMORY_HOTPLUG
 	restore_online_page_callback(&hv_online_page);
 #endif
 	kthread_stop(dm_device.thread);
 
 probe_error1:
 	vmbus_close(dev->channel);
 probe_error0:
 	kfree(send_buffer);
 	return ret;
 }
 
 static int balloon_remove(struct hv_device *dev)
 {
 	struct hv_dynmem_device *dm = hv_get_drvdata(dev);
 	struct hv_hotadd_state *has, *tmp;
 	struct hv_hotadd_gap *gap, *tmp_gap;
 	unsigned long flags;
 
 	if (dm->num_pages_ballooned != 0)
 		pr_warn("Ballooned pages: %d\n", dm->num_pages_ballooned);
 
 	cancel_work_sync(&dm->balloon_wrk.wrk);
 	cancel_work_sync(&dm->ha_wrk.wrk);
 
 	vmbus_close(dev->channel);
 	kthread_stop(dm->thread);
 	kfree(send_buffer);
 #ifdef CONFIG_MEMORY_HOTPLUG
 	restore_online_page_callback(&hv_online_page);
 	unregister_memory_notifier(&hv_memory_nb);
 #endif
 	spin_lock_irqsave(&dm_device.ha_lock, flags);
 	list_for_each_entry_safe(has, tmp, &dm->ha_region_list, list) {
 		list_for_each_entry_safe(gap, tmp_gap, &has->gap_list, list) {
 			list_del(&gap->list);
 			kfree(gap);
 		}
 		list_del(&has->list);
 		kfree(has);
 	}
 	spin_unlock_irqrestore(&dm_device.ha_lock, flags);
 
 	return 0;
 }
 
 static const struct hv_vmbus_device_id id_table[] = {
 	/* Dynamic Memory Class ID */
 	/* 525074DC-8985-46e2-8057-A307DC18A502 */
 	{ HV_DM_GUID, },
 	{ },
 };
 
 MODULE_DEVICE_TABLE(vmbus, id_table);
 
 static  struct hv_driver balloon_drv = {
 	.name = "hv_balloon",
 	.id_table = id_table,
 	.probe =  balloon_probe,
 	.remove =  balloon_remove,
 };
 
 static int __init init_balloon_drv(void)
 {
 
 	return vmbus_driver_register(&balloon_drv);
 }
 
 module_init(init_balloon_drv);
 
 MODULE_DESCRIPTION("Hyper-V Balloon");
 MODULE_LICENSE("GPL");
diff --git a/drivers/hv/hv_fcopy.c b/drivers/hv/hv_fcopy.c
index 8b2ba98831ec..9aee6014339d 100644
--- a/drivers/hv/hv_fcopy.c
+++ b/drivers/hv/hv_fcopy.c
@@ -1,348 +1,365 @@
 /*
  * An implementation of file copy service.
  *
  * Copyright (C) 2014, Microsoft, Inc.
  *
  * Author : K. Y. Srinivasan <ksrinivasan@novell.com>
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 as published
  * by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful, but
  * WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, GOOD TITLE or
  * NON INFRINGEMENT.  See the GNU General Public License for more
  * details.
  *
  */
 
 #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
 
 #include <linux/nls.h>
 #include <linux/workqueue.h>
 #include <linux/hyperv.h>
 #include <linux/sched.h>
 
 #include "hyperv_vmbus.h"
 #include "hv_utils_transport.h"
 
 #define WIN8_SRV_MAJOR		1
 #define WIN8_SRV_MINOR		1
 #define WIN8_SRV_VERSION	(WIN8_SRV_MAJOR << 16 | WIN8_SRV_MINOR)
 
+#define FCOPY_VER_COUNT 1
+static const int fcopy_versions[] = {
+	WIN8_SRV_VERSION
+};
+
+#define FW_VER_COUNT 1
+static const int fw_versions[] = {
+	UTIL_FW_VERSION
+};
+
 /*
  * Global state maintained for transaction that is being processed.
  * For a class of integration services, including the "file copy service",
  * the specified protocol is a "request/response" protocol which means that
  * there can only be single outstanding transaction from the host at any
  * given point in time. We use this to simplify memory management in this
  * driver - we cache and process only one message at a time.
  *
  * While the request/response protocol is guaranteed by the host, we further
  * ensure this by serializing packet processing in this driver - we do not
  * read additional packets from the VMBUs until the current packet is fully
  * handled.
  */
 
 static struct {
 	int state;   /* hvutil_device_state */
 	int recv_len; /* number of bytes received. */
 	struct hv_fcopy_hdr  *fcopy_msg; /* current message */
 	struct vmbus_channel *recv_channel; /* chn we got the request */
 	u64 recv_req_id; /* request ID. */
 } fcopy_transaction;
 
 static void fcopy_respond_to_host(int error);
 static void fcopy_send_data(struct work_struct *dummy);
 static void fcopy_timeout_func(struct work_struct *dummy);
 static DECLARE_DELAYED_WORK(fcopy_timeout_work, fcopy_timeout_func);
 static DECLARE_WORK(fcopy_send_work, fcopy_send_data);
 static const char fcopy_devname[] = "vmbus/hv_fcopy";
 static u8 *recv_buffer;
 static struct hvutil_transport *hvt;
+static struct completion release_event;
 /*
  * This state maintains the version number registered by the daemon.
  */
 static int dm_reg_value;
 
 static void fcopy_poll_wrapper(void *channel)
 {
 	/* Transaction is finished, reset the state here to avoid races. */
 	fcopy_transaction.state = HVUTIL_READY;
 	hv_fcopy_onchannelcallback(channel);
 }
 
 static void fcopy_timeout_func(struct work_struct *dummy)
 {
 	/*
 	 * If the timer fires, the user-mode component has not responded;
 	 * process the pending transaction.
 	 */
 	fcopy_respond_to_host(HV_E_FAIL);
 	hv_poll_channel(fcopy_transaction.recv_channel, fcopy_poll_wrapper);
 }
 
 static void fcopy_register_done(void)
 {
 	pr_debug("FCP: userspace daemon registered\n");
 	hv_poll_channel(fcopy_transaction.recv_channel, fcopy_poll_wrapper);
 }
 
 static int fcopy_handle_handshake(u32 version)
 {
 	u32 our_ver = FCOPY_CURRENT_VERSION;
 
 	switch (version) {
 	case FCOPY_VERSION_0:
 		/* Daemon doesn't expect us to reply */
 		dm_reg_value = version;
 		break;
 	case FCOPY_VERSION_1:
 		/* Daemon expects us to reply with our own version */
 		if (hvutil_transport_send(hvt, &our_ver, sizeof(our_ver),
 		    fcopy_register_done))
 			return -EFAULT;
 		dm_reg_value = version;
 		break;
 	default:
 		/*
 		 * For now we will fail the registration.
 		 * If and when we have multiple versions to
 		 * deal with, we will be backward compatible.
 		 * We will add this code when needed.
 		 */
 		return -EINVAL;
 	}
 	pr_debug("FCP: userspace daemon ver. %d connected\n", version);
 	return 0;
 }
 
 static void fcopy_send_data(struct work_struct *dummy)
 {
 	struct hv_start_fcopy *smsg_out = NULL;
 	int operation = fcopy_transaction.fcopy_msg->operation;
 	struct hv_start_fcopy *smsg_in;
 	void *out_src;
 	int rc, out_len;
 
 	/*
 	 * The  strings sent from the host are encoded in
 	 * in utf16; convert it to utf8 strings.
 	 * The host assures us that the utf16 strings will not exceed
 	 * the max lengths specified. We will however, reserve room
 	 * for the string terminating character - in the utf16s_utf8s()
 	 * function we limit the size of the buffer where the converted
 	 * string is placed to W_MAX_PATH -1 to guarantee
 	 * that the strings can be properly terminated!
 	 */
 
 	switch (operation) {
 	case START_FILE_COPY:
 		out_len = sizeof(struct hv_start_fcopy);
 		smsg_out = kzalloc(sizeof(*smsg_out), GFP_KERNEL);
 		if (!smsg_out)
 			return;
 
 		smsg_out->hdr.operation = operation;
 		smsg_in = (struct hv_start_fcopy *)fcopy_transaction.fcopy_msg;
 
 		utf16s_to_utf8s((wchar_t *)smsg_in->file_name, W_MAX_PATH,
 				UTF16_LITTLE_ENDIAN,
 				(__u8 *)&smsg_out->file_name, W_MAX_PATH - 1);
 
 		utf16s_to_utf8s((wchar_t *)smsg_in->path_name, W_MAX_PATH,
 				UTF16_LITTLE_ENDIAN,
 				(__u8 *)&smsg_out->path_name, W_MAX_PATH - 1);
 
 		smsg_out->copy_flags = smsg_in->copy_flags;
 		smsg_out->file_size = smsg_in->file_size;
 		out_src = smsg_out;
 		break;
 
 	default:
 		out_src = fcopy_transaction.fcopy_msg;
 		out_len = fcopy_transaction.recv_len;
 		break;
 	}
 
 	fcopy_transaction.state = HVUTIL_USERSPACE_REQ;
 	rc = hvutil_transport_send(hvt, out_src, out_len, NULL);
 	if (rc) {
 		pr_debug("FCP: failed to communicate to the daemon: %d\n", rc);
 		if (cancel_delayed_work_sync(&fcopy_timeout_work)) {
 			fcopy_respond_to_host(HV_E_FAIL);
 			fcopy_transaction.state = HVUTIL_READY;
 		}
 	}
 	kfree(smsg_out);
 
 	return;
 }
 
 /*
  * Send a response back to the host.
  */
 
 static void
 fcopy_respond_to_host(int error)
 {
 	struct icmsg_hdr *icmsghdr;
 	u32 buf_len;
 	struct vmbus_channel *channel;
 	u64 req_id;
 
 	/*
 	 * Copy the global state for completing the transaction. Note that
 	 * only one transaction can be active at a time. This is guaranteed
 	 * by the file copy protocol implemented by the host. Furthermore,
 	 * the "transaction active" state we maintain ensures that there can
 	 * only be one active transaction at a time.
 	 */
 
 	buf_len = fcopy_transaction.recv_len;
 	channel = fcopy_transaction.recv_channel;
 	req_id = fcopy_transaction.recv_req_id;
 
 	icmsghdr = (struct icmsg_hdr *)
 			&recv_buffer[sizeof(struct vmbuspipe_hdr)];
 
 	if (channel->onchannel_callback == NULL)
 		/*
 		 * We have raced with util driver being unloaded;
 		 * silently return.
 		 */
 		return;
 
 	icmsghdr->status = error;
 	icmsghdr->icflags = ICMSGHDRFLAG_TRANSACTION | ICMSGHDRFLAG_RESPONSE;
 	vmbus_sendpacket(channel, recv_buffer, buf_len, req_id,
 				VM_PKT_DATA_INBAND, 0);
 }
 
 void hv_fcopy_onchannelcallback(void *context)
 {
 	struct vmbus_channel *channel = context;
 	u32 recvlen;
 	u64 requestid;
 	struct hv_fcopy_hdr *fcopy_msg;
 	struct icmsg_hdr *icmsghdr;
-	struct icmsg_negotiate *negop = NULL;
-	int util_fw_version;
 	int fcopy_srv_version;
 
 	if (fcopy_transaction.state > HVUTIL_READY)
 		return;
 
 	vmbus_recvpacket(channel, recv_buffer, PAGE_SIZE * 2, &recvlen,
 			 &requestid);
 	if (recvlen <= 0)
 		return;
 
 	icmsghdr = (struct icmsg_hdr *)&recv_buffer[
 			sizeof(struct vmbuspipe_hdr)];
 	if (icmsghdr->icmsgtype == ICMSGTYPE_NEGOTIATE) {
-		util_fw_version = UTIL_FW_VERSION;
-		fcopy_srv_version = WIN8_SRV_VERSION;
-		vmbus_prep_negotiate_resp(icmsghdr, negop, recv_buffer,
-				util_fw_version, fcopy_srv_version);
+		if (vmbus_prep_negotiate_resp(icmsghdr, recv_buffer,
+				fw_versions, FW_VER_COUNT,
+				fcopy_versions, FCOPY_VER_COUNT,
+				NULL, &fcopy_srv_version)) {
+
+			pr_info("FCopy IC version %d.%d\n",
+				fcopy_srv_version >> 16,
+				fcopy_srv_version & 0xFFFF);
+		}
 	} else {
 		fcopy_msg = (struct hv_fcopy_hdr *)&recv_buffer[
 				sizeof(struct vmbuspipe_hdr) +
 				sizeof(struct icmsg_hdr)];
 
 		/*
 		 * Stash away this global state for completing the
 		 * transaction; note transactions are serialized.
 		 */
 
 		fcopy_transaction.recv_len = recvlen;
 		fcopy_transaction.recv_req_id = requestid;
 		fcopy_transaction.fcopy_msg = fcopy_msg;
 
 		if (fcopy_transaction.state < HVUTIL_READY) {
 			/* Userspace is not registered yet */
 			fcopy_respond_to_host(HV_E_FAIL);
 			return;
 		}
 		fcopy_transaction.state = HVUTIL_HOSTMSG_RECEIVED;
 
 		/*
 		 * Send the information to the user-level daemon.
 		 */
 		schedule_work(&fcopy_send_work);
 		schedule_delayed_work(&fcopy_timeout_work,
 				      HV_UTIL_TIMEOUT * HZ);
 		return;
 	}
 	icmsghdr->icflags = ICMSGHDRFLAG_TRANSACTION | ICMSGHDRFLAG_RESPONSE;
 	vmbus_sendpacket(channel, recv_buffer, recvlen, requestid,
 			VM_PKT_DATA_INBAND, 0);
 }
 
 /* Callback when data is received from userspace */
 static int fcopy_on_msg(void *msg, int len)
 {
 	int *val = (int *)msg;
 
 	if (len != sizeof(int))
 		return -EINVAL;
 
 	if (fcopy_transaction.state == HVUTIL_DEVICE_INIT)
 		return fcopy_handle_handshake(*val);
 
 	if (fcopy_transaction.state != HVUTIL_USERSPACE_REQ)
 		return -EINVAL;
 
 	/*
 	 * Complete the transaction by forwarding the result
 	 * to the host. But first, cancel the timeout.
 	 */
 	if (cancel_delayed_work_sync(&fcopy_timeout_work)) {
 		fcopy_transaction.state = HVUTIL_USERSPACE_RECV;
 		fcopy_respond_to_host(*val);
 		hv_poll_channel(fcopy_transaction.recv_channel,
 				fcopy_poll_wrapper);
 	}
 
 	return 0;
 }
 
 static void fcopy_on_reset(void)
 {
 	/*
 	 * The daemon has exited; reset the state.
 	 */
 	fcopy_transaction.state = HVUTIL_DEVICE_INIT;
 
 	if (cancel_delayed_work_sync(&fcopy_timeout_work))
 		fcopy_respond_to_host(HV_E_FAIL);
+	complete(&release_event);
 }
 
 int hv_fcopy_init(struct hv_util_service *srv)
 {
 	recv_buffer = srv->recv_buffer;
 	fcopy_transaction.recv_channel = srv->channel;
 
+	init_completion(&release_event);
 	/*
 	 * When this driver loads, the user level daemon that
 	 * processes the host requests may not yet be running.
 	 * Defer processing channel callbacks until the daemon
 	 * has registered.
 	 */
 	fcopy_transaction.state = HVUTIL_DEVICE_INIT;
 
 	hvt = hvutil_transport_init(fcopy_devname, 0, 0,
 				    fcopy_on_msg, fcopy_on_reset);
 	if (!hvt)
 		return -EFAULT;
 
 	return 0;
 }
 
 void hv_fcopy_deinit(void)
 {
 	fcopy_transaction.state = HVUTIL_DEVICE_DYING;
 	cancel_delayed_work_sync(&fcopy_timeout_work);
 	hvutil_transport_destroy(hvt);
+	wait_for_completion(&release_event);
 }
diff --git a/drivers/hv/hv_kvp.c b/drivers/hv/hv_kvp.c
index 5e1fdc8d32ab..de263712e247 100644
--- a/drivers/hv/hv_kvp.c
+++ b/drivers/hv/hv_kvp.c
@@ -1,750 +1,751 @@
 /*
  * An implementation of key value pair (KVP) functionality for Linux.
  *
  *
  * Copyright (C) 2010, Novell, Inc.
  * Author : K. Y. Srinivasan <ksrinivasan@novell.com>
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 as published
  * by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful, but
  * WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, GOOD TITLE or
  * NON INFRINGEMENT.  See the GNU General Public License for more
  * details.
  *
  * You should have received a copy of the GNU General Public License
  * along with this program; if not, write to the Free Software
  * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  *
  */
 #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
 
 #include <linux/net.h>
 #include <linux/nls.h>
 #include <linux/connector.h>
 #include <linux/workqueue.h>
 #include <linux/hyperv.h>
 
 #include "hyperv_vmbus.h"
 #include "hv_utils_transport.h"
 
 /*
  * Pre win8 version numbers used in ws2008 and ws 2008 r2 (win7)
  */
 #define WS2008_SRV_MAJOR	1
 #define WS2008_SRV_MINOR	0
 #define WS2008_SRV_VERSION     (WS2008_SRV_MAJOR << 16 | WS2008_SRV_MINOR)
 
 #define WIN7_SRV_MAJOR   3
 #define WIN7_SRV_MINOR   0
 #define WIN7_SRV_VERSION     (WIN7_SRV_MAJOR << 16 | WIN7_SRV_MINOR)
 
 #define WIN8_SRV_MAJOR   4
 #define WIN8_SRV_MINOR   0
 #define WIN8_SRV_VERSION     (WIN8_SRV_MAJOR << 16 | WIN8_SRV_MINOR)
 
+#define KVP_VER_COUNT 3
+static const int kvp_versions[] = {
+	WIN8_SRV_VERSION,
+	WIN7_SRV_VERSION,
+	WS2008_SRV_VERSION
+};
+
+#define FW_VER_COUNT 2
+static const int fw_versions[] = {
+	UTIL_FW_VERSION,
+	UTIL_WS2K8_FW_VERSION
+};
+
 /*
  * Global state maintained for transaction that is being processed. For a class
  * of integration services, including the "KVP service", the specified protocol
  * is a "request/response" protocol which means that there can only be single
  * outstanding transaction from the host at any given point in time. We use
  * this to simplify memory management in this driver - we cache and process
  * only one message at a time.
  *
  * While the request/response protocol is guaranteed by the host, we further
  * ensure this by serializing packet processing in this driver - we do not
  * read additional packets from the VMBUs until the current packet is fully
  * handled.
  */
 
 static struct {
 	int state;   /* hvutil_device_state */
 	int recv_len; /* number of bytes received. */
 	struct hv_kvp_msg  *kvp_msg; /* current message */
 	struct vmbus_channel *recv_channel; /* chn we got the request */
 	u64 recv_req_id; /* request ID. */
 } kvp_transaction;
 
 /*
  * This state maintains the version number registered by the daemon.
  */
 static int dm_reg_value;
 
 static void kvp_send_key(struct work_struct *dummy);
 
 
 static void kvp_respond_to_host(struct hv_kvp_msg *msg, int error);
 static void kvp_timeout_func(struct work_struct *dummy);
 static void kvp_host_handshake_func(struct work_struct *dummy);
 static void kvp_register(int);
 
 static DECLARE_DELAYED_WORK(kvp_timeout_work, kvp_timeout_func);
 static DECLARE_DELAYED_WORK(kvp_host_handshake_work, kvp_host_handshake_func);
 static DECLARE_WORK(kvp_sendkey_work, kvp_send_key);
 
 static const char kvp_devname[] = "vmbus/hv_kvp";
 static u8 *recv_buffer;
 static struct hvutil_transport *hvt;
+static struct completion release_event;
 /*
  * Register the kernel component with the user-level daemon.
  * As part of this registration, pass the LIC version number.
  * This number has no meaning, it satisfies the registration protocol.
  */
 #define HV_DRV_VERSION           "3.1"
 
 static void kvp_poll_wrapper(void *channel)
 {
 	/* Transaction is finished, reset the state here to avoid races. */
 	kvp_transaction.state = HVUTIL_READY;
 	hv_kvp_onchannelcallback(channel);
 }
 
 static void kvp_register_done(void)
 {
 	/*
 	 * If we're still negotiating with the host cancel the timeout
 	 * work to not poll the channel twice.
 	 */
 	pr_debug("KVP: userspace daemon registered\n");
 	cancel_delayed_work_sync(&kvp_host_handshake_work);
 	hv_poll_channel(kvp_transaction.recv_channel, kvp_poll_wrapper);
 }
 
 static void
 kvp_register(int reg_value)
 {
 
 	struct hv_kvp_msg *kvp_msg;
 	char *version;
 
 	kvp_msg = kzalloc(sizeof(*kvp_msg), GFP_KERNEL);
 
 	if (kvp_msg) {
 		version = kvp_msg->body.kvp_register.version;
 		kvp_msg->kvp_hdr.operation = reg_value;
 		strcpy(version, HV_DRV_VERSION);
 
 		hvutil_transport_send(hvt, kvp_msg, sizeof(*kvp_msg),
 				      kvp_register_done);
 		kfree(kvp_msg);
 	}
 }
 
 static void kvp_timeout_func(struct work_struct *dummy)
 {
 	/*
 	 * If the timer fires, the user-mode component has not responded;
 	 * process the pending transaction.
 	 */
 	kvp_respond_to_host(NULL, HV_E_FAIL);
 
 	hv_poll_channel(kvp_transaction.recv_channel, kvp_poll_wrapper);
 }
 
 static void kvp_host_handshake_func(struct work_struct *dummy)
 {
 	hv_poll_channel(kvp_transaction.recv_channel, hv_kvp_onchannelcallback);
 }
 
 static int kvp_handle_handshake(struct hv_kvp_msg *msg)
 {
 	switch (msg->kvp_hdr.operation) {
 	case KVP_OP_REGISTER:
 		dm_reg_value = KVP_OP_REGISTER;
 		pr_info("KVP: IP injection functionality not available\n");
 		pr_info("KVP: Upgrade the KVP daemon\n");
 		break;
 	case KVP_OP_REGISTER1:
 		dm_reg_value = KVP_OP_REGISTER1;
 		break;
 	default:
 		pr_info("KVP: incompatible daemon\n");
 		pr_info("KVP: KVP version: %d, Daemon version: %d\n",
 			KVP_OP_REGISTER1, msg->kvp_hdr.operation);
 		return -EINVAL;
 	}
 
 	/*
 	 * We have a compatible daemon; complete the handshake.
 	 */
 	pr_debug("KVP: userspace daemon ver. %d connected\n",
 		 msg->kvp_hdr.operation);
 	kvp_register(dm_reg_value);
 
 	return 0;
 }
 
 
 /*
  * Callback when data is received from user mode.
  */
 
 static int kvp_on_msg(void *msg, int len)
 {
 	struct hv_kvp_msg *message = (struct hv_kvp_msg *)msg;
 	struct hv_kvp_msg_enumerate *data;
 	int	error = 0;
 
 	if (len < sizeof(*message))
 		return -EINVAL;
 
 	/*
 	 * If we are negotiating the version information
 	 * with the daemon; handle that first.
 	 */
 
 	if (kvp_transaction.state < HVUTIL_READY) {
 		return kvp_handle_handshake(message);
 	}
 
 	/* We didn't send anything to userspace so the reply is spurious */
 	if (kvp_transaction.state < HVUTIL_USERSPACE_REQ)
 		return -EINVAL;
 
 	kvp_transaction.state = HVUTIL_USERSPACE_RECV;
 
 	/*
 	 * Based on the version of the daemon, we propagate errors from the
 	 * daemon differently.
 	 */
 
 	data = &message->body.kvp_enum_data;
 
 	switch (dm_reg_value) {
 	case KVP_OP_REGISTER:
 		/*
 		 * Null string is used to pass back error condition.
 		 */
 		if (data->data.key[0] == 0)
 			error = HV_S_CONT;
 		break;
 
 	case KVP_OP_REGISTER1:
 		/*
 		 * We use the message header information from
 		 * the user level daemon to transmit errors.
 		 */
 		error = message->error;
 		break;
 	}
 
 	/*
 	 * Complete the transaction by forwarding the key value
 	 * to the host. But first, cancel the timeout.
 	 */
 	if (cancel_delayed_work_sync(&kvp_timeout_work)) {
 		kvp_respond_to_host(message, error);
 		hv_poll_channel(kvp_transaction.recv_channel, kvp_poll_wrapper);
 	}
 
 	return 0;
 }
 
 
 static int process_ob_ipinfo(void *in_msg, void *out_msg, int op)
 {
 	struct hv_kvp_msg *in = in_msg;
 	struct hv_kvp_ip_msg *out = out_msg;
 	int len;
 
 	switch (op) {
 	case KVP_OP_GET_IP_INFO:
 		/*
 		 * Transform all parameters into utf16 encoding.
 		 */
 		len = utf8s_to_utf16s((char *)in->body.kvp_ip_val.ip_addr,
 				strlen((char *)in->body.kvp_ip_val.ip_addr),
 				UTF16_HOST_ENDIAN,
 				(wchar_t *)out->kvp_ip_val.ip_addr,
 				MAX_IP_ADDR_SIZE);
 		if (len < 0)
 			return len;
 
 		len = utf8s_to_utf16s((char *)in->body.kvp_ip_val.sub_net,
 				strlen((char *)in->body.kvp_ip_val.sub_net),
 				UTF16_HOST_ENDIAN,
 				(wchar_t *)out->kvp_ip_val.sub_net,
 				MAX_IP_ADDR_SIZE);
 		if (len < 0)
 			return len;
 
 		len = utf8s_to_utf16s((char *)in->body.kvp_ip_val.gate_way,
 				strlen((char *)in->body.kvp_ip_val.gate_way),
 				UTF16_HOST_ENDIAN,
 				(wchar_t *)out->kvp_ip_val.gate_way,
 				MAX_GATEWAY_SIZE);
 		if (len < 0)
 			return len;
 
 		len = utf8s_to_utf16s((char *)in->body.kvp_ip_val.dns_addr,
 				strlen((char *)in->body.kvp_ip_val.dns_addr),
 				UTF16_HOST_ENDIAN,
 				(wchar_t *)out->kvp_ip_val.dns_addr,
 				MAX_IP_ADDR_SIZE);
 		if (len < 0)
 			return len;
 
 		len = utf8s_to_utf16s((char *)in->body.kvp_ip_val.adapter_id,
 				strlen((char *)in->body.kvp_ip_val.adapter_id),
 				UTF16_HOST_ENDIAN,
 				(wchar_t *)out->kvp_ip_val.adapter_id,
 				MAX_IP_ADDR_SIZE);
 		if (len < 0)
 			return len;
 
 		out->kvp_ip_val.dhcp_enabled =
 			in->body.kvp_ip_val.dhcp_enabled;
 		out->kvp_ip_val.addr_family =
 			in->body.kvp_ip_val.addr_family;
 	}
 
 	return 0;
 }
 
 static void process_ib_ipinfo(void *in_msg, void *out_msg, int op)
 {
 	struct hv_kvp_ip_msg *in = in_msg;
 	struct hv_kvp_msg *out = out_msg;
 
 	switch (op) {
 	case KVP_OP_SET_IP_INFO:
 		/*
 		 * Transform all parameters into utf8 encoding.
 		 */
 		utf16s_to_utf8s((wchar_t *)in->kvp_ip_val.ip_addr,
 				MAX_IP_ADDR_SIZE,
 				UTF16_LITTLE_ENDIAN,
 				(__u8 *)out->body.kvp_ip_val.ip_addr,
 				MAX_IP_ADDR_SIZE);
 
 		utf16s_to_utf8s((wchar_t *)in->kvp_ip_val.sub_net,
 				MAX_IP_ADDR_SIZE,
 				UTF16_LITTLE_ENDIAN,
 				(__u8 *)out->body.kvp_ip_val.sub_net,
 				MAX_IP_ADDR_SIZE);
 
 		utf16s_to_utf8s((wchar_t *)in->kvp_ip_val.gate_way,
 				MAX_GATEWAY_SIZE,
 				UTF16_LITTLE_ENDIAN,
 				(__u8 *)out->body.kvp_ip_val.gate_way,
 				MAX_GATEWAY_SIZE);
 
 		utf16s_to_utf8s((wchar_t *)in->kvp_ip_val.dns_addr,
 				MAX_IP_ADDR_SIZE,
 				UTF16_LITTLE_ENDIAN,
 				(__u8 *)out->body.kvp_ip_val.dns_addr,
 				MAX_IP_ADDR_SIZE);
 
 		out->body.kvp_ip_val.dhcp_enabled = in->kvp_ip_val.dhcp_enabled;
 
 	default:
 		utf16s_to_utf8s((wchar_t *)in->kvp_ip_val.adapter_id,
 				MAX_ADAPTER_ID_SIZE,
 				UTF16_LITTLE_ENDIAN,
 				(__u8 *)out->body.kvp_ip_val.adapter_id,
 				MAX_ADAPTER_ID_SIZE);
 
 		out->body.kvp_ip_val.addr_family = in->kvp_ip_val.addr_family;
 	}
 }
 
 
 
 
 static void
 kvp_send_key(struct work_struct *dummy)
 {
 	struct hv_kvp_msg *message;
 	struct hv_kvp_msg *in_msg;
 	__u8 operation = kvp_transaction.kvp_msg->kvp_hdr.operation;
 	__u8 pool = kvp_transaction.kvp_msg->kvp_hdr.pool;
 	__u32 val32;
 	__u64 val64;
 	int rc;
 
 	/* The transaction state is wrong. */
 	if (kvp_transaction.state != HVUTIL_HOSTMSG_RECEIVED)
 		return;
 
 	message = kzalloc(sizeof(*message), GFP_KERNEL);
 	if (!message)
 		return;
 
 	message->kvp_hdr.operation = operation;
 	message->kvp_hdr.pool = pool;
 	in_msg = kvp_transaction.kvp_msg;
 
 	/*
 	 * The key/value strings sent from the host are encoded in
 	 * in utf16; convert it to utf8 strings.
 	 * The host assures us that the utf16 strings will not exceed
 	 * the max lengths specified. We will however, reserve room
 	 * for the string terminating character - in the utf16s_utf8s()
 	 * function we limit the size of the buffer where the converted
 	 * string is placed to HV_KVP_EXCHANGE_MAX_*_SIZE -1 to gaurantee
 	 * that the strings can be properly terminated!
 	 */
 
 	switch (message->kvp_hdr.operation) {
 	case KVP_OP_SET_IP_INFO:
 		process_ib_ipinfo(in_msg, message, KVP_OP_SET_IP_INFO);
 		break;
 	case KVP_OP_GET_IP_INFO:
 		process_ib_ipinfo(in_msg, message, KVP_OP_GET_IP_INFO);
 		break;
 	case KVP_OP_SET:
 		switch (in_msg->body.kvp_set.data.value_type) {
 		case REG_SZ:
 			/*
 			 * The value is a string - utf16 encoding.
 			 */
 			message->body.kvp_set.data.value_size =
 				utf16s_to_utf8s(
 				(wchar_t *)in_msg->body.kvp_set.data.value,
 				in_msg->body.kvp_set.data.value_size,
 				UTF16_LITTLE_ENDIAN,
 				message->body.kvp_set.data.value,
 				HV_KVP_EXCHANGE_MAX_VALUE_SIZE - 1) + 1;
 				break;
 
 		case REG_U32:
 			/*
 			 * The value is a 32 bit scalar.
 			 * We save this as a utf8 string.
 			 */
 			val32 = in_msg->body.kvp_set.data.value_u32;
 			message->body.kvp_set.data.value_size =
 				sprintf(message->body.kvp_set.data.value,
 					"%d", val32) + 1;
 			break;
 
 		case REG_U64:
 			/*
 			 * The value is a 64 bit scalar.
 			 * We save this as a utf8 string.
 			 */
 			val64 = in_msg->body.kvp_set.data.value_u64;
 			message->body.kvp_set.data.value_size =
 				sprintf(message->body.kvp_set.data.value,
 					"%llu", val64) + 1;
 			break;
 
 		}
 	case KVP_OP_GET:
 		message->body.kvp_set.data.key_size =
 			utf16s_to_utf8s(
 			(wchar_t *)in_msg->body.kvp_set.data.key,
 			in_msg->body.kvp_set.data.key_size,
 			UTF16_LITTLE_ENDIAN,
 			message->body.kvp_set.data.key,
 			HV_KVP_EXCHANGE_MAX_KEY_SIZE - 1) + 1;
 			break;
 
 	case KVP_OP_DELETE:
 		message->body.kvp_delete.key_size =
 			utf16s_to_utf8s(
 			(wchar_t *)in_msg->body.kvp_delete.key,
 			in_msg->body.kvp_delete.key_size,
 			UTF16_LITTLE_ENDIAN,
 			message->body.kvp_delete.key,
 			HV_KVP_EXCHANGE_MAX_KEY_SIZE - 1) + 1;
 			break;
 
 	case KVP_OP_ENUMERATE:
 		message->body.kvp_enum_data.index =
 			in_msg->body.kvp_enum_data.index;
 			break;
 	}
 
 	kvp_transaction.state = HVUTIL_USERSPACE_REQ;
 	rc = hvutil_transport_send(hvt, message, sizeof(*message), NULL);
 	if (rc) {
 		pr_debug("KVP: failed to communicate to the daemon: %d\n", rc);
 		if (cancel_delayed_work_sync(&kvp_timeout_work)) {
 			kvp_respond_to_host(message, HV_E_FAIL);
 			kvp_transaction.state = HVUTIL_READY;
 		}
 	}
 
 	kfree(message);
 
 	return;
 }
 
 /*
  * Send a response back to the host.
  */
 
 static void
 kvp_respond_to_host(struct hv_kvp_msg *msg_to_host, int error)
 {
 	struct hv_kvp_msg  *kvp_msg;
 	struct hv_kvp_exchg_msg_value  *kvp_data;
 	char	*key_name;
 	char	*value;
 	struct icmsg_hdr *icmsghdrp;
 	int	keylen = 0;
 	int	valuelen = 0;
 	u32	buf_len;
 	struct vmbus_channel *channel;
 	u64	req_id;
 	int ret;
 
 	/*
 	 * Copy the global state for completing the transaction. Note that
 	 * only one transaction can be active at a time.
 	 */
 
 	buf_len = kvp_transaction.recv_len;
 	channel = kvp_transaction.recv_channel;
 	req_id = kvp_transaction.recv_req_id;
 
 	icmsghdrp = (struct icmsg_hdr *)
 			&recv_buffer[sizeof(struct vmbuspipe_hdr)];
 
 	if (channel->onchannel_callback == NULL)
 		/*
 		 * We have raced with util driver being unloaded;
 		 * silently return.
 		 */
 		return;
 
 	icmsghdrp->status = error;
 
 	/*
 	 * If the error parameter is set, terminate the host's enumeration
 	 * on this pool.
 	 */
 	if (error) {
 		/*
 		 * Something failed or we have timedout;
 		 * terminate the current host-side iteration.
 		 */
 		goto response_done;
 	}
 
 	kvp_msg = (struct hv_kvp_msg *)
 			&recv_buffer[sizeof(struct vmbuspipe_hdr) +
 			sizeof(struct icmsg_hdr)];
 
 	switch (kvp_transaction.kvp_msg->kvp_hdr.operation) {
 	case KVP_OP_GET_IP_INFO:
 		ret = process_ob_ipinfo(msg_to_host,
 				 (struct hv_kvp_ip_msg *)kvp_msg,
 				 KVP_OP_GET_IP_INFO);
 		if (ret < 0)
 			icmsghdrp->status = HV_E_FAIL;
 
 		goto response_done;
 	case KVP_OP_SET_IP_INFO:
 		goto response_done;
 	case KVP_OP_GET:
 		kvp_data = &kvp_msg->body.kvp_get.data;
 		goto copy_value;
 
 	case KVP_OP_SET:
 	case KVP_OP_DELETE:
 		goto response_done;
 
 	default:
 		break;
 	}
 
 	kvp_data = &kvp_msg->body.kvp_enum_data.data;
 	key_name = msg_to_host->body.kvp_enum_data.data.key;
 
 	/*
 	 * The windows host expects the key/value pair to be encoded
 	 * in utf16. Ensure that the key/value size reported to the host
 	 * will be less than or equal to the MAX size (including the
 	 * terminating character).
 	 */
 	keylen = utf8s_to_utf16s(key_name, strlen(key_name), UTF16_HOST_ENDIAN,
 				(wchar_t *) kvp_data->key,
 				(HV_KVP_EXCHANGE_MAX_KEY_SIZE / 2) - 2);
 	kvp_data->key_size = 2*(keylen + 1); /* utf16 encoding */
 
 copy_value:
 	value = msg_to_host->body.kvp_enum_data.data.value;
 	valuelen = utf8s_to_utf16s(value, strlen(value), UTF16_HOST_ENDIAN,
 				(wchar_t *) kvp_data->value,
 				(HV_KVP_EXCHANGE_MAX_VALUE_SIZE / 2) - 2);
 	kvp_data->value_size = 2*(valuelen + 1); /* utf16 encoding */
 
 	/*
 	 * If the utf8s to utf16s conversion failed; notify host
 	 * of the error.
 	 */
 	if ((keylen < 0) || (valuelen < 0))
 		icmsghdrp->status = HV_E_FAIL;
 
 	kvp_data->value_type = REG_SZ; /* all our values are strings */
 
 response_done:
 	icmsghdrp->icflags = ICMSGHDRFLAG_TRANSACTION | ICMSGHDRFLAG_RESPONSE;
 
 	vmbus_sendpacket(channel, recv_buffer, buf_len, req_id,
 				VM_PKT_DATA_INBAND, 0);
 }
 
 /*
  * This callback is invoked when we get a KVP message from the host.
  * The host ensures that only one KVP transaction can be active at a time.
  * KVP implementation in Linux needs to forward the key to a user-mde
  * component to retrive the corresponding value. Consequently, we cannot
  * respond to the host in the conext of this callback. Since the host
  * guarantees that at most only one transaction can be active at a time,
  * we stash away the transaction state in a set of global variables.
  */
 
 void hv_kvp_onchannelcallback(void *context)
 {
 	struct vmbus_channel *channel = context;
 	u32 recvlen;
 	u64 requestid;
 
 	struct hv_kvp_msg *kvp_msg;
 
 	struct icmsg_hdr *icmsghdrp;
-	struct icmsg_negotiate *negop = NULL;
-	int util_fw_version;
 	int kvp_srv_version;
 	static enum {NEGO_NOT_STARTED,
 		     NEGO_IN_PROGRESS,
 		     NEGO_FINISHED} host_negotiatied = NEGO_NOT_STARTED;
 
 	if (host_negotiatied == NEGO_NOT_STARTED &&
 	    kvp_transaction.state < HVUTIL_READY) {
 		/*
 		 * If userspace daemon is not connected and host is asking
 		 * us to negotiate we need to delay to not lose messages.
 		 * This is important for Failover IP setting.
 		 */
 		host_negotiatied = NEGO_IN_PROGRESS;
 		schedule_delayed_work(&kvp_host_handshake_work,
 				      HV_UTIL_NEGO_TIMEOUT * HZ);
 		return;
 	}
 	if (kvp_transaction.state > HVUTIL_READY)
 		return;
 
 	vmbus_recvpacket(channel, recv_buffer, PAGE_SIZE * 4, &recvlen,
 			 &requestid);
 
 	if (recvlen > 0) {
 		icmsghdrp = (struct icmsg_hdr *)&recv_buffer[
 			sizeof(struct vmbuspipe_hdr)];
 
 		if (icmsghdrp->icmsgtype == ICMSGTYPE_NEGOTIATE) {
-			/*
-			 * Based on the host, select appropriate
-			 * framework and service versions we will
-			 * negotiate.
-			 */
-			switch (vmbus_proto_version) {
-			case (VERSION_WS2008):
-				util_fw_version = UTIL_WS2K8_FW_VERSION;
-				kvp_srv_version = WS2008_SRV_VERSION;
-				break;
-			case (VERSION_WIN7):
-				util_fw_version = UTIL_FW_VERSION;
-				kvp_srv_version = WIN7_SRV_VERSION;
-				break;
-			default:
-				util_fw_version = UTIL_FW_VERSION;
-				kvp_srv_version = WIN8_SRV_VERSION;
+			if (vmbus_prep_negotiate_resp(icmsghdrp,
+				 recv_buffer, fw_versions, FW_VER_COUNT,
+				 kvp_versions, KVP_VER_COUNT,
+				 NULL, &kvp_srv_version)) {
+				pr_info("KVP IC version %d.%d\n",
+					kvp_srv_version >> 16,
+					kvp_srv_version & 0xFFFF);
 			}
-			vmbus_prep_negotiate_resp(icmsghdrp, negop,
-				 recv_buffer, util_fw_version,
-				 kvp_srv_version);
-
 		} else {
 			kvp_msg = (struct hv_kvp_msg *)&recv_buffer[
 				sizeof(struct vmbuspipe_hdr) +
 				sizeof(struct icmsg_hdr)];
 
 			/*
 			 * Stash away this global state for completing the
 			 * transaction; note transactions are serialized.
 			 */
 
 			kvp_transaction.recv_len = recvlen;
 			kvp_transaction.recv_req_id = requestid;
 			kvp_transaction.kvp_msg = kvp_msg;
 
 			if (kvp_transaction.state < HVUTIL_READY) {
 				/* Userspace is not registered yet */
 				kvp_respond_to_host(NULL, HV_E_FAIL);
 				return;
 			}
 			kvp_transaction.state = HVUTIL_HOSTMSG_RECEIVED;
 
 			/*
 			 * Get the information from the
 			 * user-mode component.
 			 * component. This transaction will be
 			 * completed when we get the value from
 			 * the user-mode component.
 			 * Set a timeout to deal with
 			 * user-mode not responding.
 			 */
 			schedule_work(&kvp_sendkey_work);
 			schedule_delayed_work(&kvp_timeout_work,
 					      HV_UTIL_TIMEOUT * HZ);
 
 			return;
 
 		}
 
 		icmsghdrp->icflags = ICMSGHDRFLAG_TRANSACTION
 			| ICMSGHDRFLAG_RESPONSE;
 
 		vmbus_sendpacket(channel, recv_buffer,
 				       recvlen, requestid,
 				       VM_PKT_DATA_INBAND, 0);
 
 		host_negotiatied = NEGO_FINISHED;
 	}
 
 }
 
 static void kvp_on_reset(void)
 {
 	if (cancel_delayed_work_sync(&kvp_timeout_work))
 		kvp_respond_to_host(NULL, HV_E_FAIL);
 	kvp_transaction.state = HVUTIL_DEVICE_INIT;
+	complete(&release_event);
 }
 
 int
 hv_kvp_init(struct hv_util_service *srv)
 {
 	recv_buffer = srv->recv_buffer;
 	kvp_transaction.recv_channel = srv->channel;
 
+	init_completion(&release_event);
 	/*
 	 * When this driver loads, the user level daemon that
 	 * processes the host requests may not yet be running.
 	 * Defer processing channel callbacks until the daemon
 	 * has registered.
 	 */
 	kvp_transaction.state = HVUTIL_DEVICE_INIT;
 
 	hvt = hvutil_transport_init(kvp_devname, CN_KVP_IDX, CN_KVP_VAL,
 				    kvp_on_msg, kvp_on_reset);
 	if (!hvt)
 		return -EFAULT;
 
 	return 0;
 }
 
 void hv_kvp_deinit(void)
 {
 	kvp_transaction.state = HVUTIL_DEVICE_DYING;
 	cancel_delayed_work_sync(&kvp_host_handshake_work);
 	cancel_delayed_work_sync(&kvp_timeout_work);
 	cancel_work_sync(&kvp_sendkey_work);
 	hvutil_transport_destroy(hvt);
+	wait_for_completion(&release_event);
 }
diff --git a/drivers/hv/hv_snapshot.c b/drivers/hv/hv_snapshot.c
index eee238cc60bd..bcc03f0748d6 100644
--- a/drivers/hv/hv_snapshot.c
+++ b/drivers/hv/hv_snapshot.c
@@ -1,385 +1,404 @@
 /*
  * An implementation of host initiated guest snapshot.
  *
  *
  * Copyright (C) 2013, Microsoft, Inc.
  * Author : K. Y. Srinivasan <kys@microsoft.com>
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 as published
  * by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful, but
  * WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, GOOD TITLE or
  * NON INFRINGEMENT.  See the GNU General Public License for more
  * details.
  *
  */
 #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
 
 #include <linux/net.h>
 #include <linux/nls.h>
 #include <linux/connector.h>
 #include <linux/workqueue.h>
 #include <linux/hyperv.h>
 
 #include "hyperv_vmbus.h"
 #include "hv_utils_transport.h"
 
 #define VSS_MAJOR  5
 #define VSS_MINOR  0
 #define VSS_VERSION    (VSS_MAJOR << 16 | VSS_MINOR)
 
+#define VSS_VER_COUNT 1
+static const int vss_versions[] = {
+	VSS_VERSION
+};
+
+#define FW_VER_COUNT 1
+static const int fw_versions[] = {
+	UTIL_FW_VERSION
+};
+
 /*
  * Timeout values are based on expecations from host
  */
 #define VSS_FREEZE_TIMEOUT (15 * 60)
 
 /*
  * Global state maintained for transaction that is being processed. For a class
  * of integration services, including the "VSS service", the specified protocol
  * is a "request/response" protocol which means that there can only be single
  * outstanding transaction from the host at any given point in time. We use
  * this to simplify memory management in this driver - we cache and process
  * only one message at a time.
  *
  * While the request/response protocol is guaranteed by the host, we further
  * ensure this by serializing packet processing in this driver - we do not
  * read additional packets from the VMBUs until the current packet is fully
  * handled.
  */
 
 static struct {
 	int state;   /* hvutil_device_state */
 	int recv_len; /* number of bytes received. */
 	struct vmbus_channel *recv_channel; /* chn we got the request */
 	u64 recv_req_id; /* request ID. */
 	struct hv_vss_msg  *msg; /* current message */
 } vss_transaction;
 
 
 static void vss_respond_to_host(int error);
 
 /*
  * This state maintains the version number registered by the daemon.
  */
 static int dm_reg_value;
 
 static const char vss_devname[] = "vmbus/hv_vss";
 static __u8 *recv_buffer;
 static struct hvutil_transport *hvt;
+static struct completion release_event;
 
 static void vss_timeout_func(struct work_struct *dummy);
 static void vss_handle_request(struct work_struct *dummy);
 
 static DECLARE_DELAYED_WORK(vss_timeout_work, vss_timeout_func);
 static DECLARE_WORK(vss_handle_request_work, vss_handle_request);
 
 static void vss_poll_wrapper(void *channel)
 {
 	/* Transaction is finished, reset the state here to avoid races. */
 	vss_transaction.state = HVUTIL_READY;
 	hv_vss_onchannelcallback(channel);
 }
 
 /*
  * Callback when data is received from user mode.
  */
 
 static void vss_timeout_func(struct work_struct *dummy)
 {
 	/*
 	 * Timeout waiting for userspace component to reply happened.
 	 */
 	pr_warn("VSS: timeout waiting for daemon to reply\n");
 	vss_respond_to_host(HV_E_FAIL);
 
 	hv_poll_channel(vss_transaction.recv_channel, vss_poll_wrapper);
 }
 
 static void vss_register_done(void)
 {
 	hv_poll_channel(vss_transaction.recv_channel, vss_poll_wrapper);
 	pr_debug("VSS: userspace daemon registered\n");
 }
 
 static int vss_handle_handshake(struct hv_vss_msg *vss_msg)
 {
 	u32 our_ver = VSS_OP_REGISTER1;
 
 	switch (vss_msg->vss_hdr.operation) {
 	case VSS_OP_REGISTER:
 		/* Daemon doesn't expect us to reply */
 		dm_reg_value = VSS_OP_REGISTER;
 		break;
 	case VSS_OP_REGISTER1:
 		/* Daemon expects us to reply with our own version */
 		if (hvutil_transport_send(hvt, &our_ver, sizeof(our_ver),
 					  vss_register_done))
 			return -EFAULT;
 		dm_reg_value = VSS_OP_REGISTER1;
 		break;
 	default:
 		return -EINVAL;
 	}
 	pr_info("VSS: userspace daemon ver. %d connected\n", dm_reg_value);
 	return 0;
 }
 
 static int vss_on_msg(void *msg, int len)
 {
 	struct hv_vss_msg *vss_msg = (struct hv_vss_msg *)msg;
 
 	if (len != sizeof(*vss_msg)) {
 		pr_debug("VSS: Message size does not match length\n");
 		return -EINVAL;
 	}
 
 	if (vss_msg->vss_hdr.operation == VSS_OP_REGISTER ||
 	    vss_msg->vss_hdr.operation == VSS_OP_REGISTER1) {
 		/*
 		 * Don't process registration messages if we're in the middle
 		 * of a transaction processing.
 		 */
 		if (vss_transaction.state > HVUTIL_READY) {
 			pr_debug("VSS: Got unexpected registration request\n");
 			return -EINVAL;
 		}
 
 		return vss_handle_handshake(vss_msg);
 	} else if (vss_transaction.state == HVUTIL_USERSPACE_REQ) {
 		vss_transaction.state = HVUTIL_USERSPACE_RECV;
 
 		if (vss_msg->vss_hdr.operation == VSS_OP_HOT_BACKUP)
 			vss_transaction.msg->vss_cf.flags =
 				VSS_HBU_NO_AUTO_RECOVERY;
 
 		if (cancel_delayed_work_sync(&vss_timeout_work)) {
 			vss_respond_to_host(vss_msg->error);
 			/* Transaction is finished, reset the state. */
 			hv_poll_channel(vss_transaction.recv_channel,
 					vss_poll_wrapper);
 		}
 	} else {
 		/* This is a spurious call! */
 		pr_debug("VSS: Transaction not active\n");
 		return -EINVAL;
 	}
 	return 0;
 }
 
 static void vss_send_op(void)
 {
 	int op = vss_transaction.msg->vss_hdr.operation;
 	int rc;
 	struct hv_vss_msg *vss_msg;
 
 	/* The transaction state is wrong. */
 	if (vss_transaction.state != HVUTIL_HOSTMSG_RECEIVED) {
 		pr_debug("VSS: Unexpected attempt to send to daemon\n");
 		return;
 	}
 
 	vss_msg = kzalloc(sizeof(*vss_msg), GFP_KERNEL);
 	if (!vss_msg)
 		return;
 
 	vss_msg->vss_hdr.operation = op;
 
 	vss_transaction.state = HVUTIL_USERSPACE_REQ;
 
 	schedule_delayed_work(&vss_timeout_work, op == VSS_OP_FREEZE ?
 			VSS_FREEZE_TIMEOUT * HZ : HV_UTIL_TIMEOUT * HZ);
 
 	rc = hvutil_transport_send(hvt, vss_msg, sizeof(*vss_msg), NULL);
 	if (rc) {
 		pr_warn("VSS: failed to communicate to the daemon: %d\n", rc);
 		if (cancel_delayed_work_sync(&vss_timeout_work)) {
 			vss_respond_to_host(HV_E_FAIL);
 			vss_transaction.state = HVUTIL_READY;
 		}
 	}
 
 	kfree(vss_msg);
 
 	return;
 }
 
 static void vss_handle_request(struct work_struct *dummy)
 {
 	switch (vss_transaction.msg->vss_hdr.operation) {
 	/*
 	 * Initiate a "freeze/thaw" operation in the guest.
 	 * We respond to the host once the operation is complete.
 	 *
 	 * We send the message to the user space daemon and the operation is
 	 * performed in the daemon.
 	 */
 	case VSS_OP_THAW:
 	case VSS_OP_FREEZE:
 	case VSS_OP_HOT_BACKUP:
 		if (vss_transaction.state < HVUTIL_READY) {
 			/* Userspace is not registered yet */
 			pr_debug("VSS: Not ready for request.\n");
 			vss_respond_to_host(HV_E_FAIL);
 			return;
 		}
 
 		pr_debug("VSS: Received request for op code: %d\n",
 			vss_transaction.msg->vss_hdr.operation);
 		vss_transaction.state = HVUTIL_HOSTMSG_RECEIVED;
 		vss_send_op();
 		return;
 	case VSS_OP_GET_DM_INFO:
 		vss_transaction.msg->dm_info.flags = 0;
 		break;
 	default:
 		break;
 	}
 
 	vss_respond_to_host(0);
 	hv_poll_channel(vss_transaction.recv_channel, vss_poll_wrapper);
 }
 
 /*
  * Send a response back to the host.
  */
 
 static void
 vss_respond_to_host(int error)
 {
 	struct icmsg_hdr *icmsghdrp;
 	u32	buf_len;
 	struct vmbus_channel *channel;
 	u64	req_id;
 
 	/*
 	 * Copy the global state for completing the transaction. Note that
 	 * only one transaction can be active at a time.
 	 */
 
 	buf_len = vss_transaction.recv_len;
 	channel = vss_transaction.recv_channel;
 	req_id = vss_transaction.recv_req_id;
 
 	icmsghdrp = (struct icmsg_hdr *)
 			&recv_buffer[sizeof(struct vmbuspipe_hdr)];
 
 	if (channel->onchannel_callback == NULL)
 		/*
 		 * We have raced with util driver being unloaded;
 		 * silently return.
 		 */
 		return;
 
 	icmsghdrp->status = error;
 
 	icmsghdrp->icflags = ICMSGHDRFLAG_TRANSACTION | ICMSGHDRFLAG_RESPONSE;
 
 	vmbus_sendpacket(channel, recv_buffer, buf_len, req_id,
 				VM_PKT_DATA_INBAND, 0);
 
 }
 
 /*
  * This callback is invoked when we get a VSS message from the host.
  * The host ensures that only one VSS transaction can be active at a time.
  */
 
 void hv_vss_onchannelcallback(void *context)
 {
 	struct vmbus_channel *channel = context;
 	u32 recvlen;
 	u64 requestid;
 	struct hv_vss_msg *vss_msg;
-
+	int vss_srv_version;
 
 	struct icmsg_hdr *icmsghdrp;
-	struct icmsg_negotiate *negop = NULL;
 
 	if (vss_transaction.state > HVUTIL_READY)
 		return;
 
 	vmbus_recvpacket(channel, recv_buffer, PAGE_SIZE * 2, &recvlen,
 			 &requestid);
 
 	if (recvlen > 0) {
 		icmsghdrp = (struct icmsg_hdr *)&recv_buffer[
 			sizeof(struct vmbuspipe_hdr)];
 
 		if (icmsghdrp->icmsgtype == ICMSGTYPE_NEGOTIATE) {
-			vmbus_prep_negotiate_resp(icmsghdrp, negop,
-				 recv_buffer, UTIL_FW_VERSION,
-				 VSS_VERSION);
+			if (vmbus_prep_negotiate_resp(icmsghdrp,
+				 recv_buffer, fw_versions, FW_VER_COUNT,
+				 vss_versions, VSS_VER_COUNT,
+				 NULL, &vss_srv_version)) {
+
+				pr_info("VSS IC version %d.%d\n",
+					vss_srv_version >> 16,
+					vss_srv_version & 0xFFFF);
+			}
 		} else {
 			vss_msg = (struct hv_vss_msg *)&recv_buffer[
 				sizeof(struct vmbuspipe_hdr) +
 				sizeof(struct icmsg_hdr)];
 
 			/*
 			 * Stash away this global state for completing the
 			 * transaction; note transactions are serialized.
 			 */
 
 			vss_transaction.recv_len = recvlen;
 			vss_transaction.recv_req_id = requestid;
 			vss_transaction.msg = (struct hv_vss_msg *)vss_msg;
 
 			schedule_work(&vss_handle_request_work);
 			return;
 		}
 
 		icmsghdrp->icflags = ICMSGHDRFLAG_TRANSACTION
 			| ICMSGHDRFLAG_RESPONSE;
 
 		vmbus_sendpacket(channel, recv_buffer,
 				       recvlen, requestid,
 				       VM_PKT_DATA_INBAND, 0);
 	}
 
 }
 
 static void vss_on_reset(void)
 {
 	if (cancel_delayed_work_sync(&vss_timeout_work))
 		vss_respond_to_host(HV_E_FAIL);
 	vss_transaction.state = HVUTIL_DEVICE_INIT;
+	complete(&release_event);
 }
 
 int
 hv_vss_init(struct hv_util_service *srv)
 {
+	init_completion(&release_event);
 	if (vmbus_proto_version < VERSION_WIN8_1) {
 		pr_warn("Integration service 'Backup (volume snapshot)'"
 			" not supported on this host version.\n");
 		return -ENOTSUPP;
 	}
 	recv_buffer = srv->recv_buffer;
 	vss_transaction.recv_channel = srv->channel;
 
 	/*
 	 * When this driver loads, the user level daemon that
 	 * processes the host requests may not yet be running.
 	 * Defer processing channel callbacks until the daemon
 	 * has registered.
 	 */
 	vss_transaction.state = HVUTIL_DEVICE_INIT;
 
 	hvt = hvutil_transport_init(vss_devname, CN_VSS_IDX, CN_VSS_VAL,
 				    vss_on_msg, vss_on_reset);
 	if (!hvt) {
 		pr_warn("VSS: Failed to initialize transport\n");
 		return -EFAULT;
 	}
 
 	return 0;
 }
 
 void hv_vss_deinit(void)
 {
 	vss_transaction.state = HVUTIL_DEVICE_DYING;
 	cancel_delayed_work_sync(&vss_timeout_work);
 	cancel_work_sync(&vss_handle_request_work);
 	hvutil_transport_destroy(hvt);
+	wait_for_completion(&release_event);
 }
diff --git a/drivers/hv/hv_util.c b/drivers/hv/hv_util.c
index e7707747f56d..3042eaa13062 100644
--- a/drivers/hv/hv_util.c
+++ b/drivers/hv/hv_util.c
@@ -1,502 +1,635 @@
 /*
  * Copyright (c) 2010, Microsoft Corporation.
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms and conditions of the GNU General Public License,
  * version 2, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope it will be useful, but WITHOUT
  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
  * more details.
  *
  * You should have received a copy of the GNU General Public License along with
  * this program; if not, write to the Free Software Foundation, Inc., 59 Temple
  * Place - Suite 330, Boston, MA 02111-1307 USA.
  *
  * Authors:
  *   Haiyang Zhang <haiyangz@microsoft.com>
  *   Hank Janssen  <hjanssen@microsoft.com>
  */
 #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
 
 #include <linux/kernel.h>
 #include <linux/init.h>
 #include <linux/module.h>
 #include <linux/slab.h>
 #include <linux/sysctl.h>
 #include <linux/reboot.h>
 #include <linux/hyperv.h>
+#include <linux/clockchips.h>
+#include <linux/ptp_clock_kernel.h>
+#include <asm/mshyperv.h>
 
 #include "hyperv_vmbus.h"
 
 #define SD_MAJOR	3
 #define SD_MINOR	0
 #define SD_VERSION	(SD_MAJOR << 16 | SD_MINOR)
 
 #define SD_MAJOR_1	1
 #define SD_VERSION_1	(SD_MAJOR_1 << 16 | SD_MINOR)
 
 #define TS_MAJOR	4
 #define TS_MINOR	0
 #define TS_VERSION	(TS_MAJOR << 16 | TS_MINOR)
 
 #define TS_MAJOR_1	1
 #define TS_VERSION_1	(TS_MAJOR_1 << 16 | TS_MINOR)
 
 #define TS_MAJOR_3	3
 #define TS_VERSION_3	(TS_MAJOR_3 << 16 | TS_MINOR)
 
 #define HB_MAJOR	3
 #define HB_MINOR	0
 #define HB_VERSION	(HB_MAJOR << 16 | HB_MINOR)
 
 #define HB_MAJOR_1	1
 #define HB_VERSION_1	(HB_MAJOR_1 << 16 | HB_MINOR)
 
 static int sd_srv_version;
 static int ts_srv_version;
 static int hb_srv_version;
-static int util_fw_version;
+
+#define SD_VER_COUNT 2
+static const int sd_versions[] = {
+	SD_VERSION,
+	SD_VERSION_1
+};
+
+#define TS_VER_COUNT 3
+static const int ts_versions[] = {
+	TS_VERSION,
+	TS_VERSION_3,
+	TS_VERSION_1
+};
+
+#define HB_VER_COUNT 2
+static const int hb_versions[] = {
+	HB_VERSION,
+	HB_VERSION_1
+};
+
+#define FW_VER_COUNT 2
+static const int fw_versions[] = {
+	UTIL_FW_VERSION,
+	UTIL_WS2K8_FW_VERSION
+};
 
 static void shutdown_onchannelcallback(void *context);
 static struct hv_util_service util_shutdown = {
 	.util_cb = shutdown_onchannelcallback,
 };
 
 static int hv_timesync_init(struct hv_util_service *srv);
 static void hv_timesync_deinit(void);
 
 static void timesync_onchannelcallback(void *context);
 static struct hv_util_service util_timesynch = {
 	.util_cb = timesync_onchannelcallback,
 	.util_init = hv_timesync_init,
 	.util_deinit = hv_timesync_deinit,
 };
 
 static void heartbeat_onchannelcallback(void *context);
 static struct hv_util_service util_heartbeat = {
 	.util_cb = heartbeat_onchannelcallback,
 };
 
 static struct hv_util_service util_kvp = {
 	.util_cb = hv_kvp_onchannelcallback,
 	.util_init = hv_kvp_init,
 	.util_deinit = hv_kvp_deinit,
 };
 
 static struct hv_util_service util_vss = {
 	.util_cb = hv_vss_onchannelcallback,
 	.util_init = hv_vss_init,
 	.util_deinit = hv_vss_deinit,
 };
 
 static struct hv_util_service util_fcopy = {
 	.util_cb = hv_fcopy_onchannelcallback,
 	.util_init = hv_fcopy_init,
 	.util_deinit = hv_fcopy_deinit,
 };
 
 static void perform_shutdown(struct work_struct *dummy)
 {
 	orderly_poweroff(true);
 }
 
 /*
  * Perform the shutdown operation in a thread context.
  */
 static DECLARE_WORK(shutdown_work, perform_shutdown);
 
 static void shutdown_onchannelcallback(void *context)
 {
 	struct vmbus_channel *channel = context;
 	u32 recvlen;
 	u64 requestid;
 	bool execute_shutdown = false;
 	u8  *shut_txf_buf = util_shutdown.recv_buffer;
 
 	struct shutdown_msg_data *shutdown_msg;
 
 	struct icmsg_hdr *icmsghdrp;
-	struct icmsg_negotiate *negop = NULL;
 
 	vmbus_recvpacket(channel, shut_txf_buf,
 			 PAGE_SIZE, &recvlen, &requestid);
 
 	if (recvlen > 0) {
 		icmsghdrp = (struct icmsg_hdr *)&shut_txf_buf[
 			sizeof(struct vmbuspipe_hdr)];
 
 		if (icmsghdrp->icmsgtype == ICMSGTYPE_NEGOTIATE) {
-			vmbus_prep_negotiate_resp(icmsghdrp, negop,
-					shut_txf_buf, util_fw_version,
-					sd_srv_version);
+			if (vmbus_prep_negotiate_resp(icmsghdrp, shut_txf_buf,
+					fw_versions, FW_VER_COUNT,
+					sd_versions, SD_VER_COUNT,
+					NULL, &sd_srv_version)) {
+				pr_info("Shutdown IC version %d.%d\n",
+					sd_srv_version >> 16,
+					sd_srv_version & 0xFFFF);
+			}
 		} else {
 			shutdown_msg =
 				(struct shutdown_msg_data *)&shut_txf_buf[
 					sizeof(struct vmbuspipe_hdr) +
 					sizeof(struct icmsg_hdr)];
 
 			switch (shutdown_msg->flags) {
 			case 0:
 			case 1:
 				icmsghdrp->status = HV_S_OK;
 				execute_shutdown = true;
 
 				pr_info("Shutdown request received -"
 					    " graceful shutdown initiated\n");
 				break;
 			default:
 				icmsghdrp->status = HV_E_FAIL;
 				execute_shutdown = false;
 
 				pr_info("Shutdown request received -"
 					    " Invalid request\n");
 				break;
 			}
 		}
 
 		icmsghdrp->icflags = ICMSGHDRFLAG_TRANSACTION
 			| ICMSGHDRFLAG_RESPONSE;
 
 		vmbus_sendpacket(channel, shut_txf_buf,
 				       recvlen, requestid,
 				       VM_PKT_DATA_INBAND, 0);
 	}
 
 	if (execute_shutdown == true)
 		schedule_work(&shutdown_work);
 }
 
 /*
  * Set the host time in a process context.
  */
 
 struct adj_time_work {
 	struct work_struct work;
 	u64	host_time;
 	u64	ref_time;
 	u8	flags;
 };
 
 static void hv_set_host_time(struct work_struct *work)
 {
-	struct adj_time_work	*wrk;
-	s64 host_tns;
-	u64 newtime;
-	struct timespec host_ts;
+	struct adj_time_work *wrk;
+	struct timespec64 host_ts;
+	u64 reftime, newtime;
 
 	wrk = container_of(work, struct adj_time_work, work);
 
-	newtime = wrk->host_time;
-	if (ts_srv_version > TS_VERSION_3) {
-		/*
-		 * Some latency has been introduced since Hyper-V generated
-		 * its time sample. Take that latency into account before
-		 * using TSC reference time sample from Hyper-V.
-		 *
-		 * This sample is given by TimeSync v4 and above hosts.
-		 */
-		u64 current_tick;
-
-		rdmsrl(HV_X64_MSR_TIME_REF_COUNT, current_tick);
-		newtime += (current_tick - wrk->ref_time);
-	}
-	host_tns = (newtime - WLTIMEDELTA) * 100;
-	host_ts = ns_to_timespec(host_tns);
+	reftime = hyperv_cs->read(hyperv_cs);
+	newtime = wrk->host_time + (reftime - wrk->ref_time);
+	host_ts = ns_to_timespec64((newtime - WLTIMEDELTA) * 100);
 
-	do_settimeofday(&host_ts);
+	do_settimeofday64(&host_ts);
 }
 
 /*
  * Synchronize time with host after reboot, restore, etc.
  *
  * ICTIMESYNCFLAG_SYNC flag bit indicates reboot, restore events of the VM.
  * After reboot the flag ICTIMESYNCFLAG_SYNC is included in the first time
  * message after the timesync channel is opened. Since the hv_utils module is
  * loaded after hv_vmbus, the first message is usually missed. This bit is
  * considered a hard request to discipline the clock.
  *
  * ICTIMESYNCFLAG_SAMPLE bit indicates a time sample from host. This is
  * typically used as a hint to the guest. The guest is under no obligation
  * to discipline the clock.
  */
 static struct adj_time_work  wrk;
-static inline void adj_guesttime(u64 hosttime, u64 reftime, u8 flags)
+
+/*
+ * The last time sample, received from the host. PTP device responds to
+ * requests by using this data and the current partition-wide time reference
+ * count.
+ */
+static struct {
+	u64				host_time;
+	u64				ref_time;
+	struct system_time_snapshot	snap;
+	spinlock_t			lock;
+} host_ts;
+
+static inline void adj_guesttime(u64 hosttime, u64 reftime, u8 adj_flags)
 {
+	unsigned long flags;
+	u64 cur_reftime;
 
 	/*
 	 * This check is safe since we are executing in the
-	 * interrupt context and time synch messages arre always
+	 * interrupt context and time synch messages are always
 	 * delivered on the same CPU.
 	 */
-	if (work_pending(&wrk.work))
-		return;
-
-	wrk.host_time = hosttime;
-	wrk.ref_time = reftime;
-	wrk.flags = flags;
-	if ((flags & (ICTIMESYNCFLAG_SYNC | ICTIMESYNCFLAG_SAMPLE)) != 0) {
+	if (adj_flags & ICTIMESYNCFLAG_SYNC) {
+		/* Queue a job to do do_settimeofday64() */
+		if (work_pending(&wrk.work))
+			return;
+
+		wrk.host_time = hosttime;
+		wrk.ref_time = reftime;
+		wrk.flags = adj_flags;
 		schedule_work(&wrk.work);
+	} else {
+		/*
+		 * Save the adjusted time sample from the host and the snapshot
+		 * of the current system time for PTP device.
+		 */
+		spin_lock_irqsave(&host_ts.lock, flags);
+
+		cur_reftime = hyperv_cs->read(hyperv_cs);
+		host_ts.host_time = hosttime;
+		host_ts.ref_time = cur_reftime;
+		ktime_get_snapshot(&host_ts.snap);
+
+		/*
+		 * TimeSync v4 messages contain reference time (guest's Hyper-V
+		 * clocksource read when the time sample was generated), we can
+		 * improve the precision by adding the delta between now and the
+		 * time of generation.
+		 */
+		if (ts_srv_version > TS_VERSION_3)
+			host_ts.host_time += (cur_reftime - reftime);
+
+		spin_unlock_irqrestore(&host_ts.lock, flags);
 	}
 }
 
 /*
  * Time Sync Channel message handler.
  */
 static void timesync_onchannelcallback(void *context)
 {
 	struct vmbus_channel *channel = context;
 	u32 recvlen;
 	u64 requestid;
 	struct icmsg_hdr *icmsghdrp;
 	struct ictimesync_data *timedatap;
 	struct ictimesync_ref_data *refdata;
 	u8 *time_txf_buf = util_timesynch.recv_buffer;
-	struct icmsg_negotiate *negop = NULL;
 
 	vmbus_recvpacket(channel, time_txf_buf,
 			 PAGE_SIZE, &recvlen, &requestid);
 
 	if (recvlen > 0) {
 		icmsghdrp = (struct icmsg_hdr *)&time_txf_buf[
 				sizeof(struct vmbuspipe_hdr)];
 
 		if (icmsghdrp->icmsgtype == ICMSGTYPE_NEGOTIATE) {
-			vmbus_prep_negotiate_resp(icmsghdrp, negop,
-						time_txf_buf,
-						util_fw_version,
-						ts_srv_version);
-			pr_info("Using TimeSync version %d.%d\n",
-				ts_srv_version >> 16, ts_srv_version & 0xFFFF);
+			if (vmbus_prep_negotiate_resp(icmsghdrp, time_txf_buf,
+						fw_versions, FW_VER_COUNT,
+						ts_versions, TS_VER_COUNT,
+						NULL, &ts_srv_version)) {
+				pr_info("TimeSync IC version %d.%d\n",
+					ts_srv_version >> 16,
+					ts_srv_version & 0xFFFF);
+			}
 		} else {
 			if (ts_srv_version > TS_VERSION_3) {
 				refdata = (struct ictimesync_ref_data *)
 					&time_txf_buf[
 					sizeof(struct vmbuspipe_hdr) +
 					sizeof(struct icmsg_hdr)];
 
 				adj_guesttime(refdata->parenttime,
 						refdata->vmreferencetime,
 						refdata->flags);
 			} else {
 				timedatap = (struct ictimesync_data *)
 					&time_txf_buf[
 					sizeof(struct vmbuspipe_hdr) +
 					sizeof(struct icmsg_hdr)];
 				adj_guesttime(timedatap->parenttime,
 						0,
 						timedatap->flags);
 			}
 		}
 
 		icmsghdrp->icflags = ICMSGHDRFLAG_TRANSACTION
 			| ICMSGHDRFLAG_RESPONSE;
 
 		vmbus_sendpacket(channel, time_txf_buf,
 				recvlen, requestid,
 				VM_PKT_DATA_INBAND, 0);
 	}
 }
 
 /*
  * Heartbeat functionality.
  * Every two seconds, Hyper-V send us a heartbeat request message.
  * we respond to this message, and Hyper-V knows we are alive.
  */
 static void heartbeat_onchannelcallback(void *context)
 {
 	struct vmbus_channel *channel = context;
 	u32 recvlen;
 	u64 requestid;
 	struct icmsg_hdr *icmsghdrp;
 	struct heartbeat_msg_data *heartbeat_msg;
 	u8 *hbeat_txf_buf = util_heartbeat.recv_buffer;
-	struct icmsg_negotiate *negop = NULL;
 
 	while (1) {
 
 		vmbus_recvpacket(channel, hbeat_txf_buf,
 				 PAGE_SIZE, &recvlen, &requestid);
 
 		if (!recvlen)
 			break;
 
 		icmsghdrp = (struct icmsg_hdr *)&hbeat_txf_buf[
 				sizeof(struct vmbuspipe_hdr)];
 
 		if (icmsghdrp->icmsgtype == ICMSGTYPE_NEGOTIATE) {
-			vmbus_prep_negotiate_resp(icmsghdrp, negop,
-				hbeat_txf_buf, util_fw_version,
-				hb_srv_version);
+			if (vmbus_prep_negotiate_resp(icmsghdrp,
+					hbeat_txf_buf,
+					fw_versions, FW_VER_COUNT,
+					hb_versions, HB_VER_COUNT,
+					NULL, &hb_srv_version)) {
+
+				pr_info("Heartbeat IC version %d.%d\n",
+					hb_srv_version >> 16,
+					hb_srv_version & 0xFFFF);
+			}
 		} else {
 			heartbeat_msg =
 				(struct heartbeat_msg_data *)&hbeat_txf_buf[
 					sizeof(struct vmbuspipe_hdr) +
 					sizeof(struct icmsg_hdr)];
 
 			heartbeat_msg->seq_num += 1;
 		}
 
 		icmsghdrp->icflags = ICMSGHDRFLAG_TRANSACTION
 			| ICMSGHDRFLAG_RESPONSE;
 
 		vmbus_sendpacket(channel, hbeat_txf_buf,
 				       recvlen, requestid,
 				       VM_PKT_DATA_INBAND, 0);
 	}
 }
 
 static int util_probe(struct hv_device *dev,
 			const struct hv_vmbus_device_id *dev_id)
 {
 	struct hv_util_service *srv =
 		(struct hv_util_service *)dev_id->driver_data;
 	int ret;
 
 	srv->recv_buffer = kmalloc(PAGE_SIZE * 4, GFP_KERNEL);
 	if (!srv->recv_buffer)
 		return -ENOMEM;
 	srv->channel = dev->channel;
 	if (srv->util_init) {
 		ret = srv->util_init(srv);
 		if (ret) {
 			ret = -ENODEV;
 			goto error1;
 		}
 	}
 
 	/*
 	 * The set of services managed by the util driver are not performance
 	 * critical and do not need batched reading. Furthermore, some services
 	 * such as KVP can only handle one message from the host at a time.
 	 * Turn off batched reading for all util drivers before we open the
 	 * channel.
 	 */
-
-	set_channel_read_state(dev->channel, false);
+	set_channel_read_mode(dev->channel, HV_CALL_DIRECT);
 
 	hv_set_drvdata(dev, srv);
 
-	/*
-	 * Based on the host; initialize the framework and
-	 * service version numbers we will negotiate.
-	 */
-	switch (vmbus_proto_version) {
-	case (VERSION_WS2008):
-		util_fw_version = UTIL_WS2K8_FW_VERSION;
-		sd_srv_version = SD_VERSION_1;
-		ts_srv_version = TS_VERSION_1;
-		hb_srv_version = HB_VERSION_1;
-		break;
-	case VERSION_WIN7:
-	case VERSION_WIN8:
-	case VERSION_WIN8_1:
-		util_fw_version = UTIL_FW_VERSION;
-		sd_srv_version = SD_VERSION;
-		ts_srv_version = TS_VERSION_3;
-		hb_srv_version = HB_VERSION;
-		break;
-	case VERSION_WIN10:
-	default:
-		util_fw_version = UTIL_FW_VERSION;
-		sd_srv_version = SD_VERSION;
-		ts_srv_version = TS_VERSION;
-		hb_srv_version = HB_VERSION;
-	}
-
 	ret = vmbus_open(dev->channel, 4 * PAGE_SIZE, 4 * PAGE_SIZE, NULL, 0,
 			srv->util_cb, dev->channel);
 	if (ret)
 		goto error;
 
 	return 0;
 
 error:
 	if (srv->util_deinit)
 		srv->util_deinit();
 error1:
 	kfree(srv->recv_buffer);
 	return ret;
 }
 
 static int util_remove(struct hv_device *dev)
 {
 	struct hv_util_service *srv = hv_get_drvdata(dev);
 
 	if (srv->util_deinit)
 		srv->util_deinit();
 	vmbus_close(dev->channel);
 	kfree(srv->recv_buffer);
 
 	return 0;
 }
 
 static const struct hv_vmbus_device_id id_table[] = {
 	/* Shutdown guid */
 	{ HV_SHUTDOWN_GUID,
 	  .driver_data = (unsigned long)&util_shutdown
 	},
 	/* Time synch guid */
 	{ HV_TS_GUID,
 	  .driver_data = (unsigned long)&util_timesynch
 	},
 	/* Heartbeat guid */
 	{ HV_HEART_BEAT_GUID,
 	  .driver_data = (unsigned long)&util_heartbeat
 	},
 	/* KVP guid */
 	{ HV_KVP_GUID,
 	  .driver_data = (unsigned long)&util_kvp
 	},
 	/* VSS GUID */
 	{ HV_VSS_GUID,
 	  .driver_data = (unsigned long)&util_vss
 	},
 	/* File copy GUID */
 	{ HV_FCOPY_GUID,
 	  .driver_data = (unsigned long)&util_fcopy
 	},
 	{ },
 };
 
 MODULE_DEVICE_TABLE(vmbus, id_table);
 
 /* The one and only one */
 static  struct hv_driver util_drv = {
 	.name = "hv_util",
 	.id_table = id_table,
 	.probe =  util_probe,
 	.remove =  util_remove,
 };
 
+static int hv_ptp_enable(struct ptp_clock_info *info,
+			 struct ptp_clock_request *request, int on)
+{
+	return -EOPNOTSUPP;
+}
+
+static int hv_ptp_settime(struct ptp_clock_info *p, const struct timespec64 *ts)
+{
+	return -EOPNOTSUPP;
+}
+
+static int hv_ptp_adjfreq(struct ptp_clock_info *ptp, s32 delta)
+{
+	return -EOPNOTSUPP;
+}
+static int hv_ptp_adjtime(struct ptp_clock_info *ptp, s64 delta)
+{
+	return -EOPNOTSUPP;
+}
+
+static int hv_ptp_gettime(struct ptp_clock_info *info, struct timespec64 *ts)
+{
+	unsigned long flags;
+	u64 newtime, reftime;
+
+	spin_lock_irqsave(&host_ts.lock, flags);
+	reftime = hyperv_cs->read(hyperv_cs);
+	newtime = host_ts.host_time + (reftime - host_ts.ref_time);
+	*ts = ns_to_timespec64((newtime - WLTIMEDELTA) * 100);
+	spin_unlock_irqrestore(&host_ts.lock, flags);
+
+	return 0;
+}
+
+static int hv_ptp_get_syncdevicetime(ktime_t *device,
+				     struct system_counterval_t *system,
+				     void *ctx)
+{
+	system->cs = hyperv_cs;
+	system->cycles = host_ts.ref_time;
+	*device = ns_to_ktime((host_ts.host_time - WLTIMEDELTA) * 100);
+
+	return 0;
+}
+
+static int hv_ptp_getcrosststamp(struct ptp_clock_info *ptp,
+				 struct system_device_crosststamp *xtstamp)
+{
+	unsigned long flags;
+	int ret;
+
+	spin_lock_irqsave(&host_ts.lock, flags);
+
+	/*
+	 * host_ts contains the last time sample from the host and the snapshot
+	 * of system time. We don't need to calculate the time delta between
+	 * the reception and now as get_device_system_crosststamp() does the
+	 * required interpolation.
+	 */
+	ret = get_device_system_crosststamp(hv_ptp_get_syncdevicetime,
+					    NULL, &host_ts.snap, xtstamp);
+
+	spin_unlock_irqrestore(&host_ts.lock, flags);
+
+	return ret;
+}
+
+static struct ptp_clock_info ptp_hyperv_info = {
+	.name		= "hyperv",
+	.enable         = hv_ptp_enable,
+	.adjtime        = hv_ptp_adjtime,
+	.adjfreq        = hv_ptp_adjfreq,
+	.gettime64      = hv_ptp_gettime,
+	.getcrosststamp = hv_ptp_getcrosststamp,
+	.settime64      = hv_ptp_settime,
+	.owner		= THIS_MODULE,
+};
+
+static struct ptp_clock *hv_ptp_clock;
+
 static int hv_timesync_init(struct hv_util_service *srv)
 {
+	/* TimeSync requires Hyper-V clocksource. */
+	if (!hyperv_cs)
+		return -ENODEV;
+
 	INIT_WORK(&wrk.work, hv_set_host_time);
+
+	/*
+	 * ptp_clock_register() returns NULL when CONFIG_PTP_1588_CLOCK is
+	 * disabled but the driver is still useful without the PTP device
+	 * as it still handles the ICTIMESYNCFLAG_SYNC case.
+	 */
+	hv_ptp_clock = ptp_clock_register(&ptp_hyperv_info, NULL);
+	if (IS_ERR_OR_NULL(hv_ptp_clock)) {
+		pr_err("cannot register PTP clock: %ld\n",
+		       PTR_ERR(hv_ptp_clock));
+		hv_ptp_clock = NULL;
+	}
+
 	return 0;
 }
 
 static void hv_timesync_deinit(void)
 {
+	if (hv_ptp_clock)
+		ptp_clock_unregister(hv_ptp_clock);
 	cancel_work_sync(&wrk.work);
 }
 
 static int __init init_hyperv_utils(void)
 {
 	pr_info("Registering HyperV Utility Driver\n");
 
 	return vmbus_driver_register(&util_drv);
 }
 
 static void exit_hyperv_utils(void)
 {
 	pr_info("De-Registered HyperV Utility Driver\n");
 
 	vmbus_driver_unregister(&util_drv);
 }
 
 module_init(init_hyperv_utils);
 module_exit(exit_hyperv_utils);
 
 MODULE_DESCRIPTION("Hyper-V Utilities");
 MODULE_LICENSE("GPL");
diff --git a/drivers/hv/hyperv_vmbus.h b/drivers/hv/hyperv_vmbus.h
index 0675b395ce5c..884f83bba1ab 100644
--- a/drivers/hv/hyperv_vmbus.h
+++ b/drivers/hv/hyperv_vmbus.h
@@ -1,722 +1,437 @@
 /*
  *
  * Copyright (c) 2011, Microsoft Corporation.
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms and conditions of the GNU General Public License,
  * version 2, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope it will be useful, but WITHOUT
  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
  * more details.
  *
  * You should have received a copy of the GNU General Public License along with
  * this program; if not, write to the Free Software Foundation, Inc., 59 Temple
  * Place - Suite 330, Boston, MA 02111-1307 USA.
  *
  * Authors:
  *   Haiyang Zhang <haiyangz@microsoft.com>
  *   Hank Janssen  <hjanssen@microsoft.com>
  *   K. Y. Srinivasan <kys@microsoft.com>
  *
  */
 
 #ifndef _HYPERV_VMBUS_H
 #define _HYPERV_VMBUS_H
 
 #include <linux/list.h>
 #include <asm/sync_bitops.h>
 #include <linux/atomic.h>
 #include <linux/hyperv.h>
+#include <linux/interrupt.h>
 
 /*
  * Timeout for services such as KVP and fcopy.
  */
 #define HV_UTIL_TIMEOUT 30
 
 /*
  * Timeout for guest-host handshake for services.
  */
 #define HV_UTIL_NEGO_TIMEOUT 55
 
-/*
- * The below CPUID leaves are present if VersionAndFeatures.HypervisorPresent
- * is set by CPUID(HVCPUID_VERSION_FEATURES).
- */
-enum hv_cpuid_function {
-	HVCPUID_VERSION_FEATURES		= 0x00000001,
-	HVCPUID_VENDOR_MAXFUNCTION		= 0x40000000,
-	HVCPUID_INTERFACE			= 0x40000001,
-
-	/*
-	 * The remaining functions depend on the value of
-	 * HVCPUID_INTERFACE
-	 */
-	HVCPUID_VERSION			= 0x40000002,
-	HVCPUID_FEATURES			= 0x40000003,
-	HVCPUID_ENLIGHTENMENT_INFO	= 0x40000004,
-	HVCPUID_IMPLEMENTATION_LIMITS		= 0x40000005,
-};
-
-#define  HV_FEATURE_GUEST_CRASH_MSR_AVAILABLE   0x400
-
-#define HV_X64_MSR_CRASH_P0   0x40000100
-#define HV_X64_MSR_CRASH_P1   0x40000101
-#define HV_X64_MSR_CRASH_P2   0x40000102
-#define HV_X64_MSR_CRASH_P3   0x40000103
-#define HV_X64_MSR_CRASH_P4   0x40000104
-#define HV_X64_MSR_CRASH_CTL  0x40000105
-
-#define HV_CRASH_CTL_CRASH_NOTIFY (1ULL << 63)
-
-/* Define version of the synthetic interrupt controller. */
-#define HV_SYNIC_VERSION		(1)
-
-#define HV_ANY_VP			(0xFFFFFFFF)
-
 /* Define synthetic interrupt controller flag constants. */
 #define HV_EVENT_FLAGS_COUNT		(256 * 8)
-#define HV_EVENT_FLAGS_BYTE_COUNT	(256)
-#define HV_EVENT_FLAGS_DWORD_COUNT	(256 / sizeof(u32))
-
-/* Define invalid partition identifier. */
-#define HV_PARTITION_ID_INVALID		((u64)0x0)
-
-/* Define port type. */
-enum hv_port_type {
-	HVPORT_MSG	= 1,
-	HVPORT_EVENT		= 2,
-	HVPORT_MONITOR	= 3
-};
-
-/* Define port information structure. */
-struct hv_port_info {
-	enum hv_port_type port_type;
-	u32 padding;
-	union {
-		struct {
-			u32 target_sint;
-			u32 target_vp;
-			u64 rsvdz;
-		} message_port_info;
-		struct {
-			u32 target_sint;
-			u32 target_vp;
-			u16 base_flag_number;
-			u16 flag_count;
-			u32 rsvdz;
-		} event_port_info;
-		struct {
-			u64 monitor_address;
-			u64 rsvdz;
-		} monitor_port_info;
-	};
-};
-
-struct hv_connection_info {
-	enum hv_port_type port_type;
-	u32 padding;
-	union {
-		struct {
-			u64 rsvdz;
-		} message_connection_info;
-		struct {
-			u64 rsvdz;
-		} event_connection_info;
-		struct {
-			u64 monitor_address;
-		} monitor_connection_info;
-	};
-};
+#define HV_EVENT_FLAGS_LONG_COUNT	(256 / sizeof(unsigned long))
 
 /*
  * Timer configuration register.
  */
 union hv_timer_config {
 	u64 as_uint64;
 	struct {
 		u64 enable:1;
 		u64 periodic:1;
 		u64 lazy:1;
 		u64 auto_enable:1;
 		u64 reserved_z0:12;
 		u64 sintx:4;
 		u64 reserved_z1:44;
 	};
 };
 
-/* Define the number of message buffers associated with each port. */
-#define HV_PORT_MESSAGE_BUFFER_COUNT	(16)
 
 /* Define the synthetic interrupt controller event flags format. */
 union hv_synic_event_flags {
-	u8 flags8[HV_EVENT_FLAGS_BYTE_COUNT];
-	u32 flags32[HV_EVENT_FLAGS_DWORD_COUNT];
-};
-
-/* Define the synthetic interrupt flags page layout. */
-struct hv_synic_event_flags_page {
-	union hv_synic_event_flags sintevent_flags[HV_SYNIC_SINT_COUNT];
+	unsigned long flags[HV_EVENT_FLAGS_LONG_COUNT];
 };
 
 /* Define SynIC control register. */
 union hv_synic_scontrol {
 	u64 as_uint64;
 	struct {
 		u64 enable:1;
 		u64 reserved:63;
 	};
 };
 
 /* Define synthetic interrupt source. */
 union hv_synic_sint {
 	u64 as_uint64;
 	struct {
 		u64 vector:8;
 		u64 reserved1:8;
 		u64 masked:1;
 		u64 auto_eoi:1;
 		u64 reserved2:46;
 	};
 };
 
 /* Define the format of the SIMP register */
 union hv_synic_simp {
 	u64 as_uint64;
 	struct {
 		u64 simp_enabled:1;
 		u64 preserved:11;
 		u64 base_simp_gpa:52;
 	};
 };
 
 /* Define the format of the SIEFP register */
 union hv_synic_siefp {
 	u64 as_uint64;
 	struct {
 		u64 siefp_enabled:1;
 		u64 preserved:11;
 		u64 base_siefp_gpa:52;
 	};
 };
 
 /* Definitions for the monitored notification facility */
 union hv_monitor_trigger_group {
 	u64 as_uint64;
 	struct {
 		u32 pending;
 		u32 armed;
 	};
 };
 
 struct hv_monitor_parameter {
 	union hv_connection_id connectionid;
 	u16 flagnumber;
 	u16 rsvdz;
 };
 
 union hv_monitor_trigger_state {
 	u32 asu32;
 
 	struct {
 		u32 group_enable:4;
 		u32 rsvdz:28;
 	};
 };
 
 /* struct hv_monitor_page Layout */
 /* ------------------------------------------------------ */
 /* | 0   | TriggerState (4 bytes) | Rsvd1 (4 bytes)     | */
 /* | 8   | TriggerGroup[0]                              | */
 /* | 10  | TriggerGroup[1]                              | */
 /* | 18  | TriggerGroup[2]                              | */
 /* | 20  | TriggerGroup[3]                              | */
 /* | 28  | Rsvd2[0]                                     | */
 /* | 30  | Rsvd2[1]                                     | */
 /* | 38  | Rsvd2[2]                                     | */
 /* | 40  | NextCheckTime[0][0]    | NextCheckTime[0][1] | */
 /* | ...                                                | */
 /* | 240 | Latency[0][0..3]                             | */
 /* | 340 | Rsvz3[0]                                     | */
 /* | 440 | Parameter[0][0]                              | */
 /* | 448 | Parameter[0][1]                              | */
 /* | ...                                                | */
 /* | 840 | Rsvd4[0]                                     | */
 /* ------------------------------------------------------ */
 struct hv_monitor_page {
 	union hv_monitor_trigger_state trigger_state;
 	u32 rsvdz1;
 
 	union hv_monitor_trigger_group trigger_group[4];
 	u64 rsvdz2[3];
 
 	s32 next_checktime[4][32];
 
 	u16 latency[4][32];
 	u64 rsvdz3[32];
 
 	struct hv_monitor_parameter parameter[4][32];
 
 	u8 rsvdz4[1984];
 };
 
+#define HV_HYPERCALL_PARAM_ALIGN	sizeof(u64)
+
 /* Definition of the hv_post_message hypercall input structure. */
 struct hv_input_post_message {
 	union hv_connection_id connectionid;
 	u32 reserved;
 	u32 message_type;
 	u32 payload_size;
 	u64 payload[HV_MESSAGE_PAYLOAD_QWORD_COUNT];
 };
 
-/*
- * Versioning definitions used for guests reporting themselves to the
- * hypervisor, and visa versa.
- */
-
-/* Version info reported by guest OS's */
-enum hv_guest_os_vendor {
-	HVGUESTOS_VENDOR_MICROSOFT	= 0x0001
-};
-
-enum hv_guest_os_microsoft_ids {
-	HVGUESTOS_MICROSOFT_UNDEFINED	= 0x00,
-	HVGUESTOS_MICROSOFT_MSDOS		= 0x01,
-	HVGUESTOS_MICROSOFT_WINDOWS3X	= 0x02,
-	HVGUESTOS_MICROSOFT_WINDOWS9X	= 0x03,
-	HVGUESTOS_MICROSOFT_WINDOWSNT	= 0x04,
-	HVGUESTOS_MICROSOFT_WINDOWSCE	= 0x05
-};
-
-/*
- * Declare the MSR used to identify the guest OS.
- */
-#define HV_X64_MSR_GUEST_OS_ID	0x40000000
-
-union hv_x64_msr_guest_os_id_contents {
-	u64 as_uint64;
-	struct {
-		u64 build_number:16;
-		u64 service_version:8; /* Service Pack, etc. */
-		u64 minor_version:8;
-		u64 major_version:8;
-		u64 os_id:8; /* enum hv_guest_os_microsoft_ids (if Vendor=MS) */
-		u64 vendor_id:16; /* enum hv_guest_os_vendor */
-	};
-};
-
-/*
- * Declare the MSR used to setup pages used to communicate with the hypervisor.
- */
-#define HV_X64_MSR_HYPERCALL	0x40000001
-
-union hv_x64_msr_hypercall_contents {
-	u64 as_uint64;
-	struct {
-		u64 enable:1;
-		u64 reserved:11;
-		u64 guest_physical_address:52;
-	};
-};
-
 
 enum {
 	VMBUS_MESSAGE_CONNECTION_ID	= 1,
 	VMBUS_MESSAGE_PORT_ID		= 1,
 	VMBUS_EVENT_CONNECTION_ID	= 2,
 	VMBUS_EVENT_PORT_ID		= 2,
 	VMBUS_MONITOR_CONNECTION_ID	= 3,
 	VMBUS_MONITOR_PORT_ID		= 3,
 	VMBUS_MESSAGE_SINT		= 2,
 };
 
-/* #defines */
-
-#define HV_PRESENT_BIT			0x80000000
-
-/*
- * The guest OS needs to register the guest ID with the hypervisor.
- * The guest ID is a 64 bit entity and the structure of this ID is
- * specified in the Hyper-V specification:
- *
- * http://msdn.microsoft.com/en-us/library/windows/hardware/ff542653%28v=vs.85%29.aspx
- *
- * While the current guideline does not specify how Linux guest ID(s)
- * need to be generated, our plan is to publish the guidelines for
- * Linux and other guest operating systems that currently are hosted
- * on Hyper-V. The implementation here conforms to this yet
- * unpublished guidelines.
- *
- *
- * Bit(s)
- * 63 - Indicates if the OS is Open Source or not; 1 is Open Source
- * 62:56 - Os Type; Linux is 0x100
- * 55:48 - Distro specific identification
- * 47:16 - Linux kernel version number
- * 15:0  - Distro specific identification
- *
- *
- */
-
-#define HV_LINUX_VENDOR_ID		0x8100
-
 /*
- * Generate the guest ID based on the guideline described above.
+ * Per cpu state for channel handling
  */
+struct hv_per_cpu_context {
+	void *synic_message_page;
+	void *synic_event_page;
+	/*
+	 * buffer to post messages to the host.
+	 */
+	void *post_msg_page;
 
-static inline  __u64 generate_guest_id(__u8 d_info1, __u32 kernel_version,
-					__u16 d_info2)
-{
-	__u64 guest_id = 0;
-
-	guest_id = (((__u64)HV_LINUX_VENDOR_ID) << 48);
-	guest_id |= (((__u64)(d_info1)) << 48);
-	guest_id |= (((__u64)(kernel_version)) << 16);
-	guest_id |= ((__u64)(d_info2));
-
-	return guest_id;
-}
-
-
-#define HV_CPU_POWER_MANAGEMENT		(1 << 0)
-#define HV_RECOMMENDATIONS_MAX		4
-
-#define HV_X64_MAX			5
-#define HV_CAPS_MAX			8
-
-
-#define HV_HYPERCALL_PARAM_ALIGN	sizeof(u64)
-
-
-/* Service definitions */
-
-#define HV_SERVICE_PARENT_PORT				(0)
-#define HV_SERVICE_PARENT_CONNECTION			(0)
-
-#define HV_SERVICE_CONNECT_RESPONSE_SUCCESS		(0)
-#define HV_SERVICE_CONNECT_RESPONSE_INVALID_PARAMETER	(1)
-#define HV_SERVICE_CONNECT_RESPONSE_UNKNOWN_SERVICE	(2)
-#define HV_SERVICE_CONNECT_RESPONSE_CONNECTION_REJECTED	(3)
-
-#define HV_SERVICE_CONNECT_REQUEST_MESSAGE_ID		(1)
-#define HV_SERVICE_CONNECT_RESPONSE_MESSAGE_ID		(2)
-#define HV_SERVICE_DISCONNECT_REQUEST_MESSAGE_ID	(3)
-#define HV_SERVICE_DISCONNECT_RESPONSE_MESSAGE_ID	(4)
-#define HV_SERVICE_MAX_MESSAGE_ID				(4)
-
-#define HV_SERVICE_PROTOCOL_VERSION (0x0010)
-#define HV_CONNECT_PAYLOAD_BYTE_COUNT 64
-
-/* #define VMBUS_REVISION_NUMBER	6 */
-
-/* Our local vmbus's port and connection id. Anything >0 is fine */
-/* #define VMBUS_PORT_ID		11 */
+	/*
+	 * Starting with win8, we can take channel interrupts on any CPU;
+	 * we will manage the tasklet that handles events messages on a per CPU
+	 * basis.
+	 */
+	struct tasklet_struct msg_dpc;
 
-/* 628180B8-308D-4c5e-B7DB-1BEB62E62EF4 */
-static const uuid_le VMBUS_SERVICE_ID = {
-	.b = {
-		0xb8, 0x80, 0x81, 0x62, 0x8d, 0x30, 0x5e, 0x4c,
-		0xb7, 0xdb, 0x1b, 0xeb, 0x62, 0xe6, 0x2e, 0xf4
-	},
+	/*
+	 * To optimize the mapping of relid to channel, maintain
+	 * per-cpu list of the channels based on their CPU affinity.
+	 */
+	struct list_head chan_list;
+	struct clock_event_device *clk_evt;
 };
 
-
-
 struct hv_context {
 	/* We only support running on top of Hyper-V
 	* So at this point this really can only contain the Hyper-V ID
 	*/
 	u64 guestid;
 
-	void *hypercall_page;
 	void *tsc_page;
 
 	bool synic_initialized;
 
-	void *synic_message_page[NR_CPUS];
-	void *synic_event_page[NR_CPUS];
+	struct hv_per_cpu_context __percpu *cpu_context;
+
 	/*
 	 * Hypervisor's notion of virtual processor ID is different from
 	 * Linux' notion of CPU ID. This information can only be retrieved
 	 * in the context of the calling CPU. Setup a map for easy access
 	 * to this information:
 	 *
 	 * vp_index[a] is the Hyper-V's processor ID corresponding to
 	 * Linux cpuid 'a'.
 	 */
 	u32 vp_index[NR_CPUS];
-	/*
-	 * Starting with win8, we can take channel interrupts on any CPU;
-	 * we will manage the tasklet that handles events messages on a per CPU
-	 * basis.
-	 */
-	struct tasklet_struct *event_dpc[NR_CPUS];
-	struct tasklet_struct *msg_dpc[NR_CPUS];
-	/*
-	 * To optimize the mapping of relid to channel, maintain
-	 * per-cpu list of the channels based on their CPU affinity.
-	 */
-	struct list_head percpu_list[NR_CPUS];
-	/*
-	 * buffer to post messages to the host.
-	 */
-	void *post_msg_page[NR_CPUS];
-	/*
-	 * Support PV clockevent device.
-	 */
-	struct clock_event_device *clk_evt[NR_CPUS];
+
 	/*
 	 * To manage allocations in a NUMA node.
 	 * Array indexed by numa node ID.
 	 */
 	struct cpumask *hv_numa_map;
 };
 
 extern struct hv_context hv_context;
 
-struct ms_hyperv_tsc_page {
-	volatile u32 tsc_sequence;
-	u32 reserved1;
-	volatile u64 tsc_scale;
-	volatile s64 tsc_offset;
-	u64 reserved2[509];
-};
-
 struct hv_ring_buffer_debug_info {
 	u32 current_interrupt_mask;
 	u32 current_read_index;
 	u32 current_write_index;
 	u32 bytes_avail_toread;
 	u32 bytes_avail_towrite;
 };
 
 /* Hv Interface */
 
 extern int hv_init(void);
 
-extern void hv_cleanup(bool crash);
-
 extern int hv_post_message(union hv_connection_id connection_id,
 			 enum hv_message_type message_type,
 			 void *payload, size_t payload_size);
 
 extern int hv_synic_alloc(void);
 
 extern void hv_synic_free(void);
 
-extern void hv_synic_init(void *irqarg);
+extern int hv_synic_init(unsigned int cpu);
 
-extern void hv_synic_cleanup(void *arg);
+extern int hv_synic_cleanup(unsigned int cpu);
 
 extern void hv_synic_clockevents_cleanup(void);
 
-/*
- * Host version information.
- */
-extern unsigned int host_info_eax;
-extern unsigned int host_info_ebx;
-extern unsigned int host_info_ecx;
-extern unsigned int host_info_edx;
-
 /* Interface */
 
 
 int hv_ringbuffer_init(struct hv_ring_buffer_info *ring_info,
 		       struct page *pages, u32 pagecnt);
 
 void hv_ringbuffer_cleanup(struct hv_ring_buffer_info *ring_info);
 
 int hv_ringbuffer_write(struct vmbus_channel *channel,
-		    struct kvec *kv_list,
-		    u32 kv_count, bool lock,
-		    bool kick_q);
+			const struct kvec *kv_list, u32 kv_count);
 
 int hv_ringbuffer_read(struct vmbus_channel *channel,
 		       void *buffer, u32 buflen, u32 *buffer_actual_len,
 		       u64 *requestid, bool raw);
 
-void hv_ringbuffer_get_debuginfo(struct hv_ring_buffer_info *ring_info,
-			    struct hv_ring_buffer_debug_info *debug_info);
-
-void hv_begin_read(struct hv_ring_buffer_info *rbi);
-
-u32 hv_end_read(struct hv_ring_buffer_info *rbi);
+void hv_ringbuffer_get_debuginfo(const struct hv_ring_buffer_info *ring_info,
+				 struct hv_ring_buffer_debug_info *debug_info);
 
 /*
  * Maximum channels is determined by the size of the interrupt page
  * which is PAGE_SIZE. 1/2 of PAGE_SIZE is for send endpoint interrupt
  * and the other is receive endpoint interrupt
  */
 #define MAX_NUM_CHANNELS	((PAGE_SIZE >> 1) << 3)	/* 16348 channels */
 
 /* The value here must be in multiple of 32 */
 /* TODO: Need to make this configurable */
 #define MAX_NUM_CHANNELS_SUPPORTED	256
 
 
 enum vmbus_connect_state {
 	DISCONNECTED,
 	CONNECTING,
 	CONNECTED,
 	DISCONNECTING
 };
 
 #define MAX_SIZE_CHANNEL_MESSAGE	HV_MESSAGE_PAYLOAD_BYTE_COUNT
 
 struct vmbus_connection {
 	enum vmbus_connect_state conn_state;
 
 	atomic_t next_gpadl_handle;
 
 	struct completion  unload_event;
 	/*
 	 * Represents channel interrupts. Each bit position represents a
 	 * channel.  When a channel sends an interrupt via VMBUS, it finds its
 	 * bit in the sendInterruptPage, set it and calls Hv to generate a port
 	 * event. The other end receives the port event and parse the
 	 * recvInterruptPage to see which bit is set
 	 */
 	void *int_page;
 	void *send_int_page;
 	void *recv_int_page;
 
 	/*
 	 * 2 pages - 1st page for parent->child notification and 2nd
 	 * is child->parent notification
 	 */
 	struct hv_monitor_page *monitor_pages[2];
 	struct list_head chn_msg_list;
 	spinlock_t channelmsg_lock;
 
 	/* List of channels */
 	struct list_head chn_list;
 	struct mutex channel_mutex;
 
 	struct workqueue_struct *work_queue;
 };
 
 
 struct vmbus_msginfo {
 	/* Bookkeeping stuff */
 	struct list_head msglist_entry;
 
 	/* The message itself */
 	unsigned char msg[0];
 };
 
 
 extern struct vmbus_connection vmbus_connection;
 
+static inline void vmbus_send_interrupt(u32 relid)
+{
+	sync_set_bit(relid, vmbus_connection.send_int_page);
+}
+
 enum vmbus_message_handler_type {
 	/* The related handler can sleep. */
 	VMHT_BLOCKING = 0,
 
 	/* The related handler must NOT sleep. */
 	VMHT_NON_BLOCKING = 1,
 };
 
 struct vmbus_channel_message_table_entry {
 	enum vmbus_channel_message_type message_type;
 	enum vmbus_message_handler_type handler_type;
 	void (*message_handler)(struct vmbus_channel_message_header *msg);
 };
 
 extern struct vmbus_channel_message_table_entry
 	channel_message_table[CHANNELMSG_COUNT];
 
-/* Free the message slot and signal end-of-message if required */
-static inline void vmbus_signal_eom(struct hv_message *msg, u32 old_msg_type)
-{
-	/*
-	 * On crash we're reading some other CPU's message page and we need
-	 * to be careful: this other CPU may already had cleared the header
-	 * and the host may already had delivered some other message there.
-	 * In case we blindly write msg->header.message_type we're going
-	 * to lose it. We can still lose a message of the same type but
-	 * we count on the fact that there can only be one
-	 * CHANNELMSG_UNLOAD_RESPONSE and we don't care about other messages
-	 * on crash.
-	 */
-	if (cmpxchg(&msg->header.message_type, old_msg_type,
-		    HVMSG_NONE) != old_msg_type)
-		return;
-
-	/*
-	 * Make sure the write to MessageType (ie set to
-	 * HVMSG_NONE) happens before we read the
-	 * MessagePending and EOMing. Otherwise, the EOMing
-	 * will not deliver any more messages since there is
-	 * no empty slot
-	 */
-	mb();
-
-	if (msg->header.message_flags.msg_pending) {
-		/*
-		 * This will cause message queue rescan to
-		 * possibly deliver another msg from the
-		 * hypervisor
-		 */
-		wrmsrl(HV_X64_MSR_EOM, 0);
-	}
-}
 
 /* General vmbus interface */
 
 struct hv_device *vmbus_device_create(const uuid_le *type,
 				      const uuid_le *instance,
 				      struct vmbus_channel *channel);
 
 int vmbus_device_register(struct hv_device *child_device_obj);
 void vmbus_device_unregister(struct hv_device *device_obj);
 
-/* static void */
-/* VmbusChildDeviceDestroy( */
-/* struct hv_device *); */
-
 struct vmbus_channel *relid2channel(u32 relid);
 
 void vmbus_free_channels(void);
 
 /* Connection interface */
 
 int vmbus_connect(void);
 void vmbus_disconnect(void);
 
-int vmbus_post_msg(void *buffer, size_t buflen);
+int vmbus_post_msg(void *buffer, size_t buflen, bool can_sleep);
 
 void vmbus_on_event(unsigned long data);
 void vmbus_on_msg_dpc(unsigned long data);
 
 int hv_kvp_init(struct hv_util_service *);
 void hv_kvp_deinit(void);
 void hv_kvp_onchannelcallback(void *);
 
 int hv_vss_init(struct hv_util_service *);
 void hv_vss_deinit(void);
 void hv_vss_onchannelcallback(void *);
 
 int hv_fcopy_init(struct hv_util_service *);
 void hv_fcopy_deinit(void);
 void hv_fcopy_onchannelcallback(void *);
 void vmbus_initiate_unload(bool crash);
 
 static inline void hv_poll_channel(struct vmbus_channel *channel,
 				   void (*cb)(void *))
 {
 	if (!channel)
 		return;
 
 	smp_call_function_single(channel->target_cpu, cb, channel, true);
 }
 
 enum hvutil_device_state {
 	HVUTIL_DEVICE_INIT = 0,  /* driver is loaded, waiting for userspace */
 	HVUTIL_READY,            /* userspace is registered */
 	HVUTIL_HOSTMSG_RECEIVED, /* message from the host was received */
 	HVUTIL_USERSPACE_REQ,    /* request to userspace was sent */
 	HVUTIL_USERSPACE_RECV,   /* reply from userspace was received */
 	HVUTIL_DEVICE_DYING,     /* driver unload is in progress */
 };
 
 #endif /* _HYPERV_VMBUS_H */
diff --git a/drivers/hv/ring_buffer.c b/drivers/hv/ring_buffer.c
index 308dbda700eb..87799e81af97 100644
--- a/drivers/hv/ring_buffer.c
+++ b/drivers/hv/ring_buffer.c
@@ -1,429 +1,412 @@
 /*
  *
  * Copyright (c) 2009, Microsoft Corporation.
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms and conditions of the GNU General Public License,
  * version 2, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope it will be useful, but WITHOUT
  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
  * more details.
  *
  * You should have received a copy of the GNU General Public License along with
  * this program; if not, write to the Free Software Foundation, Inc., 59 Temple
  * Place - Suite 330, Boston, MA 02111-1307 USA.
  *
  * Authors:
  *   Haiyang Zhang <haiyangz@microsoft.com>
  *   Hank Janssen  <hjanssen@microsoft.com>
  *   K. Y. Srinivasan <kys@microsoft.com>
  *
  */
 #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
 
 #include <linux/kernel.h>
 #include <linux/mm.h>
 #include <linux/hyperv.h>
 #include <linux/uio.h>
 #include <linux/vmalloc.h>
 #include <linux/slab.h>
 
 #include "hyperv_vmbus.h"
 
-void hv_begin_read(struct hv_ring_buffer_info *rbi)
-{
-	rbi->ring_buffer->interrupt_mask = 1;
-	virt_mb();
-}
-
-u32 hv_end_read(struct hv_ring_buffer_info *rbi)
-{
-
-	rbi->ring_buffer->interrupt_mask = 0;
-	virt_mb();
-
-	/*
-	 * Now check to see if the ring buffer is still empty.
-	 * If it is not, we raced and we need to process new
-	 * incoming messages.
-	 */
-	return hv_get_bytes_to_read(rbi);
-}
-
 /*
  * When we write to the ring buffer, check if the host needs to
  * be signaled. Here is the details of this protocol:
  *
  *	1. The host guarantees that while it is draining the
  *	   ring buffer, it will set the interrupt_mask to
  *	   indicate it does not need to be interrupted when
  *	   new data is placed.
  *
  *	2. The host guarantees that it will completely drain
  *	   the ring buffer before exiting the read loop. Further,
  *	   once the ring buffer is empty, it will clear the
  *	   interrupt_mask and re-check to see if new data has
  *	   arrived.
  *
  * KYS: Oct. 30, 2016:
  * It looks like Windows hosts have logic to deal with DOS attacks that
  * can be triggered if it receives interrupts when it is not expecting
  * the interrupt. The host expects interrupts only when the ring
  * transitions from empty to non-empty (or full to non full on the guest
  * to host ring).
  * So, base the signaling decision solely on the ring state until the
  * host logic is fixed.
  */
 
-static void hv_signal_on_write(u32 old_write, struct vmbus_channel *channel,
-			       bool kick_q)
+static void hv_signal_on_write(u32 old_write, struct vmbus_channel *channel)
 {
 	struct hv_ring_buffer_info *rbi = &channel->outbound;
 
 	virt_mb();
 	if (READ_ONCE(rbi->ring_buffer->interrupt_mask))
 		return;
 
 	/* check interrupt_mask before read_index */
 	virt_rmb();
 	/*
 	 * This is the only case we need to signal when the
 	 * ring transitions from being empty to non-empty.
 	 */
 	if (old_write == READ_ONCE(rbi->ring_buffer->read_index))
 		vmbus_setevent(channel);
 
 	return;
 }
 
 /* Get the next write location for the specified ring buffer. */
 static inline u32
 hv_get_next_write_location(struct hv_ring_buffer_info *ring_info)
 {
 	u32 next = ring_info->ring_buffer->write_index;
 
 	return next;
 }
 
 /* Set the next write location for the specified ring buffer. */
 static inline void
 hv_set_next_write_location(struct hv_ring_buffer_info *ring_info,
 		     u32 next_write_location)
 {
 	ring_info->ring_buffer->write_index = next_write_location;
 }
 
 /* Get the next read location for the specified ring buffer. */
 static inline u32
-hv_get_next_read_location(struct hv_ring_buffer_info *ring_info)
+hv_get_next_read_location(const struct hv_ring_buffer_info *ring_info)
 {
-	u32 next = ring_info->ring_buffer->read_index;
-
-	return next;
+	return ring_info->ring_buffer->read_index;
 }
 
 /*
  * Get the next read location + offset for the specified ring buffer.
  * This allows the caller to skip.
  */
 static inline u32
-hv_get_next_readlocation_withoffset(struct hv_ring_buffer_info *ring_info,
-				 u32 offset)
+hv_get_next_readlocation_withoffset(const struct hv_ring_buffer_info *ring_info,
+				    u32 offset)
 {
 	u32 next = ring_info->ring_buffer->read_index;
 
 	next += offset;
-	next %= ring_info->ring_datasize;
+	if (next >= ring_info->ring_datasize)
+		next -= ring_info->ring_datasize;
 
 	return next;
 }
 
 /* Set the next read location for the specified ring buffer. */
 static inline void
 hv_set_next_read_location(struct hv_ring_buffer_info *ring_info,
 		    u32 next_read_location)
 {
 	ring_info->ring_buffer->read_index = next_read_location;
 	ring_info->priv_read_index = next_read_location;
 }
 
 /* Get the size of the ring buffer. */
 static inline u32
-hv_get_ring_buffersize(struct hv_ring_buffer_info *ring_info)
+hv_get_ring_buffersize(const struct hv_ring_buffer_info *ring_info)
 {
 	return ring_info->ring_datasize;
 }
 
 /* Get the read and write indices as u64 of the specified ring buffer. */
 static inline u64
 hv_get_ring_bufferindices(struct hv_ring_buffer_info *ring_info)
 {
 	return (u64)ring_info->ring_buffer->write_index << 32;
 }
 
 /*
  * Helper routine to copy to source from ring buffer.
  * Assume there is enough room. Handles wrap-around in src case only!!
  */
 static u32 hv_copyfrom_ringbuffer(
-	struct hv_ring_buffer_info	*ring_info,
+	const struct hv_ring_buffer_info *ring_info,
 	void				*dest,
 	u32				destlen,
 	u32				start_read_offset)
 {
 	void *ring_buffer = hv_get_ring_buffer(ring_info);
 	u32 ring_buffer_size = hv_get_ring_buffersize(ring_info);
 
 	memcpy(dest, ring_buffer + start_read_offset, destlen);
 
 	start_read_offset += destlen;
-	start_read_offset %= ring_buffer_size;
+	if (start_read_offset >= ring_buffer_size)
+		start_read_offset -= ring_buffer_size;
 
 	return start_read_offset;
 }
 
 
 /*
  * Helper routine to copy from source to ring buffer.
  * Assume there is enough room. Handles wrap-around in dest case only!!
  */
 static u32 hv_copyto_ringbuffer(
 	struct hv_ring_buffer_info	*ring_info,
 	u32				start_write_offset,
-	void				*src,
+	const void			*src,
 	u32				srclen)
 {
 	void *ring_buffer = hv_get_ring_buffer(ring_info);
 	u32 ring_buffer_size = hv_get_ring_buffersize(ring_info);
 
 	memcpy(ring_buffer + start_write_offset, src, srclen);
 
 	start_write_offset += srclen;
-	start_write_offset %= ring_buffer_size;
+	if (start_write_offset >= ring_buffer_size)
+		start_write_offset -= ring_buffer_size;
 
 	return start_write_offset;
 }
 
 /* Get various debug metrics for the specified ring buffer. */
-void hv_ringbuffer_get_debuginfo(struct hv_ring_buffer_info *ring_info,
-			    struct hv_ring_buffer_debug_info *debug_info)
+void hv_ringbuffer_get_debuginfo(const struct hv_ring_buffer_info *ring_info,
+				 struct hv_ring_buffer_debug_info *debug_info)
 {
 	u32 bytes_avail_towrite;
 	u32 bytes_avail_toread;
 
 	if (ring_info->ring_buffer) {
 		hv_get_ringbuffer_availbytes(ring_info,
 					&bytes_avail_toread,
 					&bytes_avail_towrite);
 
 		debug_info->bytes_avail_toread = bytes_avail_toread;
 		debug_info->bytes_avail_towrite = bytes_avail_towrite;
 		debug_info->current_read_index =
 			ring_info->ring_buffer->read_index;
 		debug_info->current_write_index =
 			ring_info->ring_buffer->write_index;
 		debug_info->current_interrupt_mask =
 			ring_info->ring_buffer->interrupt_mask;
 	}
 }
 
 /* Initialize the ring buffer. */
 int hv_ringbuffer_init(struct hv_ring_buffer_info *ring_info,
 		       struct page *pages, u32 page_cnt)
 {
 	int i;
 	struct page **pages_wraparound;
 
 	BUILD_BUG_ON((sizeof(struct hv_ring_buffer) != PAGE_SIZE));
 
 	memset(ring_info, 0, sizeof(struct hv_ring_buffer_info));
 
 	/*
 	 * First page holds struct hv_ring_buffer, do wraparound mapping for
 	 * the rest.
 	 */
 	pages_wraparound = kzalloc(sizeof(struct page *) * (page_cnt * 2 - 1),
 				   GFP_KERNEL);
 	if (!pages_wraparound)
 		return -ENOMEM;
 
 	pages_wraparound[0] = pages;
 	for (i = 0; i < 2 * (page_cnt - 1); i++)
 		pages_wraparound[i + 1] = &pages[i % (page_cnt - 1) + 1];
 
 	ring_info->ring_buffer = (struct hv_ring_buffer *)
 		vmap(pages_wraparound, page_cnt * 2 - 1, VM_MAP, PAGE_KERNEL);
 
 	kfree(pages_wraparound);
 
 
 	if (!ring_info->ring_buffer)
 		return -ENOMEM;
 
 	ring_info->ring_buffer->read_index =
 		ring_info->ring_buffer->write_index = 0;
 
 	/* Set the feature bit for enabling flow control. */
 	ring_info->ring_buffer->feature_bits.value = 1;
 
 	ring_info->ring_size = page_cnt << PAGE_SHIFT;
 	ring_info->ring_datasize = ring_info->ring_size -
 		sizeof(struct hv_ring_buffer);
 
 	spin_lock_init(&ring_info->ring_lock);
 
 	return 0;
 }
 
 /* Cleanup the ring buffer. */
 void hv_ringbuffer_cleanup(struct hv_ring_buffer_info *ring_info)
 {
 	vunmap(ring_info->ring_buffer);
 }
 
 /* Write to the ring buffer. */
 int hv_ringbuffer_write(struct vmbus_channel *channel,
-		    struct kvec *kv_list, u32 kv_count, bool lock,
-		    bool kick_q)
+			const struct kvec *kv_list, u32 kv_count)
 {
 	int i = 0;
 	u32 bytes_avail_towrite;
 	u32 totalbytes_towrite = 0;
 
 	u32 next_write_location;
 	u32 old_write;
 	u64 prev_indices = 0;
 	unsigned long flags = 0;
 	struct hv_ring_buffer_info *outring_info = &channel->outbound;
 
+	if (channel->rescind)
+		return -ENODEV;
+
 	for (i = 0; i < kv_count; i++)
 		totalbytes_towrite += kv_list[i].iov_len;
 
 	totalbytes_towrite += sizeof(u64);
 
-	if (lock)
-		spin_lock_irqsave(&outring_info->ring_lock, flags);
+	spin_lock_irqsave(&outring_info->ring_lock, flags);
 
 	bytes_avail_towrite = hv_get_bytes_to_write(outring_info);
 
 	/*
 	 * If there is only room for the packet, assume it is full.
 	 * Otherwise, the next time around, we think the ring buffer
 	 * is empty since the read index == write index.
 	 */
 	if (bytes_avail_towrite <= totalbytes_towrite) {
-		if (lock)
-			spin_unlock_irqrestore(&outring_info->ring_lock, flags);
+		spin_unlock_irqrestore(&outring_info->ring_lock, flags);
 		return -EAGAIN;
 	}
 
 	/* Write to the ring buffer */
 	next_write_location = hv_get_next_write_location(outring_info);
 
 	old_write = next_write_location;
 
 	for (i = 0; i < kv_count; i++) {
 		next_write_location = hv_copyto_ringbuffer(outring_info,
 						     next_write_location,
 						     kv_list[i].iov_base,
 						     kv_list[i].iov_len);
 	}
 
 	/* Set previous packet start */
 	prev_indices = hv_get_ring_bufferindices(outring_info);
 
 	next_write_location = hv_copyto_ringbuffer(outring_info,
 					     next_write_location,
 					     &prev_indices,
 					     sizeof(u64));
 
 	/* Issue a full memory barrier before updating the write index */
 	virt_mb();
 
 	/* Now, update the write location */
 	hv_set_next_write_location(outring_info, next_write_location);
 
 
-	if (lock)
-		spin_unlock_irqrestore(&outring_info->ring_lock, flags);
+	spin_unlock_irqrestore(&outring_info->ring_lock, flags);
+
+	hv_signal_on_write(old_write, channel);
+
+	if (channel->rescind)
+		return -ENODEV;
 
-	hv_signal_on_write(old_write, channel, kick_q);
 	return 0;
 }
 
 int hv_ringbuffer_read(struct vmbus_channel *channel,
 		       void *buffer, u32 buflen, u32 *buffer_actual_len,
 		       u64 *requestid, bool raw)
 {
 	u32 bytes_avail_toread;
 	u32 next_read_location = 0;
 	u64 prev_indices = 0;
 	struct vmpacket_descriptor desc;
 	u32 offset;
 	u32 packetlen;
 	int ret = 0;
 	struct hv_ring_buffer_info *inring_info = &channel->inbound;
 
 	if (buflen <= 0)
 		return -EINVAL;
 
 
 	*buffer_actual_len = 0;
 	*requestid = 0;
 
 	bytes_avail_toread = hv_get_bytes_to_read(inring_info);
 	/* Make sure there is something to read */
 	if (bytes_avail_toread < sizeof(desc)) {
 		/*
 		 * No error is set when there is even no header, drivers are
 		 * supposed to analyze buffer_actual_len.
 		 */
 		return ret;
 	}
 
 	init_cached_read_index(channel);
 	next_read_location = hv_get_next_read_location(inring_info);
 	next_read_location = hv_copyfrom_ringbuffer(inring_info, &desc,
 						    sizeof(desc),
 						    next_read_location);
 
 	offset = raw ? 0 : (desc.offset8 << 3);
 	packetlen = (desc.len8 << 3) - offset;
 	*buffer_actual_len = packetlen;
 	*requestid = desc.trans_id;
 
 	if (bytes_avail_toread < packetlen + offset)
 		return -EAGAIN;
 
 	if (packetlen > buflen)
 		return -ENOBUFS;
 
 	next_read_location =
 		hv_get_next_readlocation_withoffset(inring_info, offset);
 
 	next_read_location = hv_copyfrom_ringbuffer(inring_info,
 						buffer,
 						packetlen,
 						next_read_location);
 
 	next_read_location = hv_copyfrom_ringbuffer(inring_info,
 						&prev_indices,
 						sizeof(u64),
 						next_read_location);
 
 	/*
 	 * Make sure all reads are done before we update the read index since
 	 * the writer may start writing to the read area once the read index
 	 * is updated.
 	 */
 	virt_mb();
 
 	/* Update the read index */
 	hv_set_next_read_location(inring_info, next_read_location);
 
 	hv_signal_on_read(channel);
 
 	return ret;
 }
diff --git a/drivers/hv/vmbus_drv.c b/drivers/hv/vmbus_drv.c
index 230c62e7f567..f7f6b9144b07 100644
--- a/drivers/hv/vmbus_drv.c
+++ b/drivers/hv/vmbus_drv.c
@@ -1,1574 +1,1620 @@
 /*
  * Copyright (c) 2009, Microsoft Corporation.
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms and conditions of the GNU General Public License,
  * version 2, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope it will be useful, but WITHOUT
  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
  * more details.
  *
  * You should have received a copy of the GNU General Public License along with
  * this program; if not, write to the Free Software Foundation, Inc., 59 Temple
  * Place - Suite 330, Boston, MA 02111-1307 USA.
  *
  * Authors:
  *   Haiyang Zhang <haiyangz@microsoft.com>
  *   Hank Janssen  <hjanssen@microsoft.com>
  *   K. Y. Srinivasan <kys@microsoft.com>
  *
  */
 #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
 
 #include <linux/init.h>
 #include <linux/module.h>
 #include <linux/device.h>
 #include <linux/interrupt.h>
 #include <linux/sysctl.h>
 #include <linux/slab.h>
 #include <linux/acpi.h>
 #include <linux/completion.h>
 #include <linux/hyperv.h>
 #include <linux/kernel_stat.h>
 #include <linux/clockchips.h>
 #include <linux/cpu.h>
 #include <asm/hyperv.h>
 #include <asm/hypervisor.h>
 #include <asm/mshyperv.h>
 #include <linux/notifier.h>
 #include <linux/ptrace.h>
 #include <linux/screen_info.h>
 #include <linux/kdebug.h>
 #include <linux/efi.h>
 #include <linux/random.h>
 #include "hyperv_vmbus.h"
 
 struct vmbus_dynid {
 	struct list_head node;
 	struct hv_vmbus_device_id id;
 };
 
 static struct acpi_device  *hv_acpi_dev;
 
 static struct completion probe_event;
 
-
-static void hyperv_report_panic(struct pt_regs *regs)
-{
-	static bool panic_reported;
-
-	/*
-	 * We prefer to report panic on 'die' chain as we have proper
-	 * registers to report, but if we miss it (e.g. on BUG()) we need
-	 * to report it on 'panic'.
-	 */
-	if (panic_reported)
-		return;
-	panic_reported = true;
-
-	wrmsrl(HV_X64_MSR_CRASH_P0, regs->ip);
-	wrmsrl(HV_X64_MSR_CRASH_P1, regs->ax);
-	wrmsrl(HV_X64_MSR_CRASH_P2, regs->bx);
-	wrmsrl(HV_X64_MSR_CRASH_P3, regs->cx);
-	wrmsrl(HV_X64_MSR_CRASH_P4, regs->dx);
-
-	/*
-	 * Let Hyper-V know there is crash data available
-	 */
-	wrmsrl(HV_X64_MSR_CRASH_CTL, HV_CRASH_CTL_CRASH_NOTIFY);
-}
+static int hyperv_cpuhp_online;
 
 static int hyperv_panic_event(struct notifier_block *nb, unsigned long val,
 			      void *args)
 {
 	struct pt_regs *regs;
 
 	regs = current_pt_regs();
 
 	hyperv_report_panic(regs);
 	return NOTIFY_DONE;
 }
 
 static int hyperv_die_event(struct notifier_block *nb, unsigned long val,
 			    void *args)
 {
 	struct die_args *die = (struct die_args *)args;
 	struct pt_regs *regs = die->regs;
 
 	hyperv_report_panic(regs);
 	return NOTIFY_DONE;
 }
 
 static struct notifier_block hyperv_die_block = {
 	.notifier_call = hyperv_die_event,
 };
 static struct notifier_block hyperv_panic_block = {
 	.notifier_call = hyperv_panic_event,
 };
 
 static const char *fb_mmio_name = "fb_range";
 static struct resource *fb_mmio;
 static struct resource *hyperv_mmio;
 static DEFINE_SEMAPHORE(hyperv_mmio_lock);
 
 static int vmbus_exists(void)
 {
 	if (hv_acpi_dev == NULL)
 		return -ENODEV;
 
 	return 0;
 }
 
 #define VMBUS_ALIAS_LEN ((sizeof((struct hv_vmbus_device_id *)0)->guid) * 2)
 static void print_alias_name(struct hv_device *hv_dev, char *alias_name)
 {
 	int i;
 	for (i = 0; i < VMBUS_ALIAS_LEN; i += 2)
 		sprintf(&alias_name[i], "%02x", hv_dev->dev_type.b[i/2]);
 }
 
 static u8 channel_monitor_group(struct vmbus_channel *channel)
 {
 	return (u8)channel->offermsg.monitorid / 32;
 }
 
 static u8 channel_monitor_offset(struct vmbus_channel *channel)
 {
 	return (u8)channel->offermsg.monitorid % 32;
 }
 
 static u32 channel_pending(struct vmbus_channel *channel,
 			   struct hv_monitor_page *monitor_page)
 {
 	u8 monitor_group = channel_monitor_group(channel);
 	return monitor_page->trigger_group[monitor_group].pending;
 }
 
 static u32 channel_latency(struct vmbus_channel *channel,
 			   struct hv_monitor_page *monitor_page)
 {
 	u8 monitor_group = channel_monitor_group(channel);
 	u8 monitor_offset = channel_monitor_offset(channel);
 	return monitor_page->latency[monitor_group][monitor_offset];
 }
 
 static u32 channel_conn_id(struct vmbus_channel *channel,
 			   struct hv_monitor_page *monitor_page)
 {
 	u8 monitor_group = channel_monitor_group(channel);
 	u8 monitor_offset = channel_monitor_offset(channel);
 	return monitor_page->parameter[monitor_group][monitor_offset].connectionid.u.id;
 }
 
 static ssize_t id_show(struct device *dev, struct device_attribute *dev_attr,
 		       char *buf)
 {
 	struct hv_device *hv_dev = device_to_hv_device(dev);
 
 	if (!hv_dev->channel)
 		return -ENODEV;
 	return sprintf(buf, "%d\n", hv_dev->channel->offermsg.child_relid);
 }
 static DEVICE_ATTR_RO(id);
 
 static ssize_t state_show(struct device *dev, struct device_attribute *dev_attr,
 			  char *buf)
 {
 	struct hv_device *hv_dev = device_to_hv_device(dev);
 
 	if (!hv_dev->channel)
 		return -ENODEV;
 	return sprintf(buf, "%d\n", hv_dev->channel->state);
 }
 static DEVICE_ATTR_RO(state);
 
 static ssize_t monitor_id_show(struct device *dev,
 			       struct device_attribute *dev_attr, char *buf)
 {
 	struct hv_device *hv_dev = device_to_hv_device(dev);
 
 	if (!hv_dev->channel)
 		return -ENODEV;
 	return sprintf(buf, "%d\n", hv_dev->channel->offermsg.monitorid);
 }
 static DEVICE_ATTR_RO(monitor_id);
 
 static ssize_t class_id_show(struct device *dev,
 			       struct device_attribute *dev_attr, char *buf)
 {
 	struct hv_device *hv_dev = device_to_hv_device(dev);
 
 	if (!hv_dev->channel)
 		return -ENODEV;
 	return sprintf(buf, "{%pUl}\n",
 		       hv_dev->channel->offermsg.offer.if_type.b);
 }
 static DEVICE_ATTR_RO(class_id);
 
 static ssize_t device_id_show(struct device *dev,
 			      struct device_attribute *dev_attr, char *buf)
 {
 	struct hv_device *hv_dev = device_to_hv_device(dev);
 
 	if (!hv_dev->channel)
 		return -ENODEV;
 	return sprintf(buf, "{%pUl}\n",
 		       hv_dev->channel->offermsg.offer.if_instance.b);
 }
 static DEVICE_ATTR_RO(device_id);
 
 static ssize_t modalias_show(struct device *dev,
 			     struct device_attribute *dev_attr, char *buf)
 {
 	struct hv_device *hv_dev = device_to_hv_device(dev);
 	char alias_name[VMBUS_ALIAS_LEN + 1];
 
 	print_alias_name(hv_dev, alias_name);
 	return sprintf(buf, "vmbus:%s\n", alias_name);
 }
 static DEVICE_ATTR_RO(modalias);
 
 static ssize_t server_monitor_pending_show(struct device *dev,
 					   struct device_attribute *dev_attr,
 					   char *buf)
 {
 	struct hv_device *hv_dev = device_to_hv_device(dev);
 
 	if (!hv_dev->channel)
 		return -ENODEV;
 	return sprintf(buf, "%d\n",
 		       channel_pending(hv_dev->channel,
 				       vmbus_connection.monitor_pages[1]));
 }
 static DEVICE_ATTR_RO(server_monitor_pending);
 
 static ssize_t client_monitor_pending_show(struct device *dev,
 					   struct device_attribute *dev_attr,
 					   char *buf)
 {
 	struct hv_device *hv_dev = device_to_hv_device(dev);
 
 	if (!hv_dev->channel)
 		return -ENODEV;
 	return sprintf(buf, "%d\n",
 		       channel_pending(hv_dev->channel,
 				       vmbus_connection.monitor_pages[1]));
 }
 static DEVICE_ATTR_RO(client_monitor_pending);
 
 static ssize_t server_monitor_latency_show(struct device *dev,
 					   struct device_attribute *dev_attr,
 					   char *buf)
 {
 	struct hv_device *hv_dev = device_to_hv_device(dev);
 
 	if (!hv_dev->channel)
 		return -ENODEV;
 	return sprintf(buf, "%d\n",
 		       channel_latency(hv_dev->channel,
 				       vmbus_connection.monitor_pages[0]));
 }
 static DEVICE_ATTR_RO(server_monitor_latency);
 
 static ssize_t client_monitor_latency_show(struct device *dev,
 					   struct device_attribute *dev_attr,
 					   char *buf)
 {
 	struct hv_device *hv_dev = device_to_hv_device(dev);
 
 	if (!hv_dev->channel)
 		return -ENODEV;
 	return sprintf(buf, "%d\n",
 		       channel_latency(hv_dev->channel,
 				       vmbus_connection.monitor_pages[1]));
 }
 static DEVICE_ATTR_RO(client_monitor_latency);
 
 static ssize_t server_monitor_conn_id_show(struct device *dev,
 					   struct device_attribute *dev_attr,
 					   char *buf)
 {
 	struct hv_device *hv_dev = device_to_hv_device(dev);
 
 	if (!hv_dev->channel)
 		return -ENODEV;
 	return sprintf(buf, "%d\n",
 		       channel_conn_id(hv_dev->channel,
 				       vmbus_connection.monitor_pages[0]));
 }
 static DEVICE_ATTR_RO(server_monitor_conn_id);
 
 static ssize_t client_monitor_conn_id_show(struct device *dev,
 					   struct device_attribute *dev_attr,
 					   char *buf)
 {
 	struct hv_device *hv_dev = device_to_hv_device(dev);
 
 	if (!hv_dev->channel)
 		return -ENODEV;
 	return sprintf(buf, "%d\n",
 		       channel_conn_id(hv_dev->channel,
 				       vmbus_connection.monitor_pages[1]));
 }
 static DEVICE_ATTR_RO(client_monitor_conn_id);
 
 static ssize_t out_intr_mask_show(struct device *dev,
 				  struct device_attribute *dev_attr, char *buf)
 {
 	struct hv_device *hv_dev = device_to_hv_device(dev);
 	struct hv_ring_buffer_debug_info outbound;
 
 	if (!hv_dev->channel)
 		return -ENODEV;
 	hv_ringbuffer_get_debuginfo(&hv_dev->channel->outbound, &outbound);
 	return sprintf(buf, "%d\n", outbound.current_interrupt_mask);
 }
 static DEVICE_ATTR_RO(out_intr_mask);
 
 static ssize_t out_read_index_show(struct device *dev,
 				   struct device_attribute *dev_attr, char *buf)
 {
 	struct hv_device *hv_dev = device_to_hv_device(dev);
 	struct hv_ring_buffer_debug_info outbound;
 
 	if (!hv_dev->channel)
 		return -ENODEV;
 	hv_ringbuffer_get_debuginfo(&hv_dev->channel->outbound, &outbound);
 	return sprintf(buf, "%d\n", outbound.current_read_index);
 }
 static DEVICE_ATTR_RO(out_read_index);
 
 static ssize_t out_write_index_show(struct device *dev,
 				    struct device_attribute *dev_attr,
 				    char *buf)
 {
 	struct hv_device *hv_dev = device_to_hv_device(dev);
 	struct hv_ring_buffer_debug_info outbound;
 
 	if (!hv_dev->channel)
 		return -ENODEV;
 	hv_ringbuffer_get_debuginfo(&hv_dev->channel->outbound, &outbound);
 	return sprintf(buf, "%d\n", outbound.current_write_index);
 }
 static DEVICE_ATTR_RO(out_write_index);
 
 static ssize_t out_read_bytes_avail_show(struct device *dev,
 					 struct device_attribute *dev_attr,
 					 char *buf)
 {
 	struct hv_device *hv_dev = device_to_hv_device(dev);
 	struct hv_ring_buffer_debug_info outbound;
 
 	if (!hv_dev->channel)
 		return -ENODEV;
 	hv_ringbuffer_get_debuginfo(&hv_dev->channel->outbound, &outbound);
 	return sprintf(buf, "%d\n", outbound.bytes_avail_toread);
 }
 static DEVICE_ATTR_RO(out_read_bytes_avail);
 
 static ssize_t out_write_bytes_avail_show(struct device *dev,
 					  struct device_attribute *dev_attr,
 					  char *buf)
 {
 	struct hv_device *hv_dev = device_to_hv_device(dev);
 	struct hv_ring_buffer_debug_info outbound;
 
 	if (!hv_dev->channel)
 		return -ENODEV;
 	hv_ringbuffer_get_debuginfo(&hv_dev->channel->outbound, &outbound);
 	return sprintf(buf, "%d\n", outbound.bytes_avail_towrite);
 }
 static DEVICE_ATTR_RO(out_write_bytes_avail);
 
 static ssize_t in_intr_mask_show(struct device *dev,
 				 struct device_attribute *dev_attr, char *buf)
 {
 	struct hv_device *hv_dev = device_to_hv_device(dev);
 	struct hv_ring_buffer_debug_info inbound;
 
 	if (!hv_dev->channel)
 		return -ENODEV;
 	hv_ringbuffer_get_debuginfo(&hv_dev->channel->inbound, &inbound);
 	return sprintf(buf, "%d\n", inbound.current_interrupt_mask);
 }
 static DEVICE_ATTR_RO(in_intr_mask);
 
 static ssize_t in_read_index_show(struct device *dev,
 				  struct device_attribute *dev_attr, char *buf)
 {
 	struct hv_device *hv_dev = device_to_hv_device(dev);
 	struct hv_ring_buffer_debug_info inbound;
 
 	if (!hv_dev->channel)
 		return -ENODEV;
 	hv_ringbuffer_get_debuginfo(&hv_dev->channel->inbound, &inbound);
 	return sprintf(buf, "%d\n", inbound.current_read_index);
 }
 static DEVICE_ATTR_RO(in_read_index);
 
 static ssize_t in_write_index_show(struct device *dev,
 				   struct device_attribute *dev_attr, char *buf)
 {
 	struct hv_device *hv_dev = device_to_hv_device(dev);
 	struct hv_ring_buffer_debug_info inbound;
 
 	if (!hv_dev->channel)
 		return -ENODEV;
 	hv_ringbuffer_get_debuginfo(&hv_dev->channel->inbound, &inbound);
 	return sprintf(buf, "%d\n", inbound.current_write_index);
 }
 static DEVICE_ATTR_RO(in_write_index);
 
 static ssize_t in_read_bytes_avail_show(struct device *dev,
 					struct device_attribute *dev_attr,
 					char *buf)
 {
 	struct hv_device *hv_dev = device_to_hv_device(dev);
 	struct hv_ring_buffer_debug_info inbound;
 
 	if (!hv_dev->channel)
 		return -ENODEV;
 	hv_ringbuffer_get_debuginfo(&hv_dev->channel->inbound, &inbound);
 	return sprintf(buf, "%d\n", inbound.bytes_avail_toread);
 }
 static DEVICE_ATTR_RO(in_read_bytes_avail);
 
 static ssize_t in_write_bytes_avail_show(struct device *dev,
 					 struct device_attribute *dev_attr,
 					 char *buf)
 {
 	struct hv_device *hv_dev = device_to_hv_device(dev);
 	struct hv_ring_buffer_debug_info inbound;
 
 	if (!hv_dev->channel)
 		return -ENODEV;
 	hv_ringbuffer_get_debuginfo(&hv_dev->channel->inbound, &inbound);
 	return sprintf(buf, "%d\n", inbound.bytes_avail_towrite);
 }
 static DEVICE_ATTR_RO(in_write_bytes_avail);
 
 static ssize_t channel_vp_mapping_show(struct device *dev,
 				       struct device_attribute *dev_attr,
 				       char *buf)
 {
 	struct hv_device *hv_dev = device_to_hv_device(dev);
 	struct vmbus_channel *channel = hv_dev->channel, *cur_sc;
 	unsigned long flags;
 	int buf_size = PAGE_SIZE, n_written, tot_written;
 	struct list_head *cur;
 
 	if (!channel)
 		return -ENODEV;
 
 	tot_written = snprintf(buf, buf_size, "%u:%u\n",
 		channel->offermsg.child_relid, channel->target_cpu);
 
 	spin_lock_irqsave(&channel->lock, flags);
 
 	list_for_each(cur, &channel->sc_list) {
 		if (tot_written >= buf_size - 1)
 			break;
 
 		cur_sc = list_entry(cur, struct vmbus_channel, sc_list);
 		n_written = scnprintf(buf + tot_written,
 				     buf_size - tot_written,
 				     "%u:%u\n",
 				     cur_sc->offermsg.child_relid,
 				     cur_sc->target_cpu);
 		tot_written += n_written;
 	}
 
 	spin_unlock_irqrestore(&channel->lock, flags);
 
 	return tot_written;
 }
 static DEVICE_ATTR_RO(channel_vp_mapping);
 
 static ssize_t vendor_show(struct device *dev,
 			   struct device_attribute *dev_attr,
 			   char *buf)
 {
 	struct hv_device *hv_dev = device_to_hv_device(dev);
 	return sprintf(buf, "0x%x\n", hv_dev->vendor_id);
 }
 static DEVICE_ATTR_RO(vendor);
 
 static ssize_t device_show(struct device *dev,
 			   struct device_attribute *dev_attr,
 			   char *buf)
 {
 	struct hv_device *hv_dev = device_to_hv_device(dev);
 	return sprintf(buf, "0x%x\n", hv_dev->device_id);
 }
 static DEVICE_ATTR_RO(device);
 
 /* Set up per device attributes in /sys/bus/vmbus/devices/<bus device> */
 static struct attribute *vmbus_dev_attrs[] = {
 	&dev_attr_id.attr,
 	&dev_attr_state.attr,
 	&dev_attr_monitor_id.attr,
 	&dev_attr_class_id.attr,
 	&dev_attr_device_id.attr,
 	&dev_attr_modalias.attr,
 	&dev_attr_server_monitor_pending.attr,
 	&dev_attr_client_monitor_pending.attr,
 	&dev_attr_server_monitor_latency.attr,
 	&dev_attr_client_monitor_latency.attr,
 	&dev_attr_server_monitor_conn_id.attr,
 	&dev_attr_client_monitor_conn_id.attr,
 	&dev_attr_out_intr_mask.attr,
 	&dev_attr_out_read_index.attr,
 	&dev_attr_out_write_index.attr,
 	&dev_attr_out_read_bytes_avail.attr,
 	&dev_attr_out_write_bytes_avail.attr,
 	&dev_attr_in_intr_mask.attr,
 	&dev_attr_in_read_index.attr,
 	&dev_attr_in_write_index.attr,
 	&dev_attr_in_read_bytes_avail.attr,
 	&dev_attr_in_write_bytes_avail.attr,
 	&dev_attr_channel_vp_mapping.attr,
 	&dev_attr_vendor.attr,
 	&dev_attr_device.attr,
 	NULL,
 };
 ATTRIBUTE_GROUPS(vmbus_dev);
 
 /*
  * vmbus_uevent - add uevent for our device
  *
  * This routine is invoked when a device is added or removed on the vmbus to
  * generate a uevent to udev in the userspace. The udev will then look at its
  * rule and the uevent generated here to load the appropriate driver
  *
  * The alias string will be of the form vmbus:guid where guid is the string
  * representation of the device guid (each byte of the guid will be
  * represented with two hex characters.
  */
 static int vmbus_uevent(struct device *device, struct kobj_uevent_env *env)
 {
 	struct hv_device *dev = device_to_hv_device(device);
 	int ret;
 	char alias_name[VMBUS_ALIAS_LEN + 1];
 
 	print_alias_name(dev, alias_name);
 	ret = add_uevent_var(env, "MODALIAS=vmbus:%s", alias_name);
 	return ret;
 }
 
 static const uuid_le null_guid;
 
 static inline bool is_null_guid(const uuid_le *guid)
 {
 	if (uuid_le_cmp(*guid, null_guid))
 		return false;
 	return true;
 }
 
 /*
  * Return a matching hv_vmbus_device_id pointer.
  * If there is no match, return NULL.
  */
 static const struct hv_vmbus_device_id *hv_vmbus_get_id(struct hv_driver *drv,
 					const uuid_le *guid)
 {
 	const struct hv_vmbus_device_id *id = NULL;
 	struct vmbus_dynid *dynid;
 
 	/* Look at the dynamic ids first, before the static ones */
 	spin_lock(&drv->dynids.lock);
 	list_for_each_entry(dynid, &drv->dynids.list, node) {
 		if (!uuid_le_cmp(dynid->id.guid, *guid)) {
 			id = &dynid->id;
 			break;
 		}
 	}
 	spin_unlock(&drv->dynids.lock);
 
 	if (id)
 		return id;
 
 	id = drv->id_table;
 	if (id == NULL)
 		return NULL; /* empty device table */
 
 	for (; !is_null_guid(&id->guid); id++)
 		if (!uuid_le_cmp(id->guid, *guid))
 			return id;
 
 	return NULL;
 }
 
 /* vmbus_add_dynid - add a new device ID to this driver and re-probe devices */
 static int vmbus_add_dynid(struct hv_driver *drv, uuid_le *guid)
 {
 	struct vmbus_dynid *dynid;
 
 	dynid = kzalloc(sizeof(*dynid), GFP_KERNEL);
 	if (!dynid)
 		return -ENOMEM;
 
 	dynid->id.guid = *guid;
 
 	spin_lock(&drv->dynids.lock);
 	list_add_tail(&dynid->node, &drv->dynids.list);
 	spin_unlock(&drv->dynids.lock);
 
 	return driver_attach(&drv->driver);
 }
 
 static void vmbus_free_dynids(struct hv_driver *drv)
 {
 	struct vmbus_dynid *dynid, *n;
 
 	spin_lock(&drv->dynids.lock);
 	list_for_each_entry_safe(dynid, n, &drv->dynids.list, node) {
 		list_del(&dynid->node);
 		kfree(dynid);
 	}
 	spin_unlock(&drv->dynids.lock);
 }
 
 /* Parse string of form: 1b4e28ba-2fa1-11d2-883f-b9a761bde3f */
 static int get_uuid_le(const char *str, uuid_le *uu)
 {
 	unsigned int b[16];
 	int i;
 
 	if (strlen(str) < 37)
 		return -1;
 
 	for (i = 0; i < 36; i++) {
 		switch (i) {
 		case 8: case 13: case 18: case 23:
 			if (str[i] != '-')
 				return -1;
 			break;
 		default:
 			if (!isxdigit(str[i]))
 				return -1;
 		}
 	}
 
 	/* unparse little endian output byte order */
 	if (sscanf(str,
 		   "%2x%2x%2x%2x-%2x%2x-%2x%2x-%2x%2x-%2x%2x%2x%2x%2x%2x",
 		   &b[3], &b[2], &b[1], &b[0],
 		   &b[5], &b[4], &b[7], &b[6], &b[8], &b[9],
 		   &b[10], &b[11], &b[12], &b[13], &b[14], &b[15]) != 16)
 		return -1;
 
 	for (i = 0; i < 16; i++)
 		uu->b[i] = b[i];
 	return 0;
 }
 
 /*
  * store_new_id - sysfs frontend to vmbus_add_dynid()
  *
  * Allow GUIDs to be added to an existing driver via sysfs.
  */
 static ssize_t new_id_store(struct device_driver *driver, const char *buf,
 			    size_t count)
 {
 	struct hv_driver *drv = drv_to_hv_drv(driver);
 	uuid_le guid = NULL_UUID_LE;
 	ssize_t retval;
 
 	if (get_uuid_le(buf, &guid) != 0)
 		return -EINVAL;
 
 	if (hv_vmbus_get_id(drv, &guid))
 		return -EEXIST;
 
 	retval = vmbus_add_dynid(drv, &guid);
 	if (retval)
 		return retval;
 	return count;
 }
 static DRIVER_ATTR_WO(new_id);
 
 /*
  * store_remove_id - remove a PCI device ID from this driver
  *
  * Removes a dynamic pci device ID to this driver.
  */
 static ssize_t remove_id_store(struct device_driver *driver, const char *buf,
 			       size_t count)
 {
 	struct hv_driver *drv = drv_to_hv_drv(driver);
 	struct vmbus_dynid *dynid, *n;
 	uuid_le guid = NULL_UUID_LE;
 	size_t retval = -ENODEV;
 
 	if (get_uuid_le(buf, &guid))
 		return -EINVAL;
 
 	spin_lock(&drv->dynids.lock);
 	list_for_each_entry_safe(dynid, n, &drv->dynids.list, node) {
 		struct hv_vmbus_device_id *id = &dynid->id;
 
 		if (!uuid_le_cmp(id->guid, guid)) {
 			list_del(&dynid->node);
 			kfree(dynid);
 			retval = count;
 			break;
 		}
 	}
 	spin_unlock(&drv->dynids.lock);
 
 	return retval;
 }
 static DRIVER_ATTR_WO(remove_id);
 
 static struct attribute *vmbus_drv_attrs[] = {
 	&driver_attr_new_id.attr,
 	&driver_attr_remove_id.attr,
 	NULL,
 };
 ATTRIBUTE_GROUPS(vmbus_drv);
 
 
 /*
  * vmbus_match - Attempt to match the specified device to the specified driver
  */
 static int vmbus_match(struct device *device, struct device_driver *driver)
 {
 	struct hv_driver *drv = drv_to_hv_drv(driver);
 	struct hv_device *hv_dev = device_to_hv_device(device);
 
 	/* The hv_sock driver handles all hv_sock offers. */
 	if (is_hvsock_channel(hv_dev->channel))
 		return drv->hvsock;
 
 	if (hv_vmbus_get_id(drv, &hv_dev->dev_type))
 		return 1;
 
 	return 0;
 }
 
 /*
  * vmbus_probe - Add the new vmbus's child device
  */
 static int vmbus_probe(struct device *child_device)
 {
 	int ret = 0;
 	struct hv_driver *drv =
 			drv_to_hv_drv(child_device->driver);
 	struct hv_device *dev = device_to_hv_device(child_device);
 	const struct hv_vmbus_device_id *dev_id;
 
 	dev_id = hv_vmbus_get_id(drv, &dev->dev_type);
 	if (drv->probe) {
 		ret = drv->probe(dev, dev_id);
 		if (ret != 0)
 			pr_err("probe failed for device %s (%d)\n",
 			       dev_name(child_device), ret);
 
 	} else {
 		pr_err("probe not set for driver %s\n",
 		       dev_name(child_device));
 		ret = -ENODEV;
 	}
 	return ret;
 }
 
 /*
  * vmbus_remove - Remove a vmbus device
  */
 static int vmbus_remove(struct device *child_device)
 {
 	struct hv_driver *drv;
 	struct hv_device *dev = device_to_hv_device(child_device);
 
 	if (child_device->driver) {
 		drv = drv_to_hv_drv(child_device->driver);
 		if (drv->remove)
 			drv->remove(dev);
 	}
 
 	return 0;
 }
 
 
 /*
  * vmbus_shutdown - Shutdown a vmbus device
  */
 static void vmbus_shutdown(struct device *child_device)
 {
 	struct hv_driver *drv;
 	struct hv_device *dev = device_to_hv_device(child_device);
 
 
 	/* The device may not be attached yet */
 	if (!child_device->driver)
 		return;
 
 	drv = drv_to_hv_drv(child_device->driver);
 
 	if (drv->shutdown)
 		drv->shutdown(dev);
 
 	return;
 }
 
 
 /*
  * vmbus_device_release - Final callback release of the vmbus child device
  */
 static void vmbus_device_release(struct device *device)
 {
 	struct hv_device *hv_dev = device_to_hv_device(device);
 	struct vmbus_channel *channel = hv_dev->channel;
 
 	hv_process_channel_removal(channel,
 				   channel->offermsg.child_relid);
 	kfree(hv_dev);
 
 }
 
 /* The one and only one */
 static struct bus_type  hv_bus = {
 	.name =		"vmbus",
 	.match =		vmbus_match,
 	.shutdown =		vmbus_shutdown,
 	.remove =		vmbus_remove,
 	.probe =		vmbus_probe,
 	.uevent =		vmbus_uevent,
 	.dev_groups =		vmbus_dev_groups,
 	.drv_groups =		vmbus_drv_groups,
 };
 
 struct onmessage_work_context {
 	struct work_struct work;
 	struct hv_message msg;
 };
 
 static void vmbus_onmessage_work(struct work_struct *work)
 {
 	struct onmessage_work_context *ctx;
 
 	/* Do not process messages if we're in DISCONNECTED state */
 	if (vmbus_connection.conn_state == DISCONNECTED)
 		return;
 
 	ctx = container_of(work, struct onmessage_work_context,
 			   work);
 	vmbus_onmessage(&ctx->msg);
 	kfree(ctx);
 }
 
-static void hv_process_timer_expiration(struct hv_message *msg, int cpu)
+static void hv_process_timer_expiration(struct hv_message *msg,
+					struct hv_per_cpu_context *hv_cpu)
 {
-	struct clock_event_device *dev = hv_context.clk_evt[cpu];
+	struct clock_event_device *dev = hv_cpu->clk_evt;
 
 	if (dev->event_handler)
 		dev->event_handler(dev);
 
 	vmbus_signal_eom(msg, HVMSG_TIMER_EXPIRED);
 }
 
 void vmbus_on_msg_dpc(unsigned long data)
 {
-	int cpu = smp_processor_id();
-	void *page_addr = hv_context.synic_message_page[cpu];
+	struct hv_per_cpu_context *hv_cpu = (void *)data;
+	void *page_addr = hv_cpu->synic_message_page;
 	struct hv_message *msg = (struct hv_message *)page_addr +
 				  VMBUS_MESSAGE_SINT;
 	struct vmbus_channel_message_header *hdr;
 	struct vmbus_channel_message_table_entry *entry;
 	struct onmessage_work_context *ctx;
 	u32 message_type = msg->header.message_type;
 
 	if (message_type == HVMSG_NONE)
 		/* no msg */
 		return;
 
 	hdr = (struct vmbus_channel_message_header *)msg->u.payload;
 
 	if (hdr->msgtype >= CHANNELMSG_COUNT) {
 		WARN_ONCE(1, "unknown msgtype=%d\n", hdr->msgtype);
 		goto msg_handled;
 	}
 
 	entry = &channel_message_table[hdr->msgtype];
 	if (entry->handler_type	== VMHT_BLOCKING) {
 		ctx = kmalloc(sizeof(*ctx), GFP_ATOMIC);
 		if (ctx == NULL)
 			return;
 
 		INIT_WORK(&ctx->work, vmbus_onmessage_work);
 		memcpy(&ctx->msg, msg, sizeof(*msg));
 
 		queue_work(vmbus_connection.work_queue, &ctx->work);
 	} else
 		entry->message_handler(hdr);
 
 msg_handled:
 	vmbus_signal_eom(msg, message_type);
 }
 
+
+/*
+ * Direct callback for channels using other deferred processing
+ */
+static void vmbus_channel_isr(struct vmbus_channel *channel)
+{
+	void (*callback_fn)(void *);
+
+	callback_fn = READ_ONCE(channel->onchannel_callback);
+	if (likely(callback_fn != NULL))
+		(*callback_fn)(channel->channel_callback_context);
+}
+
+/*
+ * Schedule all channels with events pending
+ */
+static void vmbus_chan_sched(struct hv_per_cpu_context *hv_cpu)
+{
+	unsigned long *recv_int_page;
+	u32 maxbits, relid;
+
+	if (vmbus_proto_version < VERSION_WIN8) {
+		maxbits = MAX_NUM_CHANNELS_SUPPORTED;
+		recv_int_page = vmbus_connection.recv_int_page;
+	} else {
+		/*
+		 * When the host is win8 and beyond, the event page
+		 * can be directly checked to get the id of the channel
+		 * that has the interrupt pending.
+		 */
+		void *page_addr = hv_cpu->synic_event_page;
+		union hv_synic_event_flags *event
+			= (union hv_synic_event_flags *)page_addr +
+						 VMBUS_MESSAGE_SINT;
+
+		maxbits = HV_EVENT_FLAGS_COUNT;
+		recv_int_page = event->flags;
+	}
+
+	if (unlikely(!recv_int_page))
+		return;
+
+	for_each_set_bit(relid, recv_int_page, maxbits) {
+		struct vmbus_channel *channel;
+
+		if (!sync_test_and_clear_bit(relid, recv_int_page))
+			continue;
+
+		/* Special case - vmbus channel protocol msg */
+		if (relid == 0)
+			continue;
+
+		/* Find channel based on relid */
+		list_for_each_entry(channel, &hv_cpu->chan_list, percpu_list) {
+			if (channel->offermsg.child_relid != relid)
+				continue;
+
+			switch (channel->callback_mode) {
+			case HV_CALL_ISR:
+				vmbus_channel_isr(channel);
+				break;
+
+			case HV_CALL_BATCHED:
+				hv_begin_read(&channel->inbound);
+				/* fallthrough */
+			case HV_CALL_DIRECT:
+				tasklet_schedule(&channel->callback_event);
+			}
+		}
+	}
+}
+
 static void vmbus_isr(void)
 {
-	int cpu = smp_processor_id();
-	void *page_addr;
+	struct hv_per_cpu_context *hv_cpu
+		= this_cpu_ptr(hv_context.cpu_context);
+	void *page_addr = hv_cpu->synic_event_page;
 	struct hv_message *msg;
 	union hv_synic_event_flags *event;
 	bool handled = false;
 
-	page_addr = hv_context.synic_event_page[cpu];
-	if (page_addr == NULL)
+	if (unlikely(page_addr == NULL))
 		return;
 
 	event = (union hv_synic_event_flags *)page_addr +
 					 VMBUS_MESSAGE_SINT;
 	/*
 	 * Check for events before checking for messages. This is the order
 	 * in which events and messages are checked in Windows guests on
 	 * Hyper-V, and the Windows team suggested we do the same.
 	 */
 
 	if ((vmbus_proto_version == VERSION_WS2008) ||
 		(vmbus_proto_version == VERSION_WIN7)) {
 
 		/* Since we are a child, we only need to check bit 0 */
-		if (sync_test_and_clear_bit(0,
-			(unsigned long *) &event->flags32[0])) {
+		if (sync_test_and_clear_bit(0, event->flags))
 			handled = true;
-		}
 	} else {
 		/*
 		 * Our host is win8 or above. The signaling mechanism
 		 * has changed and we can directly look at the event page.
 		 * If bit n is set then we have an interrup on the channel
 		 * whose id is n.
 		 */
 		handled = true;
 	}
 
 	if (handled)
-		tasklet_schedule(hv_context.event_dpc[cpu]);
-
+		vmbus_chan_sched(hv_cpu);
 
-	page_addr = hv_context.synic_message_page[cpu];
+	page_addr = hv_cpu->synic_message_page;
 	msg = (struct hv_message *)page_addr + VMBUS_MESSAGE_SINT;
 
 	/* Check if there are actual msgs to be processed */
 	if (msg->header.message_type != HVMSG_NONE) {
 		if (msg->header.message_type == HVMSG_TIMER_EXPIRED)
-			hv_process_timer_expiration(msg, cpu);
+			hv_process_timer_expiration(msg, hv_cpu);
 		else
-			tasklet_schedule(hv_context.msg_dpc[cpu]);
+			tasklet_schedule(&hv_cpu->msg_dpc);
 	}
 
 	add_interrupt_randomness(HYPERVISOR_CALLBACK_VECTOR, 0);
 }
 
 
 /*
  * vmbus_bus_init -Main vmbus driver initialization routine.
  *
  * Here, we
  *	- initialize the vmbus driver context
  *	- invoke the vmbus hv main init routine
  *	- retrieve the channel offers
  */
 static int vmbus_bus_init(void)
 {
 	int ret;
 
 	/* Hypervisor initialization...setup hypercall page..etc */
 	ret = hv_init();
 	if (ret != 0) {
 		pr_err("Unable to initialize the hypervisor - 0x%x\n", ret);
 		return ret;
 	}
 
 	ret = bus_register(&hv_bus);
 	if (ret)
-		goto err_cleanup;
+		return ret;
 
 	hv_setup_vmbus_irq(vmbus_isr);
 
 	ret = hv_synic_alloc();
 	if (ret)
 		goto err_alloc;
 	/*
 	 * Initialize the per-cpu interrupt state and
 	 * connect to the host.
 	 */
-	on_each_cpu(hv_synic_init, NULL, 1);
+	ret = cpuhp_setup_state(CPUHP_AP_ONLINE_DYN, "x86/hyperv:online",
+				hv_synic_init, hv_synic_cleanup);
+	if (ret < 0)
+		goto err_alloc;
+	hyperv_cpuhp_online = ret;
+
 	ret = vmbus_connect();
 	if (ret)
 		goto err_connect;
 
-	if (vmbus_proto_version > VERSION_WIN7)
-		cpu_hotplug_disable();
-
 	/*
 	 * Only register if the crash MSRs are available
 	 */
 	if (ms_hyperv.misc_features & HV_FEATURE_GUEST_CRASH_MSR_AVAILABLE) {
 		register_die_notifier(&hyperv_die_block);
 		atomic_notifier_chain_register(&panic_notifier_list,
 					       &hyperv_panic_block);
 	}
 
 	vmbus_request_offers();
 
 	return 0;
 
 err_connect:
-	on_each_cpu(hv_synic_cleanup, NULL, 1);
+	cpuhp_remove_state(hyperv_cpuhp_online);
 err_alloc:
 	hv_synic_free();
 	hv_remove_vmbus_irq();
 
 	bus_unregister(&hv_bus);
 
-err_cleanup:
-	hv_cleanup(false);
-
 	return ret;
 }
 
 /**
  * __vmbus_child_driver_register() - Register a vmbus's driver
  * @hv_driver: Pointer to driver structure you want to register
  * @owner: owner module of the drv
  * @mod_name: module name string
  *
  * Registers the given driver with Linux through the 'driver_register()' call
  * and sets up the hyper-v vmbus handling for this driver.
  * It will return the state of the 'driver_register()' call.
  *
  */
 int __vmbus_driver_register(struct hv_driver *hv_driver, struct module *owner, const char *mod_name)
 {
 	int ret;
 
 	pr_info("registering driver %s\n", hv_driver->name);
 
 	ret = vmbus_exists();
 	if (ret < 0)
 		return ret;
 
 	hv_driver->driver.name = hv_driver->name;
 	hv_driver->driver.owner = owner;
 	hv_driver->driver.mod_name = mod_name;
 	hv_driver->driver.bus = &hv_bus;
 
 	spin_lock_init(&hv_driver->dynids.lock);
 	INIT_LIST_HEAD(&hv_driver->dynids.list);
 
 	ret = driver_register(&hv_driver->driver);
 
 	return ret;
 }
 EXPORT_SYMBOL_GPL(__vmbus_driver_register);
 
 /**
  * vmbus_driver_unregister() - Unregister a vmbus's driver
  * @hv_driver: Pointer to driver structure you want to
  *             un-register
  *
  * Un-register the given driver that was previous registered with a call to
  * vmbus_driver_register()
  */
 void vmbus_driver_unregister(struct hv_driver *hv_driver)
 {
 	pr_info("unregistering driver %s\n", hv_driver->name);
 
 	if (!vmbus_exists()) {
 		driver_unregister(&hv_driver->driver);
 		vmbus_free_dynids(hv_driver);
 	}
 }
 EXPORT_SYMBOL_GPL(vmbus_driver_unregister);
 
 /*
  * vmbus_device_create - Creates and registers a new child device
  * on the vmbus.
  */
 struct hv_device *vmbus_device_create(const uuid_le *type,
 				      const uuid_le *instance,
 				      struct vmbus_channel *channel)
 {
 	struct hv_device *child_device_obj;
 
 	child_device_obj = kzalloc(sizeof(struct hv_device), GFP_KERNEL);
 	if (!child_device_obj) {
 		pr_err("Unable to allocate device object for child device\n");
 		return NULL;
 	}
 
 	child_device_obj->channel = channel;
 	memcpy(&child_device_obj->dev_type, type, sizeof(uuid_le));
 	memcpy(&child_device_obj->dev_instance, instance,
 	       sizeof(uuid_le));
 	child_device_obj->vendor_id = 0x1414; /* MSFT vendor ID */
 
 
 	return child_device_obj;
 }
 
 /*
  * vmbus_device_register - Register the child device
  */
 int vmbus_device_register(struct hv_device *child_device_obj)
 {
 	int ret = 0;
 
 	dev_set_name(&child_device_obj->device, "%pUl",
 		     child_device_obj->channel->offermsg.offer.if_instance.b);
 
 	child_device_obj->device.bus = &hv_bus;
 	child_device_obj->device.parent = &hv_acpi_dev->dev;
 	child_device_obj->device.release = vmbus_device_release;
 
 	/*
 	 * Register with the LDM. This will kick off the driver/device
 	 * binding...which will eventually call vmbus_match() and vmbus_probe()
 	 */
 	ret = device_register(&child_device_obj->device);
 
 	if (ret)
 		pr_err("Unable to register child device\n");
 	else
 		pr_debug("child device %s registered\n",
 			dev_name(&child_device_obj->device));
 
 	return ret;
 }
 
 /*
  * vmbus_device_unregister - Remove the specified child device
  * from the vmbus.
  */
 void vmbus_device_unregister(struct hv_device *device_obj)
 {
 	pr_debug("child device %s unregistered\n",
 		dev_name(&device_obj->device));
 
 	/*
 	 * Kick off the process of unregistering the device.
 	 * This will call vmbus_remove() and eventually vmbus_device_release()
 	 */
 	device_unregister(&device_obj->device);
 }
 
 
 /*
  * VMBUS is an acpi enumerated device. Get the information we
  * need from DSDT.
  */
 #define VTPM_BASE_ADDRESS 0xfed40000
 static acpi_status vmbus_walk_resources(struct acpi_resource *res, void *ctx)
 {
 	resource_size_t start = 0;
 	resource_size_t end = 0;
 	struct resource *new_res;
 	struct resource **old_res = &hyperv_mmio;
 	struct resource **prev_res = NULL;
 
 	switch (res->type) {
 
 	/*
 	 * "Address" descriptors are for bus windows. Ignore
 	 * "memory" descriptors, which are for registers on
 	 * devices.
 	 */
 	case ACPI_RESOURCE_TYPE_ADDRESS32:
 		start = res->data.address32.address.minimum;
 		end = res->data.address32.address.maximum;
 		break;
 
 	case ACPI_RESOURCE_TYPE_ADDRESS64:
 		start = res->data.address64.address.minimum;
 		end = res->data.address64.address.maximum;
 		break;
 
 	default:
 		/* Unused resource type */
 		return AE_OK;
 
 	}
 	/*
 	 * Ignore ranges that are below 1MB, as they're not
 	 * necessary or useful here.
 	 */
 	if (end < 0x100000)
 		return AE_OK;
 
 	new_res = kzalloc(sizeof(*new_res), GFP_ATOMIC);
 	if (!new_res)
 		return AE_NO_MEMORY;
 
 	/* If this range overlaps the virtual TPM, truncate it. */
 	if (end > VTPM_BASE_ADDRESS && start < VTPM_BASE_ADDRESS)
 		end = VTPM_BASE_ADDRESS;
 
 	new_res->name = "hyperv mmio";
 	new_res->flags = IORESOURCE_MEM;
 	new_res->start = start;
 	new_res->end = end;
 
 	/*
 	 * If two ranges are adjacent, merge them.
 	 */
 	do {
 		if (!*old_res) {
 			*old_res = new_res;
 			break;
 		}
 
 		if (((*old_res)->end + 1) == new_res->start) {
 			(*old_res)->end = new_res->end;
 			kfree(new_res);
 			break;
 		}
 
 		if ((*old_res)->start == new_res->end + 1) {
 			(*old_res)->start = new_res->start;
 			kfree(new_res);
 			break;
 		}
 
 		if ((*old_res)->start > new_res->end) {
 			new_res->sibling = *old_res;
 			if (prev_res)
 				(*prev_res)->sibling = new_res;
 			*old_res = new_res;
 			break;
 		}
 
 		prev_res = old_res;
 		old_res = &(*old_res)->sibling;
 
 	} while (1);
 
 	return AE_OK;
 }
 
 static int vmbus_acpi_remove(struct acpi_device *device)
 {
 	struct resource *cur_res;
 	struct resource *next_res;
 
 	if (hyperv_mmio) {
 		if (fb_mmio) {
 			__release_region(hyperv_mmio, fb_mmio->start,
 					 resource_size(fb_mmio));
 			fb_mmio = NULL;
 		}
 
 		for (cur_res = hyperv_mmio; cur_res; cur_res = next_res) {
 			next_res = cur_res->sibling;
 			kfree(cur_res);
 		}
 	}
 
 	return 0;
 }
 
 static void vmbus_reserve_fb(void)
 {
 	int size;
 	/*
 	 * Make a claim for the frame buffer in the resource tree under the
 	 * first node, which will be the one below 4GB.  The length seems to
 	 * be underreported, particularly in a Generation 1 VM.  So start out
 	 * reserving a larger area and make it smaller until it succeeds.
 	 */
 
 	if (screen_info.lfb_base) {
 		if (efi_enabled(EFI_BOOT))
 			size = max_t(__u32, screen_info.lfb_size, 0x800000);
 		else
 			size = max_t(__u32, screen_info.lfb_size, 0x4000000);
 
 		for (; !fb_mmio && (size >= 0x100000); size >>= 1) {
 			fb_mmio = __request_region(hyperv_mmio,
 						   screen_info.lfb_base, size,
 						   fb_mmio_name, 0);
 		}
 	}
 }
 
 /**
  * vmbus_allocate_mmio() - Pick a memory-mapped I/O range.
  * @new:		If successful, supplied a pointer to the
  *			allocated MMIO space.
  * @device_obj:		Identifies the caller
  * @min:		Minimum guest physical address of the
  *			allocation
  * @max:		Maximum guest physical address
  * @size:		Size of the range to be allocated
  * @align:		Alignment of the range to be allocated
  * @fb_overlap_ok:	Whether this allocation can be allowed
  *			to overlap the video frame buffer.
  *
  * This function walks the resources granted to VMBus by the
  * _CRS object in the ACPI namespace underneath the parent
  * "bridge" whether that's a root PCI bus in the Generation 1
  * case or a Module Device in the Generation 2 case.  It then
  * attempts to allocate from the global MMIO pool in a way that
  * matches the constraints supplied in these parameters and by
  * that _CRS.
  *
  * Return: 0 on success, -errno on failure
  */
 int vmbus_allocate_mmio(struct resource **new, struct hv_device *device_obj,
 			resource_size_t min, resource_size_t max,
 			resource_size_t size, resource_size_t align,
 			bool fb_overlap_ok)
 {
 	struct resource *iter, *shadow;
 	resource_size_t range_min, range_max, start;
 	const char *dev_n = dev_name(&device_obj->device);
 	int retval;
 
 	retval = -ENXIO;
 	down(&hyperv_mmio_lock);
 
 	/*
 	 * If overlaps with frame buffers are allowed, then first attempt to
 	 * make the allocation from within the reserved region.  Because it
 	 * is already reserved, no shadow allocation is necessary.
 	 */
 	if (fb_overlap_ok && fb_mmio && !(min > fb_mmio->end) &&
 	    !(max < fb_mmio->start)) {
 
 		range_min = fb_mmio->start;
 		range_max = fb_mmio->end;
 		start = (range_min + align - 1) & ~(align - 1);
 		for (; start + size - 1 <= range_max; start += align) {
 			*new = request_mem_region_exclusive(start, size, dev_n);
 			if (*new) {
 				retval = 0;
 				goto exit;
 			}
 		}
 	}
 
 	for (iter = hyperv_mmio; iter; iter = iter->sibling) {
 		if ((iter->start >= max) || (iter->end <= min))
 			continue;
 
 		range_min = iter->start;
 		range_max = iter->end;
 		start = (range_min + align - 1) & ~(align - 1);
 		for (; start + size - 1 <= range_max; start += align) {
 			shadow = __request_region(iter, start, size, NULL,
 						  IORESOURCE_BUSY);
 			if (!shadow)
 				continue;
 
 			*new = request_mem_region_exclusive(start, size, dev_n);
 			if (*new) {
 				shadow->name = (char *)*new;
 				retval = 0;
 				goto exit;
 			}
 
 			__release_region(iter, start, size);
 		}
 	}
 
 exit:
 	up(&hyperv_mmio_lock);
 	return retval;
 }
 EXPORT_SYMBOL_GPL(vmbus_allocate_mmio);
 
 /**
  * vmbus_free_mmio() - Free a memory-mapped I/O range.
  * @start:		Base address of region to release.
  * @size:		Size of the range to be allocated
  *
  * This function releases anything requested by
  * vmbus_mmio_allocate().
  */
 void vmbus_free_mmio(resource_size_t start, resource_size_t size)
 {
 	struct resource *iter;
 
 	down(&hyperv_mmio_lock);
 	for (iter = hyperv_mmio; iter; iter = iter->sibling) {
 		if ((iter->start >= start + size) || (iter->end <= start))
 			continue;
 
 		__release_region(iter, start, size);
 	}
 	release_mem_region(start, size);
 	up(&hyperv_mmio_lock);
 
 }
 EXPORT_SYMBOL_GPL(vmbus_free_mmio);
 
 /**
  * vmbus_cpu_number_to_vp_number() - Map CPU to VP.
  * @cpu_number: CPU number in Linux terms
  *
  * This function returns the mapping between the Linux processor
  * number and the hypervisor's virtual processor number, useful
  * in making hypercalls and such that talk about specific
  * processors.
  *
  * Return: Virtual processor number in Hyper-V terms
  */
 int vmbus_cpu_number_to_vp_number(int cpu_number)
 {
 	return hv_context.vp_index[cpu_number];
 }
 EXPORT_SYMBOL_GPL(vmbus_cpu_number_to_vp_number);
 
 static int vmbus_acpi_add(struct acpi_device *device)
 {
 	acpi_status result;
 	int ret_val = -ENODEV;
 	struct acpi_device *ancestor;
 
 	hv_acpi_dev = device;
 
 	result = acpi_walk_resources(device->handle, METHOD_NAME__CRS,
 					vmbus_walk_resources, NULL);
 
 	if (ACPI_FAILURE(result))
 		goto acpi_walk_err;
 	/*
 	 * Some ancestor of the vmbus acpi device (Gen1 or Gen2
 	 * firmware) is the VMOD that has the mmio ranges. Get that.
 	 */
 	for (ancestor = device->parent; ancestor; ancestor = ancestor->parent) {
 		result = acpi_walk_resources(ancestor->handle, METHOD_NAME__CRS,
 					     vmbus_walk_resources, NULL);
 
 		if (ACPI_FAILURE(result))
 			continue;
 		if (hyperv_mmio) {
 			vmbus_reserve_fb();
 			break;
 		}
 	}
 	ret_val = 0;
 
 acpi_walk_err:
 	complete(&probe_event);
 	if (ret_val)
 		vmbus_acpi_remove(device);
 	return ret_val;
 }
 
 static const struct acpi_device_id vmbus_acpi_device_ids[] = {
 	{"VMBUS", 0},
 	{"VMBus", 0},
 	{"", 0},
 };
 MODULE_DEVICE_TABLE(acpi, vmbus_acpi_device_ids);
 
 static struct acpi_driver vmbus_acpi_driver = {
 	.name = "vmbus",
 	.ids = vmbus_acpi_device_ids,
 	.ops = {
 		.add = vmbus_acpi_add,
 		.remove = vmbus_acpi_remove,
 	},
 };
 
 static void hv_kexec_handler(void)
 {
-	int cpu;
-
 	hv_synic_clockevents_cleanup();
 	vmbus_initiate_unload(false);
-	for_each_online_cpu(cpu)
-		smp_call_function_single(cpu, hv_synic_cleanup, NULL, 1);
-	hv_cleanup(false);
+	vmbus_connection.conn_state = DISCONNECTED;
+	/* Make sure conn_state is set as hv_synic_cleanup checks for it */
+	mb();
+	cpuhp_remove_state(hyperv_cpuhp_online);
+	hyperv_cleanup();
 };
 
 static void hv_crash_handler(struct pt_regs *regs)
 {
 	vmbus_initiate_unload(true);
 	/*
 	 * In crash handler we can't schedule synic cleanup for all CPUs,
 	 * doing the cleanup for current CPU only. This should be sufficient
 	 * for kdump.
 	 */
-	hv_synic_cleanup(NULL);
-	hv_cleanup(true);
+	vmbus_connection.conn_state = DISCONNECTED;
+	hv_synic_cleanup(smp_processor_id());
+	hyperv_cleanup();
 };
 
 static int __init hv_acpi_init(void)
 {
 	int ret, t;
 
 	if (x86_hyper != &x86_hyper_ms_hyperv)
 		return -ENODEV;
 
 	init_completion(&probe_event);
 
 	/*
 	 * Get ACPI resources first.
 	 */
 	ret = acpi_bus_register_driver(&vmbus_acpi_driver);
 
 	if (ret)
 		return ret;
 
 	t = wait_for_completion_timeout(&probe_event, 5*HZ);
 	if (t == 0) {
 		ret = -ETIMEDOUT;
 		goto cleanup;
 	}
 
 	ret = vmbus_bus_init();
 	if (ret)
 		goto cleanup;
 
 	hv_setup_kexec_handler(hv_kexec_handler);
 	hv_setup_crash_handler(hv_crash_handler);
 
 	return 0;
 
 cleanup:
 	acpi_bus_unregister_driver(&vmbus_acpi_driver);
 	hv_acpi_dev = NULL;
 	return ret;
 }
 
 static void __exit vmbus_exit(void)
 {
 	int cpu;
 
 	hv_remove_kexec_handler();
 	hv_remove_crash_handler();
 	vmbus_connection.conn_state = DISCONNECTED;
 	hv_synic_clockevents_cleanup();
 	vmbus_disconnect();
 	hv_remove_vmbus_irq();
-	for_each_online_cpu(cpu)
-		tasklet_kill(hv_context.msg_dpc[cpu]);
+	for_each_online_cpu(cpu) {
+		struct hv_per_cpu_context *hv_cpu
+			= per_cpu_ptr(hv_context.cpu_context, cpu);
+
+		tasklet_kill(&hv_cpu->msg_dpc);
+	}
 	vmbus_free_channels();
+
 	if (ms_hyperv.misc_features & HV_FEATURE_GUEST_CRASH_MSR_AVAILABLE) {
 		unregister_die_notifier(&hyperv_die_block);
 		atomic_notifier_chain_unregister(&panic_notifier_list,
 						 &hyperv_panic_block);
 	}
 	bus_unregister(&hv_bus);
-	hv_cleanup(false);
-	for_each_online_cpu(cpu) {
-		tasklet_kill(hv_context.event_dpc[cpu]);
-		smp_call_function_single(cpu, hv_synic_cleanup, NULL, 1);
-	}
+
+	cpuhp_remove_state(hyperv_cpuhp_online);
 	hv_synic_free();
 	acpi_bus_unregister_driver(&vmbus_acpi_driver);
-	if (vmbus_proto_version > VERSION_WIN7)
-		cpu_hotplug_enable();
 }
 
 
 MODULE_LICENSE("GPL");
 
 subsys_initcall(hv_acpi_init);
 module_exit(vmbus_exit);
diff --git a/drivers/hwtracing/coresight/coresight-etm-perf.c b/drivers/hwtracing/coresight/coresight-etm-perf.c
index 17741969026e..26cfac3e6de7 100644
--- a/drivers/hwtracing/coresight/coresight-etm-perf.c
+++ b/drivers/hwtracing/coresight/coresight-etm-perf.c
@@ -1,513 +1,514 @@
 /*
  * Copyright(C) 2015 Linaro Limited. All rights reserved.
  * Author: Mathieu Poirier <mathieu.poirier@linaro.org>
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 as published by
  * the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful, but WITHOUT
  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
  * more details.
  *
  * You should have received a copy of the GNU General Public License along with
  * this program.  If not, see <http://www.gnu.org/licenses/>.
  */
 
 #include <linux/coresight.h>
 #include <linux/coresight-pmu.h>
 #include <linux/cpumask.h>
 #include <linux/device.h>
 #include <linux/list.h>
 #include <linux/mm.h>
 #include <linux/init.h>
 #include <linux/perf_event.h>
 #include <linux/slab.h>
 #include <linux/types.h>
 #include <linux/workqueue.h>
 
 #include "coresight-etm-perf.h"
 #include "coresight-priv.h"
 
 static struct pmu etm_pmu;
 static bool etm_perf_up;
 
 /**
  * struct etm_event_data - Coresight specifics associated to an event
  * @work:		Handle to free allocated memory outside IRQ context.
  * @mask:		Hold the CPU(s) this event was set for.
  * @snk_config:		The sink configuration.
  * @path:		An array of path, each slot for one CPU.
  */
 struct etm_event_data {
 	struct work_struct work;
 	cpumask_t mask;
 	void *snk_config;
 	struct list_head **path;
 };
 
 static DEFINE_PER_CPU(struct perf_output_handle, ctx_handle);
 static DEFINE_PER_CPU(struct coresight_device *, csdev_src);
 
 /* ETMv3.5/PTM's ETMCR is 'config' */
 PMU_FORMAT_ATTR(cycacc,		"config:" __stringify(ETM_OPT_CYCACC));
 PMU_FORMAT_ATTR(timestamp,	"config:" __stringify(ETM_OPT_TS));
 
 static struct attribute *etm_config_formats_attr[] = {
 	&format_attr_cycacc.attr,
 	&format_attr_timestamp.attr,
 	NULL,
 };
 
 static struct attribute_group etm_pmu_format_group = {
 	.name   = "format",
 	.attrs  = etm_config_formats_attr,
 };
 
 static const struct attribute_group *etm_pmu_attr_groups[] = {
 	&etm_pmu_format_group,
 	NULL,
 };
 
 static void etm_event_read(struct perf_event *event) {}
 
 static int etm_addr_filters_alloc(struct perf_event *event)
 {
 	struct etm_filters *filters;
 	int node = event->cpu == -1 ? -1 : cpu_to_node(event->cpu);
 
 	filters = kzalloc_node(sizeof(struct etm_filters), GFP_KERNEL, node);
 	if (!filters)
 		return -ENOMEM;
 
 	if (event->parent)
 		memcpy(filters, event->parent->hw.addr_filters,
 		       sizeof(*filters));
 
 	event->hw.addr_filters = filters;
 
 	return 0;
 }
 
 static void etm_event_destroy(struct perf_event *event)
 {
 	kfree(event->hw.addr_filters);
 	event->hw.addr_filters = NULL;
 }
 
 static int etm_event_init(struct perf_event *event)
 {
 	int ret = 0;
 
 	if (event->attr.type != etm_pmu.type) {
 		ret = -ENOENT;
 		goto out;
 	}
 
 	ret = etm_addr_filters_alloc(event);
 	if (ret)
 		goto out;
 
 	event->destroy = etm_event_destroy;
 out:
 	return ret;
 }
 
 static void free_event_data(struct work_struct *work)
 {
 	int cpu;
 	cpumask_t *mask;
 	struct etm_event_data *event_data;
 	struct coresight_device *sink;
 
 	event_data = container_of(work, struct etm_event_data, work);
 	mask = &event_data->mask;
 	/*
 	 * First deal with the sink configuration.  See comment in
 	 * etm_setup_aux() about why we take the first available path.
 	 */
 	if (event_data->snk_config) {
 		cpu = cpumask_first(mask);
 		sink = coresight_get_sink(event_data->path[cpu]);
 		if (sink_ops(sink)->free_buffer)
 			sink_ops(sink)->free_buffer(event_data->snk_config);
 	}
 
 	for_each_cpu(cpu, mask) {
 		if (!(IS_ERR_OR_NULL(event_data->path[cpu])))
 			coresight_release_path(event_data->path[cpu]);
 	}
 
 	kfree(event_data->path);
 	kfree(event_data);
 }
 
 static void *alloc_event_data(int cpu)
 {
 	int size;
 	cpumask_t *mask;
 	struct etm_event_data *event_data;
 
 	/* First get memory for the session's data */
 	event_data = kzalloc(sizeof(struct etm_event_data), GFP_KERNEL);
 	if (!event_data)
 		return NULL;
 
 	/* Make sure nothing disappears under us */
 	get_online_cpus();
 	size = num_online_cpus();
 
 	mask = &event_data->mask;
 	if (cpu != -1)
 		cpumask_set_cpu(cpu, mask);
 	else
 		cpumask_copy(mask, cpu_online_mask);
 	put_online_cpus();
 
 	/*
 	 * Each CPU has a single path between source and destination.  As such
 	 * allocate an array using CPU numbers as indexes.  That way a path
 	 * for any CPU can easily be accessed at any given time.  We proceed
 	 * the same way for sessions involving a single CPU.  The cost of
 	 * unused memory when dealing with single CPU trace scenarios is small
 	 * compared to the cost of searching through an optimized array.
 	 */
 	event_data->path = kcalloc(size,
 				   sizeof(struct list_head *), GFP_KERNEL);
 	if (!event_data->path) {
 		kfree(event_data);
 		return NULL;
 	}
 
 	return event_data;
 }
 
 static void etm_free_aux(void *data)
 {
 	struct etm_event_data *event_data = data;
 
 	schedule_work(&event_data->work);
 }
 
 static void *etm_setup_aux(int event_cpu, void **pages,
 			   int nr_pages, bool overwrite)
 {
 	int cpu;
 	cpumask_t *mask;
 	struct coresight_device *sink;
 	struct etm_event_data *event_data = NULL;
 
 	event_data = alloc_event_data(event_cpu);
 	if (!event_data)
 		return NULL;
 
 	/*
 	 * In theory nothing prevent tracers in a trace session from being
 	 * associated with different sinks, nor having a sink per tracer.  But
 	 * until we have HW with this kind of topology we need to assume tracers
 	 * in a trace session are using the same sink.  Therefore go through
 	 * the coresight bus and pick the first enabled sink.
 	 *
 	 * When operated from sysFS users are responsible to enable the sink
 	 * while from perf, the perf tools will do it based on the choice made
 	 * on the cmd line.  As such the "enable_sink" flag in sysFS is reset.
 	 */
 	sink = coresight_get_enabled_sink(true);
 	if (!sink)
 		goto err;
 
 	INIT_WORK(&event_data->work, free_event_data);
 
 	mask = &event_data->mask;
 
 	/* Setup the path for each CPU in a trace session */
 	for_each_cpu(cpu, mask) {
 		struct coresight_device *csdev;
 
 		csdev = per_cpu(csdev_src, cpu);
 		if (!csdev)
 			goto err;
 
 		/*
 		 * Building a path doesn't enable it, it simply builds a
 		 * list of devices from source to sink that can be
 		 * referenced later when the path is actually needed.
 		 */
 		event_data->path[cpu] = coresight_build_path(csdev, sink);
 		if (IS_ERR(event_data->path[cpu]))
 			goto err;
 	}
 
 	if (!sink_ops(sink)->alloc_buffer)
 		goto err;
 
+	cpu = cpumask_first(mask);
 	/* Get the AUX specific data from the sink buffer */
 	event_data->snk_config =
 			sink_ops(sink)->alloc_buffer(sink, cpu, pages,
 						     nr_pages, overwrite);
 	if (!event_data->snk_config)
 		goto err;
 
 out:
 	return event_data;
 
 err:
 	etm_free_aux(event_data);
 	event_data = NULL;
 	goto out;
 }
 
 static void etm_event_start(struct perf_event *event, int flags)
 {
 	int cpu = smp_processor_id();
 	struct etm_event_data *event_data;
 	struct perf_output_handle *handle = this_cpu_ptr(&ctx_handle);
 	struct coresight_device *sink, *csdev = per_cpu(csdev_src, cpu);
 
 	if (!csdev)
 		goto fail;
 
 	/*
 	 * Deal with the ring buffer API and get a handle on the
 	 * session's information.
 	 */
 	event_data = perf_aux_output_begin(handle, event);
 	if (!event_data)
 		goto fail;
 
 	/* We need a sink, no need to continue without one */
 	sink = coresight_get_sink(event_data->path[cpu]);
 	if (WARN_ON_ONCE(!sink || !sink_ops(sink)->set_buffer))
 		goto fail_end_stop;
 
 	/* Configure the sink */
 	if (sink_ops(sink)->set_buffer(sink, handle,
 				       event_data->snk_config))
 		goto fail_end_stop;
 
 	/* Nothing will happen without a path */
 	if (coresight_enable_path(event_data->path[cpu], CS_MODE_PERF))
 		goto fail_end_stop;
 
 	/* Tell the perf core the event is alive */
 	event->hw.state = 0;
 
 	/* Finally enable the tracer */
 	if (source_ops(csdev)->enable(csdev, event, CS_MODE_PERF))
 		goto fail_end_stop;
 
 out:
 	return;
 
 fail_end_stop:
 	perf_aux_output_end(handle, 0, true);
 fail:
 	event->hw.state = PERF_HES_STOPPED;
 	goto out;
 }
 
 static void etm_event_stop(struct perf_event *event, int mode)
 {
 	bool lost;
 	int cpu = smp_processor_id();
 	unsigned long size;
 	struct coresight_device *sink, *csdev = per_cpu(csdev_src, cpu);
 	struct perf_output_handle *handle = this_cpu_ptr(&ctx_handle);
 	struct etm_event_data *event_data = perf_get_aux(handle);
 
 	if (event->hw.state == PERF_HES_STOPPED)
 		return;
 
 	if (!csdev)
 		return;
 
 	sink = coresight_get_sink(event_data->path[cpu]);
 	if (!sink)
 		return;
 
 	/* stop tracer */
 	source_ops(csdev)->disable(csdev, event);
 
 	/* tell the core */
 	event->hw.state = PERF_HES_STOPPED;
 
 	if (mode & PERF_EF_UPDATE) {
 		if (WARN_ON_ONCE(handle->event != event))
 			return;
 
 		/* update trace information */
 		if (!sink_ops(sink)->update_buffer)
 			return;
 
 		sink_ops(sink)->update_buffer(sink, handle,
 					      event_data->snk_config);
 
 		if (!sink_ops(sink)->reset_buffer)
 			return;
 
 		size = sink_ops(sink)->reset_buffer(sink, handle,
 						    event_data->snk_config,
 						    &lost);
 
 		perf_aux_output_end(handle, size, lost);
 	}
 
 	/* Disabling the path make its elements available to other sessions */
 	coresight_disable_path(event_data->path[cpu]);
 }
 
 static int etm_event_add(struct perf_event *event, int mode)
 {
 	int ret = 0;
 	struct hw_perf_event *hwc = &event->hw;
 
 	if (mode & PERF_EF_START) {
 		etm_event_start(event, 0);
 		if (hwc->state & PERF_HES_STOPPED)
 			ret = -EINVAL;
 	} else {
 		hwc->state = PERF_HES_STOPPED;
 	}
 
 	return ret;
 }
 
 static void etm_event_del(struct perf_event *event, int mode)
 {
 	etm_event_stop(event, PERF_EF_UPDATE);
 }
 
 static int etm_addr_filters_validate(struct list_head *filters)
 {
 	bool range = false, address = false;
 	int index = 0;
 	struct perf_addr_filter *filter;
 
 	list_for_each_entry(filter, filters, entry) {
 		/*
 		 * No need to go further if there's no more
 		 * room for filters.
 		 */
 		if (++index > ETM_ADDR_CMP_MAX)
 			return -EOPNOTSUPP;
 
 		/*
 		 * As taken from the struct perf_addr_filter documentation:
 		 *	@range:	1: range, 0: address
 		 *
 		 * At this time we don't allow range and start/stop filtering
 		 * to cohabitate, they have to be mutually exclusive.
 		 */
 		if ((filter->range == 1) && address)
 			return -EOPNOTSUPP;
 
 		if ((filter->range == 0) && range)
 			return -EOPNOTSUPP;
 
 		/*
 		 * For range filtering, the second address in the address
 		 * range comparator needs to be higher than the first.
 		 * Invalid otherwise.
 		 */
 		if (filter->range && filter->size == 0)
 			return -EINVAL;
 
 		/*
 		 * Everything checks out with this filter, record what we've
 		 * received before moving on to the next one.
 		 */
 		if (filter->range)
 			range = true;
 		else
 			address = true;
 	}
 
 	return 0;
 }
 
 static void etm_addr_filters_sync(struct perf_event *event)
 {
 	struct perf_addr_filters_head *head = perf_event_addr_filters(event);
 	unsigned long start, stop, *offs = event->addr_filters_offs;
 	struct etm_filters *filters = event->hw.addr_filters;
 	struct etm_filter *etm_filter;
 	struct perf_addr_filter *filter;
 	int i = 0;
 
 	list_for_each_entry(filter, &head->list, entry) {
 		start = filter->offset + offs[i];
 		stop = start + filter->size;
 		etm_filter = &filters->etm_filter[i];
 
 		if (filter->range == 1) {
 			etm_filter->start_addr = start;
 			etm_filter->stop_addr = stop;
 			etm_filter->type = ETM_ADDR_TYPE_RANGE;
 		} else {
 			if (filter->filter == 1) {
 				etm_filter->start_addr = start;
 				etm_filter->type = ETM_ADDR_TYPE_START;
 			} else {
 				etm_filter->stop_addr = stop;
 				etm_filter->type = ETM_ADDR_TYPE_STOP;
 			}
 		}
 		i++;
 	}
 
 	filters->nr_filters = i;
 }
 
 int etm_perf_symlink(struct coresight_device *csdev, bool link)
 {
 	char entry[sizeof("cpu9999999")];
 	int ret = 0, cpu = source_ops(csdev)->cpu_id(csdev);
 	struct device *pmu_dev = etm_pmu.dev;
 	struct device *cs_dev = &csdev->dev;
 
 	sprintf(entry, "cpu%d", cpu);
 
 	if (!etm_perf_up)
 		return -EPROBE_DEFER;
 
 	if (link) {
 		ret = sysfs_create_link(&pmu_dev->kobj, &cs_dev->kobj, entry);
 		if (ret)
 			return ret;
 		per_cpu(csdev_src, cpu) = csdev;
 	} else {
 		sysfs_remove_link(&pmu_dev->kobj, entry);
 		per_cpu(csdev_src, cpu) = NULL;
 	}
 
 	return 0;
 }
 
 static int __init etm_perf_init(void)
 {
 	int ret;
 
 	etm_pmu.capabilities		= PERF_PMU_CAP_EXCLUSIVE;
 
 	etm_pmu.attr_groups		= etm_pmu_attr_groups;
 	etm_pmu.task_ctx_nr		= perf_sw_context;
 	etm_pmu.read			= etm_event_read;
 	etm_pmu.event_init		= etm_event_init;
 	etm_pmu.setup_aux		= etm_setup_aux;
 	etm_pmu.free_aux		= etm_free_aux;
 	etm_pmu.start			= etm_event_start;
 	etm_pmu.stop			= etm_event_stop;
 	etm_pmu.add			= etm_event_add;
 	etm_pmu.del			= etm_event_del;
 	etm_pmu.addr_filters_sync	= etm_addr_filters_sync;
 	etm_pmu.addr_filters_validate	= etm_addr_filters_validate;
 	etm_pmu.nr_addr_filters		= ETM_ADDR_CMP_MAX;
 
 	ret = perf_pmu_register(&etm_pmu, CORESIGHT_ETM_PMU_NAME, -1);
 	if (ret == 0)
 		etm_perf_up = true;
 
 	return ret;
 }
 device_initcall(etm_perf_init);
diff --git a/drivers/hwtracing/coresight/coresight-etm4x.c b/drivers/hwtracing/coresight/coresight-etm4x.c
index 031480f2c34d..d1340fb4e457 100644
--- a/drivers/hwtracing/coresight/coresight-etm4x.c
+++ b/drivers/hwtracing/coresight/coresight-etm4x.c
@@ -1,1074 +1,1078 @@
 /* Copyright (c) 2014, The Linux Foundation. All rights reserved.
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License version 2 and
  * only version 2 as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
  */
 
 #include <linux/kernel.h>
 #include <linux/moduleparam.h>
 #include <linux/init.h>
 #include <linux/types.h>
 #include <linux/device.h>
 #include <linux/io.h>
 #include <linux/err.h>
 #include <linux/fs.h>
 #include <linux/slab.h>
 #include <linux/delay.h>
 #include <linux/smp.h>
 #include <linux/sysfs.h>
 #include <linux/stat.h>
 #include <linux/clk.h>
 #include <linux/cpu.h>
 #include <linux/coresight.h>
 #include <linux/coresight-pmu.h>
 #include <linux/pm_wakeup.h>
 #include <linux/amba/bus.h>
 #include <linux/seq_file.h>
 #include <linux/uaccess.h>
 #include <linux/perf_event.h>
 #include <linux/pm_runtime.h>
 #include <asm/sections.h>
 #include <asm/local.h>
 
 #include "coresight-etm4x.h"
 #include "coresight-etm-perf.h"
 
 static int boot_enable;
 module_param_named(boot_enable, boot_enable, int, S_IRUGO);
 
 /* The number of ETMv4 currently registered */
 static int etm4_count;
 static struct etmv4_drvdata *etmdrvdata[NR_CPUS];
 static void etm4_set_default_config(struct etmv4_config *config);
 static int etm4_set_event_filters(struct etmv4_drvdata *drvdata,
 				  struct perf_event *event);
 
 static enum cpuhp_state hp_online;
 
 static void etm4_os_unlock(struct etmv4_drvdata *drvdata)
 {
 	/* Writing any value to ETMOSLAR unlocks the trace registers */
 	writel_relaxed(0x0, drvdata->base + TRCOSLAR);
 	drvdata->os_unlock = true;
 	isb();
 }
 
 static bool etm4_arch_supported(u8 arch)
 {
 	switch (arch) {
 	case ETM_ARCH_V4:
 		break;
 	default:
 		return false;
 	}
 	return true;
 }
 
 static int etm4_cpu_id(struct coresight_device *csdev)
 {
 	struct etmv4_drvdata *drvdata = dev_get_drvdata(csdev->dev.parent);
 
 	return drvdata->cpu;
 }
 
 static int etm4_trace_id(struct coresight_device *csdev)
 {
 	struct etmv4_drvdata *drvdata = dev_get_drvdata(csdev->dev.parent);
 
 	return drvdata->trcid;
 }
 
 static void etm4_enable_hw(void *info)
 {
 	int i;
 	struct etmv4_drvdata *drvdata = info;
 	struct etmv4_config *config = &drvdata->config;
 
 	CS_UNLOCK(drvdata->base);
 
 	etm4_os_unlock(drvdata);
 
 	/* Disable the trace unit before programming trace registers */
 	writel_relaxed(0, drvdata->base + TRCPRGCTLR);
 
 	/* wait for TRCSTATR.IDLE to go up */
 	if (coresight_timeout(drvdata->base, TRCSTATR, TRCSTATR_IDLE_BIT, 1))
 		dev_err(drvdata->dev,
 			"timeout while waiting for Idle Trace Status\n");
 
 	writel_relaxed(config->pe_sel, drvdata->base + TRCPROCSELR);
 	writel_relaxed(config->cfg, drvdata->base + TRCCONFIGR);
 	/* nothing specific implemented */
 	writel_relaxed(0x0, drvdata->base + TRCAUXCTLR);
 	writel_relaxed(config->eventctrl0, drvdata->base + TRCEVENTCTL0R);
 	writel_relaxed(config->eventctrl1, drvdata->base + TRCEVENTCTL1R);
 	writel_relaxed(config->stall_ctrl, drvdata->base + TRCSTALLCTLR);
 	writel_relaxed(config->ts_ctrl, drvdata->base + TRCTSCTLR);
 	writel_relaxed(config->syncfreq, drvdata->base + TRCSYNCPR);
 	writel_relaxed(config->ccctlr, drvdata->base + TRCCCCTLR);
 	writel_relaxed(config->bb_ctrl, drvdata->base + TRCBBCTLR);
 	writel_relaxed(drvdata->trcid, drvdata->base + TRCTRACEIDR);
 	writel_relaxed(config->vinst_ctrl, drvdata->base + TRCVICTLR);
 	writel_relaxed(config->viiectlr, drvdata->base + TRCVIIECTLR);
 	writel_relaxed(config->vissctlr,
 		       drvdata->base + TRCVISSCTLR);
 	writel_relaxed(config->vipcssctlr,
 		       drvdata->base + TRCVIPCSSCTLR);
 	for (i = 0; i < drvdata->nrseqstate - 1; i++)
 		writel_relaxed(config->seq_ctrl[i],
 			       drvdata->base + TRCSEQEVRn(i));
 	writel_relaxed(config->seq_rst, drvdata->base + TRCSEQRSTEVR);
 	writel_relaxed(config->seq_state, drvdata->base + TRCSEQSTR);
 	writel_relaxed(config->ext_inp, drvdata->base + TRCEXTINSELR);
 	for (i = 0; i < drvdata->nr_cntr; i++) {
 		writel_relaxed(config->cntrldvr[i],
 			       drvdata->base + TRCCNTRLDVRn(i));
 		writel_relaxed(config->cntr_ctrl[i],
 			       drvdata->base + TRCCNTCTLRn(i));
 		writel_relaxed(config->cntr_val[i],
 			       drvdata->base + TRCCNTVRn(i));
 	}
 
 	/* Resource selector pair 0 is always implemented and reserved */
 	for (i = 0; i < drvdata->nr_resource * 2; i++)
 		writel_relaxed(config->res_ctrl[i],
 			       drvdata->base + TRCRSCTLRn(i));
 
 	for (i = 0; i < drvdata->nr_ss_cmp; i++) {
 		writel_relaxed(config->ss_ctrl[i],
 			       drvdata->base + TRCSSCCRn(i));
 		writel_relaxed(config->ss_status[i],
 			       drvdata->base + TRCSSCSRn(i));
 		writel_relaxed(config->ss_pe_cmp[i],
 			       drvdata->base + TRCSSPCICRn(i));
 	}
 	for (i = 0; i < drvdata->nr_addr_cmp; i++) {
 		writeq_relaxed(config->addr_val[i],
 			       drvdata->base + TRCACVRn(i));
 		writeq_relaxed(config->addr_acc[i],
 			       drvdata->base + TRCACATRn(i));
 	}
 	for (i = 0; i < drvdata->numcidc; i++)
 		writeq_relaxed(config->ctxid_pid[i],
 			       drvdata->base + TRCCIDCVRn(i));
 	writel_relaxed(config->ctxid_mask0, drvdata->base + TRCCIDCCTLR0);
 	writel_relaxed(config->ctxid_mask1, drvdata->base + TRCCIDCCTLR1);
 
 	for (i = 0; i < drvdata->numvmidc; i++)
 		writeq_relaxed(config->vmid_val[i],
 			       drvdata->base + TRCVMIDCVRn(i));
 	writel_relaxed(config->vmid_mask0, drvdata->base + TRCVMIDCCTLR0);
 	writel_relaxed(config->vmid_mask1, drvdata->base + TRCVMIDCCTLR1);
 
 	/*
 	 * Request to keep the trace unit powered and also
 	 * emulation of powerdown
 	 */
 	writel_relaxed(readl_relaxed(drvdata->base + TRCPDCR) | TRCPDCR_PU,
 		       drvdata->base + TRCPDCR);
 
 	/* Enable the trace unit */
 	writel_relaxed(1, drvdata->base + TRCPRGCTLR);
 
 	/* wait for TRCSTATR.IDLE to go back down to '0' */
 	if (coresight_timeout(drvdata->base, TRCSTATR, TRCSTATR_IDLE_BIT, 0))
 		dev_err(drvdata->dev,
 			"timeout while waiting for Idle Trace Status\n");
 
 	CS_LOCK(drvdata->base);
 
 	dev_dbg(drvdata->dev, "cpu: %d enable smp call done\n", drvdata->cpu);
 }
 
 static int etm4_parse_event_config(struct etmv4_drvdata *drvdata,
 				   struct perf_event *event)
 {
 	int ret = 0;
 	struct etmv4_config *config = &drvdata->config;
 	struct perf_event_attr *attr = &event->attr;
 
 	if (!attr) {
 		ret = -EINVAL;
 		goto out;
 	}
 
 	/* Clear configuration from previous run */
 	memset(config, 0, sizeof(struct etmv4_config));
 
 	if (attr->exclude_kernel)
 		config->mode = ETM_MODE_EXCL_KERN;
 
 	if (attr->exclude_user)
 		config->mode = ETM_MODE_EXCL_USER;
 
 	/* Always start from the default config */
 	etm4_set_default_config(config);
 
 	/* Configure filters specified on the perf cmd line, if any. */
 	ret = etm4_set_event_filters(drvdata, event);
 	if (ret)
 		goto out;
 
 	/* Go from generic option to ETMv4 specifics */
-	if (attr->config & BIT(ETM_OPT_CYCACC))
-		config->cfg |= ETMv4_MODE_CYCACC;
+	if (attr->config & BIT(ETM_OPT_CYCACC)) {
+		config->cfg |= BIT(4);
+		/* TRM: Must program this for cycacc to work */
+		config->ccctlr = ETM_CYC_THRESHOLD_DEFAULT;
+	}
 	if (attr->config & BIT(ETM_OPT_TS))
-		config->cfg |= ETMv4_MODE_TIMESTAMP;
+		/* bit[11], Global timestamp tracing bit */
+		config->cfg |= BIT(11);
 
 out:
 	return ret;
 }
 
 static int etm4_enable_perf(struct coresight_device *csdev,
 			    struct perf_event *event)
 {
 	int ret = 0;
 	struct etmv4_drvdata *drvdata = dev_get_drvdata(csdev->dev.parent);
 
 	if (WARN_ON_ONCE(drvdata->cpu != smp_processor_id())) {
 		ret = -EINVAL;
 		goto out;
 	}
 
 	/* Configure the tracer based on the session's specifics */
 	ret = etm4_parse_event_config(drvdata, event);
 	if (ret)
 		goto out;
 	/* And enable it */
 	etm4_enable_hw(drvdata);
 
 out:
 	return ret;
 }
 
 static int etm4_enable_sysfs(struct coresight_device *csdev)
 {
 	struct etmv4_drvdata *drvdata = dev_get_drvdata(csdev->dev.parent);
 	int ret;
 
 	spin_lock(&drvdata->spinlock);
 
 	/*
 	 * Executing etm4_enable_hw on the cpu whose ETM is being enabled
 	 * ensures that register writes occur when cpu is powered.
 	 */
 	ret = smp_call_function_single(drvdata->cpu,
 				       etm4_enable_hw, drvdata, 1);
 	if (ret)
 		goto err;
 
 	drvdata->sticky_enable = true;
 	spin_unlock(&drvdata->spinlock);
 
 	dev_info(drvdata->dev, "ETM tracing enabled\n");
 	return 0;
 
 err:
 	spin_unlock(&drvdata->spinlock);
 	return ret;
 }
 
 static int etm4_enable(struct coresight_device *csdev,
 		       struct perf_event *event, u32 mode)
 {
 	int ret;
 	u32 val;
 	struct etmv4_drvdata *drvdata = dev_get_drvdata(csdev->dev.parent);
 
 	val = local_cmpxchg(&drvdata->mode, CS_MODE_DISABLED, mode);
 
 	/* Someone is already using the tracer */
 	if (val)
 		return -EBUSY;
 
 	switch (mode) {
 	case CS_MODE_SYSFS:
 		ret = etm4_enable_sysfs(csdev);
 		break;
 	case CS_MODE_PERF:
 		ret = etm4_enable_perf(csdev, event);
 		break;
 	default:
 		ret = -EINVAL;
 	}
 
 	/* The tracer didn't start */
 	if (ret)
 		local_set(&drvdata->mode, CS_MODE_DISABLED);
 
 	return ret;
 }
 
 static void etm4_disable_hw(void *info)
 {
 	u32 control;
 	struct etmv4_drvdata *drvdata = info;
 
 	CS_UNLOCK(drvdata->base);
 
 	/* power can be removed from the trace unit now */
 	control = readl_relaxed(drvdata->base + TRCPDCR);
 	control &= ~TRCPDCR_PU;
 	writel_relaxed(control, drvdata->base + TRCPDCR);
 
 	control = readl_relaxed(drvdata->base + TRCPRGCTLR);
 
 	/* EN, bit[0] Trace unit enable bit */
 	control &= ~0x1;
 
 	/* make sure everything completes before disabling */
 	mb();
 	isb();
 	writel_relaxed(control, drvdata->base + TRCPRGCTLR);
 
 	CS_LOCK(drvdata->base);
 
 	dev_dbg(drvdata->dev, "cpu: %d disable smp call done\n", drvdata->cpu);
 }
 
 static int etm4_disable_perf(struct coresight_device *csdev,
 			     struct perf_event *event)
 {
 	u32 control;
 	struct etm_filters *filters = event->hw.addr_filters;
 	struct etmv4_drvdata *drvdata = dev_get_drvdata(csdev->dev.parent);
 
 	if (WARN_ON_ONCE(drvdata->cpu != smp_processor_id()))
 		return -EINVAL;
 
 	etm4_disable_hw(drvdata);
 
 	/*
 	 * Check if the start/stop logic was active when the unit was stopped.
 	 * That way we can re-enable the start/stop logic when the process is
 	 * scheduled again.  Configuration of the start/stop logic happens in
 	 * function etm4_set_event_filters().
 	 */
 	control = readl_relaxed(drvdata->base + TRCVICTLR);
 	/* TRCVICTLR::SSSTATUS, bit[9] */
 	filters->ssstatus = (control & BIT(9));
 
 	return 0;
 }
 
 static void etm4_disable_sysfs(struct coresight_device *csdev)
 {
 	struct etmv4_drvdata *drvdata = dev_get_drvdata(csdev->dev.parent);
 
 	/*
 	 * Taking hotplug lock here protects from clocks getting disabled
 	 * with tracing being left on (crash scenario) if user disable occurs
 	 * after cpu online mask indicates the cpu is offline but before the
 	 * DYING hotplug callback is serviced by the ETM driver.
 	 */
 	get_online_cpus();
 	spin_lock(&drvdata->spinlock);
 
 	/*
 	 * Executing etm4_disable_hw on the cpu whose ETM is being disabled
 	 * ensures that register writes occur when cpu is powered.
 	 */
 	smp_call_function_single(drvdata->cpu, etm4_disable_hw, drvdata, 1);
 
 	spin_unlock(&drvdata->spinlock);
 	put_online_cpus();
 
 	dev_info(drvdata->dev, "ETM tracing disabled\n");
 }
 
 static void etm4_disable(struct coresight_device *csdev,
 			 struct perf_event *event)
 {
 	u32 mode;
 	struct etmv4_drvdata *drvdata = dev_get_drvdata(csdev->dev.parent);
 
 	/*
 	 * For as long as the tracer isn't disabled another entity can't
 	 * change its status.  As such we can read the status here without
 	 * fearing it will change under us.
 	 */
 	mode = local_read(&drvdata->mode);
 
 	switch (mode) {
 	case CS_MODE_DISABLED:
 		break;
 	case CS_MODE_SYSFS:
 		etm4_disable_sysfs(csdev);
 		break;
 	case CS_MODE_PERF:
 		etm4_disable_perf(csdev, event);
 		break;
 	}
 
 	if (mode)
 		local_set(&drvdata->mode, CS_MODE_DISABLED);
 }
 
 static const struct coresight_ops_source etm4_source_ops = {
 	.cpu_id		= etm4_cpu_id,
 	.trace_id	= etm4_trace_id,
 	.enable		= etm4_enable,
 	.disable	= etm4_disable,
 };
 
 static const struct coresight_ops etm4_cs_ops = {
 	.source_ops	= &etm4_source_ops,
 };
 
 static void etm4_init_arch_data(void *info)
 {
 	u32 etmidr0;
 	u32 etmidr1;
 	u32 etmidr2;
 	u32 etmidr3;
 	u32 etmidr4;
 	u32 etmidr5;
 	struct etmv4_drvdata *drvdata = info;
 
 	/* Make sure all registers are accessible */
 	etm4_os_unlock(drvdata);
 
 	CS_UNLOCK(drvdata->base);
 
 	/* find all capabilities of the tracing unit */
 	etmidr0 = readl_relaxed(drvdata->base + TRCIDR0);
 
 	/* INSTP0, bits[2:1] P0 tracing support field */
 	if (BMVAL(etmidr0, 1, 1) && BMVAL(etmidr0, 2, 2))
 		drvdata->instrp0 = true;
 	else
 		drvdata->instrp0 = false;
 
 	/* TRCBB, bit[5] Branch broadcast tracing support bit */
 	if (BMVAL(etmidr0, 5, 5))
 		drvdata->trcbb = true;
 	else
 		drvdata->trcbb = false;
 
 	/* TRCCOND, bit[6] Conditional instruction tracing support bit */
 	if (BMVAL(etmidr0, 6, 6))
 		drvdata->trccond = true;
 	else
 		drvdata->trccond = false;
 
 	/* TRCCCI, bit[7] Cycle counting instruction bit */
 	if (BMVAL(etmidr0, 7, 7))
 		drvdata->trccci = true;
 	else
 		drvdata->trccci = false;
 
 	/* RETSTACK, bit[9] Return stack bit */
 	if (BMVAL(etmidr0, 9, 9))
 		drvdata->retstack = true;
 	else
 		drvdata->retstack = false;
 
 	/* NUMEVENT, bits[11:10] Number of events field */
 	drvdata->nr_event = BMVAL(etmidr0, 10, 11);
 	/* QSUPP, bits[16:15] Q element support field */
 	drvdata->q_support = BMVAL(etmidr0, 15, 16);
 	/* TSSIZE, bits[28:24] Global timestamp size field */
 	drvdata->ts_size = BMVAL(etmidr0, 24, 28);
 
 	/* base architecture of trace unit */
 	etmidr1 = readl_relaxed(drvdata->base + TRCIDR1);
 	/*
 	 * TRCARCHMIN, bits[7:4] architecture the minor version number
 	 * TRCARCHMAJ, bits[11:8] architecture major versin number
 	 */
 	drvdata->arch = BMVAL(etmidr1, 4, 11);
 
 	/* maximum size of resources */
 	etmidr2 = readl_relaxed(drvdata->base + TRCIDR2);
 	/* CIDSIZE, bits[9:5] Indicates the Context ID size */
 	drvdata->ctxid_size = BMVAL(etmidr2, 5, 9);
 	/* VMIDSIZE, bits[14:10] Indicates the VMID size */
 	drvdata->vmid_size = BMVAL(etmidr2, 10, 14);
 	/* CCSIZE, bits[28:25] size of the cycle counter in bits minus 12 */
 	drvdata->ccsize = BMVAL(etmidr2, 25, 28);
 
 	etmidr3 = readl_relaxed(drvdata->base + TRCIDR3);
 	/* CCITMIN, bits[11:0] minimum threshold value that can be programmed */
 	drvdata->ccitmin = BMVAL(etmidr3, 0, 11);
 	/* EXLEVEL_S, bits[19:16] Secure state instruction tracing */
 	drvdata->s_ex_level = BMVAL(etmidr3, 16, 19);
 	/* EXLEVEL_NS, bits[23:20] Non-secure state instruction tracing */
 	drvdata->ns_ex_level = BMVAL(etmidr3, 20, 23);
 
 	/*
 	 * TRCERR, bit[24] whether a trace unit can trace a
 	 * system error exception.
 	 */
 	if (BMVAL(etmidr3, 24, 24))
 		drvdata->trc_error = true;
 	else
 		drvdata->trc_error = false;
 
 	/* SYNCPR, bit[25] implementation has a fixed synchronization period? */
 	if (BMVAL(etmidr3, 25, 25))
 		drvdata->syncpr = true;
 	else
 		drvdata->syncpr = false;
 
 	/* STALLCTL, bit[26] is stall control implemented? */
 	if (BMVAL(etmidr3, 26, 26))
 		drvdata->stallctl = true;
 	else
 		drvdata->stallctl = false;
 
 	/* SYSSTALL, bit[27] implementation can support stall control? */
 	if (BMVAL(etmidr3, 27, 27))
 		drvdata->sysstall = true;
 	else
 		drvdata->sysstall = false;
 
 	/* NUMPROC, bits[30:28] the number of PEs available for tracing */
 	drvdata->nr_pe = BMVAL(etmidr3, 28, 30);
 
 	/* NOOVERFLOW, bit[31] is trace overflow prevention supported */
 	if (BMVAL(etmidr3, 31, 31))
 		drvdata->nooverflow = true;
 	else
 		drvdata->nooverflow = false;
 
 	/* number of resources trace unit supports */
 	etmidr4 = readl_relaxed(drvdata->base + TRCIDR4);
 	/* NUMACPAIRS, bits[0:3] number of addr comparator pairs for tracing */
 	drvdata->nr_addr_cmp = BMVAL(etmidr4, 0, 3);
 	/* NUMPC, bits[15:12] number of PE comparator inputs for tracing */
 	drvdata->nr_pe_cmp = BMVAL(etmidr4, 12, 15);
 	/*
 	 * NUMRSPAIR, bits[19:16]
 	 * The number of resource pairs conveyed by the HW starts at 0, i.e a
 	 * value of 0x0 indicate 1 resource pair, 0x1 indicate two and so on.
 	 * As such add 1 to the value of NUMRSPAIR for a better representation.
 	 */
 	drvdata->nr_resource = BMVAL(etmidr4, 16, 19) + 1;
 	/*
 	 * NUMSSCC, bits[23:20] the number of single-shot
 	 * comparator control for tracing
 	 */
 	drvdata->nr_ss_cmp = BMVAL(etmidr4, 20, 23);
 	/* NUMCIDC, bits[27:24] number of Context ID comparators for tracing */
 	drvdata->numcidc = BMVAL(etmidr4, 24, 27);
 	/* NUMVMIDC, bits[31:28] number of VMID comparators for tracing */
 	drvdata->numvmidc = BMVAL(etmidr4, 28, 31);
 
 	etmidr5 = readl_relaxed(drvdata->base + TRCIDR5);
 	/* NUMEXTIN, bits[8:0] number of external inputs implemented */
 	drvdata->nr_ext_inp = BMVAL(etmidr5, 0, 8);
 	/* TRACEIDSIZE, bits[21:16] indicates the trace ID width */
 	drvdata->trcid_size = BMVAL(etmidr5, 16, 21);
 	/* ATBTRIG, bit[22] implementation can support ATB triggers? */
 	if (BMVAL(etmidr5, 22, 22))
 		drvdata->atbtrig = true;
 	else
 		drvdata->atbtrig = false;
 	/*
 	 * LPOVERRIDE, bit[23] implementation supports
 	 * low-power state override
 	 */
 	if (BMVAL(etmidr5, 23, 23))
 		drvdata->lpoverride = true;
 	else
 		drvdata->lpoverride = false;
 	/* NUMSEQSTATE, bits[27:25] number of sequencer states implemented */
 	drvdata->nrseqstate = BMVAL(etmidr5, 25, 27);
 	/* NUMCNTR, bits[30:28] number of counters available for tracing */
 	drvdata->nr_cntr = BMVAL(etmidr5, 28, 30);
 	CS_LOCK(drvdata->base);
 }
 
 static void etm4_set_default_config(struct etmv4_config *config)
 {
 	/* disable all events tracing */
 	config->eventctrl0 = 0x0;
 	config->eventctrl1 = 0x0;
 
 	/* disable stalling */
 	config->stall_ctrl = 0x0;
 
 	/* enable trace synchronization every 4096 bytes, if available */
 	config->syncfreq = 0xC;
 
 	/* disable timestamp event */
 	config->ts_ctrl = 0x0;
 
 	/* TRCVICTLR::EVENT = 0x01, select the always on logic */
 	config->vinst_ctrl |= BIT(0);
 }
 
 static u64 etm4_get_access_type(struct etmv4_config *config)
 {
 	u64 access_type = 0;
 
 	/*
 	 * EXLEVEL_NS, bits[15:12]
 	 * The Exception levels are:
 	 *   Bit[12] Exception level 0 - Application
 	 *   Bit[13] Exception level 1 - OS
 	 *   Bit[14] Exception level 2 - Hypervisor
 	 *   Bit[15] Never implemented
 	 *
 	 * Always stay away from hypervisor mode.
 	 */
 	access_type = ETM_EXLEVEL_NS_HYP;
 
 	if (config->mode & ETM_MODE_EXCL_KERN)
 		access_type |= ETM_EXLEVEL_NS_OS;
 
 	if (config->mode & ETM_MODE_EXCL_USER)
 		access_type |= ETM_EXLEVEL_NS_APP;
 
 	/*
 	 * EXLEVEL_S, bits[11:8], don't trace anything happening
 	 * in secure state.
 	 */
 	access_type |= (ETM_EXLEVEL_S_APP	|
 			ETM_EXLEVEL_S_OS	|
 			ETM_EXLEVEL_S_HYP);
 
 	return access_type;
 }
 
 static void etm4_set_comparator_filter(struct etmv4_config *config,
 				       u64 start, u64 stop, int comparator)
 {
 	u64 access_type = etm4_get_access_type(config);
 
 	/* First half of default address comparator */
 	config->addr_val[comparator] = start;
 	config->addr_acc[comparator] = access_type;
 	config->addr_type[comparator] = ETM_ADDR_TYPE_RANGE;
 
 	/* Second half of default address comparator */
 	config->addr_val[comparator + 1] = stop;
 	config->addr_acc[comparator + 1] = access_type;
 	config->addr_type[comparator + 1] = ETM_ADDR_TYPE_RANGE;
 
 	/*
 	 * Configure the ViewInst function to include this address range
 	 * comparator.
 	 *
 	 * @comparator is divided by two since it is the index in the
 	 * etmv4_config::addr_val array but register TRCVIIECTLR deals with
 	 * address range comparator _pairs_.
 	 *
 	 * Therefore:
 	 *	index 0 -> compatator pair 0
 	 *	index 2 -> comparator pair 1
 	 *	index 4 -> comparator pair 2
 	 *	...
 	 *	index 14 -> comparator pair 7
 	 */
 	config->viiectlr |= BIT(comparator / 2);
 }
 
 static void etm4_set_start_stop_filter(struct etmv4_config *config,
 				       u64 address, int comparator,
 				       enum etm_addr_type type)
 {
 	int shift;
 	u64 access_type = etm4_get_access_type(config);
 
 	/* Configure the comparator */
 	config->addr_val[comparator] = address;
 	config->addr_acc[comparator] = access_type;
 	config->addr_type[comparator] = type;
 
 	/*
 	 * Configure ViewInst Start-Stop control register.
 	 * Addresses configured to start tracing go from bit 0 to n-1,
 	 * while those configured to stop tracing from 16 to 16 + n-1.
 	 */
 	shift = (type == ETM_ADDR_TYPE_START ? 0 : 16);
 	config->vissctlr |= BIT(shift + comparator);
 }
 
 static void etm4_set_default_filter(struct etmv4_config *config)
 {
 	u64 start, stop;
 
 	/*
 	 * Configure address range comparator '0' to encompass all
 	 * possible addresses.
 	 */
 	start = 0x0;
 	stop = ~0x0;
 
 	etm4_set_comparator_filter(config, start, stop,
 				   ETM_DEFAULT_ADDR_COMP);
 
 	/*
 	 * TRCVICTLR::SSSTATUS == 1, the start-stop logic is
 	 * in the started state
 	 */
 	config->vinst_ctrl |= BIT(9);
 
 	/* No start-stop filtering for ViewInst */
 	config->vissctlr = 0x0;
 }
 
 static void etm4_set_default(struct etmv4_config *config)
 {
 	if (WARN_ON_ONCE(!config))
 		return;
 
 	/*
 	 * Make default initialisation trace everything
 	 *
 	 * Select the "always true" resource selector on the
 	 * "Enablign Event" line and configure address range comparator
 	 * '0' to trace all the possible address range.  From there
 	 * configure the "include/exclude" engine to include address
 	 * range comparator '0'.
 	 */
 	etm4_set_default_config(config);
 	etm4_set_default_filter(config);
 }
 
 static int etm4_get_next_comparator(struct etmv4_drvdata *drvdata, u32 type)
 {
 	int nr_comparator, index = 0;
 	struct etmv4_config *config = &drvdata->config;
 
 	/*
 	 * nr_addr_cmp holds the number of comparator _pair_, so time 2
 	 * for the total number of comparators.
 	 */
 	nr_comparator = drvdata->nr_addr_cmp * 2;
 
 	/* Go through the tally of comparators looking for a free one. */
 	while (index < nr_comparator) {
 		switch (type) {
 		case ETM_ADDR_TYPE_RANGE:
 			if (config->addr_type[index] == ETM_ADDR_TYPE_NONE &&
 			    config->addr_type[index + 1] == ETM_ADDR_TYPE_NONE)
 				return index;
 
 			/* Address range comparators go in pairs */
 			index += 2;
 			break;
 		case ETM_ADDR_TYPE_START:
 		case ETM_ADDR_TYPE_STOP:
 			if (config->addr_type[index] == ETM_ADDR_TYPE_NONE)
 				return index;
 
 			/* Start/stop address can have odd indexes */
 			index += 1;
 			break;
 		default:
 			return -EINVAL;
 		}
 	}
 
 	/* If we are here all the comparators have been used. */
 	return -ENOSPC;
 }
 
 static int etm4_set_event_filters(struct etmv4_drvdata *drvdata,
 				  struct perf_event *event)
 {
 	int i, comparator, ret = 0;
 	u64 address;
 	struct etmv4_config *config = &drvdata->config;
 	struct etm_filters *filters = event->hw.addr_filters;
 
 	if (!filters)
 		goto default_filter;
 
 	/* Sync events with what Perf got */
 	perf_event_addr_filters_sync(event);
 
 	/*
 	 * If there are no filters to deal with simply go ahead with
 	 * the default filter, i.e the entire address range.
 	 */
 	if (!filters->nr_filters)
 		goto default_filter;
 
 	for (i = 0; i < filters->nr_filters; i++) {
 		struct etm_filter *filter = &filters->etm_filter[i];
 		enum etm_addr_type type = filter->type;
 
 		/* See if a comparator is free. */
 		comparator = etm4_get_next_comparator(drvdata, type);
 		if (comparator < 0) {
 			ret = comparator;
 			goto out;
 		}
 
 		switch (type) {
 		case ETM_ADDR_TYPE_RANGE:
 			etm4_set_comparator_filter(config,
 						   filter->start_addr,
 						   filter->stop_addr,
 						   comparator);
 			/*
 			 * TRCVICTLR::SSSTATUS == 1, the start-stop logic is
 			 * in the started state
 			 */
 			config->vinst_ctrl |= BIT(9);
 
 			/* No start-stop filtering for ViewInst */
 			config->vissctlr = 0x0;
 			break;
 		case ETM_ADDR_TYPE_START:
 		case ETM_ADDR_TYPE_STOP:
 			/* Get the right start or stop address */
 			address = (type == ETM_ADDR_TYPE_START ?
 				   filter->start_addr :
 				   filter->stop_addr);
 
 			/* Configure comparator */
 			etm4_set_start_stop_filter(config, address,
 						   comparator, type);
 
 			/*
 			 * If filters::ssstatus == 1, trace acquisition was
 			 * started but the process was yanked away before the
 			 * the stop address was hit.  As such the start/stop
 			 * logic needs to be re-started so that tracing can
 			 * resume where it left.
 			 *
 			 * The start/stop logic status when a process is
 			 * scheduled out is checked in function
 			 * etm4_disable_perf().
 			 */
 			if (filters->ssstatus)
 				config->vinst_ctrl |= BIT(9);
 
 			/* No include/exclude filtering for ViewInst */
 			config->viiectlr = 0x0;
 			break;
 		default:
 			ret = -EINVAL;
 			goto out;
 		}
 	}
 
 	goto out;
 
 
 default_filter:
 	etm4_set_default_filter(config);
 
 out:
 	return ret;
 }
 
 void etm4_config_trace_mode(struct etmv4_config *config)
 {
 	u32 addr_acc, mode;
 
 	mode = config->mode;
 	mode &= (ETM_MODE_EXCL_KERN | ETM_MODE_EXCL_USER);
 
 	/* excluding kernel AND user space doesn't make sense */
 	WARN_ON_ONCE(mode == (ETM_MODE_EXCL_KERN | ETM_MODE_EXCL_USER));
 
 	/* nothing to do if neither flags are set */
 	if (!(mode & ETM_MODE_EXCL_KERN) && !(mode & ETM_MODE_EXCL_USER))
 		return;
 
 	addr_acc = config->addr_acc[ETM_DEFAULT_ADDR_COMP];
 	/* clear default config */
 	addr_acc &= ~(ETM_EXLEVEL_NS_APP | ETM_EXLEVEL_NS_OS);
 
 	/*
 	 * EXLEVEL_NS, bits[15:12]
 	 * The Exception levels are:
 	 *   Bit[12] Exception level 0 - Application
 	 *   Bit[13] Exception level 1 - OS
 	 *   Bit[14] Exception level 2 - Hypervisor
 	 *   Bit[15] Never implemented
 	 */
 	if (mode & ETM_MODE_EXCL_KERN)
 		addr_acc |= ETM_EXLEVEL_NS_OS;
 	else
 		addr_acc |= ETM_EXLEVEL_NS_APP;
 
 	config->addr_acc[ETM_DEFAULT_ADDR_COMP] = addr_acc;
 	config->addr_acc[ETM_DEFAULT_ADDR_COMP + 1] = addr_acc;
 }
 
 static int etm4_online_cpu(unsigned int cpu)
 {
 	if (!etmdrvdata[cpu])
 		return 0;
 
 	if (etmdrvdata[cpu]->boot_enable && !etmdrvdata[cpu]->sticky_enable)
 		coresight_enable(etmdrvdata[cpu]->csdev);
 	return 0;
 }
 
 static int etm4_starting_cpu(unsigned int cpu)
 {
 	if (!etmdrvdata[cpu])
 		return 0;
 
 	spin_lock(&etmdrvdata[cpu]->spinlock);
 	if (!etmdrvdata[cpu]->os_unlock) {
 		etm4_os_unlock(etmdrvdata[cpu]);
 		etmdrvdata[cpu]->os_unlock = true;
 	}
 
 	if (local_read(&etmdrvdata[cpu]->mode))
 		etm4_enable_hw(etmdrvdata[cpu]);
 	spin_unlock(&etmdrvdata[cpu]->spinlock);
 	return 0;
 }
 
 static int etm4_dying_cpu(unsigned int cpu)
 {
 	if (!etmdrvdata[cpu])
 		return 0;
 
 	spin_lock(&etmdrvdata[cpu]->spinlock);
 	if (local_read(&etmdrvdata[cpu]->mode))
 		etm4_disable_hw(etmdrvdata[cpu]);
 	spin_unlock(&etmdrvdata[cpu]->spinlock);
 	return 0;
 }
 
 static void etm4_init_trace_id(struct etmv4_drvdata *drvdata)
 {
 	drvdata->trcid = coresight_get_trace_id(drvdata->cpu);
 }
 
 static int etm4_probe(struct amba_device *adev, const struct amba_id *id)
 {
 	int ret;
 	void __iomem *base;
 	struct device *dev = &adev->dev;
 	struct coresight_platform_data *pdata = NULL;
 	struct etmv4_drvdata *drvdata;
 	struct resource *res = &adev->res;
 	struct coresight_desc desc = { 0 };
 	struct device_node *np = adev->dev.of_node;
 
 	drvdata = devm_kzalloc(dev, sizeof(*drvdata), GFP_KERNEL);
 	if (!drvdata)
 		return -ENOMEM;
 
 	if (np) {
 		pdata = of_get_coresight_platform_data(dev, np);
 		if (IS_ERR(pdata))
 			return PTR_ERR(pdata);
 		adev->dev.platform_data = pdata;
 	}
 
 	drvdata->dev = &adev->dev;
 	dev_set_drvdata(dev, drvdata);
 
 	/* Validity for the resource is already checked by the AMBA core */
 	base = devm_ioremap_resource(dev, res);
 	if (IS_ERR(base))
 		return PTR_ERR(base);
 
 	drvdata->base = base;
 
 	spin_lock_init(&drvdata->spinlock);
 
 	drvdata->cpu = pdata ? pdata->cpu : 0;
 
 	get_online_cpus();
 	etmdrvdata[drvdata->cpu] = drvdata;
 
 	if (smp_call_function_single(drvdata->cpu,
 				etm4_init_arch_data,  drvdata, 1))
 		dev_err(dev, "ETM arch init failed\n");
 
 	if (!etm4_count++) {
 		cpuhp_setup_state_nocalls(CPUHP_AP_ARM_CORESIGHT_STARTING,
 					  "arm/coresight4:starting",
 					  etm4_starting_cpu, etm4_dying_cpu);
 		ret = cpuhp_setup_state_nocalls(CPUHP_AP_ONLINE_DYN,
 						"arm/coresight4:online",
 						etm4_online_cpu, NULL);
 		if (ret < 0)
 			goto err_arch_supported;
 		hp_online = ret;
 	}
 
 	put_online_cpus();
 
 	if (etm4_arch_supported(drvdata->arch) == false) {
 		ret = -EINVAL;
 		goto err_arch_supported;
 	}
 
 	etm4_init_trace_id(drvdata);
 	etm4_set_default(&drvdata->config);
 
 	desc.type = CORESIGHT_DEV_TYPE_SOURCE;
 	desc.subtype.source_subtype = CORESIGHT_DEV_SUBTYPE_SOURCE_PROC;
 	desc.ops = &etm4_cs_ops;
 	desc.pdata = pdata;
 	desc.dev = dev;
 	desc.groups = coresight_etmv4_groups;
 	drvdata->csdev = coresight_register(&desc);
 	if (IS_ERR(drvdata->csdev)) {
 		ret = PTR_ERR(drvdata->csdev);
 		goto err_arch_supported;
 	}
 
 	ret = etm_perf_symlink(drvdata->csdev, true);
 	if (ret) {
 		coresight_unregister(drvdata->csdev);
 		goto err_arch_supported;
 	}
 
 	pm_runtime_put(&adev->dev);
 	dev_info(dev, "%s initialized\n", (char *)id->data);
 
 	if (boot_enable) {
 		coresight_enable(drvdata->csdev);
 		drvdata->boot_enable = true;
 	}
 
 	return 0;
 
 err_arch_supported:
 	if (--etm4_count == 0) {
 		cpuhp_remove_state_nocalls(CPUHP_AP_ARM_CORESIGHT_STARTING);
 		if (hp_online)
 			cpuhp_remove_state_nocalls(hp_online);
 	}
 	return ret;
 }
 
 static struct amba_id etm4_ids[] = {
 	{       /* ETM 4.0 - Cortex-A53  */
 		.id	= 0x000bb95d,
 		.mask	= 0x000fffff,
 		.data	= "ETM 4.0",
 	},
 	{       /* ETM 4.0 - Cortex-A57 */
 		.id	= 0x000bb95e,
 		.mask	= 0x000fffff,
 		.data	= "ETM 4.0",
 	},
 	{       /* ETM 4.0 - A72, Maia, HiSilicon */
 		.id = 0x000bb95a,
 		.mask = 0x000fffff,
 		.data = "ETM 4.0",
 	},
 	{ 0, 0},
 };
 
 static struct amba_driver etm4x_driver = {
 	.drv = {
 		.name   = "coresight-etm4x",
 		.suppress_bind_attrs = true,
 	},
 	.probe		= etm4_probe,
 	.id_table	= etm4_ids,
 };
 builtin_amba_driver(etm4x_driver);
diff --git a/drivers/hwtracing/coresight/coresight-etm4x.h b/drivers/hwtracing/coresight/coresight-etm4x.h
index ba8d3f86de21..b3b5ea7b7fb3 100644
--- a/drivers/hwtracing/coresight/coresight-etm4x.h
+++ b/drivers/hwtracing/coresight/coresight-etm4x.h
@@ -1,415 +1,416 @@
 /* Copyright (c) 2014-2015, The Linux Foundation. All rights reserved.
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License version 2 and
  * only version 2 as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
  */
 
 #ifndef _CORESIGHT_CORESIGHT_ETM_H
 #define _CORESIGHT_CORESIGHT_ETM_H
 
 #include <asm/local.h>
 #include <linux/spinlock.h>
 #include "coresight-priv.h"
 
 /*
  * Device registers:
  * 0x000 - 0x2FC: Trace		registers
  * 0x300 - 0x314: Management	registers
  * 0x318 - 0xEFC: Trace		registers
  * 0xF00: Management		registers
  * 0xFA0 - 0xFA4: Trace		registers
  * 0xFA8 - 0xFFC: Management	registers
  */
 /* Trace registers (0x000-0x2FC) */
 /* Main control and configuration registers */
 #define TRCPRGCTLR			0x004
 #define TRCPROCSELR			0x008
 #define TRCSTATR			0x00C
 #define TRCCONFIGR			0x010
 #define TRCAUXCTLR			0x018
 #define TRCEVENTCTL0R			0x020
 #define TRCEVENTCTL1R			0x024
 #define TRCSTALLCTLR			0x02C
 #define TRCTSCTLR			0x030
 #define TRCSYNCPR			0x034
 #define TRCCCCTLR			0x038
 #define TRCBBCTLR			0x03C
 #define TRCTRACEIDR			0x040
 #define TRCQCTLR			0x044
 /* Filtering control registers */
 #define TRCVICTLR			0x080
 #define TRCVIIECTLR			0x084
 #define TRCVISSCTLR			0x088
 #define TRCVIPCSSCTLR			0x08C
 #define TRCVDCTLR			0x0A0
 #define TRCVDSACCTLR			0x0A4
 #define TRCVDARCCTLR			0x0A8
 /* Derived resources registers */
 #define TRCSEQEVRn(n)			(0x100 + (n * 4))
 #define TRCSEQRSTEVR			0x118
 #define TRCSEQSTR			0x11C
 #define TRCEXTINSELR			0x120
 #define TRCCNTRLDVRn(n)			(0x140 + (n * 4))
 #define TRCCNTCTLRn(n)			(0x150 + (n * 4))
 #define TRCCNTVRn(n)			(0x160 + (n * 4))
 /* ID registers */
 #define TRCIDR8				0x180
 #define TRCIDR9				0x184
 #define TRCIDR10			0x188
 #define TRCIDR11			0x18C
 #define TRCIDR12			0x190
 #define TRCIDR13			0x194
 #define TRCIMSPEC0			0x1C0
 #define TRCIMSPECn(n)			(0x1C0 + (n * 4))
 #define TRCIDR0				0x1E0
 #define TRCIDR1				0x1E4
 #define TRCIDR2				0x1E8
 #define TRCIDR3				0x1EC
 #define TRCIDR4				0x1F0
 #define TRCIDR5				0x1F4
 #define TRCIDR6				0x1F8
 #define TRCIDR7				0x1FC
 /* Resource selection registers */
 #define TRCRSCTLRn(n)			(0x200 + (n * 4))
 /* Single-shot comparator registers */
 #define TRCSSCCRn(n)			(0x280 + (n * 4))
 #define TRCSSCSRn(n)			(0x2A0 + (n * 4))
 #define TRCSSPCICRn(n)			(0x2C0 + (n * 4))
 /* Management registers (0x300-0x314) */
 #define TRCOSLAR			0x300
 #define TRCOSLSR			0x304
 #define TRCPDCR				0x310
 #define TRCPDSR				0x314
 /* Trace registers (0x318-0xEFC) */
 /* Comparator registers */
 #define TRCACVRn(n)			(0x400 + (n * 8))
 #define TRCACATRn(n)			(0x480 + (n * 8))
 #define TRCDVCVRn(n)			(0x500 + (n * 16))
 #define TRCDVCMRn(n)			(0x580 + (n * 16))
 #define TRCCIDCVRn(n)			(0x600 + (n * 8))
 #define TRCVMIDCVRn(n)			(0x640 + (n * 8))
 #define TRCCIDCCTLR0			0x680
 #define TRCCIDCCTLR1			0x684
 #define TRCVMIDCCTLR0			0x688
 #define TRCVMIDCCTLR1			0x68C
 /* Management register (0xF00) */
 /* Integration control registers */
 #define TRCITCTRL			0xF00
 /* Trace registers (0xFA0-0xFA4) */
 /* Claim tag registers */
 #define TRCCLAIMSET			0xFA0
 #define TRCCLAIMCLR			0xFA4
 /* Management registers (0xFA8-0xFFC) */
 #define TRCDEVAFF0			0xFA8
 #define TRCDEVAFF1			0xFAC
 #define TRCLAR				0xFB0
 #define TRCLSR				0xFB4
 #define TRCAUTHSTATUS			0xFB8
 #define TRCDEVARCH			0xFBC
 #define TRCDEVID			0xFC8
 #define TRCDEVTYPE			0xFCC
 #define TRCPIDR4			0xFD0
 #define TRCPIDR5			0xFD4
 #define TRCPIDR6			0xFD8
 #define TRCPIDR7			0xFDC
 #define TRCPIDR0			0xFE0
 #define TRCPIDR1			0xFE4
 #define TRCPIDR2			0xFE8
 #define TRCPIDR3			0xFEC
 #define TRCCIDR0			0xFF0
 #define TRCCIDR1			0xFF4
 #define TRCCIDR2			0xFF8
 #define TRCCIDR3			0xFFC
 
 /* ETMv4 resources */
 #define ETM_MAX_NR_PE			8
 #define ETMv4_MAX_CNTR			4
 #define ETM_MAX_SEQ_STATES		4
 #define ETM_MAX_EXT_INP_SEL		4
 #define ETM_MAX_EXT_INP			256
 #define ETM_MAX_EXT_OUT			4
 #define ETM_MAX_SINGLE_ADDR_CMP		16
 #define ETM_MAX_ADDR_RANGE_CMP		(ETM_MAX_SINGLE_ADDR_CMP / 2)
 #define ETM_MAX_DATA_VAL_CMP		8
 #define ETMv4_MAX_CTXID_CMP		8
 #define ETM_MAX_VMID_CMP		8
 #define ETM_MAX_PE_CMP			8
 #define ETM_MAX_RES_SEL			16
 #define ETM_MAX_SS_CMP			8
 
 #define ETM_ARCH_V4			0x40
 #define ETMv4_SYNC_MASK			0x1F
 #define ETM_CYC_THRESHOLD_MASK		0xFFF
+#define ETM_CYC_THRESHOLD_DEFAULT       0x100
 #define ETMv4_EVENT_MASK		0xFF
 #define ETM_CNTR_MAX_VAL		0xFFFF
 #define ETM_TRACEID_MASK		0x3f
 
 /* ETMv4 programming modes */
 #define ETM_MODE_EXCLUDE		BIT(0)
 #define ETM_MODE_LOAD			BIT(1)
 #define ETM_MODE_STORE			BIT(2)
 #define ETM_MODE_LOAD_STORE		BIT(3)
 #define ETM_MODE_BB			BIT(4)
 #define ETMv4_MODE_CYCACC		BIT(5)
 #define ETMv4_MODE_CTXID		BIT(6)
 #define ETM_MODE_VMID			BIT(7)
 #define ETM_MODE_COND(val)		BMVAL(val, 8, 10)
 #define ETMv4_MODE_TIMESTAMP		BIT(11)
 #define ETM_MODE_RETURNSTACK		BIT(12)
 #define ETM_MODE_QELEM(val)		BMVAL(val, 13, 14)
 #define ETM_MODE_DATA_TRACE_ADDR	BIT(15)
 #define ETM_MODE_DATA_TRACE_VAL		BIT(16)
 #define ETM_MODE_ISTALL			BIT(17)
 #define ETM_MODE_DSTALL			BIT(18)
 #define ETM_MODE_ATB_TRIGGER		BIT(19)
 #define ETM_MODE_LPOVERRIDE		BIT(20)
 #define ETM_MODE_ISTALL_EN		BIT(21)
 #define ETM_MODE_DSTALL_EN		BIT(22)
 #define ETM_MODE_INSTPRIO		BIT(23)
 #define ETM_MODE_NOOVERFLOW		BIT(24)
 #define ETM_MODE_TRACE_RESET		BIT(25)
 #define ETM_MODE_TRACE_ERR		BIT(26)
 #define ETM_MODE_VIEWINST_STARTSTOP	BIT(27)
 #define ETMv4_MODE_ALL			(GENMASK(27, 0) | \
 					 ETM_MODE_EXCL_KERN | \
 					 ETM_MODE_EXCL_USER)
 
 #define TRCSTATR_IDLE_BIT		0
 #define ETM_DEFAULT_ADDR_COMP		0
 
 /* PowerDown Control Register bits */
 #define TRCPDCR_PU			BIT(3)
 
 /* secure state access levels */
 #define ETM_EXLEVEL_S_APP		BIT(8)
 #define ETM_EXLEVEL_S_OS		BIT(9)
 #define ETM_EXLEVEL_S_NA		BIT(10)
 #define ETM_EXLEVEL_S_HYP		BIT(11)
 /* non-secure state access levels */
 #define ETM_EXLEVEL_NS_APP		BIT(12)
 #define ETM_EXLEVEL_NS_OS		BIT(13)
 #define ETM_EXLEVEL_NS_HYP		BIT(14)
 #define ETM_EXLEVEL_NS_NA		BIT(15)
 
 /**
  * struct etmv4_config - configuration information related to an ETMv4
  * @mode:	Controls various modes supported by this ETM.
  * @pe_sel:	Controls which PE to trace.
  * @cfg:	Controls the tracing options.
  * @eventctrl0: Controls the tracing of arbitrary events.
  * @eventctrl1: Controls the behavior of the events that @event_ctrl0 selects.
  * @stallctl:	If functionality that prevents trace unit buffer overflows
  *		is available.
  * @ts_ctrl:	Controls the insertion of global timestamps in the
  *		trace streams.
  * @syncfreq:	Controls how often trace synchronization requests occur.
  *		the TRCCCCTLR register.
  * @ccctlr:	Sets the threshold value for cycle counting.
  * @vinst_ctrl:	Controls instruction trace filtering.
  * @viiectlr:	Set or read, the address range comparators.
  * @vissctlr:	Set, or read, the single address comparators that control the
  *		ViewInst start-stop logic.
  * @vipcssctlr:	Set, or read, which PE comparator inputs can control the
  *		ViewInst start-stop logic.
  * @seq_idx:	Sequencor index selector.
  * @seq_ctrl:	Control for the sequencer state transition control register.
  * @seq_rst:	Moves the sequencer to state 0 when a programmed event occurs.
  * @seq_state:	Set, or read the sequencer state.
  * @cntr_idx:	Counter index seletor.
  * @cntrldvr:	Sets or returns the reload count value for a counter.
  * @cntr_ctrl:	Controls the operation of a counter.
  * @cntr_val:	Sets or returns the value for a counter.
  * @res_idx:	Resource index selector.
  * @res_ctrl:	Controls the selection of the resources in the trace unit.
  * @ss_ctrl:	Controls the corresponding single-shot comparator resource.
  * @ss_status:	The status of the corresponding single-shot comparator.
  * @ss_pe_cmp:	Selects the PE comparator inputs for Single-shot control.
  * @addr_idx:	Address comparator index selector.
  * @addr_val:	Value for address comparator.
  * @addr_acc:	Address comparator access type.
  * @addr_type:	Current status of the comparator register.
  * @ctxid_idx:	Context ID index selector.
  * @ctxid_pid:	Value of the context ID comparator.
  * @ctxid_vpid:	Virtual PID seen by users if PID namespace is enabled, otherwise
  *		the same value of ctxid_pid.
  * @ctxid_mask0:Context ID comparator mask for comparator 0-3.
  * @ctxid_mask1:Context ID comparator mask for comparator 4-7.
  * @vmid_idx:	VM ID index selector.
  * @vmid_val:	Value of the VM ID comparator.
  * @vmid_mask0:	VM ID comparator mask for comparator 0-3.
  * @vmid_mask1:	VM ID comparator mask for comparator 4-7.
  * @ext_inp:	External input selection.
  */
 struct etmv4_config {
 	u32				mode;
 	u32				pe_sel;
 	u32				cfg;
 	u32				eventctrl0;
 	u32				eventctrl1;
 	u32				stall_ctrl;
 	u32				ts_ctrl;
 	u32				syncfreq;
 	u32				ccctlr;
 	u32				bb_ctrl;
 	u32				vinst_ctrl;
 	u32				viiectlr;
 	u32				vissctlr;
 	u32				vipcssctlr;
 	u8				seq_idx;
 	u32				seq_ctrl[ETM_MAX_SEQ_STATES];
 	u32				seq_rst;
 	u32				seq_state;
 	u8				cntr_idx;
 	u32				cntrldvr[ETMv4_MAX_CNTR];
 	u32				cntr_ctrl[ETMv4_MAX_CNTR];
 	u32				cntr_val[ETMv4_MAX_CNTR];
 	u8				res_idx;
 	u32				res_ctrl[ETM_MAX_RES_SEL];
 	u32				ss_ctrl[ETM_MAX_SS_CMP];
 	u32				ss_status[ETM_MAX_SS_CMP];
 	u32				ss_pe_cmp[ETM_MAX_SS_CMP];
 	u8				addr_idx;
 	u64				addr_val[ETM_MAX_SINGLE_ADDR_CMP];
 	u64				addr_acc[ETM_MAX_SINGLE_ADDR_CMP];
 	u8				addr_type[ETM_MAX_SINGLE_ADDR_CMP];
 	u8				ctxid_idx;
 	u64				ctxid_pid[ETMv4_MAX_CTXID_CMP];
 	u64				ctxid_vpid[ETMv4_MAX_CTXID_CMP];
 	u32				ctxid_mask0;
 	u32				ctxid_mask1;
 	u8				vmid_idx;
 	u64				vmid_val[ETM_MAX_VMID_CMP];
 	u32				vmid_mask0;
 	u32				vmid_mask1;
 	u32				ext_inp;
 };
 
 /**
  * struct etm4_drvdata - specifics associated to an ETM component
  * @base:       Memory mapped base address for this component.
  * @dev:        The device entity associated to this component.
  * @csdev:      Component vitals needed by the framework.
  * @spinlock:   Only one at a time pls.
  * @mode:	This tracer's mode, i.e sysFS, Perf or disabled.
  * @cpu:        The cpu this component is affined to.
  * @arch:       ETM version number.
  * @nr_pe:	The number of processing entity available for tracing.
  * @nr_pe_cmp:	The number of processing entity comparator inputs that are
  *		available for tracing.
  * @nr_addr_cmp:Number of pairs of address comparators available
  *		as found in ETMIDR4 0-3.
  * @nr_cntr:    Number of counters as found in ETMIDR5 bit 28-30.
  * @nr_ext_inp: Number of external input.
  * @numcidc:	Number of contextID comparators.
  * @numvmidc:	Number of VMID comparators.
  * @nrseqstate: The number of sequencer states that are implemented.
  * @nr_event:	Indicates how many events the trace unit support.
  * @nr_resource:The number of resource selection pairs available for tracing.
  * @nr_ss_cmp:	Number of single-shot comparator controls that are available.
  * @trcid:	value of the current ID for this component.
  * @trcid_size: Indicates the trace ID width.
  * @ts_size:	Global timestamp size field.
  * @ctxid_size:	Size of the context ID field to consider.
  * @vmid_size:	Size of the VM ID comparator to consider.
  * @ccsize:	Indicates the size of the cycle counter in bits.
  * @ccitmin:	minimum value that can be programmed in
  * @s_ex_level:	In secure state, indicates whether instruction tracing is
  *		supported for the corresponding Exception level.
  * @ns_ex_level:In non-secure state, indicates whether instruction tracing is
  *		supported for the corresponding Exception level.
  * @sticky_enable: true if ETM base configuration has been done.
  * @boot_enable:True if we should start tracing at boot time.
  * @os_unlock:  True if access to management registers is allowed.
  * @instrp0:	Tracing of load and store instructions
  *		as P0 elements is supported.
  * @trcbb:	Indicates if the trace unit supports branch broadcast tracing.
  * @trccond:	If the trace unit supports conditional
  *		instruction tracing.
  * @retstack:	Indicates if the implementation supports a return stack.
  * @trccci:	Indicates if the trace unit supports cycle counting
  *		for instruction.
  * @q_support:	Q element support characteristics.
  * @trc_error:	Whether a trace unit can trace a system
  *		error exception.
  * @syncpr:	Indicates if an implementation has a fixed
  *		synchronization period.
  * @stall_ctrl:	Enables trace unit functionality that prevents trace
  *		unit buffer overflows.
  * @sysstall:	Does the system support stall control of the PE?
  * @nooverflow:	Indicate if overflow prevention is supported.
  * @atbtrig:	If the implementation can support ATB triggers
  * @lpoverride:	If the implementation can support low-power state over.
  * @config:	structure holding configuration parameters.
  */
 struct etmv4_drvdata {
 	void __iomem			*base;
 	struct device			*dev;
 	struct coresight_device		*csdev;
 	spinlock_t			spinlock;
 	local_t				mode;
 	int				cpu;
 	u8				arch;
 	u8				nr_pe;
 	u8				nr_pe_cmp;
 	u8				nr_addr_cmp;
 	u8				nr_cntr;
 	u8				nr_ext_inp;
 	u8				numcidc;
 	u8				numvmidc;
 	u8				nrseqstate;
 	u8				nr_event;
 	u8				nr_resource;
 	u8				nr_ss_cmp;
 	u8				trcid;
 	u8				trcid_size;
 	u8				ts_size;
 	u8				ctxid_size;
 	u8				vmid_size;
 	u8				ccsize;
 	u8				ccitmin;
 	u8				s_ex_level;
 	u8				ns_ex_level;
 	u8				q_support;
 	bool				sticky_enable;
 	bool				boot_enable;
 	bool				os_unlock;
 	bool				instrp0;
 	bool				trcbb;
 	bool				trccond;
 	bool				retstack;
 	bool				trccci;
 	bool				trc_error;
 	bool				syncpr;
 	bool				stallctl;
 	bool				sysstall;
 	bool				nooverflow;
 	bool				atbtrig;
 	bool				lpoverride;
 	struct etmv4_config		config;
 };
 
 /* Address comparator access types */
 enum etm_addr_acctype {
 	ETM_INSTR_ADDR,
 	ETM_DATA_LOAD_ADDR,
 	ETM_DATA_STORE_ADDR,
 	ETM_DATA_LOAD_STORE_ADDR,
 };
 
 /* Address comparator context types */
 enum etm_addr_ctxtype {
 	ETM_CTX_NONE,
 	ETM_CTX_CTXID,
 	ETM_CTX_VMID,
 	ETM_CTX_CTXID_VMID,
 };
 
 extern const struct attribute_group *coresight_etmv4_groups[];
 void etm4_config_trace_mode(struct etmv4_config *config);
 #endif
diff --git a/drivers/hwtracing/coresight/coresight-stm.c b/drivers/hwtracing/coresight/coresight-stm.c
index e4c55c5f9988..93fc26f01bab 100644
--- a/drivers/hwtracing/coresight/coresight-stm.c
+++ b/drivers/hwtracing/coresight/coresight-stm.c
@@ -1,942 +1,942 @@
 /* Copyright (c) 2015-2016, The Linux Foundation. All rights reserved.
  *
  * Description: CoreSight System Trace Macrocell driver
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License version 2 and
  * only version 2 as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
  *
  * Initial implementation by Pratik Patel
  * (C) 2014-2015 Pratik Patel <pratikp@codeaurora.org>
  *
  * Serious refactoring, code cleanup and upgrading to the Coresight upstream
  * framework by Mathieu Poirier
  * (C) 2015-2016 Mathieu Poirier <mathieu.poirier@linaro.org>
  *
  * Guaranteed timing and support for various packet type coming from the
  * generic STM API by Chunyan Zhang
  * (C) 2015-2016 Chunyan Zhang <zhang.chunyan@linaro.org>
  */
 #include <asm/local.h>
 #include <linux/amba/bus.h>
 #include <linux/bitmap.h>
 #include <linux/clk.h>
 #include <linux/coresight.h>
 #include <linux/coresight-stm.h>
 #include <linux/err.h>
 #include <linux/kernel.h>
 #include <linux/moduleparam.h>
 #include <linux/of_address.h>
 #include <linux/perf_event.h>
 #include <linux/pm_runtime.h>
 #include <linux/stm.h>
 
 #include "coresight-priv.h"
 
 #define STMDMASTARTR			0xc04
 #define STMDMASTOPR			0xc08
 #define STMDMASTATR			0xc0c
 #define STMDMACTLR			0xc10
 #define STMDMAIDR			0xcfc
 #define STMHEER				0xd00
 #define STMHETER			0xd20
 #define STMHEBSR			0xd60
 #define STMHEMCR			0xd64
 #define STMHEMASTR			0xdf4
 #define STMHEFEAT1R			0xdf8
 #define STMHEIDR			0xdfc
 #define STMSPER				0xe00
 #define STMSPTER			0xe20
 #define STMPRIVMASKR			0xe40
 #define STMSPSCR			0xe60
 #define STMSPMSCR			0xe64
 #define STMSPOVERRIDER			0xe68
 #define STMSPMOVERRIDER			0xe6c
 #define STMSPTRIGCSR			0xe70
 #define STMTCSR				0xe80
 #define STMTSSTIMR			0xe84
 #define STMTSFREQR			0xe8c
 #define STMSYNCR			0xe90
 #define STMAUXCR			0xe94
 #define STMSPFEAT1R			0xea0
 #define STMSPFEAT2R			0xea4
 #define STMSPFEAT3R			0xea8
 #define STMITTRIGGER			0xee8
 #define STMITATBDATA0			0xeec
 #define STMITATBCTR2			0xef0
 #define STMITATBID			0xef4
 #define STMITATBCTR0			0xef8
 
 #define STM_32_CHANNEL			32
 #define BYTES_PER_CHANNEL		256
 #define STM_TRACE_BUF_SIZE		4096
 #define STM_SW_MASTER_END		127
 
 /* Register bit definition */
 #define STMTCSR_BUSY_BIT		23
 /* Reserve the first 10 channels for kernel usage */
 #define STM_CHANNEL_OFFSET		0
 
 enum stm_pkt_type {
 	STM_PKT_TYPE_DATA	= 0x98,
 	STM_PKT_TYPE_FLAG	= 0xE8,
 	STM_PKT_TYPE_TRIG	= 0xF8,
 };
 
 #define stm_channel_addr(drvdata, ch)	(drvdata->chs.base +	\
 					(ch * BYTES_PER_CHANNEL))
 #define stm_channel_off(type, opts)	(type & ~opts)
 
 static int boot_nr_channel;
 
 /*
  * Not really modular but using module_param is the easiest way to
  * remain consistent with existing use cases for now.
  */
 module_param_named(
 	boot_nr_channel, boot_nr_channel, int, S_IRUGO
 );
 
 /**
  * struct channel_space - central management entity for extended ports
  * @base:		memory mapped base address where channels start.
  * @phys:		physical base address of channel region.
  * @guaraneed:		is the channel delivery guaranteed.
  */
 struct channel_space {
 	void __iomem		*base;
 	phys_addr_t		phys;
 	unsigned long		*guaranteed;
 };
 
 /**
  * struct stm_drvdata - specifics associated to an STM component
  * @base:		memory mapped base address for this component.
  * @dev:		the device entity associated to this component.
  * @atclk:		optional clock for the core parts of the STM.
  * @csdev:		component vitals needed by the framework.
  * @spinlock:		only one at a time pls.
  * @chs:		the channels accociated to this STM.
  * @stm:		structure associated to the generic STM interface.
  * @mode:		this tracer's mode, i.e sysFS, or disabled.
  * @traceid:		value of the current ID for this component.
  * @write_bytes:	Maximus bytes this STM can write at a time.
  * @stmsper:		settings for register STMSPER.
  * @stmspscr:		settings for register STMSPSCR.
  * @numsp:		the total number of stimulus port support by this STM.
  * @stmheer:		settings for register STMHEER.
  * @stmheter:		settings for register STMHETER.
  * @stmhebsr:		settings for register STMHEBSR.
  */
 struct stm_drvdata {
 	void __iomem		*base;
 	struct device		*dev;
 	struct clk		*atclk;
 	struct coresight_device	*csdev;
 	spinlock_t		spinlock;
 	struct channel_space	chs;
 	struct stm_data		stm;
 	local_t			mode;
 	u8			traceid;
 	u32			write_bytes;
 	u32			stmsper;
 	u32			stmspscr;
 	u32			numsp;
 	u32			stmheer;
 	u32			stmheter;
 	u32			stmhebsr;
 };
 
 static void stm_hwevent_enable_hw(struct stm_drvdata *drvdata)
 {
 	CS_UNLOCK(drvdata->base);
 
 	writel_relaxed(drvdata->stmhebsr, drvdata->base + STMHEBSR);
 	writel_relaxed(drvdata->stmheter, drvdata->base + STMHETER);
 	writel_relaxed(drvdata->stmheer, drvdata->base + STMHEER);
 	writel_relaxed(0x01 |	/* Enable HW event tracing */
 		       0x04,	/* Error detection on event tracing */
 		       drvdata->base + STMHEMCR);
 
 	CS_LOCK(drvdata->base);
 }
 
 static void stm_port_enable_hw(struct stm_drvdata *drvdata)
 {
 	CS_UNLOCK(drvdata->base);
 	/* ATB trigger enable on direct writes to TRIG locations */
 	writel_relaxed(0x10,
 		       drvdata->base + STMSPTRIGCSR);
 	writel_relaxed(drvdata->stmspscr, drvdata->base + STMSPSCR);
 	writel_relaxed(drvdata->stmsper, drvdata->base + STMSPER);
 
 	CS_LOCK(drvdata->base);
 }
 
 static void stm_enable_hw(struct stm_drvdata *drvdata)
 {
 	if (drvdata->stmheer)
 		stm_hwevent_enable_hw(drvdata);
 
 	stm_port_enable_hw(drvdata);
 
 	CS_UNLOCK(drvdata->base);
 
 	/* 4096 byte between synchronisation packets */
 	writel_relaxed(0xFFF, drvdata->base + STMSYNCR);
 	writel_relaxed((drvdata->traceid << 16 | /* trace id */
 			0x02 |			 /* timestamp enable */
 			0x01),			 /* global STM enable */
 			drvdata->base + STMTCSR);
 
 	CS_LOCK(drvdata->base);
 }
 
 static int stm_enable(struct coresight_device *csdev,
 		      struct perf_event *event, u32 mode)
 {
 	u32 val;
 	struct stm_drvdata *drvdata = dev_get_drvdata(csdev->dev.parent);
 
 	if (mode != CS_MODE_SYSFS)
 		return -EINVAL;
 
 	val = local_cmpxchg(&drvdata->mode, CS_MODE_DISABLED, mode);
 
 	/* Someone is already using the tracer */
 	if (val)
 		return -EBUSY;
 
 	pm_runtime_get_sync(drvdata->dev);
 
 	spin_lock(&drvdata->spinlock);
 	stm_enable_hw(drvdata);
 	spin_unlock(&drvdata->spinlock);
 
 	dev_info(drvdata->dev, "STM tracing enabled\n");
 	return 0;
 }
 
 static void stm_hwevent_disable_hw(struct stm_drvdata *drvdata)
 {
 	CS_UNLOCK(drvdata->base);
 
 	writel_relaxed(0x0, drvdata->base + STMHEMCR);
 	writel_relaxed(0x0, drvdata->base + STMHEER);
 	writel_relaxed(0x0, drvdata->base + STMHETER);
 
 	CS_LOCK(drvdata->base);
 }
 
 static void stm_port_disable_hw(struct stm_drvdata *drvdata)
 {
 	CS_UNLOCK(drvdata->base);
 
 	writel_relaxed(0x0, drvdata->base + STMSPER);
 	writel_relaxed(0x0, drvdata->base + STMSPTRIGCSR);
 
 	CS_LOCK(drvdata->base);
 }
 
 static void stm_disable_hw(struct stm_drvdata *drvdata)
 {
 	u32 val;
 
 	CS_UNLOCK(drvdata->base);
 
 	val = readl_relaxed(drvdata->base + STMTCSR);
 	val &= ~0x1; /* clear global STM enable [0] */
 	writel_relaxed(val, drvdata->base + STMTCSR);
 
 	CS_LOCK(drvdata->base);
 
 	stm_port_disable_hw(drvdata);
 	if (drvdata->stmheer)
 		stm_hwevent_disable_hw(drvdata);
 }
 
 static void stm_disable(struct coresight_device *csdev,
 			struct perf_event *event)
 {
 	struct stm_drvdata *drvdata = dev_get_drvdata(csdev->dev.parent);
 
 	/*
 	 * For as long as the tracer isn't disabled another entity can't
 	 * change its status.  As such we can read the status here without
 	 * fearing it will change under us.
 	 */
 	if (local_read(&drvdata->mode) == CS_MODE_SYSFS) {
 		spin_lock(&drvdata->spinlock);
 		stm_disable_hw(drvdata);
 		spin_unlock(&drvdata->spinlock);
 
 		/* Wait until the engine has completely stopped */
 		coresight_timeout(drvdata, STMTCSR, STMTCSR_BUSY_BIT, 0);
 
 		pm_runtime_put(drvdata->dev);
 
 		local_set(&drvdata->mode, CS_MODE_DISABLED);
 		dev_info(drvdata->dev, "STM tracing disabled\n");
 	}
 }
 
 static int stm_trace_id(struct coresight_device *csdev)
 {
 	struct stm_drvdata *drvdata = dev_get_drvdata(csdev->dev.parent);
 
 	return drvdata->traceid;
 }
 
 static const struct coresight_ops_source stm_source_ops = {
 	.trace_id	= stm_trace_id,
 	.enable		= stm_enable,
 	.disable	= stm_disable,
 };
 
 static const struct coresight_ops stm_cs_ops = {
 	.source_ops	= &stm_source_ops,
 };
 
 static inline bool stm_addr_unaligned(const void *addr, u8 write_bytes)
 {
 	return ((unsigned long)addr & (write_bytes - 1));
 }
 
 static void stm_send(void *addr, const void *data, u32 size, u8 write_bytes)
 {
 	u8 paload[8];
 
 	if (stm_addr_unaligned(data, write_bytes)) {
 		memcpy(paload, data, size);
 		data = paload;
 	}
 
 	/* now we are 64bit/32bit aligned */
 	switch (size) {
 #ifdef CONFIG_64BIT
 	case 8:
 		writeq_relaxed(*(u64 *)data, addr);
 		break;
 #endif
 	case 4:
 		writel_relaxed(*(u32 *)data, addr);
 		break;
 	case 2:
 		writew_relaxed(*(u16 *)data, addr);
 		break;
 	case 1:
 		writeb_relaxed(*(u8 *)data, addr);
 		break;
 	default:
 		break;
 	}
 }
 
 static int stm_generic_link(struct stm_data *stm_data,
 			    unsigned int master,  unsigned int channel)
 {
 	struct stm_drvdata *drvdata = container_of(stm_data,
 						   struct stm_drvdata, stm);
 	if (!drvdata || !drvdata->csdev)
 		return -EINVAL;
 
 	return coresight_enable(drvdata->csdev);
 }
 
 static void stm_generic_unlink(struct stm_data *stm_data,
 			       unsigned int master,  unsigned int channel)
 {
 	struct stm_drvdata *drvdata = container_of(stm_data,
 						   struct stm_drvdata, stm);
 	if (!drvdata || !drvdata->csdev)
 		return;
 
-	stm_disable(drvdata->csdev, NULL);
+	coresight_disable(drvdata->csdev);
 }
 
 static phys_addr_t
 stm_mmio_addr(struct stm_data *stm_data, unsigned int master,
 	      unsigned int channel, unsigned int nr_chans)
 {
 	struct stm_drvdata *drvdata = container_of(stm_data,
 						   struct stm_drvdata, stm);
 	phys_addr_t addr;
 
 	addr = drvdata->chs.phys + channel * BYTES_PER_CHANNEL;
 
 	if (offset_in_page(addr) ||
 	    offset_in_page(nr_chans * BYTES_PER_CHANNEL))
 		return 0;
 
 	return addr;
 }
 
 static long stm_generic_set_options(struct stm_data *stm_data,
 				    unsigned int master,
 				    unsigned int channel,
 				    unsigned int nr_chans,
 				    unsigned long options)
 {
 	struct stm_drvdata *drvdata = container_of(stm_data,
 						   struct stm_drvdata, stm);
 	if (!(drvdata && local_read(&drvdata->mode)))
 		return -EINVAL;
 
 	if (channel >= drvdata->numsp)
 		return -EINVAL;
 
 	switch (options) {
 	case STM_OPTION_GUARANTEED:
 		set_bit(channel, drvdata->chs.guaranteed);
 		break;
 
 	case STM_OPTION_INVARIANT:
 		clear_bit(channel, drvdata->chs.guaranteed);
 		break;
 
 	default:
 		return -EINVAL;
 	}
 
 	return 0;
 }
 
 static ssize_t notrace stm_generic_packet(struct stm_data *stm_data,
 				  unsigned int master,
 				  unsigned int channel,
 				  unsigned int packet,
 				  unsigned int flags,
 				  unsigned int size,
 				  const unsigned char *payload)
 {
 	unsigned long ch_addr;
 	struct stm_drvdata *drvdata = container_of(stm_data,
 						   struct stm_drvdata, stm);
 
 	if (!(drvdata && local_read(&drvdata->mode)))
 		return -EACCES;
 
 	if (channel >= drvdata->numsp)
 		return -EINVAL;
 
 	ch_addr = (unsigned long)stm_channel_addr(drvdata, channel);
 
 	flags = (flags == STP_PACKET_TIMESTAMPED) ? STM_FLAG_TIMESTAMPED : 0;
 	flags |= test_bit(channel, drvdata->chs.guaranteed) ?
 			   STM_FLAG_GUARANTEED : 0;
 
 	if (size > drvdata->write_bytes)
 		size = drvdata->write_bytes;
 	else
 		size = rounddown_pow_of_two(size);
 
 	switch (packet) {
 	case STP_PACKET_FLAG:
 		ch_addr |= stm_channel_off(STM_PKT_TYPE_FLAG, flags);
 
 		/*
 		 * The generic STM core sets a size of '0' on flag packets.
 		 * As such send a flag packet of size '1' and tell the
 		 * core we did so.
 		 */
 		stm_send((void *)ch_addr, payload, 1, drvdata->write_bytes);
 		size = 1;
 		break;
 
 	case STP_PACKET_DATA:
 		ch_addr |= stm_channel_off(STM_PKT_TYPE_DATA, flags);
 		stm_send((void *)ch_addr, payload, size,
 				drvdata->write_bytes);
 		break;
 
 	default:
 		return -ENOTSUPP;
 	}
 
 	return size;
 }
 
 static ssize_t hwevent_enable_show(struct device *dev,
 				   struct device_attribute *attr, char *buf)
 {
 	struct stm_drvdata *drvdata = dev_get_drvdata(dev->parent);
 	unsigned long val = drvdata->stmheer;
 
 	return scnprintf(buf, PAGE_SIZE, "%#lx\n", val);
 }
 
 static ssize_t hwevent_enable_store(struct device *dev,
 				    struct device_attribute *attr,
 				    const char *buf, size_t size)
 {
 	struct stm_drvdata *drvdata = dev_get_drvdata(dev->parent);
 	unsigned long val;
 	int ret = 0;
 
 	ret = kstrtoul(buf, 16, &val);
 	if (ret)
 		return -EINVAL;
 
 	drvdata->stmheer = val;
 	/* HW event enable and trigger go hand in hand */
 	drvdata->stmheter = val;
 
 	return size;
 }
 static DEVICE_ATTR_RW(hwevent_enable);
 
 static ssize_t hwevent_select_show(struct device *dev,
 				   struct device_attribute *attr, char *buf)
 {
 	struct stm_drvdata *drvdata = dev_get_drvdata(dev->parent);
 	unsigned long val = drvdata->stmhebsr;
 
 	return scnprintf(buf, PAGE_SIZE, "%#lx\n", val);
 }
 
 static ssize_t hwevent_select_store(struct device *dev,
 				    struct device_attribute *attr,
 				    const char *buf, size_t size)
 {
 	struct stm_drvdata *drvdata = dev_get_drvdata(dev->parent);
 	unsigned long val;
 	int ret = 0;
 
 	ret = kstrtoul(buf, 16, &val);
 	if (ret)
 		return -EINVAL;
 
 	drvdata->stmhebsr = val;
 
 	return size;
 }
 static DEVICE_ATTR_RW(hwevent_select);
 
 static ssize_t port_select_show(struct device *dev,
 				struct device_attribute *attr, char *buf)
 {
 	struct stm_drvdata *drvdata = dev_get_drvdata(dev->parent);
 	unsigned long val;
 
 	if (!local_read(&drvdata->mode)) {
 		val = drvdata->stmspscr;
 	} else {
 		spin_lock(&drvdata->spinlock);
 		val = readl_relaxed(drvdata->base + STMSPSCR);
 		spin_unlock(&drvdata->spinlock);
 	}
 
 	return scnprintf(buf, PAGE_SIZE, "%#lx\n", val);
 }
 
 static ssize_t port_select_store(struct device *dev,
 				 struct device_attribute *attr,
 				 const char *buf, size_t size)
 {
 	struct stm_drvdata *drvdata = dev_get_drvdata(dev->parent);
 	unsigned long val, stmsper;
 	int ret = 0;
 
 	ret = kstrtoul(buf, 16, &val);
 	if (ret)
 		return ret;
 
 	spin_lock(&drvdata->spinlock);
 	drvdata->stmspscr = val;
 
 	if (local_read(&drvdata->mode)) {
 		CS_UNLOCK(drvdata->base);
 		/* Process as per ARM's TRM recommendation */
 		stmsper = readl_relaxed(drvdata->base + STMSPER);
 		writel_relaxed(0x0, drvdata->base + STMSPER);
 		writel_relaxed(drvdata->stmspscr, drvdata->base + STMSPSCR);
 		writel_relaxed(stmsper, drvdata->base + STMSPER);
 		CS_LOCK(drvdata->base);
 	}
 	spin_unlock(&drvdata->spinlock);
 
 	return size;
 }
 static DEVICE_ATTR_RW(port_select);
 
 static ssize_t port_enable_show(struct device *dev,
 				struct device_attribute *attr, char *buf)
 {
 	struct stm_drvdata *drvdata = dev_get_drvdata(dev->parent);
 	unsigned long val;
 
 	if (!local_read(&drvdata->mode)) {
 		val = drvdata->stmsper;
 	} else {
 		spin_lock(&drvdata->spinlock);
 		val = readl_relaxed(drvdata->base + STMSPER);
 		spin_unlock(&drvdata->spinlock);
 	}
 
 	return scnprintf(buf, PAGE_SIZE, "%#lx\n", val);
 }
 
 static ssize_t port_enable_store(struct device *dev,
 				 struct device_attribute *attr,
 				 const char *buf, size_t size)
 {
 	struct stm_drvdata *drvdata = dev_get_drvdata(dev->parent);
 	unsigned long val;
 	int ret = 0;
 
 	ret = kstrtoul(buf, 16, &val);
 	if (ret)
 		return ret;
 
 	spin_lock(&drvdata->spinlock);
 	drvdata->stmsper = val;
 
 	if (local_read(&drvdata->mode)) {
 		CS_UNLOCK(drvdata->base);
 		writel_relaxed(drvdata->stmsper, drvdata->base + STMSPER);
 		CS_LOCK(drvdata->base);
 	}
 	spin_unlock(&drvdata->spinlock);
 
 	return size;
 }
 static DEVICE_ATTR_RW(port_enable);
 
 static ssize_t traceid_show(struct device *dev,
 			    struct device_attribute *attr, char *buf)
 {
 	unsigned long val;
 	struct stm_drvdata *drvdata = dev_get_drvdata(dev->parent);
 
 	val = drvdata->traceid;
 	return sprintf(buf, "%#lx\n", val);
 }
 
 static ssize_t traceid_store(struct device *dev,
 			     struct device_attribute *attr,
 			     const char *buf, size_t size)
 {
 	int ret;
 	unsigned long val;
 	struct stm_drvdata *drvdata = dev_get_drvdata(dev->parent);
 
 	ret = kstrtoul(buf, 16, &val);
 	if (ret)
 		return ret;
 
 	/* traceid field is 7bit wide on STM32 */
 	drvdata->traceid = val & 0x7f;
 	return size;
 }
 static DEVICE_ATTR_RW(traceid);
 
 #define coresight_stm_simple_func(name, offset)	\
 	coresight_simple_func(struct stm_drvdata, NULL, name, offset)
 
 coresight_stm_simple_func(tcsr, STMTCSR);
 coresight_stm_simple_func(tsfreqr, STMTSFREQR);
 coresight_stm_simple_func(syncr, STMSYNCR);
 coresight_stm_simple_func(sper, STMSPER);
 coresight_stm_simple_func(spter, STMSPTER);
 coresight_stm_simple_func(privmaskr, STMPRIVMASKR);
 coresight_stm_simple_func(spscr, STMSPSCR);
 coresight_stm_simple_func(spmscr, STMSPMSCR);
 coresight_stm_simple_func(spfeat1r, STMSPFEAT1R);
 coresight_stm_simple_func(spfeat2r, STMSPFEAT2R);
 coresight_stm_simple_func(spfeat3r, STMSPFEAT3R);
 coresight_stm_simple_func(devid, CORESIGHT_DEVID);
 
 static struct attribute *coresight_stm_attrs[] = {
 	&dev_attr_hwevent_enable.attr,
 	&dev_attr_hwevent_select.attr,
 	&dev_attr_port_enable.attr,
 	&dev_attr_port_select.attr,
 	&dev_attr_traceid.attr,
 	NULL,
 };
 
 static struct attribute *coresight_stm_mgmt_attrs[] = {
 	&dev_attr_tcsr.attr,
 	&dev_attr_tsfreqr.attr,
 	&dev_attr_syncr.attr,
 	&dev_attr_sper.attr,
 	&dev_attr_spter.attr,
 	&dev_attr_privmaskr.attr,
 	&dev_attr_spscr.attr,
 	&dev_attr_spmscr.attr,
 	&dev_attr_spfeat1r.attr,
 	&dev_attr_spfeat2r.attr,
 	&dev_attr_spfeat3r.attr,
 	&dev_attr_devid.attr,
 	NULL,
 };
 
 static const struct attribute_group coresight_stm_group = {
 	.attrs = coresight_stm_attrs,
 };
 
 static const struct attribute_group coresight_stm_mgmt_group = {
 	.attrs = coresight_stm_mgmt_attrs,
 	.name = "mgmt",
 };
 
 static const struct attribute_group *coresight_stm_groups[] = {
 	&coresight_stm_group,
 	&coresight_stm_mgmt_group,
 	NULL,
 };
 
 static int stm_get_resource_byname(struct device_node *np,
 				   char *ch_base, struct resource *res)
 {
 	const char *name = NULL;
 	int index = 0, found = 0;
 
 	while (!of_property_read_string_index(np, "reg-names", index, &name)) {
 		if (strcmp(ch_base, name)) {
 			index++;
 			continue;
 		}
 
 		/* We have a match and @index is where it's at */
 		found = 1;
 		break;
 	}
 
 	if (!found)
 		return -EINVAL;
 
 	return of_address_to_resource(np, index, res);
 }
 
 static u32 stm_fundamental_data_size(struct stm_drvdata *drvdata)
 {
 	u32 stmspfeat2r;
 
 	if (!IS_ENABLED(CONFIG_64BIT))
 		return 4;
 
 	stmspfeat2r = readl_relaxed(drvdata->base + STMSPFEAT2R);
 
 	/*
 	 * bit[15:12] represents the fundamental data size
 	 * 0 - 32-bit data
 	 * 1 - 64-bit data
 	 */
 	return BMVAL(stmspfeat2r, 12, 15) ? 8 : 4;
 }
 
 static u32 stm_num_stimulus_port(struct stm_drvdata *drvdata)
 {
 	u32 numsp;
 
 	numsp = readl_relaxed(drvdata->base + CORESIGHT_DEVID);
 	/*
 	 * NUMPS in STMDEVID is 17 bit long and if equal to 0x0,
 	 * 32 stimulus ports are supported.
 	 */
 	numsp &= 0x1ffff;
 	if (!numsp)
 		numsp = STM_32_CHANNEL;
 	return numsp;
 }
 
 static void stm_init_default_data(struct stm_drvdata *drvdata)
 {
 	/* Don't use port selection */
 	drvdata->stmspscr = 0x0;
 	/*
 	 * Enable all channel regardless of their number.  When port
 	 * selection isn't used (see above) STMSPER applies to all
 	 * 32 channel group available, hence setting all 32 bits to 1
 	 */
 	drvdata->stmsper = ~0x0;
 
 	/*
 	 * The trace ID value for *ETM* tracers start at CPU_ID * 2 + 0x10 and
 	 * anything equal to or higher than 0x70 is reserved.  Since 0x00 is
 	 * also reserved the STM trace ID needs to be higher than 0x00 and
 	 * lowner than 0x10.
 	 */
 	drvdata->traceid = 0x1;
 
 	/* Set invariant transaction timing on all channels */
 	bitmap_clear(drvdata->chs.guaranteed, 0, drvdata->numsp);
 }
 
 static void stm_init_generic_data(struct stm_drvdata *drvdata)
 {
 	drvdata->stm.name = dev_name(drvdata->dev);
 
 	/*
 	 * MasterIDs are assigned at HW design phase. As such the core is
 	 * using a single master for interaction with this device.
 	 */
 	drvdata->stm.sw_start = 1;
 	drvdata->stm.sw_end = 1;
 	drvdata->stm.hw_override = true;
 	drvdata->stm.sw_nchannels = drvdata->numsp;
 	drvdata->stm.sw_mmiosz = BYTES_PER_CHANNEL;
 	drvdata->stm.packet = stm_generic_packet;
 	drvdata->stm.mmio_addr = stm_mmio_addr;
 	drvdata->stm.link = stm_generic_link;
 	drvdata->stm.unlink = stm_generic_unlink;
 	drvdata->stm.set_options = stm_generic_set_options;
 }
 
 static int stm_probe(struct amba_device *adev, const struct amba_id *id)
 {
 	int ret;
 	void __iomem *base;
 	unsigned long *guaranteed;
 	struct device *dev = &adev->dev;
 	struct coresight_platform_data *pdata = NULL;
 	struct stm_drvdata *drvdata;
 	struct resource *res = &adev->res;
 	struct resource ch_res;
 	size_t res_size, bitmap_size;
 	struct coresight_desc desc = { 0 };
 	struct device_node *np = adev->dev.of_node;
 
 	if (np) {
 		pdata = of_get_coresight_platform_data(dev, np);
 		if (IS_ERR(pdata))
 			return PTR_ERR(pdata);
 		adev->dev.platform_data = pdata;
 	}
 	drvdata = devm_kzalloc(dev, sizeof(*drvdata), GFP_KERNEL);
 	if (!drvdata)
 		return -ENOMEM;
 
 	drvdata->dev = &adev->dev;
 	drvdata->atclk = devm_clk_get(&adev->dev, "atclk"); /* optional */
 	if (!IS_ERR(drvdata->atclk)) {
 		ret = clk_prepare_enable(drvdata->atclk);
 		if (ret)
 			return ret;
 	}
 	dev_set_drvdata(dev, drvdata);
 
 	base = devm_ioremap_resource(dev, res);
 	if (IS_ERR(base))
 		return PTR_ERR(base);
 	drvdata->base = base;
 
 	ret = stm_get_resource_byname(np, "stm-stimulus-base", &ch_res);
 	if (ret)
 		return ret;
 	drvdata->chs.phys = ch_res.start;
 
 	base = devm_ioremap_resource(dev, &ch_res);
 	if (IS_ERR(base))
 		return PTR_ERR(base);
 	drvdata->chs.base = base;
 
 	drvdata->write_bytes = stm_fundamental_data_size(drvdata);
 
 	if (boot_nr_channel) {
 		drvdata->numsp = boot_nr_channel;
 		res_size = min((resource_size_t)(boot_nr_channel *
 				  BYTES_PER_CHANNEL), resource_size(res));
 	} else {
 		drvdata->numsp = stm_num_stimulus_port(drvdata);
 		res_size = min((resource_size_t)(drvdata->numsp *
 				 BYTES_PER_CHANNEL), resource_size(res));
 	}
 	bitmap_size = BITS_TO_LONGS(drvdata->numsp) * sizeof(long);
 
 	guaranteed = devm_kzalloc(dev, bitmap_size, GFP_KERNEL);
 	if (!guaranteed)
 		return -ENOMEM;
 	drvdata->chs.guaranteed = guaranteed;
 
 	spin_lock_init(&drvdata->spinlock);
 
 	stm_init_default_data(drvdata);
 	stm_init_generic_data(drvdata);
 
 	if (stm_register_device(dev, &drvdata->stm, THIS_MODULE)) {
 		dev_info(dev,
 			 "stm_register_device failed, probing deffered\n");
 		return -EPROBE_DEFER;
 	}
 
 	desc.type = CORESIGHT_DEV_TYPE_SOURCE;
 	desc.subtype.source_subtype = CORESIGHT_DEV_SUBTYPE_SOURCE_SOFTWARE;
 	desc.ops = &stm_cs_ops;
 	desc.pdata = pdata;
 	desc.dev = dev;
 	desc.groups = coresight_stm_groups;
 	drvdata->csdev = coresight_register(&desc);
 	if (IS_ERR(drvdata->csdev)) {
 		ret = PTR_ERR(drvdata->csdev);
 		goto stm_unregister;
 	}
 
 	pm_runtime_put(&adev->dev);
 
 	dev_info(dev, "%s initialized\n", (char *)id->data);
 	return 0;
 
 stm_unregister:
 	stm_unregister_device(&drvdata->stm);
 	return ret;
 }
 
 #ifdef CONFIG_PM
 static int stm_runtime_suspend(struct device *dev)
 {
 	struct stm_drvdata *drvdata = dev_get_drvdata(dev);
 
 	if (drvdata && !IS_ERR(drvdata->atclk))
 		clk_disable_unprepare(drvdata->atclk);
 
 	return 0;
 }
 
 static int stm_runtime_resume(struct device *dev)
 {
 	struct stm_drvdata *drvdata = dev_get_drvdata(dev);
 
 	if (drvdata && !IS_ERR(drvdata->atclk))
 		clk_prepare_enable(drvdata->atclk);
 
 	return 0;
 }
 #endif
 
 static const struct dev_pm_ops stm_dev_pm_ops = {
 	SET_RUNTIME_PM_OPS(stm_runtime_suspend, stm_runtime_resume, NULL)
 };
 
 static struct amba_id stm_ids[] = {
 	{
 		.id     = 0x0003b962,
 		.mask   = 0x0003ffff,
 		.data	= "STM32",
 	},
 	{
 		.id	= 0x0003b963,
 		.mask	= 0x0003ffff,
 		.data	= "STM500",
 	},
 	{ 0, 0},
 };
 
 static struct amba_driver stm_driver = {
 	.drv = {
 		.name   = "coresight-stm",
 		.owner	= THIS_MODULE,
 		.pm	= &stm_dev_pm_ops,
 		.suppress_bind_attrs = true,
 	},
 	.probe          = stm_probe,
 	.id_table	= stm_ids,
 };
 
 builtin_amba_driver(stm_driver);
diff --git a/drivers/memory/ti-aemif.c b/drivers/memory/ti-aemif.c
index a579a0f25840..22c1aeeb6421 100644
--- a/drivers/memory/ti-aemif.c
+++ b/drivers/memory/ti-aemif.c
@@ -1,427 +1,433 @@
 /*
  * TI AEMIF driver
  *
  * Copyright (C) 2010 - 2013 Texas Instruments Incorporated. http://www.ti.com/
  *
  * Authors:
  * Murali Karicheri <m-karicheri2@ti.com>
  * Ivan Khoronzhuk <ivan.khoronzhuk@ti.com>
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License version 2 as
  * published by the Free Software Foundation.
  */
 
 #include <linux/clk.h>
 #include <linux/err.h>
 #include <linux/io.h>
 #include <linux/kernel.h>
 #include <linux/module.h>
 #include <linux/of.h>
 #include <linux/of_platform.h>
 #include <linux/platform_device.h>
+#include <linux/platform_data/ti-aemif.h>
 
 #define TA_SHIFT	2
 #define RHOLD_SHIFT	4
 #define RSTROBE_SHIFT	7
 #define RSETUP_SHIFT	13
 #define WHOLD_SHIFT	17
 #define WSTROBE_SHIFT	20
 #define WSETUP_SHIFT	26
 #define EW_SHIFT	30
 #define SS_SHIFT	31
 
 #define TA(x)		((x) << TA_SHIFT)
 #define RHOLD(x)	((x) << RHOLD_SHIFT)
 #define RSTROBE(x)	((x) << RSTROBE_SHIFT)
 #define RSETUP(x)	((x) << RSETUP_SHIFT)
 #define WHOLD(x)	((x) << WHOLD_SHIFT)
 #define WSTROBE(x)	((x) << WSTROBE_SHIFT)
 #define WSETUP(x)	((x) << WSETUP_SHIFT)
 #define EW(x)		((x) << EW_SHIFT)
 #define SS(x)		((x) << SS_SHIFT)
 
 #define ASIZE_MAX	0x1
 #define TA_MAX		0x3
 #define RHOLD_MAX	0x7
 #define RSTROBE_MAX	0x3f
 #define RSETUP_MAX	0xf
 #define WHOLD_MAX	0x7
 #define WSTROBE_MAX	0x3f
 #define WSETUP_MAX	0xf
 #define EW_MAX		0x1
 #define SS_MAX		0x1
 #define NUM_CS		4
 
 #define TA_VAL(x)	(((x) & TA(TA_MAX)) >> TA_SHIFT)
 #define RHOLD_VAL(x)	(((x) & RHOLD(RHOLD_MAX)) >> RHOLD_SHIFT)
 #define RSTROBE_VAL(x)	(((x) & RSTROBE(RSTROBE_MAX)) >> RSTROBE_SHIFT)
 #define RSETUP_VAL(x)	(((x) & RSETUP(RSETUP_MAX)) >> RSETUP_SHIFT)
 #define WHOLD_VAL(x)	(((x) & WHOLD(WHOLD_MAX)) >> WHOLD_SHIFT)
 #define WSTROBE_VAL(x)	(((x) & WSTROBE(WSTROBE_MAX)) >> WSTROBE_SHIFT)
 #define WSETUP_VAL(x)	(((x) & WSETUP(WSETUP_MAX)) >> WSETUP_SHIFT)
 #define EW_VAL(x)	(((x) & EW(EW_MAX)) >> EW_SHIFT)
 #define SS_VAL(x)	(((x) & SS(SS_MAX)) >> SS_SHIFT)
 
 #define NRCSR_OFFSET	0x00
 #define AWCCR_OFFSET	0x04
 #define A1CR_OFFSET	0x10
 
 #define ACR_ASIZE_MASK	0x3
 #define ACR_EW_MASK	BIT(30)
 #define ACR_SS_MASK	BIT(31)
 #define ASIZE_16BIT	1
 
 #define CONFIG_MASK	(TA(TA_MAX) | \
 				RHOLD(RHOLD_MAX) | \
 				RSTROBE(RSTROBE_MAX) |	\
 				RSETUP(RSETUP_MAX) | \
 				WHOLD(WHOLD_MAX) | \
 				WSTROBE(WSTROBE_MAX) | \
 				WSETUP(WSETUP_MAX) | \
 				EW(EW_MAX) | SS(SS_MAX) | \
 				ASIZE_MAX)
 
 /**
  * struct aemif_cs_data: structure to hold cs parameters
  * @cs: chip-select number
  * @wstrobe: write strobe width, ns
  * @rstrobe: read strobe width, ns
  * @wsetup: write setup width, ns
  * @whold: write hold width, ns
  * @rsetup: read setup width, ns
  * @rhold: read hold width, ns
  * @ta: minimum turn around time, ns
  * @enable_ss: enable/disable select strobe mode
  * @enable_ew: enable/disable extended wait mode
  * @asize: width of the asynchronous device's data bus
  */
 struct aemif_cs_data {
 	u8	cs;
 	u16	wstrobe;
 	u16	rstrobe;
 	u8	wsetup;
 	u8	whold;
 	u8	rsetup;
 	u8	rhold;
 	u8	ta;
 	u8	enable_ss;
 	u8	enable_ew;
 	u8	asize;
 };
 
 /**
  * struct aemif_device: structure to hold device data
  * @base: base address of AEMIF registers
  * @clk: source clock
  * @clk_rate: clock's rate in kHz
  * @num_cs: number of assigned chip-selects
  * @cs_offset: start number of cs nodes
  * @cs_data: array of chip-select settings
  */
 struct aemif_device {
 	void __iomem *base;
 	struct clk *clk;
 	unsigned long clk_rate;
 	u8 num_cs;
 	int cs_offset;
 	struct aemif_cs_data cs_data[NUM_CS];
 };
 
 /**
  * aemif_calc_rate - calculate timing data.
  * @pdev: platform device to calculate for
  * @wanted: The cycle time needed in nanoseconds.
  * @clk: The input clock rate in kHz.
  * @max: The maximum divider value that can be programmed.
  *
  * On success, returns the calculated timing value minus 1 for easy
  * programming into AEMIF timing registers, else negative errno.
  */
 static int aemif_calc_rate(struct platform_device *pdev, int wanted,
 			   unsigned long clk, int max)
 {
 	int result;
 
 	result = DIV_ROUND_UP((wanted * clk), NSEC_PER_MSEC) - 1;
 
 	dev_dbg(&pdev->dev, "%s: result %d from %ld, %d\n", __func__, result,
 		clk, wanted);
 
 	/* It is generally OK to have a more relaxed timing than requested... */
 	if (result < 0)
 		result = 0;
 
 	/* ... But configuring tighter timings is not an option. */
 	else if (result > max)
 		result = -EINVAL;
 
 	return result;
 }
 
 /**
  * aemif_config_abus - configure async bus parameters
  * @pdev: platform device to configure for
  * @csnum: aemif chip select number
  *
  * This function programs the given timing values (in real clock) into the
  * AEMIF registers taking the AEMIF clock into account.
  *
  * This function does not use any locking while programming the AEMIF
  * because it is expected that there is only one user of a given
  * chip-select.
  *
  * Returns 0 on success, else negative errno.
  */
 static int aemif_config_abus(struct platform_device *pdev, int csnum)
 {
 	struct aemif_device *aemif = platform_get_drvdata(pdev);
 	struct aemif_cs_data *data = &aemif->cs_data[csnum];
 	int ta, rhold, rstrobe, rsetup, whold, wstrobe, wsetup;
 	unsigned long clk_rate = aemif->clk_rate;
 	unsigned offset;
 	u32 set, val;
 
 	offset = A1CR_OFFSET + (data->cs - aemif->cs_offset) * 4;
 
 	ta	= aemif_calc_rate(pdev, data->ta, clk_rate, TA_MAX);
 	rhold	= aemif_calc_rate(pdev, data->rhold, clk_rate, RHOLD_MAX);
 	rstrobe	= aemif_calc_rate(pdev, data->rstrobe, clk_rate, RSTROBE_MAX);
 	rsetup	= aemif_calc_rate(pdev, data->rsetup, clk_rate, RSETUP_MAX);
 	whold	= aemif_calc_rate(pdev, data->whold, clk_rate, WHOLD_MAX);
 	wstrobe	= aemif_calc_rate(pdev, data->wstrobe, clk_rate, WSTROBE_MAX);
 	wsetup	= aemif_calc_rate(pdev, data->wsetup, clk_rate, WSETUP_MAX);
 
 	if (ta < 0 || rhold < 0 || rstrobe < 0 || rsetup < 0 ||
 	    whold < 0 || wstrobe < 0 || wsetup < 0) {
 		dev_err(&pdev->dev, "%s: cannot get suitable timings\n",
 			__func__);
 		return -EINVAL;
 	}
 
 	set = TA(ta) | RHOLD(rhold) | RSTROBE(rstrobe) | RSETUP(rsetup) |
 		WHOLD(whold) | WSTROBE(wstrobe) | WSETUP(wsetup);
 
 	set |= (data->asize & ACR_ASIZE_MASK);
 	if (data->enable_ew)
 		set |= ACR_EW_MASK;
 	if (data->enable_ss)
 		set |= ACR_SS_MASK;
 
 	val = readl(aemif->base + offset);
 	val &= ~CONFIG_MASK;
 	val |= set;
 	writel(val, aemif->base + offset);
 
 	return 0;
 }
 
 static inline int aemif_cycles_to_nsec(int val, unsigned long clk_rate)
 {
 	return ((val + 1) * NSEC_PER_MSEC) / clk_rate;
 }
 
 /**
  * aemif_get_hw_params - function to read hw register values
  * @pdev: platform device to read for
  * @csnum: aemif chip select number
  *
  * This function reads the defaults from the registers and update
  * the timing values. Required for get/set commands and also for
  * the case when driver needs to use defaults in hardware.
  */
 static void aemif_get_hw_params(struct platform_device *pdev, int csnum)
 {
 	struct aemif_device *aemif = platform_get_drvdata(pdev);
 	struct aemif_cs_data *data = &aemif->cs_data[csnum];
 	unsigned long clk_rate = aemif->clk_rate;
 	u32 val, offset;
 
 	offset = A1CR_OFFSET + (data->cs - aemif->cs_offset) * 4;
 	val = readl(aemif->base + offset);
 
 	data->ta = aemif_cycles_to_nsec(TA_VAL(val), clk_rate);
 	data->rhold = aemif_cycles_to_nsec(RHOLD_VAL(val), clk_rate);
 	data->rstrobe = aemif_cycles_to_nsec(RSTROBE_VAL(val), clk_rate);
 	data->rsetup = aemif_cycles_to_nsec(RSETUP_VAL(val), clk_rate);
 	data->whold = aemif_cycles_to_nsec(WHOLD_VAL(val), clk_rate);
 	data->wstrobe = aemif_cycles_to_nsec(WSTROBE_VAL(val), clk_rate);
 	data->wsetup = aemif_cycles_to_nsec(WSETUP_VAL(val), clk_rate);
 	data->enable_ew = EW_VAL(val);
 	data->enable_ss = SS_VAL(val);
 	data->asize = val & ASIZE_MAX;
 }
 
 /**
  * of_aemif_parse_abus_config - parse CS configuration from DT
  * @pdev: platform device to parse for
  * @np: device node ptr
  *
  * This function update the emif async bus configuration based on the values
  * configured in a cs device binding node.
  */
 static int of_aemif_parse_abus_config(struct platform_device *pdev,
 				      struct device_node *np)
 {
 	struct aemif_device *aemif = platform_get_drvdata(pdev);
 	struct aemif_cs_data *data;
 	u32 cs;
 	u32 val;
 
 	if (of_property_read_u32(np, "ti,cs-chipselect", &cs)) {
 		dev_dbg(&pdev->dev, "cs property is required");
 		return -EINVAL;
 	}
 
 	if (cs - aemif->cs_offset >= NUM_CS || cs < aemif->cs_offset) {
 		dev_dbg(&pdev->dev, "cs number is incorrect %d", cs);
 		return -EINVAL;
 	}
 
 	if (aemif->num_cs >= NUM_CS) {
 		dev_dbg(&pdev->dev, "cs count is more than %d", NUM_CS);
 		return -EINVAL;
 	}
 
 	data = &aemif->cs_data[aemif->num_cs];
 	data->cs = cs;
 
 	/* read the current value in the hw register */
 	aemif_get_hw_params(pdev, aemif->num_cs++);
 
 	/* override the values from device node */
 	if (!of_property_read_u32(np, "ti,cs-min-turnaround-ns", &val))
 		data->ta = val;
 
 	if (!of_property_read_u32(np, "ti,cs-read-hold-ns", &val))
 		data->rhold = val;
 
 	if (!of_property_read_u32(np, "ti,cs-read-strobe-ns", &val))
 		data->rstrobe = val;
 
 	if (!of_property_read_u32(np, "ti,cs-read-setup-ns", &val))
 		data->rsetup = val;
 
 	if (!of_property_read_u32(np, "ti,cs-write-hold-ns", &val))
 		data->whold = val;
 
 	if (!of_property_read_u32(np, "ti,cs-write-strobe-ns", &val))
 		data->wstrobe = val;
 
 	if (!of_property_read_u32(np, "ti,cs-write-setup-ns", &val))
 		data->wsetup = val;
 
 	if (!of_property_read_u32(np, "ti,cs-bus-width", &val))
 		if (val == 16)
 			data->asize = 1;
 	data->enable_ew = of_property_read_bool(np, "ti,cs-extended-wait-mode");
 	data->enable_ss = of_property_read_bool(np, "ti,cs-select-strobe-mode");
 	return 0;
 }
 
 static const struct of_device_id aemif_of_match[] = {
 	{ .compatible = "ti,davinci-aemif", },
 	{ .compatible = "ti,da850-aemif", },
 	{},
 };
 MODULE_DEVICE_TABLE(of, aemif_of_match);
 
 static int aemif_probe(struct platform_device *pdev)
 {
 	int i;
 	int ret = -ENODEV;
 	struct resource *res;
 	struct device *dev = &pdev->dev;
 	struct device_node *np = dev->of_node;
 	struct device_node *child_np;
 	struct aemif_device *aemif;
+	struct aemif_platform_data *pdata;
+	struct of_dev_auxdata *dev_lookup;
 
 	if (np == NULL)
 		return 0;
 
 	aemif = devm_kzalloc(dev, sizeof(*aemif), GFP_KERNEL);
 	if (!aemif)
 		return -ENOMEM;
 
+	pdata = dev_get_platdata(&pdev->dev);
+	dev_lookup = pdata ? pdata->dev_lookup : NULL;
+
 	platform_set_drvdata(pdev, aemif);
 
 	aemif->clk = devm_clk_get(dev, NULL);
 	if (IS_ERR(aemif->clk)) {
 		dev_err(dev, "cannot get clock 'aemif'\n");
 		return PTR_ERR(aemif->clk);
 	}
 
 	clk_prepare_enable(aemif->clk);
 	aemif->clk_rate = clk_get_rate(aemif->clk) / MSEC_PER_SEC;
 
 	if (of_device_is_compatible(np, "ti,da850-aemif"))
 		aemif->cs_offset = 2;
 
 	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
 	aemif->base = devm_ioremap_resource(dev, res);
 	if (IS_ERR(aemif->base)) {
 		ret = PTR_ERR(aemif->base);
 		goto error;
 	}
 
 	/*
 	 * For every controller device node, there is a cs device node that
 	 * describe the bus configuration parameters. This functions iterate
 	 * over these nodes and update the cs data array.
 	 */
 	for_each_available_child_of_node(np, child_np) {
 		ret = of_aemif_parse_abus_config(pdev, child_np);
 		if (ret < 0)
 			goto error;
 	}
 
 	for (i = 0; i < aemif->num_cs; i++) {
 		ret = aemif_config_abus(pdev, i);
 		if (ret < 0) {
 			dev_err(dev, "Error configuring chip select %d\n",
 				aemif->cs_data[i].cs);
 			goto error;
 		}
 	}
 
 	/*
 	 * Create a child devices explicitly from here to
 	 * guarantee that the child will be probed after the AEMIF timing
 	 * parameters are set.
 	 */
 	for_each_available_child_of_node(np, child_np) {
-		ret = of_platform_populate(child_np, NULL, NULL, dev);
+		ret = of_platform_populate(child_np, NULL, dev_lookup, dev);
 		if (ret < 0)
 			goto error;
 	}
 
 	return 0;
 error:
 	clk_disable_unprepare(aemif->clk);
 	return ret;
 }
 
 static int aemif_remove(struct platform_device *pdev)
 {
 	struct aemif_device *aemif = platform_get_drvdata(pdev);
 
 	clk_disable_unprepare(aemif->clk);
 	return 0;
 }
 
 static struct platform_driver aemif_driver = {
 	.probe = aemif_probe,
 	.remove = aemif_remove,
 	.driver = {
 		.name = KBUILD_MODNAME,
 		.of_match_table = of_match_ptr(aemif_of_match),
 	},
 };
 
 module_platform_driver(aemif_driver);
 
 MODULE_AUTHOR("Murali Karicheri <m-karicheri2@ti.com>");
 MODULE_AUTHOR("Ivan Khoronzhuk <ivan.khoronzhuk@ti.com>");
 MODULE_DESCRIPTION("Texas Instruments AEMIF driver");
 MODULE_LICENSE("GPL v2");
 MODULE_ALIAS("platform:" KBUILD_MODNAME);
diff --git a/drivers/misc/Kconfig b/drivers/misc/Kconfig
index 64971baf11fa..c290990d73ed 100644
--- a/drivers/misc/Kconfig
+++ b/drivers/misc/Kconfig
@@ -1,781 +1,786 @@
 #
 # Misc strange devices
 #
 
 menu "Misc devices"
 
 config SENSORS_LIS3LV02D
 	tristate
 	depends on INPUT
 	select INPUT_POLLDEV
 	default n
 
 config AD525X_DPOT
 	tristate "Analog Devices Digital Potentiometers"
 	depends on (I2C || SPI) && SYSFS
 	help
 	  If you say yes here, you get support for the Analog Devices
 	  AD5258, AD5259, AD5251, AD5252, AD5253, AD5254, AD5255
 	  AD5160, AD5161, AD5162, AD5165, AD5200, AD5201, AD5203,
 	  AD5204, AD5206, AD5207, AD5231, AD5232, AD5233, AD5235,
 	  AD5260, AD5262, AD5263, AD5290, AD5291, AD5292, AD5293,
 	  AD7376, AD8400, AD8402, AD8403, ADN2850, AD5241, AD5242,
 	  AD5243, AD5245, AD5246, AD5247, AD5248, AD5280, AD5282,
 	  ADN2860, AD5273, AD5171, AD5170, AD5172, AD5173, AD5270,
 	  AD5271, AD5272, AD5274
 	  digital potentiometer chips.
 
 	  See Documentation/misc-devices/ad525x_dpot.txt for the
 	  userspace interface.
 
 	  This driver can also be built as a module.  If so, the module
 	  will be called ad525x_dpot.
 
 config AD525X_DPOT_I2C
 	tristate "support I2C bus connection"
 	depends on AD525X_DPOT && I2C
 	help
 	  Say Y here if you have a digital potentiometers hooked to an I2C bus.
 
 	  To compile this driver as a module, choose M here: the
 	  module will be called ad525x_dpot-i2c.
 
 config AD525X_DPOT_SPI
 	tristate "support SPI bus connection"
 	depends on AD525X_DPOT && SPI_MASTER
 	help
 	  Say Y here if you have a digital potentiometers hooked to an SPI bus.
 
 	  If unsure, say N (but it's safe to say "Y").
 
 	  To compile this driver as a module, choose M here: the
 	  module will be called ad525x_dpot-spi.
 
 config ATMEL_TCLIB
 	bool "Atmel AT32/AT91 Timer/Counter Library"
 	depends on (AVR32 || ARCH_AT91)
 	help
 	  Select this if you want a library to allocate the Timer/Counter
 	  blocks found on many Atmel processors.  This facilitates using
 	  these blocks by different drivers despite processor differences.
 
 config ATMEL_TCB_CLKSRC
 	bool "TC Block Clocksource"
 	depends on ATMEL_TCLIB
 	default y
 	help
 	  Select this to get a high precision clocksource based on a
 	  TC block with a 5+ MHz base clock rate.  Two timer channels
 	  are combined to make a single 32-bit timer.
 
 	  When GENERIC_CLOCKEVENTS is defined, the third timer channel
 	  may be used as a clock event device supporting oneshot mode
 	  (delays of up to two seconds) based on the 32 KiHz clock.
 
 config ATMEL_TCB_CLKSRC_BLOCK
 	int
 	depends on ATMEL_TCB_CLKSRC
 	prompt "TC Block" if CPU_AT32AP700X
 	default 0
 	range 0 1
 	help
 	  Some chips provide more than one TC block, so you have the
 	  choice of which one to use for the clock framework.  The other
 	  TC can be used for other purposes, such as PWM generation and
 	  interval timing.
 
 config DUMMY_IRQ
 	tristate "Dummy IRQ handler"
 	default n
 	---help---
 	  This module accepts a single 'irq' parameter, which it should register for.
 	  The sole purpose of this module is to help with debugging of systems on
 	  which spurious IRQs would happen on disabled IRQ vector.
 
 config IBM_ASM
 	tristate "Device driver for IBM RSA service processor"
 	depends on X86 && PCI && INPUT
 	depends on SERIAL_8250 || SERIAL_8250=n
 	---help---
 	  This option enables device driver support for in-band access to the
 	  IBM RSA (Condor) service processor in eServer xSeries systems.
 	  The ibmasm device driver allows user space application to access
 	  ASM (Advanced Systems Management) functions on the service
 	  processor. The driver is meant to be used in conjunction with
 	  a user space API.
 	  The ibmasm driver also enables the OS to use the UART on the
 	  service processor board as a regular serial port. To make use of
 	  this feature serial driver support (CONFIG_SERIAL_8250) must be
 	  enabled.
 
 	  WARNING: This software may not be supported or function
 	  correctly on your IBM server. Please consult the IBM ServerProven
 	  website <http://www-03.ibm.com/systems/info/x86servers/serverproven/compat/us/>
 	  for information on the specific driver level and support statement
 	  for your IBM server.
 
 config PHANTOM
 	tristate "Sensable PHANToM (PCI)"
 	depends on PCI
 	help
 	  Say Y here if you want to build a driver for Sensable PHANToM device.
 
 	  This driver is only for PCI PHANToMs.
 
 	  If you choose to build module, its name will be phantom. If unsure,
 	  say N here.
 
 config INTEL_MID_PTI
 	tristate "Parallel Trace Interface for MIPI P1149.7 cJTAG standard"
 	depends on PCI && TTY && (X86_INTEL_MID || COMPILE_TEST)
 	default n
 	help
 	  The PTI (Parallel Trace Interface) driver directs
 	  trace data routed from various parts in the system out
 	  through an Intel Penwell PTI port and out of the mobile
 	  device for analysis with a debugging tool (Lauterbach or Fido).
 
 	  You should select this driver if the target kernel is meant for
 	  an Intel Atom (non-netbook) mobile device containing a MIPI
 	  P1149.7 standard implementation.
 
 config SGI_IOC4
 	tristate "SGI IOC4 Base IO support"
 	depends on PCI
 	---help---
 	  This option enables basic support for the IOC4 chip on certain
 	  SGI IO controller cards (IO9, IO10, and PCI-RT).  This option
 	  does not enable any specific functions on such a card, but provides
 	  necessary infrastructure for other drivers to utilize.
 
 	  If you have an SGI Altix with an IOC4-based card say Y.
 	  Otherwise say N.
 
 config TIFM_CORE
 	tristate "TI Flash Media interface support"
 	depends on PCI
 	help
 	  If you want support for Texas Instruments(R) Flash Media adapters
 	  you should select this option and then also choose an appropriate
 	  host adapter, such as 'TI Flash Media PCI74xx/PCI76xx host adapter
 	  support', if you have a TI PCI74xx compatible card reader, for
 	  example.
 	  You will also have to select some flash card format drivers. MMC/SD
 	  cards are supported via 'MMC/SD Card support: TI Flash Media MMC/SD
 	  Interface support (MMC_TIFM_SD)'.
 
 	  To compile this driver as a module, choose M here: the module will
 	  be called tifm_core.
 
 config TIFM_7XX1
 	tristate "TI Flash Media PCI74xx/PCI76xx host adapter support"
 	depends on PCI && TIFM_CORE
 	default TIFM_CORE
 	help
 	  This option enables support for Texas Instruments(R) PCI74xx and
 	  PCI76xx families of Flash Media adapters, found in many laptops.
 	  To make actual use of the device, you will have to select some
 	  flash card format drivers, as outlined in the TIFM_CORE Help.
 
 	  To compile this driver as a module, choose M here: the module will
 	  be called tifm_7xx1.
 
 config ICS932S401
 	tristate "Integrated Circuits ICS932S401"
 	depends on I2C
 	help
 	  If you say yes here you get support for the Integrated Circuits
 	  ICS932S401 clock control chips.
 
 	  This driver can also be built as a module. If so, the module
 	  will be called ics932s401.
 
 config ATMEL_SSC
 	tristate "Device driver for Atmel SSC peripheral"
 	depends on HAS_IOMEM && (AVR32 || ARCH_AT91 || COMPILE_TEST)
 	---help---
 	  This option enables device driver support for Atmel Synchronized
 	  Serial Communication peripheral (SSC).
 
 	  The SSC peripheral supports a wide variety of serial frame based
 	  communications, i.e. I2S, SPI, etc.
 
 	  If unsure, say N.
 
 config ENCLOSURE_SERVICES
 	tristate "Enclosure Services"
 	default n
 	help
 	  Provides support for intelligent enclosures (bays which
 	  contain storage devices).  You also need either a host
 	  driver (SCSI/ATA) which supports enclosures
 	  or a SCSI enclosure device (SES) to use these services.
 
 config SGI_XP
 	tristate "Support communication between SGI SSIs"
 	depends on NET
 	depends on (IA64_GENERIC || IA64_SGI_SN2 || IA64_SGI_UV || X86_UV) && SMP
 	select IA64_UNCACHED_ALLOCATOR if IA64_GENERIC || IA64_SGI_SN2
 	select GENERIC_ALLOCATOR if IA64_GENERIC || IA64_SGI_SN2
 	select SGI_GRU if X86_64 && SMP
 	---help---
 	  An SGI machine can be divided into multiple Single System
 	  Images which act independently of each other and have
 	  hardware based memory protection from the others.  Enabling
 	  this feature will allow for direct communication between SSIs
 	  based on a network adapter and DMA messaging.
 
 config CS5535_MFGPT
 	tristate "CS5535/CS5536 Geode Multi-Function General Purpose Timer (MFGPT) support"
 	depends on MFD_CS5535
 	default n
 	help
 	  This driver provides access to MFGPT functionality for other
 	  drivers that need timers.  MFGPTs are available in the CS5535 and
 	  CS5536 companion chips that are found in AMD Geode and several
 	  other platforms.  They have a better resolution and max interval
 	  than the generic PIT, and are suitable for use as high-res timers.
 	  You probably don't want to enable this manually; other drivers that
 	  make use of it should enable it.
 
 config CS5535_MFGPT_DEFAULT_IRQ
 	int
 	depends on CS5535_MFGPT
 	default 7
 	help
 	  MFGPTs on the CS5535 require an interrupt.  The selected IRQ
 	  can be overridden as a module option as well as by driver that
 	  use the cs5535_mfgpt_ API; however, different architectures might
 	  want to use a different IRQ by default.  This is here for
 	  architectures to set as necessary.
 
 config CS5535_CLOCK_EVENT_SRC
 	tristate "CS5535/CS5536 high-res timer (MFGPT) events"
 	depends on GENERIC_CLOCKEVENTS && CS5535_MFGPT
 	help
 	  This driver provides a clock event source based on the MFGPT
 	  timer(s) in the CS5535 and CS5536 companion chips.
 	  MFGPTs have a better resolution and max interval than the
 	  generic PIT, and are suitable for use as high-res timers.
 
 config HP_ILO
 	tristate "Channel interface driver for the HP iLO processor"
 	depends on PCI
 	default n
 	help
 	  The channel interface driver allows applications to communicate
 	  with iLO management processors present on HP ProLiant servers.
 	  Upon loading, the driver creates /dev/hpilo/dXccbN files, which
 	  can be used to gather data from the management processor, via
 	  read and write system calls.
 
 	  To compile this driver as a module, choose M here: the
 	  module will be called hpilo.
 
 config QCOM_COINCELL
 	tristate "Qualcomm coincell charger support"
 	depends on MFD_SPMI_PMIC || COMPILE_TEST
 	help
 	  This driver supports the coincell block found inside of
 	  Qualcomm PMICs.  The coincell charger provides a means to
 	  charge a coincell battery or backup capacitor which is used
 	  to maintain PMIC register and RTC state in the absence of
 	  external power.
 
 config SGI_GRU
 	tristate "SGI GRU driver"
 	depends on X86_UV && SMP
 	default n
 	select MMU_NOTIFIER
 	---help---
 	The GRU is a hardware resource located in the system chipset. The GRU
 	contains memory that can be mmapped into the user address space. This memory is
 	used to communicate with the GRU to perform functions such as load/store,
 	scatter/gather, bcopy, AMOs, etc.  The GRU is directly accessed by user
 	instructions using user virtual addresses. GRU instructions (ex., bcopy) use
 	user virtual addresses for operands.
 
 	If you are not running on a SGI UV system, say N.
 
 config SGI_GRU_DEBUG
 	bool  "SGI GRU driver debug"
 	depends on SGI_GRU
 	default n
 	---help---
 	This option enables additional debugging code for the SGI GRU driver.
 	If you are unsure, say N.
 
 config APDS9802ALS
 	tristate "Medfield Avago APDS9802 ALS Sensor module"
 	depends on I2C
 	help
 	  If you say yes here you get support for the ALS APDS9802 ambient
 	  light sensor.
 
 	  This driver can also be built as a module.  If so, the module
 	  will be called apds9802als.
 
 config ISL29003
 	tristate "Intersil ISL29003 ambient light sensor"
 	depends on I2C && SYSFS
 	help
 	  If you say yes here you get support for the Intersil ISL29003
 	  ambient light sensor.
 
 	  This driver can also be built as a module.  If so, the module
 	  will be called isl29003.
 
 config ISL29020
 	tristate "Intersil ISL29020 ambient light sensor"
 	depends on I2C
 	help
 	  If you say yes here you get support for the Intersil ISL29020
 	  ambient light sensor.
 
 	  This driver can also be built as a module.  If so, the module
 	  will be called isl29020.
 
 config SENSORS_TSL2550
 	tristate "Taos TSL2550 ambient light sensor"
 	depends on I2C && SYSFS
 	help
 	  If you say yes here you get support for the Taos TSL2550
 	  ambient light sensor.
 
 	  This driver can also be built as a module.  If so, the module
 	  will be called tsl2550.
 
 config SENSORS_BH1770
          tristate "BH1770GLC / SFH7770 combined ALS - Proximity sensor"
          depends on I2C
          ---help---
            Say Y here if you want to build a driver for BH1770GLC (ROHM) or
 	   SFH7770 (Osram) combined ambient light and proximity sensor chip.
 
            To compile this driver as a module, choose M here: the
            module will be called bh1770glc. If unsure, say N here.
 
 config SENSORS_APDS990X
 	 tristate "APDS990X combined als and proximity sensors"
 	 depends on I2C
 	 default n
 	 ---help---
 	   Say Y here if you want to build a driver for Avago APDS990x
 	   combined ambient light and proximity sensor chip.
 
 	   To compile this driver as a module, choose M here: the
 	   module will be called apds990x. If unsure, say N here.
 
 config HMC6352
 	tristate "Honeywell HMC6352 compass"
 	depends on I2C
 	help
 	  This driver provides support for the Honeywell HMC6352 compass,
 	  providing configuration and heading data via sysfs.
 
 config DS1682
 	tristate "Dallas DS1682 Total Elapsed Time Recorder with Alarm"
 	depends on I2C
 	help
 	  If you say yes here you get support for Dallas Semiconductor
 	  DS1682 Total Elapsed Time Recorder.
 
 	  This driver can also be built as a module.  If so, the module
 	  will be called ds1682.
 
 config SPEAR13XX_PCIE_GADGET
 	bool "PCIe gadget support for SPEAr13XX platform"
 	depends on ARCH_SPEAR13XX && BROKEN
 	default n
 	help
 	 This option enables gadget support for PCIe controller. If
 	 board file defines any controller as PCIe endpoint then a sysfs
 	 entry will be created for that controller. User can use these
 	 sysfs node to configure PCIe EP as per his requirements.
 
 config TI_DAC7512
 	tristate "Texas Instruments DAC7512"
 	depends on SPI && SYSFS
 	help
 	  If you say yes here you get support for the Texas Instruments
 	  DAC7512 16-bit digital-to-analog converter.
 
 	  This driver can also be built as a module. If so, the module
 	  will be called ti_dac7512.
 
 config VMWARE_BALLOON
 	tristate "VMware Balloon Driver"
 	depends on VMWARE_VMCI && X86 && HYPERVISOR_GUEST
 	help
 	  This is VMware physical memory management driver which acts
 	  like a "balloon" that can be inflated to reclaim physical pages
 	  by reserving them in the guest and invalidating them in the
 	  monitor, freeing up the underlying machine pages so they can
 	  be allocated to other guests. The balloon can also be deflated
 	  to allow the guest to use more physical memory.
 
 	  If unsure, say N.
 
 	  To compile this driver as a module, choose M here: the
 	  module will be called vmw_balloon.
 
 config ARM_CHARLCD
 	bool "ARM Ltd. Character LCD Driver"
 	depends on PLAT_VERSATILE
 	help
 	  This is a driver for the character LCD found on the ARM Ltd.
 	  Versatile and RealView Platform Baseboards. It doesn't do
 	  very much more than display the text "ARM Linux" on the first
 	  line and the Linux version on the second line, but that's
 	  still useful.
 
 config PCH_PHUB
 	tristate "Intel EG20T PCH/LAPIS Semicon IOH(ML7213/ML7223/ML7831) PHUB"
 	select GENERIC_NET_UTILS
 	depends on PCI && (X86_32 || MIPS || COMPILE_TEST)
 	help
 	  This driver is for PCH(Platform controller Hub) PHUB(Packet Hub) of
 	  Intel Topcliff which is an IOH(Input/Output Hub) for x86 embedded
 	  processor. The Topcliff has MAC address and Option ROM data in SROM.
 	  This driver can access MAC address and Option ROM data in SROM.
 
 	  This driver also can be used for LAPIS Semiconductor's IOH,
 	  ML7213/ML7223/ML7831.
 	  ML7213 which is for IVI(In-Vehicle Infotainment) use.
 	  ML7223 IOH is for MP(Media Phone) use.
 	  ML7831 IOH is for general purpose use.
 	  ML7213/ML7223/ML7831 is companion chip for Intel Atom E6xx series.
 	  ML7213/ML7223/ML7831 is completely compatible for Intel EG20T PCH.
 
 	  To compile this driver as a module, choose M here: the module will
 	  be called pch_phub.
 
 config USB_SWITCH_FSA9480
 	tristate "FSA9480 USB Switch"
 	depends on I2C
 	help
 	  The FSA9480 is a USB port accessory detector and switch.
 	  The FSA9480 is fully controlled using I2C and enables USB data,
 	  stereo and mono audio, video, microphone and UART data to use
 	  a common connector port.
 
 config LATTICE_ECP3_CONFIG
 	tristate "Lattice ECP3 FPGA bitstream configuration via SPI"
 	depends on SPI && SYSFS
 	select FW_LOADER
 	default	n
 	help
 	  This option enables support for bitstream configuration (programming
 	  or loading) of the Lattice ECP3 FPGA family via SPI.
 
 	  If unsure, say N.
 
 config SRAM
 	bool "Generic on-chip SRAM driver"
 	depends on HAS_IOMEM
 	select GENERIC_ALLOCATOR
+	select SRAM_EXEC if ARM
 	help
 	  This driver allows you to declare a memory region to be managed by
 	  the genalloc API. It is supposed to be used for small on-chip SRAM
 	  areas found on many SoCs.
 
+config SRAM_EXEC
+	bool
+
 config VEXPRESS_SYSCFG
 	bool "Versatile Express System Configuration driver"
 	depends on VEXPRESS_CONFIG
 	default y
 	help
 	  ARM Ltd. Versatile Express uses specialised platform configuration
 	  bus. System Configuration interface is one of the possible means
 	  of generating transactions on this bus.
+
 config PANEL
 	tristate "Parallel port LCD/Keypad Panel support"
 	depends on PARPORT
 	---help---
 	  Say Y here if you have an HD44780 or KS-0074 LCD connected to your
 	  parallel port. This driver also features 4 and 6-key keypads. The LCD
 	  is accessible through the /dev/lcd char device (10, 156), and the
-	  keypad through /dev/keypad (10, 185). Both require misc device to be
-	  enabled. This code can either be compiled as a module, or linked into
-	  the kernel and started at boot. If you don't understand what all this
-	  is about, say N.
+	  keypad through /dev/keypad (10, 185). This code can either be
+	  compiled as a module, or linked into the kernel and started at boot.
+	  If you don't understand what all this is about, say N.
+
+if PANEL
 
 config PANEL_PARPORT
 	int "Default parallel port number (0=LPT1)"
-	depends on PANEL
 	range 0 255
 	default "0"
 	---help---
 	  This is the index of the parallel port the panel is connected to. One
 	  driver instance only supports one parallel port, so if your keypad
 	  and LCD are connected to two separate ports, you have to start two
 	  modules with different arguments. Numbering starts with '0' for LPT1,
 	  and so on.
 
 config PANEL_PROFILE
 	int "Default panel profile (0-5, 0=custom)"
-	depends on PANEL
 	range 0 5
 	default "5"
 	---help---
 	  To ease configuration, the driver supports different configuration
 	  profiles for past and recent wirings. These profiles can also be
 	  used to define an approximative configuration, completed by a few
 	  other options. Here are the profiles :
 
 	    0 = custom (see further)
 	    1 = 2x16 parallel LCD, old keypad
 	    2 = 2x16 serial LCD (KS-0074), new keypad
 	    3 = 2x16 parallel LCD (Hantronix), no keypad
 	    4 = 2x16 parallel LCD (Nexcom NSA1045) with Nexcom's keypad
 	    5 = 2x40 parallel LCD (old one), with old keypad
 
 	  Custom configurations allow you to define how your display is
 	  wired to the parallel port, and how it works. This is only intended
 	  for experts.
 
 config PANEL_KEYPAD
-	depends on PANEL && PANEL_PROFILE="0"
+	depends on PANEL_PROFILE="0"
 	int "Keypad type (0=none, 1=old 6 keys, 2=new 6 keys, 3=Nexcom 4 keys)"
 	range 0 3
 	default 0
 	---help---
 	  This enables and configures a keypad connected to the parallel port.
 	  The keys will be read from character device 10,185. Valid values are :
 
 	    0 : do not enable this driver
 	    1 : old 6 keys keypad
 	    2 : new 6 keys keypad, as used on the server at www.ant-computing.com
 	    3 : Nexcom NSA1045's 4 keys keypad
 
 	  New profiles can be described in the driver source. The driver also
 	  supports simultaneous keys pressed when the keypad supports them.
 
 config PANEL_LCD
-	depends on PANEL && PANEL_PROFILE="0"
+	depends on PANEL_PROFILE="0"
 	int "LCD type (0=none, 1=custom, 2=old //, 3=ks0074, 4=hantronix, 5=Nexcom)"
 	range 0 5
 	default 0
 	---help---
 	   This enables and configures an LCD connected to the parallel port.
 	   The driver includes an interpreter for escape codes starting with
 	   '\e[L' which are specific to the LCD, and a few ANSI codes. The
 	   driver will be registered as character device 10,156, usually
 	   under the name '/dev/lcd'. There are a total of 6 supported types :
 
 	     0 : do not enable the driver
 	     1 : custom configuration and wiring (see further)
 	     2 : 2x16 & 2x40 parallel LCD (old wiring)
 	     3 : 2x16 serial LCD (KS-0074 based)
 	     4 : 2x16 parallel LCD (Hantronix wiring)
 	     5 : 2x16 parallel LCD (Nexcom wiring)
 
 	   When type '1' is specified, other options will appear to configure
 	   more precise aspects (wiring, dimensions, protocol, ...). Please note
 	   that those values changed from the 2.4 driver for better consistency.
 
 config PANEL_LCD_HEIGHT
-	depends on PANEL && PANEL_PROFILE="0" && PANEL_LCD="1"
+	depends on PANEL_PROFILE="0" && PANEL_LCD="1"
 	int "Number of lines on the LCD (1-2)"
 	range 1 2
 	default 2
 	---help---
 	  This is the number of visible character lines on the LCD in custom profile.
 	  It can either be 1 or 2.
 
 config PANEL_LCD_WIDTH
-	depends on PANEL && PANEL_PROFILE="0" && PANEL_LCD="1"
+	depends on PANEL_PROFILE="0" && PANEL_LCD="1"
 	int "Number of characters per line on the LCD (1-40)"
 	range 1 40
 	default 40
 	---help---
 	  This is the number of characters per line on the LCD in custom profile.
 	  Common values are 16,20,24,40.
 
 config PANEL_LCD_BWIDTH
-	depends on PANEL && PANEL_PROFILE="0" && PANEL_LCD="1"
+	depends on PANEL_PROFILE="0" && PANEL_LCD="1"
 	int "Internal LCD line width (1-40, 40 by default)"
 	range 1 40
 	default 40
 	---help---
 	  Most LCDs use a standard controller which supports hardware lines of 40
 	  characters, although sometimes only 16, 20 or 24 of them are really wired
 	  to the terminal. This results in some non-visible but addressable characters,
 	  and is the case for most parallel LCDs. Other LCDs, and some serial ones,
 	  however, use the same line width internally as what is visible. The KS0074
 	  for example, uses 16 characters per line for 16 visible characters per line.
 
 	  This option lets you configure the value used by your LCD in 'custom' profile.
 	  If you don't know, put '40' here.
 
 config PANEL_LCD_HWIDTH
-	depends on PANEL && PANEL_PROFILE="0" && PANEL_LCD="1"
+	depends on PANEL_PROFILE="0" && PANEL_LCD="1"
 	int "Hardware LCD line width (1-64, 64 by default)"
 	range 1 64
 	default 64
 	---help---
 	  Most LCDs use a single address bit to differentiate line 0 and line 1. Since
 	  some of them need to be able to address 40 chars with the lower bits, they
 	  often use the immediately superior power of 2, which is 64, to address the
 	  next line.
 
 	  If you don't know what your LCD uses, in doubt let 16 here for a 2x16, and
 	  64 here for a 2x40.
 
 config PANEL_LCD_CHARSET
-	depends on PANEL && PANEL_PROFILE="0" && PANEL_LCD="1"
+	depends on PANEL_PROFILE="0" && PANEL_LCD="1"
 	int "LCD character set (0=normal, 1=KS0074)"
 	range 0 1
 	default 0
 	---help---
 	  Some controllers such as the KS0074 use a somewhat strange character set
 	  where many symbols are at unusual places. The driver knows how to map
 	  'standard' ASCII characters to the character sets used by these controllers.
 	  Valid values are :
 
 	     0 : normal (untranslated) character set
 	     1 : KS0074 character set
 
 	  If you don't know, use the normal one (0).
 
 config PANEL_LCD_PROTO
-	depends on PANEL && PANEL_PROFILE="0" && PANEL_LCD="1"
+	depends on PANEL_PROFILE="0" && PANEL_LCD="1"
 	int "LCD communication mode (0=parallel 8 bits, 1=serial)"
 	range 0 1
 	default 0
 	---help---
 	  This driver now supports any serial or parallel LCD wired to a parallel
 	  port. But before assigning signals, the driver needs to know if it will
 	  be driving a serial LCD or a parallel one. Serial LCDs only use 2 wires
 	  (SDA/SCL), while parallel ones use 2 or 3 wires for the control signals
 	  (E, RS, sometimes RW), and 4 or 8 for the data. Use 0 here for a 8 bits
 	  parallel LCD, and 1 for a serial LCD.
 
 config PANEL_LCD_PIN_E
-	depends on PANEL && PANEL_PROFILE="0" && PANEL_LCD="1" && PANEL_LCD_PROTO="0"
+	depends on PANEL_PROFILE="0" && PANEL_LCD="1" && PANEL_LCD_PROTO="0"
         int "Parallel port pin number & polarity connected to the LCD E signal (-17...17) "
 	range -17 17
 	default 14
 	---help---
 	  This describes the number of the parallel port pin to which the LCD 'E'
 	  signal has been connected. It can be :
 
 	          0 : no connection (eg: connected to ground)
 	      1..17 : directly connected to any of these pins on the DB25 plug
 	    -1..-17 : connected to the same pin through an inverter (eg: transistor).
 
 	  Default for the 'E' pin in custom profile is '14' (AUTOFEED).
 
 config PANEL_LCD_PIN_RS
-	depends on PANEL && PANEL_PROFILE="0" && PANEL_LCD="1" && PANEL_LCD_PROTO="0"
+	depends on PANEL_PROFILE="0" && PANEL_LCD="1" && PANEL_LCD_PROTO="0"
         int "Parallel port pin number & polarity connected to the LCD RS signal (-17...17) "
 	range -17 17
 	default 17
 	---help---
 	  This describes the number of the parallel port pin to which the LCD 'RS'
 	  signal has been connected. It can be :
 
 	          0 : no connection (eg: connected to ground)
 	      1..17 : directly connected to any of these pins on the DB25 plug
 	    -1..-17 : connected to the same pin through an inverter (eg: transistor).
 
 	  Default for the 'RS' pin in custom profile is '17' (SELECT IN).
 
 config PANEL_LCD_PIN_RW
-	depends on PANEL && PANEL_PROFILE="0" && PANEL_LCD="1" && PANEL_LCD_PROTO="0"
+	depends on PANEL_PROFILE="0" && PANEL_LCD="1" && PANEL_LCD_PROTO="0"
         int "Parallel port pin number & polarity connected to the LCD RW signal (-17...17) "
 	range -17 17
 	default 16
 	---help---
 	  This describes the number of the parallel port pin to which the LCD 'RW'
 	  signal has been connected. It can be :
 
 	          0 : no connection (eg: connected to ground)
 	      1..17 : directly connected to any of these pins on the DB25 plug
 	    -1..-17 : connected to the same pin through an inverter (eg: transistor).
 
 	  Default for the 'RW' pin in custom profile is '16' (INIT).
 
 config PANEL_LCD_PIN_SCL
-	depends on PANEL && PANEL_PROFILE="0" && PANEL_LCD="1" && PANEL_LCD_PROTO!="0"
+	depends on PANEL_PROFILE="0" && PANEL_LCD="1" && PANEL_LCD_PROTO!="0"
         int "Parallel port pin number & polarity connected to the LCD SCL signal (-17...17) "
 	range -17 17
 	default 1
 	---help---
 	  This describes the number of the parallel port pin to which the serial
 	  LCD 'SCL' signal has been connected. It can be :
 
 	          0 : no connection (eg: connected to ground)
 	      1..17 : directly connected to any of these pins on the DB25 plug
 	    -1..-17 : connected to the same pin through an inverter (eg: transistor).
 
 	  Default for the 'SCL' pin in custom profile is '1' (STROBE).
 
 config PANEL_LCD_PIN_SDA
-	depends on PANEL && PANEL_PROFILE="0" && PANEL_LCD="1" && PANEL_LCD_PROTO!="0"
+	depends on PANEL_PROFILE="0" && PANEL_LCD="1" && PANEL_LCD_PROTO!="0"
         int "Parallel port pin number & polarity connected to the LCD SDA signal (-17...17) "
 	range -17 17
 	default 2
 	---help---
 	  This describes the number of the parallel port pin to which the serial
 	  LCD 'SDA' signal has been connected. It can be :
 
 	          0 : no connection (eg: connected to ground)
 	      1..17 : directly connected to any of these pins on the DB25 plug
 	    -1..-17 : connected to the same pin through an inverter (eg: transistor).
 
 	  Default for the 'SDA' pin in custom profile is '2' (D0).
 
 config PANEL_LCD_PIN_BL
-	depends on PANEL && PANEL_PROFILE="0" && PANEL_LCD="1"
+	depends on PANEL_PROFILE="0" && PANEL_LCD="1"
         int "Parallel port pin number & polarity connected to the LCD backlight signal (-17...17) "
 	range -17 17
 	default 0
 	---help---
 	  This describes the number of the parallel port pin to which the LCD 'BL' signal
           has been connected. It can be :
 
 	          0 : no connection (eg: connected to ground)
 	      1..17 : directly connected to any of these pins on the DB25 plug
 	    -1..-17 : connected to the same pin through an inverter (eg: transistor).
 
 	  Default for the 'BL' pin in custom profile is '0' (uncontrolled).
 
 config PANEL_CHANGE_MESSAGE
-	depends on PANEL
 	bool "Change LCD initialization message ?"
 	default "n"
 	---help---
 	  This allows you to replace the boot message indicating the kernel version
 	  and the driver version with a custom message. This is useful on appliances
 	  where a simple 'Starting system' message can be enough to stop a customer
 	  from worrying.
 
 	  If you say 'Y' here, you'll be able to choose a message yourself. Otherwise,
 	  say 'N' and keep the default message with the version.
 
 config PANEL_BOOT_MESSAGE
-	depends on PANEL && PANEL_CHANGE_MESSAGE="y"
+	depends on PANEL_CHANGE_MESSAGE="y"
 	string "New initialization message"
 	default ""
 	---help---
 	  This allows you to replace the boot message indicating the kernel version
 	  and the driver version with a custom message. This is useful on appliances
 	  where a simple 'Starting system' message can be enough to stop a customer
 	  from worrying.
 
 	  An empty message will only clear the display at driver init time. Any other
 	  printf()-formatted message is valid with newline and escape codes.
 
+endif # PANEL
+
 source "drivers/misc/c2port/Kconfig"
 source "drivers/misc/eeprom/Kconfig"
 source "drivers/misc/cb710/Kconfig"
 source "drivers/misc/ti-st/Kconfig"
 source "drivers/misc/lis3lv02d/Kconfig"
 source "drivers/misc/altera-stapl/Kconfig"
 source "drivers/misc/mei/Kconfig"
 source "drivers/misc/vmw_vmci/Kconfig"
 source "drivers/misc/mic/Kconfig"
 source "drivers/misc/genwqe/Kconfig"
 source "drivers/misc/echo/Kconfig"
 source "drivers/misc/cxl/Kconfig"
 endmenu
diff --git a/drivers/misc/Makefile b/drivers/misc/Makefile
index 31983366090a..7a3ea89339b4 100644
--- a/drivers/misc/Makefile
+++ b/drivers/misc/Makefile
@@ -1,70 +1,71 @@
 #
 # Makefile for misc devices that really don't fit anywhere else.
 #
 
 obj-$(CONFIG_IBM_ASM)		+= ibmasm/
 obj-$(CONFIG_AD525X_DPOT)	+= ad525x_dpot.o
 obj-$(CONFIG_AD525X_DPOT_I2C)	+= ad525x_dpot-i2c.o
 obj-$(CONFIG_AD525X_DPOT_SPI)	+= ad525x_dpot-spi.o
 obj-$(CONFIG_INTEL_MID_PTI)	+= pti.o
 obj-$(CONFIG_ATMEL_SSC)		+= atmel-ssc.o
 obj-$(CONFIG_ATMEL_TCLIB)	+= atmel_tclib.o
 obj-$(CONFIG_DUMMY_IRQ)		+= dummy-irq.o
 obj-$(CONFIG_ICS932S401)	+= ics932s401.o
 obj-$(CONFIG_LKDTM)		+= lkdtm.o
 obj-$(CONFIG_TIFM_CORE)       	+= tifm_core.o
 obj-$(CONFIG_TIFM_7XX1)       	+= tifm_7xx1.o
 obj-$(CONFIG_PHANTOM)		+= phantom.o
 obj-$(CONFIG_QCOM_COINCELL)	+= qcom-coincell.o
 obj-$(CONFIG_SENSORS_BH1770)	+= bh1770glc.o
 obj-$(CONFIG_SENSORS_APDS990X)	+= apds990x.o
 obj-$(CONFIG_SGI_IOC4)		+= ioc4.o
 obj-$(CONFIG_ENCLOSURE_SERVICES) += enclosure.o
 obj-$(CONFIG_KGDB_TESTS)	+= kgdbts.o
 obj-$(CONFIG_SGI_XP)		+= sgi-xp/
 obj-$(CONFIG_SGI_GRU)		+= sgi-gru/
 obj-$(CONFIG_CS5535_MFGPT)	+= cs5535-mfgpt.o
 obj-$(CONFIG_HP_ILO)		+= hpilo.o
 obj-$(CONFIG_APDS9802ALS)	+= apds9802als.o
 obj-$(CONFIG_ISL29003)		+= isl29003.o
 obj-$(CONFIG_ISL29020)		+= isl29020.o
 obj-$(CONFIG_SENSORS_TSL2550)	+= tsl2550.o
 obj-$(CONFIG_DS1682)		+= ds1682.o
 obj-$(CONFIG_TI_DAC7512)	+= ti_dac7512.o
 obj-$(CONFIG_C2PORT)		+= c2port/
 obj-$(CONFIG_HMC6352)		+= hmc6352.o
 obj-y				+= eeprom/
 obj-y				+= cb710/
 obj-$(CONFIG_SPEAR13XX_PCIE_GADGET)	+= spear13xx_pcie_gadget.o
 obj-$(CONFIG_VMWARE_BALLOON)	+= vmw_balloon.o
 obj-$(CONFIG_ARM_CHARLCD)	+= arm-charlcd.o
 obj-$(CONFIG_PCH_PHUB)		+= pch_phub.o
 obj-y				+= ti-st/
 obj-y				+= lis3lv02d/
 obj-$(CONFIG_USB_SWITCH_FSA9480) += fsa9480.o
 obj-$(CONFIG_ALTERA_STAPL)	+=altera-stapl/
 obj-$(CONFIG_INTEL_MEI)		+= mei/
 obj-$(CONFIG_VMWARE_VMCI)	+= vmw_vmci/
 obj-$(CONFIG_LATTICE_ECP3_CONFIG)	+= lattice-ecp3-config.o
 obj-$(CONFIG_SRAM)		+= sram.o
+obj-$(CONFIG_SRAM_EXEC)		+= sram-exec.o
 obj-y				+= mic/
 obj-$(CONFIG_GENWQE)		+= genwqe/
 obj-$(CONFIG_ECHO)		+= echo/
 obj-$(CONFIG_VEXPRESS_SYSCFG)	+= vexpress-syscfg.o
 obj-$(CONFIG_CXL_BASE)		+= cxl/
 obj-$(CONFIG_PANEL)             += panel.o
 
 lkdtm-$(CONFIG_LKDTM)		+= lkdtm_core.o
 lkdtm-$(CONFIG_LKDTM)		+= lkdtm_bugs.o
 lkdtm-$(CONFIG_LKDTM)		+= lkdtm_heap.o
 lkdtm-$(CONFIG_LKDTM)		+= lkdtm_perms.o
 lkdtm-$(CONFIG_LKDTM)		+= lkdtm_rodata_objcopy.o
 lkdtm-$(CONFIG_LKDTM)		+= lkdtm_usercopy.o
 
 OBJCOPYFLAGS :=
 OBJCOPYFLAGS_lkdtm_rodata_objcopy.o := \
 			--set-section-flags .text=alloc,readonly \
 			--rename-section .text=.rodata
 targets += lkdtm_rodata.o lkdtm_rodata_objcopy.o
 $(obj)/lkdtm_rodata_objcopy.o: $(obj)/lkdtm_rodata.o FORCE
 	$(call if_changed,objcopy)
diff --git a/drivers/misc/eeprom/Kconfig b/drivers/misc/eeprom/Kconfig
index c4e41c26649e..de58762097c4 100644
--- a/drivers/misc/eeprom/Kconfig
+++ b/drivers/misc/eeprom/Kconfig
@@ -1,103 +1,113 @@
 menu "EEPROM support"
 
 config EEPROM_AT24
 	tristate "I2C EEPROMs / RAMs / ROMs from most vendors"
 	depends on I2C && SYSFS
 	select NVMEM
 	help
 	  Enable this driver to get read/write support to most I2C EEPROMs
 	  and compatible devices like FRAMs, SRAMs, ROMs etc. After you
 	  configure the driver to know about each chip on your target
 	  board.  Use these generic chip names, instead of vendor-specific
 	  ones like at24c64, 24lc02 or fm24c04:
 
 	     24c00, 24c01, 24c02, spd (readonly 24c02), 24c04, 24c08,
 	     24c16, 24c32, 24c64, 24c128, 24c256, 24c512, 24c1024
 
 	  Unless you like data loss puzzles, always be sure that any chip
 	  you configure as a 24c32 (32 kbit) or larger is NOT really a
 	  24c16 (16 kbit) or smaller, and vice versa. Marking the chip
 	  as read-only won't help recover from this. Also, if your chip
 	  has any software write-protect mechanism you may want to review the
 	  code to make sure this driver won't turn it on by accident.
 
 	  If you use this with an SMBus adapter instead of an I2C adapter,
 	  full functionality is not available.  Only smaller devices are
 	  supported (24c16 and below, max 4 kByte).
 
 	  This driver can also be built as a module.  If so, the module
 	  will be called at24.
 
 config EEPROM_AT25
 	tristate "SPI EEPROMs from most vendors"
 	depends on SPI && SYSFS
 	select NVMEM
 	help
 	  Enable this driver to get read/write support to most SPI EEPROMs,
 	  after you configure the board init code to know about each eeprom
 	  on your target board.
 
 	  This driver can also be built as a module.  If so, the module
 	  will be called at25.
 
 config EEPROM_LEGACY
 	tristate "Old I2C EEPROM reader"
 	depends on I2C && SYSFS
 	help
 	  If you say yes here you get read-only access to the EEPROM data
 	  available on modern memory DIMMs and Sony Vaio laptops via I2C. Such
 	  EEPROMs could theoretically be available on other devices as well.
 
 	  This driver can also be built as a module.  If so, the module
 	  will be called eeprom.
 
 config EEPROM_MAX6875
 	tristate "Maxim MAX6874/5 power supply supervisor"
 	depends on I2C
 	help
 	  If you say yes here you get read-only support for the user EEPROM of
 	  the Maxim MAX6874/5 EEPROM-programmable, quad power-supply
 	  sequencer/supervisor.
 
 	  All other features of this chip should be accessed via i2c-dev.
 
 	  This driver can also be built as a module.  If so, the module
 	  will be called max6875.
 
 
 config EEPROM_93CX6
 	tristate "EEPROM 93CX6 support"
 	help
 	  This is a driver for the EEPROM chipsets 93c46 and 93c66.
 	  The driver supports both read as well as write commands.
 
 	  If unsure, say N.
 
 config EEPROM_93XX46
 	tristate "Microwire EEPROM 93XX46 support"
 	depends on SPI && SYSFS
 	select REGMAP
 	select NVMEM
 	help
 	  Driver for the microwire EEPROM chipsets 93xx46x. The driver
 	  supports both read and write commands and also the command to
 	  erase the whole EEPROM.
 
 	  This driver can also be built as a module.  If so, the module
 	  will be called eeprom_93xx46.
 
 	  If unsure, say N.
 
 config EEPROM_DIGSY_MTC_CFG
 	bool "DigsyMTC display configuration EEPROMs device"
 	depends on GPIO_MPC5200 && SPI_GPIO
 	help
 	  This option enables access to display configuration EEPROMs
 	  on digsy_mtc board. You have to additionally select Microwire
 	  EEPROM 93XX46 driver. sysfs entries will be created for that
 	  EEPROM allowing to read/write the configuration data or to
 	  erase the whole EEPROM.
 
 	  If unsure, say N.
 
+config EEPROM_IDT_89HPESX
+	tristate "IDT 89HPESx PCIe-swtiches EEPROM / CSR support"
+	depends on I2C && SYSFS
+	help
+	  Enable this driver to get read/write access to EEPROM / CSRs
+	  over IDT PCIe-swtich i2c-slave interface.
+
+	  This driver can also be built as a module. If so, the module
+	  will be called idt_89hpesx.
+
 endmenu
diff --git a/drivers/misc/eeprom/Makefile b/drivers/misc/eeprom/Makefile
index fc1e81d29267..90a52624ddeb 100644
--- a/drivers/misc/eeprom/Makefile
+++ b/drivers/misc/eeprom/Makefile
@@ -1,7 +1,8 @@
 obj-$(CONFIG_EEPROM_AT24)	+= at24.o
 obj-$(CONFIG_EEPROM_AT25)	+= at25.o
 obj-$(CONFIG_EEPROM_LEGACY)	+= eeprom.o
 obj-$(CONFIG_EEPROM_MAX6875)	+= max6875.o
 obj-$(CONFIG_EEPROM_93CX6)	+= eeprom_93cx6.o
 obj-$(CONFIG_EEPROM_93XX46)	+= eeprom_93xx46.o
 obj-$(CONFIG_EEPROM_DIGSY_MTC_CFG) += digsy_mtc_eeprom.o
+obj-$(CONFIG_EEPROM_IDT_89HPESX) += idt_89hpesx.o
diff --git a/drivers/misc/eeprom/idt_89hpesx.c b/drivers/misc/eeprom/idt_89hpesx.c
new file mode 100644
index 000000000000..4a22a1d99395
--- /dev/null
+++ b/drivers/misc/eeprom/idt_89hpesx.c
@@ -0,0 +1,1581 @@
+/*
+ *   This file is provided under a GPLv2 license.  When using or
+ *   redistributing this file, you may do so under that license.
+ *
+ *   GPL LICENSE SUMMARY
+ *
+ *   Copyright (C) 2016 T-Platforms. All Rights Reserved.
+ *
+ *   This program is free software; you can redistribute it and/or modify it
+ *   under the terms and conditions of the GNU General Public License,
+ *   version 2, as published by the Free Software Foundation.
+ *
+ *   This program is distributed in the hope that it will be useful, but WITHOUT
+ *   ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ *   FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for
+ *   more details.
+ *
+ *   You should have received a copy of the GNU General Public License along
+ *   with this program; if not, it can be found <http://www.gnu.org/licenses/>.
+ *
+ *   The full GNU General Public License is included in this distribution in
+ *   the file called "COPYING".
+ *
+ *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * IDT PCIe-switch NTB Linux driver
+ *
+ * Contact Information:
+ * Serge Semin <fancer.lancer@gmail.com>, <Sergey.Semin@t-platforms.ru>
+ */
+/*
+ *           NOTE of the IDT 89HPESx SMBus-slave interface driver
+ *    This driver primarily is developed to have an access to EEPROM device of
+ * IDT PCIe-switches. IDT provides a simple SMBus interface to perform IO-
+ * operations from/to EEPROM, which is located at private (so called Master)
+ * SMBus of switches. Using that interface this the driver creates a simple
+ * binary sysfs-file in the device directory:
+ * /sys/bus/i2c/devices/<bus>-<devaddr>/eeprom
+ * In case if read-only flag is specified in the dts-node of device desription,
+ * User-space applications won't be able to write to the EEPROM sysfs-node.
+ *    Additionally IDT 89HPESx SMBus interface has an ability to write/read
+ * data of device CSRs. This driver exposes debugf-file to perform simple IO
+ * operations using that ability for just basic debug purpose. Particularly
+ * next file is created in the specific debugfs-directory:
+ * /sys/kernel/debug/idt_csr/
+ * Format of the debugfs-node is:
+ * $ cat /sys/kernel/debug/idt_csr/<bus>-<devaddr>/<devname>;
+ * <CSR address>:<CSR value>
+ * So reading the content of the file gives current CSR address and it value.
+ * If User-space application wishes to change current CSR address,
+ * it can just write a proper value to the sysfs-file:
+ * $ echo "<CSR address>" > /sys/kernel/debug/idt_csr/<bus>-<devaddr>/<devname>
+ * If it wants to change the CSR value as well, the format of the write
+ * operation is:
+ * $ echo "<CSR address>:<CSR value>" > \
+ *        /sys/kernel/debug/idt_csr/<bus>-<devaddr>/<devname>;
+ * CSR address and value can be any of hexadecimal, decimal or octal format.
+ */
+
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/types.h>
+#include <linux/sizes.h>
+#include <linux/slab.h>
+#include <linux/mutex.h>
+#include <linux/sysfs.h>
+#include <linux/debugfs.h>
+#include <linux/mod_devicetable.h>
+#include <linux/of.h>
+#include <linux/i2c.h>
+#include <linux/pci_ids.h>
+#include <linux/delay.h>
+
+#define IDT_NAME		"89hpesx"
+#define IDT_89HPESX_DESC	"IDT 89HPESx SMBus-slave interface driver"
+#define IDT_89HPESX_VER		"1.0"
+
+MODULE_DESCRIPTION(IDT_89HPESX_DESC);
+MODULE_VERSION(IDT_89HPESX_VER);
+MODULE_LICENSE("GPL v2");
+MODULE_AUTHOR("T-platforms");
+
+/*
+ * csr_dbgdir - CSR read/write operations Debugfs directory
+ */
+static struct dentry *csr_dbgdir;
+
+/*
+ * struct idt_89hpesx_dev - IDT 89HPESx device data structure
+ * @eesize:	Size of EEPROM in bytes (calculated from "idt,eecompatible")
+ * @eero:	EEPROM Read-only flag
+ * @eeaddr:	EEPROM custom address
+ *
+ * @inieecmd:	Initial cmd value for EEPROM read/write operations
+ * @inicsrcmd:	Initial cmd value for CSR read/write operations
+ * @iniccode:	Initialial command code value for IO-operations
+ *
+ * @csr:	CSR address to perform read operation
+ *
+ * @smb_write:	SMBus write method
+ * @smb_read:	SMBus read method
+ * @smb_mtx:	SMBus mutex
+ *
+ * @client:	i2c client used to perform IO operations
+ *
+ * @ee_file:	EEPROM read/write sysfs-file
+ * @csr_file:	CSR read/write debugfs-node
+ */
+struct idt_smb_seq;
+struct idt_89hpesx_dev {
+	u32 eesize;
+	bool eero;
+	u8 eeaddr;
+
+	u8 inieecmd;
+	u8 inicsrcmd;
+	u8 iniccode;
+
+	u16 csr;
+
+	int (*smb_write)(struct idt_89hpesx_dev *, const struct idt_smb_seq *);
+	int (*smb_read)(struct idt_89hpesx_dev *, struct idt_smb_seq *);
+	struct mutex smb_mtx;
+
+	struct i2c_client *client;
+
+	struct bin_attribute *ee_file;
+	struct dentry *csr_dir;
+	struct dentry *csr_file;
+};
+
+/*
+ * struct idt_smb_seq - sequence of data to be read/written from/to IDT 89HPESx
+ * @ccode:	SMBus command code
+ * @bytecnt:	Byte count of operation
+ * @data:	Data to by written
+ */
+struct idt_smb_seq {
+	u8 ccode;
+	u8 bytecnt;
+	u8 *data;
+};
+
+/*
+ * struct idt_eeprom_seq - sequence of data to be read/written from/to EEPROM
+ * @cmd:	Transaction CMD
+ * @eeaddr:	EEPROM custom address
+ * @memaddr:	Internal memory address of EEPROM
+ * @data:	Data to be written at the memory address
+ */
+struct idt_eeprom_seq {
+	u8 cmd;
+	u8 eeaddr;
+	u16 memaddr;
+	u8 data;
+} __packed;
+
+/*
+ * struct idt_csr_seq - sequence of data to be read/written from/to CSR
+ * @cmd:	Transaction CMD
+ * @csraddr:	Internal IDT device CSR address
+ * @data:	Data to be read/written from/to the CSR address
+ */
+struct idt_csr_seq {
+	u8 cmd;
+	u16 csraddr;
+	u32 data;
+} __packed;
+
+/*
+ * SMBus command code macros
+ * @CCODE_END:		Indicates the end of transaction
+ * @CCODE_START:	Indicates the start of transaction
+ * @CCODE_CSR:		CSR read/write transaction
+ * @CCODE_EEPROM:	EEPROM read/write transaction
+ * @CCODE_BYTE:		Supplied data has BYTE length
+ * @CCODE_WORD:		Supplied data has WORD length
+ * @CCODE_BLOCK:	Supplied data has variable length passed in bytecnt
+ *			byte right following CCODE byte
+ */
+#define CCODE_END	((u8)0x01)
+#define CCODE_START	((u8)0x02)
+#define CCODE_CSR	((u8)0x00)
+#define CCODE_EEPROM	((u8)0x04)
+#define CCODE_BYTE	((u8)0x00)
+#define CCODE_WORD	((u8)0x20)
+#define CCODE_BLOCK	((u8)0x40)
+#define CCODE_PEC	((u8)0x80)
+
+/*
+ * EEPROM command macros
+ * @EEPROM_OP_WRITE:	EEPROM write operation
+ * @EEPROM_OP_READ:	EEPROM read operation
+ * @EEPROM_USA:		Use specified address of EEPROM
+ * @EEPROM_NAERR:	EEPROM device is not ready to respond
+ * @EEPROM_LAERR:	EEPROM arbitration loss error
+ * @EEPROM_MSS:		EEPROM misplace start & stop bits error
+ * @EEPROM_WR_CNT:	Bytes count to perform write operation
+ * @EEPROM_WRRD_CNT:	Bytes count to write before reading
+ * @EEPROM_RD_CNT:	Bytes count to perform read operation
+ * @EEPROM_DEF_SIZE:	Fall back size of EEPROM
+ * @EEPROM_DEF_ADDR:	Defatul EEPROM address
+ * @EEPROM_TOUT:	Timeout before retry read operation if eeprom is busy
+ */
+#define EEPROM_OP_WRITE	((u8)0x00)
+#define EEPROM_OP_READ	((u8)0x01)
+#define EEPROM_USA	((u8)0x02)
+#define EEPROM_NAERR	((u8)0x08)
+#define EEPROM_LAERR    ((u8)0x10)
+#define EEPROM_MSS	((u8)0x20)
+#define EEPROM_WR_CNT	((u8)5)
+#define EEPROM_WRRD_CNT	((u8)4)
+#define EEPROM_RD_CNT	((u8)5)
+#define EEPROM_DEF_SIZE	((u16)4096)
+#define EEPROM_DEF_ADDR	((u8)0x50)
+#define EEPROM_TOUT	(100)
+
+/*
+ * CSR command macros
+ * @CSR_DWE:		Enable all four bytes of the operation
+ * @CSR_OP_WRITE:	CSR write operation
+ * @CSR_OP_READ:	CSR read operation
+ * @CSR_RERR:		Read operation error
+ * @CSR_WERR:		Write operation error
+ * @CSR_WR_CNT:		Bytes count to perform write operation
+ * @CSR_WRRD_CNT:	Bytes count to write before reading
+ * @CSR_RD_CNT:		Bytes count to perform read operation
+ * @CSR_MAX:		Maximum CSR address
+ * @CSR_DEF:		Default CSR address
+ * @CSR_REAL_ADDR:	CSR real unshifted address
+ */
+#define CSR_DWE			((u8)0x0F)
+#define CSR_OP_WRITE		((u8)0x00)
+#define CSR_OP_READ		((u8)0x10)
+#define CSR_RERR		((u8)0x40)
+#define CSR_WERR		((u8)0x80)
+#define CSR_WR_CNT		((u8)7)
+#define CSR_WRRD_CNT		((u8)3)
+#define CSR_RD_CNT		((u8)7)
+#define CSR_MAX			((u32)0x3FFFF)
+#define CSR_DEF			((u16)0x0000)
+#define CSR_REAL_ADDR(val)	((unsigned int)val << 2)
+
+/*
+ * IDT 89HPESx basic register
+ * @IDT_VIDDID_CSR:	PCIe VID and DID of IDT 89HPESx
+ * @IDT_VID_MASK:	Mask of VID
+ */
+#define IDT_VIDDID_CSR	((u32)0x0000)
+#define IDT_VID_MASK	((u32)0xFFFF)
+
+/*
+ * IDT 89HPESx can send NACK when new command is sent before previous one
+ * fininshed execution. In this case driver retries operation
+ * certain times.
+ * @RETRY_CNT:		Number of retries before giving up and fail
+ * @idt_smb_safe:	Generate a retry loop on corresponding SMBus method
+ */
+#define RETRY_CNT (128)
+#define idt_smb_safe(ops, args...) ({ \
+	int __retry = RETRY_CNT; \
+	s32 __sts; \
+	do { \
+		__sts = i2c_smbus_ ## ops ## _data(args); \
+	} while (__retry-- && __sts < 0); \
+	__sts; \
+})
+
+/*===========================================================================
+ *                         i2c bus level IO-operations
+ *===========================================================================
+ */
+
+/*
+ * idt_smb_write_byte() - SMBus write method when I2C_SMBUS_BYTE_DATA operation
+ *                        is only available
+ * @pdev:	Pointer to the driver data
+ * @seq:	Sequence of data to be written
+ */
+static int idt_smb_write_byte(struct idt_89hpesx_dev *pdev,
+			      const struct idt_smb_seq *seq)
+{
+	s32 sts;
+	u8 ccode;
+	int idx;
+
+	/* Loop over the supplied data sending byte one-by-one */
+	for (idx = 0; idx < seq->bytecnt; idx++) {
+		/* Collect the command code byte */
+		ccode = seq->ccode | CCODE_BYTE;
+		if (idx == 0)
+			ccode |= CCODE_START;
+		if (idx == seq->bytecnt - 1)
+			ccode |= CCODE_END;
+
+		/* Send data to the device */
+		sts = idt_smb_safe(write_byte, pdev->client, ccode,
+			seq->data[idx]);
+		if (sts != 0)
+			return (int)sts;
+	}
+
+	return 0;
+}
+
+/*
+ * idt_smb_read_byte() - SMBus read method when I2C_SMBUS_BYTE_DATA operation
+ *                        is only available
+ * @pdev:	Pointer to the driver data
+ * @seq:	Buffer to read data to
+ */
+static int idt_smb_read_byte(struct idt_89hpesx_dev *pdev,
+			     struct idt_smb_seq *seq)
+{
+	s32 sts;
+	u8 ccode;
+	int idx;
+
+	/* Loop over the supplied buffer receiving byte one-by-one */
+	for (idx = 0; idx < seq->bytecnt; idx++) {
+		/* Collect the command code byte */
+		ccode = seq->ccode | CCODE_BYTE;
+		if (idx == 0)
+			ccode |= CCODE_START;
+		if (idx == seq->bytecnt - 1)
+			ccode |= CCODE_END;
+
+		/* Read data from the device */
+		sts = idt_smb_safe(read_byte, pdev->client, ccode);
+		if (sts < 0)
+			return (int)sts;
+
+		seq->data[idx] = (u8)sts;
+	}
+
+	return 0;
+}
+
+/*
+ * idt_smb_write_word() - SMBus write method when I2C_SMBUS_BYTE_DATA and
+ *                        I2C_FUNC_SMBUS_WORD_DATA operations are available
+ * @pdev:	Pointer to the driver data
+ * @seq:	Sequence of data to be written
+ */
+static int idt_smb_write_word(struct idt_89hpesx_dev *pdev,
+			      const struct idt_smb_seq *seq)
+{
+	s32 sts;
+	u8 ccode;
+	int idx, evencnt;
+
+	/* Calculate the even count of data to send */
+	evencnt = seq->bytecnt - (seq->bytecnt % 2);
+
+	/* Loop over the supplied data sending two bytes at a time */
+	for (idx = 0; idx < evencnt; idx += 2) {
+		/* Collect the command code byte */
+		ccode = seq->ccode | CCODE_WORD;
+		if (idx == 0)
+			ccode |= CCODE_START;
+		if (idx == evencnt - 2)
+			ccode |= CCODE_END;
+
+		/* Send word data to the device */
+		sts = idt_smb_safe(write_word, pdev->client, ccode,
+			*(u16 *)&seq->data[idx]);
+		if (sts != 0)
+			return (int)sts;
+	}
+
+	/* If there is odd number of bytes then send just one last byte */
+	if (seq->bytecnt != evencnt) {
+		/* Collect the command code byte */
+		ccode = seq->ccode | CCODE_BYTE | CCODE_END;
+		if (idx == 0)
+			ccode |= CCODE_START;
+
+		/* Send byte data to the device */
+		sts = idt_smb_safe(write_byte, pdev->client, ccode,
+			seq->data[idx]);
+		if (sts != 0)
+			return (int)sts;
+	}
+
+	return 0;
+}
+
+/*
+ * idt_smb_read_word() - SMBus read method when I2C_SMBUS_BYTE_DATA and
+ *                       I2C_FUNC_SMBUS_WORD_DATA operations are available
+ * @pdev:	Pointer to the driver data
+ * @seq:	Buffer to read data to
+ */
+static int idt_smb_read_word(struct idt_89hpesx_dev *pdev,
+			     struct idt_smb_seq *seq)
+{
+	s32 sts;
+	u8 ccode;
+	int idx, evencnt;
+
+	/* Calculate the even count of data to send */
+	evencnt = seq->bytecnt - (seq->bytecnt % 2);
+
+	/* Loop over the supplied data reading two bytes at a time */
+	for (idx = 0; idx < evencnt; idx += 2) {
+		/* Collect the command code byte */
+		ccode = seq->ccode | CCODE_WORD;
+		if (idx == 0)
+			ccode |= CCODE_START;
+		if (idx == evencnt - 2)
+			ccode |= CCODE_END;
+
+		/* Read word data from the device */
+		sts = idt_smb_safe(read_word, pdev->client, ccode);
+		if (sts < 0)
+			return (int)sts;
+
+		*(u16 *)&seq->data[idx] = (u16)sts;
+	}
+
+	/* If there is odd number of bytes then receive just one last byte */
+	if (seq->bytecnt != evencnt) {
+		/* Collect the command code byte */
+		ccode = seq->ccode | CCODE_BYTE | CCODE_END;
+		if (idx == 0)
+			ccode |= CCODE_START;
+
+		/* Read last data byte from the device */
+		sts = idt_smb_safe(read_byte, pdev->client, ccode);
+		if (sts < 0)
+			return (int)sts;
+
+		seq->data[idx] = (u8)sts;
+	}
+
+	return 0;
+}
+
+/*
+ * idt_smb_write_block() - SMBus write method when I2C_SMBUS_BLOCK_DATA
+ *                         operation is available
+ * @pdev:	Pointer to the driver data
+ * @seq:	Sequence of data to be written
+ */
+static int idt_smb_write_block(struct idt_89hpesx_dev *pdev,
+			       const struct idt_smb_seq *seq)
+{
+	u8 ccode;
+
+	/* Return error if too much data passed to send */
+	if (seq->bytecnt > I2C_SMBUS_BLOCK_MAX)
+		return -EINVAL;
+
+	/* Collect the command code byte */
+	ccode = seq->ccode | CCODE_BLOCK | CCODE_START | CCODE_END;
+
+	/* Send block of data to the device */
+	return idt_smb_safe(write_block, pdev->client, ccode, seq->bytecnt,
+		seq->data);
+}
+
+/*
+ * idt_smb_read_block() - SMBus read method when I2C_SMBUS_BLOCK_DATA
+ *                        operation is available
+ * @pdev:	Pointer to the driver data
+ * @seq:	Buffer to read data to
+ */
+static int idt_smb_read_block(struct idt_89hpesx_dev *pdev,
+			      struct idt_smb_seq *seq)
+{
+	s32 sts;
+	u8 ccode;
+
+	/* Return error if too much data passed to send */
+	if (seq->bytecnt > I2C_SMBUS_BLOCK_MAX)
+		return -EINVAL;
+
+	/* Collect the command code byte */
+	ccode = seq->ccode | CCODE_BLOCK | CCODE_START | CCODE_END;
+
+	/* Read block of data from the device */
+	sts = idt_smb_safe(read_block, pdev->client, ccode, seq->data);
+	if (sts != seq->bytecnt)
+		return (sts < 0 ? sts : -ENODATA);
+
+	return 0;
+}
+
+/*
+ * idt_smb_write_i2c_block() - SMBus write method when I2C_SMBUS_I2C_BLOCK_DATA
+ *                             operation is available
+ * @pdev:	Pointer to the driver data
+ * @seq:	Sequence of data to be written
+ *
+ * NOTE It's usual SMBus write block operation, except the actual data length is
+ * sent as first byte of data
+ */
+static int idt_smb_write_i2c_block(struct idt_89hpesx_dev *pdev,
+				   const struct idt_smb_seq *seq)
+{
+	u8 ccode, buf[I2C_SMBUS_BLOCK_MAX + 1];
+
+	/* Return error if too much data passed to send */
+	if (seq->bytecnt > I2C_SMBUS_BLOCK_MAX)
+		return -EINVAL;
+
+	/* Collect the data to send. Length byte must be added prior the data */
+	buf[0] = seq->bytecnt;
+	memcpy(&buf[1], seq->data, seq->bytecnt);
+
+	/* Collect the command code byte */
+	ccode = seq->ccode | CCODE_BLOCK | CCODE_START | CCODE_END;
+
+	/* Send length and block of data to the device */
+	return idt_smb_safe(write_i2c_block, pdev->client, ccode,
+		seq->bytecnt + 1, buf);
+}
+
+/*
+ * idt_smb_read_i2c_block() - SMBus read method when I2C_SMBUS_I2C_BLOCK_DATA
+ *                            operation is available
+ * @pdev:	Pointer to the driver data
+ * @seq:	Buffer to read data to
+ *
+ * NOTE It's usual SMBus read block operation, except the actual data length is
+ * retrieved as first byte of data
+ */
+static int idt_smb_read_i2c_block(struct idt_89hpesx_dev *pdev,
+				  struct idt_smb_seq *seq)
+{
+	u8 ccode, buf[I2C_SMBUS_BLOCK_MAX + 1];
+	s32 sts;
+
+	/* Return error if too much data passed to send */
+	if (seq->bytecnt > I2C_SMBUS_BLOCK_MAX)
+		return -EINVAL;
+
+	/* Collect the command code byte */
+	ccode = seq->ccode | CCODE_BLOCK | CCODE_START | CCODE_END;
+
+	/* Read length and block of data from the device */
+	sts = idt_smb_safe(read_i2c_block, pdev->client, ccode,
+		seq->bytecnt + 1, buf);
+	if (sts != seq->bytecnt + 1)
+		return (sts < 0 ? sts : -ENODATA);
+	if (buf[0] != seq->bytecnt)
+		return -ENODATA;
+
+	/* Copy retrieved data to the output data buffer */
+	memcpy(seq->data, &buf[1], seq->bytecnt);
+
+	return 0;
+}
+
+/*===========================================================================
+ *                          EEPROM IO-operations
+ *===========================================================================
+ */
+
+/*
+ * idt_eeprom_read_byte() - read just one byte from EEPROM
+ * @pdev:	Pointer to the driver data
+ * @memaddr:	Start EEPROM memory address
+ * @data:	Data to be written to EEPROM
+ */
+static int idt_eeprom_read_byte(struct idt_89hpesx_dev *pdev, u16 memaddr,
+				u8 *data)
+{
+	struct device *dev = &pdev->client->dev;
+	struct idt_eeprom_seq eeseq;
+	struct idt_smb_seq smbseq;
+	int ret, retry;
+
+	/* Initialize SMBus sequence fields */
+	smbseq.ccode = pdev->iniccode | CCODE_EEPROM;
+	smbseq.data = (u8 *)&eeseq;
+
+	/*
+	 * Sometimes EEPROM may respond with NACK if it's busy with previous
+	 * operation, so we need to perform a few attempts of read cycle
+	 */
+	retry = RETRY_CNT;
+	do {
+		/* Send EEPROM memory address to read data from */
+		smbseq.bytecnt = EEPROM_WRRD_CNT;
+		eeseq.cmd = pdev->inieecmd | EEPROM_OP_READ;
+		eeseq.eeaddr = pdev->eeaddr;
+		eeseq.memaddr = cpu_to_le16(memaddr);
+		ret = pdev->smb_write(pdev, &smbseq);
+		if (ret != 0) {
+			dev_err(dev, "Failed to init eeprom addr 0x%02hhx",
+				memaddr);
+			break;
+		}
+
+		/* Perform read operation */
+		smbseq.bytecnt = EEPROM_RD_CNT;
+		ret = pdev->smb_read(pdev, &smbseq);
+		if (ret != 0) {
+			dev_err(dev, "Failed to read eeprom data 0x%02hhx",
+				memaddr);
+			break;
+		}
+
+		/* Restart read operation if the device is busy */
+		if (retry && (eeseq.cmd & EEPROM_NAERR)) {
+			dev_dbg(dev, "EEPROM busy, retry reading after %d ms",
+				EEPROM_TOUT);
+			msleep(EEPROM_TOUT);
+			continue;
+		}
+
+		/* Check whether IDT successfully read data from EEPROM */
+		if (eeseq.cmd & (EEPROM_NAERR | EEPROM_LAERR | EEPROM_MSS)) {
+			dev_err(dev,
+				"Communication with eeprom failed, cmd 0x%hhx",
+				eeseq.cmd);
+			ret = -EREMOTEIO;
+			break;
+		}
+
+		/* Save retrieved data and exit the loop */
+		*data = eeseq.data;
+		break;
+	} while (retry--);
+
+	/* Return the status of operation */
+	return ret;
+}
+
+/*
+ * idt_eeprom_write() - EEPROM write operation
+ * @pdev:	Pointer to the driver data
+ * @memaddr:	Start EEPROM memory address
+ * @len:	Length of data to be written
+ * @data:	Data to be written to EEPROM
+ */
+static int idt_eeprom_write(struct idt_89hpesx_dev *pdev, u16 memaddr, u16 len,
+			    const u8 *data)
+{
+	struct device *dev = &pdev->client->dev;
+	struct idt_eeprom_seq eeseq;
+	struct idt_smb_seq smbseq;
+	int ret;
+	u16 idx;
+
+	/* Initialize SMBus sequence fields */
+	smbseq.ccode = pdev->iniccode | CCODE_EEPROM;
+	smbseq.data = (u8 *)&eeseq;
+
+	/* Send data byte-by-byte, checking if it is successfully written */
+	for (idx = 0; idx < len; idx++, memaddr++) {
+		/* Lock IDT SMBus device */
+		mutex_lock(&pdev->smb_mtx);
+
+		/* Perform write operation */
+		smbseq.bytecnt = EEPROM_WR_CNT;
+		eeseq.cmd = pdev->inieecmd | EEPROM_OP_WRITE;
+		eeseq.eeaddr = pdev->eeaddr;
+		eeseq.memaddr = cpu_to_le16(memaddr);
+		eeseq.data = data[idx];
+		ret = pdev->smb_write(pdev, &smbseq);
+		if (ret != 0) {
+			dev_err(dev,
+				"Failed to write 0x%04hx:0x%02hhx to eeprom",
+				memaddr, data[idx]);
+			goto err_mutex_unlock;
+		}
+
+		/*
+		 * Check whether the data is successfully written by reading
+		 * from the same EEPROM memory address.
+		 */
+		eeseq.data = ~data[idx];
+		ret = idt_eeprom_read_byte(pdev, memaddr, &eeseq.data);
+		if (ret != 0)
+			goto err_mutex_unlock;
+
+		/* Check whether the read byte is the same as written one */
+		if (eeseq.data != data[idx]) {
+			dev_err(dev, "Values don't match 0x%02hhx != 0x%02hhx",
+				eeseq.data, data[idx]);
+			ret = -EREMOTEIO;
+			goto err_mutex_unlock;
+		}
+
+		/* Unlock IDT SMBus device */
+err_mutex_unlock:
+		mutex_unlock(&pdev->smb_mtx);
+		if (ret != 0)
+			return ret;
+	}
+
+	return 0;
+}
+
+/*
+ * idt_eeprom_read() - EEPROM read operation
+ * @pdev:	Pointer to the driver data
+ * @memaddr:	Start EEPROM memory address
+ * @len:	Length of data to read
+ * @buf:	Buffer to read data to
+ */
+static int idt_eeprom_read(struct idt_89hpesx_dev *pdev, u16 memaddr, u16 len,
+			   u8 *buf)
+{
+	int ret;
+	u16 idx;
+
+	/* Read data byte-by-byte, retrying if it wasn't successful */
+	for (idx = 0; idx < len; idx++, memaddr++) {
+		/* Lock IDT SMBus device */
+		mutex_lock(&pdev->smb_mtx);
+
+		/* Just read the byte to the buffer */
+		ret = idt_eeprom_read_byte(pdev, memaddr, &buf[idx]);
+
+		/* Unlock IDT SMBus device */
+		mutex_unlock(&pdev->smb_mtx);
+
+		/* Return error if read operation failed */
+		if (ret != 0)
+			return ret;
+	}
+
+	return 0;
+}
+
+/*===========================================================================
+ *                          CSR IO-operations
+ *===========================================================================
+ */
+
+/*
+ * idt_csr_write() - CSR write operation
+ * @pdev:	Pointer to the driver data
+ * @csraddr:	CSR address (with no two LS bits)
+ * @data:	Data to be written to CSR
+ */
+static int idt_csr_write(struct idt_89hpesx_dev *pdev, u16 csraddr,
+			 const u32 data)
+{
+	struct device *dev = &pdev->client->dev;
+	struct idt_csr_seq csrseq;
+	struct idt_smb_seq smbseq;
+	int ret;
+
+	/* Initialize SMBus sequence fields */
+	smbseq.ccode = pdev->iniccode | CCODE_CSR;
+	smbseq.data = (u8 *)&csrseq;
+
+	/* Lock IDT SMBus device */
+	mutex_lock(&pdev->smb_mtx);
+
+	/* Perform write operation */
+	smbseq.bytecnt = CSR_WR_CNT;
+	csrseq.cmd = pdev->inicsrcmd | CSR_OP_WRITE;
+	csrseq.csraddr = cpu_to_le16(csraddr);
+	csrseq.data = cpu_to_le32(data);
+	ret = pdev->smb_write(pdev, &smbseq);
+	if (ret != 0) {
+		dev_err(dev, "Failed to write 0x%04x: 0x%04x to csr",
+			CSR_REAL_ADDR(csraddr), data);
+		goto err_mutex_unlock;
+	}
+
+	/* Send CSR address to read data from */
+	smbseq.bytecnt = CSR_WRRD_CNT;
+	csrseq.cmd = pdev->inicsrcmd | CSR_OP_READ;
+	ret = pdev->smb_write(pdev, &smbseq);
+	if (ret != 0) {
+		dev_err(dev, "Failed to init csr address 0x%04x",
+			CSR_REAL_ADDR(csraddr));
+		goto err_mutex_unlock;
+	}
+
+	/* Perform read operation */
+	smbseq.bytecnt = CSR_RD_CNT;
+	ret = pdev->smb_read(pdev, &smbseq);
+	if (ret != 0) {
+		dev_err(dev, "Failed to read csr 0x%04x",
+			CSR_REAL_ADDR(csraddr));
+		goto err_mutex_unlock;
+	}
+
+	/* Check whether IDT successfully retrieved CSR data */
+	if (csrseq.cmd & (CSR_RERR | CSR_WERR)) {
+		dev_err(dev, "IDT failed to perform CSR r/w");
+		ret = -EREMOTEIO;
+		goto err_mutex_unlock;
+	}
+
+	/* Unlock IDT SMBus device */
+err_mutex_unlock:
+	mutex_unlock(&pdev->smb_mtx);
+
+	return ret;
+}
+
+/*
+ * idt_csr_read() - CSR read operation
+ * @pdev:	Pointer to the driver data
+ * @csraddr:	CSR address (with no two LS bits)
+ * @data:	Data to be written to CSR
+ */
+static int idt_csr_read(struct idt_89hpesx_dev *pdev, u16 csraddr, u32 *data)
+{
+	struct device *dev = &pdev->client->dev;
+	struct idt_csr_seq csrseq;
+	struct idt_smb_seq smbseq;
+	int ret;
+
+	/* Initialize SMBus sequence fields */
+	smbseq.ccode = pdev->iniccode | CCODE_CSR;
+	smbseq.data = (u8 *)&csrseq;
+
+	/* Lock IDT SMBus device */
+	mutex_lock(&pdev->smb_mtx);
+
+	/* Send CSR register address before reading it */
+	smbseq.bytecnt = CSR_WRRD_CNT;
+	csrseq.cmd = pdev->inicsrcmd | CSR_OP_READ;
+	csrseq.csraddr = cpu_to_le16(csraddr);
+	ret = pdev->smb_write(pdev, &smbseq);
+	if (ret != 0) {
+		dev_err(dev, "Failed to init csr address 0x%04x",
+			CSR_REAL_ADDR(csraddr));
+		goto err_mutex_unlock;
+	}
+
+	/* Perform read operation */
+	smbseq.bytecnt = CSR_RD_CNT;
+	ret = pdev->smb_read(pdev, &smbseq);
+	if (ret != 0) {
+		dev_err(dev, "Failed to read csr 0x%04hx",
+			CSR_REAL_ADDR(csraddr));
+		goto err_mutex_unlock;
+	}
+
+	/* Check whether IDT successfully retrieved CSR data */
+	if (csrseq.cmd & (CSR_RERR | CSR_WERR)) {
+		dev_err(dev, "IDT failed to perform CSR r/w");
+		ret = -EREMOTEIO;
+		goto err_mutex_unlock;
+	}
+
+	/* Save data retrieved from IDT */
+	*data = le32_to_cpu(csrseq.data);
+
+	/* Unlock IDT SMBus device */
+err_mutex_unlock:
+	mutex_unlock(&pdev->smb_mtx);
+
+	return ret;
+}
+
+/*===========================================================================
+ *                          Sysfs/debugfs-nodes IO-operations
+ *===========================================================================
+ */
+
+/*
+ * eeprom_write() - EEPROM sysfs-node write callback
+ * @filep:	Pointer to the file system node
+ * @kobj:	Pointer to the kernel object related to the sysfs-node
+ * @attr:	Attributes of the file
+ * @buf:	Buffer to write data to
+ * @off:	Offset at which data should be written to
+ * @count:	Number of bytes to write
+ */
+static ssize_t eeprom_write(struct file *filp, struct kobject *kobj,
+			    struct bin_attribute *attr,
+			    char *buf, loff_t off, size_t count)
+{
+	struct idt_89hpesx_dev *pdev;
+	int ret;
+
+	/* Retrieve driver data */
+	pdev = dev_get_drvdata(kobj_to_dev(kobj));
+
+	/* Perform EEPROM write operation */
+	ret = idt_eeprom_write(pdev, (u16)off, (u16)count, (u8 *)buf);
+	return (ret != 0 ? ret : count);
+}
+
+/*
+ * eeprom_read() - EEPROM sysfs-node read callback
+ * @filep:	Pointer to the file system node
+ * @kobj:	Pointer to the kernel object related to the sysfs-node
+ * @attr:	Attributes of the file
+ * @buf:	Buffer to write data to
+ * @off:	Offset at which data should be written to
+ * @count:	Number of bytes to write
+ */
+static ssize_t eeprom_read(struct file *filp, struct kobject *kobj,
+			   struct bin_attribute *attr,
+			   char *buf, loff_t off, size_t count)
+{
+	struct idt_89hpesx_dev *pdev;
+	int ret;
+
+	/* Retrieve driver data */
+	pdev = dev_get_drvdata(kobj_to_dev(kobj));
+
+	/* Perform EEPROM read operation */
+	ret = idt_eeprom_read(pdev, (u16)off, (u16)count, (u8 *)buf);
+	return (ret != 0 ? ret : count);
+}
+
+/*
+ * idt_dbgfs_csr_write() - CSR debugfs-node write callback
+ * @filep:	Pointer to the file system file descriptor
+ * @buf:	Buffer to read data from
+ * @count:	Size of the buffer
+ * @offp:	Offset within the file
+ *
+ * It accepts either "0x<reg addr>:0x<value>" for saving register address
+ * and writing value to specified DWORD register or "0x<reg addr>" for
+ * just saving register address in order to perform next read operation.
+ *
+ * WARNING No spaces are allowed. Incoming string must be strictly formated as:
+ * "<reg addr>:<value>". Register address must be aligned within 4 bytes
+ * (one DWORD).
+ */
+static ssize_t idt_dbgfs_csr_write(struct file *filep, const char __user *ubuf,
+				   size_t count, loff_t *offp)
+{
+	struct idt_89hpesx_dev *pdev = filep->private_data;
+	char *colon_ch, *csraddr_str, *csrval_str;
+	int ret, csraddr_len, csrval_len;
+	u32 csraddr, csrval;
+	char *buf;
+
+	/* Copy data from User-space */
+	buf = kmalloc(count + 1, GFP_KERNEL);
+	if (!buf)
+		return -ENOMEM;
+
+	ret = simple_write_to_buffer(buf, count, offp, ubuf, count);
+	if (ret < 0)
+		goto free_buf;
+	buf[count] = 0;
+
+	/* Find position of colon in the buffer */
+	colon_ch = strnchr(buf, count, ':');
+
+	/*
+	 * If there is colon passed then new CSR value should be parsed as
+	 * well, so allocate buffer for CSR address substring.
+	 * If no colon is found, then string must have just one number with
+	 * no new CSR value
+	 */
+	if (colon_ch != NULL) {
+		csraddr_len = colon_ch - buf;
+		csraddr_str =
+			kmalloc(sizeof(char)*(csraddr_len + 1), GFP_KERNEL);
+		if (csraddr_str == NULL) {
+			ret = -ENOMEM;
+			goto free_buf;
+		}
+		/* Copy the register address to the substring buffer */
+		strncpy(csraddr_str, buf, csraddr_len);
+		csraddr_str[csraddr_len] = '\0';
+		/* Register value must follow the colon */
+		csrval_str = colon_ch + 1;
+		csrval_len = strnlen(csrval_str, count - csraddr_len);
+	} else /* if (str_colon == NULL) */ {
+		csraddr_str = (char *)buf; /* Just to shut warning up */
+		csraddr_len = strnlen(csraddr_str, count);
+		csrval_str = NULL;
+		csrval_len = 0;
+	}
+
+	/* Convert CSR address to u32 value */
+	ret = kstrtou32(csraddr_str, 0, &csraddr);
+	if (ret != 0)
+		goto free_csraddr_str;
+
+	/* Check whether passed register address is valid */
+	if (csraddr > CSR_MAX || !IS_ALIGNED(csraddr, SZ_4)) {
+		ret = -EINVAL;
+		goto free_csraddr_str;
+	}
+
+	/* Shift register address to the right so to have u16 address */
+	pdev->csr = (csraddr >> 2);
+
+	/* Parse new CSR value and send it to IDT, if colon has been found */
+	if (colon_ch != NULL) {
+		ret = kstrtou32(csrval_str, 0, &csrval);
+		if (ret != 0)
+			goto free_csraddr_str;
+
+		ret = idt_csr_write(pdev, pdev->csr, csrval);
+		if (ret != 0)
+			goto free_csraddr_str;
+	}
+
+	/* Free memory only if colon has been found */
+free_csraddr_str:
+	if (colon_ch != NULL)
+		kfree(csraddr_str);
+
+	/* Free buffer allocated for data retrieved from User-space */
+free_buf:
+	kfree(buf);
+
+	return (ret != 0 ? ret : count);
+}
+
+/*
+ * idt_dbgfs_csr_read() - CSR debugfs-node read callback
+ * @filep:	Pointer to the file system file descriptor
+ * @buf:	Buffer to write data to
+ * @count:	Size of the buffer
+ * @offp:	Offset within the file
+ *
+ * It just prints the pair "0x<reg addr>:0x<value>" to passed buffer.
+ */
+#define CSRBUF_SIZE	((size_t)32)
+static ssize_t idt_dbgfs_csr_read(struct file *filep, char __user *ubuf,
+				  size_t count, loff_t *offp)
+{
+	struct idt_89hpesx_dev *pdev = filep->private_data;
+	u32 csraddr, csrval;
+	char buf[CSRBUF_SIZE];
+	int ret, size;
+
+	/* Perform CSR read operation */
+	ret = idt_csr_read(pdev, pdev->csr, &csrval);
+	if (ret != 0)
+		return ret;
+
+	/* Shift register address to the left so to have real address */
+	csraddr = ((u32)pdev->csr << 2);
+
+	/* Print the "0x<reg addr>:0x<value>" to buffer */
+	size = snprintf(buf, CSRBUF_SIZE, "0x%05x:0x%08x\n",
+		(unsigned int)csraddr, (unsigned int)csrval);
+
+	/* Copy data to User-space */
+	return simple_read_from_buffer(ubuf, count, offp, buf, size);
+}
+
+/*
+ * eeprom_attribute - EEPROM sysfs-node attributes
+ *
+ * NOTE Size will be changed in compliance with OF node. EEPROM attribute will
+ * be read-only as well if the corresponding flag is specified in OF node.
+ */
+static BIN_ATTR_RW(eeprom, EEPROM_DEF_SIZE);
+
+/*
+ * csr_dbgfs_ops - CSR debugfs-node read/write operations
+ */
+static const struct file_operations csr_dbgfs_ops = {
+	.owner = THIS_MODULE,
+	.open = simple_open,
+	.write = idt_dbgfs_csr_write,
+	.read = idt_dbgfs_csr_read
+};
+
+/*===========================================================================
+ *                       Driver init/deinit methods
+ *===========================================================================
+ */
+
+/*
+ * idt_set_defval() - disable EEPROM access by default
+ * @pdev:	Pointer to the driver data
+ */
+static void idt_set_defval(struct idt_89hpesx_dev *pdev)
+{
+	/* If OF info is missing then use next values */
+	pdev->eesize = 0;
+	pdev->eero = true;
+	pdev->inieecmd = 0;
+	pdev->eeaddr = 0;
+}
+
+#ifdef CONFIG_OF
+static const struct i2c_device_id ee_ids[];
+/*
+ * idt_ee_match_id() - check whether the node belongs to compatible EEPROMs
+ */
+static const struct i2c_device_id *idt_ee_match_id(struct device_node *node)
+{
+	const struct i2c_device_id *id = ee_ids;
+	char devname[I2C_NAME_SIZE];
+
+	/* Retrieve the device name without manufacturer name */
+	if (of_modalias_node(node, devname, sizeof(devname)))
+		return NULL;
+
+	/* Search through the device name */
+        while (id->name[0]) {
+                if (strcmp(devname, id->name) == 0)
+                        return id;
+                id++;
+        }
+        return NULL;
+}
+
+/*
+ * idt_get_ofdata() - get IDT i2c-device parameters from device tree
+ * @pdev:	Pointer to the driver data
+ */
+static void idt_get_ofdata(struct idt_89hpesx_dev *pdev)
+{
+	const struct device_node *node = pdev->client->dev.of_node;
+	struct device *dev = &pdev->client->dev;
+
+	/* Read dts node parameters */
+	if (node) {
+		const struct i2c_device_id *ee_id = NULL;
+		struct device_node *child;
+		const __be32 *addr_be;
+		int len;
+
+		/* Walk through all child nodes looking for compatible one */
+		for_each_available_child_of_node(node, child) {
+			ee_id = idt_ee_match_id(child);
+			if (IS_ERR_OR_NULL(ee_id)) {
+				dev_warn(dev, "Skip unsupported child node %s",
+					child->full_name);
+				continue;
+			} else
+				break;
+		}
+
+		/* If there is no child EEPROM device, then set zero size */
+		if (!ee_id) {
+			idt_set_defval(pdev);
+			return;
+		}
+
+		/* Retrieve EEPROM size */
+		pdev->eesize = (u32)ee_id->driver_data;
+
+		/* Get custom EEPROM address from 'reg' attribute */
+		addr_be = of_get_property(child, "reg", &len);
+		if (!addr_be || (len < sizeof(*addr_be))) {
+			dev_warn(dev, "No reg on %s, use default address %d",
+				child->full_name, EEPROM_DEF_ADDR);
+			pdev->inieecmd = 0;
+			pdev->eeaddr = EEPROM_DEF_ADDR << 1;
+		} else {
+			pdev->inieecmd = EEPROM_USA;
+			pdev->eeaddr = be32_to_cpup(addr_be) << 1;
+		}
+
+		/* Check EEPROM 'read-only' flag */
+		if (of_get_property(child, "read-only", NULL))
+			pdev->eero = true;
+		else /* if (!of_get_property(node, "read-only", NULL)) */
+			pdev->eero = false;
+
+		dev_dbg(dev, "EEPROM of %u bytes found by %hhu",
+			pdev->eesize, pdev->eeaddr);
+	} else {
+		dev_warn(dev, "No dts node, EEPROM access disabled");
+		idt_set_defval(pdev);
+	}
+}
+#else
+static void idt_get_ofdata(struct idt_89hpesx_dev *pdev)
+{
+	struct device *dev = &pdev->client->dev;
+
+	dev_warn(dev, "OF table is unsupported, EEPROM access disabled");
+
+	/* Nothing we can do, just set the default values */
+	idt_set_defval(pdev);
+}
+#endif /* CONFIG_OF */
+
+/*
+ * idt_create_pdev() - create and init data structure of the driver
+ * @client:	i2c client of IDT PCIe-switch device
+ */
+static struct idt_89hpesx_dev *idt_create_pdev(struct i2c_client *client)
+{
+	struct idt_89hpesx_dev *pdev;
+
+	/* Allocate memory for driver data */
+	pdev = devm_kmalloc(&client->dev, sizeof(struct idt_89hpesx_dev),
+		GFP_KERNEL);
+	if (pdev == NULL)
+		return ERR_PTR(-ENOMEM);
+
+	/* Initialize basic fields of the data */
+	pdev->client = client;
+	i2c_set_clientdata(client, pdev);
+
+	/* Read OF nodes information */
+	idt_get_ofdata(pdev);
+
+	/* Initialize basic CSR CMD field - use full DWORD-sized r/w ops */
+	pdev->inicsrcmd = CSR_DWE;
+	pdev->csr = CSR_DEF;
+
+	/* Enable Packet Error Checking if it's supported by adapter */
+	if (i2c_check_functionality(client->adapter, I2C_FUNC_SMBUS_PEC)) {
+		pdev->iniccode = CCODE_PEC;
+		client->flags |= I2C_CLIENT_PEC;
+	} else /* PEC is unsupported */ {
+		pdev->iniccode = 0;
+	}
+
+	return pdev;
+}
+
+/*
+ * idt_free_pdev() - free data structure of the driver
+ * @pdev:	Pointer to the driver data
+ */
+static void idt_free_pdev(struct idt_89hpesx_dev *pdev)
+{
+	/* Clear driver data from device private field */
+	i2c_set_clientdata(pdev->client, NULL);
+}
+
+/*
+ * idt_set_smbus_ops() - set supported SMBus operations
+ * @pdev:	Pointer to the driver data
+ * Return status of smbus check operations
+ */
+static int idt_set_smbus_ops(struct idt_89hpesx_dev *pdev)
+{
+	struct i2c_adapter *adapter = pdev->client->adapter;
+	struct device *dev = &pdev->client->dev;
+
+	/* Check i2c adapter read functionality */
+	if (i2c_check_functionality(adapter,
+				    I2C_FUNC_SMBUS_READ_BLOCK_DATA)) {
+		pdev->smb_read = idt_smb_read_block;
+		dev_dbg(dev, "SMBus block-read op chosen");
+	} else if (i2c_check_functionality(adapter,
+					   I2C_FUNC_SMBUS_READ_I2C_BLOCK)) {
+		pdev->smb_read = idt_smb_read_i2c_block;
+		dev_dbg(dev, "SMBus i2c-block-read op chosen");
+	} else if (i2c_check_functionality(adapter,
+					   I2C_FUNC_SMBUS_READ_WORD_DATA) &&
+		   i2c_check_functionality(adapter,
+					   I2C_FUNC_SMBUS_READ_BYTE_DATA)) {
+		pdev->smb_read = idt_smb_read_word;
+		dev_warn(dev, "Use slow word/byte SMBus read ops");
+	} else if (i2c_check_functionality(adapter,
+					   I2C_FUNC_SMBUS_READ_BYTE_DATA)) {
+		pdev->smb_read = idt_smb_read_byte;
+		dev_warn(dev, "Use slow byte SMBus read op");
+	} else /* no supported smbus read operations */ {
+		dev_err(dev, "No supported SMBus read op");
+		return -EPFNOSUPPORT;
+	}
+
+	/* Check i2c adapter write functionality */
+	if (i2c_check_functionality(adapter,
+				    I2C_FUNC_SMBUS_WRITE_BLOCK_DATA)) {
+		pdev->smb_write = idt_smb_write_block;
+		dev_dbg(dev, "SMBus block-write op chosen");
+	} else if (i2c_check_functionality(adapter,
+					   I2C_FUNC_SMBUS_WRITE_I2C_BLOCK)) {
+		pdev->smb_write = idt_smb_write_i2c_block;
+		dev_dbg(dev, "SMBus i2c-block-write op chosen");
+	} else if (i2c_check_functionality(adapter,
+					   I2C_FUNC_SMBUS_WRITE_WORD_DATA) &&
+		   i2c_check_functionality(adapter,
+					   I2C_FUNC_SMBUS_WRITE_BYTE_DATA)) {
+		pdev->smb_write = idt_smb_write_word;
+		dev_warn(dev, "Use slow word/byte SMBus write op");
+	} else if (i2c_check_functionality(adapter,
+					   I2C_FUNC_SMBUS_WRITE_BYTE_DATA)) {
+		pdev->smb_write = idt_smb_write_byte;
+		dev_warn(dev, "Use slow byte SMBus write op");
+	} else /* no supported smbus write operations */ {
+		dev_err(dev, "No supported SMBus write op");
+		return -EPFNOSUPPORT;
+	}
+
+	/* Initialize IDT SMBus slave interface mutex */
+	mutex_init(&pdev->smb_mtx);
+
+	return 0;
+}
+
+/*
+ * idt_check_dev() - check whether it's really IDT 89HPESx device
+ * @pdev:	Pointer to the driver data
+ * Return status of i2c adapter check operation
+ */
+static int idt_check_dev(struct idt_89hpesx_dev *pdev)
+{
+	struct device *dev = &pdev->client->dev;
+	u32 viddid;
+	int ret;
+
+	/* Read VID and DID directly from IDT memory space */
+	ret = idt_csr_read(pdev, IDT_VIDDID_CSR, &viddid);
+	if (ret != 0) {
+		dev_err(dev, "Failed to read VID/DID");
+		return ret;
+	}
+
+	/* Check whether it's IDT device */
+	if ((viddid & IDT_VID_MASK) != PCI_VENDOR_ID_IDT) {
+		dev_err(dev, "Got unsupported VID/DID: 0x%08x", viddid);
+		return -ENODEV;
+	}
+
+	dev_info(dev, "Found IDT 89HPES device VID:0x%04x, DID:0x%04x",
+		(viddid & IDT_VID_MASK), (viddid >> 16));
+
+	return 0;
+}
+
+/*
+ * idt_create_sysfs_files() - create sysfs attribute files
+ * @pdev:	Pointer to the driver data
+ * Return status of operation
+ */
+static int idt_create_sysfs_files(struct idt_89hpesx_dev *pdev)
+{
+	struct device *dev = &pdev->client->dev;
+	int ret;
+
+	/* Don't do anything if EEPROM isn't accessible */
+	if (pdev->eesize == 0) {
+		dev_dbg(dev, "Skip creating sysfs-files");
+		return 0;
+	}
+
+	/* Allocate memory for attribute file */
+	pdev->ee_file = devm_kmalloc(dev, sizeof(*pdev->ee_file), GFP_KERNEL);
+	if (!pdev->ee_file)
+		return -ENOMEM;
+
+	/* Copy the declared EEPROM attr structure to change some of fields */
+	memcpy(pdev->ee_file, &bin_attr_eeprom, sizeof(*pdev->ee_file));
+
+	/* In case of read-only EEPROM get rid of write ability */
+	if (pdev->eero) {
+		pdev->ee_file->attr.mode &= ~0200;
+		pdev->ee_file->write = NULL;
+	}
+	/* Create EEPROM sysfs file */
+	pdev->ee_file->size = pdev->eesize;
+	ret = sysfs_create_bin_file(&dev->kobj, pdev->ee_file);
+	if (ret != 0) {
+		dev_err(dev, "Failed to create EEPROM sysfs-node");
+		return ret;
+	}
+
+	return 0;
+}
+
+/*
+ * idt_remove_sysfs_files() - remove sysfs attribute files
+ * @pdev:	Pointer to the driver data
+ */
+static void idt_remove_sysfs_files(struct idt_89hpesx_dev *pdev)
+{
+	struct device *dev = &pdev->client->dev;
+
+	/* Don't do anything if EEPROM wasn't accessible */
+	if (pdev->eesize == 0)
+		return;
+
+	/* Remove EEPROM sysfs file */
+	sysfs_remove_bin_file(&dev->kobj, pdev->ee_file);
+}
+
+/*
+ * idt_create_dbgfs_files() - create debugfs files
+ * @pdev:	Pointer to the driver data
+ */
+#define CSRNAME_LEN	((size_t)32)
+static void idt_create_dbgfs_files(struct idt_89hpesx_dev *pdev)
+{
+	struct i2c_client *cli = pdev->client;
+	char fname[CSRNAME_LEN];
+
+	/* Create Debugfs directory for CSR file */
+	snprintf(fname, CSRNAME_LEN, "%d-%04hx", cli->adapter->nr, cli->addr);
+	pdev->csr_dir = debugfs_create_dir(fname, csr_dbgdir);
+
+	/* Create Debugfs file for CSR read/write operations */
+	pdev->csr_file = debugfs_create_file(cli->name, 0600,
+		pdev->csr_dir, pdev, &csr_dbgfs_ops);
+}
+
+/*
+ * idt_remove_dbgfs_files() - remove debugfs files
+ * @pdev:	Pointer to the driver data
+ */
+static void idt_remove_dbgfs_files(struct idt_89hpesx_dev *pdev)
+{
+	/* Remove CSR directory and it sysfs-node */
+	debugfs_remove_recursive(pdev->csr_dir);
+}
+
+/*
+ * idt_probe() - IDT 89HPESx driver probe() callback method
+ */
+static int idt_probe(struct i2c_client *client, const struct i2c_device_id *id)
+{
+	struct idt_89hpesx_dev *pdev;
+	int ret;
+
+	/* Create driver data */
+	pdev = idt_create_pdev(client);
+	if (IS_ERR(pdev))
+		return PTR_ERR(pdev);
+
+	/* Set SMBus operations */
+	ret = idt_set_smbus_ops(pdev);
+	if (ret != 0)
+		goto err_free_pdev;
+
+	/* Check whether it is truly IDT 89HPESx device */
+	ret = idt_check_dev(pdev);
+	if (ret != 0)
+		goto err_free_pdev;
+
+	/* Create sysfs files */
+	ret = idt_create_sysfs_files(pdev);
+	if (ret != 0)
+		goto err_free_pdev;
+
+	/* Create debugfs files */
+	idt_create_dbgfs_files(pdev);
+
+	return 0;
+
+err_free_pdev:
+	idt_free_pdev(pdev);
+
+	return ret;
+}
+
+/*
+ * idt_remove() - IDT 89HPESx driver remove() callback method
+ */
+static int idt_remove(struct i2c_client *client)
+{
+	struct idt_89hpesx_dev *pdev = i2c_get_clientdata(client);
+
+	/* Remove debugfs files first */
+	idt_remove_dbgfs_files(pdev);
+
+	/* Remove sysfs files */
+	idt_remove_sysfs_files(pdev);
+
+	/* Discard driver data structure */
+	idt_free_pdev(pdev);
+
+	return 0;
+}
+
+/*
+ * ee_ids - array of supported EEPROMs
+ */
+static const struct i2c_device_id ee_ids[] = {
+	{ "24c32",  4096},
+	{ "24c64",  8192},
+	{ "24c128", 16384},
+	{ "24c256", 32768},
+	{ "24c512", 65536},
+	{}
+};
+MODULE_DEVICE_TABLE(i2c, ee_ids);
+
+/*
+ * idt_ids - supported IDT 89HPESx devices
+ */
+static const struct i2c_device_id idt_ids[] = {
+	{ "89hpes8nt2", 0 },
+	{ "89hpes12nt3", 0 },
+
+	{ "89hpes24nt6ag2", 0 },
+	{ "89hpes32nt8ag2", 0 },
+	{ "89hpes32nt8bg2", 0 },
+	{ "89hpes12nt12g2", 0 },
+	{ "89hpes16nt16g2", 0 },
+	{ "89hpes24nt24g2", 0 },
+	{ "89hpes32nt24ag2", 0 },
+	{ "89hpes32nt24bg2", 0 },
+
+	{ "89hpes12n3", 0 },
+	{ "89hpes12n3a", 0 },
+	{ "89hpes24n3", 0 },
+	{ "89hpes24n3a", 0 },
+
+	{ "89hpes32h8", 0 },
+	{ "89hpes32h8g2", 0 },
+	{ "89hpes48h12", 0 },
+	{ "89hpes48h12g2", 0 },
+	{ "89hpes48h12ag2", 0 },
+	{ "89hpes16h16", 0 },
+	{ "89hpes22h16", 0 },
+	{ "89hpes22h16g2", 0 },
+	{ "89hpes34h16", 0 },
+	{ "89hpes34h16g2", 0 },
+	{ "89hpes64h16", 0 },
+	{ "89hpes64h16g2", 0 },
+	{ "89hpes64h16ag2", 0 },
+
+	/* { "89hpes3t3", 0 }, // No SMBus-slave iface */
+	{ "89hpes12t3g2", 0 },
+	{ "89hpes24t3g2", 0 },
+	/* { "89hpes4t4", 0 }, // No SMBus-slave iface */
+	{ "89hpes16t4", 0 },
+	{ "89hpes4t4g2", 0 },
+	{ "89hpes10t4g2", 0 },
+	{ "89hpes16t4g2", 0 },
+	{ "89hpes16t4ag2", 0 },
+	{ "89hpes5t5", 0 },
+	{ "89hpes6t5", 0 },
+	{ "89hpes8t5", 0 },
+	{ "89hpes8t5a", 0 },
+	{ "89hpes24t6", 0 },
+	{ "89hpes6t6g2", 0 },
+	{ "89hpes24t6g2", 0 },
+	{ "89hpes16t7", 0 },
+	{ "89hpes32t8", 0 },
+	{ "89hpes32t8g2", 0 },
+	{ "89hpes48t12", 0 },
+	{ "89hpes48t12g2", 0 },
+	{ /* END OF LIST */ }
+};
+MODULE_DEVICE_TABLE(i2c, idt_ids);
+
+/*
+ * idt_driver - IDT 89HPESx driver structure
+ */
+static struct i2c_driver idt_driver = {
+	.driver = {
+		.name = IDT_NAME,
+	},
+	.probe = idt_probe,
+	.remove = idt_remove,
+	.id_table = idt_ids,
+};
+
+/*
+ * idt_init() - IDT 89HPESx driver init() callback method
+ */
+static int __init idt_init(void)
+{
+	/* Create Debugfs directory first */
+	if (debugfs_initialized())
+		csr_dbgdir = debugfs_create_dir("idt_csr", NULL);
+
+	/* Add new i2c-device driver */
+	return i2c_add_driver(&idt_driver);
+}
+module_init(idt_init);
+
+/*
+ * idt_exit() - IDT 89HPESx driver exit() callback method
+ */
+static void __exit idt_exit(void)
+{
+	/* Discard debugfs directory and all files if any */
+	debugfs_remove_recursive(csr_dbgdir);
+
+	/* Unregister i2c-device driver */
+	i2c_del_driver(&idt_driver);
+}
+module_exit(idt_exit);
diff --git a/drivers/misc/genwqe/card_base.c b/drivers/misc/genwqe/card_base.c
index 6c1f49a85023..4fd21e86ad56 100644
--- a/drivers/misc/genwqe/card_base.c
+++ b/drivers/misc/genwqe/card_base.c
@@ -1,1413 +1,1412 @@
 /**
  * IBM Accelerator Family 'GenWQE'
  *
  * (C) Copyright IBM Corp. 2013
  *
  * Author: Frank Haverkamp <haver@linux.vnet.ibm.com>
  * Author: Joerg-Stephan Vogt <jsvogt@de.ibm.com>
  * Author: Michael Jung <mijung@gmx.net>
  * Author: Michael Ruettger <michael@ibmra.de>
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License (version 2 only)
  * as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
  * GNU General Public License for more details.
  */
 
 /*
  * Module initialization and PCIe setup. Card health monitoring and
  * recovery functionality. Character device creation and deletion are
  * controlled from here.
  */
 
 #include <linux/module.h>
 #include <linux/types.h>
 #include <linux/pci.h>
 #include <linux/err.h>
 #include <linux/aer.h>
 #include <linux/string.h>
 #include <linux/sched.h>
 #include <linux/wait.h>
 #include <linux/delay.h>
 #include <linux/dma-mapping.h>
 #include <linux/module.h>
 #include <linux/notifier.h>
 #include <linux/device.h>
 #include <linux/log2.h>
 
 #include "card_base.h"
 #include "card_ddcb.h"
 
 MODULE_AUTHOR("Frank Haverkamp <haver@linux.vnet.ibm.com>");
 MODULE_AUTHOR("Michael Ruettger <michael@ibmra.de>");
 MODULE_AUTHOR("Joerg-Stephan Vogt <jsvogt@de.ibm.com>");
 MODULE_AUTHOR("Michael Jung <mijung@gmx.net>");
 
 MODULE_DESCRIPTION("GenWQE Card");
 MODULE_VERSION(DRV_VERSION);
 MODULE_LICENSE("GPL");
 
 static char genwqe_driver_name[] = GENWQE_DEVNAME;
 static struct class *class_genwqe;
 static struct dentry *debugfs_genwqe;
 static struct genwqe_dev *genwqe_devices[GENWQE_CARD_NO_MAX];
 
 /* PCI structure for identifying device by PCI vendor and device ID */
 static const struct pci_device_id genwqe_device_table[] = {
 	{ .vendor      = PCI_VENDOR_ID_IBM,
 	  .device      = PCI_DEVICE_GENWQE,
 	  .subvendor   = PCI_SUBVENDOR_ID_IBM,
 	  .subdevice   = PCI_SUBSYSTEM_ID_GENWQE5,
 	  .class       = (PCI_CLASSCODE_GENWQE5 << 8),
 	  .class_mask  = ~0,
 	  .driver_data = 0 },
 
 	/* Initial SR-IOV bring-up image */
 	{ .vendor      = PCI_VENDOR_ID_IBM,
 	  .device      = PCI_DEVICE_GENWQE,
 	  .subvendor   = PCI_SUBVENDOR_ID_IBM_SRIOV,
 	  .subdevice   = PCI_SUBSYSTEM_ID_GENWQE5_SRIOV,
 	  .class       = (PCI_CLASSCODE_GENWQE5_SRIOV << 8),
 	  .class_mask  = ~0,
 	  .driver_data = 0 },
 
 	{ .vendor      = PCI_VENDOR_ID_IBM,  /* VF Vendor ID */
 	  .device      = 0x0000,  /* VF Device ID */
 	  .subvendor   = PCI_SUBVENDOR_ID_IBM_SRIOV,
 	  .subdevice   = PCI_SUBSYSTEM_ID_GENWQE5_SRIOV,
 	  .class       = (PCI_CLASSCODE_GENWQE5_SRIOV << 8),
 	  .class_mask  = ~0,
 	  .driver_data = 0 },
 
 	/* Fixed up image */
 	{ .vendor      = PCI_VENDOR_ID_IBM,
 	  .device      = PCI_DEVICE_GENWQE,
 	  .subvendor   = PCI_SUBVENDOR_ID_IBM_SRIOV,
 	  .subdevice   = PCI_SUBSYSTEM_ID_GENWQE5,
 	  .class       = (PCI_CLASSCODE_GENWQE5_SRIOV << 8),
 	  .class_mask  = ~0,
 	  .driver_data = 0 },
 
 	{ .vendor      = PCI_VENDOR_ID_IBM,  /* VF Vendor ID */
 	  .device      = 0x0000,  /* VF Device ID */
 	  .subvendor   = PCI_SUBVENDOR_ID_IBM_SRIOV,
 	  .subdevice   = PCI_SUBSYSTEM_ID_GENWQE5,
 	  .class       = (PCI_CLASSCODE_GENWQE5_SRIOV << 8),
 	  .class_mask  = ~0,
 	  .driver_data = 0 },
 
 	/* Even one more ... */
 	{ .vendor      = PCI_VENDOR_ID_IBM,
 	  .device      = PCI_DEVICE_GENWQE,
 	  .subvendor   = PCI_SUBVENDOR_ID_IBM,
 	  .subdevice   = PCI_SUBSYSTEM_ID_GENWQE5_NEW,
 	  .class       = (PCI_CLASSCODE_GENWQE5 << 8),
 	  .class_mask  = ~0,
 	  .driver_data = 0 },
 
 	{ 0, }			/* 0 terminated list. */
 };
 
 MODULE_DEVICE_TABLE(pci, genwqe_device_table);
 
 /**
  * genwqe_dev_alloc() - Create and prepare a new card descriptor
  *
  * Return: Pointer to card descriptor, or ERR_PTR(err) on error
  */
 static struct genwqe_dev *genwqe_dev_alloc(void)
 {
 	unsigned int i = 0, j;
 	struct genwqe_dev *cd;
 
 	for (i = 0; i < GENWQE_CARD_NO_MAX; i++) {
 		if (genwqe_devices[i] == NULL)
 			break;
 	}
 	if (i >= GENWQE_CARD_NO_MAX)
 		return ERR_PTR(-ENODEV);
 
 	cd = kzalloc(sizeof(struct genwqe_dev), GFP_KERNEL);
 	if (!cd)
 		return ERR_PTR(-ENOMEM);
 
 	cd->card_idx = i;
 	cd->class_genwqe = class_genwqe;
 	cd->debugfs_genwqe = debugfs_genwqe;
 
 	/*
 	 * This comes from kernel config option and can be overritten via
 	 * debugfs.
 	 */
 	cd->use_platform_recovery = CONFIG_GENWQE_PLATFORM_ERROR_RECOVERY;
 
 	init_waitqueue_head(&cd->queue_waitq);
 
 	spin_lock_init(&cd->file_lock);
 	INIT_LIST_HEAD(&cd->file_list);
 
 	cd->card_state = GENWQE_CARD_UNUSED;
 	spin_lock_init(&cd->print_lock);
 
 	cd->ddcb_software_timeout = genwqe_ddcb_software_timeout;
 	cd->kill_timeout = genwqe_kill_timeout;
 
 	for (j = 0; j < GENWQE_MAX_VFS; j++)
 		cd->vf_jobtimeout_msec[j] = genwqe_vf_jobtimeout_msec;
 
 	genwqe_devices[i] = cd;
 	return cd;
 }
 
 static void genwqe_dev_free(struct genwqe_dev *cd)
 {
 	if (!cd)
 		return;
 
 	genwqe_devices[cd->card_idx] = NULL;
 	kfree(cd);
 }
 
 /**
  * genwqe_bus_reset() - Card recovery
  *
  * pci_reset_function() will recover the device and ensure that the
  * registers are accessible again when it completes with success. If
  * not, the card will stay dead and registers will be unaccessible
  * still.
  */
 static int genwqe_bus_reset(struct genwqe_dev *cd)
 {
 	int rc = 0;
 	struct pci_dev *pci_dev = cd->pci_dev;
 	void __iomem *mmio;
 
 	if (cd->err_inject & GENWQE_INJECT_BUS_RESET_FAILURE)
 		return -EIO;
 
 	mmio = cd->mmio;
 	cd->mmio = NULL;
 	pci_iounmap(pci_dev, mmio);
 
 	pci_release_mem_regions(pci_dev);
 
 	/*
 	 * Firmware/BIOS might change memory mapping during bus reset.
 	 * Settings like enable bus-mastering, ... are backuped and
 	 * restored by the pci_reset_function().
 	 */
 	dev_dbg(&pci_dev->dev, "[%s] pci_reset function ...\n", __func__);
 	rc = pci_reset_function(pci_dev);
 	if (rc) {
 		dev_err(&pci_dev->dev,
 			"[%s] err: failed reset func (rc %d)\n", __func__, rc);
 		return rc;
 	}
 	dev_dbg(&pci_dev->dev, "[%s] done with rc=%d\n", __func__, rc);
 
 	/*
 	 * Here is the right spot to clear the register read
 	 * failure. pci_bus_reset() does this job in real systems.
 	 */
 	cd->err_inject &= ~(GENWQE_INJECT_HARDWARE_FAILURE |
 			    GENWQE_INJECT_GFIR_FATAL |
 			    GENWQE_INJECT_GFIR_INFO);
 
 	rc = pci_request_mem_regions(pci_dev, genwqe_driver_name);
 	if (rc) {
 		dev_err(&pci_dev->dev,
 			"[%s] err: request bars failed (%d)\n", __func__, rc);
 		return -EIO;
 	}
 
 	cd->mmio = pci_iomap(pci_dev, 0, 0);
 	if (cd->mmio == NULL) {
 		dev_err(&pci_dev->dev,
 			"[%s] err: mapping BAR0 failed\n", __func__);
 		return -ENOMEM;
 	}
 	return 0;
 }
 
 /*
  * Hardware circumvention section. Certain bitstreams in our test-lab
  * had different kinds of problems. Here is where we adjust those
  * bitstreams to function will with this version of our device driver.
  *
  * Thise circumventions are applied to the physical function only.
  * The magical numbers below are identifying development/manufacturing
  * versions of the bitstream used on the card.
  *
  * Turn off error reporting for old/manufacturing images.
  */
 
 bool genwqe_need_err_masking(struct genwqe_dev *cd)
 {
 	return (cd->slu_unitcfg & 0xFFFF0ull) < 0x32170ull;
 }
 
 static void genwqe_tweak_hardware(struct genwqe_dev *cd)
 {
 	struct pci_dev *pci_dev = cd->pci_dev;
 
 	/* Mask FIRs for development images */
 	if (((cd->slu_unitcfg & 0xFFFF0ull) >= 0x32000ull) &&
 	    ((cd->slu_unitcfg & 0xFFFF0ull) <= 0x33250ull)) {
 		dev_warn(&pci_dev->dev,
 			 "FIRs masked due to bitstream %016llx.%016llx\n",
 			 cd->slu_unitcfg, cd->app_unitcfg);
 
 		__genwqe_writeq(cd, IO_APP_SEC_LEM_DEBUG_OVR,
 				0xFFFFFFFFFFFFFFFFull);
 
 		__genwqe_writeq(cd, IO_APP_ERR_ACT_MASK,
 				0x0000000000000000ull);
 	}
 }
 
 /**
  * genwqe_recovery_on_fatal_gfir_required() - Version depended actions
  *
  * Bitstreams older than 2013-02-17 have a bug where fatal GFIRs must
  * be ignored. This is e.g. true for the bitstream we gave to the card
  * manufacturer, but also for some old bitstreams we released to our
  * test-lab.
  */
 int genwqe_recovery_on_fatal_gfir_required(struct genwqe_dev *cd)
 {
 	return (cd->slu_unitcfg & 0xFFFF0ull) >= 0x32170ull;
 }
 
 int genwqe_flash_readback_fails(struct genwqe_dev *cd)
 {
 	return (cd->slu_unitcfg & 0xFFFF0ull) < 0x32170ull;
 }
 
 /**
  * genwqe_T_psec() - Calculate PF/VF timeout register content
  *
  * Note: From a design perspective it turned out to be a bad idea to
  * use codes here to specifiy the frequency/speed values. An old
  * driver cannot understand new codes and is therefore always a
  * problem. Better is to measure out the value or put the
  * speed/frequency directly into a register which is always a valid
  * value for old as well as for new software.
  */
 /* T = 1/f */
 static int genwqe_T_psec(struct genwqe_dev *cd)
 {
 	u16 speed;	/* 1/f -> 250,  200,  166,  175 */
 	static const int T[] = { 4000, 5000, 6000, 5714 };
 
 	speed = (u16)((cd->slu_unitcfg >> 28) & 0x0full);
 	if (speed >= ARRAY_SIZE(T))
 		return -1;	/* illegal value */
 
 	return T[speed];
 }
 
 /**
  * genwqe_setup_pf_jtimer() - Setup PF hardware timeouts for DDCB execution
  *
  * Do this _after_ card_reset() is called. Otherwise the values will
  * vanish. The settings need to be done when the queues are inactive.
  *
  * The max. timeout value is 2^(10+x) * T (6ns for 166MHz) * 15/16.
  * The min. timeout value is 2^(10+x) * T (6ns for 166MHz) * 14/16.
  */
 static bool genwqe_setup_pf_jtimer(struct genwqe_dev *cd)
 {
 	u32 T = genwqe_T_psec(cd);
 	u64 x;
 
 	if (genwqe_pf_jobtimeout_msec == 0)
 		return false;
 
 	/* PF: large value needed, flash update 2sec per block */
 	x = ilog2(genwqe_pf_jobtimeout_msec *
 		  16000000000uL/(T * 15)) - 10;
 
 	genwqe_write_vreg(cd, IO_SLC_VF_APPJOB_TIMEOUT,
 			  0xff00 | (x & 0xff), 0);
 	return true;
 }
 
 /**
  * genwqe_setup_vf_jtimer() - Setup VF hardware timeouts for DDCB execution
  */
 static bool genwqe_setup_vf_jtimer(struct genwqe_dev *cd)
 {
 	struct pci_dev *pci_dev = cd->pci_dev;
 	unsigned int vf;
 	u32 T = genwqe_T_psec(cd);
 	u64 x;
 	int totalvfs;
 
 	totalvfs = pci_sriov_get_totalvfs(pci_dev);
 	if (totalvfs <= 0)
 		return false;
 
 	for (vf = 0; vf < totalvfs; vf++) {
 
 		if (cd->vf_jobtimeout_msec[vf] == 0)
 			continue;
 
 		x = ilog2(cd->vf_jobtimeout_msec[vf] *
 			  16000000000uL/(T * 15)) - 10;
 
 		genwqe_write_vreg(cd, IO_SLC_VF_APPJOB_TIMEOUT,
 				  0xff00 | (x & 0xff), vf + 1);
 	}
 	return true;
 }
 
 static int genwqe_ffdc_buffs_alloc(struct genwqe_dev *cd)
 {
 	unsigned int type, e = 0;
 
 	for (type = 0; type < GENWQE_DBG_UNITS; type++) {
 		switch (type) {
 		case GENWQE_DBG_UNIT0:
 			e = genwqe_ffdc_buff_size(cd, 0);
 			break;
 		case GENWQE_DBG_UNIT1:
 			e = genwqe_ffdc_buff_size(cd, 1);
 			break;
 		case GENWQE_DBG_UNIT2:
 			e = genwqe_ffdc_buff_size(cd, 2);
 			break;
 		case GENWQE_DBG_REGS:
 			e = GENWQE_FFDC_REGS;
 			break;
 		}
 
 		/* currently support only the debug units mentioned here */
 		cd->ffdc[type].entries = e;
 		cd->ffdc[type].regs =
 			kmalloc_array(e, sizeof(struct genwqe_reg),
 				      GFP_KERNEL);
 		/*
 		 * regs == NULL is ok, the using code treats this as no regs,
 		 * Printing warning is ok in this case.
 		 */
 	}
 	return 0;
 }
 
 static void genwqe_ffdc_buffs_free(struct genwqe_dev *cd)
 {
 	unsigned int type;
 
 	for (type = 0; type < GENWQE_DBG_UNITS; type++) {
 		kfree(cd->ffdc[type].regs);
 		cd->ffdc[type].regs = NULL;
 	}
 }
 
 static int genwqe_read_ids(struct genwqe_dev *cd)
 {
 	int err = 0;
 	int slu_id;
 	struct pci_dev *pci_dev = cd->pci_dev;
 
 	cd->slu_unitcfg = __genwqe_readq(cd, IO_SLU_UNITCFG);
 	if (cd->slu_unitcfg == IO_ILLEGAL_VALUE) {
 		dev_err(&pci_dev->dev,
 			"err: SLUID=%016llx\n", cd->slu_unitcfg);
 		err = -EIO;
 		goto out_err;
 	}
 
 	slu_id = genwqe_get_slu_id(cd);
 	if (slu_id < GENWQE_SLU_ARCH_REQ || slu_id == 0xff) {
 		dev_err(&pci_dev->dev,
 			"err: incompatible SLU Architecture %u\n", slu_id);
 		err = -ENOENT;
 		goto out_err;
 	}
 
 	cd->app_unitcfg = __genwqe_readq(cd, IO_APP_UNITCFG);
 	if (cd->app_unitcfg == IO_ILLEGAL_VALUE) {
 		dev_err(&pci_dev->dev,
 			"err: APPID=%016llx\n", cd->app_unitcfg);
 		err = -EIO;
 		goto out_err;
 	}
 	genwqe_read_app_id(cd, cd->app_name, sizeof(cd->app_name));
 
 	/*
 	 * Is access to all registers possible? If we are a VF the
 	 * answer is obvious. If we run fully virtualized, we need to
 	 * check if we can access all registers. If we do not have
 	 * full access we will cause an UR and some informational FIRs
 	 * in the PF, but that should not harm.
 	 */
 	if (pci_dev->is_virtfn)
 		cd->is_privileged = 0;
 	else
 		cd->is_privileged = (__genwqe_readq(cd, IO_SLU_BITSTREAM)
 				     != IO_ILLEGAL_VALUE);
 
  out_err:
 	return err;
 }
 
 static int genwqe_start(struct genwqe_dev *cd)
 {
 	int err;
 	struct pci_dev *pci_dev = cd->pci_dev;
 
 	err = genwqe_read_ids(cd);
 	if (err)
 		return err;
 
 	if (genwqe_is_privileged(cd)) {
 		/* do this after the tweaks. alloc fail is acceptable */
 		genwqe_ffdc_buffs_alloc(cd);
 		genwqe_stop_traps(cd);
 
 		/* Collect registers e.g. FIRs, UNITIDs, traces ... */
 		genwqe_read_ffdc_regs(cd, cd->ffdc[GENWQE_DBG_REGS].regs,
 				      cd->ffdc[GENWQE_DBG_REGS].entries, 0);
 
 		genwqe_ffdc_buff_read(cd, GENWQE_DBG_UNIT0,
 				      cd->ffdc[GENWQE_DBG_UNIT0].regs,
 				      cd->ffdc[GENWQE_DBG_UNIT0].entries);
 
 		genwqe_ffdc_buff_read(cd, GENWQE_DBG_UNIT1,
 				      cd->ffdc[GENWQE_DBG_UNIT1].regs,
 				      cd->ffdc[GENWQE_DBG_UNIT1].entries);
 
 		genwqe_ffdc_buff_read(cd, GENWQE_DBG_UNIT2,
 				      cd->ffdc[GENWQE_DBG_UNIT2].regs,
 				      cd->ffdc[GENWQE_DBG_UNIT2].entries);
 
 		genwqe_start_traps(cd);
 
 		if (cd->card_state == GENWQE_CARD_FATAL_ERROR) {
 			dev_warn(&pci_dev->dev,
 				 "[%s] chip reload/recovery!\n", __func__);
 
 			/*
 			 * Stealth Mode: Reload chip on either hot
 			 * reset or PERST.
 			 */
 			cd->softreset = 0x7Cull;
 			__genwqe_writeq(cd, IO_SLC_CFGREG_SOFTRESET,
 				       cd->softreset);
 
 			err = genwqe_bus_reset(cd);
 			if (err != 0) {
 				dev_err(&pci_dev->dev,
 					"[%s] err: bus reset failed!\n",
 					__func__);
 				goto out;
 			}
 
 			/*
 			 * Re-read the IDs because
 			 * it could happen that the bitstream load
 			 * failed!
 			 */
 			err = genwqe_read_ids(cd);
 			if (err)
 				goto out;
 		}
 	}
 
 	err = genwqe_setup_service_layer(cd);  /* does a reset to the card */
 	if (err != 0) {
 		dev_err(&pci_dev->dev,
 			"[%s] err: could not setup servicelayer!\n", __func__);
 		err = -ENODEV;
 		goto out;
 	}
 
 	if (genwqe_is_privileged(cd)) {	 /* code is running _after_ reset */
 		genwqe_tweak_hardware(cd);
 
 		genwqe_setup_pf_jtimer(cd);
 		genwqe_setup_vf_jtimer(cd);
 	}
 
 	err = genwqe_device_create(cd);
 	if (err < 0) {
 		dev_err(&pci_dev->dev,
 			"err: chdev init failed! (err=%d)\n", err);
 		goto out_release_service_layer;
 	}
 	return 0;
 
  out_release_service_layer:
 	genwqe_release_service_layer(cd);
  out:
 	if (genwqe_is_privileged(cd))
 		genwqe_ffdc_buffs_free(cd);
 	return -EIO;
 }
 
 /**
  * genwqe_stop() - Stop card operation
  *
  * Recovery notes:
  *   As long as genwqe_thread runs we might access registers during
  *   error data capture. Same is with the genwqe_health_thread.
  *   When genwqe_bus_reset() fails this function might called two times:
  *   first by the genwqe_health_thread() and later by genwqe_remove() to
  *   unbind the device. We must be able to survive that.
  *
  * This function must be robust enough to be called twice.
  */
 static int genwqe_stop(struct genwqe_dev *cd)
 {
 	genwqe_finish_queue(cd);	    /* no register access */
 	genwqe_device_remove(cd);	    /* device removed, procs killed */
 	genwqe_release_service_layer(cd);   /* here genwqe_thread is stopped */
 
 	if (genwqe_is_privileged(cd)) {
 		pci_disable_sriov(cd->pci_dev);	/* access pci config space */
 		genwqe_ffdc_buffs_free(cd);
 	}
 
 	return 0;
 }
 
 /**
  * genwqe_recover_card() - Try to recover the card if it is possible
  *
  * If fatal_err is set no register access is possible anymore. It is
  * likely that genwqe_start fails in that situation. Proper error
  * handling is required in this case.
  *
  * genwqe_bus_reset() will cause the pci code to call genwqe_remove()
  * and later genwqe_probe() for all virtual functions.
  */
 static int genwqe_recover_card(struct genwqe_dev *cd, int fatal_err)
 {
 	int rc;
 	struct pci_dev *pci_dev = cd->pci_dev;
 
 	genwqe_stop(cd);
 
 	/*
 	 * Make sure chip is not reloaded to maintain FFDC. Write SLU
 	 * Reset Register, CPLDReset field to 0.
 	 */
 	if (!fatal_err) {
 		cd->softreset = 0x70ull;
 		__genwqe_writeq(cd, IO_SLC_CFGREG_SOFTRESET, cd->softreset);
 	}
 
 	rc = genwqe_bus_reset(cd);
 	if (rc != 0) {
 		dev_err(&pci_dev->dev,
 			"[%s] err: card recovery impossible!\n", __func__);
 		return rc;
 	}
 
 	rc = genwqe_start(cd);
 	if (rc < 0) {
 		dev_err(&pci_dev->dev,
 			"[%s] err: failed to launch device!\n", __func__);
 		return rc;
 	}
 	return 0;
 }
 
 static int genwqe_health_check_cond(struct genwqe_dev *cd, u64 *gfir)
 {
 	*gfir = __genwqe_readq(cd, IO_SLC_CFGREG_GFIR);
 	return (*gfir & GFIR_ERR_TRIGGER) &&
 		genwqe_recovery_on_fatal_gfir_required(cd);
 }
 
 /**
  * genwqe_fir_checking() - Check the fault isolation registers of the card
  *
  * If this code works ok, can be tried out with help of the genwqe_poke tool:
  *   sudo ./tools/genwqe_poke 0x8 0xfefefefefef
  *
  * Now the relevant FIRs/sFIRs should be printed out and the driver should
  * invoke recovery (devices are removed and readded).
  */
 static u64 genwqe_fir_checking(struct genwqe_dev *cd)
 {
 	int j, iterations = 0;
 	u64 mask, fir, fec, uid, gfir, gfir_masked, sfir, sfec;
 	u32 fir_addr, fir_clr_addr, fec_addr, sfir_addr, sfec_addr;
 	struct pci_dev *pci_dev = cd->pci_dev;
 
  healthMonitor:
 	iterations++;
 	if (iterations > 16) {
 		dev_err(&pci_dev->dev, "* exit looping after %d times\n",
 			iterations);
 		goto fatal_error;
 	}
 
 	gfir = __genwqe_readq(cd, IO_SLC_CFGREG_GFIR);
 	if (gfir != 0x0)
 		dev_err(&pci_dev->dev, "* 0x%08x 0x%016llx\n",
 				    IO_SLC_CFGREG_GFIR, gfir);
 	if (gfir == IO_ILLEGAL_VALUE)
 		goto fatal_error;
 
 	/*
 	 * Avoid printing when to GFIR bit is on prevents contignous
 	 * printout e.g. for the following bug:
 	 *   FIR set without a 2ndary FIR/FIR cannot be cleared
 	 * Comment out the following if to get the prints:
 	 */
 	if (gfir == 0)
 		return 0;
 
 	gfir_masked = gfir & GFIR_ERR_TRIGGER;  /* fatal errors */
 
 	for (uid = 0; uid < GENWQE_MAX_UNITS; uid++) { /* 0..2 in zEDC */
 
 		/* read the primary FIR (pfir) */
 		fir_addr = (uid << 24) + 0x08;
 		fir = __genwqe_readq(cd, fir_addr);
 		if (fir == 0x0)
 			continue;  /* no error in this unit */
 
 		dev_err(&pci_dev->dev, "* 0x%08x 0x%016llx\n", fir_addr, fir);
 		if (fir == IO_ILLEGAL_VALUE)
 			goto fatal_error;
 
 		/* read primary FEC */
 		fec_addr = (uid << 24) + 0x18;
 		fec = __genwqe_readq(cd, fec_addr);
 
 		dev_err(&pci_dev->dev, "* 0x%08x 0x%016llx\n", fec_addr, fec);
 		if (fec == IO_ILLEGAL_VALUE)
 			goto fatal_error;
 
 		for (j = 0, mask = 1ULL; j < 64; j++, mask <<= 1) {
 
 			/* secondary fir empty, skip it */
 			if ((fir & mask) == 0x0)
 				continue;
 
 			sfir_addr = (uid << 24) + 0x100 + 0x08 * j;
 			sfir = __genwqe_readq(cd, sfir_addr);
 
 			if (sfir == IO_ILLEGAL_VALUE)
 				goto fatal_error;
 			dev_err(&pci_dev->dev,
 				"* 0x%08x 0x%016llx\n", sfir_addr, sfir);
 
 			sfec_addr = (uid << 24) + 0x300 + 0x08 * j;
 			sfec = __genwqe_readq(cd, sfec_addr);
 
 			if (sfec == IO_ILLEGAL_VALUE)
 				goto fatal_error;
 			dev_err(&pci_dev->dev,
 				"* 0x%08x 0x%016llx\n", sfec_addr, sfec);
 
 			gfir = __genwqe_readq(cd, IO_SLC_CFGREG_GFIR);
 			if (gfir == IO_ILLEGAL_VALUE)
 				goto fatal_error;
 
 			/* gfir turned on during routine! get out and
 			   start over. */
 			if ((gfir_masked == 0x0) &&
 			    (gfir & GFIR_ERR_TRIGGER)) {
 				goto healthMonitor;
 			}
 
 			/* do not clear if we entered with a fatal gfir */
 			if (gfir_masked == 0x0) {
 
 				/* NEW clear by mask the logged bits */
 				sfir_addr = (uid << 24) + 0x100 + 0x08 * j;
 				__genwqe_writeq(cd, sfir_addr, sfir);
 
 				dev_dbg(&pci_dev->dev,
 					"[HM] Clearing  2ndary FIR 0x%08x with 0x%016llx\n",
 					sfir_addr, sfir);
 
 				/*
 				 * note, these cannot be error-Firs
 				 * since gfir_masked is 0 after sfir
 				 * was read. Also, it is safe to do
 				 * this write if sfir=0. Still need to
 				 * clear the primary. This just means
 				 * there is no secondary FIR.
 				 */
 
 				/* clear by mask the logged bit. */
 				fir_clr_addr = (uid << 24) + 0x10;
 				__genwqe_writeq(cd, fir_clr_addr, mask);
 
 				dev_dbg(&pci_dev->dev,
 					"[HM] Clearing primary FIR 0x%08x with 0x%016llx\n",
 					fir_clr_addr, mask);
 			}
 		}
 	}
 	gfir = __genwqe_readq(cd, IO_SLC_CFGREG_GFIR);
 	if (gfir == IO_ILLEGAL_VALUE)
 		goto fatal_error;
 
 	if ((gfir_masked == 0x0) && (gfir & GFIR_ERR_TRIGGER)) {
 		/*
 		 * Check once more that it didn't go on after all the
 		 * FIRS were cleared.
 		 */
 		dev_dbg(&pci_dev->dev, "ACK! Another FIR! Recursing %d!\n",
 			iterations);
 		goto healthMonitor;
 	}
 	return gfir_masked;
 
  fatal_error:
 	return IO_ILLEGAL_VALUE;
 }
 
 /**
  * genwqe_pci_fundamental_reset() - trigger a PCIe fundamental reset on the slot
  *
  * Note: pci_set_pcie_reset_state() is not implemented on all archs, so this
  * reset method will not work in all cases.
  *
  * Return: 0 on success or error code from pci_set_pcie_reset_state()
  */
 static int genwqe_pci_fundamental_reset(struct pci_dev *pci_dev)
 {
 	int rc;
 
 	/*
 	 * lock pci config space access from userspace,
 	 * save state and issue PCIe fundamental reset
 	 */
 	pci_cfg_access_lock(pci_dev);
 	pci_save_state(pci_dev);
 	rc = pci_set_pcie_reset_state(pci_dev, pcie_warm_reset);
 	if (!rc) {
 		/* keep PCIe reset asserted for 250ms */
 		msleep(250);
 		pci_set_pcie_reset_state(pci_dev, pcie_deassert_reset);
 		/* Wait for 2s to reload flash and train the link */
 		msleep(2000);
 	}
 	pci_restore_state(pci_dev);
 	pci_cfg_access_unlock(pci_dev);
 	return rc;
 }
 
 
 static int genwqe_platform_recovery(struct genwqe_dev *cd)
 {
 	struct pci_dev *pci_dev = cd->pci_dev;
 	int rc;
 
 	dev_info(&pci_dev->dev,
 		 "[%s] resetting card for error recovery\n", __func__);
 
 	/* Clear out error injection flags */
 	cd->err_inject &= ~(GENWQE_INJECT_HARDWARE_FAILURE |
 			    GENWQE_INJECT_GFIR_FATAL |
 			    GENWQE_INJECT_GFIR_INFO);
 
 	genwqe_stop(cd);
 
 	/* Try recoverying the card with fundamental reset */
 	rc = genwqe_pci_fundamental_reset(pci_dev);
 	if (!rc) {
 		rc = genwqe_start(cd);
 		if (!rc)
 			dev_info(&pci_dev->dev,
 				 "[%s] card recovered\n", __func__);
 		else
 			dev_err(&pci_dev->dev,
 				"[%s] err: cannot start card services! (err=%d)\n",
 				__func__, rc);
 	} else {
 		dev_err(&pci_dev->dev,
 			"[%s] card reset failed\n", __func__);
 	}
 
 	return rc;
 }
 
 /*
  * genwqe_reload_bistream() - reload card bitstream
  *
  * Set the appropriate register and call fundamental reset to reaload the card
  * bitstream.
  *
  * Return: 0 on success, error code otherwise
  */
 static int genwqe_reload_bistream(struct genwqe_dev *cd)
 {
 	struct pci_dev *pci_dev = cd->pci_dev;
 	int rc;
 
 	dev_info(&pci_dev->dev,
 		 "[%s] resetting card for bitstream reload\n",
 		 __func__);
 
 	genwqe_stop(cd);
 
 	/*
 	 * Cause a CPLD reprogram with the 'next_bitstream'
 	 * partition on PCIe hot or fundamental reset
 	 */
 	__genwqe_writeq(cd, IO_SLC_CFGREG_SOFTRESET,
 			(cd->softreset & 0xcull) | 0x70ull);
 
 	rc = genwqe_pci_fundamental_reset(pci_dev);
 	if (rc) {
 		/*
 		 * A fundamental reset failure can be caused
 		 * by lack of support on the arch, so we just
 		 * log the error and try to start the card
 		 * again.
 		 */
 		dev_err(&pci_dev->dev,
 			"[%s] err: failed to reset card for bitstream reload\n",
 			__func__);
 	}
 
 	rc = genwqe_start(cd);
 	if (rc) {
 		dev_err(&pci_dev->dev,
 			"[%s] err: cannot start card services! (err=%d)\n",
 			__func__, rc);
 		return rc;
 	}
 	dev_info(&pci_dev->dev,
 		 "[%s] card reloaded\n", __func__);
 	return 0;
 }
 
 
 /**
  * genwqe_health_thread() - Health checking thread
  *
  * This thread is only started for the PF of the card.
  *
  * This thread monitors the health of the card. A critical situation
  * is when we read registers which contain -1 (IO_ILLEGAL_VALUE). In
  * this case we need to be recovered from outside. Writing to
  * registers will very likely not work either.
  *
  * This thread must only exit if kthread_should_stop() becomes true.
  *
  * Condition for the health-thread to trigger:
  *   a) when a kthread_stop() request comes in or
  *   b) a critical GFIR occured
  *
  * Informational GFIRs are checked and potentially printed in
  * health_check_interval seconds.
  */
 static int genwqe_health_thread(void *data)
 {
 	int rc, should_stop = 0;
 	struct genwqe_dev *cd = data;
 	struct pci_dev *pci_dev = cd->pci_dev;
 	u64 gfir, gfir_masked, slu_unitcfg, app_unitcfg;
 
  health_thread_begin:
 	while (!kthread_should_stop()) {
 		rc = wait_event_interruptible_timeout(cd->health_waitq,
 			 (genwqe_health_check_cond(cd, &gfir) ||
 			  (should_stop = kthread_should_stop())),
 				genwqe_health_check_interval * HZ);
 
 		if (should_stop)
 			break;
 
 		if (gfir == IO_ILLEGAL_VALUE) {
 			dev_err(&pci_dev->dev,
 				"[%s] GFIR=%016llx\n", __func__, gfir);
 			goto fatal_error;
 		}
 
 		slu_unitcfg = __genwqe_readq(cd, IO_SLU_UNITCFG);
 		if (slu_unitcfg == IO_ILLEGAL_VALUE) {
 			dev_err(&pci_dev->dev,
 				"[%s] SLU_UNITCFG=%016llx\n",
 				__func__, slu_unitcfg);
 			goto fatal_error;
 		}
 
 		app_unitcfg = __genwqe_readq(cd, IO_APP_UNITCFG);
 		if (app_unitcfg == IO_ILLEGAL_VALUE) {
 			dev_err(&pci_dev->dev,
 				"[%s] APP_UNITCFG=%016llx\n",
 				__func__, app_unitcfg);
 			goto fatal_error;
 		}
 
 		gfir = __genwqe_readq(cd, IO_SLC_CFGREG_GFIR);
 		if (gfir == IO_ILLEGAL_VALUE) {
 			dev_err(&pci_dev->dev,
 				"[%s] %s: GFIR=%016llx\n", __func__,
 				(gfir & GFIR_ERR_TRIGGER) ? "err" : "info",
 				gfir);
 			goto fatal_error;
 		}
 
 		gfir_masked = genwqe_fir_checking(cd);
 		if (gfir_masked == IO_ILLEGAL_VALUE)
 			goto fatal_error;
 
 		/*
 		 * GFIR ErrorTrigger bits set => reset the card!
 		 * Never do this for old/manufacturing images!
 		 */
 		if ((gfir_masked) && !cd->skip_recovery &&
 		    genwqe_recovery_on_fatal_gfir_required(cd)) {
 
 			cd->card_state = GENWQE_CARD_FATAL_ERROR;
 
 			rc = genwqe_recover_card(cd, 0);
 			if (rc < 0) {
 				/* FIXME Card is unusable and needs unbind! */
 				goto fatal_error;
 			}
 		}
 
 		if (cd->card_state == GENWQE_CARD_RELOAD_BITSTREAM) {
 			/* Userspace requested card bitstream reload */
 			rc = genwqe_reload_bistream(cd);
 			if (rc)
 				goto fatal_error;
 		}
 
 		cd->last_gfir = gfir;
 		cond_resched();
 	}
 
 	return 0;
 
  fatal_error:
 	if (cd->use_platform_recovery) {
 		/*
 		 * Since we use raw accessors, EEH errors won't be detected
 		 * by the platform until we do a non-raw MMIO or config space
 		 * read
 		 */
 		readq(cd->mmio + IO_SLC_CFGREG_GFIR);
 
 		/* We do nothing if the card is going over PCI recovery */
 		if (pci_channel_offline(pci_dev))
 			return -EIO;
 
 		/*
 		 * If it's supported by the platform, we try a fundamental reset
 		 * to recover from a fatal error. Otherwise, we continue to wait
 		 * for an external recovery procedure to take care of it.
 		 */
 		rc = genwqe_platform_recovery(cd);
 		if (!rc)
 			goto health_thread_begin;
 	}
 
 	dev_err(&pci_dev->dev,
 		"[%s] card unusable. Please trigger unbind!\n", __func__);
 
 	/* Bring down logical devices to inform user space via udev remove. */
 	cd->card_state = GENWQE_CARD_FATAL_ERROR;
 	genwqe_stop(cd);
 
 	/* genwqe_bus_reset failed(). Now wait for genwqe_remove(). */
 	while (!kthread_should_stop())
 		cond_resched();
 
 	return -EIO;
 }
 
 static int genwqe_health_check_start(struct genwqe_dev *cd)
 {
 	int rc;
 
 	if (genwqe_health_check_interval <= 0)
 		return 0;	/* valid for disabling the service */
 
 	/* moved before request_irq() */
 	/* init_waitqueue_head(&cd->health_waitq); */
 
 	cd->health_thread = kthread_run(genwqe_health_thread, cd,
 					GENWQE_DEVNAME "%d_health",
 					cd->card_idx);
 	if (IS_ERR(cd->health_thread)) {
 		rc = PTR_ERR(cd->health_thread);
 		cd->health_thread = NULL;
 		return rc;
 	}
 	return 0;
 }
 
 static int genwqe_health_thread_running(struct genwqe_dev *cd)
 {
 	return cd->health_thread != NULL;
 }
 
 static int genwqe_health_check_stop(struct genwqe_dev *cd)
 {
 	int rc;
 
 	if (!genwqe_health_thread_running(cd))
 		return -EIO;
 
 	rc = kthread_stop(cd->health_thread);
 	cd->health_thread = NULL;
 	return 0;
 }
 
 /**
  * genwqe_pci_setup() - Allocate PCIe related resources for our card
  */
 static int genwqe_pci_setup(struct genwqe_dev *cd)
 {
 	int err;
 	struct pci_dev *pci_dev = cd->pci_dev;
 
 	err = pci_enable_device_mem(pci_dev);
 	if (err) {
 		dev_err(&pci_dev->dev,
 			"err: failed to enable pci memory (err=%d)\n", err);
 		goto err_out;
 	}
 
 	/* Reserve PCI I/O and memory resources */
 	err = pci_request_mem_regions(pci_dev, genwqe_driver_name);
 	if (err) {
 		dev_err(&pci_dev->dev,
 			"[%s] err: request bars failed (%d)\n", __func__, err);
 		err = -EIO;
 		goto err_disable_device;
 	}
 
 	/* check for 64-bit DMA address supported (DAC) */
 	if (!pci_set_dma_mask(pci_dev, DMA_BIT_MASK(64))) {
 		err = pci_set_consistent_dma_mask(pci_dev, DMA_BIT_MASK(64));
 		if (err) {
 			dev_err(&pci_dev->dev,
 				"err: DMA64 consistent mask error\n");
 			err = -EIO;
 			goto out_release_resources;
 		}
 	/* check for 32-bit DMA address supported (SAC) */
 	} else if (!pci_set_dma_mask(pci_dev, DMA_BIT_MASK(32))) {
 		err = pci_set_consistent_dma_mask(pci_dev, DMA_BIT_MASK(32));
 		if (err) {
 			dev_err(&pci_dev->dev,
 				"err: DMA32 consistent mask error\n");
 			err = -EIO;
 			goto out_release_resources;
 		}
 	} else {
 		dev_err(&pci_dev->dev,
 			"err: neither DMA32 nor DMA64 supported\n");
 		err = -EIO;
 		goto out_release_resources;
 	}
 
 	pci_set_master(pci_dev);
 	pci_enable_pcie_error_reporting(pci_dev);
 
 	/* EEH recovery requires PCIe fundamental reset */
 	pci_dev->needs_freset = 1;
 
 	/* request complete BAR-0 space (length = 0) */
 	cd->mmio_len = pci_resource_len(pci_dev, 0);
 	cd->mmio = pci_iomap(pci_dev, 0, 0);
 	if (cd->mmio == NULL) {
 		dev_err(&pci_dev->dev,
 			"[%s] err: mapping BAR0 failed\n", __func__);
 		err = -ENOMEM;
 		goto out_release_resources;
 	}
 
 	cd->num_vfs = pci_sriov_get_totalvfs(pci_dev);
 	if (cd->num_vfs < 0)
 		cd->num_vfs = 0;
 
 	err = genwqe_read_ids(cd);
 	if (err)
 		goto out_iounmap;
 
 	return 0;
 
  out_iounmap:
 	pci_iounmap(pci_dev, cd->mmio);
  out_release_resources:
 	pci_release_mem_regions(pci_dev);
  err_disable_device:
 	pci_disable_device(pci_dev);
  err_out:
 	return err;
 }
 
 /**
  * genwqe_pci_remove() - Free PCIe related resources for our card
  */
 static void genwqe_pci_remove(struct genwqe_dev *cd)
 {
 	struct pci_dev *pci_dev = cd->pci_dev;
 
 	if (cd->mmio)
 		pci_iounmap(pci_dev, cd->mmio);
 
 	pci_release_mem_regions(pci_dev);
 	pci_disable_device(pci_dev);
 }
 
 /**
  * genwqe_probe() - Device initialization
  * @pdev:	PCI device information struct
  *
  * Callable for multiple cards. This function is called on bind.
  *
  * Return: 0 if succeeded, < 0 when failed
  */
 static int genwqe_probe(struct pci_dev *pci_dev,
 			const struct pci_device_id *id)
 {
 	int err;
 	struct genwqe_dev *cd;
 
 	genwqe_init_crc32();
 
 	cd = genwqe_dev_alloc();
 	if (IS_ERR(cd)) {
 		dev_err(&pci_dev->dev, "err: could not alloc mem (err=%d)!\n",
 			(int)PTR_ERR(cd));
 		return PTR_ERR(cd);
 	}
 
 	dev_set_drvdata(&pci_dev->dev, cd);
 	cd->pci_dev = pci_dev;
 
 	err = genwqe_pci_setup(cd);
 	if (err < 0) {
 		dev_err(&pci_dev->dev,
 			"err: problems with PCI setup (err=%d)\n", err);
 		goto out_free_dev;
 	}
 
 	err = genwqe_start(cd);
 	if (err < 0) {
 		dev_err(&pci_dev->dev,
 			"err: cannot start card services! (err=%d)\n", err);
 		goto out_pci_remove;
 	}
 
 	if (genwqe_is_privileged(cd)) {
 		err = genwqe_health_check_start(cd);
 		if (err < 0) {
 			dev_err(&pci_dev->dev,
 				"err: cannot start health checking! (err=%d)\n",
 				err);
 			goto out_stop_services;
 		}
 	}
 	return 0;
 
  out_stop_services:
 	genwqe_stop(cd);
  out_pci_remove:
 	genwqe_pci_remove(cd);
  out_free_dev:
 	genwqe_dev_free(cd);
 	return err;
 }
 
 /**
  * genwqe_remove() - Called when device is removed (hot-plugable)
  *
  * Or when driver is unloaded respecitively when unbind is done.
  */
 static void genwqe_remove(struct pci_dev *pci_dev)
 {
 	struct genwqe_dev *cd = dev_get_drvdata(&pci_dev->dev);
 
 	genwqe_health_check_stop(cd);
 
 	/*
 	 * genwqe_stop() must survive if it is called twice
 	 * sequentially. This happens when the health thread calls it
 	 * and fails on genwqe_bus_reset().
 	 */
 	genwqe_stop(cd);
 	genwqe_pci_remove(cd);
 	genwqe_dev_free(cd);
 }
 
 /*
  * genwqe_err_error_detected() - Error detection callback
  *
  * This callback is called by the PCI subsystem whenever a PCI bus
  * error is detected.
  */
 static pci_ers_result_t genwqe_err_error_detected(struct pci_dev *pci_dev,
 						 enum pci_channel_state state)
 {
 	struct genwqe_dev *cd;
 
 	dev_err(&pci_dev->dev, "[%s] state=%d\n", __func__, state);
 
 	cd = dev_get_drvdata(&pci_dev->dev);
 	if (cd == NULL)
 		return PCI_ERS_RESULT_DISCONNECT;
 
 	/* Stop the card */
 	genwqe_health_check_stop(cd);
 	genwqe_stop(cd);
 
 	/*
 	 * On permanent failure, the PCI code will call device remove
 	 * after the return of this function.
 	 * genwqe_stop() can be called twice.
 	 */
 	if (state == pci_channel_io_perm_failure) {
 		return PCI_ERS_RESULT_DISCONNECT;
 	} else {
 		genwqe_pci_remove(cd);
 		return PCI_ERS_RESULT_NEED_RESET;
 	}
 }
 
 static pci_ers_result_t genwqe_err_slot_reset(struct pci_dev *pci_dev)
 {
 	int rc;
 	struct genwqe_dev *cd = dev_get_drvdata(&pci_dev->dev);
 
 	rc = genwqe_pci_setup(cd);
 	if (!rc) {
 		return PCI_ERS_RESULT_RECOVERED;
 	} else {
 		dev_err(&pci_dev->dev,
 			"err: problems with PCI setup (err=%d)\n", rc);
 		return PCI_ERS_RESULT_DISCONNECT;
 	}
 }
 
 static pci_ers_result_t genwqe_err_result_none(struct pci_dev *dev)
 {
 	return PCI_ERS_RESULT_NONE;
 }
 
 static void genwqe_err_resume(struct pci_dev *pci_dev)
 {
 	int rc;
 	struct genwqe_dev *cd = dev_get_drvdata(&pci_dev->dev);
 
 	rc = genwqe_start(cd);
 	if (!rc) {
 		rc = genwqe_health_check_start(cd);
 		if (rc)
 			dev_err(&pci_dev->dev,
 				"err: cannot start health checking! (err=%d)\n",
 				rc);
 	} else {
 		dev_err(&pci_dev->dev,
 			"err: cannot start card services! (err=%d)\n", rc);
 	}
 }
 
 static int genwqe_sriov_configure(struct pci_dev *dev, int numvfs)
 {
 	int rc;
 	struct genwqe_dev *cd = dev_get_drvdata(&dev->dev);
 
 	if (numvfs > 0) {
 		genwqe_setup_vf_jtimer(cd);
 		rc = pci_enable_sriov(dev, numvfs);
 		if (rc < 0)
 			return rc;
 		return numvfs;
 	}
 	if (numvfs == 0) {
 		pci_disable_sriov(dev);
 		return 0;
 	}
 	return 0;
 }
 
 static struct pci_error_handlers genwqe_err_handler = {
 	.error_detected = genwqe_err_error_detected,
 	.mmio_enabled	= genwqe_err_result_none,
-	.link_reset	= genwqe_err_result_none,
 	.slot_reset	= genwqe_err_slot_reset,
 	.resume		= genwqe_err_resume,
 };
 
 static struct pci_driver genwqe_driver = {
 	.name	  = genwqe_driver_name,
 	.id_table = genwqe_device_table,
 	.probe	  = genwqe_probe,
 	.remove	  = genwqe_remove,
 	.sriov_configure = genwqe_sriov_configure,
 	.err_handler = &genwqe_err_handler,
 };
 
 /**
  * genwqe_devnode() - Set default access mode for genwqe devices.
  *
  * Default mode should be rw for everybody. Do not change default
  * device name.
  */
 static char *genwqe_devnode(struct device *dev, umode_t *mode)
 {
 	if (mode)
 		*mode = 0666;
 	return NULL;
 }
 
 /**
  * genwqe_init_module() - Driver registration and initialization
  */
 static int __init genwqe_init_module(void)
 {
 	int rc;
 
 	class_genwqe = class_create(THIS_MODULE, GENWQE_DEVNAME);
 	if (IS_ERR(class_genwqe)) {
 		pr_err("[%s] create class failed\n", __func__);
 		return -ENOMEM;
 	}
 
 	class_genwqe->devnode = genwqe_devnode;
 
 	debugfs_genwqe = debugfs_create_dir(GENWQE_DEVNAME, NULL);
 	if (!debugfs_genwqe) {
 		rc = -ENOMEM;
 		goto err_out;
 	}
 
 	rc = pci_register_driver(&genwqe_driver);
 	if (rc != 0) {
 		pr_err("[%s] pci_reg_driver (rc=%d)\n", __func__, rc);
 		goto err_out0;
 	}
 
 	return rc;
 
  err_out0:
 	debugfs_remove(debugfs_genwqe);
  err_out:
 	class_destroy(class_genwqe);
 	return rc;
 }
 
 /**
  * genwqe_exit_module() - Driver exit
  */
 static void __exit genwqe_exit_module(void)
 {
 	pci_unregister_driver(&genwqe_driver);
 	debugfs_remove(debugfs_genwqe);
 	class_destroy(class_genwqe);
 }
 
 module_init(genwqe_init_module);
 module_exit(genwqe_exit_module);
diff --git a/drivers/misc/lkdtm_bugs.c b/drivers/misc/lkdtm_bugs.c
index cba0837aee2e..e3f4cd8876b5 100644
--- a/drivers/misc/lkdtm_bugs.c
+++ b/drivers/misc/lkdtm_bugs.c
@@ -1,276 +1,281 @@
 /*
  * This is for all the tests related to logic bugs (e.g. bad dereferences,
  * bad alignment, bad loops, bad locking, bad scheduling, deep stacks, and
  * lockups) along with other things that don't fit well into existing LKDTM
  * test source files.
  */
 #include "lkdtm.h"
 #include <linux/list.h>
 #include <linux/refcount.h>
 #include <linux/sched.h>
 
 struct lkdtm_list {
 	struct list_head node;
 };
 
 /*
  * Make sure our attempts to over run the kernel stack doesn't trigger
  * a compiler warning when CONFIG_FRAME_WARN is set. Then make sure we
  * recurse past the end of THREAD_SIZE by default.
  */
 #if defined(CONFIG_FRAME_WARN) && (CONFIG_FRAME_WARN > 0)
 #define REC_STACK_SIZE (CONFIG_FRAME_WARN / 2)
 #else
 #define REC_STACK_SIZE (THREAD_SIZE / 8)
 #endif
 #define REC_NUM_DEFAULT ((THREAD_SIZE / REC_STACK_SIZE) * 2)
 
 static int recur_count = REC_NUM_DEFAULT;
 
 static DEFINE_SPINLOCK(lock_me_up);
 
 static int recursive_loop(int remaining)
 {
 	char buf[REC_STACK_SIZE];
 
 	/* Make sure compiler does not optimize this away. */
 	memset(buf, (remaining & 0xff) | 0x1, REC_STACK_SIZE);
 	if (!remaining)
 		return 0;
 	else
 		return recursive_loop(remaining - 1);
 }
 
 /* If the depth is negative, use the default, otherwise keep parameter. */
 void __init lkdtm_bugs_init(int *recur_param)
 {
 	if (*recur_param < 0)
 		*recur_param = recur_count;
 	else
 		recur_count = *recur_param;
 }
 
 void lkdtm_PANIC(void)
 {
 	panic("dumptest");
 }
 
 void lkdtm_BUG(void)
 {
 	BUG();
 }
 
 void lkdtm_WARNING(void)
 {
 	WARN_ON(1);
 }
 
 void lkdtm_EXCEPTION(void)
 {
 	*((int *) 0) = 0;
 }
 
 void lkdtm_LOOP(void)
 {
 	for (;;)
 		;
 }
 
 void lkdtm_OVERFLOW(void)
 {
 	(void) recursive_loop(recur_count);
 }
 
+static noinline void __lkdtm_CORRUPT_STACK(void *stack)
+{
+	memset(stack, 'a', 64);
+}
+
 noinline void lkdtm_CORRUPT_STACK(void)
 {
 	/* Use default char array length that triggers stack protection. */
 	char data[8];
+	__lkdtm_CORRUPT_STACK(&data);
 
-	memset((void *)data, 'a', 64);
 	pr_info("Corrupted stack with '%16s'...\n", data);
 }
 
 void lkdtm_UNALIGNED_LOAD_STORE_WRITE(void)
 {
 	static u8 data[5] __attribute__((aligned(4))) = {1, 2, 3, 4, 5};
 	u32 *p;
 	u32 val = 0x12345678;
 
 	p = (u32 *)(data + 1);
 	if (*p == 0)
 		val = 0x87654321;
 	*p = val;
 }
 
 void lkdtm_SOFTLOCKUP(void)
 {
 	preempt_disable();
 	for (;;)
 		cpu_relax();
 }
 
 void lkdtm_HARDLOCKUP(void)
 {
 	local_irq_disable();
 	for (;;)
 		cpu_relax();
 }
 
 void lkdtm_SPINLOCKUP(void)
 {
 	/* Must be called twice to trigger. */
 	spin_lock(&lock_me_up);
 	/* Let sparse know we intended to exit holding the lock. */
 	__release(&lock_me_up);
 }
 
 void lkdtm_HUNG_TASK(void)
 {
 	set_current_state(TASK_UNINTERRUPTIBLE);
 	schedule();
 }
 
 void lkdtm_REFCOUNT_SATURATE_INC(void)
 {
 	refcount_t over = REFCOUNT_INIT(UINT_MAX - 1);
 
 	pr_info("attempting good refcount decrement\n");
 	refcount_dec(&over);
 	refcount_inc(&over);
 
 	pr_info("attempting bad refcount inc overflow\n");
 	refcount_inc(&over);
 	refcount_inc(&over);
 	if (refcount_read(&over) == UINT_MAX)
 		pr_err("Correctly stayed saturated, but no BUG?!\n");
 	else
 		pr_err("Fail: refcount wrapped\n");
 }
 
 void lkdtm_REFCOUNT_SATURATE_ADD(void)
 {
 	refcount_t over = REFCOUNT_INIT(UINT_MAX - 1);
 
 	pr_info("attempting good refcount decrement\n");
 	refcount_dec(&over);
 	refcount_inc(&over);
 
 	pr_info("attempting bad refcount add overflow\n");
 	refcount_add(2, &over);
 	if (refcount_read(&over) == UINT_MAX)
 		pr_err("Correctly stayed saturated, but no BUG?!\n");
 	else
 		pr_err("Fail: refcount wrapped\n");
 }
 
 void lkdtm_REFCOUNT_ZERO_DEC(void)
 {
 	refcount_t zero = REFCOUNT_INIT(1);
 
 	pr_info("attempting bad refcount decrement to zero\n");
 	refcount_dec(&zero);
 	if (refcount_read(&zero) == 0)
 		pr_err("Stayed at zero, but no BUG?!\n");
 	else
 		pr_err("Fail: refcount went crazy\n");
 }
 
 void lkdtm_REFCOUNT_ZERO_SUB(void)
 {
 	refcount_t zero = REFCOUNT_INIT(1);
 
 	pr_info("attempting bad refcount subtract past zero\n");
 	if (!refcount_sub_and_test(2, &zero))
 		pr_info("wrap attempt was noticed\n");
 	if (refcount_read(&zero) == 1)
 		pr_err("Correctly stayed above 0, but no BUG?!\n");
 	else
 		pr_err("Fail: refcount wrapped\n");
 }
 
 void lkdtm_REFCOUNT_ZERO_INC(void)
 {
 	refcount_t zero = REFCOUNT_INIT(0);
 
 	pr_info("attempting bad refcount increment from zero\n");
 	refcount_inc(&zero);
 	if (refcount_read(&zero) == 0)
 		pr_err("Stayed at zero, but no BUG?!\n");
 	else
 		pr_err("Fail: refcount went past zero\n");
 }
 
 void lkdtm_REFCOUNT_ZERO_ADD(void)
 {
 	refcount_t zero = REFCOUNT_INIT(0);
 
 	pr_info("attempting bad refcount addition from zero\n");
 	refcount_add(2, &zero);
 	if (refcount_read(&zero) == 0)
 		pr_err("Stayed at zero, but no BUG?!\n");
 	else
 		pr_err("Fail: refcount went past zero\n");
 }
 
 void lkdtm_CORRUPT_LIST_ADD(void)
 {
 	/*
 	 * Initially, an empty list via LIST_HEAD:
 	 *	test_head.next = &test_head
 	 *	test_head.prev = &test_head
 	 */
 	LIST_HEAD(test_head);
 	struct lkdtm_list good, bad;
 	void *target[2] = { };
 	void *redirection = &target;
 
 	pr_info("attempting good list addition\n");
 
 	/*
 	 * Adding to the list performs these actions:
 	 *	test_head.next->prev = &good.node
 	 *	good.node.next = test_head.next
 	 *	good.node.prev = test_head
 	 *	test_head.next = good.node
 	 */
 	list_add(&good.node, &test_head);
 
 	pr_info("attempting corrupted list addition\n");
 	/*
 	 * In simulating this "write what where" primitive, the "what" is
 	 * the address of &bad.node, and the "where" is the address held
 	 * by "redirection".
 	 */
 	test_head.next = redirection;
 	list_add(&bad.node, &test_head);
 
 	if (target[0] == NULL && target[1] == NULL)
 		pr_err("Overwrite did not happen, but no BUG?!\n");
 	else
 		pr_err("list_add() corruption not detected!\n");
 }
 
 void lkdtm_CORRUPT_LIST_DEL(void)
 {
 	LIST_HEAD(test_head);
 	struct lkdtm_list item;
 	void *target[2] = { };
 	void *redirection = &target;
 
 	list_add(&item.node, &test_head);
 
 	pr_info("attempting good list removal\n");
 	list_del(&item.node);
 
 	pr_info("attempting corrupted list removal\n");
 	list_add(&item.node, &test_head);
 
 	/* As with the list_add() test above, this corrupts "next". */
 	item.node.next = redirection;
 	list_del(&item.node);
 
 	if (target[0] == NULL && target[1] == NULL)
 		pr_err("Overwrite did not happen, but no BUG?!\n");
 	else
 		pr_err("list_del() corruption not detected!\n");
 }
diff --git a/drivers/misc/lkdtm_core.c b/drivers/misc/lkdtm_core.c
index 16e4cf110930..b9a4cd4a9b68 100644
--- a/drivers/misc/lkdtm_core.c
+++ b/drivers/misc/lkdtm_core.c
@@ -1,550 +1,552 @@
 /*
  * Linux Kernel Dump Test Module for testing kernel crashes conditions:
  * induces system failures at predefined crashpoints and under predefined
  * operational conditions in order to evaluate the reliability of kernel
  * sanity checking and crash dumps obtained using different dumping
  * solutions.
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
  * the Free Software Foundation; either version 2 of the License, or
  * (at your option) any later version.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
  *
  * You should have received a copy of the GNU General Public License
  * along with this program; if not, write to the Free Software
  * Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.
  *
  * Copyright (C) IBM Corporation, 2006
  *
  * Author: Ankita Garg <ankita@in.ibm.com>
  *
  * It is adapted from the Linux Kernel Dump Test Tool by
  * Fernando Luis Vazquez Cao <http://lkdtt.sourceforge.net>
  *
  * Debugfs support added by Simon Kagstrom <simon.kagstrom@netinsight.net>
  *
  * See Documentation/fault-injection/provoke-crashes.txt for instructions
  */
 #include "lkdtm.h"
 #include <linux/fs.h>
 #include <linux/module.h>
 #include <linux/buffer_head.h>
 #include <linux/kprobes.h>
 #include <linux/list.h>
 #include <linux/init.h>
 #include <linux/interrupt.h>
 #include <linux/hrtimer.h>
 #include <linux/slab.h>
 #include <scsi/scsi_cmnd.h>
 #include <linux/debugfs.h>
 
 #ifdef CONFIG_IDE
 #include <linux/ide.h>
 #endif
 
 #define DEFAULT_COUNT 10
 
 static int lkdtm_debugfs_open(struct inode *inode, struct file *file);
 static ssize_t lkdtm_debugfs_read(struct file *f, char __user *user_buf,
 		size_t count, loff_t *off);
 static ssize_t direct_entry(struct file *f, const char __user *user_buf,
 			    size_t count, loff_t *off);
 
 #ifdef CONFIG_KPROBES
 static void lkdtm_handler(void);
 static ssize_t lkdtm_debugfs_entry(struct file *f,
 				   const char __user *user_buf,
 				   size_t count, loff_t *off);
 
 
 /* jprobe entry point handlers. */
 static unsigned int jp_do_irq(unsigned int irq)
 {
 	lkdtm_handler();
 	jprobe_return();
 	return 0;
 }
 
 static irqreturn_t jp_handle_irq_event(unsigned int irq,
 				       struct irqaction *action)
 {
 	lkdtm_handler();
 	jprobe_return();
 	return 0;
 }
 
 static void jp_tasklet_action(struct softirq_action *a)
 {
 	lkdtm_handler();
 	jprobe_return();
 }
 
 static void jp_ll_rw_block(int rw, int nr, struct buffer_head *bhs[])
 {
 	lkdtm_handler();
 	jprobe_return();
 }
 
 struct scan_control;
 
 static unsigned long jp_shrink_inactive_list(unsigned long max_scan,
 					     struct zone *zone,
 					     struct scan_control *sc)
 {
 	lkdtm_handler();
 	jprobe_return();
 	return 0;
 }
 
 static int jp_hrtimer_start(struct hrtimer *timer, ktime_t tim,
 			    const enum hrtimer_mode mode)
 {
 	lkdtm_handler();
 	jprobe_return();
 	return 0;
 }
 
 static int jp_scsi_dispatch_cmd(struct scsi_cmnd *cmd)
 {
 	lkdtm_handler();
 	jprobe_return();
 	return 0;
 }
 
 # ifdef CONFIG_IDE
 static int jp_generic_ide_ioctl(ide_drive_t *drive, struct file *file,
 			struct block_device *bdev, unsigned int cmd,
 			unsigned long arg)
 {
 	lkdtm_handler();
 	jprobe_return();
 	return 0;
 }
 # endif
 #endif
 
 /* Crash points */
 struct crashpoint {
 	const char *name;
 	const struct file_operations fops;
 	struct jprobe jprobe;
 };
 
 #define CRASHPOINT(_name, _write, _symbol, _entry)		\
 	{							\
 		.name = _name,					\
 		.fops = {					\
 			.read	= lkdtm_debugfs_read,		\
 			.llseek	= generic_file_llseek,		\
 			.open	= lkdtm_debugfs_open,		\
 			.write	= _write,			\
 		},						\
 		.jprobe = {					\
 			.kp.symbol_name = _symbol,		\
 			.entry = (kprobe_opcode_t *)_entry,	\
 		},						\
 	}
 
 /* Define the possible places where we can trigger a crash point. */
 struct crashpoint crashpoints[] = {
 	CRASHPOINT("DIRECT",			direct_entry,
 		   NULL,			NULL),
 #ifdef CONFIG_KPROBES
 	CRASHPOINT("INT_HARDWARE_ENTRY",	lkdtm_debugfs_entry,
 		   "do_IRQ",			jp_do_irq),
 	CRASHPOINT("INT_HW_IRQ_EN",		lkdtm_debugfs_entry,
 		   "handle_IRQ_event",		jp_handle_irq_event),
 	CRASHPOINT("INT_TASKLET_ENTRY",		lkdtm_debugfs_entry,
 		   "tasklet_action",		jp_tasklet_action),
 	CRASHPOINT("FS_DEVRW",			lkdtm_debugfs_entry,
 		   "ll_rw_block",		jp_ll_rw_block),
 	CRASHPOINT("MEM_SWAPOUT",		lkdtm_debugfs_entry,
 		   "shrink_inactive_list",	jp_shrink_inactive_list),
 	CRASHPOINT("TIMERADD",			lkdtm_debugfs_entry,
 		   "hrtimer_start",		jp_hrtimer_start),
 	CRASHPOINT("SCSI_DISPATCH_CMD",		lkdtm_debugfs_entry,
 		   "scsi_dispatch_cmd",		jp_scsi_dispatch_cmd),
 # ifdef CONFIG_IDE
 	CRASHPOINT("IDE_CORE_CP",		lkdtm_debugfs_entry,
 		   "generic_ide_ioctl",		jp_generic_ide_ioctl),
 # endif
 #endif
 };
 
 
 /* Crash types. */
 struct crashtype {
 	const char *name;
 	void (*func)(void);
 };
 
 #define CRASHTYPE(_name)			\
 	{					\
 		.name = __stringify(_name),	\
 		.func = lkdtm_ ## _name,	\
 	}
 
 /* Define the possible types of crashes that can be triggered. */
 struct crashtype crashtypes[] = {
 	CRASHTYPE(PANIC),
 	CRASHTYPE(BUG),
 	CRASHTYPE(WARNING),
 	CRASHTYPE(EXCEPTION),
 	CRASHTYPE(LOOP),
 	CRASHTYPE(OVERFLOW),
 	CRASHTYPE(CORRUPT_LIST_ADD),
 	CRASHTYPE(CORRUPT_LIST_DEL),
 	CRASHTYPE(CORRUPT_STACK),
 	CRASHTYPE(UNALIGNED_LOAD_STORE_WRITE),
 	CRASHTYPE(OVERWRITE_ALLOCATION),
 	CRASHTYPE(WRITE_AFTER_FREE),
 	CRASHTYPE(READ_AFTER_FREE),
 	CRASHTYPE(WRITE_BUDDY_AFTER_FREE),
 	CRASHTYPE(READ_BUDDY_AFTER_FREE),
 	CRASHTYPE(SOFTLOCKUP),
 	CRASHTYPE(HARDLOCKUP),
 	CRASHTYPE(SPINLOCKUP),
 	CRASHTYPE(HUNG_TASK),
 	CRASHTYPE(EXEC_DATA),
 	CRASHTYPE(EXEC_STACK),
 	CRASHTYPE(EXEC_KMALLOC),
 	CRASHTYPE(EXEC_VMALLOC),
 	CRASHTYPE(EXEC_RODATA),
 	CRASHTYPE(EXEC_USERSPACE),
 	CRASHTYPE(ACCESS_USERSPACE),
 	CRASHTYPE(WRITE_RO),
 	CRASHTYPE(WRITE_RO_AFTER_INIT),
 	CRASHTYPE(WRITE_KERN),
 	CRASHTYPE(REFCOUNT_SATURATE_INC),
 	CRASHTYPE(REFCOUNT_SATURATE_ADD),
 	CRASHTYPE(REFCOUNT_ZERO_DEC),
 	CRASHTYPE(REFCOUNT_ZERO_INC),
 	CRASHTYPE(REFCOUNT_ZERO_SUB),
 	CRASHTYPE(REFCOUNT_ZERO_ADD),
 	CRASHTYPE(USERCOPY_HEAP_SIZE_TO),
 	CRASHTYPE(USERCOPY_HEAP_SIZE_FROM),
 	CRASHTYPE(USERCOPY_HEAP_FLAG_TO),
 	CRASHTYPE(USERCOPY_HEAP_FLAG_FROM),
 	CRASHTYPE(USERCOPY_STACK_FRAME_TO),
 	CRASHTYPE(USERCOPY_STACK_FRAME_FROM),
 	CRASHTYPE(USERCOPY_STACK_BEYOND),
 	CRASHTYPE(USERCOPY_KERNEL),
 };
 
 
 /* Global jprobe entry and crashtype. */
 static struct jprobe *lkdtm_jprobe;
 struct crashpoint *lkdtm_crashpoint;
 struct crashtype *lkdtm_crashtype;
 
 /* Module parameters */
 static int recur_count = -1;
 module_param(recur_count, int, 0644);
 MODULE_PARM_DESC(recur_count, " Recursion level for the stack overflow test");
 
 static char* cpoint_name;
 module_param(cpoint_name, charp, 0444);
 MODULE_PARM_DESC(cpoint_name, " Crash Point, where kernel is to be crashed");
 
 static char* cpoint_type;
 module_param(cpoint_type, charp, 0444);
 MODULE_PARM_DESC(cpoint_type, " Crash Point Type, action to be taken on "\
 				"hitting the crash point");
 
 static int cpoint_count = DEFAULT_COUNT;
 module_param(cpoint_count, int, 0644);
 MODULE_PARM_DESC(cpoint_count, " Crash Point Count, number of times the "\
 				"crash point is to be hit to trigger action");
 
 
 /* Return the crashtype number or NULL if the name is invalid */
 static struct crashtype *find_crashtype(const char *name)
 {
 	int i;
 
 	for (i = 0; i < ARRAY_SIZE(crashtypes); i++) {
 		if (!strcmp(name, crashtypes[i].name))
 			return &crashtypes[i];
 	}
 
 	return NULL;
 }
 
 /*
  * This is forced noinline just so it distinctly shows up in the stackdump
  * which makes validation of expected lkdtm crashes easier.
  */
 static noinline void lkdtm_do_action(struct crashtype *crashtype)
 {
 	BUG_ON(!crashtype || !crashtype->func);
 	crashtype->func();
 }
 
 static int lkdtm_register_cpoint(struct crashpoint *crashpoint,
 				 struct crashtype *crashtype)
 {
 	int ret;
 
 	/* If this doesn't have a symbol, just call immediately. */
 	if (!crashpoint->jprobe.kp.symbol_name) {
 		lkdtm_do_action(crashtype);
 		return 0;
 	}
 
 	if (lkdtm_jprobe != NULL)
 		unregister_jprobe(lkdtm_jprobe);
 
 	lkdtm_crashpoint = crashpoint;
 	lkdtm_crashtype = crashtype;
 	lkdtm_jprobe = &crashpoint->jprobe;
 	ret = register_jprobe(lkdtm_jprobe);
 	if (ret < 0) {
 		pr_info("Couldn't register jprobe %s\n",
 			crashpoint->jprobe.kp.symbol_name);
 		lkdtm_jprobe = NULL;
 		lkdtm_crashpoint = NULL;
 		lkdtm_crashtype = NULL;
 	}
 
 	return ret;
 }
 
 #ifdef CONFIG_KPROBES
 /* Global crash counter and spinlock. */
 static int crash_count = DEFAULT_COUNT;
 static DEFINE_SPINLOCK(crash_count_lock);
 
 /* Called by jprobe entry points. */
 static void lkdtm_handler(void)
 {
 	unsigned long flags;
 	bool do_it = false;
 
 	BUG_ON(!lkdtm_crashpoint || !lkdtm_crashtype);
 
 	spin_lock_irqsave(&crash_count_lock, flags);
 	crash_count--;
 	pr_info("Crash point %s of type %s hit, trigger in %d rounds\n",
 		lkdtm_crashpoint->name, lkdtm_crashtype->name, crash_count);
 
 	if (crash_count == 0) {
 		do_it = true;
 		crash_count = cpoint_count;
 	}
 	spin_unlock_irqrestore(&crash_count_lock, flags);
 
 	if (do_it)
 		lkdtm_do_action(lkdtm_crashtype);
 }
 
 static ssize_t lkdtm_debugfs_entry(struct file *f,
 				   const char __user *user_buf,
 				   size_t count, loff_t *off)
 {
 	struct crashpoint *crashpoint = file_inode(f)->i_private;
 	struct crashtype *crashtype = NULL;
 	char *buf;
 	int err;
 
 	if (count >= PAGE_SIZE)
 		return -EINVAL;
 
 	buf = (char *)__get_free_page(GFP_KERNEL);
 	if (!buf)
 		return -ENOMEM;
 	if (copy_from_user(buf, user_buf, count)) {
 		free_page((unsigned long) buf);
 		return -EFAULT;
 	}
 	/* NULL-terminate and remove enter */
 	buf[count] = '\0';
 	strim(buf);
 
 	crashtype = find_crashtype(buf);
 	free_page((unsigned long)buf);
 
 	if (!crashtype)
 		return -EINVAL;
 
 	err = lkdtm_register_cpoint(crashpoint, crashtype);
 	if (err < 0)
 		return err;
 
 	*off += count;
 
 	return count;
 }
 #endif
 
 /* Generic read callback that just prints out the available crash types */
 static ssize_t lkdtm_debugfs_read(struct file *f, char __user *user_buf,
 		size_t count, loff_t *off)
 {
 	char *buf;
 	int i, n, out;
 
 	buf = (char *)__get_free_page(GFP_KERNEL);
 	if (buf == NULL)
 		return -ENOMEM;
 
 	n = snprintf(buf, PAGE_SIZE, "Available crash types:\n");
 	for (i = 0; i < ARRAY_SIZE(crashtypes); i++) {
 		n += snprintf(buf + n, PAGE_SIZE - n, "%s\n",
 			      crashtypes[i].name);
 	}
 	buf[n] = '\0';
 
 	out = simple_read_from_buffer(user_buf, count, off,
 				      buf, n);
 	free_page((unsigned long) buf);
 
 	return out;
 }
 
 static int lkdtm_debugfs_open(struct inode *inode, struct file *file)
 {
 	return 0;
 }
 
 /* Special entry to just crash directly. Available without KPROBEs */
 static ssize_t direct_entry(struct file *f, const char __user *user_buf,
 		size_t count, loff_t *off)
 {
 	struct crashtype *crashtype;
 	char *buf;
 
 	if (count >= PAGE_SIZE)
 		return -EINVAL;
 	if (count < 1)
 		return -EINVAL;
 
 	buf = (char *)__get_free_page(GFP_KERNEL);
 	if (!buf)
 		return -ENOMEM;
 	if (copy_from_user(buf, user_buf, count)) {
 		free_page((unsigned long) buf);
 		return -EFAULT;
 	}
 	/* NULL-terminate and remove enter */
 	buf[count] = '\0';
 	strim(buf);
 
 	crashtype = find_crashtype(buf);
 	free_page((unsigned long) buf);
 	if (!crashtype)
 		return -EINVAL;
 
 	pr_info("Performing direct entry %s\n", crashtype->name);
 	lkdtm_do_action(crashtype);
 	*off += count;
 
 	return count;
 }
 
 static struct dentry *lkdtm_debugfs_root;
 
 static int __init lkdtm_module_init(void)
 {
 	struct crashpoint *crashpoint = NULL;
 	struct crashtype *crashtype = NULL;
 	int ret = -EINVAL;
 	int i;
 
 	/* Neither or both of these need to be set */
 	if ((cpoint_type || cpoint_name) && !(cpoint_type && cpoint_name)) {
 		pr_err("Need both cpoint_type and cpoint_name or neither\n");
 		return -EINVAL;
 	}
 
 	if (cpoint_type) {
 		crashtype = find_crashtype(cpoint_type);
 		if (!crashtype) {
 			pr_err("Unknown crashtype '%s'\n", cpoint_type);
 			return -EINVAL;
 		}
 	}
 
 	if (cpoint_name) {
 		for (i = 0; i < ARRAY_SIZE(crashpoints); i++) {
 			if (!strcmp(cpoint_name, crashpoints[i].name))
 				crashpoint = &crashpoints[i];
 		}
 
 		/* Refuse unknown crashpoints. */
 		if (!crashpoint) {
 			pr_err("Invalid crashpoint %s\n", cpoint_name);
 			return -EINVAL;
 		}
 	}
 
 #ifdef CONFIG_KPROBES
 	/* Set crash count. */
 	crash_count = cpoint_count;
 #endif
 
 	/* Handle test-specific initialization. */
 	lkdtm_bugs_init(&recur_count);
 	lkdtm_perms_init();
 	lkdtm_usercopy_init();
 
 	/* Register debugfs interface */
 	lkdtm_debugfs_root = debugfs_create_dir("provoke-crash", NULL);
 	if (!lkdtm_debugfs_root) {
 		pr_err("creating root dir failed\n");
 		return -ENODEV;
 	}
 
 	/* Install debugfs trigger files. */
 	for (i = 0; i < ARRAY_SIZE(crashpoints); i++) {
 		struct crashpoint *cur = &crashpoints[i];
 		struct dentry *de;
 
 		de = debugfs_create_file(cur->name, 0644, lkdtm_debugfs_root,
 					 cur, &cur->fops);
 		if (de == NULL) {
 			pr_err("could not create crashpoint %s\n", cur->name);
 			goto out_err;
 		}
 	}
 
 	/* Install crashpoint if one was selected. */
 	if (crashpoint) {
 		ret = lkdtm_register_cpoint(crashpoint, crashtype);
 		if (ret < 0) {
 			pr_info("Invalid crashpoint %s\n", crashpoint->name);
 			goto out_err;
 		}
 		pr_info("Crash point %s of type %s registered\n",
 			crashpoint->name, cpoint_type);
 	} else {
 		pr_info("No crash points registered, enable through debugfs\n");
 	}
 
 	return 0;
 
 out_err:
 	debugfs_remove_recursive(lkdtm_debugfs_root);
 	return ret;
 }
 
 static void __exit lkdtm_module_exit(void)
 {
 	debugfs_remove_recursive(lkdtm_debugfs_root);
 
 	/* Handle test-specific clean-up. */
 	lkdtm_usercopy_exit();
 
-	unregister_jprobe(lkdtm_jprobe);
+	if (lkdtm_jprobe != NULL)
+		unregister_jprobe(lkdtm_jprobe);
+
 	pr_info("Crash point unregistered\n");
 }
 
 module_init(lkdtm_module_init);
 module_exit(lkdtm_module_exit);
 
 MODULE_LICENSE("GPL");
 MODULE_DESCRIPTION("Kernel crash testing module");
diff --git a/drivers/misc/mei/amthif.c b/drivers/misc/mei/amthif.c
index 466afb2611c6..0e7406ccb6dd 100644
--- a/drivers/misc/mei/amthif.c
+++ b/drivers/misc/mei/amthif.c
@@ -1,361 +1,340 @@
 /*
  *
  * Intel Management Engine Interface (Intel MEI) Linux driver
  * Copyright (c) 2003-2012, Intel Corporation.
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms and conditions of the GNU General Public License,
  * version 2, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope it will be useful, but WITHOUT
  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
  * more details.
  *
  */
 
 #include <linux/kernel.h>
 #include <linux/fs.h>
 #include <linux/errno.h>
 #include <linux/types.h>
 #include <linux/fcntl.h>
 #include <linux/ioctl.h>
 #include <linux/cdev.h>
 #include <linux/list.h>
 #include <linux/delay.h>
 #include <linux/sched.h>
 #include <linux/uuid.h>
 #include <linux/jiffies.h>
 #include <linux/uaccess.h>
 #include <linux/slab.h>
 
 #include <linux/mei.h>
 
 #include "mei_dev.h"
 #include "hbm.h"
 #include "client.h"
 
 const uuid_le mei_amthif_guid  = UUID_LE(0x12f80028, 0xb4b7, 0x4b2d,
 					 0xac, 0xa8, 0x46, 0xe0,
 					 0xff, 0x65, 0x81, 0x4c);
 
 /**
  * mei_amthif_reset_params - initializes mei device iamthif
  *
  * @dev: the device structure
  */
 void mei_amthif_reset_params(struct mei_device *dev)
 {
 	/* reset iamthif parameters. */
 	dev->iamthif_canceled = false;
 	dev->iamthif_state = MEI_IAMTHIF_IDLE;
 	dev->iamthif_stall_timer = 0;
 	dev->iamthif_open_count = 0;
 }
 
 /**
  * mei_amthif_host_init - mei initialization amthif client.
  *
  * @dev: the device structure
  * @me_cl: me client
  *
  * Return: 0 on success, <0 on failure.
  */
 int mei_amthif_host_init(struct mei_device *dev, struct mei_me_client *me_cl)
 {
 	struct mei_cl *cl = &dev->iamthif_cl;
 	int ret;
 
 	mutex_lock(&dev->device_lock);
 
 	if (mei_cl_is_connected(cl)) {
 		ret = 0;
 		goto out;
 	}
 
 	dev->iamthif_state = MEI_IAMTHIF_IDLE;
 
 	mei_cl_init(cl, dev);
 
 	ret = mei_cl_link(cl);
 	if (ret < 0) {
 		dev_err(dev->dev, "amthif: failed cl_link %d\n", ret);
 		goto out;
 	}
 
 	ret = mei_cl_connect(cl, me_cl, NULL);
 
 out:
 	mutex_unlock(&dev->device_lock);
 	return ret;
 }
 
 /**
  * mei_amthif_read_start - queue message for sending read credential
  *
  * @cl: host client
  * @fp: file pointer of message recipient
  *
  * Return: 0 on success, <0 on failure.
  */
 static int mei_amthif_read_start(struct mei_cl *cl, const struct file *fp)
 {
 	struct mei_device *dev = cl->dev;
 	struct mei_cl_cb *cb;
 
 	cb = mei_cl_enqueue_ctrl_wr_cb(cl, mei_cl_mtu(cl), MEI_FOP_READ, fp);
 	if (!cb)
 		return -ENOMEM;
 
 	cl->rx_flow_ctrl_creds++;
 
 	dev->iamthif_state = MEI_IAMTHIF_READING;
 	cl->fp = cb->fp;
 
 	return 0;
 }
 
 /**
  * mei_amthif_run_next_cmd - send next amt command from queue
  *
  * @dev: the device structure
  *
  * Return: 0 on success, <0 on failure.
  */
 int mei_amthif_run_next_cmd(struct mei_device *dev)
 {
 	struct mei_cl *cl = &dev->iamthif_cl;
 	struct mei_cl_cb *cb;
 	int ret;
 
 	dev->iamthif_canceled = false;
 
 	dev_dbg(dev->dev, "complete amthif cmd_list cb.\n");
 
-	cb = list_first_entry_or_null(&dev->amthif_cmd_list.list,
-					typeof(*cb), list);
+	cb = list_first_entry_or_null(&dev->amthif_cmd_list, typeof(*cb), list);
 	if (!cb) {
 		dev->iamthif_state = MEI_IAMTHIF_IDLE;
 		cl->fp = NULL;
 		return 0;
 	}
 
 	list_del_init(&cb->list);
 	dev->iamthif_state = MEI_IAMTHIF_WRITING;
 	cl->fp = cb->fp;
 
 	ret = mei_cl_write(cl, cb);
 	if (ret < 0)
 		return ret;
 
 	if (cb->completed)
 		cb->status = mei_amthif_read_start(cl, cb->fp);
 
 	return 0;
 }
 
 /**
  * mei_amthif_write - write amthif data to amthif client
  *
  * @cl: host client
  * @cb: mei call back struct
  *
  * Return: 0 on success, <0 on failure.
  */
 int mei_amthif_write(struct mei_cl *cl, struct mei_cl_cb *cb)
 {
 
 	struct mei_device *dev = cl->dev;
 
-	list_add_tail(&cb->list, &dev->amthif_cmd_list.list);
+	list_add_tail(&cb->list, &dev->amthif_cmd_list);
 
 	/*
 	 * The previous request is still in processing, queue this one.
 	 */
 	if (dev->iamthif_state != MEI_IAMTHIF_IDLE)
 		return 0;
 
 	return mei_amthif_run_next_cmd(dev);
 }
 
 /**
  * mei_amthif_poll - the amthif poll function
  *
  * @file: pointer to file structure
  * @wait: pointer to poll_table structure
  *
  * Return: poll mask
  *
  * Locking: called under "dev->device_lock" lock
  */
 unsigned int mei_amthif_poll(struct file *file, poll_table *wait)
 {
 	struct mei_cl *cl = file->private_data;
 	struct mei_cl_cb *cb = mei_cl_read_cb(cl, file);
 	unsigned int mask = 0;
 
 	poll_wait(file, &cl->rx_wait, wait);
 	if (cb)
 		mask |= POLLIN | POLLRDNORM;
 
 	return mask;
 }
 
 /**
  * mei_amthif_irq_write - write iamthif command in irq thread context.
  *
  * @cl: private data of the file object.
  * @cb: callback block.
  * @cmpl_list: complete list.
  *
  * Return: 0, OK; otherwise, error.
  */
 int mei_amthif_irq_write(struct mei_cl *cl, struct mei_cl_cb *cb,
-			 struct mei_cl_cb *cmpl_list)
+			 struct list_head *cmpl_list)
 {
 	int ret;
 
 	ret = mei_cl_irq_write(cl, cb, cmpl_list);
 	if (ret)
 		return ret;
 
 	if (cb->completed)
 		cb->status = mei_amthif_read_start(cl, cb->fp);
 
 	return 0;
 }
 
 /**
  * mei_amthif_irq_read_msg - read routine after ISR to
  *			handle the read amthif message
  *
  * @cl: mei client
  * @mei_hdr: header of amthif message
  * @cmpl_list: completed callbacks list
  *
  * Return: -ENODEV if cb is NULL 0 otherwise; error message is in cb->status
  */
 int mei_amthif_irq_read_msg(struct mei_cl *cl,
 			    struct mei_msg_hdr *mei_hdr,
-			    struct mei_cl_cb *cmpl_list)
+			    struct list_head *cmpl_list)
 {
 	struct mei_device *dev;
 	int ret;
 
 	dev = cl->dev;
 
 	if (dev->iamthif_state != MEI_IAMTHIF_READING) {
 		mei_irq_discard_msg(dev, mei_hdr);
 		return 0;
 	}
 
 	ret = mei_cl_irq_read_msg(cl, mei_hdr, cmpl_list);
 	if (ret)
 		return ret;
 
 	if (!mei_hdr->msg_complete)
 		return 0;
 
 	dev_dbg(dev->dev, "completed amthif read.\n ");
 	dev->iamthif_stall_timer = 0;
 
 	return 0;
 }
 
 /**
  * mei_amthif_complete - complete amthif callback.
  *
  * @cl: host client
  * @cb: callback block.
  */
 void mei_amthif_complete(struct mei_cl *cl, struct mei_cl_cb *cb)
 {
 	struct mei_device *dev = cl->dev;
 
 	dev_dbg(dev->dev, "completing amthif call back.\n");
 	switch (cb->fop_type) {
 	case MEI_FOP_WRITE:
 		if (!cb->status) {
 			dev->iamthif_stall_timer = MEI_IAMTHIF_STALL_TIMER;
 			mei_schedule_stall_timer(dev);
 			mei_io_cb_free(cb);
 			return;
 		}
 		dev->iamthif_state = MEI_IAMTHIF_IDLE;
 		cl->fp = NULL;
 		if (!dev->iamthif_canceled) {
 			/*
 			 * in case of error enqueue the write cb to complete
 			 * read list so it can be propagated to the reader
 			 */
 			list_add_tail(&cb->list, &cl->rd_completed);
 			wake_up_interruptible(&cl->rx_wait);
 		} else {
 			mei_io_cb_free(cb);
 		}
 		break;
 	case MEI_FOP_READ:
 		if (!dev->iamthif_canceled) {
 			list_add_tail(&cb->list, &cl->rd_completed);
 			dev_dbg(dev->dev, "amthif read completed\n");
 			wake_up_interruptible(&cl->rx_wait);
 		} else {
 			mei_io_cb_free(cb);
 		}
 
 		dev->iamthif_stall_timer = 0;
 		mei_amthif_run_next_cmd(dev);
 		break;
 	default:
 		WARN_ON(1);
 	}
 }
 
-/**
- * mei_clear_list - removes all callbacks associated with file
- *		from mei_cb_list
- *
- * @file: file structure
- * @mei_cb_list: callbacks list
- *
- * mei_clear_list is called to clear resources associated with file
- * when application calls close function or Ctrl-C was pressed
- */
-static void mei_clear_list(const struct file *file,
-			   struct list_head *mei_cb_list)
-{
-	struct mei_cl_cb *cb, *next;
-
-	list_for_each_entry_safe(cb, next, mei_cb_list, list)
-		if (file == cb->fp)
-			mei_io_cb_free(cb);
-}
-
 /**
 * mei_amthif_release - the release function
 *
 *  @dev: device structure
-*  @file: pointer to file structure
+*  @fp: pointer to file structure
 *
 *  Return: 0 on success, <0 on error
 */
-int mei_amthif_release(struct mei_device *dev, struct file *file)
+int mei_amthif_release(struct mei_device *dev, struct file *fp)
 {
-	struct mei_cl *cl = file->private_data;
+	struct mei_cl *cl = fp->private_data;
 
 	if (dev->iamthif_open_count > 0)
 		dev->iamthif_open_count--;
 
-	if (cl->fp == file && dev->iamthif_state != MEI_IAMTHIF_IDLE) {
+	if (cl->fp == fp && dev->iamthif_state != MEI_IAMTHIF_IDLE) {
 
 		dev_dbg(dev->dev, "amthif canceled iamthif state %d\n",
-		    dev->iamthif_state);
+			dev->iamthif_state);
 		dev->iamthif_canceled = true;
 	}
 
-	mei_clear_list(file, &dev->amthif_cmd_list.list);
-	mei_clear_list(file, &cl->rd_completed);
-	mei_clear_list(file, &dev->ctrl_rd_list.list);
+	/* Don't clean ctrl_rd_list here, the reads has to be completed */
+	mei_io_list_free_fp(&dev->amthif_cmd_list, fp);
+	mei_io_list_free_fp(&cl->rd_completed, fp);
 
 	return 0;
 }
diff --git a/drivers/misc/mei/bus.c b/drivers/misc/mei/bus.c
index 2d9c5dd06e42..cb3e9e0ca049 100644
--- a/drivers/misc/mei/bus.c
+++ b/drivers/misc/mei/bus.c
@@ -1,1080 +1,1125 @@
 /*
  * Intel Management Engine Interface (Intel MEI) Linux driver
  * Copyright (c) 2012-2013, Intel Corporation.
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms and conditions of the GNU General Public License,
  * version 2, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope it will be useful, but WITHOUT
  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
  * more details.
  *
  */
 
 #include <linux/module.h>
 #include <linux/device.h>
 #include <linux/kernel.h>
 #include <linux/sched.h>
 #include <linux/init.h>
 #include <linux/errno.h>
 #include <linux/slab.h>
 #include <linux/mutex.h>
 #include <linux/interrupt.h>
 #include <linux/mei_cl_bus.h>
 
 #include "mei_dev.h"
 #include "client.h"
 
 #define to_mei_cl_driver(d) container_of(d, struct mei_cl_driver, driver)
 #define to_mei_cl_device(d) container_of(d, struct mei_cl_device, dev)
 
 /**
  * __mei_cl_send - internal client send (write)
  *
  * @cl: host client
  * @buf: buffer to send
  * @length: buffer length
  * @mode: sending mode
  *
  * Return: written size bytes or < 0 on error
  */
 ssize_t __mei_cl_send(struct mei_cl *cl, u8 *buf, size_t length,
 		      unsigned int mode)
 {
 	struct mei_device *bus;
 	struct mei_cl_cb *cb;
 	ssize_t rets;
 
 	if (WARN_ON(!cl || !cl->dev))
 		return -ENODEV;
 
 	bus = cl->dev;
 
 	mutex_lock(&bus->device_lock);
 	if (bus->dev_state != MEI_DEV_ENABLED) {
 		rets = -ENODEV;
 		goto out;
 	}
 
 	if (!mei_cl_is_connected(cl)) {
 		rets = -ENODEV;
 		goto out;
 	}
 
 	/* Check if we have an ME client device */
 	if (!mei_me_cl_is_active(cl->me_cl)) {
 		rets = -ENOTTY;
 		goto out;
 	}
 
 	if (length > mei_cl_mtu(cl)) {
 		rets = -EFBIG;
 		goto out;
 	}
 
 	cb = mei_cl_alloc_cb(cl, length, MEI_FOP_WRITE, NULL);
 	if (!cb) {
 		rets = -ENOMEM;
 		goto out;
 	}
 
 	cb->internal = !!(mode & MEI_CL_IO_TX_INTERNAL);
 	cb->blocking = !!(mode & MEI_CL_IO_TX_BLOCKING);
 	memcpy(cb->buf.data, buf, length);
 
 	rets = mei_cl_write(cl, cb);
 
 out:
 	mutex_unlock(&bus->device_lock);
 
 	return rets;
 }
 
 /**
  * __mei_cl_recv - internal client receive (read)
  *
  * @cl: host client
  * @buf: buffer to receive
  * @length: buffer length
  * @mode: io mode
  *
  * Return: read size in bytes of < 0 on error
  */
 ssize_t __mei_cl_recv(struct mei_cl *cl, u8 *buf, size_t length,
 		      unsigned int mode)
 {
 	struct mei_device *bus;
 	struct mei_cl_cb *cb;
 	size_t r_length;
 	ssize_t rets;
 	bool nonblock = !!(mode & MEI_CL_IO_RX_NONBLOCK);
 
 	if (WARN_ON(!cl || !cl->dev))
 		return -ENODEV;
 
 	bus = cl->dev;
 
 	mutex_lock(&bus->device_lock);
 	if (bus->dev_state != MEI_DEV_ENABLED) {
 		rets = -ENODEV;
 		goto out;
 	}
 
 	cb = mei_cl_read_cb(cl, NULL);
 	if (cb)
 		goto copy;
 
 	rets = mei_cl_read_start(cl, length, NULL);
 	if (rets && rets != -EBUSY)
 		goto out;
 
 	if (nonblock) {
 		rets = -EAGAIN;
 		goto out;
 	}
 
 	/* wait on event only if there is no other waiter */
 	/* synchronized under device mutex */
 	if (!waitqueue_active(&cl->rx_wait)) {
 
 		mutex_unlock(&bus->device_lock);
 
 		if (wait_event_interruptible(cl->rx_wait,
 				(!list_empty(&cl->rd_completed)) ||
 				(!mei_cl_is_connected(cl)))) {
 
 			if (signal_pending(current))
 				return -EINTR;
 			return -ERESTARTSYS;
 		}
 
 		mutex_lock(&bus->device_lock);
 
 		if (!mei_cl_is_connected(cl)) {
 			rets = -ENODEV;
 			goto out;
 		}
 	}
 
 	cb = mei_cl_read_cb(cl, NULL);
 	if (!cb) {
 		rets = 0;
 		goto out;
 	}
 
 copy:
 	if (cb->status) {
 		rets = cb->status;
 		goto free;
 	}
 
 	r_length = min_t(size_t, length, cb->buf_idx);
 	memcpy(buf, cb->buf.data, r_length);
 	rets = r_length;
 
 free:
 	mei_io_cb_free(cb);
 out:
 	mutex_unlock(&bus->device_lock);
 
 	return rets;
 }
 
 /**
  * mei_cldev_send - me device send  (write)
  *
  * @cldev: me client device
  * @buf: buffer to send
  * @length: buffer length
  *
  * Return: written size in bytes or < 0 on error
  */
 ssize_t mei_cldev_send(struct mei_cl_device *cldev, u8 *buf, size_t length)
 {
 	struct mei_cl *cl = cldev->cl;
 
 	return __mei_cl_send(cl, buf, length, MEI_CL_IO_TX_BLOCKING);
 }
 EXPORT_SYMBOL_GPL(mei_cldev_send);
 
 /**
  * mei_cldev_recv_nonblock - non block client receive (read)
  *
  * @cldev: me client device
  * @buf: buffer to receive
  * @length: buffer length
  *
  * Return: read size in bytes of < 0 on error
  *         -EAGAIN if function will block.
  */
 ssize_t mei_cldev_recv_nonblock(struct mei_cl_device *cldev, u8 *buf,
 				size_t length)
 {
 	struct mei_cl *cl = cldev->cl;
 
 	return __mei_cl_recv(cl, buf, length, MEI_CL_IO_RX_NONBLOCK);
 }
 EXPORT_SYMBOL_GPL(mei_cldev_recv_nonblock);
 
 /**
  * mei_cldev_recv - client receive (read)
  *
  * @cldev: me client device
  * @buf: buffer to receive
  * @length: buffer length
  *
  * Return: read size in bytes of < 0 on error
  */
 ssize_t mei_cldev_recv(struct mei_cl_device *cldev, u8 *buf, size_t length)
 {
 	struct mei_cl *cl = cldev->cl;
 
 	return __mei_cl_recv(cl, buf, length, 0);
 }
 EXPORT_SYMBOL_GPL(mei_cldev_recv);
 
 /**
  * mei_cl_bus_rx_work - dispatch rx event for a bus device
  *
  * @work: work
  */
 static void mei_cl_bus_rx_work(struct work_struct *work)
 {
 	struct mei_cl_device *cldev;
 	struct mei_device *bus;
 
 	cldev = container_of(work, struct mei_cl_device, rx_work);
 
 	bus = cldev->bus;
 
 	if (cldev->rx_cb)
 		cldev->rx_cb(cldev);
 
 	mutex_lock(&bus->device_lock);
 	mei_cl_read_start(cldev->cl, mei_cl_mtu(cldev->cl), NULL);
 	mutex_unlock(&bus->device_lock);
 }
 
 /**
  * mei_cl_bus_notif_work - dispatch FW notif event for a bus device
  *
  * @work: work
  */
 static void mei_cl_bus_notif_work(struct work_struct *work)
 {
 	struct mei_cl_device *cldev;
 
 	cldev = container_of(work, struct mei_cl_device, notif_work);
 
 	if (cldev->notif_cb)
 		cldev->notif_cb(cldev);
 }
 
 /**
  * mei_cl_bus_notify_event - schedule notify cb on bus client
  *
  * @cl: host client
  *
  * Return: true if event was scheduled
  *         false if the client is not waiting for event
  */
 bool mei_cl_bus_notify_event(struct mei_cl *cl)
 {
 	struct mei_cl_device *cldev = cl->cldev;
 
 	if (!cldev || !cldev->notif_cb)
 		return false;
 
 	if (!cl->notify_ev)
 		return false;
 
 	schedule_work(&cldev->notif_work);
 
 	cl->notify_ev = false;
 
 	return true;
 }
 
 /**
  * mei_cl_bus_rx_event - schedule rx event
  *
  * @cl: host client
  *
  * Return: true if event was scheduled
  *         false if the client is not waiting for event
  */
 bool mei_cl_bus_rx_event(struct mei_cl *cl)
 {
 	struct mei_cl_device *cldev = cl->cldev;
 
 	if (!cldev || !cldev->rx_cb)
 		return false;
 
 	schedule_work(&cldev->rx_work);
 
 	return true;
 }
 
 /**
  * mei_cldev_register_rx_cb - register Rx event callback
  *
  * @cldev: me client devices
  * @rx_cb: callback function
  *
  * Return: 0 on success
  *         -EALREADY if an callback is already registered
  *         <0 on other errors
  */
 int mei_cldev_register_rx_cb(struct mei_cl_device *cldev, mei_cldev_cb_t rx_cb)
 {
 	struct mei_device *bus = cldev->bus;
 	int ret;
 
 	if (!rx_cb)
 		return -EINVAL;
 	if (cldev->rx_cb)
 		return -EALREADY;
 
 	cldev->rx_cb = rx_cb;
 	INIT_WORK(&cldev->rx_work, mei_cl_bus_rx_work);
 
 	mutex_lock(&bus->device_lock);
 	ret = mei_cl_read_start(cldev->cl, mei_cl_mtu(cldev->cl), NULL);
 	mutex_unlock(&bus->device_lock);
 	if (ret && ret != -EBUSY)
 		return ret;
 
 	return 0;
 }
 EXPORT_SYMBOL_GPL(mei_cldev_register_rx_cb);
 
 /**
  * mei_cldev_register_notif_cb - register FW notification event callback
  *
  * @cldev: me client devices
  * @notif_cb: callback function
  *
  * Return: 0 on success
  *         -EALREADY if an callback is already registered
  *         <0 on other errors
  */
 int mei_cldev_register_notif_cb(struct mei_cl_device *cldev,
 				mei_cldev_cb_t notif_cb)
 {
 	struct mei_device *bus = cldev->bus;
 	int ret;
 
 	if (!notif_cb)
 		return -EINVAL;
 
 	if (cldev->notif_cb)
 		return -EALREADY;
 
 	cldev->notif_cb = notif_cb;
 	INIT_WORK(&cldev->notif_work, mei_cl_bus_notif_work);
 
 	mutex_lock(&bus->device_lock);
 	ret = mei_cl_notify_request(cldev->cl, NULL, 1);
 	mutex_unlock(&bus->device_lock);
 	if (ret)
 		return ret;
 
 	return 0;
 }
 EXPORT_SYMBOL_GPL(mei_cldev_register_notif_cb);
 
 /**
  * mei_cldev_get_drvdata - driver data getter
  *
  * @cldev: mei client device
  *
  * Return: driver private data
  */
 void *mei_cldev_get_drvdata(const struct mei_cl_device *cldev)
 {
 	return dev_get_drvdata(&cldev->dev);
 }
 EXPORT_SYMBOL_GPL(mei_cldev_get_drvdata);
 
 /**
  * mei_cldev_set_drvdata - driver data setter
  *
  * @cldev: mei client device
  * @data: data to store
  */
 void mei_cldev_set_drvdata(struct mei_cl_device *cldev, void *data)
 {
 	dev_set_drvdata(&cldev->dev, data);
 }
 EXPORT_SYMBOL_GPL(mei_cldev_set_drvdata);
 
 /**
  * mei_cldev_uuid - return uuid of the underlying me client
  *
  * @cldev: mei client device
  *
  * Return: me client uuid
  */
 const uuid_le *mei_cldev_uuid(const struct mei_cl_device *cldev)
 {
 	return mei_me_cl_uuid(cldev->me_cl);
 }
 EXPORT_SYMBOL_GPL(mei_cldev_uuid);
 
 /**
  * mei_cldev_ver - return protocol version of the underlying me client
  *
  * @cldev: mei client device
  *
  * Return: me client protocol version
  */
 u8 mei_cldev_ver(const struct mei_cl_device *cldev)
 {
 	return mei_me_cl_ver(cldev->me_cl);
 }
 EXPORT_SYMBOL_GPL(mei_cldev_ver);
 
 /**
  * mei_cldev_enabled - check whether the device is enabled
  *
  * @cldev: mei client device
  *
  * Return: true if me client is initialized and connected
  */
 bool mei_cldev_enabled(struct mei_cl_device *cldev)
 {
 	return mei_cl_is_connected(cldev->cl);
 }
 EXPORT_SYMBOL_GPL(mei_cldev_enabled);
 
 /**
  * mei_cldev_enable - enable me client device
  *     create connection with me client
  *
  * @cldev: me client device
  *
  * Return: 0 on success and < 0 on error
  */
 int mei_cldev_enable(struct mei_cl_device *cldev)
 {
 	struct mei_device *bus = cldev->bus;
 	struct mei_cl *cl;
 	int ret;
 
 	cl = cldev->cl;
 
 	if (cl->state == MEI_FILE_UNINITIALIZED) {
 		mutex_lock(&bus->device_lock);
 		ret = mei_cl_link(cl);
 		mutex_unlock(&bus->device_lock);
 		if (ret)
 			return ret;
 		/* update pointers */
 		cl->cldev = cldev;
 	}
 
 	mutex_lock(&bus->device_lock);
 	if (mei_cl_is_connected(cl)) {
 		ret = 0;
 		goto out;
 	}
 
 	if (!mei_me_cl_is_active(cldev->me_cl)) {
 		dev_err(&cldev->dev, "me client is not active\n");
 		ret = -ENOTTY;
 		goto out;
 	}
 
 	ret = mei_cl_connect(cl, cldev->me_cl, NULL);
 	if (ret < 0)
 		dev_err(&cldev->dev, "cannot connect\n");
 
 out:
 	mutex_unlock(&bus->device_lock);
 
 	return ret;
 }
 EXPORT_SYMBOL_GPL(mei_cldev_enable);
 
+/**
+ * mei_cldev_unregister_callbacks - internal wrapper for unregistering
+ *  callbacks.
+ *
+ * @cldev: client device
+ */
+static void mei_cldev_unregister_callbacks(struct mei_cl_device *cldev)
+{
+	if (cldev->rx_cb) {
+		cancel_work_sync(&cldev->rx_work);
+		cldev->rx_cb = NULL;
+	}
+
+	if (cldev->notif_cb) {
+		cancel_work_sync(&cldev->notif_work);
+		cldev->notif_cb = NULL;
+	}
+}
+
 /**
  * mei_cldev_disable - disable me client device
  *     disconnect form the me client
  *
  * @cldev: me client device
  *
  * Return: 0 on success and < 0 on error
  */
 int mei_cldev_disable(struct mei_cl_device *cldev)
 {
 	struct mei_device *bus;
 	struct mei_cl *cl;
 	int err;
 
 	if (!cldev)
 		return -ENODEV;
 
 	cl = cldev->cl;
 
 	bus = cldev->bus;
 
+	mei_cldev_unregister_callbacks(cldev);
+
 	mutex_lock(&bus->device_lock);
 
 	if (!mei_cl_is_connected(cl)) {
 		dev_dbg(bus->dev, "Already disconnected");
 		err = 0;
 		goto out;
 	}
 
 	err = mei_cl_disconnect(cl);
 	if (err < 0)
 		dev_err(bus->dev, "Could not disconnect from the ME client");
 
 out:
 	/* Flush queues and remove any pending read */
 	mei_cl_flush_queues(cl, NULL);
 	mei_cl_unlink(cl);
 
 	mutex_unlock(&bus->device_lock);
 	return err;
 }
 EXPORT_SYMBOL_GPL(mei_cldev_disable);
 
+/**
+ * mei_cl_bus_module_get - acquire module of the underlying
+ *    hw module.
+ *
+ * @cl: host client
+ *
+ * Return: true on success; false if the module was removed.
+ */
+bool mei_cl_bus_module_get(struct mei_cl *cl)
+{
+	struct mei_cl_device *cldev = cl->cldev;
+
+	if (!cldev)
+		return true;
+
+	return try_module_get(cldev->bus->dev->driver->owner);
+}
+
+/**
+ * mei_cl_bus_module_put -  release the underlying hw module.
+ *
+ * @cl: host client
+ */
+void mei_cl_bus_module_put(struct mei_cl *cl)
+{
+	struct mei_cl_device *cldev = cl->cldev;
+
+	if (cldev)
+		module_put(cldev->bus->dev->driver->owner);
+}
+
 /**
  * mei_cl_device_find - find matching entry in the driver id table
  *
  * @cldev: me client device
  * @cldrv: me client driver
  *
  * Return: id on success; NULL if no id is matching
  */
 static const
 struct mei_cl_device_id *mei_cl_device_find(struct mei_cl_device *cldev,
 					    struct mei_cl_driver *cldrv)
 {
 	const struct mei_cl_device_id *id;
 	const uuid_le *uuid;
 	u8 version;
 	bool match;
 
 	uuid = mei_me_cl_uuid(cldev->me_cl);
 	version = mei_me_cl_ver(cldev->me_cl);
 
 	id = cldrv->id_table;
 	while (uuid_le_cmp(NULL_UUID_LE, id->uuid)) {
 		if (!uuid_le_cmp(*uuid, id->uuid)) {
 			match = true;
 
 			if (cldev->name[0])
 				if (strncmp(cldev->name, id->name,
 					    sizeof(id->name)))
 					match = false;
 
 			if (id->version != MEI_CL_VERSION_ANY)
 				if (id->version != version)
 					match = false;
 			if (match)
 				return id;
 		}
 
 		id++;
 	}
 
 	return NULL;
 }
 
 /**
  * mei_cl_device_match  - device match function
  *
  * @dev: device
  * @drv: driver
  *
  * Return:  1 if matching device was found 0 otherwise
  */
 static int mei_cl_device_match(struct device *dev, struct device_driver *drv)
 {
 	struct mei_cl_device *cldev = to_mei_cl_device(dev);
 	struct mei_cl_driver *cldrv = to_mei_cl_driver(drv);
 	const struct mei_cl_device_id *found_id;
 
 	if (!cldev)
 		return 0;
 
 	if (!cldev->do_match)
 		return 0;
 
 	if (!cldrv || !cldrv->id_table)
 		return 0;
 
 	found_id = mei_cl_device_find(cldev, cldrv);
 	if (found_id)
 		return 1;
 
 	return 0;
 }
 
 /**
  * mei_cl_device_probe - bus probe function
  *
  * @dev: device
  *
  * Return:  0 on success; < 0 otherwise
  */
 static int mei_cl_device_probe(struct device *dev)
 {
 	struct mei_cl_device *cldev;
 	struct mei_cl_driver *cldrv;
 	const struct mei_cl_device_id *id;
 	int ret;
 
 	cldev = to_mei_cl_device(dev);
 	cldrv = to_mei_cl_driver(dev->driver);
 
 	if (!cldev)
 		return 0;
 
 	if (!cldrv || !cldrv->probe)
 		return -ENODEV;
 
 	id = mei_cl_device_find(cldev, cldrv);
 	if (!id)
 		return -ENODEV;
 
 	ret = cldrv->probe(cldev, id);
 	if (ret)
 		return ret;
 
 	__module_get(THIS_MODULE);
 	return 0;
 }
 
 /**
  * mei_cl_device_remove - remove device from the bus
  *
  * @dev: device
  *
  * Return:  0 on success; < 0 otherwise
  */
 static int mei_cl_device_remove(struct device *dev)
 {
 	struct mei_cl_device *cldev = to_mei_cl_device(dev);
 	struct mei_cl_driver *cldrv;
 	int ret = 0;
 
 	if (!cldev || !dev->driver)
 		return 0;
 
-	if (cldev->rx_cb) {
-		cancel_work_sync(&cldev->rx_work);
-		cldev->rx_cb = NULL;
-	}
-	if (cldev->notif_cb) {
-		cancel_work_sync(&cldev->notif_work);
-		cldev->notif_cb = NULL;
-	}
-
 	cldrv = to_mei_cl_driver(dev->driver);
 	if (cldrv->remove)
 		ret = cldrv->remove(cldev);
 
+	mei_cldev_unregister_callbacks(cldev);
+
 	module_put(THIS_MODULE);
 	dev->driver = NULL;
 	return ret;
 
 }
 
 static ssize_t name_show(struct device *dev, struct device_attribute *a,
 			     char *buf)
 {
 	struct mei_cl_device *cldev = to_mei_cl_device(dev);
 
 	return scnprintf(buf, PAGE_SIZE, "%s", cldev->name);
 }
 static DEVICE_ATTR_RO(name);
 
 static ssize_t uuid_show(struct device *dev, struct device_attribute *a,
 			     char *buf)
 {
 	struct mei_cl_device *cldev = to_mei_cl_device(dev);
 	const uuid_le *uuid = mei_me_cl_uuid(cldev->me_cl);
 
 	return scnprintf(buf, PAGE_SIZE, "%pUl", uuid);
 }
 static DEVICE_ATTR_RO(uuid);
 
 static ssize_t version_show(struct device *dev, struct device_attribute *a,
 			     char *buf)
 {
 	struct mei_cl_device *cldev = to_mei_cl_device(dev);
 	u8 version = mei_me_cl_ver(cldev->me_cl);
 
 	return scnprintf(buf, PAGE_SIZE, "%02X", version);
 }
 static DEVICE_ATTR_RO(version);
 
 static ssize_t modalias_show(struct device *dev, struct device_attribute *a,
 			     char *buf)
 {
 	struct mei_cl_device *cldev = to_mei_cl_device(dev);
 	const uuid_le *uuid = mei_me_cl_uuid(cldev->me_cl);
 
 	return scnprintf(buf, PAGE_SIZE, "mei:%s:%pUl:", cldev->name, uuid);
 }
 static DEVICE_ATTR_RO(modalias);
 
 static struct attribute *mei_cldev_attrs[] = {
 	&dev_attr_name.attr,
 	&dev_attr_uuid.attr,
 	&dev_attr_version.attr,
 	&dev_attr_modalias.attr,
 	NULL,
 };
 ATTRIBUTE_GROUPS(mei_cldev);
 
 /**
  * mei_cl_device_uevent - me client bus uevent handler
  *
  * @dev: device
  * @env: uevent kobject
  *
  * Return: 0 on success -ENOMEM on when add_uevent_var fails
  */
 static int mei_cl_device_uevent(struct device *dev, struct kobj_uevent_env *env)
 {
 	struct mei_cl_device *cldev = to_mei_cl_device(dev);
 	const uuid_le *uuid = mei_me_cl_uuid(cldev->me_cl);
 	u8 version = mei_me_cl_ver(cldev->me_cl);
 
 	if (add_uevent_var(env, "MEI_CL_VERSION=%d", version))
 		return -ENOMEM;
 
 	if (add_uevent_var(env, "MEI_CL_UUID=%pUl", uuid))
 		return -ENOMEM;
 
 	if (add_uevent_var(env, "MEI_CL_NAME=%s", cldev->name))
 		return -ENOMEM;
 
 	if (add_uevent_var(env, "MODALIAS=mei:%s:%pUl:%02X:",
 			   cldev->name, uuid, version))
 		return -ENOMEM;
 
 	return 0;
 }
 
 static struct bus_type mei_cl_bus_type = {
 	.name		= "mei",
 	.dev_groups	= mei_cldev_groups,
 	.match		= mei_cl_device_match,
 	.probe		= mei_cl_device_probe,
 	.remove		= mei_cl_device_remove,
 	.uevent		= mei_cl_device_uevent,
 };
 
 static struct mei_device *mei_dev_bus_get(struct mei_device *bus)
 {
 	if (bus)
 		get_device(bus->dev);
 
 	return bus;
 }
 
 static void mei_dev_bus_put(struct mei_device *bus)
 {
 	if (bus)
 		put_device(bus->dev);
 }
 
 static void mei_cl_bus_dev_release(struct device *dev)
 {
 	struct mei_cl_device *cldev = to_mei_cl_device(dev);
 
 	if (!cldev)
 		return;
 
 	mei_me_cl_put(cldev->me_cl);
 	mei_dev_bus_put(cldev->bus);
 	kfree(cldev->cl);
 	kfree(cldev);
 }
 
 static struct device_type mei_cl_device_type = {
 	.release	= mei_cl_bus_dev_release,
 };
 
 /**
  * mei_cl_bus_set_name - set device name for me client device
  *
  * @cldev: me client device
  */
 static inline void mei_cl_bus_set_name(struct mei_cl_device *cldev)
 {
 	dev_set_name(&cldev->dev, "mei:%s:%pUl:%02X",
 		     cldev->name,
 		     mei_me_cl_uuid(cldev->me_cl),
 		     mei_me_cl_ver(cldev->me_cl));
 }
 
 /**
  * mei_cl_bus_dev_alloc - initialize and allocate mei client device
  *
  * @bus: mei device
  * @me_cl: me client
  *
  * Return: allocated device structur or NULL on allocation failure
  */
 static struct mei_cl_device *mei_cl_bus_dev_alloc(struct mei_device *bus,
 						  struct mei_me_client *me_cl)
 {
 	struct mei_cl_device *cldev;
 	struct mei_cl *cl;
 
 	cldev = kzalloc(sizeof(struct mei_cl_device), GFP_KERNEL);
 	if (!cldev)
 		return NULL;
 
 	cl = mei_cl_allocate(bus);
 	if (!cl) {
 		kfree(cldev);
 		return NULL;
 	}
 
 	device_initialize(&cldev->dev);
 	cldev->dev.parent = bus->dev;
 	cldev->dev.bus    = &mei_cl_bus_type;
 	cldev->dev.type   = &mei_cl_device_type;
 	cldev->bus        = mei_dev_bus_get(bus);
 	cldev->me_cl      = mei_me_cl_get(me_cl);
 	cldev->cl         = cl;
 	mei_cl_bus_set_name(cldev);
 	cldev->is_added   = 0;
 	INIT_LIST_HEAD(&cldev->bus_list);
 
 	return cldev;
 }
 
 /**
  * mei_cl_dev_setup - setup me client device
  *    run fix up routines and set the device name
  *
  * @bus: mei device
  * @cldev: me client device
  *
  * Return: true if the device is eligible for enumeration
  */
 static bool mei_cl_bus_dev_setup(struct mei_device *bus,
 				 struct mei_cl_device *cldev)
 {
 	cldev->do_match = 1;
 	mei_cl_bus_dev_fixup(cldev);
 
 	/* the device name can change during fix up */
 	if (cldev->do_match)
 		mei_cl_bus_set_name(cldev);
 
 	return cldev->do_match == 1;
 }
 
 /**
  * mei_cl_bus_dev_add - add me client devices
  *
  * @cldev: me client device
  *
  * Return: 0 on success; < 0 on failre
  */
 static int mei_cl_bus_dev_add(struct mei_cl_device *cldev)
 {
 	int ret;
 
 	dev_dbg(cldev->bus->dev, "adding %pUL:%02X\n",
 		mei_me_cl_uuid(cldev->me_cl),
 		mei_me_cl_ver(cldev->me_cl));
 	ret = device_add(&cldev->dev);
 	if (!ret)
 		cldev->is_added = 1;
 
 	return ret;
 }
 
 /**
  * mei_cl_bus_dev_stop - stop the driver
  *
  * @cldev: me client device
  */
 static void mei_cl_bus_dev_stop(struct mei_cl_device *cldev)
 {
 	if (cldev->is_added)
 		device_release_driver(&cldev->dev);
 }
 
 /**
  * mei_cl_bus_dev_destroy - destroy me client devices object
  *
  * @cldev: me client device
  *
  * Locking: called under "dev->cl_bus_lock" lock
  */
 static void mei_cl_bus_dev_destroy(struct mei_cl_device *cldev)
 {
 
 	WARN_ON(!mutex_is_locked(&cldev->bus->cl_bus_lock));
 
 	if (!cldev->is_added)
 		return;
 
 	device_del(&cldev->dev);
 
 	list_del_init(&cldev->bus_list);
 
 	cldev->is_added = 0;
 	put_device(&cldev->dev);
 }
 
 /**
  * mei_cl_bus_remove_device - remove a devices form the bus
  *
  * @cldev: me client device
  */
 static void mei_cl_bus_remove_device(struct mei_cl_device *cldev)
 {
 	mei_cl_bus_dev_stop(cldev);
 	mei_cl_bus_dev_destroy(cldev);
 }
 
 /**
  * mei_cl_bus_remove_devices - remove all devices form the bus
  *
  * @bus: mei device
  */
 void mei_cl_bus_remove_devices(struct mei_device *bus)
 {
 	struct mei_cl_device *cldev, *next;
 
 	mutex_lock(&bus->cl_bus_lock);
 	list_for_each_entry_safe(cldev, next, &bus->device_list, bus_list)
 		mei_cl_bus_remove_device(cldev);
 	mutex_unlock(&bus->cl_bus_lock);
 }
 
 
 /**
  * mei_cl_bus_dev_init - allocate and initializes an mei client devices
  *     based on me client
  *
  * @bus: mei device
  * @me_cl: me client
  *
  * Locking: called under "dev->cl_bus_lock" lock
  */
 static void mei_cl_bus_dev_init(struct mei_device *bus,
 				struct mei_me_client *me_cl)
 {
 	struct mei_cl_device *cldev;
 
 	WARN_ON(!mutex_is_locked(&bus->cl_bus_lock));
 
 	dev_dbg(bus->dev, "initializing %pUl", mei_me_cl_uuid(me_cl));
 
 	if (me_cl->bus_added)
 		return;
 
 	cldev = mei_cl_bus_dev_alloc(bus, me_cl);
 	if (!cldev)
 		return;
 
 	me_cl->bus_added = true;
 	list_add_tail(&cldev->bus_list, &bus->device_list);
 
 }
 
 /**
  * mei_cl_bus_rescan - scan me clients list and add create
  *    devices for eligible clients
  *
  * @bus: mei device
  */
 void mei_cl_bus_rescan(struct mei_device *bus)
 {
 	struct mei_cl_device *cldev, *n;
 	struct mei_me_client *me_cl;
 
 	mutex_lock(&bus->cl_bus_lock);
 
 	down_read(&bus->me_clients_rwsem);
 	list_for_each_entry(me_cl, &bus->me_clients, list)
 		mei_cl_bus_dev_init(bus, me_cl);
 	up_read(&bus->me_clients_rwsem);
 
 	list_for_each_entry_safe(cldev, n, &bus->device_list, bus_list) {
 
 		if (!mei_me_cl_is_active(cldev->me_cl)) {
 			mei_cl_bus_remove_device(cldev);
 			continue;
 		}
 
 		if (cldev->is_added)
 			continue;
 
 		if (mei_cl_bus_dev_setup(bus, cldev))
 			mei_cl_bus_dev_add(cldev);
 		else {
 			list_del_init(&cldev->bus_list);
 			put_device(&cldev->dev);
 		}
 	}
 	mutex_unlock(&bus->cl_bus_lock);
 
 	dev_dbg(bus->dev, "rescan end");
 }
 
 void mei_cl_bus_rescan_work(struct work_struct *work)
 {
 	struct mei_device *bus =
 		container_of(work, struct mei_device, bus_rescan_work);
 	struct mei_me_client *me_cl;
 
 	me_cl = mei_me_cl_by_uuid(bus, &mei_amthif_guid);
 	if (me_cl)
 		mei_amthif_host_init(bus, me_cl);
 	mei_me_cl_put(me_cl);
 
 	mei_cl_bus_rescan(bus);
 }
 
 int __mei_cldev_driver_register(struct mei_cl_driver *cldrv,
 				struct module *owner)
 {
 	int err;
 
 	cldrv->driver.name = cldrv->name;
 	cldrv->driver.owner = owner;
 	cldrv->driver.bus = &mei_cl_bus_type;
 
 	err = driver_register(&cldrv->driver);
 	if (err)
 		return err;
 
 	pr_debug("mei: driver [%s] registered\n", cldrv->driver.name);
 
 	return 0;
 }
 EXPORT_SYMBOL_GPL(__mei_cldev_driver_register);
 
 void mei_cldev_driver_unregister(struct mei_cl_driver *cldrv)
 {
 	driver_unregister(&cldrv->driver);
 
 	pr_debug("mei: driver [%s] unregistered\n", cldrv->driver.name);
 }
 EXPORT_SYMBOL_GPL(mei_cldev_driver_unregister);
 
 
 int __init mei_cl_bus_init(void)
 {
 	return bus_register(&mei_cl_bus_type);
 }
 
 void __exit mei_cl_bus_exit(void)
 {
 	bus_unregister(&mei_cl_bus_type);
 }
diff --git a/drivers/misc/mei/client.c b/drivers/misc/mei/client.c
index b0395601c6ae..68fe37b5bc52 100644
--- a/drivers/misc/mei/client.c
+++ b/drivers/misc/mei/client.c
@@ -1,1786 +1,1795 @@
 /*
  *
  * Intel Management Engine Interface (Intel MEI) Linux driver
  * Copyright (c) 2003-2012, Intel Corporation.
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms and conditions of the GNU General Public License,
  * version 2, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope it will be useful, but WITHOUT
  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
  * more details.
  *
  */
 
 #include <linux/sched.h>
 #include <linux/wait.h>
 #include <linux/delay.h>
 #include <linux/slab.h>
 #include <linux/pm_runtime.h>
 
 #include <linux/mei.h>
 
 #include "mei_dev.h"
 #include "hbm.h"
 #include "client.h"
 
 /**
  * mei_me_cl_init - initialize me client
  *
  * @me_cl: me client
  */
 void mei_me_cl_init(struct mei_me_client *me_cl)
 {
 	INIT_LIST_HEAD(&me_cl->list);
 	kref_init(&me_cl->refcnt);
 }
 
 /**
  * mei_me_cl_get - increases me client refcount
  *
  * @me_cl: me client
  *
  * Locking: called under "dev->device_lock" lock
  *
  * Return: me client or NULL
  */
 struct mei_me_client *mei_me_cl_get(struct mei_me_client *me_cl)
 {
 	if (me_cl && kref_get_unless_zero(&me_cl->refcnt))
 		return me_cl;
 
 	return NULL;
 }
 
 /**
  * mei_me_cl_release - free me client
  *
  * Locking: called under "dev->device_lock" lock
  *
  * @ref: me_client refcount
  */
 static void mei_me_cl_release(struct kref *ref)
 {
 	struct mei_me_client *me_cl =
 		container_of(ref, struct mei_me_client, refcnt);
 
 	kfree(me_cl);
 }
 
 /**
  * mei_me_cl_put - decrease me client refcount and free client if necessary
  *
  * Locking: called under "dev->device_lock" lock
  *
  * @me_cl: me client
  */
 void mei_me_cl_put(struct mei_me_client *me_cl)
 {
 	if (me_cl)
 		kref_put(&me_cl->refcnt, mei_me_cl_release);
 }
 
 /**
  * __mei_me_cl_del  - delete me client from the list and decrease
  *     reference counter
  *
  * @dev: mei device
  * @me_cl: me client
  *
  * Locking: dev->me_clients_rwsem
  */
 static void __mei_me_cl_del(struct mei_device *dev, struct mei_me_client *me_cl)
 {
 	if (!me_cl)
 		return;
 
 	list_del_init(&me_cl->list);
 	mei_me_cl_put(me_cl);
 }
 
 /**
  * mei_me_cl_del - delete me client from the list and decrease
  *     reference counter
  *
  * @dev: mei device
  * @me_cl: me client
  */
 void mei_me_cl_del(struct mei_device *dev, struct mei_me_client *me_cl)
 {
 	down_write(&dev->me_clients_rwsem);
 	__mei_me_cl_del(dev, me_cl);
 	up_write(&dev->me_clients_rwsem);
 }
 
 /**
  * mei_me_cl_add - add me client to the list
  *
  * @dev: mei device
  * @me_cl: me client
  */
 void mei_me_cl_add(struct mei_device *dev, struct mei_me_client *me_cl)
 {
 	down_write(&dev->me_clients_rwsem);
 	list_add(&me_cl->list, &dev->me_clients);
 	up_write(&dev->me_clients_rwsem);
 }
 
 /**
  * __mei_me_cl_by_uuid - locate me client by uuid
  *	increases ref count
  *
  * @dev: mei device
  * @uuid: me client uuid
  *
  * Return: me client or NULL if not found
  *
  * Locking: dev->me_clients_rwsem
  */
 static struct mei_me_client *__mei_me_cl_by_uuid(struct mei_device *dev,
 					const uuid_le *uuid)
 {
 	struct mei_me_client *me_cl;
 	const uuid_le *pn;
 
 	WARN_ON(!rwsem_is_locked(&dev->me_clients_rwsem));
 
 	list_for_each_entry(me_cl, &dev->me_clients, list) {
 		pn = &me_cl->props.protocol_name;
 		if (uuid_le_cmp(*uuid, *pn) == 0)
 			return mei_me_cl_get(me_cl);
 	}
 
 	return NULL;
 }
 
 /**
  * mei_me_cl_by_uuid - locate me client by uuid
  *	increases ref count
  *
  * @dev: mei device
  * @uuid: me client uuid
  *
  * Return: me client or NULL if not found
  *
  * Locking: dev->me_clients_rwsem
  */
 struct mei_me_client *mei_me_cl_by_uuid(struct mei_device *dev,
 					const uuid_le *uuid)
 {
 	struct mei_me_client *me_cl;
 
 	down_read(&dev->me_clients_rwsem);
 	me_cl = __mei_me_cl_by_uuid(dev, uuid);
 	up_read(&dev->me_clients_rwsem);
 
 	return me_cl;
 }
 
 /**
  * mei_me_cl_by_id - locate me client by client id
  *	increases ref count
  *
  * @dev: the device structure
  * @client_id: me client id
  *
  * Return: me client or NULL if not found
  *
  * Locking: dev->me_clients_rwsem
  */
 struct mei_me_client *mei_me_cl_by_id(struct mei_device *dev, u8 client_id)
 {
 
 	struct mei_me_client *__me_cl, *me_cl = NULL;
 
 	down_read(&dev->me_clients_rwsem);
 	list_for_each_entry(__me_cl, &dev->me_clients, list) {
 		if (__me_cl->client_id == client_id) {
 			me_cl = mei_me_cl_get(__me_cl);
 			break;
 		}
 	}
 	up_read(&dev->me_clients_rwsem);
 
 	return me_cl;
 }
 
 /**
  * __mei_me_cl_by_uuid_id - locate me client by client id and uuid
  *	increases ref count
  *
  * @dev: the device structure
  * @uuid: me client uuid
  * @client_id: me client id
  *
  * Return: me client or null if not found
  *
  * Locking: dev->me_clients_rwsem
  */
 static struct mei_me_client *__mei_me_cl_by_uuid_id(struct mei_device *dev,
 					   const uuid_le *uuid, u8 client_id)
 {
 	struct mei_me_client *me_cl;
 	const uuid_le *pn;
 
 	WARN_ON(!rwsem_is_locked(&dev->me_clients_rwsem));
 
 	list_for_each_entry(me_cl, &dev->me_clients, list) {
 		pn = &me_cl->props.protocol_name;
 		if (uuid_le_cmp(*uuid, *pn) == 0 &&
 		    me_cl->client_id == client_id)
 			return mei_me_cl_get(me_cl);
 	}
 
 	return NULL;
 }
 
 
 /**
  * mei_me_cl_by_uuid_id - locate me client by client id and uuid
  *	increases ref count
  *
  * @dev: the device structure
  * @uuid: me client uuid
  * @client_id: me client id
  *
  * Return: me client or null if not found
  */
 struct mei_me_client *mei_me_cl_by_uuid_id(struct mei_device *dev,
 					   const uuid_le *uuid, u8 client_id)
 {
 	struct mei_me_client *me_cl;
 
 	down_read(&dev->me_clients_rwsem);
 	me_cl = __mei_me_cl_by_uuid_id(dev, uuid, client_id);
 	up_read(&dev->me_clients_rwsem);
 
 	return me_cl;
 }
 
 /**
  * mei_me_cl_rm_by_uuid - remove all me clients matching uuid
  *
  * @dev: the device structure
  * @uuid: me client uuid
  *
  * Locking: called under "dev->device_lock" lock
  */
 void mei_me_cl_rm_by_uuid(struct mei_device *dev, const uuid_le *uuid)
 {
 	struct mei_me_client *me_cl;
 
 	dev_dbg(dev->dev, "remove %pUl\n", uuid);
 
 	down_write(&dev->me_clients_rwsem);
 	me_cl = __mei_me_cl_by_uuid(dev, uuid);
 	__mei_me_cl_del(dev, me_cl);
 	up_write(&dev->me_clients_rwsem);
 }
 
 /**
  * mei_me_cl_rm_by_uuid_id - remove all me clients matching client id
  *
  * @dev: the device structure
  * @uuid: me client uuid
  * @id: me client id
  *
  * Locking: called under "dev->device_lock" lock
  */
 void mei_me_cl_rm_by_uuid_id(struct mei_device *dev, const uuid_le *uuid, u8 id)
 {
 	struct mei_me_client *me_cl;
 
 	dev_dbg(dev->dev, "remove %pUl %d\n", uuid, id);
 
 	down_write(&dev->me_clients_rwsem);
 	me_cl = __mei_me_cl_by_uuid_id(dev, uuid, id);
 	__mei_me_cl_del(dev, me_cl);
 	up_write(&dev->me_clients_rwsem);
 }
 
 /**
  * mei_me_cl_rm_all - remove all me clients
  *
  * @dev: the device structure
  *
  * Locking: called under "dev->device_lock" lock
  */
 void mei_me_cl_rm_all(struct mei_device *dev)
 {
 	struct mei_me_client *me_cl, *next;
 
 	down_write(&dev->me_clients_rwsem);
 	list_for_each_entry_safe(me_cl, next, &dev->me_clients, list)
 		__mei_me_cl_del(dev, me_cl);
 	up_write(&dev->me_clients_rwsem);
 }
 
 /**
  * mei_cl_cmp_id - tells if the clients are the same
  *
  * @cl1: host client 1
  * @cl2: host client 2
  *
  * Return: true  - if the clients has same host and me ids
  *         false - otherwise
  */
 static inline bool mei_cl_cmp_id(const struct mei_cl *cl1,
 				const struct mei_cl *cl2)
 {
 	return cl1 && cl2 &&
 		(cl1->host_client_id == cl2->host_client_id) &&
 		(mei_cl_me_id(cl1) == mei_cl_me_id(cl2));
 }
 
 /**
  * mei_io_cb_free - free mei_cb_private related memory
  *
  * @cb: mei callback struct
  */
 void mei_io_cb_free(struct mei_cl_cb *cb)
 {
 	if (cb == NULL)
 		return;
 
 	list_del(&cb->list);
 	kfree(cb->buf.data);
 	kfree(cb);
 }
 
 /**
  * mei_io_cb_init - allocate and initialize io callback
  *
  * @cl: mei client
  * @type: operation type
  * @fp: pointer to file structure
  *
  * Return: mei_cl_cb pointer or NULL;
  */
 static struct mei_cl_cb *mei_io_cb_init(struct mei_cl *cl,
 					enum mei_cb_file_ops type,
 					const struct file *fp)
 {
 	struct mei_cl_cb *cb;
 
 	cb = kzalloc(sizeof(struct mei_cl_cb), GFP_KERNEL);
 	if (!cb)
 		return NULL;
 
 	INIT_LIST_HEAD(&cb->list);
 	cb->fp = fp;
 	cb->cl = cl;
 	cb->buf_idx = 0;
 	cb->fop_type = type;
 	return cb;
 }
 
 /**
- * __mei_io_list_flush - removes and frees cbs belonging to cl.
+ * __mei_io_list_flush_cl - removes and frees cbs belonging to cl.
  *
- * @list:  an instance of our list structure
+ * @head:  an instance of our list structure
  * @cl:    host client, can be NULL for flushing the whole list
  * @free:  whether to free the cbs
  */
-static void __mei_io_list_flush(struct mei_cl_cb *list,
-				struct mei_cl *cl, bool free)
+static void __mei_io_list_flush_cl(struct list_head *head,
+				   const struct mei_cl *cl, bool free)
 {
 	struct mei_cl_cb *cb, *next;
 
 	/* enable removing everything if no cl is specified */
-	list_for_each_entry_safe(cb, next, &list->list, list) {
+	list_for_each_entry_safe(cb, next, head, list) {
 		if (!cl || mei_cl_cmp_id(cl, cb->cl)) {
 			list_del_init(&cb->list);
 			if (free)
 				mei_io_cb_free(cb);
 		}
 	}
 }
 
 /**
- * mei_io_list_flush - removes list entry belonging to cl.
+ * mei_io_list_flush_cl - removes list entry belonging to cl.
  *
- * @list:  An instance of our list structure
+ * @head: An instance of our list structure
  * @cl: host client
  */
-void mei_io_list_flush(struct mei_cl_cb *list, struct mei_cl *cl)
+static inline void mei_io_list_flush_cl(struct list_head *head,
+					const struct mei_cl *cl)
 {
-	__mei_io_list_flush(list, cl, false);
+	__mei_io_list_flush_cl(head, cl, false);
 }
 
 /**
- * mei_io_list_free - removes cb belonging to cl and free them
+ * mei_io_list_free_cl - removes cb belonging to cl and free them
  *
- * @list:  An instance of our list structure
+ * @head: An instance of our list structure
  * @cl: host client
  */
-static inline void mei_io_list_free(struct mei_cl_cb *list, struct mei_cl *cl)
+static inline void mei_io_list_free_cl(struct list_head *head,
+				       const struct mei_cl *cl)
 {
-	__mei_io_list_flush(list, cl, true);
+	__mei_io_list_flush_cl(head, cl, true);
+}
+
+/**
+ * mei_io_list_free_fp - free cb from a list that matches file pointer
+ *
+ * @head: io list
+ * @fp: file pointer (matching cb file object), may be NULL
+ */
+void mei_io_list_free_fp(struct list_head *head, const struct file *fp)
+{
+	struct mei_cl_cb *cb, *next;
+
+	list_for_each_entry_safe(cb, next, head, list)
+		if (!fp || fp == cb->fp)
+			mei_io_cb_free(cb);
 }
 
 /**
  * mei_cl_alloc_cb - a convenient wrapper for allocating read cb
  *
  * @cl: host client
  * @length: size of the buffer
  * @fop_type: operation type
  * @fp: associated file pointer (might be NULL)
  *
  * Return: cb on success and NULL on failure
  */
 struct mei_cl_cb *mei_cl_alloc_cb(struct mei_cl *cl, size_t length,
 				  enum mei_cb_file_ops fop_type,
 				  const struct file *fp)
 {
 	struct mei_cl_cb *cb;
 
 	cb = mei_io_cb_init(cl, fop_type, fp);
 	if (!cb)
 		return NULL;
 
 	if (length == 0)
 		return cb;
 
 	cb->buf.data = kmalloc(length, GFP_KERNEL);
 	if (!cb->buf.data) {
 		mei_io_cb_free(cb);
 		return NULL;
 	}
 	cb->buf.size = length;
 
 	return cb;
 }
 
 /**
  * mei_cl_enqueue_ctrl_wr_cb - a convenient wrapper for allocating
  *     and enqueuing of the control commands cb
  *
  * @cl: host client
  * @length: size of the buffer
  * @fop_type: operation type
  * @fp: associated file pointer (might be NULL)
  *
  * Return: cb on success and NULL on failure
  * Locking: called under "dev->device_lock" lock
  */
 struct mei_cl_cb *mei_cl_enqueue_ctrl_wr_cb(struct mei_cl *cl, size_t length,
 					    enum mei_cb_file_ops fop_type,
 					    const struct file *fp)
 {
 	struct mei_cl_cb *cb;
 
 	/* for RX always allocate at least client's mtu */
 	if (length)
 		length = max_t(size_t, length, mei_cl_mtu(cl));
 
 	cb = mei_cl_alloc_cb(cl, length, fop_type, fp);
 	if (!cb)
 		return NULL;
 
-	list_add_tail(&cb->list, &cl->dev->ctrl_wr_list.list);
+	list_add_tail(&cb->list, &cl->dev->ctrl_wr_list);
 	return cb;
 }
 
 /**
  * mei_cl_read_cb - find this cl's callback in the read list
  *     for a specific file
  *
  * @cl: host client
  * @fp: file pointer (matching cb file object), may be NULL
  *
  * Return: cb on success, NULL if cb is not found
  */
 struct mei_cl_cb *mei_cl_read_cb(const struct mei_cl *cl, const struct file *fp)
 {
 	struct mei_cl_cb *cb;
 
 	list_for_each_entry(cb, &cl->rd_completed, list)
 		if (!fp || fp == cb->fp)
 			return cb;
 
 	return NULL;
 }
 
-/**
- * mei_cl_read_cb_flush - free client's read pending and completed cbs
- *   for a specific file
- *
- * @cl: host client
- * @fp: file pointer (matching cb file object), may be NULL
- */
-void mei_cl_read_cb_flush(const struct mei_cl *cl, const struct file *fp)
-{
-	struct mei_cl_cb *cb, *next;
-
-	list_for_each_entry_safe(cb, next, &cl->rd_completed, list)
-		if (!fp || fp == cb->fp)
-			mei_io_cb_free(cb);
-
-
-	list_for_each_entry_safe(cb, next, &cl->rd_pending, list)
-		if (!fp || fp == cb->fp)
-			mei_io_cb_free(cb);
-}
-
 /**
  * mei_cl_flush_queues - flushes queue lists belonging to cl.
  *
  * @cl: host client
  * @fp: file pointer (matching cb file object), may be NULL
  *
  * Return: 0 on success, -EINVAL if cl or cl->dev is NULL.
  */
 int mei_cl_flush_queues(struct mei_cl *cl, const struct file *fp)
 {
 	struct mei_device *dev;
 
 	if (WARN_ON(!cl || !cl->dev))
 		return -EINVAL;
 
 	dev = cl->dev;
 
 	cl_dbg(dev, cl, "remove list entry belonging to cl\n");
-	mei_io_list_free(&cl->dev->write_list, cl);
-	mei_io_list_free(&cl->dev->write_waiting_list, cl);
-	mei_io_list_flush(&cl->dev->ctrl_wr_list, cl);
-	mei_io_list_flush(&cl->dev->ctrl_rd_list, cl);
-	mei_io_list_flush(&cl->dev->amthif_cmd_list, cl);
-
-	mei_cl_read_cb_flush(cl, fp);
+	mei_io_list_free_cl(&cl->dev->write_list, cl);
+	mei_io_list_free_cl(&cl->dev->write_waiting_list, cl);
+	mei_io_list_flush_cl(&cl->dev->ctrl_wr_list, cl);
+	mei_io_list_flush_cl(&cl->dev->ctrl_rd_list, cl);
+	mei_io_list_free_fp(&cl->rd_pending, fp);
+	mei_io_list_free_fp(&cl->rd_completed, fp);
 
 	return 0;
 }
 
-
 /**
  * mei_cl_init - initializes cl.
  *
  * @cl: host client to be initialized
  * @dev: mei device
  */
 void mei_cl_init(struct mei_cl *cl, struct mei_device *dev)
 {
 	memset(cl, 0, sizeof(struct mei_cl));
 	init_waitqueue_head(&cl->wait);
 	init_waitqueue_head(&cl->rx_wait);
 	init_waitqueue_head(&cl->tx_wait);
 	init_waitqueue_head(&cl->ev_wait);
 	INIT_LIST_HEAD(&cl->rd_completed);
 	INIT_LIST_HEAD(&cl->rd_pending);
 	INIT_LIST_HEAD(&cl->link);
 	cl->writing_state = MEI_IDLE;
 	cl->state = MEI_FILE_UNINITIALIZED;
 	cl->dev = dev;
 }
 
 /**
  * mei_cl_allocate - allocates cl  structure and sets it up.
  *
  * @dev: mei device
  * Return:  The allocated file or NULL on failure
  */
 struct mei_cl *mei_cl_allocate(struct mei_device *dev)
 {
 	struct mei_cl *cl;
 
 	cl = kmalloc(sizeof(struct mei_cl), GFP_KERNEL);
 	if (!cl)
 		return NULL;
 
 	mei_cl_init(cl, dev);
 
 	return cl;
 }
 
 /**
  * mei_cl_link - allocate host id in the host map
  *
  * @cl: host client
  *
  * Return: 0 on success
  *	-EINVAL on incorrect values
  *	-EMFILE if open count exceeded.
  */
 int mei_cl_link(struct mei_cl *cl)
 {
 	struct mei_device *dev;
 	long open_handle_count;
 	int id;
 
 	if (WARN_ON(!cl || !cl->dev))
 		return -EINVAL;
 
 	dev = cl->dev;
 
 	id = find_first_zero_bit(dev->host_clients_map, MEI_CLIENTS_MAX);
 	if (id >= MEI_CLIENTS_MAX) {
 		dev_err(dev->dev, "id exceeded %d", MEI_CLIENTS_MAX);
 		return -EMFILE;
 	}
 
 	open_handle_count = dev->open_handle_count + dev->iamthif_open_count;
 	if (open_handle_count >= MEI_MAX_OPEN_HANDLE_COUNT) {
 		dev_err(dev->dev, "open_handle_count exceeded %d",
 			MEI_MAX_OPEN_HANDLE_COUNT);
 		return -EMFILE;
 	}
 
 	dev->open_handle_count++;
 
 	cl->host_client_id = id;
 	list_add_tail(&cl->link, &dev->file_list);
 
 	set_bit(id, dev->host_clients_map);
 
 	cl->state = MEI_FILE_INITIALIZING;
 
 	cl_dbg(dev, cl, "link cl\n");
 	return 0;
 }
 
 /**
  * mei_cl_unlink - remove host client from the list
  *
  * @cl: host client
  *
  * Return: always 0
  */
 int mei_cl_unlink(struct mei_cl *cl)
 {
 	struct mei_device *dev;
 
 	/* don't shout on error exit path */
 	if (!cl)
 		return 0;
 
 	/* amthif might not be initialized */
 	if (!cl->dev)
 		return 0;
 
 	dev = cl->dev;
 
 	cl_dbg(dev, cl, "unlink client");
 
 	if (dev->open_handle_count > 0)
 		dev->open_handle_count--;
 
 	/* never clear the 0 bit */
 	if (cl->host_client_id)
 		clear_bit(cl->host_client_id, dev->host_clients_map);
 
 	list_del_init(&cl->link);
 
 	cl->state = MEI_FILE_UNINITIALIZED;
 	cl->writing_state = MEI_IDLE;
 
 	WARN_ON(!list_empty(&cl->rd_completed) ||
 		!list_empty(&cl->rd_pending) ||
 		!list_empty(&cl->link));
 
 	return 0;
 }
 
 void mei_host_client_init(struct mei_device *dev)
 {
 	dev->dev_state = MEI_DEV_ENABLED;
 	dev->reset_count = 0;
 
 	schedule_work(&dev->bus_rescan_work);
 
 	pm_runtime_mark_last_busy(dev->dev);
 	dev_dbg(dev->dev, "rpm: autosuspend\n");
 	pm_request_autosuspend(dev->dev);
 }
 
 /**
  * mei_hbuf_acquire - try to acquire host buffer
  *
  * @dev: the device structure
  * Return: true if host buffer was acquired
  */
 bool mei_hbuf_acquire(struct mei_device *dev)
 {
 	if (mei_pg_state(dev) == MEI_PG_ON ||
 	    mei_pg_in_transition(dev)) {
 		dev_dbg(dev->dev, "device is in pg\n");
 		return false;
 	}
 
 	if (!dev->hbuf_is_ready) {
 		dev_dbg(dev->dev, "hbuf is not ready\n");
 		return false;
 	}
 
 	dev->hbuf_is_ready = false;
 
 	return true;
 }
 
 /**
  * mei_cl_wake_all - wake up readers, writers and event waiters so
  *                 they can be interrupted
  *
  * @cl: host client
  */
 static void mei_cl_wake_all(struct mei_cl *cl)
 {
 	struct mei_device *dev = cl->dev;
 
 	/* synchronized under device mutex */
 	if (waitqueue_active(&cl->rx_wait)) {
 		cl_dbg(dev, cl, "Waking up reading client!\n");
 		wake_up_interruptible(&cl->rx_wait);
 	}
 	/* synchronized under device mutex */
 	if (waitqueue_active(&cl->tx_wait)) {
 		cl_dbg(dev, cl, "Waking up writing client!\n");
 		wake_up_interruptible(&cl->tx_wait);
 	}
 	/* synchronized under device mutex */
 	if (waitqueue_active(&cl->ev_wait)) {
 		cl_dbg(dev, cl, "Waking up waiting for event clients!\n");
 		wake_up_interruptible(&cl->ev_wait);
 	}
 	/* synchronized under device mutex */
 	if (waitqueue_active(&cl->wait)) {
 		cl_dbg(dev, cl, "Waking up ctrl write clients!\n");
 		wake_up(&cl->wait);
 	}
 }
 
 /**
  * mei_cl_set_disconnected - set disconnected state and clear
  *   associated states and resources
  *
  * @cl: host client
  */
-void mei_cl_set_disconnected(struct mei_cl *cl)
+static void mei_cl_set_disconnected(struct mei_cl *cl)
 {
 	struct mei_device *dev = cl->dev;
 
 	if (cl->state == MEI_FILE_DISCONNECTED ||
 	    cl->state <= MEI_FILE_INITIALIZING)
 		return;
 
 	cl->state = MEI_FILE_DISCONNECTED;
-	mei_io_list_free(&dev->write_list, cl);
-	mei_io_list_free(&dev->write_waiting_list, cl);
-	mei_io_list_flush(&dev->ctrl_rd_list, cl);
-	mei_io_list_flush(&dev->ctrl_wr_list, cl);
+	mei_io_list_free_cl(&dev->write_list, cl);
+	mei_io_list_free_cl(&dev->write_waiting_list, cl);
+	mei_io_list_flush_cl(&dev->ctrl_rd_list, cl);
+	mei_io_list_flush_cl(&dev->ctrl_wr_list, cl);
+	mei_io_list_free_cl(&dev->amthif_cmd_list, cl);
 	mei_cl_wake_all(cl);
 	cl->rx_flow_ctrl_creds = 0;
 	cl->tx_flow_ctrl_creds = 0;
 	cl->timer_count = 0;
 
+	mei_cl_bus_module_put(cl);
+
 	if (!cl->me_cl)
 		return;
 
 	if (!WARN_ON(cl->me_cl->connect_count == 0))
 		cl->me_cl->connect_count--;
 
 	if (cl->me_cl->connect_count == 0)
 		cl->me_cl->tx_flow_ctrl_creds = 0;
 
 	mei_me_cl_put(cl->me_cl);
 	cl->me_cl = NULL;
 }
 
 static int mei_cl_set_connecting(struct mei_cl *cl, struct mei_me_client *me_cl)
 {
 	if (!mei_me_cl_get(me_cl))
 		return -ENOENT;
 
 	/* only one connection is allowed for fixed address clients */
 	if (me_cl->props.fixed_address) {
 		if (me_cl->connect_count) {
 			mei_me_cl_put(me_cl);
 			return -EBUSY;
 		}
 	}
 
 	cl->me_cl = me_cl;
 	cl->state = MEI_FILE_CONNECTING;
 	cl->me_cl->connect_count++;
 
 	return 0;
 }
 
 /*
  * mei_cl_send_disconnect - send disconnect request
  *
  * @cl: host client
  * @cb: callback block
  *
  * Return: 0, OK; otherwise, error.
  */
 static int mei_cl_send_disconnect(struct mei_cl *cl, struct mei_cl_cb *cb)
 {
 	struct mei_device *dev;
 	int ret;
 
 	dev = cl->dev;
 
 	ret = mei_hbm_cl_disconnect_req(dev, cl);
 	cl->status = ret;
 	if (ret) {
 		cl->state = MEI_FILE_DISCONNECT_REPLY;
 		return ret;
 	}
 
-	list_move_tail(&cb->list, &dev->ctrl_rd_list.list);
+	list_move_tail(&cb->list, &dev->ctrl_rd_list);
 	cl->timer_count = MEI_CONNECT_TIMEOUT;
 	mei_schedule_stall_timer(dev);
 
 	return 0;
 }
 
 /**
  * mei_cl_irq_disconnect - processes close related operation from
  *	interrupt thread context - send disconnect request
  *
  * @cl: client
  * @cb: callback block.
  * @cmpl_list: complete list.
  *
  * Return: 0, OK; otherwise, error.
  */
 int mei_cl_irq_disconnect(struct mei_cl *cl, struct mei_cl_cb *cb,
-			    struct mei_cl_cb *cmpl_list)
+			  struct list_head *cmpl_list)
 {
 	struct mei_device *dev = cl->dev;
 	u32 msg_slots;
 	int slots;
 	int ret;
 
 	msg_slots = mei_data2slots(sizeof(struct hbm_client_connect_request));
 	slots = mei_hbuf_empty_slots(dev);
 
 	if (slots < msg_slots)
 		return -EMSGSIZE;
 
 	ret = mei_cl_send_disconnect(cl, cb);
 	if (ret)
-		list_move_tail(&cb->list, &cmpl_list->list);
+		list_move_tail(&cb->list, cmpl_list);
 
 	return ret;
 }
 
 /**
  * __mei_cl_disconnect - disconnect host client from the me one
  *     internal function runtime pm has to be already acquired
  *
  * @cl: host client
  *
  * Return: 0 on success, <0 on failure.
  */
 static int __mei_cl_disconnect(struct mei_cl *cl)
 {
 	struct mei_device *dev;
 	struct mei_cl_cb *cb;
 	int rets;
 
 	dev = cl->dev;
 
 	cl->state = MEI_FILE_DISCONNECTING;
 
 	cb = mei_cl_enqueue_ctrl_wr_cb(cl, 0, MEI_FOP_DISCONNECT, NULL);
 	if (!cb) {
 		rets = -ENOMEM;
 		goto out;
 	}
 
 	if (mei_hbuf_acquire(dev)) {
 		rets = mei_cl_send_disconnect(cl, cb);
 		if (rets) {
 			cl_err(dev, cl, "failed to disconnect.\n");
 			goto out;
 		}
 	}
 
 	mutex_unlock(&dev->device_lock);
 	wait_event_timeout(cl->wait,
 			   cl->state == MEI_FILE_DISCONNECT_REPLY ||
 			   cl->state == MEI_FILE_DISCONNECTED,
 			   mei_secs_to_jiffies(MEI_CL_CONNECT_TIMEOUT));
 	mutex_lock(&dev->device_lock);
 
 	rets = cl->status;
 	if (cl->state != MEI_FILE_DISCONNECT_REPLY &&
 	    cl->state != MEI_FILE_DISCONNECTED) {
 		cl_dbg(dev, cl, "timeout on disconnect from FW client.\n");
 		rets = -ETIME;
 	}
 
 out:
 	/* we disconnect also on error */
 	mei_cl_set_disconnected(cl);
 	if (!rets)
 		cl_dbg(dev, cl, "successfully disconnected from FW client.\n");
 
 	mei_io_cb_free(cb);
 	return rets;
 }
 
 /**
  * mei_cl_disconnect - disconnect host client from the me one
  *
  * @cl: host client
  *
  * Locking: called under "dev->device_lock" lock
  *
  * Return: 0 on success, <0 on failure.
  */
 int mei_cl_disconnect(struct mei_cl *cl)
 {
 	struct mei_device *dev;
 	int rets;
 
 	if (WARN_ON(!cl || !cl->dev))
 		return -ENODEV;
 
 	dev = cl->dev;
 
 	cl_dbg(dev, cl, "disconnecting");
 
 	if (!mei_cl_is_connected(cl))
 		return 0;
 
 	if (mei_cl_is_fixed_address(cl)) {
 		mei_cl_set_disconnected(cl);
 		return 0;
 	}
 
 	rets = pm_runtime_get(dev->dev);
 	if (rets < 0 && rets != -EINPROGRESS) {
 		pm_runtime_put_noidle(dev->dev);
 		cl_err(dev, cl, "rpm: get failed %d\n", rets);
 		return rets;
 	}
 
 	rets = __mei_cl_disconnect(cl);
 
 	cl_dbg(dev, cl, "rpm: autosuspend\n");
 	pm_runtime_mark_last_busy(dev->dev);
 	pm_runtime_put_autosuspend(dev->dev);
 
 	return rets;
 }
 
 
 /**
  * mei_cl_is_other_connecting - checks if other
  *    client with the same me client id is connecting
  *
  * @cl: private data of the file object
  *
  * Return: true if other client is connected, false - otherwise.
  */
 static bool mei_cl_is_other_connecting(struct mei_cl *cl)
 {
 	struct mei_device *dev;
 	struct mei_cl_cb *cb;
 
 	dev = cl->dev;
 
-	list_for_each_entry(cb, &dev->ctrl_rd_list.list, list) {
+	list_for_each_entry(cb, &dev->ctrl_rd_list, list) {
 		if (cb->fop_type == MEI_FOP_CONNECT &&
 		    mei_cl_me_id(cl) == mei_cl_me_id(cb->cl))
 			return true;
 	}
 
 	return false;
 }
 
 /**
  * mei_cl_send_connect - send connect request
  *
  * @cl: host client
  * @cb: callback block
  *
  * Return: 0, OK; otherwise, error.
  */
 static int mei_cl_send_connect(struct mei_cl *cl, struct mei_cl_cb *cb)
 {
 	struct mei_device *dev;
 	int ret;
 
 	dev = cl->dev;
 
 	ret = mei_hbm_cl_connect_req(dev, cl);
 	cl->status = ret;
 	if (ret) {
 		cl->state = MEI_FILE_DISCONNECT_REPLY;
 		return ret;
 	}
 
-	list_move_tail(&cb->list, &dev->ctrl_rd_list.list);
+	list_move_tail(&cb->list, &dev->ctrl_rd_list);
 	cl->timer_count = MEI_CONNECT_TIMEOUT;
 	mei_schedule_stall_timer(dev);
 	return 0;
 }
 
 /**
  * mei_cl_irq_connect - send connect request in irq_thread context
  *
  * @cl: host client
  * @cb: callback block
  * @cmpl_list: complete list
  *
  * Return: 0, OK; otherwise, error.
  */
 int mei_cl_irq_connect(struct mei_cl *cl, struct mei_cl_cb *cb,
-			      struct mei_cl_cb *cmpl_list)
+		       struct list_head *cmpl_list)
 {
 	struct mei_device *dev = cl->dev;
 	u32 msg_slots;
 	int slots;
 	int rets;
 
 	msg_slots = mei_data2slots(sizeof(struct hbm_client_connect_request));
 	slots = mei_hbuf_empty_slots(dev);
 
 	if (mei_cl_is_other_connecting(cl))
 		return 0;
 
 	if (slots < msg_slots)
 		return -EMSGSIZE;
 
 	rets = mei_cl_send_connect(cl, cb);
 	if (rets)
-		list_move_tail(&cb->list, &cmpl_list->list);
+		list_move_tail(&cb->list, cmpl_list);
 
 	return rets;
 }
 
 /**
  * mei_cl_connect - connect host client to the me one
  *
  * @cl: host client
  * @me_cl: me client
  * @fp: pointer to file structure
  *
  * Locking: called under "dev->device_lock" lock
  *
  * Return: 0 on success, <0 on failure.
  */
 int mei_cl_connect(struct mei_cl *cl, struct mei_me_client *me_cl,
 		   const struct file *fp)
 {
 	struct mei_device *dev;
 	struct mei_cl_cb *cb;
 	int rets;
 
 	if (WARN_ON(!cl || !cl->dev || !me_cl))
 		return -ENODEV;
 
 	dev = cl->dev;
 
+	if (!mei_cl_bus_module_get(cl))
+		return -ENODEV;
+
 	rets = mei_cl_set_connecting(cl, me_cl);
 	if (rets)
-		return rets;
+		goto nortpm;
 
 	if (mei_cl_is_fixed_address(cl)) {
 		cl->state = MEI_FILE_CONNECTED;
-		return 0;
+		rets = 0;
+		goto nortpm;
 	}
 
 	rets = pm_runtime_get(dev->dev);
 	if (rets < 0 && rets != -EINPROGRESS) {
 		pm_runtime_put_noidle(dev->dev);
 		cl_err(dev, cl, "rpm: get failed %d\n", rets);
 		goto nortpm;
 	}
 
 	cb = mei_cl_enqueue_ctrl_wr_cb(cl, 0, MEI_FOP_CONNECT, fp);
 	if (!cb) {
 		rets = -ENOMEM;
 		goto out;
 	}
 
 	/* run hbuf acquire last so we don't have to undo */
 	if (!mei_cl_is_other_connecting(cl) && mei_hbuf_acquire(dev)) {
 		rets = mei_cl_send_connect(cl, cb);
 		if (rets)
 			goto out;
 	}
 
 	mutex_unlock(&dev->device_lock);
 	wait_event_timeout(cl->wait,
 			(cl->state == MEI_FILE_CONNECTED ||
 			 cl->state == MEI_FILE_DISCONNECTED ||
 			 cl->state == MEI_FILE_DISCONNECT_REQUIRED ||
 			 cl->state == MEI_FILE_DISCONNECT_REPLY),
 			mei_secs_to_jiffies(MEI_CL_CONNECT_TIMEOUT));
 	mutex_lock(&dev->device_lock);
 
 	if (!mei_cl_is_connected(cl)) {
 		if (cl->state == MEI_FILE_DISCONNECT_REQUIRED) {
-			mei_io_list_flush(&dev->ctrl_rd_list, cl);
-			mei_io_list_flush(&dev->ctrl_wr_list, cl);
+			mei_io_list_flush_cl(&dev->ctrl_rd_list, cl);
+			mei_io_list_flush_cl(&dev->ctrl_wr_list, cl);
 			 /* ignore disconnect return valuue;
 			  * in case of failure reset will be invoked
 			  */
 			__mei_cl_disconnect(cl);
 			rets = -EFAULT;
 			goto out;
 		}
 
 		/* timeout or something went really wrong */
 		if (!cl->status)
 			cl->status = -EFAULT;
 	}
 
 	rets = cl->status;
 out:
 	cl_dbg(dev, cl, "rpm: autosuspend\n");
 	pm_runtime_mark_last_busy(dev->dev);
 	pm_runtime_put_autosuspend(dev->dev);
 
 	mei_io_cb_free(cb);
 
 nortpm:
 	if (!mei_cl_is_connected(cl))
 		mei_cl_set_disconnected(cl);
 
 	return rets;
 }
 
 /**
  * mei_cl_alloc_linked - allocate and link host client
  *
  * @dev: the device structure
  *
  * Return: cl on success ERR_PTR on failure
  */
 struct mei_cl *mei_cl_alloc_linked(struct mei_device *dev)
 {
 	struct mei_cl *cl;
 	int ret;
 
 	cl = mei_cl_allocate(dev);
 	if (!cl) {
 		ret = -ENOMEM;
 		goto err;
 	}
 
 	ret = mei_cl_link(cl);
 	if (ret)
 		goto err;
 
 	return cl;
 err:
 	kfree(cl);
 	return ERR_PTR(ret);
 }
 
 /**
  * mei_cl_tx_flow_ctrl_creds - checks flow_control credits for cl.
  *
  * @cl: host client
  *
  * Return: 1 if tx_flow_ctrl_creds >0, 0 - otherwise.
  */
 static int mei_cl_tx_flow_ctrl_creds(struct mei_cl *cl)
 {
 	if (WARN_ON(!cl || !cl->me_cl))
 		return -EINVAL;
 
 	if (cl->tx_flow_ctrl_creds > 0)
 		return 1;
 
 	if (mei_cl_is_fixed_address(cl))
 		return 1;
 
 	if (mei_cl_is_single_recv_buf(cl)) {
 		if (cl->me_cl->tx_flow_ctrl_creds > 0)
 			return 1;
 	}
 	return 0;
 }
 
 /**
  * mei_cl_tx_flow_ctrl_creds_reduce - reduces transmit flow control credits
  *   for a client
  *
  * @cl: host client
  *
  * Return:
  *	0 on success
  *	-EINVAL when ctrl credits are <= 0
  */
 static int mei_cl_tx_flow_ctrl_creds_reduce(struct mei_cl *cl)
 {
 	if (WARN_ON(!cl || !cl->me_cl))
 		return -EINVAL;
 
 	if (mei_cl_is_fixed_address(cl))
 		return 0;
 
 	if (mei_cl_is_single_recv_buf(cl)) {
 		if (WARN_ON(cl->me_cl->tx_flow_ctrl_creds <= 0))
 			return -EINVAL;
 		cl->me_cl->tx_flow_ctrl_creds--;
 	} else {
 		if (WARN_ON(cl->tx_flow_ctrl_creds <= 0))
 			return -EINVAL;
 		cl->tx_flow_ctrl_creds--;
 	}
 	return 0;
 }
 
 /**
  *  mei_cl_notify_fop2req - convert fop to proper request
  *
  * @fop: client notification start response command
  *
  * Return:  MEI_HBM_NOTIFICATION_START/STOP
  */
 u8 mei_cl_notify_fop2req(enum mei_cb_file_ops fop)
 {
 	if (fop == MEI_FOP_NOTIFY_START)
 		return MEI_HBM_NOTIFICATION_START;
 	else
 		return MEI_HBM_NOTIFICATION_STOP;
 }
 
 /**
  *  mei_cl_notify_req2fop - convert notification request top file operation type
  *
  * @req: hbm notification request type
  *
  * Return:  MEI_FOP_NOTIFY_START/STOP
  */
 enum mei_cb_file_ops mei_cl_notify_req2fop(u8 req)
 {
 	if (req == MEI_HBM_NOTIFICATION_START)
 		return MEI_FOP_NOTIFY_START;
 	else
 		return MEI_FOP_NOTIFY_STOP;
 }
 
 /**
  * mei_cl_irq_notify - send notification request in irq_thread context
  *
  * @cl: client
  * @cb: callback block.
  * @cmpl_list: complete list.
  *
  * Return: 0 on such and error otherwise.
  */
 int mei_cl_irq_notify(struct mei_cl *cl, struct mei_cl_cb *cb,
-		      struct mei_cl_cb *cmpl_list)
+		      struct list_head *cmpl_list)
 {
 	struct mei_device *dev = cl->dev;
 	u32 msg_slots;
 	int slots;
 	int ret;
 	bool request;
 
 	msg_slots = mei_data2slots(sizeof(struct hbm_client_connect_request));
 	slots = mei_hbuf_empty_slots(dev);
 
 	if (slots < msg_slots)
 		return -EMSGSIZE;
 
 	request = mei_cl_notify_fop2req(cb->fop_type);
 	ret = mei_hbm_cl_notify_req(dev, cl, request);
 	if (ret) {
 		cl->status = ret;
-		list_move_tail(&cb->list, &cmpl_list->list);
+		list_move_tail(&cb->list, cmpl_list);
 		return ret;
 	}
 
-	list_move_tail(&cb->list, &dev->ctrl_rd_list.list);
+	list_move_tail(&cb->list, &dev->ctrl_rd_list);
 	return 0;
 }
 
 /**
  * mei_cl_notify_request - send notification stop/start request
  *
  * @cl: host client
  * @fp: associate request with file
  * @request: 1 for start or 0 for stop
  *
  * Locking: called under "dev->device_lock" lock
  *
  * Return: 0 on such and error otherwise.
  */
 int mei_cl_notify_request(struct mei_cl *cl,
 			  const struct file *fp, u8 request)
 {
 	struct mei_device *dev;
 	struct mei_cl_cb *cb;
 	enum mei_cb_file_ops fop_type;
 	int rets;
 
 	if (WARN_ON(!cl || !cl->dev))
 		return -ENODEV;
 
 	dev = cl->dev;
 
 	if (!dev->hbm_f_ev_supported) {
 		cl_dbg(dev, cl, "notifications not supported\n");
 		return -EOPNOTSUPP;
 	}
 
+	if (!mei_cl_is_connected(cl))
+		return -ENODEV;
+
 	rets = pm_runtime_get(dev->dev);
 	if (rets < 0 && rets != -EINPROGRESS) {
 		pm_runtime_put_noidle(dev->dev);
 		cl_err(dev, cl, "rpm: get failed %d\n", rets);
 		return rets;
 	}
 
 	fop_type = mei_cl_notify_req2fop(request);
 	cb = mei_cl_enqueue_ctrl_wr_cb(cl, 0, fop_type, fp);
 	if (!cb) {
 		rets = -ENOMEM;
 		goto out;
 	}
 
 	if (mei_hbuf_acquire(dev)) {
 		if (mei_hbm_cl_notify_req(dev, cl, request)) {
 			rets = -ENODEV;
 			goto out;
 		}
-		list_move_tail(&cb->list, &dev->ctrl_rd_list.list);
+		list_move_tail(&cb->list, &dev->ctrl_rd_list);
 	}
 
 	mutex_unlock(&dev->device_lock);
 	wait_event_timeout(cl->wait,
 			   cl->notify_en == request || !mei_cl_is_connected(cl),
 			   mei_secs_to_jiffies(MEI_CL_CONNECT_TIMEOUT));
 	mutex_lock(&dev->device_lock);
 
 	if (cl->notify_en != request && !cl->status)
 		cl->status = -EFAULT;
 
 	rets = cl->status;
 
 out:
 	cl_dbg(dev, cl, "rpm: autosuspend\n");
 	pm_runtime_mark_last_busy(dev->dev);
 	pm_runtime_put_autosuspend(dev->dev);
 
 	mei_io_cb_free(cb);
 	return rets;
 }
 
 /**
  * mei_cl_notify - raise notification
  *
  * @cl: host client
  *
  * Locking: called under "dev->device_lock" lock
  */
 void mei_cl_notify(struct mei_cl *cl)
 {
 	struct mei_device *dev;
 
 	if (!cl || !cl->dev)
 		return;
 
 	dev = cl->dev;
 
 	if (!cl->notify_en)
 		return;
 
 	cl_dbg(dev, cl, "notify event");
 	cl->notify_ev = true;
 	if (!mei_cl_bus_notify_event(cl))
 		wake_up_interruptible(&cl->ev_wait);
 
 	if (cl->ev_async)
 		kill_fasync(&cl->ev_async, SIGIO, POLL_PRI);
 
 }
 
 /**
  * mei_cl_notify_get - get or wait for notification event
  *
  * @cl: host client
  * @block: this request is blocking
  * @notify_ev: true if notification event was received
  *
  * Locking: called under "dev->device_lock" lock
  *
  * Return: 0 on such and error otherwise.
  */
 int mei_cl_notify_get(struct mei_cl *cl, bool block, bool *notify_ev)
 {
 	struct mei_device *dev;
 	int rets;
 
 	*notify_ev = false;
 
 	if (WARN_ON(!cl || !cl->dev))
 		return -ENODEV;
 
 	dev = cl->dev;
 
+	if (!dev->hbm_f_ev_supported) {
+		cl_dbg(dev, cl, "notifications not supported\n");
+		return -EOPNOTSUPP;
+	}
+
 	if (!mei_cl_is_connected(cl))
 		return -ENODEV;
 
 	if (cl->notify_ev)
 		goto out;
 
 	if (!block)
 		return -EAGAIN;
 
 	mutex_unlock(&dev->device_lock);
 	rets = wait_event_interruptible(cl->ev_wait, cl->notify_ev);
 	mutex_lock(&dev->device_lock);
 
 	if (rets < 0)
 		return rets;
 
 out:
 	*notify_ev = cl->notify_ev;
 	cl->notify_ev = false;
 	return 0;
 }
 
 /**
  * mei_cl_read_start - the start read client message function.
  *
  * @cl: host client
  * @length: number of bytes to read
  * @fp: pointer to file structure
  *
  * Return: 0 on success, <0 on failure.
  */
 int mei_cl_read_start(struct mei_cl *cl, size_t length, const struct file *fp)
 {
 	struct mei_device *dev;
 	struct mei_cl_cb *cb;
 	int rets;
 
 	if (WARN_ON(!cl || !cl->dev))
 		return -ENODEV;
 
 	dev = cl->dev;
 
 	if (!mei_cl_is_connected(cl))
 		return -ENODEV;
 
 	if (!mei_me_cl_is_active(cl->me_cl)) {
 		cl_err(dev, cl, "no such me client\n");
 		return  -ENOTTY;
 	}
 
 	if (mei_cl_is_fixed_address(cl) || cl == &dev->iamthif_cl)
 		return 0;
 
 	/* HW currently supports only one pending read */
 	if (cl->rx_flow_ctrl_creds)
 		return -EBUSY;
 
 	cb = mei_cl_enqueue_ctrl_wr_cb(cl, length, MEI_FOP_READ, fp);
 	if (!cb)
 		return -ENOMEM;
 
 	rets = pm_runtime_get(dev->dev);
 	if (rets < 0 && rets != -EINPROGRESS) {
 		pm_runtime_put_noidle(dev->dev);
 		cl_err(dev, cl, "rpm: get failed %d\n", rets);
 		goto nortpm;
 	}
 
 	rets = 0;
 	if (mei_hbuf_acquire(dev)) {
 		rets = mei_hbm_cl_flow_control_req(dev, cl);
 		if (rets < 0)
 			goto out;
 
 		list_move_tail(&cb->list, &cl->rd_pending);
 	}
 	cl->rx_flow_ctrl_creds++;
 
 out:
 	cl_dbg(dev, cl, "rpm: autosuspend\n");
 	pm_runtime_mark_last_busy(dev->dev);
 	pm_runtime_put_autosuspend(dev->dev);
 nortpm:
 	if (rets)
 		mei_io_cb_free(cb);
 
 	return rets;
 }
 
 /**
  * mei_cl_irq_write - write a message to device
  *	from the interrupt thread context
  *
  * @cl: client
  * @cb: callback block.
  * @cmpl_list: complete list.
  *
  * Return: 0, OK; otherwise error.
  */
 int mei_cl_irq_write(struct mei_cl *cl, struct mei_cl_cb *cb,
-		     struct mei_cl_cb *cmpl_list)
+		     struct list_head *cmpl_list)
 {
 	struct mei_device *dev;
 	struct mei_msg_data *buf;
 	struct mei_msg_hdr mei_hdr;
 	size_t len;
 	u32 msg_slots;
 	int slots;
 	int rets;
 	bool first_chunk;
 
 	if (WARN_ON(!cl || !cl->dev))
 		return -ENODEV;
 
 	dev = cl->dev;
 
 	buf = &cb->buf;
 
 	first_chunk = cb->buf_idx == 0;
 
 	rets = first_chunk ? mei_cl_tx_flow_ctrl_creds(cl) : 1;
 	if (rets < 0)
 		goto err;
 
 	if (rets == 0) {
 		cl_dbg(dev, cl, "No flow control credentials: not sending.\n");
 		return 0;
 	}
 
 	slots = mei_hbuf_empty_slots(dev);
 	len = buf->size - cb->buf_idx;
 	msg_slots = mei_data2slots(len);
 
 	mei_hdr.host_addr = mei_cl_host_addr(cl);
 	mei_hdr.me_addr = mei_cl_me_id(cl);
 	mei_hdr.reserved = 0;
 	mei_hdr.internal = cb->internal;
 
 	if (slots >= msg_slots) {
 		mei_hdr.length = len;
 		mei_hdr.msg_complete = 1;
 	/* Split the message only if we can write the whole host buffer */
 	} else if (slots == dev->hbuf_depth) {
 		msg_slots = slots;
 		len = (slots * sizeof(u32)) - sizeof(struct mei_msg_hdr);
 		mei_hdr.length = len;
 		mei_hdr.msg_complete = 0;
 	} else {
 		/* wait for next time the host buffer is empty */
 		return 0;
 	}
 
 	cl_dbg(dev, cl, "buf: size = %zu idx = %zu\n",
 			cb->buf.size, cb->buf_idx);
 
 	rets = mei_write_message(dev, &mei_hdr, buf->data + cb->buf_idx);
 	if (rets)
 		goto err;
 
 	cl->status = 0;
 	cl->writing_state = MEI_WRITING;
 	cb->buf_idx += mei_hdr.length;
 	cb->completed = mei_hdr.msg_complete == 1;
 
 	if (first_chunk) {
 		if (mei_cl_tx_flow_ctrl_creds_reduce(cl)) {
 			rets = -EIO;
 			goto err;
 		}
 	}
 
 	if (mei_hdr.msg_complete)
-		list_move_tail(&cb->list, &dev->write_waiting_list.list);
+		list_move_tail(&cb->list, &dev->write_waiting_list);
 
 	return 0;
 
 err:
 	cl->status = rets;
-	list_move_tail(&cb->list, &cmpl_list->list);
+	list_move_tail(&cb->list, cmpl_list);
 	return rets;
 }
 
 /**
  * mei_cl_write - submit a write cb to mei device
  *	assumes device_lock is locked
  *
  * @cl: host client
  * @cb: write callback with filled data
  *
  * Return: number of bytes sent on success, <0 on failure.
  */
 int mei_cl_write(struct mei_cl *cl, struct mei_cl_cb *cb)
 {
 	struct mei_device *dev;
 	struct mei_msg_data *buf;
 	struct mei_msg_hdr mei_hdr;
 	int size;
 	int rets;
 	bool blocking;
 
 	if (WARN_ON(!cl || !cl->dev))
 		return -ENODEV;
 
 	if (WARN_ON(!cb))
 		return -EINVAL;
 
 	dev = cl->dev;
 
 	buf = &cb->buf;
 	size = buf->size;
 	blocking = cb->blocking;
 
 	cl_dbg(dev, cl, "size=%d\n", size);
 
 	rets = pm_runtime_get(dev->dev);
 	if (rets < 0 && rets != -EINPROGRESS) {
 		pm_runtime_put_noidle(dev->dev);
 		cl_err(dev, cl, "rpm: get failed %d\n", rets);
 		goto free;
 	}
 
 	cb->buf_idx = 0;
 	cl->writing_state = MEI_IDLE;
 
 	mei_hdr.host_addr = mei_cl_host_addr(cl);
 	mei_hdr.me_addr = mei_cl_me_id(cl);
 	mei_hdr.reserved = 0;
 	mei_hdr.msg_complete = 0;
 	mei_hdr.internal = cb->internal;
 
 	rets = mei_cl_tx_flow_ctrl_creds(cl);
 	if (rets < 0)
 		goto err;
 
 	if (rets == 0) {
 		cl_dbg(dev, cl, "No flow control credentials: not sending.\n");
 		rets = size;
 		goto out;
 	}
 	if (!mei_hbuf_acquire(dev)) {
 		cl_dbg(dev, cl, "Cannot acquire the host buffer: not sending.\n");
 		rets = size;
 		goto out;
 	}
 
 	/* Check for a maximum length */
 	if (size > mei_hbuf_max_len(dev)) {
 		mei_hdr.length = mei_hbuf_max_len(dev);
 		mei_hdr.msg_complete = 0;
 	} else {
 		mei_hdr.length = size;
 		mei_hdr.msg_complete = 1;
 	}
 
 	rets = mei_write_message(dev, &mei_hdr, buf->data);
 	if (rets)
 		goto err;
 
 	rets = mei_cl_tx_flow_ctrl_creds_reduce(cl);
 	if (rets)
 		goto err;
 
 	cl->writing_state = MEI_WRITING;
 	cb->buf_idx = mei_hdr.length;
 	cb->completed = mei_hdr.msg_complete == 1;
 
 out:
 	if (mei_hdr.msg_complete)
-		list_add_tail(&cb->list, &dev->write_waiting_list.list);
+		list_add_tail(&cb->list, &dev->write_waiting_list);
 	else
-		list_add_tail(&cb->list, &dev->write_list.list);
+		list_add_tail(&cb->list, &dev->write_list);
 
 	cb = NULL;
 	if (blocking && cl->writing_state != MEI_WRITE_COMPLETE) {
 
 		mutex_unlock(&dev->device_lock);
 		rets = wait_event_interruptible(cl->tx_wait,
 				cl->writing_state == MEI_WRITE_COMPLETE ||
 				(!mei_cl_is_connected(cl)));
 		mutex_lock(&dev->device_lock);
 		/* wait_event_interruptible returns -ERESTARTSYS */
 		if (rets) {
 			if (signal_pending(current))
 				rets = -EINTR;
 			goto err;
 		}
 		if (cl->writing_state != MEI_WRITE_COMPLETE) {
 			rets = -EFAULT;
 			goto err;
 		}
 	}
 
 	rets = size;
 err:
 	cl_dbg(dev, cl, "rpm: autosuspend\n");
 	pm_runtime_mark_last_busy(dev->dev);
 	pm_runtime_put_autosuspend(dev->dev);
 free:
 	mei_io_cb_free(cb);
 
 	return rets;
 }
 
 
 /**
  * mei_cl_complete - processes completed operation for a client
  *
  * @cl: private data of the file object.
  * @cb: callback block.
  */
 void mei_cl_complete(struct mei_cl *cl, struct mei_cl_cb *cb)
 {
 	struct mei_device *dev = cl->dev;
 
 	switch (cb->fop_type) {
 	case MEI_FOP_WRITE:
 		mei_io_cb_free(cb);
 		cl->writing_state = MEI_WRITE_COMPLETE;
 		if (waitqueue_active(&cl->tx_wait)) {
 			wake_up_interruptible(&cl->tx_wait);
 		} else {
 			pm_runtime_mark_last_busy(dev->dev);
 			pm_request_autosuspend(dev->dev);
 		}
 		break;
 
 	case MEI_FOP_READ:
 		list_add_tail(&cb->list, &cl->rd_completed);
 		if (!mei_cl_is_fixed_address(cl) &&
 		    !WARN_ON(!cl->rx_flow_ctrl_creds))
 			cl->rx_flow_ctrl_creds--;
 		if (!mei_cl_bus_rx_event(cl))
 			wake_up_interruptible(&cl->rx_wait);
 		break;
 
 	case MEI_FOP_CONNECT:
 	case MEI_FOP_DISCONNECT:
 	case MEI_FOP_NOTIFY_STOP:
 	case MEI_FOP_NOTIFY_START:
 		if (waitqueue_active(&cl->wait))
 			wake_up(&cl->wait);
 
 		break;
 	case MEI_FOP_DISCONNECT_RSP:
 		mei_io_cb_free(cb);
 		mei_cl_set_disconnected(cl);
 		break;
 	default:
 		BUG_ON(0);
 	}
 }
 
 
 /**
  * mei_cl_all_disconnect - disconnect forcefully all connected clients
  *
  * @dev: mei device
  */
 void mei_cl_all_disconnect(struct mei_device *dev)
 {
 	struct mei_cl *cl;
 
 	list_for_each_entry(cl, &dev->file_list, link)
 		mei_cl_set_disconnected(cl);
 }
diff --git a/drivers/misc/mei/client.h b/drivers/misc/mei/client.h
index f2545af9be7b..545ae319ba90 100644
--- a/drivers/misc/mei/client.h
+++ b/drivers/misc/mei/client.h
@@ -1,253 +1,241 @@
 /*
  *
  * Intel Management Engine Interface (Intel MEI) Linux driver
  * Copyright (c) 2003-2012, Intel Corporation.
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms and conditions of the GNU General Public License,
  * version 2, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope it will be useful, but WITHOUT
  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
  * more details.
  *
  */
 
 #ifndef _MEI_CLIENT_H_
 #define _MEI_CLIENT_H_
 
 #include <linux/types.h>
 #include <linux/poll.h>
 #include <linux/mei.h>
 
 #include "mei_dev.h"
 
 /*
  * reference counting base function
  */
 void mei_me_cl_init(struct mei_me_client *me_cl);
 void mei_me_cl_put(struct mei_me_client *me_cl);
 struct mei_me_client *mei_me_cl_get(struct mei_me_client *me_cl);
 
 void mei_me_cl_add(struct mei_device *dev, struct mei_me_client *me_cl);
 void mei_me_cl_del(struct mei_device *dev, struct mei_me_client *me_cl);
 
 struct mei_me_client *mei_me_cl_by_uuid(struct mei_device *dev,
 					const uuid_le *uuid);
 struct mei_me_client *mei_me_cl_by_id(struct mei_device *dev, u8 client_id);
 struct mei_me_client *mei_me_cl_by_uuid_id(struct mei_device *dev,
 					   const uuid_le *uuid, u8 client_id);
 void mei_me_cl_rm_by_uuid(struct mei_device *dev, const uuid_le *uuid);
 void mei_me_cl_rm_by_uuid_id(struct mei_device *dev,
 			     const uuid_le *uuid, u8 id);
 void mei_me_cl_rm_all(struct mei_device *dev);
 
 /**
  * mei_me_cl_is_active - check whether me client is active in the fw
  *
  * @me_cl: me client
  *
  * Return: true if the me client is active in the firmware
  */
 static inline bool mei_me_cl_is_active(const struct mei_me_client *me_cl)
 {
 	return !list_empty_careful(&me_cl->list);
 }
 
 /**
  * mei_me_cl_uuid - return me client protocol name (uuid)
  *
  * @me_cl: me client
  *
  * Return: me client protocol name
  */
 static inline const uuid_le *mei_me_cl_uuid(const struct mei_me_client *me_cl)
 {
 	return &me_cl->props.protocol_name;
 }
 
 /**
  * mei_me_cl_ver - return me client protocol version
  *
  * @me_cl: me client
  *
  * Return: me client protocol version
  */
 static inline u8 mei_me_cl_ver(const struct mei_me_client *me_cl)
 {
 	return me_cl->props.protocol_version;
 }
 
 /*
  * MEI IO Functions
  */
 void mei_io_cb_free(struct mei_cl_cb *priv_cb);
-
-/**
- * mei_io_list_init - Sets up a queue list.
- *
- * @list: An instance cl callback structure
- */
-static inline void mei_io_list_init(struct mei_cl_cb *list)
-{
-	INIT_LIST_HEAD(&list->list);
-}
-void mei_io_list_flush(struct mei_cl_cb *list, struct mei_cl *cl);
+void mei_io_list_free_fp(struct list_head *head, const struct file *fp);
 
 /*
  * MEI Host Client Functions
  */
 
 struct mei_cl *mei_cl_allocate(struct mei_device *dev);
 void mei_cl_init(struct mei_cl *cl, struct mei_device *dev);
 
 
 int mei_cl_link(struct mei_cl *cl);
 int mei_cl_unlink(struct mei_cl *cl);
 
 struct mei_cl *mei_cl_alloc_linked(struct mei_device *dev);
 
 struct mei_cl_cb *mei_cl_read_cb(const struct mei_cl *cl,
 				 const struct file *fp);
-void mei_cl_read_cb_flush(const struct mei_cl *cl, const struct file *fp);
 struct mei_cl_cb *mei_cl_alloc_cb(struct mei_cl *cl, size_t length,
 				  enum mei_cb_file_ops type,
 				  const struct file *fp);
 struct mei_cl_cb *mei_cl_enqueue_ctrl_wr_cb(struct mei_cl *cl, size_t length,
 					    enum mei_cb_file_ops type,
 					    const struct file *fp);
 int mei_cl_flush_queues(struct mei_cl *cl, const struct file *fp);
 
 /*
  *  MEI input output function prototype
  */
 
 /**
  * mei_cl_is_connected - host client is connected
  *
  * @cl: host client
  *
  * Return: true if the host client is connected
  */
 static inline bool mei_cl_is_connected(struct mei_cl *cl)
 {
 	return  cl->state == MEI_FILE_CONNECTED;
 }
 
 /**
  * mei_cl_me_id - me client id
  *
  * @cl: host client
  *
  * Return: me client id or 0 if client is not connected
  */
 static inline u8 mei_cl_me_id(const struct mei_cl *cl)
 {
 	return cl->me_cl ? cl->me_cl->client_id : 0;
 }
 
 /**
  * mei_cl_mtu - maximal message that client can send and receive
  *
  * @cl: host client
  *
  * Return: mtu
  */
 static inline size_t mei_cl_mtu(const struct mei_cl *cl)
 {
 	return cl->me_cl->props.max_msg_length;
 }
 
 /**
  * mei_cl_is_fixed_address - check whether the me client uses fixed address
  *
  * @cl: host client
  *
  * Return: true if the client is connected and it has fixed me address
  */
 static inline bool mei_cl_is_fixed_address(const struct mei_cl *cl)
 {
 	return cl->me_cl && cl->me_cl->props.fixed_address;
 }
 
 /**
  * mei_cl_is_single_recv_buf- check whether the me client
  *       uses single receiving buffer
  *
  * @cl: host client
  *
  * Return: true if single_recv_buf == 1; 0 otherwise
  */
 static inline bool mei_cl_is_single_recv_buf(const struct mei_cl *cl)
 {
 	return cl->me_cl->props.single_recv_buf;
 }
 
 /**
  * mei_cl_uuid -  client's uuid
  *
  * @cl: host client
  *
  * Return: return uuid of connected me client
  */
 static inline const uuid_le *mei_cl_uuid(const struct mei_cl *cl)
 {
 	return mei_me_cl_uuid(cl->me_cl);
 }
 
 /**
  * mei_cl_host_addr - client's host address
  *
  * @cl: host client
  *
  * Return: 0 for fixed address client, host address for dynamic client
  */
 static inline u8 mei_cl_host_addr(const struct mei_cl *cl)
 {
 	return  mei_cl_is_fixed_address(cl) ? 0 : cl->host_client_id;
 }
 
 int mei_cl_disconnect(struct mei_cl *cl);
-void mei_cl_set_disconnected(struct mei_cl *cl);
 int mei_cl_irq_disconnect(struct mei_cl *cl, struct mei_cl_cb *cb,
-			  struct mei_cl_cb *cmpl_list);
+			  struct list_head *cmpl_list);
 int mei_cl_connect(struct mei_cl *cl, struct mei_me_client *me_cl,
 		   const struct file *file);
 int mei_cl_irq_connect(struct mei_cl *cl, struct mei_cl_cb *cb,
-			      struct mei_cl_cb *cmpl_list);
+		       struct list_head *cmpl_list);
 int mei_cl_read_start(struct mei_cl *cl, size_t length, const struct file *fp);
 int mei_cl_irq_read_msg(struct mei_cl *cl, struct mei_msg_hdr *hdr,
-			struct mei_cl_cb *cmpl_list);
+			struct list_head *cmpl_list);
 int mei_cl_write(struct mei_cl *cl, struct mei_cl_cb *cb);
 int mei_cl_irq_write(struct mei_cl *cl, struct mei_cl_cb *cb,
-		     struct mei_cl_cb *cmpl_list);
+		     struct list_head *cmpl_list);
 
 void mei_cl_complete(struct mei_cl *cl, struct mei_cl_cb *cb);
 
 void mei_host_client_init(struct mei_device *dev);
 
 u8 mei_cl_notify_fop2req(enum mei_cb_file_ops fop);
 enum mei_cb_file_ops mei_cl_notify_req2fop(u8 request);
 int mei_cl_notify_request(struct mei_cl *cl,
 			  const struct file *file, u8 request);
 int mei_cl_irq_notify(struct mei_cl *cl, struct mei_cl_cb *cb,
-		      struct mei_cl_cb *cmpl_list);
+		      struct list_head *cmpl_list);
 int mei_cl_notify_get(struct mei_cl *cl, bool block, bool *notify_ev);
 void mei_cl_notify(struct mei_cl *cl);
 
 void mei_cl_all_disconnect(struct mei_device *dev);
 
 #define MEI_CL_FMT "cl:host=%02d me=%02d "
 #define MEI_CL_PRM(cl) (cl)->host_client_id, mei_cl_me_id(cl)
 
 #define cl_dbg(dev, cl, format, arg...) \
 	dev_dbg((dev)->dev, MEI_CL_FMT format, MEI_CL_PRM(cl), ##arg)
 
 #define cl_warn(dev, cl, format, arg...) \
 	dev_warn((dev)->dev, MEI_CL_FMT format, MEI_CL_PRM(cl), ##arg)
 
 #define cl_err(dev, cl, format, arg...) \
 	dev_err((dev)->dev, MEI_CL_FMT format, MEI_CL_PRM(cl), ##arg)
 
 #endif /* _MEI_CLIENT_H_ */
diff --git a/drivers/misc/mei/hbm.c b/drivers/misc/mei/hbm.c
index 25b4a1ba522d..ba3a774c8d71 100644
--- a/drivers/misc/mei/hbm.c
+++ b/drivers/misc/mei/hbm.c
@@ -1,1257 +1,1257 @@
 /*
  *
  * Intel Management Engine Interface (Intel MEI) Linux driver
  * Copyright (c) 2003-2012, Intel Corporation.
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms and conditions of the GNU General Public License,
  * version 2, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope it will be useful, but WITHOUT
  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
  * more details.
  *
  */
 
 #include <linux/export.h>
 #include <linux/sched.h>
 #include <linux/wait.h>
 #include <linux/pm_runtime.h>
 #include <linux/slab.h>
 
 #include <linux/mei.h>
 
 #include "mei_dev.h"
 #include "hbm.h"
 #include "client.h"
 
 static const char *mei_hbm_status_str(enum mei_hbm_status status)
 {
 #define MEI_HBM_STATUS(status) case MEI_HBMS_##status: return #status
 	switch (status) {
 	MEI_HBM_STATUS(SUCCESS);
 	MEI_HBM_STATUS(CLIENT_NOT_FOUND);
 	MEI_HBM_STATUS(ALREADY_EXISTS);
 	MEI_HBM_STATUS(REJECTED);
 	MEI_HBM_STATUS(INVALID_PARAMETER);
 	MEI_HBM_STATUS(NOT_ALLOWED);
 	MEI_HBM_STATUS(ALREADY_STARTED);
 	MEI_HBM_STATUS(NOT_STARTED);
 	default: return "unknown";
 	}
 #undef MEI_HBM_STATUS
 };
 
 static const char *mei_cl_conn_status_str(enum mei_cl_connect_status status)
 {
 #define MEI_CL_CS(status) case MEI_CL_CONN_##status: return #status
 	switch (status) {
 	MEI_CL_CS(SUCCESS);
 	MEI_CL_CS(NOT_FOUND);
 	MEI_CL_CS(ALREADY_STARTED);
 	MEI_CL_CS(OUT_OF_RESOURCES);
 	MEI_CL_CS(MESSAGE_SMALL);
 	MEI_CL_CS(NOT_ALLOWED);
 	default: return "unknown";
 	}
 #undef MEI_CL_CCS
 }
 
 const char *mei_hbm_state_str(enum mei_hbm_state state)
 {
 #define MEI_HBM_STATE(state) case MEI_HBM_##state: return #state
 	switch (state) {
 	MEI_HBM_STATE(IDLE);
 	MEI_HBM_STATE(STARTING);
 	MEI_HBM_STATE(STARTED);
 	MEI_HBM_STATE(ENUM_CLIENTS);
 	MEI_HBM_STATE(CLIENT_PROPERTIES);
 	MEI_HBM_STATE(STOPPED);
 	default:
 		return "unknown";
 	}
 #undef MEI_HBM_STATE
 }
 
 /**
  * mei_cl_conn_status_to_errno - convert client connect response
  * status to error code
  *
  * @status: client connect response status
  *
  * Return: corresponding error code
  */
 static int mei_cl_conn_status_to_errno(enum mei_cl_connect_status status)
 {
 	switch (status) {
 	case MEI_CL_CONN_SUCCESS:          return 0;
 	case MEI_CL_CONN_NOT_FOUND:        return -ENOTTY;
 	case MEI_CL_CONN_ALREADY_STARTED:  return -EBUSY;
 	case MEI_CL_CONN_OUT_OF_RESOURCES: return -EBUSY;
 	case MEI_CL_CONN_MESSAGE_SMALL:    return -EINVAL;
 	case MEI_CL_CONN_NOT_ALLOWED:      return -EBUSY;
 	default:                           return -EINVAL;
 	}
 }
 
 /**
  * mei_hbm_idle - set hbm to idle state
  *
  * @dev: the device structure
  */
 void mei_hbm_idle(struct mei_device *dev)
 {
 	dev->init_clients_timer = 0;
 	dev->hbm_state = MEI_HBM_IDLE;
 }
 
 /**
  * mei_hbm_reset - reset hbm counters and book keeping data structurs
  *
  * @dev: the device structure
  */
 void mei_hbm_reset(struct mei_device *dev)
 {
 	mei_me_cl_rm_all(dev);
 
 	mei_hbm_idle(dev);
 }
 
 /**
  * mei_hbm_hdr - construct hbm header
  *
  * @hdr: hbm header
  * @length: payload length
  */
 
 static inline void mei_hbm_hdr(struct mei_msg_hdr *hdr, size_t length)
 {
 	hdr->host_addr = 0;
 	hdr->me_addr = 0;
 	hdr->length = length;
 	hdr->msg_complete = 1;
 	hdr->reserved = 0;
 	hdr->internal = 0;
 }
 
 /**
  * mei_hbm_cl_hdr - construct client hbm header
  *
  * @cl: client
  * @hbm_cmd: host bus message command
  * @buf: buffer for cl header
  * @len: buffer length
  */
 static inline
 void mei_hbm_cl_hdr(struct mei_cl *cl, u8 hbm_cmd, void *buf, size_t len)
 {
 	struct mei_hbm_cl_cmd *cmd = buf;
 
 	memset(cmd, 0, len);
 
 	cmd->hbm_cmd = hbm_cmd;
 	cmd->host_addr = mei_cl_host_addr(cl);
 	cmd->me_addr = mei_cl_me_id(cl);
 }
 
 /**
  * mei_hbm_cl_write - write simple hbm client message
  *
  * @dev: the device structure
  * @cl: client
  * @hbm_cmd: host bus message command
  * @buf: message buffer
  * @len: buffer length
  *
  * Return: 0 on success, <0 on failure.
  */
 static inline
 int mei_hbm_cl_write(struct mei_device *dev, struct mei_cl *cl,
 		     u8 hbm_cmd, u8 *buf, size_t len)
 {
 	struct mei_msg_hdr mei_hdr;
 
 	mei_hbm_hdr(&mei_hdr, len);
 	mei_hbm_cl_hdr(cl, hbm_cmd, buf, len);
 
 	return mei_write_message(dev, &mei_hdr, buf);
 }
 
 /**
  * mei_hbm_cl_addr_equal - check if the client's and
  *	the message address match
  *
  * @cl: client
  * @cmd: hbm client message
  *
  * Return: true if addresses are the same
  */
 static inline
 bool mei_hbm_cl_addr_equal(struct mei_cl *cl, struct mei_hbm_cl_cmd *cmd)
 {
 	return  mei_cl_host_addr(cl) == cmd->host_addr &&
 		mei_cl_me_id(cl) == cmd->me_addr;
 }
 
 /**
  * mei_hbm_cl_find_by_cmd - find recipient client
  *
  * @dev: the device structure
  * @buf: a buffer with hbm cl command
  *
  * Return: the recipient client or NULL if not found
  */
 static inline
 struct mei_cl *mei_hbm_cl_find_by_cmd(struct mei_device *dev, void *buf)
 {
 	struct mei_hbm_cl_cmd *cmd = (struct mei_hbm_cl_cmd *)buf;
 	struct mei_cl *cl;
 
 	list_for_each_entry(cl, &dev->file_list, link)
 		if (mei_hbm_cl_addr_equal(cl, cmd))
 			return cl;
 	return NULL;
 }
 
 
 /**
  * mei_hbm_start_wait - wait for start response message.
  *
  * @dev: the device structure
  *
  * Return: 0 on success and < 0 on failure
  */
 int mei_hbm_start_wait(struct mei_device *dev)
 {
 	int ret;
 
 	if (dev->hbm_state > MEI_HBM_STARTING)
 		return 0;
 
 	mutex_unlock(&dev->device_lock);
 	ret = wait_event_timeout(dev->wait_hbm_start,
 			dev->hbm_state != MEI_HBM_STARTING,
 			mei_secs_to_jiffies(MEI_HBM_TIMEOUT));
 	mutex_lock(&dev->device_lock);
 
 	if (ret == 0 && (dev->hbm_state <= MEI_HBM_STARTING)) {
 		dev->hbm_state = MEI_HBM_IDLE;
 		dev_err(dev->dev, "waiting for mei start failed\n");
 		return -ETIME;
 	}
 	return 0;
 }
 
 /**
  * mei_hbm_start_req - sends start request message.
  *
  * @dev: the device structure
  *
  * Return: 0 on success and < 0 on failure
  */
 int mei_hbm_start_req(struct mei_device *dev)
 {
 	struct mei_msg_hdr mei_hdr;
 	struct hbm_host_version_request start_req;
 	const size_t len = sizeof(struct hbm_host_version_request);
 	int ret;
 
 	mei_hbm_reset(dev);
 
 	mei_hbm_hdr(&mei_hdr, len);
 
 	/* host start message */
 	memset(&start_req, 0, len);
 	start_req.hbm_cmd = HOST_START_REQ_CMD;
 	start_req.host_version.major_version = HBM_MAJOR_VERSION;
 	start_req.host_version.minor_version = HBM_MINOR_VERSION;
 
 	dev->hbm_state = MEI_HBM_IDLE;
 	ret = mei_write_message(dev, &mei_hdr, &start_req);
 	if (ret) {
 		dev_err(dev->dev, "version message write failed: ret = %d\n",
 			ret);
 		return ret;
 	}
 
 	dev->hbm_state = MEI_HBM_STARTING;
 	dev->init_clients_timer = MEI_CLIENTS_INIT_TIMEOUT;
 	mei_schedule_stall_timer(dev);
 	return 0;
 }
 
 /**
  * mei_hbm_enum_clients_req - sends enumeration client request message.
  *
  * @dev: the device structure
  *
  * Return: 0 on success and < 0 on failure
  */
 static int mei_hbm_enum_clients_req(struct mei_device *dev)
 {
 	struct mei_msg_hdr mei_hdr;
 	struct hbm_host_enum_request enum_req;
 	const size_t len = sizeof(struct hbm_host_enum_request);
 	int ret;
 
 	/* enumerate clients */
 	mei_hbm_hdr(&mei_hdr, len);
 
 	memset(&enum_req, 0, len);
 	enum_req.hbm_cmd = HOST_ENUM_REQ_CMD;
 	enum_req.flags |= dev->hbm_f_dc_supported ?
 			  MEI_HBM_ENUM_F_ALLOW_ADD : 0;
 	enum_req.flags |= dev->hbm_f_ie_supported ?
 			  MEI_HBM_ENUM_F_IMMEDIATE_ENUM : 0;
 
 	ret = mei_write_message(dev, &mei_hdr, &enum_req);
 	if (ret) {
 		dev_err(dev->dev, "enumeration request write failed: ret = %d.\n",
 			ret);
 		return ret;
 	}
 	dev->hbm_state = MEI_HBM_ENUM_CLIENTS;
 	dev->init_clients_timer = MEI_CLIENTS_INIT_TIMEOUT;
 	mei_schedule_stall_timer(dev);
 	return 0;
 }
 
 /**
  * mei_hbm_me_cl_add - add new me client to the list
  *
  * @dev: the device structure
  * @res: hbm property response
  *
  * Return: 0 on success and -ENOMEM on allocation failure
  */
 
 static int mei_hbm_me_cl_add(struct mei_device *dev,
 			     struct hbm_props_response *res)
 {
 	struct mei_me_client *me_cl;
 	const uuid_le *uuid = &res->client_properties.protocol_name;
 
 	mei_me_cl_rm_by_uuid(dev, uuid);
 
 	me_cl = kzalloc(sizeof(struct mei_me_client), GFP_KERNEL);
 	if (!me_cl)
 		return -ENOMEM;
 
 	mei_me_cl_init(me_cl);
 
 	me_cl->props = res->client_properties;
 	me_cl->client_id = res->me_addr;
 	me_cl->tx_flow_ctrl_creds = 0;
 
 	mei_me_cl_add(dev, me_cl);
 
 	return 0;
 }
 
 /**
  * mei_hbm_add_cl_resp - send response to fw on client add request
  *
  * @dev: the device structure
  * @addr: me address
  * @status: response status
  *
  * Return: 0 on success and < 0 on failure
  */
 static int mei_hbm_add_cl_resp(struct mei_device *dev, u8 addr, u8 status)
 {
 	struct mei_msg_hdr mei_hdr;
 	struct hbm_add_client_response resp;
 	const size_t len = sizeof(struct hbm_add_client_response);
 	int ret;
 
 	dev_dbg(dev->dev, "adding client response\n");
 
 	mei_hbm_hdr(&mei_hdr, len);
 
 	memset(&resp, 0, sizeof(struct hbm_add_client_response));
 	resp.hbm_cmd = MEI_HBM_ADD_CLIENT_RES_CMD;
 	resp.me_addr = addr;
 	resp.status  = status;
 
 	ret = mei_write_message(dev, &mei_hdr, &resp);
 	if (ret)
 		dev_err(dev->dev, "add client response write failed: ret = %d\n",
 			ret);
 	return ret;
 }
 
 /**
  * mei_hbm_fw_add_cl_req - request from the fw to add a client
  *
  * @dev: the device structure
  * @req: add client request
  *
  * Return: 0 on success and < 0 on failure
  */
 static int mei_hbm_fw_add_cl_req(struct mei_device *dev,
 			      struct hbm_add_client_request *req)
 {
 	int ret;
 	u8 status = MEI_HBMS_SUCCESS;
 
 	BUILD_BUG_ON(sizeof(struct hbm_add_client_request) !=
 			sizeof(struct hbm_props_response));
 
 	ret = mei_hbm_me_cl_add(dev, (struct hbm_props_response *)req);
 	if (ret)
 		status = !MEI_HBMS_SUCCESS;
 
 	if (dev->dev_state == MEI_DEV_ENABLED)
 		schedule_work(&dev->bus_rescan_work);
 
 	return mei_hbm_add_cl_resp(dev, req->me_addr, status);
 }
 
 /**
  * mei_hbm_cl_notify_req - send notification request
  *
  * @dev: the device structure
  * @cl: a client to disconnect from
  * @start: true for start false for stop
  *
  * Return: 0 on success and -EIO on write failure
  */
 int mei_hbm_cl_notify_req(struct mei_device *dev,
 			  struct mei_cl *cl, u8 start)
 {
 
 	struct mei_msg_hdr mei_hdr;
 	struct hbm_notification_request req;
 	const size_t len = sizeof(struct hbm_notification_request);
 	int ret;
 
 	mei_hbm_hdr(&mei_hdr, len);
 	mei_hbm_cl_hdr(cl, MEI_HBM_NOTIFY_REQ_CMD, &req, len);
 
 	req.start = start;
 
 	ret = mei_write_message(dev, &mei_hdr, &req);
 	if (ret)
 		dev_err(dev->dev, "notify request failed: ret = %d\n", ret);
 
 	return ret;
 }
 
 /**
  *  notify_res_to_fop - convert notification response to the proper
  *      notification FOP
  *
  * @cmd: client notification start response command
  *
  * Return:  MEI_FOP_NOTIFY_START or MEI_FOP_NOTIFY_STOP;
  */
 static inline enum mei_cb_file_ops notify_res_to_fop(struct mei_hbm_cl_cmd *cmd)
 {
 	struct hbm_notification_response *rs =
 		(struct hbm_notification_response *)cmd;
 
 	return mei_cl_notify_req2fop(rs->start);
 }
 
 /**
  * mei_hbm_cl_notify_start_res - update the client state according
  *       notify start response
  *
  * @dev: the device structure
  * @cl: mei host client
  * @cmd: client notification start response command
  */
 static void mei_hbm_cl_notify_start_res(struct mei_device *dev,
 					struct mei_cl *cl,
 					struct mei_hbm_cl_cmd *cmd)
 {
 	struct hbm_notification_response *rs =
 		(struct hbm_notification_response *)cmd;
 
 	cl_dbg(dev, cl, "hbm: notify start response status=%d\n", rs->status);
 
 	if (rs->status == MEI_HBMS_SUCCESS ||
 	    rs->status == MEI_HBMS_ALREADY_STARTED) {
 		cl->notify_en = true;
 		cl->status = 0;
 	} else {
 		cl->status = -EINVAL;
 	}
 }
 
 /**
  * mei_hbm_cl_notify_stop_res - update the client state according
  *       notify stop response
  *
  * @dev: the device structure
  * @cl: mei host client
  * @cmd: client notification stop response command
  */
 static void mei_hbm_cl_notify_stop_res(struct mei_device *dev,
 				       struct mei_cl *cl,
 				       struct mei_hbm_cl_cmd *cmd)
 {
 	struct hbm_notification_response *rs =
 		(struct hbm_notification_response *)cmd;
 
 	cl_dbg(dev, cl, "hbm: notify stop response status=%d\n", rs->status);
 
 	if (rs->status == MEI_HBMS_SUCCESS ||
 	    rs->status == MEI_HBMS_NOT_STARTED) {
 		cl->notify_en = false;
 		cl->status = 0;
 	} else {
 		/* TODO: spec is not clear yet about other possible issues */
 		cl->status = -EINVAL;
 	}
 }
 
 /**
  * mei_hbm_cl_notify - signal notification event
  *
  * @dev: the device structure
  * @cmd: notification client message
  */
 static void mei_hbm_cl_notify(struct mei_device *dev,
 			      struct mei_hbm_cl_cmd *cmd)
 {
 	struct mei_cl *cl;
 
 	cl = mei_hbm_cl_find_by_cmd(dev, cmd);
 	if (cl)
 		mei_cl_notify(cl);
 }
 
 /**
  * mei_hbm_prop_req - request property for a single client
  *
  * @dev: the device structure
  * @start_idx: client index to start search
  *
  * Return: 0 on success and < 0 on failure
  */
 static int mei_hbm_prop_req(struct mei_device *dev, unsigned long start_idx)
 {
 	struct mei_msg_hdr mei_hdr;
 	struct hbm_props_request prop_req;
 	const size_t len = sizeof(struct hbm_props_request);
 	unsigned long addr;
 	int ret;
 
 	addr = find_next_bit(dev->me_clients_map, MEI_CLIENTS_MAX, start_idx);
 
 	/* We got all client properties */
 	if (addr == MEI_CLIENTS_MAX) {
 		dev->hbm_state = MEI_HBM_STARTED;
 		mei_host_client_init(dev);
 
 		return 0;
 	}
 
 	mei_hbm_hdr(&mei_hdr, len);
 
 	memset(&prop_req, 0, sizeof(struct hbm_props_request));
 
 	prop_req.hbm_cmd = HOST_CLIENT_PROPERTIES_REQ_CMD;
 	prop_req.me_addr = addr;
 
 	ret = mei_write_message(dev, &mei_hdr, &prop_req);
 	if (ret) {
 		dev_err(dev->dev, "properties request write failed: ret = %d\n",
 			ret);
 		return ret;
 	}
 
 	dev->init_clients_timer = MEI_CLIENTS_INIT_TIMEOUT;
 	mei_schedule_stall_timer(dev);
 
 	return 0;
 }
 
 /**
  * mei_hbm_pg - sends pg command
  *
  * @dev: the device structure
  * @pg_cmd: the pg command code
  *
  * Return: -EIO on write failure
  *         -EOPNOTSUPP if the operation is not supported by the protocol
  */
 int mei_hbm_pg(struct mei_device *dev, u8 pg_cmd)
 {
 	struct mei_msg_hdr mei_hdr;
 	struct hbm_power_gate req;
 	const size_t len = sizeof(struct hbm_power_gate);
 	int ret;
 
 	if (!dev->hbm_f_pg_supported)
 		return -EOPNOTSUPP;
 
 	mei_hbm_hdr(&mei_hdr, len);
 
 	memset(&req, 0, len);
 	req.hbm_cmd = pg_cmd;
 
 	ret = mei_write_message(dev, &mei_hdr, &req);
 	if (ret)
 		dev_err(dev->dev, "power gate command write failed.\n");
 	return ret;
 }
 EXPORT_SYMBOL_GPL(mei_hbm_pg);
 
 /**
  * mei_hbm_stop_req - send stop request message
  *
  * @dev: mei device
  *
  * Return: -EIO on write failure
  */
 static int mei_hbm_stop_req(struct mei_device *dev)
 {
 	struct mei_msg_hdr mei_hdr;
 	struct hbm_host_stop_request req;
 	const size_t len = sizeof(struct hbm_host_stop_request);
 
 	mei_hbm_hdr(&mei_hdr, len);
 
 	memset(&req, 0, len);
 	req.hbm_cmd = HOST_STOP_REQ_CMD;
 	req.reason = DRIVER_STOP_REQUEST;
 
 	return mei_write_message(dev, &mei_hdr, &req);
 }
 
 /**
  * mei_hbm_cl_flow_control_req - sends flow control request.
  *
  * @dev: the device structure
  * @cl: client info
  *
  * Return: -EIO on write failure
  */
 int mei_hbm_cl_flow_control_req(struct mei_device *dev, struct mei_cl *cl)
 {
 	const size_t len = sizeof(struct hbm_flow_control);
 	u8 buf[len];
 
 	cl_dbg(dev, cl, "sending flow control\n");
 	return mei_hbm_cl_write(dev, cl, MEI_FLOW_CONTROL_CMD, buf, len);
 }
 
 /**
  * mei_hbm_add_single_tx_flow_ctrl_creds - adds single buffer credentials.
  *
  * @dev: the device structure
  * @fctrl: flow control response bus message
  *
  * Return: 0 on success, < 0 otherwise
  */
 static int mei_hbm_add_single_tx_flow_ctrl_creds(struct mei_device *dev,
 						 struct hbm_flow_control *fctrl)
 {
 	struct mei_me_client *me_cl;
 	int rets;
 
 	me_cl = mei_me_cl_by_id(dev, fctrl->me_addr);
 	if (!me_cl) {
 		dev_err(dev->dev, "no such me client %d\n", fctrl->me_addr);
 		return -ENOENT;
 	}
 
 	if (WARN_ON(me_cl->props.single_recv_buf == 0)) {
 		rets = -EINVAL;
 		goto out;
 	}
 
 	me_cl->tx_flow_ctrl_creds++;
 	dev_dbg(dev->dev, "recv flow ctrl msg ME %d (single) creds = %d.\n",
 		fctrl->me_addr, me_cl->tx_flow_ctrl_creds);
 
 	rets = 0;
 out:
 	mei_me_cl_put(me_cl);
 	return rets;
 }
 
 /**
  * mei_hbm_cl_flow_control_res - flow control response from me
  *
  * @dev: the device structure
  * @fctrl: flow control response bus message
  */
 static void mei_hbm_cl_tx_flow_ctrl_creds_res(struct mei_device *dev,
 					       struct hbm_flow_control *fctrl)
 {
 	struct mei_cl *cl;
 
 	if (!fctrl->host_addr) {
 		/* single receive buffer */
 		mei_hbm_add_single_tx_flow_ctrl_creds(dev, fctrl);
 		return;
 	}
 
 	cl = mei_hbm_cl_find_by_cmd(dev, fctrl);
 	if (cl) {
 		cl->tx_flow_ctrl_creds++;
 		cl_dbg(dev, cl, "flow control creds = %d.\n",
 				cl->tx_flow_ctrl_creds);
 	}
 }
 
 
 /**
  * mei_hbm_cl_disconnect_req - sends disconnect message to fw.
  *
  * @dev: the device structure
  * @cl: a client to disconnect from
  *
  * Return: -EIO on write failure
  */
 int mei_hbm_cl_disconnect_req(struct mei_device *dev, struct mei_cl *cl)
 {
 	const size_t len = sizeof(struct hbm_client_connect_request);
 	u8 buf[len];
 
 	return mei_hbm_cl_write(dev, cl, CLIENT_DISCONNECT_REQ_CMD, buf, len);
 }
 
 /**
  * mei_hbm_cl_disconnect_rsp - sends disconnect respose to the FW
  *
  * @dev: the device structure
  * @cl: a client to disconnect from
  *
  * Return: -EIO on write failure
  */
 int mei_hbm_cl_disconnect_rsp(struct mei_device *dev, struct mei_cl *cl)
 {
 	const size_t len = sizeof(struct hbm_client_connect_response);
 	u8 buf[len];
 
 	return mei_hbm_cl_write(dev, cl, CLIENT_DISCONNECT_RES_CMD, buf, len);
 }
 
 /**
  * mei_hbm_cl_disconnect_res - update the client state according
  *       disconnect response
  *
  * @dev: the device structure
  * @cl: mei host client
  * @cmd: disconnect client response host bus message
  */
 static void mei_hbm_cl_disconnect_res(struct mei_device *dev, struct mei_cl *cl,
 				      struct mei_hbm_cl_cmd *cmd)
 {
 	struct hbm_client_connect_response *rs =
 		(struct hbm_client_connect_response *)cmd;
 
 	cl_dbg(dev, cl, "hbm: disconnect response status=%d\n", rs->status);
 
 	if (rs->status == MEI_CL_DISCONN_SUCCESS)
 		cl->state = MEI_FILE_DISCONNECT_REPLY;
 	cl->status = 0;
 }
 
 /**
  * mei_hbm_cl_connect_req - send connection request to specific me client
  *
  * @dev: the device structure
  * @cl: a client to connect to
  *
  * Return: -EIO on write failure
  */
 int mei_hbm_cl_connect_req(struct mei_device *dev, struct mei_cl *cl)
 {
 	const size_t len = sizeof(struct hbm_client_connect_request);
 	u8 buf[len];
 
 	return mei_hbm_cl_write(dev, cl, CLIENT_CONNECT_REQ_CMD, buf, len);
 }
 
 /**
  * mei_hbm_cl_connect_res - update the client state according
  *        connection response
  *
  * @dev: the device structure
  * @cl: mei host client
  * @cmd: connect client response host bus message
  */
 static void mei_hbm_cl_connect_res(struct mei_device *dev, struct mei_cl *cl,
 				   struct mei_hbm_cl_cmd *cmd)
 {
 	struct hbm_client_connect_response *rs =
 		(struct hbm_client_connect_response *)cmd;
 
 	cl_dbg(dev, cl, "hbm: connect response status=%s\n",
 			mei_cl_conn_status_str(rs->status));
 
 	if (rs->status == MEI_CL_CONN_SUCCESS)
 		cl->state = MEI_FILE_CONNECTED;
 	else {
 		cl->state = MEI_FILE_DISCONNECT_REPLY;
 		if (rs->status == MEI_CL_CONN_NOT_FOUND) {
 			mei_me_cl_del(dev, cl->me_cl);
 			if (dev->dev_state == MEI_DEV_ENABLED)
 				schedule_work(&dev->bus_rescan_work);
 		}
 	}
 	cl->status = mei_cl_conn_status_to_errno(rs->status);
 }
 
 /**
  * mei_hbm_cl_res - process hbm response received on behalf
  *         an client
  *
  * @dev: the device structure
  * @rs:  hbm client message
  * @fop_type: file operation type
  */
 static void mei_hbm_cl_res(struct mei_device *dev,
 			   struct mei_hbm_cl_cmd *rs,
 			   enum mei_cb_file_ops fop_type)
 {
 	struct mei_cl *cl;
 	struct mei_cl_cb *cb, *next;
 
 	cl = NULL;
-	list_for_each_entry_safe(cb, next, &dev->ctrl_rd_list.list, list) {
+	list_for_each_entry_safe(cb, next, &dev->ctrl_rd_list, list) {
 
 		cl = cb->cl;
 
 		if (cb->fop_type != fop_type)
 			continue;
 
 		if (mei_hbm_cl_addr_equal(cl, rs)) {
 			list_del_init(&cb->list);
 			break;
 		}
 	}
 
 	if (!cl)
 		return;
 
 	switch (fop_type) {
 	case MEI_FOP_CONNECT:
 		mei_hbm_cl_connect_res(dev, cl, rs);
 		break;
 	case MEI_FOP_DISCONNECT:
 		mei_hbm_cl_disconnect_res(dev, cl, rs);
 		break;
 	case MEI_FOP_NOTIFY_START:
 		mei_hbm_cl_notify_start_res(dev, cl, rs);
 		break;
 	case MEI_FOP_NOTIFY_STOP:
 		mei_hbm_cl_notify_stop_res(dev, cl, rs);
 		break;
 	default:
 		return;
 	}
 
 	cl->timer_count = 0;
 	wake_up(&cl->wait);
 }
 
 
 /**
  * mei_hbm_fw_disconnect_req - disconnect request initiated by ME firmware
  *  host sends disconnect response
  *
  * @dev: the device structure.
  * @disconnect_req: disconnect request bus message from the me
  *
  * Return: -ENOMEM on allocation failure
  */
 static int mei_hbm_fw_disconnect_req(struct mei_device *dev,
 		struct hbm_client_connect_request *disconnect_req)
 {
 	struct mei_cl *cl;
 	struct mei_cl_cb *cb;
 
 	cl = mei_hbm_cl_find_by_cmd(dev, disconnect_req);
 	if (cl) {
 		cl_warn(dev, cl, "fw disconnect request received\n");
 		cl->state = MEI_FILE_DISCONNECTING;
 		cl->timer_count = 0;
 
 		cb = mei_cl_enqueue_ctrl_wr_cb(cl, 0, MEI_FOP_DISCONNECT_RSP,
 					       NULL);
 		if (!cb)
 			return -ENOMEM;
 	}
 	return 0;
 }
 
 /**
  * mei_hbm_pg_enter_res - PG enter response received
  *
  * @dev: the device structure.
  *
  * Return: 0 on success, -EPROTO on state mismatch
  */
 static int mei_hbm_pg_enter_res(struct mei_device *dev)
 {
 	if (mei_pg_state(dev) != MEI_PG_OFF ||
 	    dev->pg_event != MEI_PG_EVENT_WAIT) {
 		dev_err(dev->dev, "hbm: pg entry response: state mismatch [%s, %d]\n",
 			mei_pg_state_str(mei_pg_state(dev)), dev->pg_event);
 		return -EPROTO;
 	}
 
 	dev->pg_event = MEI_PG_EVENT_RECEIVED;
 	wake_up(&dev->wait_pg);
 
 	return 0;
 }
 
 /**
  * mei_hbm_pg_resume - process with PG resume
  *
  * @dev: the device structure.
  */
 void mei_hbm_pg_resume(struct mei_device *dev)
 {
 	pm_request_resume(dev->dev);
 }
 EXPORT_SYMBOL_GPL(mei_hbm_pg_resume);
 
 /**
  * mei_hbm_pg_exit_res - PG exit response received
  *
  * @dev: the device structure.
  *
  * Return: 0 on success, -EPROTO on state mismatch
  */
 static int mei_hbm_pg_exit_res(struct mei_device *dev)
 {
 	if (mei_pg_state(dev) != MEI_PG_ON ||
 	    (dev->pg_event != MEI_PG_EVENT_WAIT &&
 	     dev->pg_event != MEI_PG_EVENT_IDLE)) {
 		dev_err(dev->dev, "hbm: pg exit response: state mismatch [%s, %d]\n",
 			mei_pg_state_str(mei_pg_state(dev)), dev->pg_event);
 		return -EPROTO;
 	}
 
 	switch (dev->pg_event) {
 	case MEI_PG_EVENT_WAIT:
 		dev->pg_event = MEI_PG_EVENT_RECEIVED;
 		wake_up(&dev->wait_pg);
 		break;
 	case MEI_PG_EVENT_IDLE:
 		/*
 		* If the driver is not waiting on this then
 		* this is HW initiated exit from PG.
 		* Start runtime pm resume sequence to exit from PG.
 		*/
 		dev->pg_event = MEI_PG_EVENT_RECEIVED;
 		mei_hbm_pg_resume(dev);
 		break;
 	default:
 		WARN(1, "hbm: pg exit response: unexpected pg event = %d\n",
 		     dev->pg_event);
 		return -EPROTO;
 	}
 
 	return 0;
 }
 
 /**
  * mei_hbm_config_features - check what hbm features and commands
  *        are supported by the fw
  *
  * @dev: the device structure
  */
 static void mei_hbm_config_features(struct mei_device *dev)
 {
 	/* Power Gating Isolation Support */
 	dev->hbm_f_pg_supported = 0;
 	if (dev->version.major_version > HBM_MAJOR_VERSION_PGI)
 		dev->hbm_f_pg_supported = 1;
 
 	if (dev->version.major_version == HBM_MAJOR_VERSION_PGI &&
 	    dev->version.minor_version >= HBM_MINOR_VERSION_PGI)
 		dev->hbm_f_pg_supported = 1;
 
 	if (dev->version.major_version >= HBM_MAJOR_VERSION_DC)
 		dev->hbm_f_dc_supported = 1;
 
 	if (dev->version.major_version >= HBM_MAJOR_VERSION_IE)
 		dev->hbm_f_ie_supported = 1;
 
 	/* disconnect on connect timeout instead of link reset */
 	if (dev->version.major_version >= HBM_MAJOR_VERSION_DOT)
 		dev->hbm_f_dot_supported = 1;
 
 	/* Notification Event Support */
 	if (dev->version.major_version >= HBM_MAJOR_VERSION_EV)
 		dev->hbm_f_ev_supported = 1;
 
 	/* Fixed Address Client Support */
 	if (dev->version.major_version >= HBM_MAJOR_VERSION_FA)
 		dev->hbm_f_fa_supported = 1;
 
 	/* OS ver message Support */
 	if (dev->version.major_version >= HBM_MAJOR_VERSION_OS)
 		dev->hbm_f_os_supported = 1;
 }
 
 /**
  * mei_hbm_version_is_supported - checks whether the driver can
  *     support the hbm version of the device
  *
  * @dev: the device structure
  * Return: true if driver can support hbm version of the device
  */
 bool mei_hbm_version_is_supported(struct mei_device *dev)
 {
 	return	(dev->version.major_version < HBM_MAJOR_VERSION) ||
 		(dev->version.major_version == HBM_MAJOR_VERSION &&
 		 dev->version.minor_version <= HBM_MINOR_VERSION);
 }
 
 /**
  * mei_hbm_dispatch - bottom half read routine after ISR to
  * handle the read bus message cmd processing.
  *
  * @dev: the device structure
  * @hdr: header of bus message
  *
  * Return: 0 on success and < 0 on failure
  */
 int mei_hbm_dispatch(struct mei_device *dev, struct mei_msg_hdr *hdr)
 {
 	struct mei_bus_message *mei_msg;
 	struct hbm_host_version_response *version_res;
 	struct hbm_props_response *props_res;
 	struct hbm_host_enum_response *enum_res;
 	struct hbm_add_client_request *add_cl_req;
 	int ret;
 
 	struct mei_hbm_cl_cmd *cl_cmd;
 	struct hbm_client_connect_request *disconnect_req;
 	struct hbm_flow_control *fctrl;
 
 	/* read the message to our buffer */
 	BUG_ON(hdr->length >= sizeof(dev->rd_msg_buf));
 	mei_read_slots(dev, dev->rd_msg_buf, hdr->length);
 	mei_msg = (struct mei_bus_message *)dev->rd_msg_buf;
 	cl_cmd  = (struct mei_hbm_cl_cmd *)mei_msg;
 
 	/* ignore spurious message and prevent reset nesting
 	 * hbm is put to idle during system reset
 	 */
 	if (dev->hbm_state == MEI_HBM_IDLE) {
 		dev_dbg(dev->dev, "hbm: state is idle ignore spurious messages\n");
 		return 0;
 	}
 
 	switch (mei_msg->hbm_cmd) {
 	case HOST_START_RES_CMD:
 		dev_dbg(dev->dev, "hbm: start: response message received.\n");
 
 		dev->init_clients_timer = 0;
 
 		version_res = (struct hbm_host_version_response *)mei_msg;
 
 		dev_dbg(dev->dev, "HBM VERSION: DRIVER=%02d:%02d DEVICE=%02d:%02d\n",
 				HBM_MAJOR_VERSION, HBM_MINOR_VERSION,
 				version_res->me_max_version.major_version,
 				version_res->me_max_version.minor_version);
 
 		if (version_res->host_version_supported) {
 			dev->version.major_version = HBM_MAJOR_VERSION;
 			dev->version.minor_version = HBM_MINOR_VERSION;
 		} else {
 			dev->version.major_version =
 				version_res->me_max_version.major_version;
 			dev->version.minor_version =
 				version_res->me_max_version.minor_version;
 		}
 
 		if (!mei_hbm_version_is_supported(dev)) {
 			dev_warn(dev->dev, "hbm: start: version mismatch - stopping the driver.\n");
 
 			dev->hbm_state = MEI_HBM_STOPPED;
 			if (mei_hbm_stop_req(dev)) {
 				dev_err(dev->dev, "hbm: start: failed to send stop request\n");
 				return -EIO;
 			}
 			break;
 		}
 
 		mei_hbm_config_features(dev);
 
 		if (dev->dev_state != MEI_DEV_INIT_CLIENTS ||
 		    dev->hbm_state != MEI_HBM_STARTING) {
 			dev_err(dev->dev, "hbm: start: state mismatch, [%d, %d]\n",
 				dev->dev_state, dev->hbm_state);
 			return -EPROTO;
 		}
 
 		if (mei_hbm_enum_clients_req(dev)) {
 			dev_err(dev->dev, "hbm: start: failed to send enumeration request\n");
 			return -EIO;
 		}
 
 		wake_up(&dev->wait_hbm_start);
 		break;
 
 	case CLIENT_CONNECT_RES_CMD:
 		dev_dbg(dev->dev, "hbm: client connect response: message received.\n");
 		mei_hbm_cl_res(dev, cl_cmd, MEI_FOP_CONNECT);
 		break;
 
 	case CLIENT_DISCONNECT_RES_CMD:
 		dev_dbg(dev->dev, "hbm: client disconnect response: message received.\n");
 		mei_hbm_cl_res(dev, cl_cmd, MEI_FOP_DISCONNECT);
 		break;
 
 	case MEI_FLOW_CONTROL_CMD:
 		dev_dbg(dev->dev, "hbm: client flow control response: message received.\n");
 
 		fctrl = (struct hbm_flow_control *)mei_msg;
 		mei_hbm_cl_tx_flow_ctrl_creds_res(dev, fctrl);
 		break;
 
 	case MEI_PG_ISOLATION_ENTRY_RES_CMD:
 		dev_dbg(dev->dev, "hbm: power gate isolation entry response received\n");
 		ret = mei_hbm_pg_enter_res(dev);
 		if (ret)
 			return ret;
 		break;
 
 	case MEI_PG_ISOLATION_EXIT_REQ_CMD:
 		dev_dbg(dev->dev, "hbm: power gate isolation exit request received\n");
 		ret = mei_hbm_pg_exit_res(dev);
 		if (ret)
 			return ret;
 		break;
 
 	case HOST_CLIENT_PROPERTIES_RES_CMD:
 		dev_dbg(dev->dev, "hbm: properties response: message received.\n");
 
 		dev->init_clients_timer = 0;
 
 		if (dev->dev_state != MEI_DEV_INIT_CLIENTS ||
 		    dev->hbm_state != MEI_HBM_CLIENT_PROPERTIES) {
 			dev_err(dev->dev, "hbm: properties response: state mismatch, [%d, %d]\n",
 				dev->dev_state, dev->hbm_state);
 			return -EPROTO;
 		}
 
 		props_res = (struct hbm_props_response *)mei_msg;
 
 		if (props_res->status) {
 			dev_err(dev->dev, "hbm: properties response: wrong status = %d %s\n",
 				props_res->status,
 				mei_hbm_status_str(props_res->status));
 			return -EPROTO;
 		}
 
 		mei_hbm_me_cl_add(dev, props_res);
 
 		/* request property for the next client */
 		if (mei_hbm_prop_req(dev, props_res->me_addr + 1))
 			return -EIO;
 
 		break;
 
 	case HOST_ENUM_RES_CMD:
 		dev_dbg(dev->dev, "hbm: enumeration response: message received\n");
 
 		dev->init_clients_timer = 0;
 
 		enum_res = (struct hbm_host_enum_response *) mei_msg;
 		BUILD_BUG_ON(sizeof(dev->me_clients_map)
 				< sizeof(enum_res->valid_addresses));
 		memcpy(dev->me_clients_map, enum_res->valid_addresses,
 				sizeof(enum_res->valid_addresses));
 
 		if (dev->dev_state != MEI_DEV_INIT_CLIENTS ||
 		    dev->hbm_state != MEI_HBM_ENUM_CLIENTS) {
 			dev_err(dev->dev, "hbm: enumeration response: state mismatch, [%d, %d]\n",
 				dev->dev_state, dev->hbm_state);
 			return -EPROTO;
 		}
 
 		dev->hbm_state = MEI_HBM_CLIENT_PROPERTIES;
 
 		/* first property request */
 		if (mei_hbm_prop_req(dev, 0))
 			return -EIO;
 
 		break;
 
 	case HOST_STOP_RES_CMD:
 		dev_dbg(dev->dev, "hbm: stop response: message received\n");
 
 		dev->init_clients_timer = 0;
 
 		if (dev->hbm_state != MEI_HBM_STOPPED) {
 			dev_err(dev->dev, "hbm: stop response: state mismatch, [%d, %d]\n",
 				dev->dev_state, dev->hbm_state);
 			return -EPROTO;
 		}
 
 		dev->dev_state = MEI_DEV_POWER_DOWN;
 		dev_info(dev->dev, "hbm: stop response: resetting.\n");
 		/* force the reset */
 		return -EPROTO;
 		break;
 
 	case CLIENT_DISCONNECT_REQ_CMD:
 		dev_dbg(dev->dev, "hbm: disconnect request: message received\n");
 
 		disconnect_req = (struct hbm_client_connect_request *)mei_msg;
 		mei_hbm_fw_disconnect_req(dev, disconnect_req);
 		break;
 
 	case ME_STOP_REQ_CMD:
 		dev_dbg(dev->dev, "hbm: stop request: message received\n");
 		dev->hbm_state = MEI_HBM_STOPPED;
 		if (mei_hbm_stop_req(dev)) {
 			dev_err(dev->dev, "hbm: stop request: failed to send stop request\n");
 			return -EIO;
 		}
 		break;
 
 	case MEI_HBM_ADD_CLIENT_REQ_CMD:
 		dev_dbg(dev->dev, "hbm: add client request received\n");
 		/*
 		 * after the host receives the enum_resp
 		 * message clients may be added or removed
 		 */
 		if (dev->hbm_state <= MEI_HBM_ENUM_CLIENTS ||
 		    dev->hbm_state >= MEI_HBM_STOPPED) {
 			dev_err(dev->dev, "hbm: add client: state mismatch, [%d, %d]\n",
 				dev->dev_state, dev->hbm_state);
 			return -EPROTO;
 		}
 		add_cl_req = (struct hbm_add_client_request *)mei_msg;
 		ret = mei_hbm_fw_add_cl_req(dev, add_cl_req);
 		if (ret) {
 			dev_err(dev->dev, "hbm: add client: failed to send response %d\n",
 				ret);
 			return -EIO;
 		}
 		dev_dbg(dev->dev, "hbm: add client request processed\n");
 		break;
 
 	case MEI_HBM_NOTIFY_RES_CMD:
 		dev_dbg(dev->dev, "hbm: notify response received\n");
 		mei_hbm_cl_res(dev, cl_cmd, notify_res_to_fop(cl_cmd));
 		break;
 
 	case MEI_HBM_NOTIFICATION_CMD:
 		dev_dbg(dev->dev, "hbm: notification\n");
 		mei_hbm_cl_notify(dev, cl_cmd);
 		break;
 
 	default:
 		BUG();
 		break;
 
 	}
 	return 0;
 }
 
diff --git a/drivers/misc/mei/hw-me.c b/drivers/misc/mei/hw-me.c
index a05375a3338a..71216affcab1 100644
--- a/drivers/misc/mei/hw-me.c
+++ b/drivers/misc/mei/hw-me.c
@@ -1,1410 +1,1435 @@
 /*
  *
  * Intel Management Engine Interface (Intel MEI) Linux driver
  * Copyright (c) 2003-2012, Intel Corporation.
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms and conditions of the GNU General Public License,
  * version 2, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope it will be useful, but WITHOUT
  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
  * more details.
  *
  */
 
 #include <linux/pci.h>
 
 #include <linux/kthread.h>
 #include <linux/interrupt.h>
 #include <linux/pm_runtime.h>
 
 #include "mei_dev.h"
 #include "hbm.h"
 
 #include "hw-me.h"
 #include "hw-me-regs.h"
 
 #include "mei-trace.h"
 
 /**
  * mei_me_reg_read - Reads 32bit data from the mei device
  *
  * @hw: the me hardware structure
  * @offset: offset from which to read the data
  *
  * Return: register value (u32)
  */
 static inline u32 mei_me_reg_read(const struct mei_me_hw *hw,
 			       unsigned long offset)
 {
 	return ioread32(hw->mem_addr + offset);
 }
 
 
 /**
  * mei_me_reg_write - Writes 32bit data to the mei device
  *
  * @hw: the me hardware structure
  * @offset: offset from which to write the data
  * @value: register value to write (u32)
  */
 static inline void mei_me_reg_write(const struct mei_me_hw *hw,
 				 unsigned long offset, u32 value)
 {
 	iowrite32(value, hw->mem_addr + offset);
 }
 
 /**
  * mei_me_mecbrw_read - Reads 32bit data from ME circular buffer
  *  read window register
  *
  * @dev: the device structure
  *
  * Return: ME_CB_RW register value (u32)
  */
 static inline u32 mei_me_mecbrw_read(const struct mei_device *dev)
 {
 	return mei_me_reg_read(to_me_hw(dev), ME_CB_RW);
 }
 
 /**
  * mei_me_hcbww_write - write 32bit data to the host circular buffer
  *
  * @dev: the device structure
  * @data: 32bit data to be written to the host circular buffer
  */
 static inline void mei_me_hcbww_write(struct mei_device *dev, u32 data)
 {
 	mei_me_reg_write(to_me_hw(dev), H_CB_WW, data);
 }
 
 /**
  * mei_me_mecsr_read - Reads 32bit data from the ME CSR
  *
  * @dev: the device structure
  *
  * Return: ME_CSR_HA register value (u32)
  */
 static inline u32 mei_me_mecsr_read(const struct mei_device *dev)
 {
 	u32 reg;
 
 	reg = mei_me_reg_read(to_me_hw(dev), ME_CSR_HA);
 	trace_mei_reg_read(dev->dev, "ME_CSR_HA", ME_CSR_HA, reg);
 
 	return reg;
 }
 
 /**
  * mei_hcsr_read - Reads 32bit data from the host CSR
  *
  * @dev: the device structure
  *
  * Return: H_CSR register value (u32)
  */
 static inline u32 mei_hcsr_read(const struct mei_device *dev)
 {
 	u32 reg;
 
 	reg = mei_me_reg_read(to_me_hw(dev), H_CSR);
 	trace_mei_reg_read(dev->dev, "H_CSR", H_CSR, reg);
 
 	return reg;
 }
 
 /**
  * mei_hcsr_write - writes H_CSR register to the mei device
  *
  * @dev: the device structure
  * @reg: new register value
  */
 static inline void mei_hcsr_write(struct mei_device *dev, u32 reg)
 {
 	trace_mei_reg_write(dev->dev, "H_CSR", H_CSR, reg);
 	mei_me_reg_write(to_me_hw(dev), H_CSR, reg);
 }
 
 /**
  * mei_hcsr_set - writes H_CSR register to the mei device,
  * and ignores the H_IS bit for it is write-one-to-zero.
  *
  * @dev: the device structure
  * @reg: new register value
  */
 static inline void mei_hcsr_set(struct mei_device *dev, u32 reg)
 {
 	reg &= ~H_CSR_IS_MASK;
 	mei_hcsr_write(dev, reg);
 }
 
+/**
+ * mei_hcsr_set_hig - set host interrupt (set H_IG)
+ *
+ * @dev: the device structure
+ */
+static inline void mei_hcsr_set_hig(struct mei_device *dev)
+{
+	u32 hcsr;
+
+	hcsr = mei_hcsr_read(dev) | H_IG;
+	mei_hcsr_set(dev, hcsr);
+}
+
 /**
  * mei_me_d0i3c_read - Reads 32bit data from the D0I3C register
  *
  * @dev: the device structure
  *
  * Return: H_D0I3C register value (u32)
  */
 static inline u32 mei_me_d0i3c_read(const struct mei_device *dev)
 {
 	u32 reg;
 
 	reg = mei_me_reg_read(to_me_hw(dev), H_D0I3C);
 	trace_mei_reg_read(dev->dev, "H_D0I3C", H_D0I3C, reg);
 
 	return reg;
 }
 
 /**
  * mei_me_d0i3c_write - writes H_D0I3C register to device
  *
  * @dev: the device structure
  * @reg: new register value
  */
 static inline void mei_me_d0i3c_write(struct mei_device *dev, u32 reg)
 {
 	trace_mei_reg_write(dev->dev, "H_D0I3C", H_D0I3C, reg);
 	mei_me_reg_write(to_me_hw(dev), H_D0I3C, reg);
 }
 
 /**
  * mei_me_fw_status - read fw status register from pci config space
  *
  * @dev: mei device
  * @fw_status: fw status register values
  *
  * Return: 0 on success, error otherwise
  */
 static int mei_me_fw_status(struct mei_device *dev,
 			    struct mei_fw_status *fw_status)
 {
 	struct pci_dev *pdev = to_pci_dev(dev->dev);
 	struct mei_me_hw *hw = to_me_hw(dev);
 	const struct mei_fw_status *fw_src = &hw->cfg->fw_status;
 	int ret;
 	int i;
 
 	if (!fw_status)
 		return -EINVAL;
 
 	fw_status->count = fw_src->count;
 	for (i = 0; i < fw_src->count && i < MEI_FW_STATUS_MAX; i++) {
 		ret = pci_read_config_dword(pdev, fw_src->status[i],
 					    &fw_status->status[i]);
 		trace_mei_pci_cfg_read(dev->dev, "PCI_CFG_HSF_X",
 				       fw_src->status[i],
 				       fw_status->status[i]);
 		if (ret)
 			return ret;
 	}
 
 	return 0;
 }
 
 /**
  * mei_me_hw_config - configure hw dependent settings
  *
  * @dev: mei device
  */
 static void mei_me_hw_config(struct mei_device *dev)
 {
 	struct pci_dev *pdev = to_pci_dev(dev->dev);
 	struct mei_me_hw *hw = to_me_hw(dev);
 	u32 hcsr, reg;
 
 	/* Doesn't change in runtime */
 	hcsr = mei_hcsr_read(dev);
 	dev->hbuf_depth = (hcsr & H_CBD) >> 24;
 
 	reg = 0;
 	pci_read_config_dword(pdev, PCI_CFG_HFS_1, &reg);
 	trace_mei_pci_cfg_read(dev->dev, "PCI_CFG_HFS_1", PCI_CFG_HFS_1, reg);
 	hw->d0i3_supported =
 		((reg & PCI_CFG_HFS_1_D0I3_MSK) == PCI_CFG_HFS_1_D0I3_MSK);
 
 	hw->pg_state = MEI_PG_OFF;
 	if (hw->d0i3_supported) {
 		reg = mei_me_d0i3c_read(dev);
 		if (reg & H_D0I3C_I3)
 			hw->pg_state = MEI_PG_ON;
 	}
 }
 
 /**
  * mei_me_pg_state  - translate internal pg state
  *   to the mei power gating state
  *
  * @dev:  mei device
  *
  * Return: MEI_PG_OFF if aliveness is on and MEI_PG_ON otherwise
  */
 static inline enum mei_pg_state mei_me_pg_state(struct mei_device *dev)
 {
 	struct mei_me_hw *hw = to_me_hw(dev);
 
 	return hw->pg_state;
 }
 
 static inline u32 me_intr_src(u32 hcsr)
 {
 	return hcsr & H_CSR_IS_MASK;
 }
 
 /**
  * me_intr_disable - disables mei device interrupts
  *      using supplied hcsr register value.
  *
  * @dev: the device structure
  * @hcsr: supplied hcsr register value
  */
 static inline void me_intr_disable(struct mei_device *dev, u32 hcsr)
 {
 	hcsr &= ~H_CSR_IE_MASK;
 	mei_hcsr_set(dev, hcsr);
 }
 
 /**
  * mei_me_intr_clear - clear and stop interrupts
  *
  * @dev: the device structure
  * @hcsr: supplied hcsr register value
  */
 static inline void me_intr_clear(struct mei_device *dev, u32 hcsr)
 {
 	if (me_intr_src(hcsr))
 		mei_hcsr_write(dev, hcsr);
 }
 
 /**
  * mei_me_intr_clear - clear and stop interrupts
  *
  * @dev: the device structure
  */
 static void mei_me_intr_clear(struct mei_device *dev)
 {
 	u32 hcsr = mei_hcsr_read(dev);
 
 	me_intr_clear(dev, hcsr);
 }
 /**
  * mei_me_intr_enable - enables mei device interrupts
  *
  * @dev: the device structure
  */
 static void mei_me_intr_enable(struct mei_device *dev)
 {
 	u32 hcsr = mei_hcsr_read(dev);
 
 	hcsr |= H_CSR_IE_MASK;
 	mei_hcsr_set(dev, hcsr);
 }
 
 /**
  * mei_me_intr_disable - disables mei device interrupts
  *
  * @dev: the device structure
  */
 static void mei_me_intr_disable(struct mei_device *dev)
 {
 	u32 hcsr = mei_hcsr_read(dev);
 
 	me_intr_disable(dev, hcsr);
 }
 
 /**
  * mei_me_synchronize_irq - wait for pending IRQ handlers
  *
  * @dev: the device structure
  */
 static void mei_me_synchronize_irq(struct mei_device *dev)
 {
 	struct pci_dev *pdev = to_pci_dev(dev->dev);
 
 	synchronize_irq(pdev->irq);
 }
 
 /**
  * mei_me_hw_reset_release - release device from the reset
  *
  * @dev: the device structure
  */
 static void mei_me_hw_reset_release(struct mei_device *dev)
 {
 	u32 hcsr = mei_hcsr_read(dev);
 
 	hcsr |= H_IG;
 	hcsr &= ~H_RST;
 	mei_hcsr_set(dev, hcsr);
 
 	/* complete this write before we set host ready on another CPU */
 	mmiowb();
 }
 
 /**
  * mei_me_host_set_ready - enable device
  *
  * @dev: mei device
  */
 static void mei_me_host_set_ready(struct mei_device *dev)
 {
 	u32 hcsr = mei_hcsr_read(dev);
 
 	hcsr |= H_CSR_IE_MASK | H_IG | H_RDY;
 	mei_hcsr_set(dev, hcsr);
 }
 
 /**
  * mei_me_host_is_ready - check whether the host has turned ready
  *
  * @dev: mei device
  * Return: bool
  */
 static bool mei_me_host_is_ready(struct mei_device *dev)
 {
 	u32 hcsr = mei_hcsr_read(dev);
 
 	return (hcsr & H_RDY) == H_RDY;
 }
 
 /**
  * mei_me_hw_is_ready - check whether the me(hw) has turned ready
  *
  * @dev: mei device
  * Return: bool
  */
 static bool mei_me_hw_is_ready(struct mei_device *dev)
 {
 	u32 mecsr = mei_me_mecsr_read(dev);
 
 	return (mecsr & ME_RDY_HRA) == ME_RDY_HRA;
 }
 
+/**
+ * mei_me_hw_is_resetting - check whether the me(hw) is in reset
+ *
+ * @dev: mei device
+ * Return: bool
+ */
+static bool mei_me_hw_is_resetting(struct mei_device *dev)
+{
+	u32 mecsr = mei_me_mecsr_read(dev);
+
+	return (mecsr & ME_RST_HRA) == ME_RST_HRA;
+}
+
 /**
  * mei_me_hw_ready_wait - wait until the me(hw) has turned ready
  *  or timeout is reached
  *
  * @dev: mei device
  * Return: 0 on success, error otherwise
  */
 static int mei_me_hw_ready_wait(struct mei_device *dev)
 {
 	mutex_unlock(&dev->device_lock);
 	wait_event_timeout(dev->wait_hw_ready,
 			dev->recvd_hw_ready,
 			mei_secs_to_jiffies(MEI_HW_READY_TIMEOUT));
 	mutex_lock(&dev->device_lock);
 	if (!dev->recvd_hw_ready) {
 		dev_err(dev->dev, "wait hw ready failed\n");
 		return -ETIME;
 	}
 
 	mei_me_hw_reset_release(dev);
 	dev->recvd_hw_ready = false;
 	return 0;
 }
 
 /**
  * mei_me_hw_start - hw start routine
  *
  * @dev: mei device
  * Return: 0 on success, error otherwise
  */
 static int mei_me_hw_start(struct mei_device *dev)
 {
 	int ret = mei_me_hw_ready_wait(dev);
 
 	if (ret)
 		return ret;
 	dev_dbg(dev->dev, "hw is ready\n");
 
 	mei_me_host_set_ready(dev);
 	return ret;
 }
 
 
 /**
  * mei_hbuf_filled_slots - gets number of device filled buffer slots
  *
  * @dev: the device structure
  *
  * Return: number of filled slots
  */
 static unsigned char mei_hbuf_filled_slots(struct mei_device *dev)
 {
 	u32 hcsr;
 	char read_ptr, write_ptr;
 
 	hcsr = mei_hcsr_read(dev);
 
 	read_ptr = (char) ((hcsr & H_CBRP) >> 8);
 	write_ptr = (char) ((hcsr & H_CBWP) >> 16);
 
 	return (unsigned char) (write_ptr - read_ptr);
 }
 
 /**
  * mei_me_hbuf_is_empty - checks if host buffer is empty.
  *
  * @dev: the device structure
  *
  * Return: true if empty, false - otherwise.
  */
 static bool mei_me_hbuf_is_empty(struct mei_device *dev)
 {
 	return mei_hbuf_filled_slots(dev) == 0;
 }
 
 /**
  * mei_me_hbuf_empty_slots - counts write empty slots.
  *
  * @dev: the device structure
  *
  * Return: -EOVERFLOW if overflow, otherwise empty slots count
  */
 static int mei_me_hbuf_empty_slots(struct mei_device *dev)
 {
 	unsigned char filled_slots, empty_slots;
 
 	filled_slots = mei_hbuf_filled_slots(dev);
 	empty_slots = dev->hbuf_depth - filled_slots;
 
 	/* check for overflow */
 	if (filled_slots > dev->hbuf_depth)
 		return -EOVERFLOW;
 
 	return empty_slots;
 }
 
 /**
  * mei_me_hbuf_max_len - returns size of hw buffer.
  *
  * @dev: the device structure
  *
  * Return: size of hw buffer in bytes
  */
 static size_t mei_me_hbuf_max_len(const struct mei_device *dev)
 {
 	return dev->hbuf_depth * sizeof(u32) - sizeof(struct mei_msg_hdr);
 }
 
 
 /**
  * mei_me_hbuf_write - writes a message to host hw buffer.
  *
  * @dev: the device structure
  * @header: mei HECI header of message
  * @buf: message payload will be written
  *
  * Return: -EIO if write has failed
  */
 static int mei_me_hbuf_write(struct mei_device *dev,
 			     struct mei_msg_hdr *header,
 			     const unsigned char *buf)
 {
 	unsigned long rem;
 	unsigned long length = header->length;
 	u32 *reg_buf = (u32 *)buf;
-	u32 hcsr;
 	u32 dw_cnt;
 	int i;
 	int empty_slots;
 
 	dev_dbg(dev->dev, MEI_HDR_FMT, MEI_HDR_PRM(header));
 
 	empty_slots = mei_hbuf_empty_slots(dev);
 	dev_dbg(dev->dev, "empty slots = %hu.\n", empty_slots);
 
 	dw_cnt = mei_data2slots(length);
 	if (empty_slots < 0 || dw_cnt > empty_slots)
 		return -EMSGSIZE;
 
 	mei_me_hcbww_write(dev, *((u32 *) header));
 
 	for (i = 0; i < length / 4; i++)
 		mei_me_hcbww_write(dev, reg_buf[i]);
 
 	rem = length & 0x3;
 	if (rem > 0) {
 		u32 reg = 0;
 
 		memcpy(&reg, &buf[length - rem], rem);
 		mei_me_hcbww_write(dev, reg);
 	}
 
-	hcsr = mei_hcsr_read(dev) | H_IG;
-	mei_hcsr_set(dev, hcsr);
+	mei_hcsr_set_hig(dev);
 	if (!mei_me_hw_is_ready(dev))
 		return -EIO;
 
 	return 0;
 }
 
 /**
  * mei_me_count_full_read_slots - counts read full slots.
  *
  * @dev: the device structure
  *
  * Return: -EOVERFLOW if overflow, otherwise filled slots count
  */
 static int mei_me_count_full_read_slots(struct mei_device *dev)
 {
 	u32 me_csr;
 	char read_ptr, write_ptr;
 	unsigned char buffer_depth, filled_slots;
 
 	me_csr = mei_me_mecsr_read(dev);
 	buffer_depth = (unsigned char)((me_csr & ME_CBD_HRA) >> 24);
 	read_ptr = (char) ((me_csr & ME_CBRP_HRA) >> 8);
 	write_ptr = (char) ((me_csr & ME_CBWP_HRA) >> 16);
 	filled_slots = (unsigned char) (write_ptr - read_ptr);
 
 	/* check for overflow */
 	if (filled_slots > buffer_depth)
 		return -EOVERFLOW;
 
 	dev_dbg(dev->dev, "filled_slots =%08x\n", filled_slots);
 	return (int)filled_slots;
 }
 
 /**
  * mei_me_read_slots - reads a message from mei device.
  *
  * @dev: the device structure
  * @buffer: message buffer will be written
  * @buffer_length: message size will be read
  *
  * Return: always 0
  */
 static int mei_me_read_slots(struct mei_device *dev, unsigned char *buffer,
 		    unsigned long buffer_length)
 {
 	u32 *reg_buf = (u32 *)buffer;
-	u32 hcsr;
 
 	for (; buffer_length >= sizeof(u32); buffer_length -= sizeof(u32))
 		*reg_buf++ = mei_me_mecbrw_read(dev);
 
 	if (buffer_length > 0) {
 		u32 reg = mei_me_mecbrw_read(dev);
 
 		memcpy(reg_buf, &reg, buffer_length);
 	}
 
-	hcsr = mei_hcsr_read(dev) | H_IG;
-	mei_hcsr_set(dev, hcsr);
+	mei_hcsr_set_hig(dev);
 	return 0;
 }
 
 /**
  * mei_me_pg_set - write pg enter register
  *
  * @dev: the device structure
  */
 static void mei_me_pg_set(struct mei_device *dev)
 {
 	struct mei_me_hw *hw = to_me_hw(dev);
 	u32 reg;
 
 	reg = mei_me_reg_read(hw, H_HPG_CSR);
 	trace_mei_reg_read(dev->dev, "H_HPG_CSR", H_HPG_CSR, reg);
 
 	reg |= H_HPG_CSR_PGI;
 
 	trace_mei_reg_write(dev->dev, "H_HPG_CSR", H_HPG_CSR, reg);
 	mei_me_reg_write(hw, H_HPG_CSR, reg);
 }
 
 /**
  * mei_me_pg_unset - write pg exit register
  *
  * @dev: the device structure
  */
 static void mei_me_pg_unset(struct mei_device *dev)
 {
 	struct mei_me_hw *hw = to_me_hw(dev);
 	u32 reg;
 
 	reg = mei_me_reg_read(hw, H_HPG_CSR);
 	trace_mei_reg_read(dev->dev, "H_HPG_CSR", H_HPG_CSR, reg);
 
 	WARN(!(reg & H_HPG_CSR_PGI), "PGI is not set\n");
 
 	reg |= H_HPG_CSR_PGIHEXR;
 
 	trace_mei_reg_write(dev->dev, "H_HPG_CSR", H_HPG_CSR, reg);
 	mei_me_reg_write(hw, H_HPG_CSR, reg);
 }
 
 /**
  * mei_me_pg_legacy_enter_sync - perform legacy pg entry procedure
  *
  * @dev: the device structure
  *
  * Return: 0 on success an error code otherwise
  */
 static int mei_me_pg_legacy_enter_sync(struct mei_device *dev)
 {
 	struct mei_me_hw *hw = to_me_hw(dev);
 	unsigned long timeout = mei_secs_to_jiffies(MEI_PGI_TIMEOUT);
 	int ret;
 
 	dev->pg_event = MEI_PG_EVENT_WAIT;
 
 	ret = mei_hbm_pg(dev, MEI_PG_ISOLATION_ENTRY_REQ_CMD);
 	if (ret)
 		return ret;
 
 	mutex_unlock(&dev->device_lock);
 	wait_event_timeout(dev->wait_pg,
 		dev->pg_event == MEI_PG_EVENT_RECEIVED, timeout);
 	mutex_lock(&dev->device_lock);
 
 	if (dev->pg_event == MEI_PG_EVENT_RECEIVED) {
 		mei_me_pg_set(dev);
 		ret = 0;
 	} else {
 		ret = -ETIME;
 	}
 
 	dev->pg_event = MEI_PG_EVENT_IDLE;
 	hw->pg_state = MEI_PG_ON;
 
 	return ret;
 }
 
 /**
  * mei_me_pg_legacy_exit_sync - perform legacy pg exit procedure
  *
  * @dev: the device structure
  *
  * Return: 0 on success an error code otherwise
  */
 static int mei_me_pg_legacy_exit_sync(struct mei_device *dev)
 {
 	struct mei_me_hw *hw = to_me_hw(dev);
 	unsigned long timeout = mei_secs_to_jiffies(MEI_PGI_TIMEOUT);
 	int ret;
 
 	if (dev->pg_event == MEI_PG_EVENT_RECEIVED)
 		goto reply;
 
 	dev->pg_event = MEI_PG_EVENT_WAIT;
 
 	mei_me_pg_unset(dev);
 
 	mutex_unlock(&dev->device_lock);
 	wait_event_timeout(dev->wait_pg,
 		dev->pg_event == MEI_PG_EVENT_RECEIVED, timeout);
 	mutex_lock(&dev->device_lock);
 
 reply:
 	if (dev->pg_event != MEI_PG_EVENT_RECEIVED) {
 		ret = -ETIME;
 		goto out;
 	}
 
 	dev->pg_event = MEI_PG_EVENT_INTR_WAIT;
 	ret = mei_hbm_pg(dev, MEI_PG_ISOLATION_EXIT_RES_CMD);
 	if (ret)
 		return ret;
 
 	mutex_unlock(&dev->device_lock);
 	wait_event_timeout(dev->wait_pg,
 		dev->pg_event == MEI_PG_EVENT_INTR_RECEIVED, timeout);
 	mutex_lock(&dev->device_lock);
 
 	if (dev->pg_event == MEI_PG_EVENT_INTR_RECEIVED)
 		ret = 0;
 	else
 		ret = -ETIME;
 
 out:
 	dev->pg_event = MEI_PG_EVENT_IDLE;
 	hw->pg_state = MEI_PG_OFF;
 
 	return ret;
 }
 
 /**
  * mei_me_pg_in_transition - is device now in pg transition
  *
  * @dev: the device structure
  *
  * Return: true if in pg transition, false otherwise
  */
 static bool mei_me_pg_in_transition(struct mei_device *dev)
 {
 	return dev->pg_event >= MEI_PG_EVENT_WAIT &&
 	       dev->pg_event <= MEI_PG_EVENT_INTR_WAIT;
 }
 
 /**
  * mei_me_pg_is_enabled - detect if PG is supported by HW
  *
  * @dev: the device structure
  *
  * Return: true is pg supported, false otherwise
  */
 static bool mei_me_pg_is_enabled(struct mei_device *dev)
 {
 	struct mei_me_hw *hw = to_me_hw(dev);
 	u32 reg = mei_me_mecsr_read(dev);
 
 	if (hw->d0i3_supported)
 		return true;
 
 	if ((reg & ME_PGIC_HRA) == 0)
 		goto notsupported;
 
 	if (!dev->hbm_f_pg_supported)
 		goto notsupported;
 
 	return true;
 
 notsupported:
 	dev_dbg(dev->dev, "pg: not supported: d0i3 = %d HGP = %d hbm version %d.%d ?= %d.%d\n",
 		hw->d0i3_supported,
 		!!(reg & ME_PGIC_HRA),
 		dev->version.major_version,
 		dev->version.minor_version,
 		HBM_MAJOR_VERSION_PGI,
 		HBM_MINOR_VERSION_PGI);
 
 	return false;
 }
 
 /**
  * mei_me_d0i3_set - write d0i3 register bit on mei device.
  *
  * @dev: the device structure
  * @intr: ask for interrupt
  *
  * Return: D0I3C register value
  */
 static u32 mei_me_d0i3_set(struct mei_device *dev, bool intr)
 {
 	u32 reg = mei_me_d0i3c_read(dev);
 
 	reg |= H_D0I3C_I3;
 	if (intr)
 		reg |= H_D0I3C_IR;
 	else
 		reg &= ~H_D0I3C_IR;
 	mei_me_d0i3c_write(dev, reg);
 	/* read it to ensure HW consistency */
 	reg = mei_me_d0i3c_read(dev);
 	return reg;
 }
 
 /**
  * mei_me_d0i3_unset - clean d0i3 register bit on mei device.
  *
  * @dev: the device structure
  *
  * Return: D0I3C register value
  */
 static u32 mei_me_d0i3_unset(struct mei_device *dev)
 {
 	u32 reg = mei_me_d0i3c_read(dev);
 
 	reg &= ~H_D0I3C_I3;
 	reg |= H_D0I3C_IR;
 	mei_me_d0i3c_write(dev, reg);
 	/* read it to ensure HW consistency */
 	reg = mei_me_d0i3c_read(dev);
 	return reg;
 }
 
 /**
  * mei_me_d0i3_enter_sync - perform d0i3 entry procedure
  *
  * @dev: the device structure
  *
  * Return: 0 on success an error code otherwise
  */
 static int mei_me_d0i3_enter_sync(struct mei_device *dev)
 {
 	struct mei_me_hw *hw = to_me_hw(dev);
 	unsigned long d0i3_timeout = mei_secs_to_jiffies(MEI_D0I3_TIMEOUT);
 	unsigned long pgi_timeout = mei_secs_to_jiffies(MEI_PGI_TIMEOUT);
 	int ret;
 	u32 reg;
 
 	reg = mei_me_d0i3c_read(dev);
 	if (reg & H_D0I3C_I3) {
 		/* we are in d0i3, nothing to do */
 		dev_dbg(dev->dev, "d0i3 set not needed\n");
 		ret = 0;
 		goto on;
 	}
 
 	/* PGI entry procedure */
 	dev->pg_event = MEI_PG_EVENT_WAIT;
 
 	ret = mei_hbm_pg(dev, MEI_PG_ISOLATION_ENTRY_REQ_CMD);
 	if (ret)
 		/* FIXME: should we reset here? */
 		goto out;
 
 	mutex_unlock(&dev->device_lock);
 	wait_event_timeout(dev->wait_pg,
 		dev->pg_event == MEI_PG_EVENT_RECEIVED, pgi_timeout);
 	mutex_lock(&dev->device_lock);
 
 	if (dev->pg_event != MEI_PG_EVENT_RECEIVED) {
 		ret = -ETIME;
 		goto out;
 	}
 	/* end PGI entry procedure */
 
 	dev->pg_event = MEI_PG_EVENT_INTR_WAIT;
 
 	reg = mei_me_d0i3_set(dev, true);
 	if (!(reg & H_D0I3C_CIP)) {
 		dev_dbg(dev->dev, "d0i3 enter wait not needed\n");
 		ret = 0;
 		goto on;
 	}
 
 	mutex_unlock(&dev->device_lock);
 	wait_event_timeout(dev->wait_pg,
 		dev->pg_event == MEI_PG_EVENT_INTR_RECEIVED, d0i3_timeout);
 	mutex_lock(&dev->device_lock);
 
 	if (dev->pg_event != MEI_PG_EVENT_INTR_RECEIVED) {
 		reg = mei_me_d0i3c_read(dev);
 		if (!(reg & H_D0I3C_I3)) {
 			ret = -ETIME;
 			goto out;
 		}
 	}
 
 	ret = 0;
 on:
 	hw->pg_state = MEI_PG_ON;
 out:
 	dev->pg_event = MEI_PG_EVENT_IDLE;
 	dev_dbg(dev->dev, "d0i3 enter ret = %d\n", ret);
 	return ret;
 }
 
 /**
  * mei_me_d0i3_enter - perform d0i3 entry procedure
  *   no hbm PG handshake
  *   no waiting for confirmation; runs with interrupts
  *   disabled
  *
  * @dev: the device structure
  *
  * Return: 0 on success an error code otherwise
  */
 static int mei_me_d0i3_enter(struct mei_device *dev)
 {
 	struct mei_me_hw *hw = to_me_hw(dev);
 	u32 reg;
 
 	reg = mei_me_d0i3c_read(dev);
 	if (reg & H_D0I3C_I3) {
 		/* we are in d0i3, nothing to do */
 		dev_dbg(dev->dev, "already d0i3 : set not needed\n");
 		goto on;
 	}
 
 	mei_me_d0i3_set(dev, false);
 on:
 	hw->pg_state = MEI_PG_ON;
 	dev->pg_event = MEI_PG_EVENT_IDLE;
 	dev_dbg(dev->dev, "d0i3 enter\n");
 	return 0;
 }
 
 /**
  * mei_me_d0i3_exit_sync - perform d0i3 exit procedure
  *
  * @dev: the device structure
  *
  * Return: 0 on success an error code otherwise
  */
 static int mei_me_d0i3_exit_sync(struct mei_device *dev)
 {
 	struct mei_me_hw *hw = to_me_hw(dev);
 	unsigned long timeout = mei_secs_to_jiffies(MEI_D0I3_TIMEOUT);
 	int ret;
 	u32 reg;
 
 	dev->pg_event = MEI_PG_EVENT_INTR_WAIT;
 
 	reg = mei_me_d0i3c_read(dev);
 	if (!(reg & H_D0I3C_I3)) {
 		/* we are not in d0i3, nothing to do */
 		dev_dbg(dev->dev, "d0i3 exit not needed\n");
 		ret = 0;
 		goto off;
 	}
 
 	reg = mei_me_d0i3_unset(dev);
 	if (!(reg & H_D0I3C_CIP)) {
 		dev_dbg(dev->dev, "d0i3 exit wait not needed\n");
 		ret = 0;
 		goto off;
 	}
 
 	mutex_unlock(&dev->device_lock);
 	wait_event_timeout(dev->wait_pg,
 		dev->pg_event == MEI_PG_EVENT_INTR_RECEIVED, timeout);
 	mutex_lock(&dev->device_lock);
 
 	if (dev->pg_event != MEI_PG_EVENT_INTR_RECEIVED) {
 		reg = mei_me_d0i3c_read(dev);
 		if (reg & H_D0I3C_I3) {
 			ret = -ETIME;
 			goto out;
 		}
 	}
 
 	ret = 0;
 off:
 	hw->pg_state = MEI_PG_OFF;
 out:
 	dev->pg_event = MEI_PG_EVENT_IDLE;
 
 	dev_dbg(dev->dev, "d0i3 exit ret = %d\n", ret);
 	return ret;
 }
 
 /**
  * mei_me_pg_legacy_intr - perform legacy pg processing
  *			   in interrupt thread handler
  *
  * @dev: the device structure
  */
 static void mei_me_pg_legacy_intr(struct mei_device *dev)
 {
 	struct mei_me_hw *hw = to_me_hw(dev);
 
 	if (dev->pg_event != MEI_PG_EVENT_INTR_WAIT)
 		return;
 
 	dev->pg_event = MEI_PG_EVENT_INTR_RECEIVED;
 	hw->pg_state = MEI_PG_OFF;
 	if (waitqueue_active(&dev->wait_pg))
 		wake_up(&dev->wait_pg);
 }
 
 /**
  * mei_me_d0i3_intr - perform d0i3 processing in interrupt thread handler
  *
  * @dev: the device structure
  * @intr_source: interrupt source
  */
 static void mei_me_d0i3_intr(struct mei_device *dev, u32 intr_source)
 {
 	struct mei_me_hw *hw = to_me_hw(dev);
 
 	if (dev->pg_event == MEI_PG_EVENT_INTR_WAIT &&
 	    (intr_source & H_D0I3C_IS)) {
 		dev->pg_event = MEI_PG_EVENT_INTR_RECEIVED;
 		if (hw->pg_state == MEI_PG_ON) {
 			hw->pg_state = MEI_PG_OFF;
 			if (dev->hbm_state != MEI_HBM_IDLE) {
 				/*
 				 * force H_RDY because it could be
 				 * wiped off during PG
 				 */
 				dev_dbg(dev->dev, "d0i3 set host ready\n");
 				mei_me_host_set_ready(dev);
 			}
 		} else {
 			hw->pg_state = MEI_PG_ON;
 		}
 
 		wake_up(&dev->wait_pg);
 	}
 
 	if (hw->pg_state == MEI_PG_ON && (intr_source & H_IS)) {
 		/*
 		 * HW sent some data and we are in D0i3, so
 		 * we got here because of HW initiated exit from D0i3.
 		 * Start runtime pm resume sequence to exit low power state.
 		 */
 		dev_dbg(dev->dev, "d0i3 want resume\n");
 		mei_hbm_pg_resume(dev);
 	}
 }
 
 /**
  * mei_me_pg_intr - perform pg processing in interrupt thread handler
  *
  * @dev: the device structure
  * @intr_source: interrupt source
  */
 static void mei_me_pg_intr(struct mei_device *dev, u32 intr_source)
 {
 	struct mei_me_hw *hw = to_me_hw(dev);
 
 	if (hw->d0i3_supported)
 		mei_me_d0i3_intr(dev, intr_source);
 	else
 		mei_me_pg_legacy_intr(dev);
 }
 
 /**
  * mei_me_pg_enter_sync - perform runtime pm entry procedure
  *
  * @dev: the device structure
  *
  * Return: 0 on success an error code otherwise
  */
 int mei_me_pg_enter_sync(struct mei_device *dev)
 {
 	struct mei_me_hw *hw = to_me_hw(dev);
 
 	if (hw->d0i3_supported)
 		return mei_me_d0i3_enter_sync(dev);
 	else
 		return mei_me_pg_legacy_enter_sync(dev);
 }
 
 /**
  * mei_me_pg_exit_sync - perform runtime pm exit procedure
  *
  * @dev: the device structure
  *
  * Return: 0 on success an error code otherwise
  */
 int mei_me_pg_exit_sync(struct mei_device *dev)
 {
 	struct mei_me_hw *hw = to_me_hw(dev);
 
 	if (hw->d0i3_supported)
 		return mei_me_d0i3_exit_sync(dev);
 	else
 		return mei_me_pg_legacy_exit_sync(dev);
 }
 
 /**
  * mei_me_hw_reset - resets fw via mei csr register.
  *
  * @dev: the device structure
  * @intr_enable: if interrupt should be enabled after reset.
  *
  * Return: 0 on success an error code otherwise
  */
 static int mei_me_hw_reset(struct mei_device *dev, bool intr_enable)
 {
 	struct mei_me_hw *hw = to_me_hw(dev);
 	int ret;
 	u32 hcsr;
 
 	if (intr_enable) {
 		mei_me_intr_enable(dev);
 		if (hw->d0i3_supported) {
 			ret = mei_me_d0i3_exit_sync(dev);
 			if (ret)
 				return ret;
 		}
 	}
 
 	pm_runtime_set_active(dev->dev);
 
 	hcsr = mei_hcsr_read(dev);
 	/* H_RST may be found lit before reset is started,
 	 * for example if preceding reset flow hasn't completed.
 	 * In that case asserting H_RST will be ignored, therefore
 	 * we need to clean H_RST bit to start a successful reset sequence.
 	 */
 	if ((hcsr & H_RST) == H_RST) {
 		dev_warn(dev->dev, "H_RST is set = 0x%08X", hcsr);
 		hcsr &= ~H_RST;
 		mei_hcsr_set(dev, hcsr);
 		hcsr = mei_hcsr_read(dev);
 	}
 
 	hcsr |= H_RST | H_IG | H_CSR_IS_MASK;
 
 	if (!intr_enable)
 		hcsr &= ~H_CSR_IE_MASK;
 
 	dev->recvd_hw_ready = false;
 	mei_hcsr_write(dev, hcsr);
 
 	/*
 	 * Host reads the H_CSR once to ensure that the
 	 * posted write to H_CSR completes.
 	 */
 	hcsr = mei_hcsr_read(dev);
 
 	if ((hcsr & H_RST) == 0)
 		dev_warn(dev->dev, "H_RST is not set = 0x%08X", hcsr);
 
 	if ((hcsr & H_RDY) == H_RDY)
 		dev_warn(dev->dev, "H_RDY is not cleared 0x%08X", hcsr);
 
 	if (!intr_enable) {
 		mei_me_hw_reset_release(dev);
 		if (hw->d0i3_supported) {
 			ret = mei_me_d0i3_enter(dev);
 			if (ret)
 				return ret;
 		}
 	}
 	return 0;
 }
 
 /**
  * mei_me_irq_quick_handler - The ISR of the MEI device
  *
  * @irq: The irq number
  * @dev_id: pointer to the device structure
  *
  * Return: irqreturn_t
  */
 irqreturn_t mei_me_irq_quick_handler(int irq, void *dev_id)
 {
 	struct mei_device *dev = (struct mei_device *)dev_id;
 	u32 hcsr;
 
 	hcsr = mei_hcsr_read(dev);
 	if (!me_intr_src(hcsr))
 		return IRQ_NONE;
 
 	dev_dbg(dev->dev, "interrupt source 0x%08X\n", me_intr_src(hcsr));
 
 	/* disable interrupts on device */
 	me_intr_disable(dev, hcsr);
 	return IRQ_WAKE_THREAD;
 }
 
 /**
  * mei_me_irq_thread_handler - function called after ISR to handle the interrupt
  * processing.
  *
  * @irq: The irq number
  * @dev_id: pointer to the device structure
  *
  * Return: irqreturn_t
  *
  */
 irqreturn_t mei_me_irq_thread_handler(int irq, void *dev_id)
 {
 	struct mei_device *dev = (struct mei_device *) dev_id;
-	struct mei_cl_cb complete_list;
+	struct list_head cmpl_list;
 	s32 slots;
 	u32 hcsr;
 	int rets = 0;
 
 	dev_dbg(dev->dev, "function called after ISR to handle the interrupt processing.\n");
 	/* initialize our complete list */
 	mutex_lock(&dev->device_lock);
 
 	hcsr = mei_hcsr_read(dev);
 	me_intr_clear(dev, hcsr);
 
-	mei_io_list_init(&complete_list);
+	INIT_LIST_HEAD(&cmpl_list);
 
 	/* check if ME wants a reset */
 	if (!mei_hw_is_ready(dev) && dev->dev_state != MEI_DEV_RESETTING) {
 		dev_warn(dev->dev, "FW not ready: resetting.\n");
 		schedule_work(&dev->reset_work);
 		goto end;
 	}
 
+	if (mei_me_hw_is_resetting(dev))
+		mei_hcsr_set_hig(dev);
+
 	mei_me_pg_intr(dev, me_intr_src(hcsr));
 
 	/*  check if we need to start the dev */
 	if (!mei_host_is_ready(dev)) {
 		if (mei_hw_is_ready(dev)) {
 			dev_dbg(dev->dev, "we need to start the dev.\n");
 			dev->recvd_hw_ready = true;
 			wake_up(&dev->wait_hw_ready);
 		} else {
 			dev_dbg(dev->dev, "Spurious Interrupt\n");
 		}
 		goto end;
 	}
 	/* check slots available for reading */
 	slots = mei_count_full_read_slots(dev);
 	while (slots > 0) {
 		dev_dbg(dev->dev, "slots to read = %08x\n", slots);
-		rets = mei_irq_read_handler(dev, &complete_list, &slots);
+		rets = mei_irq_read_handler(dev, &cmpl_list, &slots);
 		/* There is a race between ME write and interrupt delivery:
 		 * Not all data is always available immediately after the
 		 * interrupt, so try to read again on the next interrupt.
 		 */
 		if (rets == -ENODATA)
 			break;
 
 		if (rets && dev->dev_state != MEI_DEV_RESETTING) {
 			dev_err(dev->dev, "mei_irq_read_handler ret = %d.\n",
 						rets);
 			schedule_work(&dev->reset_work);
 			goto end;
 		}
 	}
 
 	dev->hbuf_is_ready = mei_hbuf_is_ready(dev);
 
 	/*
 	 * During PG handshake only allowed write is the replay to the
 	 * PG exit message, so block calling write function
 	 * if the pg event is in PG handshake
 	 */
 	if (dev->pg_event != MEI_PG_EVENT_WAIT &&
 	    dev->pg_event != MEI_PG_EVENT_RECEIVED) {
-		rets = mei_irq_write_handler(dev, &complete_list);
+		rets = mei_irq_write_handler(dev, &cmpl_list);
 		dev->hbuf_is_ready = mei_hbuf_is_ready(dev);
 	}
 
-	mei_irq_compl_handler(dev, &complete_list);
+	mei_irq_compl_handler(dev, &cmpl_list);
 
 end:
 	dev_dbg(dev->dev, "interrupt thread end ret = %d\n", rets);
 	mei_me_intr_enable(dev);
 	mutex_unlock(&dev->device_lock);
 	return IRQ_HANDLED;
 }
 
 static const struct mei_hw_ops mei_me_hw_ops = {
 
 	.fw_status = mei_me_fw_status,
 	.pg_state  = mei_me_pg_state,
 
 	.host_is_ready = mei_me_host_is_ready,
 
 	.hw_is_ready = mei_me_hw_is_ready,
 	.hw_reset = mei_me_hw_reset,
 	.hw_config = mei_me_hw_config,
 	.hw_start = mei_me_hw_start,
 
 	.pg_in_transition = mei_me_pg_in_transition,
 	.pg_is_enabled = mei_me_pg_is_enabled,
 
 	.intr_clear = mei_me_intr_clear,
 	.intr_enable = mei_me_intr_enable,
 	.intr_disable = mei_me_intr_disable,
 	.synchronize_irq = mei_me_synchronize_irq,
 
 	.hbuf_free_slots = mei_me_hbuf_empty_slots,
 	.hbuf_is_ready = mei_me_hbuf_is_empty,
 	.hbuf_max_len = mei_me_hbuf_max_len,
 
 	.write = mei_me_hbuf_write,
 
 	.rdbuf_full_slots = mei_me_count_full_read_slots,
 	.read_hdr = mei_me_mecbrw_read,
 	.read = mei_me_read_slots
 };
 
 static bool mei_me_fw_type_nm(struct pci_dev *pdev)
 {
 	u32 reg;
 
 	pci_read_config_dword(pdev, PCI_CFG_HFS_2, &reg);
 	trace_mei_pci_cfg_read(&pdev->dev, "PCI_CFG_HFS_2", PCI_CFG_HFS_2, reg);
 	/* make sure that bit 9 (NM) is up and bit 10 (DM) is down */
 	return (reg & 0x600) == 0x200;
 }
 
 #define MEI_CFG_FW_NM                           \
 	.quirk_probe = mei_me_fw_type_nm
 
 static bool mei_me_fw_type_sps(struct pci_dev *pdev)
 {
 	u32 reg;
 	unsigned int devfn;
 
 	/*
 	 * Read ME FW Status register to check for SPS Firmware
 	 * The SPS FW is only signaled in pci function 0
 	 */
 	devfn = PCI_DEVFN(PCI_SLOT(pdev->devfn), 0);
 	pci_bus_read_config_dword(pdev->bus, devfn, PCI_CFG_HFS_1, &reg);
 	trace_mei_pci_cfg_read(&pdev->dev, "PCI_CFG_HFS_1", PCI_CFG_HFS_1, reg);
 	/* if bits [19:16] = 15, running SPS Firmware */
 	return (reg & 0xf0000) == 0xf0000;
 }
 
 #define MEI_CFG_FW_SPS                           \
 	.quirk_probe = mei_me_fw_type_sps
 
 
 #define MEI_CFG_LEGACY_HFS                      \
 	.fw_status.count = 0
 
 #define MEI_CFG_ICH_HFS                        \
 	.fw_status.count = 1,                   \
 	.fw_status.status[0] = PCI_CFG_HFS_1
 
 #define MEI_CFG_PCH_HFS                         \
 	.fw_status.count = 2,                   \
 	.fw_status.status[0] = PCI_CFG_HFS_1,   \
 	.fw_status.status[1] = PCI_CFG_HFS_2
 
 #define MEI_CFG_PCH8_HFS                        \
 	.fw_status.count = 6,                   \
 	.fw_status.status[0] = PCI_CFG_HFS_1,   \
 	.fw_status.status[1] = PCI_CFG_HFS_2,   \
 	.fw_status.status[2] = PCI_CFG_HFS_3,   \
 	.fw_status.status[3] = PCI_CFG_HFS_4,   \
 	.fw_status.status[4] = PCI_CFG_HFS_5,   \
 	.fw_status.status[5] = PCI_CFG_HFS_6
 
 /* ICH Legacy devices */
 const struct mei_cfg mei_me_legacy_cfg = {
 	MEI_CFG_LEGACY_HFS,
 };
 
 /* ICH devices */
 const struct mei_cfg mei_me_ich_cfg = {
 	MEI_CFG_ICH_HFS,
 };
 
 /* PCH devices */
 const struct mei_cfg mei_me_pch_cfg = {
 	MEI_CFG_PCH_HFS,
 };
 
 
 /* PCH Cougar Point and Patsburg with quirk for Node Manager exclusion */
 const struct mei_cfg mei_me_pch_cpt_pbg_cfg = {
 	MEI_CFG_PCH_HFS,
 	MEI_CFG_FW_NM,
 };
 
 /* PCH8 Lynx Point and newer devices */
 const struct mei_cfg mei_me_pch8_cfg = {
 	MEI_CFG_PCH8_HFS,
 };
 
 /* PCH8 Lynx Point with quirk for SPS Firmware exclusion */
 const struct mei_cfg mei_me_pch8_sps_cfg = {
 	MEI_CFG_PCH8_HFS,
 	MEI_CFG_FW_SPS,
 };
 
 /**
  * mei_me_dev_init - allocates and initializes the mei device structure
  *
  * @pdev: The pci device structure
  * @cfg: per device generation config
  *
- * Return: The mei_device_device pointer on success, NULL on failure.
+ * Return: The mei_device pointer on success, NULL on failure.
  */
 struct mei_device *mei_me_dev_init(struct pci_dev *pdev,
 				   const struct mei_cfg *cfg)
 {
 	struct mei_device *dev;
 	struct mei_me_hw *hw;
 
-	dev = kzalloc(sizeof(struct mei_device) +
-			 sizeof(struct mei_me_hw), GFP_KERNEL);
+	dev = devm_kzalloc(&pdev->dev, sizeof(struct mei_device) +
+			   sizeof(struct mei_me_hw), GFP_KERNEL);
 	if (!dev)
 		return NULL;
 	hw = to_me_hw(dev);
 
 	mei_device_init(dev, &pdev->dev, &mei_me_hw_ops);
 	hw->cfg = cfg;
 	return dev;
 }
 
diff --git a/drivers/misc/mei/hw-txe.c b/drivers/misc/mei/hw-txe.c
index e9f8c0aeec13..24e4a4c96606 100644
--- a/drivers/misc/mei/hw-txe.c
+++ b/drivers/misc/mei/hw-txe.c
@@ -1,1267 +1,1267 @@
 /*
  *
  * Intel Management Engine Interface (Intel MEI) Linux driver
  * Copyright (c) 2013-2014, Intel Corporation.
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms and conditions of the GNU General Public License,
  * version 2, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope it will be useful, but WITHOUT
  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  * FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for
  * more details.
  *
  */
 
 #include <linux/pci.h>
 #include <linux/jiffies.h>
 #include <linux/ktime.h>
 #include <linux/delay.h>
 #include <linux/kthread.h>
 #include <linux/interrupt.h>
 #include <linux/pm_runtime.h>
 
 #include <linux/mei.h>
 
 #include "mei_dev.h"
 #include "hw-txe.h"
 #include "client.h"
 #include "hbm.h"
 
 #include "mei-trace.h"
 
 
 /**
  * mei_txe_reg_read - Reads 32bit data from the txe device
  *
  * @base_addr: registers base address
  * @offset: register offset
  *
  * Return: register value
  */
 static inline u32 mei_txe_reg_read(void __iomem *base_addr,
 					unsigned long offset)
 {
 	return ioread32(base_addr + offset);
 }
 
 /**
  * mei_txe_reg_write - Writes 32bit data to the txe device
  *
  * @base_addr: registers base address
  * @offset: register offset
  * @value: the value to write
  */
 static inline void mei_txe_reg_write(void __iomem *base_addr,
 				unsigned long offset, u32 value)
 {
 	iowrite32(value, base_addr + offset);
 }
 
 /**
  * mei_txe_sec_reg_read_silent - Reads 32bit data from the SeC BAR
  *
  * @hw: the txe hardware structure
  * @offset: register offset
  *
  * Doesn't check for aliveness while Reads 32bit data from the SeC BAR
  *
  * Return: register value
  */
 static inline u32 mei_txe_sec_reg_read_silent(struct mei_txe_hw *hw,
 				unsigned long offset)
 {
 	return mei_txe_reg_read(hw->mem_addr[SEC_BAR], offset);
 }
 
 /**
  * mei_txe_sec_reg_read - Reads 32bit data from the SeC BAR
  *
  * @hw: the txe hardware structure
  * @offset: register offset
  *
  * Reads 32bit data from the SeC BAR and shout loud if aliveness is not set
  *
  * Return: register value
  */
 static inline u32 mei_txe_sec_reg_read(struct mei_txe_hw *hw,
 				unsigned long offset)
 {
 	WARN(!hw->aliveness, "sec read: aliveness not asserted\n");
 	return mei_txe_sec_reg_read_silent(hw, offset);
 }
 /**
  * mei_txe_sec_reg_write_silent - Writes 32bit data to the SeC BAR
  *   doesn't check for aliveness
  *
  * @hw: the txe hardware structure
  * @offset: register offset
  * @value: value to write
  *
  * Doesn't check for aliveness while writes 32bit data from to the SeC BAR
  */
 static inline void mei_txe_sec_reg_write_silent(struct mei_txe_hw *hw,
 				unsigned long offset, u32 value)
 {
 	mei_txe_reg_write(hw->mem_addr[SEC_BAR], offset, value);
 }
 
 /**
  * mei_txe_sec_reg_write - Writes 32bit data to the SeC BAR
  *
  * @hw: the txe hardware structure
  * @offset: register offset
  * @value: value to write
  *
  * Writes 32bit data from the SeC BAR and shout loud if aliveness is not set
  */
 static inline void mei_txe_sec_reg_write(struct mei_txe_hw *hw,
 				unsigned long offset, u32 value)
 {
 	WARN(!hw->aliveness, "sec write: aliveness not asserted\n");
 	mei_txe_sec_reg_write_silent(hw, offset, value);
 }
 /**
  * mei_txe_br_reg_read - Reads 32bit data from the Bridge BAR
  *
  * @hw: the txe hardware structure
  * @offset: offset from which to read the data
  *
  * Return: the byte read.
  */
 static inline u32 mei_txe_br_reg_read(struct mei_txe_hw *hw,
 				unsigned long offset)
 {
 	return mei_txe_reg_read(hw->mem_addr[BRIDGE_BAR], offset);
 }
 
 /**
  * mei_txe_br_reg_write - Writes 32bit data to the Bridge BAR
  *
  * @hw: the txe hardware structure
  * @offset: offset from which to write the data
  * @value: the byte to write
  */
 static inline void mei_txe_br_reg_write(struct mei_txe_hw *hw,
 				unsigned long offset, u32 value)
 {
 	mei_txe_reg_write(hw->mem_addr[BRIDGE_BAR], offset, value);
 }
 
 /**
  * mei_txe_aliveness_set - request for aliveness change
  *
  * @dev: the device structure
  * @req: requested aliveness value
  *
  * Request for aliveness change and returns true if the change is
  *   really needed and false if aliveness is already
  *   in the requested state
  *
  * Locking: called under "dev->device_lock" lock
  *
  * Return: true if request was send
  */
 static bool mei_txe_aliveness_set(struct mei_device *dev, u32 req)
 {
 
 	struct mei_txe_hw *hw = to_txe_hw(dev);
 	bool do_req = hw->aliveness != req;
 
 	dev_dbg(dev->dev, "Aliveness current=%d request=%d\n",
 				hw->aliveness, req);
 	if (do_req) {
 		dev->pg_event = MEI_PG_EVENT_WAIT;
 		mei_txe_br_reg_write(hw, SICR_HOST_ALIVENESS_REQ_REG, req);
 	}
 	return do_req;
 }
 
 
 /**
  * mei_txe_aliveness_req_get - get aliveness requested register value
  *
  * @dev: the device structure
  *
  * Extract HICR_HOST_ALIVENESS_RESP_ACK bit from
  * from HICR_HOST_ALIVENESS_REQ register value
  *
  * Return: SICR_HOST_ALIVENESS_REQ_REQUESTED bit value
  */
 static u32 mei_txe_aliveness_req_get(struct mei_device *dev)
 {
 	struct mei_txe_hw *hw = to_txe_hw(dev);
 	u32 reg;
 
 	reg = mei_txe_br_reg_read(hw, SICR_HOST_ALIVENESS_REQ_REG);
 	return reg & SICR_HOST_ALIVENESS_REQ_REQUESTED;
 }
 
 /**
  * mei_txe_aliveness_get - get aliveness response register value
  *
  * @dev: the device structure
  *
  * Return: HICR_HOST_ALIVENESS_RESP_ACK bit from HICR_HOST_ALIVENESS_RESP
  *         register
  */
 static u32 mei_txe_aliveness_get(struct mei_device *dev)
 {
 	struct mei_txe_hw *hw = to_txe_hw(dev);
 	u32 reg;
 
 	reg = mei_txe_br_reg_read(hw, HICR_HOST_ALIVENESS_RESP_REG);
 	return reg & HICR_HOST_ALIVENESS_RESP_ACK;
 }
 
 /**
  * mei_txe_aliveness_poll - waits for aliveness to settle
  *
  * @dev: the device structure
  * @expected: expected aliveness value
  *
  * Polls for HICR_HOST_ALIVENESS_RESP.ALIVENESS_RESP to be set
  *
  * Return: 0 if the expected value was received, -ETIME otherwise
  */
 static int mei_txe_aliveness_poll(struct mei_device *dev, u32 expected)
 {
 	struct mei_txe_hw *hw = to_txe_hw(dev);
 	ktime_t stop, start;
 
 	start = ktime_get();
 	stop = ktime_add(start, ms_to_ktime(SEC_ALIVENESS_WAIT_TIMEOUT));
 	do {
 		hw->aliveness = mei_txe_aliveness_get(dev);
 		if (hw->aliveness == expected) {
 			dev->pg_event = MEI_PG_EVENT_IDLE;
 			dev_dbg(dev->dev, "aliveness settled after %lld usecs\n",
 				ktime_to_us(ktime_sub(ktime_get(), start)));
 			return 0;
 		}
 		usleep_range(20, 50);
 	} while (ktime_before(ktime_get(), stop));
 
 	dev->pg_event = MEI_PG_EVENT_IDLE;
 	dev_err(dev->dev, "aliveness timed out\n");
 	return -ETIME;
 }
 
 /**
  * mei_txe_aliveness_wait - waits for aliveness to settle
  *
  * @dev: the device structure
  * @expected: expected aliveness value
  *
  * Waits for HICR_HOST_ALIVENESS_RESP.ALIVENESS_RESP to be set
  *
  * Return: 0 on success and < 0 otherwise
  */
 static int mei_txe_aliveness_wait(struct mei_device *dev, u32 expected)
 {
 	struct mei_txe_hw *hw = to_txe_hw(dev);
 	const unsigned long timeout =
 			msecs_to_jiffies(SEC_ALIVENESS_WAIT_TIMEOUT);
 	long err;
 	int ret;
 
 	hw->aliveness = mei_txe_aliveness_get(dev);
 	if (hw->aliveness == expected)
 		return 0;
 
 	mutex_unlock(&dev->device_lock);
 	err = wait_event_timeout(hw->wait_aliveness_resp,
 			dev->pg_event == MEI_PG_EVENT_RECEIVED, timeout);
 	mutex_lock(&dev->device_lock);
 
 	hw->aliveness = mei_txe_aliveness_get(dev);
 	ret = hw->aliveness == expected ? 0 : -ETIME;
 
 	if (ret)
 		dev_warn(dev->dev, "aliveness timed out = %ld aliveness = %d event = %d\n",
 			err, hw->aliveness, dev->pg_event);
 	else
 		dev_dbg(dev->dev, "aliveness settled after = %d msec aliveness = %d event = %d\n",
 			jiffies_to_msecs(timeout - err),
 			hw->aliveness, dev->pg_event);
 
 	dev->pg_event = MEI_PG_EVENT_IDLE;
 	return ret;
 }
 
 /**
  * mei_txe_aliveness_set_sync - sets an wait for aliveness to complete
  *
  * @dev: the device structure
  * @req: requested aliveness value
  *
  * Return: 0 on success and < 0 otherwise
  */
 int mei_txe_aliveness_set_sync(struct mei_device *dev, u32 req)
 {
 	if (mei_txe_aliveness_set(dev, req))
 		return mei_txe_aliveness_wait(dev, req);
 	return 0;
 }
 
 /**
  * mei_txe_pg_in_transition - is device now in pg transition
  *
  * @dev: the device structure
  *
  * Return: true if in pg transition, false otherwise
  */
 static bool mei_txe_pg_in_transition(struct mei_device *dev)
 {
 	return dev->pg_event == MEI_PG_EVENT_WAIT;
 }
 
 /**
  * mei_txe_pg_is_enabled - detect if PG is supported by HW
  *
  * @dev: the device structure
  *
  * Return: true is pg supported, false otherwise
  */
 static bool mei_txe_pg_is_enabled(struct mei_device *dev)
 {
 	return true;
 }
 
 /**
  * mei_txe_pg_state  - translate aliveness register value
  *   to the mei power gating state
  *
  * @dev: the device structure
  *
  * Return: MEI_PG_OFF if aliveness is on and MEI_PG_ON otherwise
  */
 static inline enum mei_pg_state mei_txe_pg_state(struct mei_device *dev)
 {
 	struct mei_txe_hw *hw = to_txe_hw(dev);
 
 	return hw->aliveness ? MEI_PG_OFF : MEI_PG_ON;
 }
 
 /**
  * mei_txe_input_ready_interrupt_enable - sets the Input Ready Interrupt
  *
  * @dev: the device structure
  */
 static void mei_txe_input_ready_interrupt_enable(struct mei_device *dev)
 {
 	struct mei_txe_hw *hw = to_txe_hw(dev);
 	u32 hintmsk;
 	/* Enable the SEC_IPC_HOST_INT_MASK_IN_RDY interrupt */
 	hintmsk = mei_txe_sec_reg_read(hw, SEC_IPC_HOST_INT_MASK_REG);
 	hintmsk |= SEC_IPC_HOST_INT_MASK_IN_RDY;
 	mei_txe_sec_reg_write(hw, SEC_IPC_HOST_INT_MASK_REG, hintmsk);
 }
 
 /**
  * mei_txe_input_doorbell_set - sets bit 0 in
  *    SEC_IPC_INPUT_DOORBELL.IPC_INPUT_DOORBELL.
  *
  * @hw: the txe hardware structure
  */
 static void mei_txe_input_doorbell_set(struct mei_txe_hw *hw)
 {
 	/* Clear the interrupt cause */
 	clear_bit(TXE_INTR_IN_READY_BIT, &hw->intr_cause);
 	mei_txe_sec_reg_write(hw, SEC_IPC_INPUT_DOORBELL_REG, 1);
 }
 
 /**
  * mei_txe_output_ready_set - Sets the SICR_SEC_IPC_OUTPUT_STATUS bit to 1
  *
  * @hw: the txe hardware structure
  */
 static void mei_txe_output_ready_set(struct mei_txe_hw *hw)
 {
 	mei_txe_br_reg_write(hw,
 			SICR_SEC_IPC_OUTPUT_STATUS_REG,
 			SEC_IPC_OUTPUT_STATUS_RDY);
 }
 
 /**
  * mei_txe_is_input_ready - check if TXE is ready for receiving data
  *
  * @dev: the device structure
  *
  * Return: true if INPUT STATUS READY bit is set
  */
 static bool mei_txe_is_input_ready(struct mei_device *dev)
 {
 	struct mei_txe_hw *hw = to_txe_hw(dev);
 	u32 status;
 
 	status = mei_txe_sec_reg_read(hw, SEC_IPC_INPUT_STATUS_REG);
 	return !!(SEC_IPC_INPUT_STATUS_RDY & status);
 }
 
 /**
  * mei_txe_intr_clear - clear all interrupts
  *
  * @dev: the device structure
  */
 static inline void mei_txe_intr_clear(struct mei_device *dev)
 {
 	struct mei_txe_hw *hw = to_txe_hw(dev);
 
 	mei_txe_sec_reg_write_silent(hw, SEC_IPC_HOST_INT_STATUS_REG,
 		SEC_IPC_HOST_INT_STATUS_PENDING);
 	mei_txe_br_reg_write(hw, HISR_REG, HISR_INT_STS_MSK);
 	mei_txe_br_reg_write(hw, HHISR_REG, IPC_HHIER_MSK);
 }
 
 /**
  * mei_txe_intr_disable - disable all interrupts
  *
  * @dev: the device structure
  */
 static void mei_txe_intr_disable(struct mei_device *dev)
 {
 	struct mei_txe_hw *hw = to_txe_hw(dev);
 
 	mei_txe_br_reg_write(hw, HHIER_REG, 0);
 	mei_txe_br_reg_write(hw, HIER_REG, 0);
 }
 /**
  * mei_txe_intr_enable - enable all interrupts
  *
  * @dev: the device structure
  */
 static void mei_txe_intr_enable(struct mei_device *dev)
 {
 	struct mei_txe_hw *hw = to_txe_hw(dev);
 
 	mei_txe_br_reg_write(hw, HHIER_REG, IPC_HHIER_MSK);
 	mei_txe_br_reg_write(hw, HIER_REG, HIER_INT_EN_MSK);
 }
 
 /**
  * mei_txe_synchronize_irq - wait for pending IRQ handlers
  *
  * @dev: the device structure
  */
 static void mei_txe_synchronize_irq(struct mei_device *dev)
 {
 	struct pci_dev *pdev = to_pci_dev(dev->dev);
 
 	synchronize_irq(pdev->irq);
 }
 
 /**
  * mei_txe_pending_interrupts - check if there are pending interrupts
  *	only Aliveness, Input ready, and output doorbell are of relevance
  *
  * @dev: the device structure
  *
  * Checks if there are pending interrupts
  * only Aliveness, Readiness, Input ready, and Output doorbell are relevant
  *
  * Return: true if there are pending interrupts
  */
 static bool mei_txe_pending_interrupts(struct mei_device *dev)
 {
 
 	struct mei_txe_hw *hw = to_txe_hw(dev);
 	bool ret = (hw->intr_cause & (TXE_INTR_READINESS |
 				      TXE_INTR_ALIVENESS |
 				      TXE_INTR_IN_READY  |
 				      TXE_INTR_OUT_DB));
 
 	if (ret) {
 		dev_dbg(dev->dev,
 			"Pending Interrupts InReady=%01d Readiness=%01d, Aliveness=%01d, OutDoor=%01d\n",
 			!!(hw->intr_cause & TXE_INTR_IN_READY),
 			!!(hw->intr_cause & TXE_INTR_READINESS),
 			!!(hw->intr_cause & TXE_INTR_ALIVENESS),
 			!!(hw->intr_cause & TXE_INTR_OUT_DB));
 	}
 	return ret;
 }
 
 /**
  * mei_txe_input_payload_write - write a dword to the host buffer
  *	at offset idx
  *
  * @dev: the device structure
  * @idx: index in the host buffer
  * @value: value
  */
 static void mei_txe_input_payload_write(struct mei_device *dev,
 			unsigned long idx, u32 value)
 {
 	struct mei_txe_hw *hw = to_txe_hw(dev);
 
 	mei_txe_sec_reg_write(hw, SEC_IPC_INPUT_PAYLOAD_REG +
 			(idx * sizeof(u32)), value);
 }
 
 /**
  * mei_txe_out_data_read - read dword from the device buffer
  *	at offset idx
  *
  * @dev: the device structure
  * @idx: index in the device buffer
  *
  * Return: register value at index
  */
 static u32 mei_txe_out_data_read(const struct mei_device *dev,
 					unsigned long idx)
 {
 	struct mei_txe_hw *hw = to_txe_hw(dev);
 
 	return mei_txe_br_reg_read(hw,
 		BRIDGE_IPC_OUTPUT_PAYLOAD_REG + (idx * sizeof(u32)));
 }
 
 /* Readiness */
 
 /**
  * mei_txe_readiness_set_host_rdy - set host readiness bit
  *
  * @dev: the device structure
  */
 static void mei_txe_readiness_set_host_rdy(struct mei_device *dev)
 {
 	struct mei_txe_hw *hw = to_txe_hw(dev);
 
 	mei_txe_br_reg_write(hw,
 		SICR_HOST_IPC_READINESS_REQ_REG,
 		SICR_HOST_IPC_READINESS_HOST_RDY);
 }
 
 /**
  * mei_txe_readiness_clear - clear host readiness bit
  *
  * @dev: the device structure
  */
 static void mei_txe_readiness_clear(struct mei_device *dev)
 {
 	struct mei_txe_hw *hw = to_txe_hw(dev);
 
 	mei_txe_br_reg_write(hw, SICR_HOST_IPC_READINESS_REQ_REG,
 				SICR_HOST_IPC_READINESS_RDY_CLR);
 }
 /**
  * mei_txe_readiness_get - Reads and returns
  *	the HICR_SEC_IPC_READINESS register value
  *
  * @dev: the device structure
  *
  * Return: the HICR_SEC_IPC_READINESS register value
  */
 static u32 mei_txe_readiness_get(struct mei_device *dev)
 {
 	struct mei_txe_hw *hw = to_txe_hw(dev);
 
 	return mei_txe_br_reg_read(hw, HICR_SEC_IPC_READINESS_REG);
 }
 
 
 /**
  * mei_txe_readiness_is_sec_rdy - check readiness
  *  for HICR_SEC_IPC_READINESS_SEC_RDY
  *
  * @readiness: cached readiness state
  *
  * Return: true if readiness bit is set
  */
 static inline bool mei_txe_readiness_is_sec_rdy(u32 readiness)
 {
 	return !!(readiness & HICR_SEC_IPC_READINESS_SEC_RDY);
 }
 
 /**
  * mei_txe_hw_is_ready - check if the hw is ready
  *
  * @dev: the device structure
  *
  * Return: true if sec is ready
  */
 static bool mei_txe_hw_is_ready(struct mei_device *dev)
 {
 	u32 readiness =  mei_txe_readiness_get(dev);
 
 	return mei_txe_readiness_is_sec_rdy(readiness);
 }
 
 /**
  * mei_txe_host_is_ready - check if the host is ready
  *
  * @dev: the device structure
  *
  * Return: true if host is ready
  */
 static inline bool mei_txe_host_is_ready(struct mei_device *dev)
 {
 	struct mei_txe_hw *hw = to_txe_hw(dev);
 	u32 reg = mei_txe_br_reg_read(hw, HICR_SEC_IPC_READINESS_REG);
 
 	return !!(reg & HICR_SEC_IPC_READINESS_HOST_RDY);
 }
 
 /**
  * mei_txe_readiness_wait - wait till readiness settles
  *
  * @dev: the device structure
  *
  * Return: 0 on success and -ETIME on timeout
  */
 static int mei_txe_readiness_wait(struct mei_device *dev)
 {
 	if (mei_txe_hw_is_ready(dev))
 		return 0;
 
 	mutex_unlock(&dev->device_lock);
 	wait_event_timeout(dev->wait_hw_ready, dev->recvd_hw_ready,
 			msecs_to_jiffies(SEC_RESET_WAIT_TIMEOUT));
 	mutex_lock(&dev->device_lock);
 	if (!dev->recvd_hw_ready) {
 		dev_err(dev->dev, "wait for readiness failed\n");
 		return -ETIME;
 	}
 
 	dev->recvd_hw_ready = false;
 	return 0;
 }
 
 static const struct mei_fw_status mei_txe_fw_sts = {
 	.count = 2,
 	.status[0] = PCI_CFG_TXE_FW_STS0,
 	.status[1] = PCI_CFG_TXE_FW_STS1
 };
 
 /**
  * mei_txe_fw_status - read fw status register from pci config space
  *
  * @dev: mei device
  * @fw_status: fw status register values
  *
  * Return: 0 on success, error otherwise
  */
 static int mei_txe_fw_status(struct mei_device *dev,
 			     struct mei_fw_status *fw_status)
 {
 	const struct mei_fw_status *fw_src = &mei_txe_fw_sts;
 	struct pci_dev *pdev = to_pci_dev(dev->dev);
 	int ret;
 	int i;
 
 	if (!fw_status)
 		return -EINVAL;
 
 	fw_status->count = fw_src->count;
 	for (i = 0; i < fw_src->count && i < MEI_FW_STATUS_MAX; i++) {
 		ret = pci_read_config_dword(pdev, fw_src->status[i],
 					    &fw_status->status[i]);
 		trace_mei_pci_cfg_read(dev->dev, "PCI_CFG_HSF_X",
 				       fw_src->status[i],
 				       fw_status->status[i]);
 		if (ret)
 			return ret;
 	}
 
 	return 0;
 }
 
 /**
  *  mei_txe_hw_config - configure hardware at the start of the devices
  *
  * @dev: the device structure
  *
  * Configure hardware at the start of the device should be done only
  *   once at the device probe time
  */
 static void mei_txe_hw_config(struct mei_device *dev)
 {
 
 	struct mei_txe_hw *hw = to_txe_hw(dev);
 
 	/* Doesn't change in runtime */
 	dev->hbuf_depth = PAYLOAD_SIZE / 4;
 
 	hw->aliveness = mei_txe_aliveness_get(dev);
 	hw->readiness = mei_txe_readiness_get(dev);
 
 	dev_dbg(dev->dev, "aliveness_resp = 0x%08x, readiness = 0x%08x.\n",
 		hw->aliveness, hw->readiness);
 }
 
 
 /**
  * mei_txe_write - writes a message to device.
  *
  * @dev: the device structure
  * @header: header of message
  * @buf: message buffer will be written
  *
  * Return: 0 if success, <0 - otherwise.
  */
 
 static int mei_txe_write(struct mei_device *dev,
 			 struct mei_msg_hdr *header,
 			 const unsigned char *buf)
 {
 	struct mei_txe_hw *hw = to_txe_hw(dev);
 	unsigned long rem;
 	unsigned long length;
 	int slots = dev->hbuf_depth;
 	u32 *reg_buf = (u32 *)buf;
 	u32 dw_cnt;
 	int i;
 
 	if (WARN_ON(!header || !buf))
 		return -EINVAL;
 
 	length = header->length;
 
 	dev_dbg(dev->dev, MEI_HDR_FMT, MEI_HDR_PRM(header));
 
 	dw_cnt = mei_data2slots(length);
 	if (dw_cnt > slots)
 		return -EMSGSIZE;
 
 	if (WARN(!hw->aliveness, "txe write: aliveness not asserted\n"))
 		return -EAGAIN;
 
 	/* Enable Input Ready Interrupt. */
 	mei_txe_input_ready_interrupt_enable(dev);
 
 	if (!mei_txe_is_input_ready(dev)) {
 		char fw_sts_str[MEI_FW_STATUS_STR_SZ];
 
 		mei_fw_status_str(dev, fw_sts_str, MEI_FW_STATUS_STR_SZ);
 		dev_err(dev->dev, "Input is not ready %s\n", fw_sts_str);
 		return -EAGAIN;
 	}
 
 	mei_txe_input_payload_write(dev, 0, *((u32 *)header));
 
 	for (i = 0; i < length / 4; i++)
 		mei_txe_input_payload_write(dev, i + 1, reg_buf[i]);
 
 	rem = length & 0x3;
 	if (rem > 0) {
 		u32 reg = 0;
 
 		memcpy(&reg, &buf[length - rem], rem);
 		mei_txe_input_payload_write(dev, i + 1, reg);
 	}
 
 	/* after each write the whole buffer is consumed */
 	hw->slots = 0;
 
 	/* Set Input-Doorbell */
 	mei_txe_input_doorbell_set(hw);
 
 	return 0;
 }
 
 /**
  * mei_txe_hbuf_max_len - mimics the me hbuf circular buffer
  *
  * @dev: the device structure
  *
  * Return: the PAYLOAD_SIZE - 4
  */
 static size_t mei_txe_hbuf_max_len(const struct mei_device *dev)
 {
 	return PAYLOAD_SIZE - sizeof(struct mei_msg_hdr);
 }
 
 /**
  * mei_txe_hbuf_empty_slots - mimics the me hbuf circular buffer
  *
  * @dev: the device structure
  *
  * Return: always hbuf_depth
  */
 static int mei_txe_hbuf_empty_slots(struct mei_device *dev)
 {
 	struct mei_txe_hw *hw = to_txe_hw(dev);
 
 	return hw->slots;
 }
 
 /**
  * mei_txe_count_full_read_slots - mimics the me device circular buffer
  *
  * @dev: the device structure
  *
  * Return: always buffer size in dwords count
  */
 static int mei_txe_count_full_read_slots(struct mei_device *dev)
 {
 	/* read buffers has static size */
 	return  PAYLOAD_SIZE / 4;
 }
 
 /**
  * mei_txe_read_hdr - read message header which is always in 4 first bytes
  *
  * @dev: the device structure
  *
  * Return: mei message header
  */
 
 static u32 mei_txe_read_hdr(const struct mei_device *dev)
 {
 	return mei_txe_out_data_read(dev, 0);
 }
 /**
  * mei_txe_read - reads a message from the txe device.
  *
  * @dev: the device structure
  * @buf: message buffer will be written
  * @len: message size will be read
  *
  * Return: -EINVAL on error wrong argument and 0 on success
  */
 static int mei_txe_read(struct mei_device *dev,
 		unsigned char *buf, unsigned long len)
 {
 
 	struct mei_txe_hw *hw = to_txe_hw(dev);
 	u32 *reg_buf, reg;
 	u32 rem;
 	u32 i;
 
 	if (WARN_ON(!buf || !len))
 		return -EINVAL;
 
 	reg_buf = (u32 *)buf;
 	rem = len & 0x3;
 
 	dev_dbg(dev->dev, "buffer-length = %lu buf[0]0x%08X\n",
 		len, mei_txe_out_data_read(dev, 0));
 
 	for (i = 0; i < len / 4; i++) {
 		/* skip header: index starts from 1 */
 		reg = mei_txe_out_data_read(dev, i + 1);
 		dev_dbg(dev->dev, "buf[%d] = 0x%08X\n", i, reg);
 		*reg_buf++ = reg;
 	}
 
 	if (rem) {
 		reg = mei_txe_out_data_read(dev, i + 1);
 		memcpy(reg_buf, &reg, rem);
 	}
 
 	mei_txe_output_ready_set(hw);
 	return 0;
 }
 
 /**
  * mei_txe_hw_reset - resets host and fw.
  *
  * @dev: the device structure
  * @intr_enable: if interrupt should be enabled after reset.
  *
  * Return: 0 on success and < 0 in case of error
  */
 static int mei_txe_hw_reset(struct mei_device *dev, bool intr_enable)
 {
 	struct mei_txe_hw *hw = to_txe_hw(dev);
 
 	u32 aliveness_req;
 	/*
 	 * read input doorbell to ensure consistency between  Bridge and SeC
 	 * return value might be garbage return
 	 */
 	(void)mei_txe_sec_reg_read_silent(hw, SEC_IPC_INPUT_DOORBELL_REG);
 
 	aliveness_req = mei_txe_aliveness_req_get(dev);
 	hw->aliveness = mei_txe_aliveness_get(dev);
 
 	/* Disable interrupts in this stage we will poll */
 	mei_txe_intr_disable(dev);
 
 	/*
 	 * If Aliveness Request and Aliveness Response are not equal then
 	 * wait for them to be equal
 	 * Since we might have interrupts disabled - poll for it
 	 */
 	if (aliveness_req != hw->aliveness)
 		if (mei_txe_aliveness_poll(dev, aliveness_req) < 0) {
 			dev_err(dev->dev, "wait for aliveness settle failed ... bailing out\n");
 			return -EIO;
 		}
 
 	/*
 	 * If Aliveness Request and Aliveness Response are set then clear them
 	 */
 	if (aliveness_req) {
 		mei_txe_aliveness_set(dev, 0);
 		if (mei_txe_aliveness_poll(dev, 0) < 0) {
 			dev_err(dev->dev, "wait for aliveness failed ... bailing out\n");
 			return -EIO;
 		}
 	}
 
 	/*
 	 * Set readiness RDY_CLR bit
 	 */
 	mei_txe_readiness_clear(dev);
 
 	return 0;
 }
 
 /**
  * mei_txe_hw_start - start the hardware after reset
  *
  * @dev: the device structure
  *
  * Return: 0 on success an error code otherwise
  */
 static int mei_txe_hw_start(struct mei_device *dev)
 {
 	struct mei_txe_hw *hw = to_txe_hw(dev);
 	int ret;
 
 	u32 hisr;
 
 	/* bring back interrupts */
 	mei_txe_intr_enable(dev);
 
 	ret = mei_txe_readiness_wait(dev);
 	if (ret < 0) {
 		dev_err(dev->dev, "waiting for readiness failed\n");
 		return ret;
 	}
 
 	/*
 	 * If HISR.INT2_STS interrupt status bit is set then clear it.
 	 */
 	hisr = mei_txe_br_reg_read(hw, HISR_REG);
 	if (hisr & HISR_INT_2_STS)
 		mei_txe_br_reg_write(hw, HISR_REG, HISR_INT_2_STS);
 
 	/* Clear the interrupt cause of OutputDoorbell */
 	clear_bit(TXE_INTR_OUT_DB_BIT, &hw->intr_cause);
 
 	ret = mei_txe_aliveness_set_sync(dev, 1);
 	if (ret < 0) {
 		dev_err(dev->dev, "wait for aliveness failed ... bailing out\n");
 		return ret;
 	}
 
 	pm_runtime_set_active(dev->dev);
 
 	/* enable input ready interrupts:
 	 * SEC_IPC_HOST_INT_MASK.IPC_INPUT_READY_INT_MASK
 	 */
 	mei_txe_input_ready_interrupt_enable(dev);
 
 
 	/*  Set the SICR_SEC_IPC_OUTPUT_STATUS.IPC_OUTPUT_READY bit */
 	mei_txe_output_ready_set(hw);
 
 	/* Set bit SICR_HOST_IPC_READINESS.HOST_RDY
 	 */
 	mei_txe_readiness_set_host_rdy(dev);
 
 	return 0;
 }
 
 /**
  * mei_txe_check_and_ack_intrs - translate multi BAR interrupt into
  *  single bit mask and acknowledge the interrupts
  *
  * @dev: the device structure
  * @do_ack: acknowledge interrupts
  *
  * Return: true if found interrupts to process.
  */
 static bool mei_txe_check_and_ack_intrs(struct mei_device *dev, bool do_ack)
 {
 	struct mei_txe_hw *hw = to_txe_hw(dev);
 	u32 hisr;
 	u32 hhisr;
 	u32 ipc_isr;
 	u32 aliveness;
 	bool generated;
 
 	/* read interrupt registers */
 	hhisr = mei_txe_br_reg_read(hw, HHISR_REG);
 	generated = (hhisr & IPC_HHIER_MSK);
 	if (!generated)
 		goto out;
 
 	hisr = mei_txe_br_reg_read(hw, HISR_REG);
 
 	aliveness = mei_txe_aliveness_get(dev);
 	if (hhisr & IPC_HHIER_SEC && aliveness) {
 		ipc_isr = mei_txe_sec_reg_read_silent(hw,
 				SEC_IPC_HOST_INT_STATUS_REG);
 	} else {
 		ipc_isr = 0;
 		hhisr &= ~IPC_HHIER_SEC;
 	}
 
 	generated = generated ||
 		(hisr & HISR_INT_STS_MSK) ||
 		(ipc_isr & SEC_IPC_HOST_INT_STATUS_PENDING);
 
 	if (generated && do_ack) {
 		/* Save the interrupt causes */
 		hw->intr_cause |= hisr & HISR_INT_STS_MSK;
 		if (ipc_isr & SEC_IPC_HOST_INT_STATUS_IN_RDY)
 			hw->intr_cause |= TXE_INTR_IN_READY;
 
 
 		mei_txe_intr_disable(dev);
 		/* Clear the interrupts in hierarchy:
 		 * IPC and Bridge, than the High Level */
 		mei_txe_sec_reg_write_silent(hw,
 			SEC_IPC_HOST_INT_STATUS_REG, ipc_isr);
 		mei_txe_br_reg_write(hw, HISR_REG, hisr);
 		mei_txe_br_reg_write(hw, HHISR_REG, hhisr);
 	}
 
 out:
 	return generated;
 }
 
 /**
  * mei_txe_irq_quick_handler - The ISR of the MEI device
  *
  * @irq: The irq number
  * @dev_id: pointer to the device structure
  *
  * Return: IRQ_WAKE_THREAD if interrupt is designed for the device
  *         IRQ_NONE otherwise
  */
 irqreturn_t mei_txe_irq_quick_handler(int irq, void *dev_id)
 {
 	struct mei_device *dev = dev_id;
 
 	if (mei_txe_check_and_ack_intrs(dev, true))
 		return IRQ_WAKE_THREAD;
 	return IRQ_NONE;
 }
 
 
 /**
  * mei_txe_irq_thread_handler - txe interrupt thread
  *
  * @irq: The irq number
  * @dev_id: pointer to the device structure
  *
  * Return: IRQ_HANDLED
  */
 irqreturn_t mei_txe_irq_thread_handler(int irq, void *dev_id)
 {
 	struct mei_device *dev = (struct mei_device *) dev_id;
 	struct mei_txe_hw *hw = to_txe_hw(dev);
-	struct mei_cl_cb complete_list;
+	struct list_head cmpl_list;
 	s32 slots;
 	int rets = 0;
 
 	dev_dbg(dev->dev, "irq thread: Interrupt Registers HHISR|HISR|SEC=%02X|%04X|%02X\n",
 		mei_txe_br_reg_read(hw, HHISR_REG),
 		mei_txe_br_reg_read(hw, HISR_REG),
 		mei_txe_sec_reg_read_silent(hw, SEC_IPC_HOST_INT_STATUS_REG));
 
 
 	/* initialize our complete list */
 	mutex_lock(&dev->device_lock);
-	mei_io_list_init(&complete_list);
+	INIT_LIST_HEAD(&cmpl_list);
 
 	if (pci_dev_msi_enabled(to_pci_dev(dev->dev)))
 		mei_txe_check_and_ack_intrs(dev, true);
 
 	/* show irq events */
 	mei_txe_pending_interrupts(dev);
 
 	hw->aliveness = mei_txe_aliveness_get(dev);
 	hw->readiness = mei_txe_readiness_get(dev);
 
 	/* Readiness:
 	 * Detection of TXE driver going through reset
 	 * or TXE driver resetting the HECI interface.
 	 */
 	if (test_and_clear_bit(TXE_INTR_READINESS_BIT, &hw->intr_cause)) {
 		dev_dbg(dev->dev, "Readiness Interrupt was received...\n");
 
 		/* Check if SeC is going through reset */
 		if (mei_txe_readiness_is_sec_rdy(hw->readiness)) {
 			dev_dbg(dev->dev, "we need to start the dev.\n");
 			dev->recvd_hw_ready = true;
 		} else {
 			dev->recvd_hw_ready = false;
 			if (dev->dev_state != MEI_DEV_RESETTING) {
 
 				dev_warn(dev->dev, "FW not ready: resetting.\n");
 				schedule_work(&dev->reset_work);
 				goto end;
 
 			}
 		}
 		wake_up(&dev->wait_hw_ready);
 	}
 
 	/************************************************************/
 	/* Check interrupt cause:
 	 * Aliveness: Detection of SeC acknowledge of host request that
 	 * it remain alive or host cancellation of that request.
 	 */
 
 	if (test_and_clear_bit(TXE_INTR_ALIVENESS_BIT, &hw->intr_cause)) {
 		/* Clear the interrupt cause */
 		dev_dbg(dev->dev,
 			"Aliveness Interrupt: Status: %d\n", hw->aliveness);
 		dev->pg_event = MEI_PG_EVENT_RECEIVED;
 		if (waitqueue_active(&hw->wait_aliveness_resp))
 			wake_up(&hw->wait_aliveness_resp);
 	}
 
 
 	/* Output Doorbell:
 	 * Detection of SeC having sent output to host
 	 */
 	slots = mei_count_full_read_slots(dev);
 	if (test_and_clear_bit(TXE_INTR_OUT_DB_BIT, &hw->intr_cause)) {
 		/* Read from TXE */
-		rets = mei_irq_read_handler(dev, &complete_list, &slots);
+		rets = mei_irq_read_handler(dev, &cmpl_list, &slots);
 		if (rets && dev->dev_state != MEI_DEV_RESETTING) {
 			dev_err(dev->dev,
 				"mei_irq_read_handler ret = %d.\n", rets);
 
 			schedule_work(&dev->reset_work);
 			goto end;
 		}
 	}
 	/* Input Ready: Detection if host can write to SeC */
 	if (test_and_clear_bit(TXE_INTR_IN_READY_BIT, &hw->intr_cause)) {
 		dev->hbuf_is_ready = true;
 		hw->slots = dev->hbuf_depth;
 	}
 
 	if (hw->aliveness && dev->hbuf_is_ready) {
 		/* get the real register value */
 		dev->hbuf_is_ready = mei_hbuf_is_ready(dev);
-		rets = mei_irq_write_handler(dev, &complete_list);
+		rets = mei_irq_write_handler(dev, &cmpl_list);
 		if (rets && rets != -EMSGSIZE)
 			dev_err(dev->dev, "mei_irq_write_handler ret = %d.\n",
 				rets);
 		dev->hbuf_is_ready = mei_hbuf_is_ready(dev);
 	}
 
-	mei_irq_compl_handler(dev, &complete_list);
+	mei_irq_compl_handler(dev, &cmpl_list);
 
 end:
 	dev_dbg(dev->dev, "interrupt thread end ret = %d\n", rets);
 
 	mutex_unlock(&dev->device_lock);
 
 	mei_enable_interrupts(dev);
 	return IRQ_HANDLED;
 }
 
 static const struct mei_hw_ops mei_txe_hw_ops = {
 
 	.host_is_ready = mei_txe_host_is_ready,
 
 	.fw_status = mei_txe_fw_status,
 	.pg_state = mei_txe_pg_state,
 
 	.hw_is_ready = mei_txe_hw_is_ready,
 	.hw_reset = mei_txe_hw_reset,
 	.hw_config = mei_txe_hw_config,
 	.hw_start = mei_txe_hw_start,
 
 	.pg_in_transition = mei_txe_pg_in_transition,
 	.pg_is_enabled = mei_txe_pg_is_enabled,
 
 	.intr_clear = mei_txe_intr_clear,
 	.intr_enable = mei_txe_intr_enable,
 	.intr_disable = mei_txe_intr_disable,
 	.synchronize_irq = mei_txe_synchronize_irq,
 
 	.hbuf_free_slots = mei_txe_hbuf_empty_slots,
 	.hbuf_is_ready = mei_txe_is_input_ready,
 	.hbuf_max_len = mei_txe_hbuf_max_len,
 
 	.write = mei_txe_write,
 
 	.rdbuf_full_slots = mei_txe_count_full_read_slots,
 	.read_hdr = mei_txe_read_hdr,
 
 	.read = mei_txe_read,
 
 };
 
 /**
  * mei_txe_dev_init - allocates and initializes txe hardware specific structure
  *
  * @pdev: pci device
  *
  * Return: struct mei_device * on success or NULL
  */
 struct mei_device *mei_txe_dev_init(struct pci_dev *pdev)
 {
 	struct mei_device *dev;
 	struct mei_txe_hw *hw;
 
-	dev = kzalloc(sizeof(struct mei_device) +
-			 sizeof(struct mei_txe_hw), GFP_KERNEL);
+	dev = devm_kzalloc(&pdev->dev, sizeof(struct mei_device) +
+			   sizeof(struct mei_txe_hw), GFP_KERNEL);
 	if (!dev)
 		return NULL;
 
 	mei_device_init(dev, &pdev->dev, &mei_txe_hw_ops);
 
 	hw = to_txe_hw(dev);
 
 	init_waitqueue_head(&hw->wait_aliveness_resp);
 
 	return dev;
 }
 
 /**
  * mei_txe_setup_satt2 - SATT2 configuration for DMA support.
  *
  * @dev:   the device structure
  * @addr:  physical address start of the range
  * @range: physical range size
  *
  * Return: 0 on success an error code otherwise
  */
 int mei_txe_setup_satt2(struct mei_device *dev, phys_addr_t addr, u32 range)
 {
 	struct mei_txe_hw *hw = to_txe_hw(dev);
 
 	u32 lo32 = lower_32_bits(addr);
 	u32 hi32 = upper_32_bits(addr);
 	u32 ctrl;
 
 	/* SATT is limited to 36 Bits */
 	if (hi32 & ~0xF)
 		return -EINVAL;
 
 	/* SATT has to be 16Byte aligned */
 	if (lo32 & 0xF)
 		return -EINVAL;
 
 	/* SATT range has to be 4Bytes aligned */
 	if (range & 0x4)
 		return -EINVAL;
 
 	/* SATT is limited to 32 MB range*/
 	if (range > SATT_RANGE_MAX)
 		return -EINVAL;
 
 	ctrl = SATT2_CTRL_VALID_MSK;
 	ctrl |= hi32  << SATT2_CTRL_BR_BASE_ADDR_REG_SHIFT;
 
 	mei_txe_br_reg_write(hw, SATT2_SAP_SIZE_REG, range);
 	mei_txe_br_reg_write(hw, SATT2_BRG_BA_LSB_REG, lo32);
 	mei_txe_br_reg_write(hw, SATT2_CTRL_REG, ctrl);
 	dev_dbg(dev->dev, "SATT2: SAP_SIZE_OFFSET=0x%08X, BRG_BA_LSB_OFFSET=0x%08X, CTRL_OFFSET=0x%08X\n",
 		range, lo32, ctrl);
 
 	return 0;
 }
diff --git a/drivers/misc/mei/hw-txe.h b/drivers/misc/mei/hw-txe.h
index ce3ed0b88b0c..e1e8b66d7648 100644
--- a/drivers/misc/mei/hw-txe.h
+++ b/drivers/misc/mei/hw-txe.h
@@ -1,75 +1,75 @@
 /*
  *
  * Intel Management Engine Interface (Intel MEI) Linux driver
  * Copyright (c) 2013-2014, Intel Corporation.
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms and conditions of the GNU General Public License,
  * version 2, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope it will be useful, but WITHOUT
  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
  * more details.
  *
  */
 
 #ifndef _MEI_HW_TXE_H_
 #define _MEI_HW_TXE_H_
 
 #include <linux/irqreturn.h>
 
 #include "hw.h"
 #include "hw-txe-regs.h"
 
 #define MEI_TXI_RPM_TIMEOUT    500 /* ms */
 
 /* Flatten Hierarchy interrupt cause */
 #define TXE_INTR_READINESS_BIT  0 /* HISR_INT_0_STS */
 #define TXE_INTR_READINESS      HISR_INT_0_STS
 #define TXE_INTR_ALIVENESS_BIT  1 /* HISR_INT_1_STS */
 #define TXE_INTR_ALIVENESS      HISR_INT_1_STS
 #define TXE_INTR_OUT_DB_BIT     2 /* HISR_INT_2_STS */
 #define TXE_INTR_OUT_DB         HISR_INT_2_STS
 #define TXE_INTR_IN_READY_BIT   8 /* beyond HISR */
 #define TXE_INTR_IN_READY       BIT(8)
 
 /**
  * struct mei_txe_hw - txe hardware specifics
  *
  * @mem_addr:            SeC and BRIDGE bars
  * @aliveness:           aliveness (power gating) state of the hardware
  * @readiness:           readiness state of the hardware
  * @slots:               number of empty slots
  * @wait_aliveness_resp: aliveness wait queue
  * @intr_cause:          translated interrupt cause
  */
 struct mei_txe_hw {
-	void __iomem *mem_addr[NUM_OF_MEM_BARS];
+	void __iomem * const *mem_addr;
 	u32 aliveness;
 	u32 readiness;
 	u32 slots;
 
 	wait_queue_head_t wait_aliveness_resp;
 
 	unsigned long intr_cause;
 };
 
 #define to_txe_hw(dev) (struct mei_txe_hw *)((dev)->hw)
 
 static inline struct mei_device *hw_txe_to_mei(struct mei_txe_hw *hw)
 {
 	return container_of((void *)hw, struct mei_device, hw);
 }
 
 struct mei_device *mei_txe_dev_init(struct pci_dev *pdev);
 
 irqreturn_t mei_txe_irq_quick_handler(int irq, void *dev_id);
 irqreturn_t mei_txe_irq_thread_handler(int irq, void *dev_id);
 
 int mei_txe_aliveness_set_sync(struct mei_device *dev, u32 req);
 
 int mei_txe_setup_satt2(struct mei_device *dev, phys_addr_t addr, u32 range);
 
 
 #endif /* _MEI_HW_TXE_H_ */
diff --git a/drivers/misc/mei/init.c b/drivers/misc/mei/init.c
index 41e5760a6886..cfb1cdf176fa 100644
--- a/drivers/misc/mei/init.c
+++ b/drivers/misc/mei/init.c
@@ -1,417 +1,417 @@
 /*
  *
  * Intel Management Engine Interface (Intel MEI) Linux driver
  * Copyright (c) 2003-2012, Intel Corporation.
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms and conditions of the GNU General Public License,
  * version 2, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope it will be useful, but WITHOUT
  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
  * more details.
  *
  */
 
 #include <linux/export.h>
 #include <linux/sched.h>
 #include <linux/wait.h>
 #include <linux/delay.h>
 
 #include <linux/mei.h>
 
 #include "mei_dev.h"
 #include "hbm.h"
 #include "client.h"
 
 const char *mei_dev_state_str(int state)
 {
 #define MEI_DEV_STATE(state) case MEI_DEV_##state: return #state
 	switch (state) {
 	MEI_DEV_STATE(INITIALIZING);
 	MEI_DEV_STATE(INIT_CLIENTS);
 	MEI_DEV_STATE(ENABLED);
 	MEI_DEV_STATE(RESETTING);
 	MEI_DEV_STATE(DISABLED);
 	MEI_DEV_STATE(POWER_DOWN);
 	MEI_DEV_STATE(POWER_UP);
 	default:
 		return "unknown";
 	}
 #undef MEI_DEV_STATE
 }
 
 const char *mei_pg_state_str(enum mei_pg_state state)
 {
 #define MEI_PG_STATE(state) case MEI_PG_##state: return #state
 	switch (state) {
 	MEI_PG_STATE(OFF);
 	MEI_PG_STATE(ON);
 	default:
 		return "unknown";
 	}
 #undef MEI_PG_STATE
 }
 
 /**
  * mei_fw_status2str - convert fw status registers to printable string
  *
  * @fw_status:  firmware status
  * @buf: string buffer at minimal size MEI_FW_STATUS_STR_SZ
  * @len: buffer len must be >= MEI_FW_STATUS_STR_SZ
  *
  * Return: number of bytes written or -EINVAL if buffer is to small
  */
 ssize_t mei_fw_status2str(struct mei_fw_status *fw_status,
 			  char *buf, size_t len)
 {
 	ssize_t cnt = 0;
 	int i;
 
 	buf[0] = '\0';
 
 	if (len < MEI_FW_STATUS_STR_SZ)
 		return -EINVAL;
 
 	for (i = 0; i < fw_status->count; i++)
 		cnt += scnprintf(buf + cnt, len - cnt, "%08X ",
 				fw_status->status[i]);
 
 	/* drop last space */
 	buf[cnt] = '\0';
 	return cnt;
 }
 EXPORT_SYMBOL_GPL(mei_fw_status2str);
 
 /**
  * mei_cancel_work - Cancel mei background jobs
  *
  * @dev: the device structure
  */
 void mei_cancel_work(struct mei_device *dev)
 {
 	cancel_work_sync(&dev->reset_work);
 	cancel_work_sync(&dev->bus_rescan_work);
 
 	cancel_delayed_work_sync(&dev->timer_work);
 }
 EXPORT_SYMBOL_GPL(mei_cancel_work);
 
 /**
  * mei_reset - resets host and fw.
  *
  * @dev: the device structure
  *
  * Return: 0 on success or < 0 if the reset hasn't succeeded
  */
 int mei_reset(struct mei_device *dev)
 {
 	enum mei_dev_state state = dev->dev_state;
 	bool interrupts_enabled;
 	int ret;
 
 	if (state != MEI_DEV_INITIALIZING &&
 	    state != MEI_DEV_DISABLED &&
 	    state != MEI_DEV_POWER_DOWN &&
 	    state != MEI_DEV_POWER_UP) {
 		char fw_sts_str[MEI_FW_STATUS_STR_SZ];
 
 		mei_fw_status_str(dev, fw_sts_str, MEI_FW_STATUS_STR_SZ);
 		dev_warn(dev->dev, "unexpected reset: dev_state = %s fw status = %s\n",
 			 mei_dev_state_str(state), fw_sts_str);
 	}
 
 	mei_clear_interrupts(dev);
 
 	mei_synchronize_irq(dev);
 
 	/* we're already in reset, cancel the init timer
 	 * if the reset was called due the hbm protocol error
 	 * we need to call it before hw start
 	 * so the hbm watchdog won't kick in
 	 */
 	mei_hbm_idle(dev);
 
 	/* enter reset flow */
 	interrupts_enabled = state != MEI_DEV_POWER_DOWN;
 	dev->dev_state = MEI_DEV_RESETTING;
 
 	dev->reset_count++;
 	if (dev->reset_count > MEI_MAX_CONSEC_RESET) {
 		dev_err(dev->dev, "reset: reached maximal consecutive resets: disabling the device\n");
 		dev->dev_state = MEI_DEV_DISABLED;
 		return -ENODEV;
 	}
 
 	ret = mei_hw_reset(dev, interrupts_enabled);
 	/* fall through and remove the sw state even if hw reset has failed */
 
 	/* no need to clean up software state in case of power up */
 	if (state != MEI_DEV_INITIALIZING &&
 	    state != MEI_DEV_POWER_UP) {
 
 		/* remove all waiting requests */
 		mei_cl_all_disconnect(dev);
 
 		/* remove entry if already in list */
 		dev_dbg(dev->dev, "remove iamthif from the file list.\n");
 		mei_cl_unlink(&dev->iamthif_cl);
 		mei_amthif_reset_params(dev);
 	}
 
 	mei_hbm_reset(dev);
 
 	dev->rd_msg_hdr = 0;
 
 	if (ret) {
 		dev_err(dev->dev, "hw_reset failed ret = %d\n", ret);
 		return ret;
 	}
 
 	if (state == MEI_DEV_POWER_DOWN) {
 		dev_dbg(dev->dev, "powering down: end of reset\n");
 		dev->dev_state = MEI_DEV_DISABLED;
 		return 0;
 	}
 
 	ret = mei_hw_start(dev);
 	if (ret) {
 		dev_err(dev->dev, "hw_start failed ret = %d\n", ret);
 		return ret;
 	}
 
 	dev_dbg(dev->dev, "link is established start sending messages.\n");
 
 	dev->dev_state = MEI_DEV_INIT_CLIENTS;
 	ret = mei_hbm_start_req(dev);
 	if (ret) {
 		dev_err(dev->dev, "hbm_start failed ret = %d\n", ret);
 		dev->dev_state = MEI_DEV_RESETTING;
 		return ret;
 	}
 
 	return 0;
 }
 EXPORT_SYMBOL_GPL(mei_reset);
 
 /**
  * mei_start - initializes host and fw to start work.
  *
  * @dev: the device structure
  *
  * Return: 0 on success, <0 on failure.
  */
 int mei_start(struct mei_device *dev)
 {
 	int ret;
 
 	mutex_lock(&dev->device_lock);
 
 	/* acknowledge interrupt and stop interrupts */
 	mei_clear_interrupts(dev);
 
 	mei_hw_config(dev);
 
 	dev_dbg(dev->dev, "reset in start the mei device.\n");
 
 	dev->reset_count = 0;
 	do {
 		dev->dev_state = MEI_DEV_INITIALIZING;
 		ret = mei_reset(dev);
 
 		if (ret == -ENODEV || dev->dev_state == MEI_DEV_DISABLED) {
 			dev_err(dev->dev, "reset failed ret = %d", ret);
 			goto err;
 		}
 	} while (ret);
 
 	/* we cannot start the device w/o hbm start message completed */
 	if (dev->dev_state == MEI_DEV_DISABLED) {
 		dev_err(dev->dev, "reset failed");
 		goto err;
 	}
 
 	if (mei_hbm_start_wait(dev)) {
 		dev_err(dev->dev, "HBM haven't started");
 		goto err;
 	}
 
 	if (!mei_host_is_ready(dev)) {
 		dev_err(dev->dev, "host is not ready.\n");
 		goto err;
 	}
 
 	if (!mei_hw_is_ready(dev)) {
 		dev_err(dev->dev, "ME is not ready.\n");
 		goto err;
 	}
 
 	if (!mei_hbm_version_is_supported(dev)) {
 		dev_dbg(dev->dev, "MEI start failed.\n");
 		goto err;
 	}
 
 	dev_dbg(dev->dev, "link layer has been established.\n");
 
 	mutex_unlock(&dev->device_lock);
 	return 0;
 err:
 	dev_err(dev->dev, "link layer initialization failed.\n");
 	dev->dev_state = MEI_DEV_DISABLED;
 	mutex_unlock(&dev->device_lock);
 	return -ENODEV;
 }
 EXPORT_SYMBOL_GPL(mei_start);
 
 /**
  * mei_restart - restart device after suspend
  *
  * @dev: the device structure
  *
  * Return: 0 on success or -ENODEV if the restart hasn't succeeded
  */
 int mei_restart(struct mei_device *dev)
 {
 	int err;
 
 	mutex_lock(&dev->device_lock);
 
 	dev->dev_state = MEI_DEV_POWER_UP;
 	dev->reset_count = 0;
 
 	err = mei_reset(dev);
 
 	mutex_unlock(&dev->device_lock);
 
 	if (err == -ENODEV || dev->dev_state == MEI_DEV_DISABLED) {
 		dev_err(dev->dev, "device disabled = %d\n", err);
 		return -ENODEV;
 	}
 
 	/* try to start again */
 	if (err)
 		schedule_work(&dev->reset_work);
 
 
 	return 0;
 }
 EXPORT_SYMBOL_GPL(mei_restart);
 
 static void mei_reset_work(struct work_struct *work)
 {
 	struct mei_device *dev =
 		container_of(work, struct mei_device,  reset_work);
 	int ret;
 
 	mutex_lock(&dev->device_lock);
 
 	ret = mei_reset(dev);
 
 	mutex_unlock(&dev->device_lock);
 
 	if (dev->dev_state == MEI_DEV_DISABLED) {
 		dev_err(dev->dev, "device disabled = %d\n", ret);
 		return;
 	}
 
 	/* retry reset in case of failure */
 	if (ret)
 		schedule_work(&dev->reset_work);
 }
 
 void mei_stop(struct mei_device *dev)
 {
 	dev_dbg(dev->dev, "stopping the device.\n");
 
 	mei_cl_bus_remove_devices(dev);
 
 	mei_cancel_work(dev);
 
 	mutex_lock(&dev->device_lock);
 
 	dev->dev_state = MEI_DEV_POWER_DOWN;
 	mei_reset(dev);
 	/* move device to disabled state unconditionally */
 	dev->dev_state = MEI_DEV_DISABLED;
 
 	mutex_unlock(&dev->device_lock);
 }
 EXPORT_SYMBOL_GPL(mei_stop);
 
 /**
  * mei_write_is_idle - check if the write queues are idle
  *
  * @dev: the device structure
  *
  * Return: true of there is no pending write
  */
 bool mei_write_is_idle(struct mei_device *dev)
 {
 	bool idle = (dev->dev_state == MEI_DEV_ENABLED &&
-		list_empty(&dev->ctrl_wr_list.list) &&
-		list_empty(&dev->write_list.list)   &&
-		list_empty(&dev->write_waiting_list.list));
+		list_empty(&dev->ctrl_wr_list) &&
+		list_empty(&dev->write_list)   &&
+		list_empty(&dev->write_waiting_list));
 
 	dev_dbg(dev->dev, "write pg: is idle[%d] state=%s ctrl=%01d write=%01d wwait=%01d\n",
 		idle,
 		mei_dev_state_str(dev->dev_state),
-		list_empty(&dev->ctrl_wr_list.list),
-		list_empty(&dev->write_list.list),
-		list_empty(&dev->write_waiting_list.list));
+		list_empty(&dev->ctrl_wr_list),
+		list_empty(&dev->write_list),
+		list_empty(&dev->write_waiting_list));
 
 	return idle;
 }
 EXPORT_SYMBOL_GPL(mei_write_is_idle);
 
 /**
  * mei_device_init  -- initialize mei_device structure
  *
  * @dev: the mei device
  * @device: the device structure
  * @hw_ops: hw operations
  */
 void mei_device_init(struct mei_device *dev,
 		     struct device *device,
 		     const struct mei_hw_ops *hw_ops)
 {
 	/* setup our list array */
 	INIT_LIST_HEAD(&dev->file_list);
 	INIT_LIST_HEAD(&dev->device_list);
 	INIT_LIST_HEAD(&dev->me_clients);
 	mutex_init(&dev->device_lock);
 	init_rwsem(&dev->me_clients_rwsem);
 	mutex_init(&dev->cl_bus_lock);
 	init_waitqueue_head(&dev->wait_hw_ready);
 	init_waitqueue_head(&dev->wait_pg);
 	init_waitqueue_head(&dev->wait_hbm_start);
 	dev->dev_state = MEI_DEV_INITIALIZING;
 	dev->reset_count = 0;
 
-	mei_io_list_init(&dev->write_list);
-	mei_io_list_init(&dev->write_waiting_list);
-	mei_io_list_init(&dev->ctrl_wr_list);
-	mei_io_list_init(&dev->ctrl_rd_list);
+	INIT_LIST_HEAD(&dev->write_list);
+	INIT_LIST_HEAD(&dev->write_waiting_list);
+	INIT_LIST_HEAD(&dev->ctrl_wr_list);
+	INIT_LIST_HEAD(&dev->ctrl_rd_list);
 
 	INIT_DELAYED_WORK(&dev->timer_work, mei_timer);
 	INIT_WORK(&dev->reset_work, mei_reset_work);
 	INIT_WORK(&dev->bus_rescan_work, mei_cl_bus_rescan_work);
 
 	INIT_LIST_HEAD(&dev->iamthif_cl.link);
-	mei_io_list_init(&dev->amthif_cmd_list);
+	INIT_LIST_HEAD(&dev->amthif_cmd_list);
 
 	bitmap_zero(dev->host_clients_map, MEI_CLIENTS_MAX);
 	dev->open_handle_count = 0;
 
 	/*
 	 * Reserving the first client ID
 	 * 0: Reserved for MEI Bus Message communications
 	 */
 	bitmap_set(dev->host_clients_map, 0, 1);
 
 	dev->pg_event = MEI_PG_EVENT_IDLE;
 	dev->ops      = hw_ops;
 	dev->dev      = device;
 }
 EXPORT_SYMBOL_GPL(mei_device_init);
 
diff --git a/drivers/misc/mei/interrupt.c b/drivers/misc/mei/interrupt.c
index b584749bcc4a..406e9e2b2fff 100644
--- a/drivers/misc/mei/interrupt.c
+++ b/drivers/misc/mei/interrupt.c
@@ -1,536 +1,534 @@
 /*
  *
  * Intel Management Engine Interface (Intel MEI) Linux driver
  * Copyright (c) 2003-2012, Intel Corporation.
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms and conditions of the GNU General Public License,
  * version 2, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope it will be useful, but WITHOUT
  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
  * more details.
  *
  */
 
 
 #include <linux/export.h>
 #include <linux/kthread.h>
 #include <linux/interrupt.h>
 #include <linux/fs.h>
 #include <linux/jiffies.h>
 #include <linux/slab.h>
 #include <linux/pm_runtime.h>
 
 #include <linux/mei.h>
 
 #include "mei_dev.h"
 #include "hbm.h"
 #include "client.h"
 
 
 /**
  * mei_irq_compl_handler - dispatch complete handlers
  *	for the completed callbacks
  *
  * @dev: mei device
- * @compl_list: list of completed cbs
+ * @cmpl_list: list of completed cbs
  */
-void mei_irq_compl_handler(struct mei_device *dev, struct mei_cl_cb *compl_list)
+void mei_irq_compl_handler(struct mei_device *dev, struct list_head *cmpl_list)
 {
 	struct mei_cl_cb *cb, *next;
 	struct mei_cl *cl;
 
-	list_for_each_entry_safe(cb, next, &compl_list->list, list) {
+	list_for_each_entry_safe(cb, next, cmpl_list, list) {
 		cl = cb->cl;
 		list_del_init(&cb->list);
 
 		dev_dbg(dev->dev, "completing call back.\n");
 		if (cl == &dev->iamthif_cl)
 			mei_amthif_complete(cl, cb);
 		else
 			mei_cl_complete(cl, cb);
 	}
 }
 EXPORT_SYMBOL_GPL(mei_irq_compl_handler);
 
 /**
  * mei_cl_hbm_equal - check if hbm is addressed to the client
  *
  * @cl: host client
  * @mei_hdr: header of mei client message
  *
  * Return: true if matches, false otherwise
  */
 static inline int mei_cl_hbm_equal(struct mei_cl *cl,
 			struct mei_msg_hdr *mei_hdr)
 {
 	return  mei_cl_host_addr(cl) == mei_hdr->host_addr &&
 		mei_cl_me_id(cl) == mei_hdr->me_addr;
 }
 
 /**
  * mei_irq_discard_msg  - discard received message
  *
  * @dev: mei device
  * @hdr: message header
  */
 void mei_irq_discard_msg(struct mei_device *dev, struct mei_msg_hdr *hdr)
 {
 	/*
 	 * no need to check for size as it is guarantied
 	 * that length fits into rd_msg_buf
 	 */
 	mei_read_slots(dev, dev->rd_msg_buf, hdr->length);
 	dev_dbg(dev->dev, "discarding message " MEI_HDR_FMT "\n",
 		MEI_HDR_PRM(hdr));
 }
 
 /**
  * mei_cl_irq_read_msg - process client message
  *
  * @cl: reading client
  * @mei_hdr: header of mei client message
- * @complete_list: completion list
+ * @cmpl_list: completion list
  *
  * Return: always 0
  */
 int mei_cl_irq_read_msg(struct mei_cl *cl,
 		       struct mei_msg_hdr *mei_hdr,
-		       struct mei_cl_cb *complete_list)
+		       struct list_head *cmpl_list)
 {
 	struct mei_device *dev = cl->dev;
 	struct mei_cl_cb *cb;
 	size_t buf_sz;
 
 	cb = list_first_entry_or_null(&cl->rd_pending, struct mei_cl_cb, list);
 	if (!cb) {
 		if (!mei_cl_is_fixed_address(cl)) {
 			cl_err(dev, cl, "pending read cb not found\n");
 			goto discard;
 		}
 		cb = mei_cl_alloc_cb(cl, mei_cl_mtu(cl), MEI_FOP_READ, cl->fp);
 		if (!cb)
 			goto discard;
 		list_add_tail(&cb->list, &cl->rd_pending);
 	}
 
 	if (!mei_cl_is_connected(cl)) {
 		cl_dbg(dev, cl, "not connected\n");
 		cb->status = -ENODEV;
 		goto discard;
 	}
 
 	buf_sz = mei_hdr->length + cb->buf_idx;
 	/* catch for integer overflow */
 	if (buf_sz < cb->buf_idx) {
 		cl_err(dev, cl, "message is too big len %d idx %zu\n",
 		       mei_hdr->length, cb->buf_idx);
 		cb->status = -EMSGSIZE;
 		goto discard;
 	}
 
 	if (cb->buf.size < buf_sz) {
 		cl_dbg(dev, cl, "message overflow. size %zu len %d idx %zu\n",
 			cb->buf.size, mei_hdr->length, cb->buf_idx);
 		cb->status = -EMSGSIZE;
 		goto discard;
 	}
 
 	mei_read_slots(dev, cb->buf.data + cb->buf_idx, mei_hdr->length);
 
 	cb->buf_idx += mei_hdr->length;
 
 	if (mei_hdr->msg_complete) {
 		cl_dbg(dev, cl, "completed read length = %zu\n", cb->buf_idx);
-		list_move_tail(&cb->list, &complete_list->list);
+		list_move_tail(&cb->list, cmpl_list);
 	} else {
 		pm_runtime_mark_last_busy(dev->dev);
 		pm_request_autosuspend(dev->dev);
 	}
 
 	return 0;
 
 discard:
 	if (cb)
-		list_move_tail(&cb->list, &complete_list->list);
+		list_move_tail(&cb->list, cmpl_list);
 	mei_irq_discard_msg(dev, mei_hdr);
 	return 0;
 }
 
 /**
  * mei_cl_irq_disconnect_rsp - send disconnection response message
  *
  * @cl: client
  * @cb: callback block.
  * @cmpl_list: complete list.
  *
  * Return: 0, OK; otherwise, error.
  */
 static int mei_cl_irq_disconnect_rsp(struct mei_cl *cl, struct mei_cl_cb *cb,
-				     struct mei_cl_cb *cmpl_list)
+				     struct list_head *cmpl_list)
 {
 	struct mei_device *dev = cl->dev;
 	u32 msg_slots;
 	int slots;
 	int ret;
 
 	slots = mei_hbuf_empty_slots(dev);
 	msg_slots = mei_data2slots(sizeof(struct hbm_client_connect_response));
 
 	if (slots < msg_slots)
 		return -EMSGSIZE;
 
 	ret = mei_hbm_cl_disconnect_rsp(dev, cl);
-	list_move_tail(&cb->list, &cmpl_list->list);
+	list_move_tail(&cb->list, cmpl_list);
 
 	return ret;
 }
 
 /**
  * mei_cl_irq_read - processes client read related operation from the
  *	interrupt thread context - request for flow control credits
  *
  * @cl: client
  * @cb: callback block.
  * @cmpl_list: complete list.
  *
  * Return: 0, OK; otherwise, error.
  */
 static int mei_cl_irq_read(struct mei_cl *cl, struct mei_cl_cb *cb,
-			   struct mei_cl_cb *cmpl_list)
+			   struct list_head *cmpl_list)
 {
 	struct mei_device *dev = cl->dev;
 	u32 msg_slots;
 	int slots;
 	int ret;
 
 	if (!list_empty(&cl->rd_pending))
 		return 0;
 
 	msg_slots = mei_data2slots(sizeof(struct hbm_flow_control));
 	slots = mei_hbuf_empty_slots(dev);
 
 	if (slots < msg_slots)
 		return -EMSGSIZE;
 
 	ret = mei_hbm_cl_flow_control_req(dev, cl);
 	if (ret) {
 		cl->status = ret;
 		cb->buf_idx = 0;
-		list_move_tail(&cb->list, &cmpl_list->list);
+		list_move_tail(&cb->list, cmpl_list);
 		return ret;
 	}
 
 	list_move_tail(&cb->list, &cl->rd_pending);
 
 	return 0;
 }
 
 static inline bool hdr_is_hbm(struct mei_msg_hdr *mei_hdr)
 {
 	return mei_hdr->host_addr == 0 && mei_hdr->me_addr == 0;
 }
 
 static inline bool hdr_is_fixed(struct mei_msg_hdr *mei_hdr)
 {
 	return mei_hdr->host_addr == 0 && mei_hdr->me_addr != 0;
 }
 
 /**
  * mei_irq_read_handler - bottom half read routine after ISR to
  * handle the read processing.
  *
  * @dev: the device structure
  * @cmpl_list: An instance of our list structure
  * @slots: slots to read.
  *
  * Return: 0 on success, <0 on failure.
  */
 int mei_irq_read_handler(struct mei_device *dev,
-		struct mei_cl_cb *cmpl_list, s32 *slots)
+			 struct list_head *cmpl_list, s32 *slots)
 {
 	struct mei_msg_hdr *mei_hdr;
 	struct mei_cl *cl;
 	int ret;
 
 	if (!dev->rd_msg_hdr) {
 		dev->rd_msg_hdr = mei_read_hdr(dev);
 		(*slots)--;
 		dev_dbg(dev->dev, "slots =%08x.\n", *slots);
 	}
 	mei_hdr = (struct mei_msg_hdr *) &dev->rd_msg_hdr;
 	dev_dbg(dev->dev, MEI_HDR_FMT, MEI_HDR_PRM(mei_hdr));
 
 	if (mei_hdr->reserved || !dev->rd_msg_hdr) {
 		dev_err(dev->dev, "corrupted message header 0x%08X\n",
 				dev->rd_msg_hdr);
 		ret = -EBADMSG;
 		goto end;
 	}
 
 	if (mei_slots2data(*slots) < mei_hdr->length) {
 		dev_err(dev->dev, "less data available than length=%08x.\n",
 				*slots);
 		/* we can't read the message */
 		ret = -ENODATA;
 		goto end;
 	}
 
 	/*  HBM message */
 	if (hdr_is_hbm(mei_hdr)) {
 		ret = mei_hbm_dispatch(dev, mei_hdr);
 		if (ret) {
 			dev_dbg(dev->dev, "mei_hbm_dispatch failed ret = %d\n",
 					ret);
 			goto end;
 		}
 		goto reset_slots;
 	}
 
 	/* find recipient cl */
 	list_for_each_entry(cl, &dev->file_list, link) {
 		if (mei_cl_hbm_equal(cl, mei_hdr)) {
 			cl_dbg(dev, cl, "got a message\n");
 			break;
 		}
 	}
 
 	/* if no recipient cl was found we assume corrupted header */
 	if (&cl->link == &dev->file_list) {
 		/* A message for not connected fixed address clients
 		 * should be silently discarded
 		 */
 		if (hdr_is_fixed(mei_hdr)) {
 			mei_irq_discard_msg(dev, mei_hdr);
 			ret = 0;
 			goto reset_slots;
 		}
 		dev_err(dev->dev, "no destination client found 0x%08X\n",
 				dev->rd_msg_hdr);
 		ret = -EBADMSG;
 		goto end;
 	}
 
 	if (cl == &dev->iamthif_cl) {
 		ret = mei_amthif_irq_read_msg(cl, mei_hdr, cmpl_list);
 	} else {
 		ret = mei_cl_irq_read_msg(cl, mei_hdr, cmpl_list);
 	}
 
 
 reset_slots:
 	/* reset the number of slots and header */
 	*slots = mei_count_full_read_slots(dev);
 	dev->rd_msg_hdr = 0;
 
 	if (*slots == -EOVERFLOW) {
 		/* overflow - reset */
 		dev_err(dev->dev, "resetting due to slots overflow.\n");
 		/* set the event since message has been read */
 		ret = -ERANGE;
 		goto end;
 	}
 end:
 	return ret;
 }
 EXPORT_SYMBOL_GPL(mei_irq_read_handler);
 
 
 /**
  * mei_irq_write_handler -  dispatch write requests
  *  after irq received
  *
  * @dev: the device structure
  * @cmpl_list: An instance of our list structure
  *
  * Return: 0 on success, <0 on failure.
  */
-int mei_irq_write_handler(struct mei_device *dev, struct mei_cl_cb *cmpl_list)
+int mei_irq_write_handler(struct mei_device *dev, struct list_head *cmpl_list)
 {
 
 	struct mei_cl *cl;
 	struct mei_cl_cb *cb, *next;
-	struct mei_cl_cb *list;
 	s32 slots;
 	int ret;
 
 
 	if (!mei_hbuf_acquire(dev))
 		return 0;
 
 	slots = mei_hbuf_empty_slots(dev);
 	if (slots <= 0)
 		return -EMSGSIZE;
 
 	/* complete all waiting for write CB */
 	dev_dbg(dev->dev, "complete all waiting for write cb.\n");
 
-	list = &dev->write_waiting_list;
-	list_for_each_entry_safe(cb, next, &list->list, list) {
+	list_for_each_entry_safe(cb, next, &dev->write_waiting_list, list) {
 		cl = cb->cl;
 
 		cl->status = 0;
 		cl_dbg(dev, cl, "MEI WRITE COMPLETE\n");
 		cl->writing_state = MEI_WRITE_COMPLETE;
-		list_move_tail(&cb->list, &cmpl_list->list);
+		list_move_tail(&cb->list, cmpl_list);
 	}
 
 	/* complete control write list CB */
 	dev_dbg(dev->dev, "complete control write list cb.\n");
-	list_for_each_entry_safe(cb, next, &dev->ctrl_wr_list.list, list) {
+	list_for_each_entry_safe(cb, next, &dev->ctrl_wr_list, list) {
 		cl = cb->cl;
 		switch (cb->fop_type) {
 		case MEI_FOP_DISCONNECT:
 			/* send disconnect message */
 			ret = mei_cl_irq_disconnect(cl, cb, cmpl_list);
 			if (ret)
 				return ret;
 
 			break;
 		case MEI_FOP_READ:
 			/* send flow control message */
 			ret = mei_cl_irq_read(cl, cb, cmpl_list);
 			if (ret)
 				return ret;
 
 			break;
 		case MEI_FOP_CONNECT:
 			/* connect message */
 			ret = mei_cl_irq_connect(cl, cb, cmpl_list);
 			if (ret)
 				return ret;
 
 			break;
 		case MEI_FOP_DISCONNECT_RSP:
 			/* send disconnect resp */
 			ret = mei_cl_irq_disconnect_rsp(cl, cb, cmpl_list);
 			if (ret)
 				return ret;
 			break;
 
 		case MEI_FOP_NOTIFY_START:
 		case MEI_FOP_NOTIFY_STOP:
 			ret = mei_cl_irq_notify(cl, cb, cmpl_list);
 			if (ret)
 				return ret;
 			break;
 		default:
 			BUG();
 		}
 
 	}
 	/* complete  write list CB */
 	dev_dbg(dev->dev, "complete write list cb.\n");
-	list_for_each_entry_safe(cb, next, &dev->write_list.list, list) {
+	list_for_each_entry_safe(cb, next, &dev->write_list, list) {
 		cl = cb->cl;
 		if (cl == &dev->iamthif_cl)
 			ret = mei_amthif_irq_write(cl, cb, cmpl_list);
 		else
 			ret = mei_cl_irq_write(cl, cb, cmpl_list);
 		if (ret)
 			return ret;
 	}
 	return 0;
 }
 EXPORT_SYMBOL_GPL(mei_irq_write_handler);
 
 
 /**
  * mei_connect_timeout  - connect/disconnect timeouts
  *
  * @cl: host client
  */
 static void mei_connect_timeout(struct mei_cl *cl)
 {
 	struct mei_device *dev = cl->dev;
 
 	if (cl->state == MEI_FILE_CONNECTING) {
 		if (dev->hbm_f_dot_supported) {
 			cl->state = MEI_FILE_DISCONNECT_REQUIRED;
 			wake_up(&cl->wait);
 			return;
 		}
 	}
 	mei_reset(dev);
 }
 
 #define MEI_STALL_TIMER_FREQ (2 * HZ)
 /**
  * mei_schedule_stall_timer - re-arm stall_timer work
  *
  * Schedule stall timer
  *
  * @dev: the device structure
  */
 void mei_schedule_stall_timer(struct mei_device *dev)
 {
 	schedule_delayed_work(&dev->timer_work, MEI_STALL_TIMER_FREQ);
 }
 
 /**
  * mei_timer - timer function.
  *
  * @work: pointer to the work_struct structure
  *
  */
 void mei_timer(struct work_struct *work)
 {
 	struct mei_cl *cl;
 	struct mei_device *dev = container_of(work,
 					struct mei_device, timer_work.work);
 	bool reschedule_timer = false;
 
 	mutex_lock(&dev->device_lock);
 
 	/* Catch interrupt stalls during HBM init handshake */
 	if (dev->dev_state == MEI_DEV_INIT_CLIENTS &&
 	    dev->hbm_state != MEI_HBM_IDLE) {
 
 		if (dev->init_clients_timer) {
 			if (--dev->init_clients_timer == 0) {
 				dev_err(dev->dev, "timer: init clients timeout hbm_state = %d.\n",
 					dev->hbm_state);
 				mei_reset(dev);
 				goto out;
 			}
 			reschedule_timer = true;
 		}
 	}
 
 	if (dev->dev_state != MEI_DEV_ENABLED)
 		goto out;
 
 	/*** connect/disconnect timeouts ***/
 	list_for_each_entry(cl, &dev->file_list, link) {
 		if (cl->timer_count) {
 			if (--cl->timer_count == 0) {
 				dev_err(dev->dev, "timer: connect/disconnect timeout.\n");
 				mei_connect_timeout(cl);
 				goto out;
 			}
 			reschedule_timer = true;
 		}
 	}
 
 	if (!mei_cl_is_connected(&dev->iamthif_cl))
 		goto out;
 
 	if (dev->iamthif_stall_timer) {
 		if (--dev->iamthif_stall_timer == 0) {
 			dev_err(dev->dev, "timer: amthif  hanged.\n");
 			mei_reset(dev);
 
 			mei_amthif_run_next_cmd(dev);
 			goto out;
 		}
 		reschedule_timer = true;
 	}
 
 out:
 	if (dev->dev_state != MEI_DEV_DISABLED && reschedule_timer)
 		mei_schedule_stall_timer(dev);
 
 	mutex_unlock(&dev->device_lock);
 }
diff --git a/drivers/misc/mei/main.c b/drivers/misc/mei/main.c
index e1bf54481fd6..9d0b7050c79a 100644
--- a/drivers/misc/mei/main.c
+++ b/drivers/misc/mei/main.c
@@ -1,904 +1,908 @@
 /*
  *
  * Intel Management Engine Interface (Intel MEI) Linux driver
  * Copyright (c) 2003-2012, Intel Corporation.
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms and conditions of the GNU General Public License,
  * version 2, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope it will be useful, but WITHOUT
  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
  * more details.
  *
  */
 #include <linux/module.h>
 #include <linux/moduleparam.h>
 #include <linux/kernel.h>
 #include <linux/device.h>
 #include <linux/slab.h>
 #include <linux/fs.h>
 #include <linux/errno.h>
 #include <linux/types.h>
 #include <linux/fcntl.h>
 #include <linux/poll.h>
 #include <linux/init.h>
 #include <linux/ioctl.h>
 #include <linux/cdev.h>
 #include <linux/sched.h>
 #include <linux/uuid.h>
 #include <linux/compat.h>
 #include <linux/jiffies.h>
 #include <linux/interrupt.h>
 
 #include <linux/mei.h>
 
 #include "mei_dev.h"
 #include "client.h"
 
 /**
  * mei_open - the open function
  *
  * @inode: pointer to inode structure
  * @file: pointer to file structure
  *
  * Return: 0 on success, <0 on error
  */
 static int mei_open(struct inode *inode, struct file *file)
 {
 	struct mei_device *dev;
 	struct mei_cl *cl;
 
 	int err;
 
 	dev = container_of(inode->i_cdev, struct mei_device, cdev);
 	if (!dev)
 		return -ENODEV;
 
 	mutex_lock(&dev->device_lock);
 
 	if (dev->dev_state != MEI_DEV_ENABLED) {
 		dev_dbg(dev->dev, "dev_state != MEI_ENABLED  dev_state = %s\n",
 		    mei_dev_state_str(dev->dev_state));
 		err = -ENODEV;
 		goto err_unlock;
 	}
 
 	cl = mei_cl_alloc_linked(dev);
 	if (IS_ERR(cl)) {
 		err = PTR_ERR(cl);
 		goto err_unlock;
 	}
 
 	cl->fp = file;
 	file->private_data = cl;
 
 	mutex_unlock(&dev->device_lock);
 
 	return nonseekable_open(inode, file);
 
 err_unlock:
 	mutex_unlock(&dev->device_lock);
 	return err;
 }
 
 /**
  * mei_release - the release function
  *
  * @inode: pointer to inode structure
  * @file: pointer to file structure
  *
  * Return: 0 on success, <0 on error
  */
 static int mei_release(struct inode *inode, struct file *file)
 {
 	struct mei_cl *cl = file->private_data;
 	struct mei_device *dev;
 	int rets;
 
 	if (WARN_ON(!cl || !cl->dev))
 		return -ENODEV;
 
 	dev = cl->dev;
 
 	mutex_lock(&dev->device_lock);
 	if (cl == &dev->iamthif_cl) {
 		rets = mei_amthif_release(dev, file);
 		goto out;
 	}
 	rets = mei_cl_disconnect(cl);
 
 	mei_cl_flush_queues(cl, file);
 	cl_dbg(dev, cl, "removing\n");
 
 	mei_cl_unlink(cl);
 
 	file->private_data = NULL;
 
 	kfree(cl);
 out:
 	mutex_unlock(&dev->device_lock);
 	return rets;
 }
 
 
 /**
  * mei_read - the read function.
  *
  * @file: pointer to file structure
  * @ubuf: pointer to user buffer
  * @length: buffer length
  * @offset: data offset in buffer
  *
  * Return: >=0 data length on success , <0 on error
  */
 static ssize_t mei_read(struct file *file, char __user *ubuf,
 			size_t length, loff_t *offset)
 {
 	struct mei_cl *cl = file->private_data;
 	struct mei_device *dev;
 	struct mei_cl_cb *cb = NULL;
 	bool nonblock = !!(file->f_flags & O_NONBLOCK);
 	int rets;
 
 	if (WARN_ON(!cl || !cl->dev))
 		return -ENODEV;
 
 	dev = cl->dev;
 
 
 	mutex_lock(&dev->device_lock);
 	if (dev->dev_state != MEI_DEV_ENABLED) {
 		rets = -ENODEV;
 		goto out;
 	}
 
 	if (length == 0) {
 		rets = 0;
 		goto out;
 	}
 
 	if (ubuf == NULL) {
 		rets = -EMSGSIZE;
 		goto out;
 	}
 
 	cb = mei_cl_read_cb(cl, file);
 	if (cb)
 		goto copy_buffer;
 
 	if (*offset > 0)
 		*offset = 0;
 
 	rets = mei_cl_read_start(cl, length, file);
 	if (rets && rets != -EBUSY) {
 		cl_dbg(dev, cl, "mei start read failure status = %d\n", rets);
 		goto out;
 	}
 
 	if (nonblock) {
 		rets = -EAGAIN;
 		goto out;
 	}
 
-	if (rets == -EBUSY &&
-	    !mei_cl_enqueue_ctrl_wr_cb(cl, length, MEI_FOP_READ, file)) {
-		rets = -ENOMEM;
-		goto out;
-	}
 
-	do {
-		mutex_unlock(&dev->device_lock);
-
-		if (wait_event_interruptible(cl->rx_wait,
-					     (!list_empty(&cl->rd_completed)) ||
-					     (!mei_cl_is_connected(cl)))) {
+again:
+	mutex_unlock(&dev->device_lock);
+	if (wait_event_interruptible(cl->rx_wait,
+				     !list_empty(&cl->rd_completed) ||
+				     !mei_cl_is_connected(cl))) {
+		if (signal_pending(current))
+			return -EINTR;
+		return -ERESTARTSYS;
+	}
+	mutex_lock(&dev->device_lock);
 
-			if (signal_pending(current))
-				return -EINTR;
-			return -ERESTARTSYS;
-		}
+	if (!mei_cl_is_connected(cl)) {
+		rets = -ENODEV;
+		goto out;
+	}
 
-		mutex_lock(&dev->device_lock);
-		if (!mei_cl_is_connected(cl)) {
-			rets = -ENODEV;
-			goto out;
-		}
+	cb = mei_cl_read_cb(cl, file);
+	if (!cb) {
+		/*
+		 * For amthif all the waiters are woken up,
+		 * but only fp with matching cb->fp get the cb,
+		 * the others have to return to wait on read.
+		 */
+		if (cl == &dev->iamthif_cl)
+			goto again;
 
-		cb = mei_cl_read_cb(cl, file);
-	} while (!cb);
+		rets = 0;
+		goto out;
+	}
 
 copy_buffer:
 	/* now copy the data to user space */
 	if (cb->status) {
 		rets = cb->status;
 		cl_dbg(dev, cl, "read operation failed %d\n", rets);
 		goto free;
 	}
 
 	cl_dbg(dev, cl, "buf.size = %zu buf.idx = %zu offset = %lld\n",
 	       cb->buf.size, cb->buf_idx, *offset);
 	if (*offset >= cb->buf_idx) {
 		rets = 0;
 		goto free;
 	}
 
 	/* length is being truncated to PAGE_SIZE,
 	 * however buf_idx may point beyond that */
 	length = min_t(size_t, length, cb->buf_idx - *offset);
 
 	if (copy_to_user(ubuf, cb->buf.data + *offset, length)) {
 		dev_dbg(dev->dev, "failed to copy data to userland\n");
 		rets = -EFAULT;
 		goto free;
 	}
 
 	rets = length;
 	*offset += length;
 	/* not all data was read, keep the cb */
 	if (*offset < cb->buf_idx)
 		goto out;
 
 free:
 	mei_io_cb_free(cb);
 	*offset = 0;
 
 out:
 	cl_dbg(dev, cl, "end mei read rets = %d\n", rets);
 	mutex_unlock(&dev->device_lock);
 	return rets;
 }
 /**
  * mei_write - the write function.
  *
  * @file: pointer to file structure
  * @ubuf: pointer to user buffer
  * @length: buffer length
  * @offset: data offset in buffer
  *
  * Return: >=0 data length on success , <0 on error
  */
 static ssize_t mei_write(struct file *file, const char __user *ubuf,
 			 size_t length, loff_t *offset)
 {
 	struct mei_cl *cl = file->private_data;
 	struct mei_cl_cb *cb;
 	struct mei_device *dev;
 	int rets;
 
 	if (WARN_ON(!cl || !cl->dev))
 		return -ENODEV;
 
 	dev = cl->dev;
 
 	mutex_lock(&dev->device_lock);
 
 	if (dev->dev_state != MEI_DEV_ENABLED) {
 		rets = -ENODEV;
 		goto out;
 	}
 
 	if (!mei_cl_is_connected(cl)) {
 		cl_err(dev, cl, "is not connected");
 		rets = -ENODEV;
 		goto out;
 	}
 
 	if (!mei_me_cl_is_active(cl->me_cl)) {
 		rets = -ENOTTY;
 		goto out;
 	}
 
 	if (length > mei_cl_mtu(cl)) {
 		rets = -EFBIG;
 		goto out;
 	}
 
 	if (length == 0) {
 		rets = 0;
 		goto out;
 	}
 
 	*offset = 0;
 	cb = mei_cl_alloc_cb(cl, length, MEI_FOP_WRITE, file);
 	if (!cb) {
 		rets = -ENOMEM;
 		goto out;
 	}
 
 	rets = copy_from_user(cb->buf.data, ubuf, length);
 	if (rets) {
 		dev_dbg(dev->dev, "failed to copy data from userland\n");
 		rets = -EFAULT;
 		mei_io_cb_free(cb);
 		goto out;
 	}
 
 	if (cl == &dev->iamthif_cl) {
 		rets = mei_amthif_write(cl, cb);
 		if (!rets)
 			rets = length;
 		goto out;
 	}
 
 	rets = mei_cl_write(cl, cb);
 out:
 	mutex_unlock(&dev->device_lock);
 	return rets;
 }
 
 /**
  * mei_ioctl_connect_client - the connect to fw client IOCTL function
  *
  * @file: private data of the file object
  * @data: IOCTL connect data, input and output parameters
  *
  * Locking: called under "dev->device_lock" lock
  *
  * Return: 0 on success, <0 on failure.
  */
 static int mei_ioctl_connect_client(struct file *file,
 			struct mei_connect_client_data *data)
 {
 	struct mei_device *dev;
 	struct mei_client *client;
 	struct mei_me_client *me_cl;
 	struct mei_cl *cl;
 	int rets;
 
 	cl = file->private_data;
 	dev = cl->dev;
 
 	if (dev->dev_state != MEI_DEV_ENABLED)
 		return -ENODEV;
 
 	if (cl->state != MEI_FILE_INITIALIZING &&
 	    cl->state != MEI_FILE_DISCONNECTED)
 		return  -EBUSY;
 
 	/* find ME client we're trying to connect to */
 	me_cl = mei_me_cl_by_uuid(dev, &data->in_client_uuid);
 	if (!me_cl) {
 		dev_dbg(dev->dev, "Cannot connect to FW Client UUID = %pUl\n",
 			&data->in_client_uuid);
 		rets = -ENOTTY;
 		goto end;
 	}
 
 	if (me_cl->props.fixed_address) {
 		bool forbidden = dev->override_fixed_address ?
 			 !dev->allow_fixed_address : !dev->hbm_f_fa_supported;
 		if (forbidden) {
 			dev_dbg(dev->dev, "Connection forbidden to FW Client UUID = %pUl\n",
 				&data->in_client_uuid);
 			rets = -ENOTTY;
 			goto end;
 		}
 	}
 
 	dev_dbg(dev->dev, "Connect to FW Client ID = %d\n",
 			me_cl->client_id);
 	dev_dbg(dev->dev, "FW Client - Protocol Version = %d\n",
 			me_cl->props.protocol_version);
 	dev_dbg(dev->dev, "FW Client - Max Msg Len = %d\n",
 			me_cl->props.max_msg_length);
 
 	/* if we're connecting to amthif client then we will use the
 	 * existing connection
 	 */
 	if (uuid_le_cmp(data->in_client_uuid, mei_amthif_guid) == 0) {
 		dev_dbg(dev->dev, "FW Client is amthi\n");
 		if (!mei_cl_is_connected(&dev->iamthif_cl)) {
 			rets = -ENODEV;
 			goto end;
 		}
 		mei_cl_unlink(cl);
 
 		kfree(cl);
 		cl = NULL;
 		dev->iamthif_open_count++;
 		file->private_data = &dev->iamthif_cl;
 
 		client = &data->out_client_properties;
 		client->max_msg_length = me_cl->props.max_msg_length;
 		client->protocol_version = me_cl->props.protocol_version;
 		rets = dev->iamthif_cl.status;
 
 		goto end;
 	}
 
 	/* prepare the output buffer */
 	client = &data->out_client_properties;
 	client->max_msg_length = me_cl->props.max_msg_length;
 	client->protocol_version = me_cl->props.protocol_version;
 	dev_dbg(dev->dev, "Can connect?\n");
 
 	rets = mei_cl_connect(cl, me_cl, file);
 
 end:
 	mei_me_cl_put(me_cl);
 	return rets;
 }
 
 /**
  * mei_ioctl_client_notify_request -
  *     propagate event notification request to client
  *
  * @file: pointer to file structure
  * @request: 0 - disable, 1 - enable
  *
  * Return: 0 on success , <0 on error
  */
 static int mei_ioctl_client_notify_request(const struct file *file, u32 request)
 {
 	struct mei_cl *cl = file->private_data;
 
 	if (request != MEI_HBM_NOTIFICATION_START &&
 	    request != MEI_HBM_NOTIFICATION_STOP)
 		return -EINVAL;
 
 	return mei_cl_notify_request(cl, file, (u8)request);
 }
 
 /**
  * mei_ioctl_client_notify_get -  wait for notification request
  *
  * @file: pointer to file structure
  * @notify_get: 0 - disable, 1 - enable
  *
  * Return: 0 on success , <0 on error
  */
 static int mei_ioctl_client_notify_get(const struct file *file, u32 *notify_get)
 {
 	struct mei_cl *cl = file->private_data;
 	bool notify_ev;
 	bool block = (file->f_flags & O_NONBLOCK) == 0;
 	int rets;
 
 	rets = mei_cl_notify_get(cl, block, &notify_ev);
 	if (rets)
 		return rets;
 
 	*notify_get = notify_ev ? 1 : 0;
 	return 0;
 }
 
 /**
  * mei_ioctl - the IOCTL function
  *
  * @file: pointer to file structure
  * @cmd: ioctl command
  * @data: pointer to mei message structure
  *
  * Return: 0 on success , <0 on error
  */
 static long mei_ioctl(struct file *file, unsigned int cmd, unsigned long data)
 {
 	struct mei_device *dev;
 	struct mei_cl *cl = file->private_data;
 	struct mei_connect_client_data connect_data;
 	u32 notify_get, notify_req;
 	int rets;
 
 
 	if (WARN_ON(!cl || !cl->dev))
 		return -ENODEV;
 
 	dev = cl->dev;
 
 	dev_dbg(dev->dev, "IOCTL cmd = 0x%x", cmd);
 
 	mutex_lock(&dev->device_lock);
 	if (dev->dev_state != MEI_DEV_ENABLED) {
 		rets = -ENODEV;
 		goto out;
 	}
 
 	switch (cmd) {
 	case IOCTL_MEI_CONNECT_CLIENT:
 		dev_dbg(dev->dev, ": IOCTL_MEI_CONNECT_CLIENT.\n");
 		if (copy_from_user(&connect_data, (char __user *)data,
 				sizeof(struct mei_connect_client_data))) {
 			dev_dbg(dev->dev, "failed to copy data from userland\n");
 			rets = -EFAULT;
 			goto out;
 		}
 
 		rets = mei_ioctl_connect_client(file, &connect_data);
 		if (rets)
 			goto out;
 
 		/* if all is ok, copying the data back to user. */
 		if (copy_to_user((char __user *)data, &connect_data,
 				sizeof(struct mei_connect_client_data))) {
 			dev_dbg(dev->dev, "failed to copy data to userland\n");
 			rets = -EFAULT;
 			goto out;
 		}
 
 		break;
 
 	case IOCTL_MEI_NOTIFY_SET:
 		dev_dbg(dev->dev, ": IOCTL_MEI_NOTIFY_SET.\n");
 		if (copy_from_user(&notify_req,
 				   (char __user *)data, sizeof(notify_req))) {
 			dev_dbg(dev->dev, "failed to copy data from userland\n");
 			rets = -EFAULT;
 			goto out;
 		}
 		rets = mei_ioctl_client_notify_request(file, notify_req);
 		break;
 
 	case IOCTL_MEI_NOTIFY_GET:
 		dev_dbg(dev->dev, ": IOCTL_MEI_NOTIFY_GET.\n");
 		rets = mei_ioctl_client_notify_get(file, &notify_get);
 		if (rets)
 			goto out;
 
 		dev_dbg(dev->dev, "copy connect data to user\n");
 		if (copy_to_user((char __user *)data,
 				&notify_get, sizeof(notify_get))) {
 			dev_dbg(dev->dev, "failed to copy data to userland\n");
 			rets = -EFAULT;
 			goto out;
 
 		}
 		break;
 
 	default:
 		dev_err(dev->dev, ": unsupported ioctl %d.\n", cmd);
 		rets = -ENOIOCTLCMD;
 	}
 
 out:
 	mutex_unlock(&dev->device_lock);
 	return rets;
 }
 
 /**
  * mei_compat_ioctl - the compat IOCTL function
  *
  * @file: pointer to file structure
  * @cmd: ioctl command
  * @data: pointer to mei message structure
  *
  * Return: 0 on success , <0 on error
  */
 #ifdef CONFIG_COMPAT
 static long mei_compat_ioctl(struct file *file,
 			unsigned int cmd, unsigned long data)
 {
 	return mei_ioctl(file, cmd, (unsigned long)compat_ptr(data));
 }
 #endif
 
 
 /**
  * mei_poll - the poll function
  *
  * @file: pointer to file structure
  * @wait: pointer to poll_table structure
  *
  * Return: poll mask
  */
 static unsigned int mei_poll(struct file *file, poll_table *wait)
 {
 	unsigned long req_events = poll_requested_events(wait);
 	struct mei_cl *cl = file->private_data;
 	struct mei_device *dev;
 	unsigned int mask = 0;
 	bool notify_en;
 
 	if (WARN_ON(!cl || !cl->dev))
 		return POLLERR;
 
 	dev = cl->dev;
 
 	mutex_lock(&dev->device_lock);
 
 	notify_en = cl->notify_en && (req_events & POLLPRI);
 
 	if (dev->dev_state != MEI_DEV_ENABLED ||
 	    !mei_cl_is_connected(cl)) {
 		mask = POLLERR;
 		goto out;
 	}
 
 	if (notify_en) {
 		poll_wait(file, &cl->ev_wait, wait);
 		if (cl->notify_ev)
 			mask |= POLLPRI;
 	}
 
 	if (cl == &dev->iamthif_cl) {
 		mask |= mei_amthif_poll(file, wait);
 		goto out;
 	}
 
 	if (req_events & (POLLIN | POLLRDNORM)) {
 		poll_wait(file, &cl->rx_wait, wait);
 
 		if (!list_empty(&cl->rd_completed))
 			mask |= POLLIN | POLLRDNORM;
 		else
 			mei_cl_read_start(cl, mei_cl_mtu(cl), file);
 	}
 
 out:
 	mutex_unlock(&dev->device_lock);
 	return mask;
 }
 
 /**
  * mei_fasync - asynchronous io support
  *
  * @fd: file descriptor
  * @file: pointer to file structure
  * @band: band bitmap
  *
  * Return: negative on error,
  *         0 if it did no changes,
  *         and positive a process was added or deleted
  */
 static int mei_fasync(int fd, struct file *file, int band)
 {
 
 	struct mei_cl *cl = file->private_data;
 
 	if (!mei_cl_is_connected(cl))
 		return -ENODEV;
 
 	return fasync_helper(fd, file, band, &cl->ev_async);
 }
 
 /**
  * fw_status_show - mei device fw_status attribute show method
  *
  * @device: device pointer
  * @attr: attribute pointer
  * @buf:  char out buffer
  *
  * Return: number of the bytes printed into buf or error
  */
 static ssize_t fw_status_show(struct device *device,
 		struct device_attribute *attr, char *buf)
 {
 	struct mei_device *dev = dev_get_drvdata(device);
 	struct mei_fw_status fw_status;
 	int err, i;
 	ssize_t cnt = 0;
 
 	mutex_lock(&dev->device_lock);
 	err = mei_fw_status(dev, &fw_status);
 	mutex_unlock(&dev->device_lock);
 	if (err) {
 		dev_err(device, "read fw_status error = %d\n", err);
 		return err;
 	}
 
 	for (i = 0; i < fw_status.count; i++)
 		cnt += scnprintf(buf + cnt, PAGE_SIZE - cnt, "%08X\n",
 				fw_status.status[i]);
 	return cnt;
 }
 static DEVICE_ATTR_RO(fw_status);
 
 /**
  * hbm_ver_show - display HBM protocol version negotiated with FW
  *
  * @device: device pointer
  * @attr: attribute pointer
  * @buf:  char out buffer
  *
  * Return: number of the bytes printed into buf or error
  */
 static ssize_t hbm_ver_show(struct device *device,
 			    struct device_attribute *attr, char *buf)
 {
 	struct mei_device *dev = dev_get_drvdata(device);
 	struct hbm_version ver;
 
 	mutex_lock(&dev->device_lock);
 	ver = dev->version;
 	mutex_unlock(&dev->device_lock);
 
 	return sprintf(buf, "%u.%u\n", ver.major_version, ver.minor_version);
 }
 static DEVICE_ATTR_RO(hbm_ver);
 
 /**
  * hbm_ver_drv_show - display HBM protocol version advertised by driver
  *
  * @device: device pointer
  * @attr: attribute pointer
  * @buf:  char out buffer
  *
  * Return: number of the bytes printed into buf or error
  */
 static ssize_t hbm_ver_drv_show(struct device *device,
 				struct device_attribute *attr, char *buf)
 {
 	return sprintf(buf, "%u.%u\n", HBM_MAJOR_VERSION, HBM_MINOR_VERSION);
 }
 static DEVICE_ATTR_RO(hbm_ver_drv);
 
 static struct attribute *mei_attrs[] = {
 	&dev_attr_fw_status.attr,
 	&dev_attr_hbm_ver.attr,
 	&dev_attr_hbm_ver_drv.attr,
 	NULL
 };
 ATTRIBUTE_GROUPS(mei);
 
 /*
  * file operations structure will be used for mei char device.
  */
 static const struct file_operations mei_fops = {
 	.owner = THIS_MODULE,
 	.read = mei_read,
 	.unlocked_ioctl = mei_ioctl,
 #ifdef CONFIG_COMPAT
 	.compat_ioctl = mei_compat_ioctl,
 #endif
 	.open = mei_open,
 	.release = mei_release,
 	.write = mei_write,
 	.poll = mei_poll,
 	.fasync = mei_fasync,
 	.llseek = no_llseek
 };
 
 static struct class *mei_class;
 static dev_t mei_devt;
 #define MEI_MAX_DEVS  MINORMASK
 static DEFINE_MUTEX(mei_minor_lock);
 static DEFINE_IDR(mei_idr);
 
 /**
  * mei_minor_get - obtain next free device minor number
  *
  * @dev:  device pointer
  *
  * Return: allocated minor, or -ENOSPC if no free minor left
  */
 static int mei_minor_get(struct mei_device *dev)
 {
 	int ret;
 
 	mutex_lock(&mei_minor_lock);
 	ret = idr_alloc(&mei_idr, dev, 0, MEI_MAX_DEVS, GFP_KERNEL);
 	if (ret >= 0)
 		dev->minor = ret;
 	else if (ret == -ENOSPC)
 		dev_err(dev->dev, "too many mei devices\n");
 
 	mutex_unlock(&mei_minor_lock);
 	return ret;
 }
 
 /**
  * mei_minor_free - mark device minor number as free
  *
  * @dev:  device pointer
  */
 static void mei_minor_free(struct mei_device *dev)
 {
 	mutex_lock(&mei_minor_lock);
 	idr_remove(&mei_idr, dev->minor);
 	mutex_unlock(&mei_minor_lock);
 }
 
 int mei_register(struct mei_device *dev, struct device *parent)
 {
 	struct device *clsdev; /* class device */
 	int ret, devno;
 
 	ret = mei_minor_get(dev);
 	if (ret < 0)
 		return ret;
 
 	/* Fill in the data structures */
 	devno = MKDEV(MAJOR(mei_devt), dev->minor);
 	cdev_init(&dev->cdev, &mei_fops);
 	dev->cdev.owner = parent->driver->owner;
 
 	/* Add the device */
 	ret = cdev_add(&dev->cdev, devno, 1);
 	if (ret) {
 		dev_err(parent, "unable to add device %d:%d\n",
 			MAJOR(mei_devt), dev->minor);
 		goto err_dev_add;
 	}
 
 	clsdev = device_create_with_groups(mei_class, parent, devno,
 					   dev, mei_groups,
 					   "mei%d", dev->minor);
 
 	if (IS_ERR(clsdev)) {
 		dev_err(parent, "unable to create device %d:%d\n",
 			MAJOR(mei_devt), dev->minor);
 		ret = PTR_ERR(clsdev);
 		goto err_dev_create;
 	}
 
 	ret = mei_dbgfs_register(dev, dev_name(clsdev));
 	if (ret) {
 		dev_err(clsdev, "cannot register debugfs ret = %d\n", ret);
 		goto err_dev_dbgfs;
 	}
 
 	return 0;
 
 err_dev_dbgfs:
 	device_destroy(mei_class, devno);
 err_dev_create:
 	cdev_del(&dev->cdev);
 err_dev_add:
 	mei_minor_free(dev);
 	return ret;
 }
 EXPORT_SYMBOL_GPL(mei_register);
 
 void mei_deregister(struct mei_device *dev)
 {
 	int devno;
 
 	devno = dev->cdev.dev;
 	cdev_del(&dev->cdev);
 
 	mei_dbgfs_deregister(dev);
 
 	device_destroy(mei_class, devno);
 
 	mei_minor_free(dev);
 }
 EXPORT_SYMBOL_GPL(mei_deregister);
 
 static int __init mei_init(void)
 {
 	int ret;
 
 	mei_class = class_create(THIS_MODULE, "mei");
 	if (IS_ERR(mei_class)) {
 		pr_err("couldn't create class\n");
 		ret = PTR_ERR(mei_class);
 		goto err;
 	}
 
 	ret = alloc_chrdev_region(&mei_devt, 0, MEI_MAX_DEVS, "mei");
 	if (ret < 0) {
 		pr_err("unable to allocate char dev region\n");
 		goto err_class;
 	}
 
 	ret = mei_cl_bus_init();
 	if (ret < 0) {
 		pr_err("unable to initialize bus\n");
 		goto err_chrdev;
 	}
 
 	return 0;
 
 err_chrdev:
 	unregister_chrdev_region(mei_devt, MEI_MAX_DEVS);
 err_class:
 	class_destroy(mei_class);
 err:
 	return ret;
 }
 
 static void __exit mei_exit(void)
 {
 	unregister_chrdev_region(mei_devt, MEI_MAX_DEVS);
 	class_destroy(mei_class);
 	mei_cl_bus_exit();
 }
 
 module_init(mei_init);
 module_exit(mei_exit);
 
 MODULE_AUTHOR("Intel Corporation");
 MODULE_DESCRIPTION("Intel(R) Management Engine Interface");
 MODULE_LICENSE("GPL v2");
 
diff --git a/drivers/misc/mei/mei_dev.h b/drivers/misc/mei/mei_dev.h
index 8dadb98662a9..d41aac53a2ac 100644
--- a/drivers/misc/mei/mei_dev.h
+++ b/drivers/misc/mei/mei_dev.h
@@ -1,761 +1,763 @@
 /*
  *
  * Intel Management Engine Interface (Intel MEI) Linux driver
  * Copyright (c) 2003-2012, Intel Corporation.
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms and conditions of the GNU General Public License,
  * version 2, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope it will be useful, but WITHOUT
  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
  * more details.
  *
  */
 
 #ifndef _MEI_DEV_H_
 #define _MEI_DEV_H_
 
 #include <linux/types.h>
 #include <linux/cdev.h>
 #include <linux/poll.h>
 #include <linux/mei.h>
 #include <linux/mei_cl_bus.h>
 
 #include "hw.h"
 #include "hbm.h"
 
 
 /*
  * AMTHI Client UUID
  */
 extern const uuid_le mei_amthif_guid;
 
 #define MEI_RD_MSG_BUF_SIZE           (128 * sizeof(u32))
 
 /*
  * Number of Maximum MEI Clients
  */
 #define MEI_CLIENTS_MAX 256
 
 /*
  * maximum number of consecutive resets
  */
 #define MEI_MAX_CONSEC_RESET  3
 
 /*
  * Number of File descriptors/handles
  * that can be opened to the driver.
  *
  * Limit to 255: 256 Total Clients
  * minus internal client for MEI Bus Messages
  */
 #define  MEI_MAX_OPEN_HANDLE_COUNT (MEI_CLIENTS_MAX - 1)
 
 /* File state */
 enum file_state {
 	MEI_FILE_UNINITIALIZED = 0,
 	MEI_FILE_INITIALIZING,
 	MEI_FILE_CONNECTING,
 	MEI_FILE_CONNECTED,
 	MEI_FILE_DISCONNECTING,
 	MEI_FILE_DISCONNECT_REPLY,
 	MEI_FILE_DISCONNECT_REQUIRED,
 	MEI_FILE_DISCONNECTED,
 };
 
 /* MEI device states */
 enum mei_dev_state {
 	MEI_DEV_INITIALIZING = 0,
 	MEI_DEV_INIT_CLIENTS,
 	MEI_DEV_ENABLED,
 	MEI_DEV_RESETTING,
 	MEI_DEV_DISABLED,
 	MEI_DEV_POWER_DOWN,
 	MEI_DEV_POWER_UP
 };
 
 const char *mei_dev_state_str(int state);
 
 enum iamthif_states {
 	MEI_IAMTHIF_IDLE,
 	MEI_IAMTHIF_WRITING,
 	MEI_IAMTHIF_READING,
 };
 
 enum mei_file_transaction_states {
 	MEI_IDLE,
 	MEI_WRITING,
 	MEI_WRITE_COMPLETE,
 };
 
 /**
  * enum mei_cb_file_ops  - file operation associated with the callback
  * @MEI_FOP_READ:       read
  * @MEI_FOP_WRITE:      write
  * @MEI_FOP_CONNECT:    connect
  * @MEI_FOP_DISCONNECT: disconnect
  * @MEI_FOP_DISCONNECT_RSP: disconnect response
  * @MEI_FOP_NOTIFY_START:   start notification
  * @MEI_FOP_NOTIFY_STOP:    stop notification
  */
 enum mei_cb_file_ops {
 	MEI_FOP_READ = 0,
 	MEI_FOP_WRITE,
 	MEI_FOP_CONNECT,
 	MEI_FOP_DISCONNECT,
 	MEI_FOP_DISCONNECT_RSP,
 	MEI_FOP_NOTIFY_START,
 	MEI_FOP_NOTIFY_STOP,
 };
 
 /**
  * enum mei_cl_io_mode - io mode between driver and fw
  *
  * @MEI_CL_IO_TX_BLOCKING: send is blocking
  * @MEI_CL_IO_TX_INTERNAL: internal communication between driver and FW
  *
  * @MEI_CL_IO_RX_NONBLOCK: recv is non-blocking
  */
 enum mei_cl_io_mode {
 	MEI_CL_IO_TX_BLOCKING = BIT(0),
 	MEI_CL_IO_TX_INTERNAL = BIT(1),
 
 	MEI_CL_IO_RX_NONBLOCK = BIT(2),
 };
 
 /*
  * Intel MEI message data struct
  */
 struct mei_msg_data {
 	size_t size;
 	unsigned char *data;
 };
 
 /* Maximum number of processed FW status registers */
 #define MEI_FW_STATUS_MAX 6
 /* Minimal  buffer for FW status string (8 bytes in dw + space or '\0') */
 #define MEI_FW_STATUS_STR_SZ (MEI_FW_STATUS_MAX * (8 + 1))
 
 
 /*
  * struct mei_fw_status - storage of FW status data
  *
  * @count: number of actually available elements in array
  * @status: FW status registers
  */
 struct mei_fw_status {
 	int count;
 	u32 status[MEI_FW_STATUS_MAX];
 };
 
 /**
  * struct mei_me_client - representation of me (fw) client
  *
  * @list: link in me client list
  * @refcnt: struct reference count
  * @props: client properties
  * @client_id: me client id
  * @tx_flow_ctrl_creds: flow control credits
  * @connect_count: number connections to this client
  * @bus_added: added to bus
  */
 struct mei_me_client {
 	struct list_head list;
 	struct kref refcnt;
 	struct mei_client_properties props;
 	u8 client_id;
 	u8 tx_flow_ctrl_creds;
 	u8 connect_count;
 	u8 bus_added;
 };
 
 
 struct mei_cl;
 
 /**
  * struct mei_cl_cb - file operation callback structure
  *
  * @list: link in callback queue
  * @cl: file client who is running this operation
  * @fop_type: file operation type
  * @buf: buffer for data associated with the callback
  * @buf_idx: last read index
  * @fp: pointer to file structure
  * @status: io status of the cb
  * @internal: communication between driver and FW flag
  * @blocking: transmission blocking mode
  * @completed: the transfer or reception has completed
  */
 struct mei_cl_cb {
 	struct list_head list;
 	struct mei_cl *cl;
 	enum mei_cb_file_ops fop_type;
 	struct mei_msg_data buf;
 	size_t buf_idx;
 	const struct file *fp;
 	int status;
 	u32 internal:1;
 	u32 blocking:1;
 	u32 completed:1;
 };
 
 /**
  * struct mei_cl - me client host representation
  *    carried in file->private_data
  *
  * @link: link in the clients list
  * @dev: mei parent device
  * @state: file operation state
  * @tx_wait: wait queue for tx completion
  * @rx_wait: wait queue for rx completion
  * @wait:  wait queue for management operation
  * @ev_wait: notification wait queue
  * @ev_async: event async notification
  * @status: connection status
  * @me_cl: fw client connected
  * @fp: file associated with client
  * @host_client_id: host id
  * @tx_flow_ctrl_creds: transmit flow credentials
  * @rx_flow_ctrl_creds: receive flow credentials
  * @timer_count:  watchdog timer for operation completion
  * @notify_en: notification - enabled/disabled
  * @notify_ev: pending notification event
  * @writing_state: state of the tx
  * @rd_pending: pending read credits
  * @rd_completed: completed read
  *
  * @cldev: device on the mei client bus
  */
 struct mei_cl {
 	struct list_head link;
 	struct mei_device *dev;
 	enum file_state state;
 	wait_queue_head_t tx_wait;
 	wait_queue_head_t rx_wait;
 	wait_queue_head_t wait;
 	wait_queue_head_t ev_wait;
 	struct fasync_struct *ev_async;
 	int status;
 	struct mei_me_client *me_cl;
 	const struct file *fp;
 	u8 host_client_id;
 	u8 tx_flow_ctrl_creds;
 	u8 rx_flow_ctrl_creds;
 	u8 timer_count;
 	u8 notify_en;
 	u8 notify_ev;
 	enum mei_file_transaction_states writing_state;
 	struct list_head rd_pending;
 	struct list_head rd_completed;
 
 	struct mei_cl_device *cldev;
 };
 
 /**
  * struct mei_hw_ops - hw specific ops
  *
  * @host_is_ready    : query for host readiness
  *
  * @hw_is_ready      : query if hw is ready
  * @hw_reset         : reset hw
  * @hw_start         : start hw after reset
  * @hw_config        : configure hw
  *
  * @fw_status        : get fw status registers
  * @pg_state         : power gating state of the device
  * @pg_in_transition : is device now in pg transition
  * @pg_is_enabled    : is power gating enabled
  *
  * @intr_clear       : clear pending interrupts
  * @intr_enable      : enable interrupts
  * @intr_disable     : disable interrupts
  * @synchronize_irq  : synchronize irqs
  *
  * @hbuf_free_slots  : query for write buffer empty slots
  * @hbuf_is_ready    : query if write buffer is empty
  * @hbuf_max_len     : query for write buffer max len
  *
  * @write            : write a message to FW
  *
  * @rdbuf_full_slots : query how many slots are filled
  *
  * @read_hdr         : get first 4 bytes (header)
  * @read             : read a buffer from the FW
  */
 struct mei_hw_ops {
 
 	bool (*host_is_ready)(struct mei_device *dev);
 
 	bool (*hw_is_ready)(struct mei_device *dev);
 	int (*hw_reset)(struct mei_device *dev, bool enable);
 	int (*hw_start)(struct mei_device *dev);
 	void (*hw_config)(struct mei_device *dev);
 
 	int (*fw_status)(struct mei_device *dev, struct mei_fw_status *fw_sts);
 	enum mei_pg_state (*pg_state)(struct mei_device *dev);
 	bool (*pg_in_transition)(struct mei_device *dev);
 	bool (*pg_is_enabled)(struct mei_device *dev);
 
 	void (*intr_clear)(struct mei_device *dev);
 	void (*intr_enable)(struct mei_device *dev);
 	void (*intr_disable)(struct mei_device *dev);
 	void (*synchronize_irq)(struct mei_device *dev);
 
 	int (*hbuf_free_slots)(struct mei_device *dev);
 	bool (*hbuf_is_ready)(struct mei_device *dev);
 	size_t (*hbuf_max_len)(const struct mei_device *dev);
 	int (*write)(struct mei_device *dev,
 		     struct mei_msg_hdr *hdr,
 		     const unsigned char *buf);
 
 	int (*rdbuf_full_slots)(struct mei_device *dev);
 
 	u32 (*read_hdr)(const struct mei_device *dev);
 	int (*read)(struct mei_device *dev,
 		     unsigned char *buf, unsigned long len);
 };
 
 /* MEI bus API*/
 void mei_cl_bus_rescan(struct mei_device *bus);
 void mei_cl_bus_rescan_work(struct work_struct *work);
 void mei_cl_bus_dev_fixup(struct mei_cl_device *dev);
 ssize_t __mei_cl_send(struct mei_cl *cl, u8 *buf, size_t length,
 		      unsigned int mode);
 ssize_t __mei_cl_recv(struct mei_cl *cl, u8 *buf, size_t length,
 		      unsigned int mode);
 bool mei_cl_bus_rx_event(struct mei_cl *cl);
 bool mei_cl_bus_notify_event(struct mei_cl *cl);
 void mei_cl_bus_remove_devices(struct mei_device *bus);
+bool mei_cl_bus_module_get(struct mei_cl *cl);
+void mei_cl_bus_module_put(struct mei_cl *cl);
 int mei_cl_bus_init(void);
 void mei_cl_bus_exit(void);
 
 /**
  * enum mei_pg_event - power gating transition events
  *
  * @MEI_PG_EVENT_IDLE: the driver is not in power gating transition
  * @MEI_PG_EVENT_WAIT: the driver is waiting for a pg event to complete
  * @MEI_PG_EVENT_RECEIVED: the driver received pg event
  * @MEI_PG_EVENT_INTR_WAIT: the driver is waiting for a pg event interrupt
  * @MEI_PG_EVENT_INTR_RECEIVED: the driver received pg event interrupt
  */
 enum mei_pg_event {
 	MEI_PG_EVENT_IDLE,
 	MEI_PG_EVENT_WAIT,
 	MEI_PG_EVENT_RECEIVED,
 	MEI_PG_EVENT_INTR_WAIT,
 	MEI_PG_EVENT_INTR_RECEIVED,
 };
 
 /**
  * enum mei_pg_state - device internal power gating state
  *
  * @MEI_PG_OFF: device is not power gated - it is active
  * @MEI_PG_ON:  device is power gated - it is in lower power state
  */
 enum mei_pg_state {
 	MEI_PG_OFF = 0,
 	MEI_PG_ON =  1,
 };
 
 const char *mei_pg_state_str(enum mei_pg_state state);
 
 /**
  * struct mei_device -  MEI private device struct
  *
  * @dev         : device on a bus
  * @cdev        : character device
  * @minor       : minor number allocated for device
  *
  * @write_list  : write pending list
  * @write_waiting_list : write completion list
  * @ctrl_wr_list : pending control write list
  * @ctrl_rd_list : pending control read list
  *
  * @file_list   : list of opened handles
  * @open_handle_count: number of opened handles
  *
  * @device_lock : big device lock
  * @timer_work  : MEI timer delayed work (timeouts)
  *
  * @recvd_hw_ready : hw ready message received flag
  *
  * @wait_hw_ready : wait queue for receive HW ready message form FW
  * @wait_pg     : wait queue for receive PG message from FW
  * @wait_hbm_start : wait queue for receive HBM start message from FW
  *
  * @reset_count : number of consecutive resets
  * @dev_state   : device state
  * @hbm_state   : state of host bus message protocol
  * @init_clients_timer : HBM init handshake timeout
  *
  * @pg_event    : power gating event
  * @pg_domain   : runtime PM domain
  *
  * @rd_msg_buf  : control messages buffer
  * @rd_msg_hdr  : read message header storage
  *
  * @hbuf_depth  : depth of hardware host/write buffer is slots
  * @hbuf_is_ready : query if the host host/write buffer is ready
  *
  * @version     : HBM protocol version in use
  * @hbm_f_pg_supported  : hbm feature pgi protocol
  * @hbm_f_dc_supported  : hbm feature dynamic clients
  * @hbm_f_dot_supported : hbm feature disconnect on timeout
  * @hbm_f_ev_supported  : hbm feature event notification
  * @hbm_f_fa_supported  : hbm feature fixed address client
  * @hbm_f_ie_supported  : hbm feature immediate reply to enum request
  * @hbm_f_os_supported  : hbm feature support OS ver message
  *
  * @me_clients_rwsem: rw lock over me_clients list
  * @me_clients  : list of FW clients
  * @me_clients_map : FW clients bit map
  * @host_clients_map : host clients id pool
  *
  * @allow_fixed_address: allow user space to connect a fixed client
  * @override_fixed_address: force allow fixed address behavior
  *
  * @amthif_cmd_list : amthif list for cmd waiting
  * @iamthif_cl  : amthif host client
  * @iamthif_open_count : number of opened amthif connections
  * @iamthif_stall_timer : timer to detect amthif hang
  * @iamthif_state : amthif processor state
  * @iamthif_canceled : current amthif command is canceled
  *
  * @reset_work  : work item for the device reset
  * @bus_rescan_work : work item for the bus rescan
  *
  * @device_list : mei client bus list
  * @cl_bus_lock : client bus list lock
  *
  * @dbgfs_dir   : debugfs mei root directory
  *
  * @ops:        : hw specific operations
  * @hw          : hw specific data
  */
 struct mei_device {
 	struct device *dev;
 	struct cdev cdev;
 	int minor;
 
-	struct mei_cl_cb write_list;
-	struct mei_cl_cb write_waiting_list;
-	struct mei_cl_cb ctrl_wr_list;
-	struct mei_cl_cb ctrl_rd_list;
+	struct list_head write_list;
+	struct list_head write_waiting_list;
+	struct list_head ctrl_wr_list;
+	struct list_head ctrl_rd_list;
 
 	struct list_head file_list;
 	long open_handle_count;
 
 	struct mutex device_lock;
 	struct delayed_work timer_work;
 
 	bool recvd_hw_ready;
 	/*
 	 * waiting queue for receive message from FW
 	 */
 	wait_queue_head_t wait_hw_ready;
 	wait_queue_head_t wait_pg;
 	wait_queue_head_t wait_hbm_start;
 
 	/*
 	 * mei device  states
 	 */
 	unsigned long reset_count;
 	enum mei_dev_state dev_state;
 	enum mei_hbm_state hbm_state;
 	u16 init_clients_timer;
 
 	/*
 	 * Power Gating support
 	 */
 	enum mei_pg_event pg_event;
 #ifdef CONFIG_PM
 	struct dev_pm_domain pg_domain;
 #endif /* CONFIG_PM */
 
 	unsigned char rd_msg_buf[MEI_RD_MSG_BUF_SIZE];
 	u32 rd_msg_hdr;
 
 	/* write buffer */
 	u8 hbuf_depth;
 	bool hbuf_is_ready;
 
 	struct hbm_version version;
 	unsigned int hbm_f_pg_supported:1;
 	unsigned int hbm_f_dc_supported:1;
 	unsigned int hbm_f_dot_supported:1;
 	unsigned int hbm_f_ev_supported:1;
 	unsigned int hbm_f_fa_supported:1;
 	unsigned int hbm_f_ie_supported:1;
 	unsigned int hbm_f_os_supported:1;
 
 	struct rw_semaphore me_clients_rwsem;
 	struct list_head me_clients;
 	DECLARE_BITMAP(me_clients_map, MEI_CLIENTS_MAX);
 	DECLARE_BITMAP(host_clients_map, MEI_CLIENTS_MAX);
 
 	bool allow_fixed_address;
 	bool override_fixed_address;
 
 	/* amthif list for cmd waiting */
-	struct mei_cl_cb amthif_cmd_list;
+	struct list_head amthif_cmd_list;
 	struct mei_cl iamthif_cl;
 	long iamthif_open_count;
 	u32 iamthif_stall_timer;
 	enum iamthif_states iamthif_state;
 	bool iamthif_canceled;
 
 	struct work_struct reset_work;
 	struct work_struct bus_rescan_work;
 
 	/* List of bus devices */
 	struct list_head device_list;
 	struct mutex cl_bus_lock;
 
 #if IS_ENABLED(CONFIG_DEBUG_FS)
 	struct dentry *dbgfs_dir;
 #endif /* CONFIG_DEBUG_FS */
 
 
 	const struct mei_hw_ops *ops;
 	char hw[0] __aligned(sizeof(void *));
 };
 
 static inline unsigned long mei_secs_to_jiffies(unsigned long sec)
 {
 	return msecs_to_jiffies(sec * MSEC_PER_SEC);
 }
 
 /**
  * mei_data2slots - get slots - number of (dwords) from a message length
  *	+ size of the mei header
  *
  * @length: size of the messages in bytes
  *
  * Return: number of slots
  */
 static inline u32 mei_data2slots(size_t length)
 {
 	return DIV_ROUND_UP(sizeof(struct mei_msg_hdr) + length, 4);
 }
 
 /**
  * mei_slots2data - get data in slots - bytes from slots
  *
  * @slots: number of available slots
  *
  * Return: number of bytes in slots
  */
 static inline u32 mei_slots2data(int slots)
 {
 	return slots * 4;
 }
 
 /*
  * mei init function prototypes
  */
 void mei_device_init(struct mei_device *dev,
 		     struct device *device,
 		     const struct mei_hw_ops *hw_ops);
 int mei_reset(struct mei_device *dev);
 int mei_start(struct mei_device *dev);
 int mei_restart(struct mei_device *dev);
 void mei_stop(struct mei_device *dev);
 void mei_cancel_work(struct mei_device *dev);
 
 /*
  *  MEI interrupt functions prototype
  */
 
 void mei_timer(struct work_struct *work);
 void mei_schedule_stall_timer(struct mei_device *dev);
 int mei_irq_read_handler(struct mei_device *dev,
-		struct mei_cl_cb *cmpl_list, s32 *slots);
+			 struct list_head *cmpl_list, s32 *slots);
 
-int mei_irq_write_handler(struct mei_device *dev, struct mei_cl_cb *cmpl_list);
-void mei_irq_compl_handler(struct mei_device *dev, struct mei_cl_cb *cmpl_list);
+int mei_irq_write_handler(struct mei_device *dev, struct list_head *cmpl_list);
+void mei_irq_compl_handler(struct mei_device *dev, struct list_head *cmpl_list);
 
 /*
  * AMTHIF - AMT Host Interface Functions
  */
 void mei_amthif_reset_params(struct mei_device *dev);
 
 int mei_amthif_host_init(struct mei_device *dev, struct mei_me_client *me_cl);
 
 unsigned int mei_amthif_poll(struct file *file, poll_table *wait);
 
 int mei_amthif_release(struct mei_device *dev, struct file *file);
 
 int mei_amthif_write(struct mei_cl *cl, struct mei_cl_cb *cb);
 int mei_amthif_run_next_cmd(struct mei_device *dev);
 int mei_amthif_irq_write(struct mei_cl *cl, struct mei_cl_cb *cb,
-			struct mei_cl_cb *cmpl_list);
+			 struct list_head *cmpl_list);
 
 void mei_amthif_complete(struct mei_cl *cl, struct mei_cl_cb *cb);
 int mei_amthif_irq_read_msg(struct mei_cl *cl,
 			    struct mei_msg_hdr *mei_hdr,
-			    struct mei_cl_cb *complete_list);
+			    struct list_head *cmpl_list);
 int mei_amthif_irq_read(struct mei_device *dev, s32 *slots);
 
 /*
  * Register Access Function
  */
 
 
 static inline void mei_hw_config(struct mei_device *dev)
 {
 	dev->ops->hw_config(dev);
 }
 
 static inline enum mei_pg_state mei_pg_state(struct mei_device *dev)
 {
 	return dev->ops->pg_state(dev);
 }
 
 static inline bool mei_pg_in_transition(struct mei_device *dev)
 {
 	return dev->ops->pg_in_transition(dev);
 }
 
 static inline bool mei_pg_is_enabled(struct mei_device *dev)
 {
 	return dev->ops->pg_is_enabled(dev);
 }
 
 static inline int mei_hw_reset(struct mei_device *dev, bool enable)
 {
 	return dev->ops->hw_reset(dev, enable);
 }
 
 static inline int mei_hw_start(struct mei_device *dev)
 {
 	return dev->ops->hw_start(dev);
 }
 
 static inline void mei_clear_interrupts(struct mei_device *dev)
 {
 	dev->ops->intr_clear(dev);
 }
 
 static inline void mei_enable_interrupts(struct mei_device *dev)
 {
 	dev->ops->intr_enable(dev);
 }
 
 static inline void mei_disable_interrupts(struct mei_device *dev)
 {
 	dev->ops->intr_disable(dev);
 }
 
 static inline void mei_synchronize_irq(struct mei_device *dev)
 {
 	dev->ops->synchronize_irq(dev);
 }
 
 static inline bool mei_host_is_ready(struct mei_device *dev)
 {
 	return dev->ops->host_is_ready(dev);
 }
 static inline bool mei_hw_is_ready(struct mei_device *dev)
 {
 	return dev->ops->hw_is_ready(dev);
 }
 
 static inline bool mei_hbuf_is_ready(struct mei_device *dev)
 {
 	return dev->ops->hbuf_is_ready(dev);
 }
 
 static inline int mei_hbuf_empty_slots(struct mei_device *dev)
 {
 	return dev->ops->hbuf_free_slots(dev);
 }
 
 static inline size_t mei_hbuf_max_len(const struct mei_device *dev)
 {
 	return dev->ops->hbuf_max_len(dev);
 }
 
 static inline int mei_write_message(struct mei_device *dev,
 				    struct mei_msg_hdr *hdr, const void *buf)
 {
 	return dev->ops->write(dev, hdr, buf);
 }
 
 static inline u32 mei_read_hdr(const struct mei_device *dev)
 {
 	return dev->ops->read_hdr(dev);
 }
 
 static inline void mei_read_slots(struct mei_device *dev,
 		     unsigned char *buf, unsigned long len)
 {
 	dev->ops->read(dev, buf, len);
 }
 
 static inline int mei_count_full_read_slots(struct mei_device *dev)
 {
 	return dev->ops->rdbuf_full_slots(dev);
 }
 
 static inline int mei_fw_status(struct mei_device *dev,
 				struct mei_fw_status *fw_status)
 {
 	return dev->ops->fw_status(dev, fw_status);
 }
 
 bool mei_hbuf_acquire(struct mei_device *dev);
 
 bool mei_write_is_idle(struct mei_device *dev);
 
 void mei_irq_discard_msg(struct mei_device *dev, struct mei_msg_hdr *hdr);
 
 #if IS_ENABLED(CONFIG_DEBUG_FS)
 int mei_dbgfs_register(struct mei_device *dev, const char *name);
 void mei_dbgfs_deregister(struct mei_device *dev);
 #else
 static inline int mei_dbgfs_register(struct mei_device *dev, const char *name)
 {
 	return 0;
 }
 static inline void mei_dbgfs_deregister(struct mei_device *dev) {}
 #endif /* CONFIG_DEBUG_FS */
 
 int mei_register(struct mei_device *dev, struct device *parent);
 void mei_deregister(struct mei_device *dev);
 
 #define MEI_HDR_FMT "hdr:host=%02d me=%02d len=%d internal=%1d comp=%1d"
 #define MEI_HDR_PRM(hdr)                  \
 	(hdr)->host_addr, (hdr)->me_addr, \
 	(hdr)->length, (hdr)->internal, (hdr)->msg_complete
 
 ssize_t mei_fw_status2str(struct mei_fw_status *fw_sts, char *buf, size_t len);
 /**
  * mei_fw_status_str - fetch and convert fw status registers to printable string
  *
  * @dev: the device structure
  * @buf: string buffer at minimal size MEI_FW_STATUS_STR_SZ
  * @len: buffer len must be >= MEI_FW_STATUS_STR_SZ
  *
  * Return: number of bytes written or < 0 on failure
  */
 static inline ssize_t mei_fw_status_str(struct mei_device *dev,
 					char *buf, size_t len)
 {
 	struct mei_fw_status fw_status;
 	int ret;
 
 	buf[0] = '\0';
 
 	ret = mei_fw_status(dev, &fw_status);
 	if (ret)
 		return ret;
 
 	ret = mei_fw_status2str(&fw_status, buf, MEI_FW_STATUS_STR_SZ);
 
 	return ret;
 }
 
 
 #endif
diff --git a/drivers/misc/mei/pci-me.c b/drivers/misc/mei/pci-me.c
index f9c6ec4b98ab..0a668fdfbbe9 100644
--- a/drivers/misc/mei/pci-me.c
+++ b/drivers/misc/mei/pci-me.c
@@ -1,497 +1,467 @@
 /*
  *
  * Intel Management Engine Interface (Intel MEI) Linux driver
  * Copyright (c) 2003-2012, Intel Corporation.
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms and conditions of the GNU General Public License,
  * version 2, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope it will be useful, but WITHOUT
  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
  * more details.
  *
  */
 #include <linux/module.h>
 #include <linux/moduleparam.h>
 #include <linux/kernel.h>
 #include <linux/device.h>
 #include <linux/fs.h>
 #include <linux/errno.h>
 #include <linux/types.h>
 #include <linux/fcntl.h>
 #include <linux/pci.h>
 #include <linux/poll.h>
 #include <linux/ioctl.h>
 #include <linux/cdev.h>
 #include <linux/sched.h>
 #include <linux/uuid.h>
 #include <linux/compat.h>
 #include <linux/jiffies.h>
 #include <linux/interrupt.h>
 
 #include <linux/pm_domain.h>
 #include <linux/pm_runtime.h>
 
 #include <linux/mei.h>
 
 #include "mei_dev.h"
 #include "client.h"
 #include "hw-me-regs.h"
 #include "hw-me.h"
 
 /* mei_pci_tbl - PCI Device ID Table */
 static const struct pci_device_id mei_me_pci_tbl[] = {
 	{MEI_PCI_DEVICE(MEI_DEV_ID_82946GZ, mei_me_legacy_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_82G35, mei_me_legacy_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_82Q965, mei_me_legacy_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_82G965, mei_me_legacy_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_82GM965, mei_me_legacy_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_82GME965, mei_me_legacy_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_ICH9_82Q35, mei_me_legacy_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_ICH9_82G33, mei_me_legacy_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_ICH9_82Q33, mei_me_legacy_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_ICH9_82X38, mei_me_legacy_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_ICH9_3200, mei_me_legacy_cfg)},
 
 	{MEI_PCI_DEVICE(MEI_DEV_ID_ICH9_6, mei_me_legacy_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_ICH9_7, mei_me_legacy_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_ICH9_8, mei_me_legacy_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_ICH9_9, mei_me_legacy_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_ICH9_10, mei_me_legacy_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_ICH9M_1, mei_me_legacy_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_ICH9M_2, mei_me_legacy_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_ICH9M_3, mei_me_legacy_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_ICH9M_4, mei_me_legacy_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_ICH10_1, mei_me_ich_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_ICH10_2, mei_me_ich_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_ICH10_3, mei_me_ich_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_ICH10_4, mei_me_ich_cfg)},
 
 	{MEI_PCI_DEVICE(MEI_DEV_ID_IBXPK_1, mei_me_pch_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_IBXPK_2, mei_me_pch_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_CPT_1, mei_me_pch_cpt_pbg_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_PBG_1, mei_me_pch_cpt_pbg_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_PPT_1, mei_me_pch_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_PPT_2, mei_me_pch_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_PPT_3, mei_me_pch_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_LPT_H, mei_me_pch8_sps_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_LPT_W, mei_me_pch8_sps_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_LPT_LP, mei_me_pch8_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_LPT_HR, mei_me_pch8_sps_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_WPT_LP, mei_me_pch8_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_WPT_LP_2, mei_me_pch8_cfg)},
 
 	{MEI_PCI_DEVICE(MEI_DEV_ID_SPT, mei_me_pch8_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_SPT_2, mei_me_pch8_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_SPT_H, mei_me_pch8_sps_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_SPT_H_2, mei_me_pch8_sps_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_LBG, mei_me_pch8_cfg)},
 
 	{MEI_PCI_DEVICE(MEI_DEV_ID_BXT_M, mei_me_pch8_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_APL_I, mei_me_pch8_cfg)},
 
 	{MEI_PCI_DEVICE(MEI_DEV_ID_KBP, mei_me_pch8_cfg)},
 	{MEI_PCI_DEVICE(MEI_DEV_ID_KBP_2, mei_me_pch8_cfg)},
 
 	/* required last entry */
 	{0, }
 };
 
 MODULE_DEVICE_TABLE(pci, mei_me_pci_tbl);
 
 #ifdef CONFIG_PM
 static inline void mei_me_set_pm_domain(struct mei_device *dev);
 static inline void mei_me_unset_pm_domain(struct mei_device *dev);
 #else
 static inline void mei_me_set_pm_domain(struct mei_device *dev) {}
 static inline void mei_me_unset_pm_domain(struct mei_device *dev) {}
 #endif /* CONFIG_PM */
 
 /**
  * mei_me_quirk_probe - probe for devices that doesn't valid ME interface
  *
  * @pdev: PCI device structure
  * @cfg: per generation config
  *
  * Return: true if ME Interface is valid, false otherwise
  */
 static bool mei_me_quirk_probe(struct pci_dev *pdev,
 				const struct mei_cfg *cfg)
 {
 	if (cfg->quirk_probe && cfg->quirk_probe(pdev)) {
 		dev_info(&pdev->dev, "Device doesn't have valid ME Interface\n");
 		return false;
 	}
 
 	return true;
 }
 
 /**
  * mei_me_probe - Device Initialization Routine
  *
  * @pdev: PCI device structure
  * @ent: entry in kcs_pci_tbl
  *
  * Return: 0 on success, <0 on failure.
  */
 static int mei_me_probe(struct pci_dev *pdev, const struct pci_device_id *ent)
 {
 	const struct mei_cfg *cfg = (struct mei_cfg *)(ent->driver_data);
 	struct mei_device *dev;
 	struct mei_me_hw *hw;
 	unsigned int irqflags;
 	int err;
 
 
 	if (!mei_me_quirk_probe(pdev, cfg))
 		return -ENODEV;
 
 	/* enable pci dev */
-	err = pci_enable_device(pdev);
+	err = pcim_enable_device(pdev);
 	if (err) {
 		dev_err(&pdev->dev, "failed to enable pci device.\n");
 		goto end;
 	}
 	/* set PCI host mastering  */
 	pci_set_master(pdev);
-	/* pci request regions for mei driver */
-	err = pci_request_regions(pdev, KBUILD_MODNAME);
+	/* pci request regions and mapping IO device memory for mei driver */
+	err = pcim_iomap_regions(pdev, BIT(0), KBUILD_MODNAME);
 	if (err) {
 		dev_err(&pdev->dev, "failed to get pci regions.\n");
-		goto disable_device;
+		goto end;
 	}
 
 	if (dma_set_mask(&pdev->dev, DMA_BIT_MASK(64)) ||
 	    dma_set_coherent_mask(&pdev->dev, DMA_BIT_MASK(64))) {
 
 		err = dma_set_mask(&pdev->dev, DMA_BIT_MASK(32));
 		if (err)
 			err = dma_set_coherent_mask(&pdev->dev,
 						    DMA_BIT_MASK(32));
 	}
 	if (err) {
 		dev_err(&pdev->dev, "No usable DMA configuration, aborting\n");
-		goto release_regions;
+		goto end;
 	}
 
-
 	/* allocates and initializes the mei dev structure */
 	dev = mei_me_dev_init(pdev, cfg);
 	if (!dev) {
 		err = -ENOMEM;
-		goto release_regions;
+		goto end;
 	}
 	hw = to_me_hw(dev);
-	/* mapping  IO device memory */
-	hw->mem_addr = pci_iomap(pdev, 0, 0);
-	if (!hw->mem_addr) {
-		dev_err(&pdev->dev, "mapping I/O device memory failure.\n");
-		err = -ENOMEM;
-		goto free_device;
-	}
+	hw->mem_addr = pcim_iomap_table(pdev)[0];
+
 	pci_enable_msi(pdev);
 
 	 /* request and enable interrupt */
 	irqflags = pci_dev_msi_enabled(pdev) ? IRQF_ONESHOT : IRQF_SHARED;
 
 	err = request_threaded_irq(pdev->irq,
 			mei_me_irq_quick_handler,
 			mei_me_irq_thread_handler,
 			irqflags, KBUILD_MODNAME, dev);
 	if (err) {
 		dev_err(&pdev->dev, "request_threaded_irq failure. irq = %d\n",
 		       pdev->irq);
-		goto disable_msi;
+		goto end;
 	}
 
 	if (mei_start(dev)) {
 		dev_err(&pdev->dev, "init hw failure.\n");
 		err = -ENODEV;
 		goto release_irq;
 	}
 
 	pm_runtime_set_autosuspend_delay(&pdev->dev, MEI_ME_RPM_TIMEOUT);
 	pm_runtime_use_autosuspend(&pdev->dev);
 
 	err = mei_register(dev, &pdev->dev);
 	if (err)
 		goto stop;
 
 	pci_set_drvdata(pdev, dev);
 
 	/*
 	* For not wake-able HW runtime pm framework
 	* can't be used on pci device level.
 	* Use domain runtime pm callbacks instead.
 	*/
 	if (!pci_dev_run_wake(pdev))
 		mei_me_set_pm_domain(dev);
 
 	if (mei_pg_is_enabled(dev))
 		pm_runtime_put_noidle(&pdev->dev);
 
 	dev_dbg(&pdev->dev, "initialization successful.\n");
 
 	return 0;
 
 stop:
 	mei_stop(dev);
 release_irq:
 	mei_cancel_work(dev);
 	mei_disable_interrupts(dev);
 	free_irq(pdev->irq, dev);
-disable_msi:
-	pci_disable_msi(pdev);
-	pci_iounmap(pdev, hw->mem_addr);
-free_device:
-	kfree(dev);
-release_regions:
-	pci_release_regions(pdev);
-disable_device:
-	pci_disable_device(pdev);
 end:
 	dev_err(&pdev->dev, "initialization failed.\n");
 	return err;
 }
 
 /**
  * mei_me_remove - Device Removal Routine
  *
  * @pdev: PCI device structure
  *
  * mei_remove is called by the PCI subsystem to alert the driver
  * that it should release a PCI device.
  */
 static void mei_me_remove(struct pci_dev *pdev)
 {
 	struct mei_device *dev;
-	struct mei_me_hw *hw;
 
 	dev = pci_get_drvdata(pdev);
 	if (!dev)
 		return;
 
 	if (mei_pg_is_enabled(dev))
 		pm_runtime_get_noresume(&pdev->dev);
 
-	hw = to_me_hw(dev);
-
-
 	dev_dbg(&pdev->dev, "stop\n");
 	mei_stop(dev);
 
 	if (!pci_dev_run_wake(pdev))
 		mei_me_unset_pm_domain(dev);
 
-	/* disable interrupts */
 	mei_disable_interrupts(dev);
 
 	free_irq(pdev->irq, dev);
-	pci_disable_msi(pdev);
-
-	if (hw->mem_addr)
-		pci_iounmap(pdev, hw->mem_addr);
 
 	mei_deregister(dev);
-
-	kfree(dev);
-
-	pci_release_regions(pdev);
-	pci_disable_device(pdev);
-
-
 }
+
 #ifdef CONFIG_PM_SLEEP
 static int mei_me_pci_suspend(struct device *device)
 {
 	struct pci_dev *pdev = to_pci_dev(device);
 	struct mei_device *dev = pci_get_drvdata(pdev);
 
 	if (!dev)
 		return -ENODEV;
 
 	dev_dbg(&pdev->dev, "suspend\n");
 
 	mei_stop(dev);
 
 	mei_disable_interrupts(dev);
 
 	free_irq(pdev->irq, dev);
 	pci_disable_msi(pdev);
 
 	return 0;
 }
 
 static int mei_me_pci_resume(struct device *device)
 {
 	struct pci_dev *pdev = to_pci_dev(device);
 	struct mei_device *dev;
 	unsigned int irqflags;
 	int err;
 
 	dev = pci_get_drvdata(pdev);
 	if (!dev)
 		return -ENODEV;
 
 	pci_enable_msi(pdev);
 
 	irqflags = pci_dev_msi_enabled(pdev) ? IRQF_ONESHOT : IRQF_SHARED;
 
 	/* request and enable interrupt */
 	err = request_threaded_irq(pdev->irq,
 			mei_me_irq_quick_handler,
 			mei_me_irq_thread_handler,
 			irqflags, KBUILD_MODNAME, dev);
 
 	if (err) {
 		dev_err(&pdev->dev, "request_threaded_irq failed: irq = %d.\n",
 				pdev->irq);
 		return err;
 	}
 
 	err = mei_restart(dev);
 	if (err)
 		return err;
 
 	/* Start timer if stopped in suspend */
 	schedule_delayed_work(&dev->timer_work, HZ);
 
 	return 0;
 }
 #endif /* CONFIG_PM_SLEEP */
 
 #ifdef CONFIG_PM
 static int mei_me_pm_runtime_idle(struct device *device)
 {
 	struct pci_dev *pdev = to_pci_dev(device);
 	struct mei_device *dev;
 
 	dev_dbg(&pdev->dev, "rpm: me: runtime_idle\n");
 
 	dev = pci_get_drvdata(pdev);
 	if (!dev)
 		return -ENODEV;
 	if (mei_write_is_idle(dev))
 		pm_runtime_autosuspend(device);
 
 	return -EBUSY;
 }
 
 static int mei_me_pm_runtime_suspend(struct device *device)
 {
 	struct pci_dev *pdev = to_pci_dev(device);
 	struct mei_device *dev;
 	int ret;
 
 	dev_dbg(&pdev->dev, "rpm: me: runtime suspend\n");
 
 	dev = pci_get_drvdata(pdev);
 	if (!dev)
 		return -ENODEV;
 
 	mutex_lock(&dev->device_lock);
 
 	if (mei_write_is_idle(dev))
 		ret = mei_me_pg_enter_sync(dev);
 	else
 		ret = -EAGAIN;
 
 	mutex_unlock(&dev->device_lock);
 
 	dev_dbg(&pdev->dev, "rpm: me: runtime suspend ret=%d\n", ret);
 
 	if (ret && ret != -EAGAIN)
 		schedule_work(&dev->reset_work);
 
 	return ret;
 }
 
 static int mei_me_pm_runtime_resume(struct device *device)
 {
 	struct pci_dev *pdev = to_pci_dev(device);
 	struct mei_device *dev;
 	int ret;
 
 	dev_dbg(&pdev->dev, "rpm: me: runtime resume\n");
 
 	dev = pci_get_drvdata(pdev);
 	if (!dev)
 		return -ENODEV;
 
 	mutex_lock(&dev->device_lock);
 
 	ret = mei_me_pg_exit_sync(dev);
 
 	mutex_unlock(&dev->device_lock);
 
 	dev_dbg(&pdev->dev, "rpm: me: runtime resume ret = %d\n", ret);
 
 	if (ret)
 		schedule_work(&dev->reset_work);
 
 	return ret;
 }
 
 /**
  * mei_me_set_pm_domain - fill and set pm domain structure for device
  *
  * @dev: mei_device
  */
 static inline void mei_me_set_pm_domain(struct mei_device *dev)
 {
 	struct pci_dev *pdev  = to_pci_dev(dev->dev);
 
 	if (pdev->dev.bus && pdev->dev.bus->pm) {
 		dev->pg_domain.ops = *pdev->dev.bus->pm;
 
 		dev->pg_domain.ops.runtime_suspend = mei_me_pm_runtime_suspend;
 		dev->pg_domain.ops.runtime_resume = mei_me_pm_runtime_resume;
 		dev->pg_domain.ops.runtime_idle = mei_me_pm_runtime_idle;
 
 		dev_pm_domain_set(&pdev->dev, &dev->pg_domain);
 	}
 }
 
 /**
  * mei_me_unset_pm_domain - clean pm domain structure for device
  *
  * @dev: mei_device
  */
 static inline void mei_me_unset_pm_domain(struct mei_device *dev)
 {
 	/* stop using pm callbacks if any */
 	dev_pm_domain_set(dev->dev, NULL);
 }
 
 static const struct dev_pm_ops mei_me_pm_ops = {
 	SET_SYSTEM_SLEEP_PM_OPS(mei_me_pci_suspend,
 				mei_me_pci_resume)
 	SET_RUNTIME_PM_OPS(
 		mei_me_pm_runtime_suspend,
 		mei_me_pm_runtime_resume,
 		mei_me_pm_runtime_idle)
 };
 
 #define MEI_ME_PM_OPS	(&mei_me_pm_ops)
 #else
 #define MEI_ME_PM_OPS	NULL
 #endif /* CONFIG_PM */
 /*
  *  PCI driver structure
  */
 static struct pci_driver mei_me_driver = {
 	.name = KBUILD_MODNAME,
 	.id_table = mei_me_pci_tbl,
 	.probe = mei_me_probe,
 	.remove = mei_me_remove,
 	.shutdown = mei_me_remove,
 	.driver.pm = MEI_ME_PM_OPS,
 };
 
 module_pci_driver(mei_me_driver);
 
 MODULE_AUTHOR("Intel Corporation");
 MODULE_DESCRIPTION("Intel(R) Management Engine Interface");
 MODULE_LICENSE("GPL v2");
diff --git a/drivers/misc/mei/pci-txe.c b/drivers/misc/mei/pci-txe.c
index 58ffd30dcc91..fe088b40daf9 100644
--- a/drivers/misc/mei/pci-txe.c
+++ b/drivers/misc/mei/pci-txe.c
@@ -1,446 +1,397 @@
 /*
  *
  * Intel Management Engine Interface (Intel MEI) Linux driver
  * Copyright (c) 2013-2014, Intel Corporation.
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms and conditions of the GNU General Public License,
  * version 2, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope it will be useful, but WITHOUT
  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
  * more details.
  *
  */
 
 #include <linux/module.h>
 #include <linux/kernel.h>
 #include <linux/device.h>
 #include <linux/fs.h>
 #include <linux/errno.h>
 #include <linux/types.h>
 #include <linux/pci.h>
 #include <linux/init.h>
 #include <linux/sched.h>
 #include <linux/uuid.h>
 #include <linux/jiffies.h>
 #include <linux/interrupt.h>
 #include <linux/workqueue.h>
 #include <linux/pm_domain.h>
 #include <linux/pm_runtime.h>
 
 #include <linux/mei.h>
 
 
 #include "mei_dev.h"
 #include "hw-txe.h"
 
 static const struct pci_device_id mei_txe_pci_tbl[] = {
 	{PCI_VDEVICE(INTEL, 0x0F18)}, /* Baytrail */
 	{PCI_VDEVICE(INTEL, 0x2298)}, /* Cherrytrail */
 
 	{0, }
 };
 MODULE_DEVICE_TABLE(pci, mei_txe_pci_tbl);
 
 #ifdef CONFIG_PM
 static inline void mei_txe_set_pm_domain(struct mei_device *dev);
 static inline void mei_txe_unset_pm_domain(struct mei_device *dev);
 #else
 static inline void mei_txe_set_pm_domain(struct mei_device *dev) {}
 static inline void mei_txe_unset_pm_domain(struct mei_device *dev) {}
 #endif /* CONFIG_PM */
 
-static void mei_txe_pci_iounmap(struct pci_dev *pdev, struct mei_txe_hw *hw)
-{
-	int i;
-
-	for (i = SEC_BAR; i < NUM_OF_MEM_BARS; i++) {
-		if (hw->mem_addr[i]) {
-			pci_iounmap(pdev, hw->mem_addr[i]);
-			hw->mem_addr[i] = NULL;
-		}
-	}
-}
 /**
  * mei_txe_probe - Device Initialization Routine
  *
  * @pdev: PCI device structure
  * @ent: entry in mei_txe_pci_tbl
  *
  * Return: 0 on success, <0 on failure.
  */
 static int mei_txe_probe(struct pci_dev *pdev, const struct pci_device_id *ent)
 {
 	struct mei_device *dev;
 	struct mei_txe_hw *hw;
+	const int mask = BIT(SEC_BAR) | BIT(BRIDGE_BAR);
 	int err;
-	int i;
 
 	/* enable pci dev */
-	err = pci_enable_device(pdev);
+	err = pcim_enable_device(pdev);
 	if (err) {
 		dev_err(&pdev->dev, "failed to enable pci device.\n");
 		goto end;
 	}
 	/* set PCI host mastering  */
 	pci_set_master(pdev);
-	/* pci request regions for mei driver */
-	err = pci_request_regions(pdev, KBUILD_MODNAME);
+	/* pci request regions and mapping IO device memory for mei driver */
+	err = pcim_iomap_regions(pdev, mask, KBUILD_MODNAME);
 	if (err) {
 		dev_err(&pdev->dev, "failed to get pci regions.\n");
-		goto disable_device;
+		goto end;
 	}
 
 	err = pci_set_dma_mask(pdev, DMA_BIT_MASK(36));
 	if (err) {
 		err = pci_set_dma_mask(pdev, DMA_BIT_MASK(32));
 		if (err) {
 			dev_err(&pdev->dev, "No suitable DMA available.\n");
-			goto release_regions;
+			goto end;
 		}
 	}
 
 	/* allocates and initializes the mei dev structure */
 	dev = mei_txe_dev_init(pdev);
 	if (!dev) {
 		err = -ENOMEM;
-		goto release_regions;
+		goto end;
 	}
 	hw = to_txe_hw(dev);
-
-	/* mapping  IO device memory */
-	for (i = SEC_BAR; i < NUM_OF_MEM_BARS; i++) {
-		hw->mem_addr[i] = pci_iomap(pdev, i, 0);
-		if (!hw->mem_addr[i]) {
-			dev_err(&pdev->dev, "mapping I/O device memory failure.\n");
-			err = -ENOMEM;
-			goto free_device;
-		}
-	}
-
+	hw->mem_addr = pcim_iomap_table(pdev);
 
 	pci_enable_msi(pdev);
 
 	/* clear spurious interrupts */
 	mei_clear_interrupts(dev);
 
 	/* request and enable interrupt  */
 	if (pci_dev_msi_enabled(pdev))
 		err = request_threaded_irq(pdev->irq,
 			NULL,
 			mei_txe_irq_thread_handler,
 			IRQF_ONESHOT, KBUILD_MODNAME, dev);
 	else
 		err = request_threaded_irq(pdev->irq,
 			mei_txe_irq_quick_handler,
 			mei_txe_irq_thread_handler,
 			IRQF_SHARED, KBUILD_MODNAME, dev);
 	if (err) {
 		dev_err(&pdev->dev, "mei: request_threaded_irq failure. irq = %d\n",
 			pdev->irq);
-		goto free_device;
+		goto end;
 	}
 
 	if (mei_start(dev)) {
 		dev_err(&pdev->dev, "init hw failure.\n");
 		err = -ENODEV;
 		goto release_irq;
 	}
 
 	pm_runtime_set_autosuspend_delay(&pdev->dev, MEI_TXI_RPM_TIMEOUT);
 	pm_runtime_use_autosuspend(&pdev->dev);
 
 	err = mei_register(dev, &pdev->dev);
 	if (err)
 		goto stop;
 
 	pci_set_drvdata(pdev, dev);
 
 	/*
 	* For not wake-able HW runtime pm framework
 	* can't be used on pci device level.
 	* Use domain runtime pm callbacks instead.
 	*/
 	if (!pci_dev_run_wake(pdev))
 		mei_txe_set_pm_domain(dev);
 
 	pm_runtime_put_noidle(&pdev->dev);
 
 	return 0;
 
 stop:
 	mei_stop(dev);
 release_irq:
-
 	mei_cancel_work(dev);
-
-	/* disable interrupts */
 	mei_disable_interrupts(dev);
-
 	free_irq(pdev->irq, dev);
-	pci_disable_msi(pdev);
-
-free_device:
-	mei_txe_pci_iounmap(pdev, hw);
-
-	kfree(dev);
-release_regions:
-	pci_release_regions(pdev);
-disable_device:
-	pci_disable_device(pdev);
 end:
 	dev_err(&pdev->dev, "initialization failed.\n");
 	return err;
 }
 
 /**
  * mei_txe_remove - Device Removal Routine
  *
  * @pdev: PCI device structure
  *
  * mei_remove is called by the PCI subsystem to alert the driver
  * that it should release a PCI device.
  */
 static void mei_txe_remove(struct pci_dev *pdev)
 {
 	struct mei_device *dev;
-	struct mei_txe_hw *hw;
 
 	dev = pci_get_drvdata(pdev);
 	if (!dev) {
-		dev_err(&pdev->dev, "mei: dev =NULL\n");
+		dev_err(&pdev->dev, "mei: dev == NULL\n");
 		return;
 	}
 
 	pm_runtime_get_noresume(&pdev->dev);
 
-	hw = to_txe_hw(dev);
-
 	mei_stop(dev);
 
 	if (!pci_dev_run_wake(pdev))
 		mei_txe_unset_pm_domain(dev);
 
-	/* disable interrupts */
 	mei_disable_interrupts(dev);
 	free_irq(pdev->irq, dev);
-	pci_disable_msi(pdev);
-
-	pci_set_drvdata(pdev, NULL);
-
-	mei_txe_pci_iounmap(pdev, hw);
 
 	mei_deregister(dev);
-
-	kfree(dev);
-
-	pci_release_regions(pdev);
-	pci_disable_device(pdev);
 }
 
 
 #ifdef CONFIG_PM_SLEEP
 static int mei_txe_pci_suspend(struct device *device)
 {
 	struct pci_dev *pdev = to_pci_dev(device);
 	struct mei_device *dev = pci_get_drvdata(pdev);
 
 	if (!dev)
 		return -ENODEV;
 
 	dev_dbg(&pdev->dev, "suspend\n");
 
 	mei_stop(dev);
 
 	mei_disable_interrupts(dev);
 
 	free_irq(pdev->irq, dev);
 	pci_disable_msi(pdev);
 
 	return 0;
 }
 
 static int mei_txe_pci_resume(struct device *device)
 {
 	struct pci_dev *pdev = to_pci_dev(device);
 	struct mei_device *dev;
 	int err;
 
 	dev = pci_get_drvdata(pdev);
 	if (!dev)
 		return -ENODEV;
 
 	pci_enable_msi(pdev);
 
 	mei_clear_interrupts(dev);
 
 	/* request and enable interrupt */
 	if (pci_dev_msi_enabled(pdev))
 		err = request_threaded_irq(pdev->irq,
 			NULL,
 			mei_txe_irq_thread_handler,
 			IRQF_ONESHOT, KBUILD_MODNAME, dev);
 	else
 		err = request_threaded_irq(pdev->irq,
 			mei_txe_irq_quick_handler,
 			mei_txe_irq_thread_handler,
 			IRQF_SHARED, KBUILD_MODNAME, dev);
 	if (err) {
 		dev_err(&pdev->dev, "request_threaded_irq failed: irq = %d.\n",
 				pdev->irq);
 		return err;
 	}
 
 	err = mei_restart(dev);
 
 	return err;
 }
 #endif /* CONFIG_PM_SLEEP */
 
 #ifdef CONFIG_PM
 static int mei_txe_pm_runtime_idle(struct device *device)
 {
 	struct pci_dev *pdev = to_pci_dev(device);
 	struct mei_device *dev;
 
 	dev_dbg(&pdev->dev, "rpm: txe: runtime_idle\n");
 
 	dev = pci_get_drvdata(pdev);
 	if (!dev)
 		return -ENODEV;
 	if (mei_write_is_idle(dev))
 		pm_runtime_autosuspend(device);
 
 	return -EBUSY;
 }
 static int mei_txe_pm_runtime_suspend(struct device *device)
 {
 	struct pci_dev *pdev = to_pci_dev(device);
 	struct mei_device *dev;
 	int ret;
 
 	dev_dbg(&pdev->dev, "rpm: txe: runtime suspend\n");
 
 	dev = pci_get_drvdata(pdev);
 	if (!dev)
 		return -ENODEV;
 
 	mutex_lock(&dev->device_lock);
 
 	if (mei_write_is_idle(dev))
 		ret = mei_txe_aliveness_set_sync(dev, 0);
 	else
 		ret = -EAGAIN;
 
 	/*
 	 * If everything is okay we're about to enter PCI low
 	 * power state (D3) therefor we need to disable the
 	 * interrupts towards host.
 	 * However if device is not wakeable we do not enter
 	 * D-low state and we need to keep the interrupt kicking
 	 */
 	if (!ret && pci_dev_run_wake(pdev))
 		mei_disable_interrupts(dev);
 
 	dev_dbg(&pdev->dev, "rpm: txe: runtime suspend ret=%d\n", ret);
 
 	mutex_unlock(&dev->device_lock);
 
 	if (ret && ret != -EAGAIN)
 		schedule_work(&dev->reset_work);
 
 	return ret;
 }
 
 static int mei_txe_pm_runtime_resume(struct device *device)
 {
 	struct pci_dev *pdev = to_pci_dev(device);
 	struct mei_device *dev;
 	int ret;
 
 	dev_dbg(&pdev->dev, "rpm: txe: runtime resume\n");
 
 	dev = pci_get_drvdata(pdev);
 	if (!dev)
 		return -ENODEV;
 
 	mutex_lock(&dev->device_lock);
 
 	mei_enable_interrupts(dev);
 
 	ret = mei_txe_aliveness_set_sync(dev, 1);
 
 	mutex_unlock(&dev->device_lock);
 
 	dev_dbg(&pdev->dev, "rpm: txe: runtime resume ret = %d\n", ret);
 
 	if (ret)
 		schedule_work(&dev->reset_work);
 
 	return ret;
 }
 
 /**
  * mei_txe_set_pm_domain - fill and set pm domain structure for device
  *
  * @dev: mei_device
  */
 static inline void mei_txe_set_pm_domain(struct mei_device *dev)
 {
 	struct pci_dev *pdev  = to_pci_dev(dev->dev);
 
 	if (pdev->dev.bus && pdev->dev.bus->pm) {
 		dev->pg_domain.ops = *pdev->dev.bus->pm;
 
 		dev->pg_domain.ops.runtime_suspend = mei_txe_pm_runtime_suspend;
 		dev->pg_domain.ops.runtime_resume = mei_txe_pm_runtime_resume;
 		dev->pg_domain.ops.runtime_idle = mei_txe_pm_runtime_idle;
 
 		dev_pm_domain_set(&pdev->dev, &dev->pg_domain);
 	}
 }
 
 /**
  * mei_txe_unset_pm_domain - clean pm domain structure for device
  *
  * @dev: mei_device
  */
 static inline void mei_txe_unset_pm_domain(struct mei_device *dev)
 {
 	/* stop using pm callbacks if any */
 	dev_pm_domain_set(dev->dev, NULL);
 }
 
 static const struct dev_pm_ops mei_txe_pm_ops = {
 	SET_SYSTEM_SLEEP_PM_OPS(mei_txe_pci_suspend,
 				mei_txe_pci_resume)
 	SET_RUNTIME_PM_OPS(
 		mei_txe_pm_runtime_suspend,
 		mei_txe_pm_runtime_resume,
 		mei_txe_pm_runtime_idle)
 };
 
 #define MEI_TXE_PM_OPS	(&mei_txe_pm_ops)
 #else
 #define MEI_TXE_PM_OPS	NULL
 #endif /* CONFIG_PM */
 
 /*
  *  PCI driver structure
  */
 static struct pci_driver mei_txe_driver = {
 	.name = KBUILD_MODNAME,
 	.id_table = mei_txe_pci_tbl,
 	.probe = mei_txe_probe,
 	.remove = mei_txe_remove,
 	.shutdown = mei_txe_remove,
 	.driver.pm = MEI_TXE_PM_OPS,
 };
 
 module_pci_driver(mei_txe_driver);
 
 MODULE_AUTHOR("Intel Corporation");
 MODULE_DESCRIPTION("Intel(R) Trusted Execution Environment Interface");
 MODULE_LICENSE("GPL v2");
diff --git a/drivers/misc/mic/vop/vop_vringh.c b/drivers/misc/mic/vop/vop_vringh.c
index 88e45234d527..fed992e2c258 100644
--- a/drivers/misc/mic/vop/vop_vringh.c
+++ b/drivers/misc/mic/vop/vop_vringh.c
@@ -1,1170 +1,1169 @@
 /*
  * Intel MIC Platform Software Stack (MPSS)
  *
  * Copyright(c) 2016 Intel Corporation.
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License, version 2, as
  * published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful, but
  * WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
  * General Public License for more details.
  *
  * The full GNU General Public License is included in this distribution in
  * the file called "COPYING".
  *
  * Intel Virtio Over PCIe (VOP) driver.
  *
  */
 #include <linux/sched.h>
 #include <linux/poll.h>
 #include <linux/dma-mapping.h>
 
 #include <linux/mic_common.h>
 #include "../common/mic_dev.h"
 
 #include <linux/mic_ioctl.h>
 #include "vop_main.h"
 
 /* Helper API to obtain the VOP PCIe device */
 static inline struct device *vop_dev(struct vop_vdev *vdev)
 {
 	return vdev->vpdev->dev.parent;
 }
 
 /* Helper API to check if a virtio device is initialized */
 static inline int vop_vdev_inited(struct vop_vdev *vdev)
 {
 	if (!vdev)
 		return -EINVAL;
 	/* Device has not been created yet */
 	if (!vdev->dd || !vdev->dd->type) {
 		dev_err(vop_dev(vdev), "%s %d err %d\n",
 			__func__, __LINE__, -EINVAL);
 		return -EINVAL;
 	}
 	/* Device has been removed/deleted */
 	if (vdev->dd->type == -1) {
 		dev_dbg(vop_dev(vdev), "%s %d err %d\n",
 			__func__, __LINE__, -ENODEV);
 		return -ENODEV;
 	}
 	return 0;
 }
 
 static void _vop_notify(struct vringh *vrh)
 {
 	struct vop_vringh *vvrh = container_of(vrh, struct vop_vringh, vrh);
 	struct vop_vdev *vdev = vvrh->vdev;
 	struct vop_device *vpdev = vdev->vpdev;
 	s8 db = vdev->dc->h2c_vdev_db;
 
 	if (db != -1)
 		vpdev->hw_ops->send_intr(vpdev, db);
 }
 
 static void vop_virtio_init_post(struct vop_vdev *vdev)
 {
 	struct mic_vqconfig *vqconfig = mic_vq_config(vdev->dd);
 	struct vop_device *vpdev = vdev->vpdev;
 	int i, used_size;
 
 	for (i = 0; i < vdev->dd->num_vq; i++) {
 		used_size = PAGE_ALIGN(sizeof(u16) * 3 +
 				sizeof(struct vring_used_elem) *
 				le16_to_cpu(vqconfig->num));
 		if (!le64_to_cpu(vqconfig[i].used_address)) {
 			dev_warn(vop_dev(vdev), "used_address zero??\n");
 			continue;
 		}
 		vdev->vvr[i].vrh.vring.used =
 			(void __force *)vpdev->hw_ops->ioremap(
 			vpdev,
 			le64_to_cpu(vqconfig[i].used_address),
 			used_size);
 	}
 
 	vdev->dc->used_address_updated = 0;
 
 	dev_info(vop_dev(vdev), "%s: device type %d LINKUP\n",
 		 __func__, vdev->virtio_id);
 }
 
 static inline void vop_virtio_device_reset(struct vop_vdev *vdev)
 {
 	int i;
 
 	dev_dbg(vop_dev(vdev), "%s: status %d device type %d RESET\n",
 		__func__, vdev->dd->status, vdev->virtio_id);
 
 	for (i = 0; i < vdev->dd->num_vq; i++)
 		/*
 		 * Avoid lockdep false positive. The + 1 is for the vop
 		 * mutex which is held in the reset devices code path.
 		 */
 		mutex_lock_nested(&vdev->vvr[i].vr_mutex, i + 1);
 
 	/* 0 status means "reset" */
 	vdev->dd->status = 0;
 	vdev->dc->vdev_reset = 0;
 	vdev->dc->host_ack = 1;
 
 	for (i = 0; i < vdev->dd->num_vq; i++) {
 		struct vringh *vrh = &vdev->vvr[i].vrh;
 
 		vdev->vvr[i].vring.info->avail_idx = 0;
 		vrh->completed = 0;
 		vrh->last_avail_idx = 0;
 		vrh->last_used_idx = 0;
 	}
 
 	for (i = 0; i < vdev->dd->num_vq; i++)
 		mutex_unlock(&vdev->vvr[i].vr_mutex);
 }
 
 static void vop_virtio_reset_devices(struct vop_info *vi)
 {
 	struct list_head *pos, *tmp;
 	struct vop_vdev *vdev;
 
 	list_for_each_safe(pos, tmp, &vi->vdev_list) {
 		vdev = list_entry(pos, struct vop_vdev, list);
 		vop_virtio_device_reset(vdev);
 		vdev->poll_wake = 1;
 		wake_up(&vdev->waitq);
 	}
 }
 
 static void vop_bh_handler(struct work_struct *work)
 {
 	struct vop_vdev *vdev = container_of(work, struct vop_vdev,
 			virtio_bh_work);
 
 	if (vdev->dc->used_address_updated)
 		vop_virtio_init_post(vdev);
 
 	if (vdev->dc->vdev_reset)
 		vop_virtio_device_reset(vdev);
 
 	vdev->poll_wake = 1;
 	wake_up(&vdev->waitq);
 }
 
 static irqreturn_t _vop_virtio_intr_handler(int irq, void *data)
 {
 	struct vop_vdev *vdev = data;
 	struct vop_device *vpdev = vdev->vpdev;
 
 	vpdev->hw_ops->ack_interrupt(vpdev, vdev->virtio_db);
 	schedule_work(&vdev->virtio_bh_work);
 	return IRQ_HANDLED;
 }
 
 static int vop_virtio_config_change(struct vop_vdev *vdev, void *argp)
 {
 	DECLARE_WAIT_QUEUE_HEAD_ONSTACK(wake);
 	int ret = 0, retry, i;
 	struct vop_device *vpdev = vdev->vpdev;
 	struct vop_info *vi = dev_get_drvdata(&vpdev->dev);
 	struct mic_bootparam *bootparam = vpdev->hw_ops->get_dp(vpdev);
 	s8 db = bootparam->h2c_config_db;
 
 	mutex_lock(&vi->vop_mutex);
 	for (i = 0; i < vdev->dd->num_vq; i++)
 		mutex_lock_nested(&vdev->vvr[i].vr_mutex, i + 1);
 
 	if (db == -1 || vdev->dd->type == -1) {
 		ret = -EIO;
 		goto exit;
 	}
 
 	memcpy(mic_vq_configspace(vdev->dd), argp, vdev->dd->config_len);
 	vdev->dc->config_change = MIC_VIRTIO_PARAM_CONFIG_CHANGED;
 	vpdev->hw_ops->send_intr(vpdev, db);
 
 	for (retry = 100; retry--;) {
 		ret = wait_event_timeout(wake, vdev->dc->guest_ack,
 					 msecs_to_jiffies(100));
 		if (ret)
 			break;
 	}
 
 	dev_dbg(vop_dev(vdev),
 		"%s %d retry: %d\n", __func__, __LINE__, retry);
 	vdev->dc->config_change = 0;
 	vdev->dc->guest_ack = 0;
 exit:
 	for (i = 0; i < vdev->dd->num_vq; i++)
 		mutex_unlock(&vdev->vvr[i].vr_mutex);
 	mutex_unlock(&vi->vop_mutex);
 	return ret;
 }
 
 static int vop_copy_dp_entry(struct vop_vdev *vdev,
 			     struct mic_device_desc *argp, __u8 *type,
 			     struct mic_device_desc **devpage)
 {
 	struct vop_device *vpdev = vdev->vpdev;
 	struct mic_device_desc *devp;
 	struct mic_vqconfig *vqconfig;
 	int ret = 0, i;
 	bool slot_found = false;
 
 	vqconfig = mic_vq_config(argp);
 	for (i = 0; i < argp->num_vq; i++) {
 		if (le16_to_cpu(vqconfig[i].num) > MIC_MAX_VRING_ENTRIES) {
 			ret =  -EINVAL;
 			dev_err(vop_dev(vdev), "%s %d err %d\n",
 				__func__, __LINE__, ret);
 			goto exit;
 		}
 	}
 
 	/* Find the first free device page entry */
 	for (i = sizeof(struct mic_bootparam);
 		i < MIC_DP_SIZE - mic_total_desc_size(argp);
 		i += mic_total_desc_size(devp)) {
 		devp = vpdev->hw_ops->get_dp(vpdev) + i;
 		if (devp->type == 0 || devp->type == -1) {
 			slot_found = true;
 			break;
 		}
 	}
 	if (!slot_found) {
 		ret =  -EINVAL;
 		dev_err(vop_dev(vdev), "%s %d err %d\n",
 			__func__, __LINE__, ret);
 		goto exit;
 	}
 	/*
 	 * Save off the type before doing the memcpy. Type will be set in the
 	 * end after completing all initialization for the new device.
 	 */
 	*type = argp->type;
 	argp->type = 0;
 	memcpy(devp, argp, mic_desc_size(argp));
 
 	*devpage = devp;
 exit:
 	return ret;
 }
 
 static void vop_init_device_ctrl(struct vop_vdev *vdev,
 				 struct mic_device_desc *devpage)
 {
 	struct mic_device_ctrl *dc;
 
 	dc = (void *)devpage + mic_aligned_desc_size(devpage);
 
 	dc->config_change = 0;
 	dc->guest_ack = 0;
 	dc->vdev_reset = 0;
 	dc->host_ack = 0;
 	dc->used_address_updated = 0;
 	dc->c2h_vdev_db = -1;
 	dc->h2c_vdev_db = -1;
 	vdev->dc = dc;
 }
 
 static int vop_virtio_add_device(struct vop_vdev *vdev,
 				 struct mic_device_desc *argp)
 {
 	struct vop_info *vi = vdev->vi;
 	struct vop_device *vpdev = vi->vpdev;
 	struct mic_device_desc *dd = NULL;
 	struct mic_vqconfig *vqconfig;
 	int vr_size, i, j, ret;
 	u8 type = 0;
 	s8 db = -1;
 	char irqname[16];
 	struct mic_bootparam *bootparam;
 	u16 num;
 	dma_addr_t vr_addr;
 
 	bootparam = vpdev->hw_ops->get_dp(vpdev);
 	init_waitqueue_head(&vdev->waitq);
 	INIT_LIST_HEAD(&vdev->list);
 	vdev->vpdev = vpdev;
 
 	ret = vop_copy_dp_entry(vdev, argp, &type, &dd);
 	if (ret) {
 		dev_err(vop_dev(vdev), "%s %d err %d\n",
 			__func__, __LINE__, ret);
-		kfree(vdev);
 		return ret;
 	}
 
 	vop_init_device_ctrl(vdev, dd);
 
 	vdev->dd = dd;
 	vdev->virtio_id = type;
 	vqconfig = mic_vq_config(dd);
 	INIT_WORK(&vdev->virtio_bh_work, vop_bh_handler);
 
 	for (i = 0; i < dd->num_vq; i++) {
 		struct vop_vringh *vvr = &vdev->vvr[i];
 		struct mic_vring *vr = &vdev->vvr[i].vring;
 
 		num = le16_to_cpu(vqconfig[i].num);
 		mutex_init(&vvr->vr_mutex);
 		vr_size = PAGE_ALIGN(vring_size(num, MIC_VIRTIO_RING_ALIGN) +
 			sizeof(struct _mic_vring_info));
 		vr->va = (void *)
 			__get_free_pages(GFP_KERNEL | __GFP_ZERO,
 					 get_order(vr_size));
 		if (!vr->va) {
 			ret = -ENOMEM;
 			dev_err(vop_dev(vdev), "%s %d err %d\n",
 				__func__, __LINE__, ret);
 			goto err;
 		}
 		vr->len = vr_size;
 		vr->info = vr->va + vring_size(num, MIC_VIRTIO_RING_ALIGN);
 		vr->info->magic = cpu_to_le32(MIC_MAGIC + vdev->virtio_id + i);
 		vr_addr = dma_map_single(&vpdev->dev, vr->va, vr_size,
 					 DMA_BIDIRECTIONAL);
 		if (dma_mapping_error(&vpdev->dev, vr_addr)) {
 			free_pages((unsigned long)vr->va, get_order(vr_size));
 			ret = -ENOMEM;
 			dev_err(vop_dev(vdev), "%s %d err %d\n",
 				__func__, __LINE__, ret);
 			goto err;
 		}
 		vqconfig[i].address = cpu_to_le64(vr_addr);
 
 		vring_init(&vr->vr, num, vr->va, MIC_VIRTIO_RING_ALIGN);
 		ret = vringh_init_kern(&vvr->vrh,
 				       *(u32 *)mic_vq_features(vdev->dd),
 				       num, false, vr->vr.desc, vr->vr.avail,
 				       vr->vr.used);
 		if (ret) {
 			dev_err(vop_dev(vdev), "%s %d err %d\n",
 				__func__, __LINE__, ret);
 			goto err;
 		}
 		vringh_kiov_init(&vvr->riov, NULL, 0);
 		vringh_kiov_init(&vvr->wiov, NULL, 0);
 		vvr->head = USHRT_MAX;
 		vvr->vdev = vdev;
 		vvr->vrh.notify = _vop_notify;
 		dev_dbg(&vpdev->dev,
 			"%s %d index %d va %p info %p vr_size 0x%x\n",
 			__func__, __LINE__, i, vr->va, vr->info, vr_size);
 		vvr->buf = (void *)__get_free_pages(GFP_KERNEL,
 					get_order(VOP_INT_DMA_BUF_SIZE));
 		vvr->buf_da = dma_map_single(&vpdev->dev,
 					  vvr->buf, VOP_INT_DMA_BUF_SIZE,
 					  DMA_BIDIRECTIONAL);
 	}
 
 	snprintf(irqname, sizeof(irqname), "vop%dvirtio%d", vpdev->index,
 		 vdev->virtio_id);
 	vdev->virtio_db = vpdev->hw_ops->next_db(vpdev);
 	vdev->virtio_cookie = vpdev->hw_ops->request_irq(vpdev,
 			_vop_virtio_intr_handler, irqname, vdev,
 			vdev->virtio_db);
 	if (IS_ERR(vdev->virtio_cookie)) {
 		ret = PTR_ERR(vdev->virtio_cookie);
 		dev_dbg(&vpdev->dev, "request irq failed\n");
 		goto err;
 	}
 
 	vdev->dc->c2h_vdev_db = vdev->virtio_db;
 
 	/*
 	 * Order the type update with previous stores. This write barrier
 	 * is paired with the corresponding read barrier before the uncached
 	 * system memory read of the type, on the card while scanning the
 	 * device page.
 	 */
 	smp_wmb();
 	dd->type = type;
 	argp->type = type;
 
 	if (bootparam) {
 		db = bootparam->h2c_config_db;
 		if (db != -1)
 			vpdev->hw_ops->send_intr(vpdev, db);
 	}
 	dev_dbg(&vpdev->dev, "Added virtio id %d db %d\n", dd->type, db);
 	return 0;
 err:
 	vqconfig = mic_vq_config(dd);
 	for (j = 0; j < i; j++) {
 		struct vop_vringh *vvr = &vdev->vvr[j];
 
 		dma_unmap_single(&vpdev->dev, le64_to_cpu(vqconfig[j].address),
 				 vvr->vring.len, DMA_BIDIRECTIONAL);
 		free_pages((unsigned long)vvr->vring.va,
 			   get_order(vvr->vring.len));
 	}
 	return ret;
 }
 
 static void vop_dev_remove(struct vop_info *pvi, struct mic_device_ctrl *devp,
 			   struct vop_device *vpdev)
 {
 	struct mic_bootparam *bootparam = vpdev->hw_ops->get_dp(vpdev);
 	s8 db;
 	int ret, retry;
 	DECLARE_WAIT_QUEUE_HEAD_ONSTACK(wake);
 
 	devp->config_change = MIC_VIRTIO_PARAM_DEV_REMOVE;
 	db = bootparam->h2c_config_db;
 	if (db != -1)
 		vpdev->hw_ops->send_intr(vpdev, db);
 	else
 		goto done;
 	for (retry = 15; retry--;) {
 		ret = wait_event_timeout(wake, devp->guest_ack,
 					 msecs_to_jiffies(1000));
 		if (ret)
 			break;
 	}
 done:
 	devp->config_change = 0;
 	devp->guest_ack = 0;
 }
 
 static void vop_virtio_del_device(struct vop_vdev *vdev)
 {
 	struct vop_info *vi = vdev->vi;
 	struct vop_device *vpdev = vdev->vpdev;
 	int i;
 	struct mic_vqconfig *vqconfig;
 	struct mic_bootparam *bootparam = vpdev->hw_ops->get_dp(vpdev);
 
 	if (!bootparam)
 		goto skip_hot_remove;
 	vop_dev_remove(vi, vdev->dc, vpdev);
 skip_hot_remove:
 	vpdev->hw_ops->free_irq(vpdev, vdev->virtio_cookie, vdev);
 	flush_work(&vdev->virtio_bh_work);
 	vqconfig = mic_vq_config(vdev->dd);
 	for (i = 0; i < vdev->dd->num_vq; i++) {
 		struct vop_vringh *vvr = &vdev->vvr[i];
 
 		dma_unmap_single(&vpdev->dev,
 				 vvr->buf_da, VOP_INT_DMA_BUF_SIZE,
 				 DMA_BIDIRECTIONAL);
 		free_pages((unsigned long)vvr->buf,
 			   get_order(VOP_INT_DMA_BUF_SIZE));
 		vringh_kiov_cleanup(&vvr->riov);
 		vringh_kiov_cleanup(&vvr->wiov);
 		dma_unmap_single(&vpdev->dev, le64_to_cpu(vqconfig[i].address),
 				 vvr->vring.len, DMA_BIDIRECTIONAL);
 		free_pages((unsigned long)vvr->vring.va,
 			   get_order(vvr->vring.len));
 	}
 	/*
 	 * Order the type update with previous stores. This write barrier
 	 * is paired with the corresponding read barrier before the uncached
 	 * system memory read of the type, on the card while scanning the
 	 * device page.
 	 */
 	smp_wmb();
 	vdev->dd->type = -1;
 }
 
 /*
  * vop_sync_dma - Wrapper for synchronous DMAs.
  *
  * @dev - The address of the pointer to the device instance used
  * for DMA registration.
  * @dst - destination DMA address.
  * @src - source DMA address.
  * @len - size of the transfer.
  *
  * Return DMA_SUCCESS on success
  */
 static int vop_sync_dma(struct vop_vdev *vdev, dma_addr_t dst, dma_addr_t src,
 			size_t len)
 {
 	int err = 0;
 	struct dma_device *ddev;
 	struct dma_async_tx_descriptor *tx;
 	struct vop_info *vi = dev_get_drvdata(&vdev->vpdev->dev);
 	struct dma_chan *vop_ch = vi->dma_ch;
 
 	if (!vop_ch) {
 		err = -EBUSY;
 		goto error;
 	}
 	ddev = vop_ch->device;
 	tx = ddev->device_prep_dma_memcpy(vop_ch, dst, src, len,
 		DMA_PREP_FENCE);
 	if (!tx) {
 		err = -ENOMEM;
 		goto error;
 	} else {
 		dma_cookie_t cookie;
 
 		cookie = tx->tx_submit(tx);
 		if (dma_submit_error(cookie)) {
 			err = -ENOMEM;
 			goto error;
 		}
 		dma_async_issue_pending(vop_ch);
 		err = dma_sync_wait(vop_ch, cookie);
 	}
 error:
 	if (err)
 		dev_err(&vi->vpdev->dev, "%s %d err %d\n",
 			__func__, __LINE__, err);
 	return err;
 }
 
 #define VOP_USE_DMA true
 
 /*
  * Initiates the copies across the PCIe bus from card memory to a user
  * space buffer. When transfers are done using DMA, source/destination
  * addresses and transfer length must follow the alignment requirements of
  * the MIC DMA engine.
  */
 static int vop_virtio_copy_to_user(struct vop_vdev *vdev, void __user *ubuf,
 				   size_t len, u64 daddr, size_t dlen,
 				   int vr_idx)
 {
 	struct vop_device *vpdev = vdev->vpdev;
 	void __iomem *dbuf = vpdev->hw_ops->ioremap(vpdev, daddr, len);
 	struct vop_vringh *vvr = &vdev->vvr[vr_idx];
 	struct vop_info *vi = dev_get_drvdata(&vpdev->dev);
 	size_t dma_alignment = 1 << vi->dma_ch->device->copy_align;
 	bool x200 = is_dma_copy_aligned(vi->dma_ch->device, 1, 1, 1);
 	size_t dma_offset, partlen;
 	int err;
 
 	if (!VOP_USE_DMA) {
 		if (copy_to_user(ubuf, (void __force *)dbuf, len)) {
 			err = -EFAULT;
 			dev_err(vop_dev(vdev), "%s %d err %d\n",
 				__func__, __LINE__, err);
 			goto err;
 		}
 		vdev->in_bytes += len;
 		err = 0;
 		goto err;
 	}
 
 	dma_offset = daddr - round_down(daddr, dma_alignment);
 	daddr -= dma_offset;
 	len += dma_offset;
 	/*
 	 * X100 uses DMA addresses as seen by the card so adding
 	 * the aperture base is not required for DMA. However x200
 	 * requires DMA addresses to be an offset into the bar so
 	 * add the aperture base for x200.
 	 */
 	if (x200)
 		daddr += vpdev->aper->pa;
 	while (len) {
 		partlen = min_t(size_t, len, VOP_INT_DMA_BUF_SIZE);
 		err = vop_sync_dma(vdev, vvr->buf_da, daddr,
 				   ALIGN(partlen, dma_alignment));
 		if (err) {
 			dev_err(vop_dev(vdev), "%s %d err %d\n",
 				__func__, __LINE__, err);
 			goto err;
 		}
 		if (copy_to_user(ubuf, vvr->buf + dma_offset,
 				 partlen - dma_offset)) {
 			err = -EFAULT;
 			dev_err(vop_dev(vdev), "%s %d err %d\n",
 				__func__, __LINE__, err);
 			goto err;
 		}
 		daddr += partlen;
 		ubuf += partlen;
 		dbuf += partlen;
 		vdev->in_bytes_dma += partlen;
 		vdev->in_bytes += partlen;
 		len -= partlen;
 		dma_offset = 0;
 	}
 	err = 0;
 err:
 	vpdev->hw_ops->iounmap(vpdev, dbuf);
 	dev_dbg(vop_dev(vdev),
 		"%s: ubuf %p dbuf %p len 0x%lx vr_idx 0x%x\n",
 		__func__, ubuf, dbuf, len, vr_idx);
 	return err;
 }
 
 /*
  * Initiates copies across the PCIe bus from a user space buffer to card
  * memory. When transfers are done using DMA, source/destination addresses
  * and transfer length must follow the alignment requirements of the MIC
  * DMA engine.
  */
 static int vop_virtio_copy_from_user(struct vop_vdev *vdev, void __user *ubuf,
 				     size_t len, u64 daddr, size_t dlen,
 				     int vr_idx)
 {
 	struct vop_device *vpdev = vdev->vpdev;
 	void __iomem *dbuf = vpdev->hw_ops->ioremap(vpdev, daddr, len);
 	struct vop_vringh *vvr = &vdev->vvr[vr_idx];
 	struct vop_info *vi = dev_get_drvdata(&vdev->vpdev->dev);
 	size_t dma_alignment = 1 << vi->dma_ch->device->copy_align;
 	bool x200 = is_dma_copy_aligned(vi->dma_ch->device, 1, 1, 1);
 	size_t partlen;
 	bool dma = VOP_USE_DMA;
 	int err = 0;
 
 	if (daddr & (dma_alignment - 1)) {
 		vdev->tx_dst_unaligned += len;
 		dma = false;
 	} else if (ALIGN(len, dma_alignment) > dlen) {
 		vdev->tx_len_unaligned += len;
 		dma = false;
 	}
 
 	if (!dma)
 		goto memcpy;
 
 	/*
 	 * X100 uses DMA addresses as seen by the card so adding
 	 * the aperture base is not required for DMA. However x200
 	 * requires DMA addresses to be an offset into the bar so
 	 * add the aperture base for x200.
 	 */
 	if (x200)
 		daddr += vpdev->aper->pa;
 	while (len) {
 		partlen = min_t(size_t, len, VOP_INT_DMA_BUF_SIZE);
 
 		if (copy_from_user(vvr->buf, ubuf, partlen)) {
 			err = -EFAULT;
 			dev_err(vop_dev(vdev), "%s %d err %d\n",
 				__func__, __LINE__, err);
 			goto err;
 		}
 		err = vop_sync_dma(vdev, daddr, vvr->buf_da,
 				   ALIGN(partlen, dma_alignment));
 		if (err) {
 			dev_err(vop_dev(vdev), "%s %d err %d\n",
 				__func__, __LINE__, err);
 			goto err;
 		}
 		daddr += partlen;
 		ubuf += partlen;
 		dbuf += partlen;
 		vdev->out_bytes_dma += partlen;
 		vdev->out_bytes += partlen;
 		len -= partlen;
 	}
 memcpy:
 	/*
 	 * We are copying to IO below and should ideally use something
 	 * like copy_from_user_toio(..) if it existed.
 	 */
 	if (copy_from_user((void __force *)dbuf, ubuf, len)) {
 		err = -EFAULT;
 		dev_err(vop_dev(vdev), "%s %d err %d\n",
 			__func__, __LINE__, err);
 		goto err;
 	}
 	vdev->out_bytes += len;
 	err = 0;
 err:
 	vpdev->hw_ops->iounmap(vpdev, dbuf);
 	dev_dbg(vop_dev(vdev),
 		"%s: ubuf %p dbuf %p len 0x%lx vr_idx 0x%x\n",
 		__func__, ubuf, dbuf, len, vr_idx);
 	return err;
 }
 
 #define MIC_VRINGH_READ true
 
 /* Determine the total number of bytes consumed in a VRINGH KIOV */
 static inline u32 vop_vringh_iov_consumed(struct vringh_kiov *iov)
 {
 	int i;
 	u32 total = iov->consumed;
 
 	for (i = 0; i < iov->i; i++)
 		total += iov->iov[i].iov_len;
 	return total;
 }
 
 /*
  * Traverse the VRINGH KIOV and issue the APIs to trigger the copies.
  * This API is heavily based on the vringh_iov_xfer(..) implementation
  * in vringh.c. The reason we cannot reuse vringh_iov_pull_kern(..)
  * and vringh_iov_push_kern(..) directly is because there is no
  * way to override the VRINGH xfer(..) routines as of v3.10.
  */
 static int vop_vringh_copy(struct vop_vdev *vdev, struct vringh_kiov *iov,
 			   void __user *ubuf, size_t len, bool read, int vr_idx,
 			   size_t *out_len)
 {
 	int ret = 0;
 	size_t partlen, tot_len = 0;
 
 	while (len && iov->i < iov->used) {
 		struct kvec *kiov = &iov->iov[iov->i];
 
 		partlen = min(kiov->iov_len, len);
 		if (read)
 			ret = vop_virtio_copy_to_user(vdev, ubuf, partlen,
 						      (u64)kiov->iov_base,
 						      kiov->iov_len,
 						      vr_idx);
 		else
 			ret = vop_virtio_copy_from_user(vdev, ubuf, partlen,
 							(u64)kiov->iov_base,
 							kiov->iov_len,
 							vr_idx);
 		if (ret) {
 			dev_err(vop_dev(vdev), "%s %d err %d\n",
 				__func__, __LINE__, ret);
 			break;
 		}
 		len -= partlen;
 		ubuf += partlen;
 		tot_len += partlen;
 		iov->consumed += partlen;
 		kiov->iov_len -= partlen;
 		kiov->iov_base += partlen;
 		if (!kiov->iov_len) {
 			/* Fix up old iov element then increment. */
 			kiov->iov_len = iov->consumed;
 			kiov->iov_base -= iov->consumed;
 
 			iov->consumed = 0;
 			iov->i++;
 		}
 	}
 	*out_len = tot_len;
 	return ret;
 }
 
 /*
  * Use the standard VRINGH infrastructure in the kernel to fetch new
  * descriptors, initiate the copies and update the used ring.
  */
 static int _vop_virtio_copy(struct vop_vdev *vdev, struct mic_copy_desc *copy)
 {
 	int ret = 0;
 	u32 iovcnt = copy->iovcnt;
 	struct iovec iov;
 	struct iovec __user *u_iov = copy->iov;
 	void __user *ubuf = NULL;
 	struct vop_vringh *vvr = &vdev->vvr[copy->vr_idx];
 	struct vringh_kiov *riov = &vvr->riov;
 	struct vringh_kiov *wiov = &vvr->wiov;
 	struct vringh *vrh = &vvr->vrh;
 	u16 *head = &vvr->head;
 	struct mic_vring *vr = &vvr->vring;
 	size_t len = 0, out_len;
 
 	copy->out_len = 0;
 	/* Fetch a new IOVEC if all previous elements have been processed */
 	if (riov->i == riov->used && wiov->i == wiov->used) {
 		ret = vringh_getdesc_kern(vrh, riov, wiov,
 					  head, GFP_KERNEL);
 		/* Check if there are available descriptors */
 		if (ret <= 0)
 			return ret;
 	}
 	while (iovcnt) {
 		if (!len) {
 			/* Copy over a new iovec from user space. */
 			ret = copy_from_user(&iov, u_iov, sizeof(*u_iov));
 			if (ret) {
 				ret = -EINVAL;
 				dev_err(vop_dev(vdev), "%s %d err %d\n",
 					__func__, __LINE__, ret);
 				break;
 			}
 			len = iov.iov_len;
 			ubuf = iov.iov_base;
 		}
 		/* Issue all the read descriptors first */
 		ret = vop_vringh_copy(vdev, riov, ubuf, len,
 				      MIC_VRINGH_READ, copy->vr_idx, &out_len);
 		if (ret) {
 			dev_err(vop_dev(vdev), "%s %d err %d\n",
 				__func__, __LINE__, ret);
 			break;
 		}
 		len -= out_len;
 		ubuf += out_len;
 		copy->out_len += out_len;
 		/* Issue the write descriptors next */
 		ret = vop_vringh_copy(vdev, wiov, ubuf, len,
 				      !MIC_VRINGH_READ, copy->vr_idx, &out_len);
 		if (ret) {
 			dev_err(vop_dev(vdev), "%s %d err %d\n",
 				__func__, __LINE__, ret);
 			break;
 		}
 		len -= out_len;
 		ubuf += out_len;
 		copy->out_len += out_len;
 		if (!len) {
 			/* One user space iovec is now completed */
 			iovcnt--;
 			u_iov++;
 		}
 		/* Exit loop if all elements in KIOVs have been processed. */
 		if (riov->i == riov->used && wiov->i == wiov->used)
 			break;
 	}
 	/*
 	 * Update the used ring if a descriptor was available and some data was
 	 * copied in/out and the user asked for a used ring update.
 	 */
 	if (*head != USHRT_MAX && copy->out_len && copy->update_used) {
 		u32 total = 0;
 
 		/* Determine the total data consumed */
 		total += vop_vringh_iov_consumed(riov);
 		total += vop_vringh_iov_consumed(wiov);
 		vringh_complete_kern(vrh, *head, total);
 		*head = USHRT_MAX;
 		if (vringh_need_notify_kern(vrh) > 0)
 			vringh_notify(vrh);
 		vringh_kiov_cleanup(riov);
 		vringh_kiov_cleanup(wiov);
 		/* Update avail idx for user space */
 		vr->info->avail_idx = vrh->last_avail_idx;
 	}
 	return ret;
 }
 
 static inline int vop_verify_copy_args(struct vop_vdev *vdev,
 				       struct mic_copy_desc *copy)
 {
 	if (!vdev || copy->vr_idx >= vdev->dd->num_vq)
 		return -EINVAL;
 	return 0;
 }
 
 /* Copy a specified number of virtio descriptors in a chain */
 static int vop_virtio_copy_desc(struct vop_vdev *vdev,
 				struct mic_copy_desc *copy)
 {
 	int err;
 	struct vop_vringh *vvr;
 
 	err = vop_verify_copy_args(vdev, copy);
 	if (err)
 		return err;
 
 	vvr = &vdev->vvr[copy->vr_idx];
 	mutex_lock(&vvr->vr_mutex);
 	if (!vop_vdevup(vdev)) {
 		err = -ENODEV;
 		dev_err(vop_dev(vdev), "%s %d err %d\n",
 			__func__, __LINE__, err);
 		goto err;
 	}
 	err = _vop_virtio_copy(vdev, copy);
 	if (err) {
 		dev_err(vop_dev(vdev), "%s %d err %d\n",
 			__func__, __LINE__, err);
 	}
 err:
 	mutex_unlock(&vvr->vr_mutex);
 	return err;
 }
 
 static int vop_open(struct inode *inode, struct file *f)
 {
 	struct vop_vdev *vdev;
 	struct vop_info *vi = container_of(f->private_data,
 		struct vop_info, miscdev);
 
 	vdev = kzalloc(sizeof(*vdev), GFP_KERNEL);
 	if (!vdev)
 		return -ENOMEM;
 	vdev->vi = vi;
 	mutex_init(&vdev->vdev_mutex);
 	f->private_data = vdev;
 	init_completion(&vdev->destroy);
 	complete(&vdev->destroy);
 	return 0;
 }
 
 static int vop_release(struct inode *inode, struct file *f)
 {
 	struct vop_vdev *vdev = f->private_data, *vdev_tmp;
 	struct vop_info *vi = vdev->vi;
 	struct list_head *pos, *tmp;
 	bool found = false;
 
 	mutex_lock(&vdev->vdev_mutex);
 	if (vdev->deleted)
 		goto unlock;
 	mutex_lock(&vi->vop_mutex);
 	list_for_each_safe(pos, tmp, &vi->vdev_list) {
 		vdev_tmp = list_entry(pos, struct vop_vdev, list);
 		if (vdev == vdev_tmp) {
 			vop_virtio_del_device(vdev);
 			list_del(pos);
 			found = true;
 			break;
 		}
 	}
 	mutex_unlock(&vi->vop_mutex);
 unlock:
 	mutex_unlock(&vdev->vdev_mutex);
 	if (!found)
 		wait_for_completion(&vdev->destroy);
 	f->private_data = NULL;
 	kfree(vdev);
 	return 0;
 }
 
 static long vop_ioctl(struct file *f, unsigned int cmd, unsigned long arg)
 {
 	struct vop_vdev *vdev = f->private_data;
 	struct vop_info *vi = vdev->vi;
 	void __user *argp = (void __user *)arg;
 	int ret;
 
 	switch (cmd) {
 	case MIC_VIRTIO_ADD_DEVICE:
 	{
 		struct mic_device_desc dd, *dd_config;
 
 		if (copy_from_user(&dd, argp, sizeof(dd)))
 			return -EFAULT;
 
 		if (mic_aligned_desc_size(&dd) > MIC_MAX_DESC_BLK_SIZE ||
 		    dd.num_vq > MIC_MAX_VRINGS)
 			return -EINVAL;
 
 		dd_config = kzalloc(mic_desc_size(&dd), GFP_KERNEL);
 		if (!dd_config)
 			return -ENOMEM;
 		if (copy_from_user(dd_config, argp, mic_desc_size(&dd))) {
 			ret = -EFAULT;
 			goto free_ret;
 		}
 		/* Ensure desc has not changed between the two reads */
 		if (memcmp(&dd, dd_config, sizeof(dd))) {
 			ret = -EINVAL;
 			goto free_ret;
 		}
 		mutex_lock(&vdev->vdev_mutex);
 		mutex_lock(&vi->vop_mutex);
 		ret = vop_virtio_add_device(vdev, dd_config);
 		if (ret)
 			goto unlock_ret;
 		list_add_tail(&vdev->list, &vi->vdev_list);
 unlock_ret:
 		mutex_unlock(&vi->vop_mutex);
 		mutex_unlock(&vdev->vdev_mutex);
 free_ret:
 		kfree(dd_config);
 		return ret;
 	}
 	case MIC_VIRTIO_COPY_DESC:
 	{
 		struct mic_copy_desc copy;
 
 		mutex_lock(&vdev->vdev_mutex);
 		ret = vop_vdev_inited(vdev);
 		if (ret)
 			goto _unlock_ret;
 
 		if (copy_from_user(&copy, argp, sizeof(copy))) {
 			ret = -EFAULT;
 			goto _unlock_ret;
 		}
 
 		ret = vop_virtio_copy_desc(vdev, &copy);
 		if (ret < 0)
 			goto _unlock_ret;
 		if (copy_to_user(
 			&((struct mic_copy_desc __user *)argp)->out_len,
 			&copy.out_len, sizeof(copy.out_len)))
 			ret = -EFAULT;
 _unlock_ret:
 		mutex_unlock(&vdev->vdev_mutex);
 		return ret;
 	}
 	case MIC_VIRTIO_CONFIG_CHANGE:
 	{
 		void *buf;
 
 		mutex_lock(&vdev->vdev_mutex);
 		ret = vop_vdev_inited(vdev);
 		if (ret)
 			goto __unlock_ret;
 		buf = kzalloc(vdev->dd->config_len, GFP_KERNEL);
 		if (!buf) {
 			ret = -ENOMEM;
 			goto __unlock_ret;
 		}
 		if (copy_from_user(buf, argp, vdev->dd->config_len)) {
 			ret = -EFAULT;
 			goto done;
 		}
 		ret = vop_virtio_config_change(vdev, buf);
 done:
 		kfree(buf);
 __unlock_ret:
 		mutex_unlock(&vdev->vdev_mutex);
 		return ret;
 	}
 	default:
 		return -ENOIOCTLCMD;
 	};
 	return 0;
 }
 
 /*
  * We return POLLIN | POLLOUT from poll when new buffers are enqueued, and
  * not when previously enqueued buffers may be available. This means that
  * in the card->host (TX) path, when userspace is unblocked by poll it
  * must drain all available descriptors or it can stall.
  */
 static unsigned int vop_poll(struct file *f, poll_table *wait)
 {
 	struct vop_vdev *vdev = f->private_data;
 	int mask = 0;
 
 	mutex_lock(&vdev->vdev_mutex);
 	if (vop_vdev_inited(vdev)) {
 		mask = POLLERR;
 		goto done;
 	}
 	poll_wait(f, &vdev->waitq, wait);
 	if (vop_vdev_inited(vdev)) {
 		mask = POLLERR;
 	} else if (vdev->poll_wake) {
 		vdev->poll_wake = 0;
 		mask = POLLIN | POLLOUT;
 	}
 done:
 	mutex_unlock(&vdev->vdev_mutex);
 	return mask;
 }
 
 static inline int
 vop_query_offset(struct vop_vdev *vdev, unsigned long offset,
 		 unsigned long *size, unsigned long *pa)
 {
 	struct vop_device *vpdev = vdev->vpdev;
 	unsigned long start = MIC_DP_SIZE;
 	int i;
 
 	/*
 	 * MMAP interface is as follows:
 	 * offset				region
 	 * 0x0					virtio device_page
 	 * 0x1000				first vring
 	 * 0x1000 + size of 1st vring		second vring
 	 * ....
 	 */
 	if (!offset) {
 		*pa = virt_to_phys(vpdev->hw_ops->get_dp(vpdev));
 		*size = MIC_DP_SIZE;
 		return 0;
 	}
 
 	for (i = 0; i < vdev->dd->num_vq; i++) {
 		struct vop_vringh *vvr = &vdev->vvr[i];
 
 		if (offset == start) {
 			*pa = virt_to_phys(vvr->vring.va);
 			*size = vvr->vring.len;
 			return 0;
 		}
 		start += vvr->vring.len;
 	}
 	return -1;
 }
 
 /*
  * Maps the device page and virtio rings to user space for readonly access.
  */
 static int vop_mmap(struct file *f, struct vm_area_struct *vma)
 {
 	struct vop_vdev *vdev = f->private_data;
 	unsigned long offset = vma->vm_pgoff << PAGE_SHIFT;
 	unsigned long pa, size = vma->vm_end - vma->vm_start, size_rem = size;
 	int i, err;
 
 	err = vop_vdev_inited(vdev);
 	if (err)
 		goto ret;
 	if (vma->vm_flags & VM_WRITE) {
 		err = -EACCES;
 		goto ret;
 	}
 	while (size_rem) {
 		i = vop_query_offset(vdev, offset, &size, &pa);
 		if (i < 0) {
 			err = -EINVAL;
 			goto ret;
 		}
 		err = remap_pfn_range(vma, vma->vm_start + offset,
 				      pa >> PAGE_SHIFT, size,
 				      vma->vm_page_prot);
 		if (err)
 			goto ret;
 		size_rem -= size;
 		offset += size;
 	}
 ret:
 	return err;
 }
 
 static const struct file_operations vop_fops = {
 	.open = vop_open,
 	.release = vop_release,
 	.unlocked_ioctl = vop_ioctl,
 	.poll = vop_poll,
 	.mmap = vop_mmap,
 	.owner = THIS_MODULE,
 };
 
 int vop_host_init(struct vop_info *vi)
 {
 	int rc;
 	struct miscdevice *mdev;
 	struct vop_device *vpdev = vi->vpdev;
 
 	INIT_LIST_HEAD(&vi->vdev_list);
 	vi->dma_ch = vpdev->dma_ch;
 	mdev = &vi->miscdev;
 	mdev->minor = MISC_DYNAMIC_MINOR;
 	snprintf(vi->name, sizeof(vi->name), "vop_virtio%d", vpdev->index);
 	mdev->name = vi->name;
 	mdev->fops = &vop_fops;
 	mdev->parent = &vpdev->dev;
 
 	rc = misc_register(mdev);
 	if (rc)
 		dev_err(&vpdev->dev, "%s failed rc %d\n", __func__, rc);
 	return rc;
 }
 
 void vop_host_uninit(struct vop_info *vi)
 {
 	struct list_head *pos, *tmp;
 	struct vop_vdev *vdev;
 
 	mutex_lock(&vi->vop_mutex);
 	vop_virtio_reset_devices(vi);
 	list_for_each_safe(pos, tmp, &vi->vdev_list) {
 		vdev = list_entry(pos, struct vop_vdev, list);
 		list_del(pos);
 		reinit_completion(&vdev->destroy);
 		mutex_unlock(&vi->vop_mutex);
 		mutex_lock(&vdev->vdev_mutex);
 		vop_virtio_del_device(vdev);
 		vdev->deleted = true;
 		mutex_unlock(&vdev->vdev_mutex);
 		complete(&vdev->destroy);
 		mutex_lock(&vi->vop_mutex);
 	}
 	mutex_unlock(&vi->vop_mutex);
 	misc_deregister(&vi->miscdev);
 }
diff --git a/drivers/misc/panel.c b/drivers/misc/panel.c
index 6030ac5b8c63..ef2ece0f26af 100644
--- a/drivers/misc/panel.c
+++ b/drivers/misc/panel.c
@@ -1,2438 +1,2439 @@
 /*
  * Front panel driver for Linux
  * Copyright (C) 2000-2008, Willy Tarreau <w@1wt.eu>
  *
  * This program is free software; you can redistribute it and/or
  * modify it under the terms of the GNU General Public License
  * as published by the Free Software Foundation; either version
  * 2 of the License, or (at your option) any later version.
  *
  * This code drives an LCD module (/dev/lcd), and a keypad (/dev/keypad)
  * connected to a parallel printer port.
  *
  * The LCD module may either be an HD44780-like 8-bit parallel LCD, or a 1-bit
  * serial module compatible with Samsung's KS0074. The pins may be connected in
  * any combination, everything is programmable.
  *
  * The keypad consists in a matrix of push buttons connecting input pins to
  * data output pins or to the ground. The combinations have to be hard-coded
  * in the driver, though several profiles exist and adding new ones is easy.
  *
  * Several profiles are provided for commonly found LCD+keypad modules on the
  * market, such as those found in Nexcom's appliances.
  *
  * FIXME:
  *      - the initialization/deinitialization process is very dirty and should
  *        be rewritten. It may even be buggy.
  *
  * TODO:
  *	- document 24 keys keyboard (3 rows of 8 cols, 32 diodes + 2 inputs)
  *      - make the LCD a part of a virtual screen of Vx*Vy
  *	- make the inputs list smp-safe
  *      - change the keyboard to a double mapping : signals -> key_id -> values
  *        so that applications can change values without knowing signals
  *
  */
 
 #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
 
 #include <linux/module.h>
 
 #include <linux/types.h>
 #include <linux/errno.h>
 #include <linux/signal.h>
 #include <linux/sched.h>
 #include <linux/spinlock.h>
 #include <linux/interrupt.h>
 #include <linux/miscdevice.h>
 #include <linux/slab.h>
 #include <linux/ioport.h>
 #include <linux/fcntl.h>
 #include <linux/init.h>
 #include <linux/delay.h>
 #include <linux/kernel.h>
 #include <linux/ctype.h>
 #include <linux/parport.h>
 #include <linux/list.h>
 #include <linux/notifier.h>
 #include <linux/reboot.h>
+#include <linux/workqueue.h>
 #include <generated/utsrelease.h>
 
 #include <linux/io.h>
 #include <linux/uaccess.h>
 
 #define LCD_MINOR		156
 #define KEYPAD_MINOR		185
 
-#define PANEL_VERSION		"0.9.5"
-
 #define LCD_MAXBYTES		256	/* max burst write */
 
 #define KEYPAD_BUFFER		64
 
 /* poll the keyboard this every second */
 #define INPUT_POLL_TIME		(HZ / 50)
 /* a key starts to repeat after this times INPUT_POLL_TIME */
 #define KEYPAD_REP_START	(10)
 /* a key repeats this times INPUT_POLL_TIME */
 #define KEYPAD_REP_DELAY	(2)
 
-/* keep the light on this times INPUT_POLL_TIME for each flash */
-#define FLASH_LIGHT_TEMPO	(200)
+/* keep the light on this many seconds for each flash */
+#define FLASH_LIGHT_TEMPO	(4)
 
 /* converts an r_str() input to an active high, bits string : 000BAOSE */
 #define PNL_PINPUT(a)		((((unsigned char)(a)) ^ 0x7F) >> 3)
 
 #define PNL_PBUSY		0x80	/* inverted input, active low */
 #define PNL_PACK		0x40	/* direct input, active low */
 #define PNL_POUTPA		0x20	/* direct input, active high */
 #define PNL_PSELECD		0x10	/* direct input, active high */
 #define PNL_PERRORP		0x08	/* direct input, active low */
 
 #define PNL_PBIDIR		0x20	/* bi-directional ports */
 /* high to read data in or-ed with data out */
 #define PNL_PINTEN		0x10
 #define PNL_PSELECP		0x08	/* inverted output, active low */
 #define PNL_PINITP		0x04	/* direct output, active low */
 #define PNL_PAUTOLF		0x02	/* inverted output, active low */
 #define PNL_PSTROBE		0x01	/* inverted output */
 
 #define PNL_PD0			0x01
 #define PNL_PD1			0x02
 #define PNL_PD2			0x04
 #define PNL_PD3			0x08
 #define PNL_PD4			0x10
 #define PNL_PD5			0x20
 #define PNL_PD6			0x40
 #define PNL_PD7			0x80
 
 #define PIN_NONE		0
 #define PIN_STROBE		1
 #define PIN_D0			2
 #define PIN_D1			3
 #define PIN_D2			4
 #define PIN_D3			5
 #define PIN_D4			6
 #define PIN_D5			7
 #define PIN_D6			8
 #define PIN_D7			9
 #define PIN_AUTOLF		14
 #define PIN_INITP		16
 #define PIN_SELECP		17
 #define PIN_NOT_SET		127
 
-#define LCD_FLAG_S		0x0001
-#define LCD_FLAG_ID		0x0002
 #define LCD_FLAG_B		0x0004	/* blink on */
 #define LCD_FLAG_C		0x0008	/* cursor on */
 #define LCD_FLAG_D		0x0010	/* display on */
 #define LCD_FLAG_F		0x0020	/* large font mode */
 #define LCD_FLAG_N		0x0040	/* 2-rows mode */
 #define LCD_FLAG_L		0x0080	/* backlight enabled */
 
 /* LCD commands */
 #define LCD_CMD_DISPLAY_CLEAR	0x01	/* Clear entire display */
 
 #define LCD_CMD_ENTRY_MODE	0x04	/* Set entry mode */
 #define LCD_CMD_CURSOR_INC	0x02	/* Increment cursor */
 
 #define LCD_CMD_DISPLAY_CTRL	0x08	/* Display control */
 #define LCD_CMD_DISPLAY_ON	0x04	/* Set display on */
 #define LCD_CMD_CURSOR_ON	0x02	/* Set cursor on */
 #define LCD_CMD_BLINK_ON	0x01	/* Set blink on */
 
 #define LCD_CMD_SHIFT		0x10	/* Shift cursor/display */
 #define LCD_CMD_DISPLAY_SHIFT	0x08	/* Shift display instead of cursor */
 #define LCD_CMD_SHIFT_RIGHT	0x04	/* Shift display/cursor to the right */
 
 #define LCD_CMD_FUNCTION_SET	0x20	/* Set function */
 #define LCD_CMD_DATA_LEN_8BITS	0x10	/* Set data length to 8 bits */
 #define LCD_CMD_TWO_LINES	0x08	/* Set to two display lines */
 #define LCD_CMD_FONT_5X10_DOTS	0x04	/* Set char font to 5x10 dots */
 
 #define LCD_CMD_SET_CGRAM_ADDR	0x40	/* Set char generator RAM address */
 
 #define LCD_CMD_SET_DDRAM_ADDR	0x80	/* Set display data RAM address */
 
 #define LCD_ESCAPE_LEN		24	/* max chars for LCD escape command */
 #define LCD_ESCAPE_CHAR	27	/* use char 27 for escape command */
 
 #define NOT_SET			-1
 
 /* macros to simplify use of the parallel port */
 #define r_ctr(x)        (parport_read_control((x)->port))
 #define r_dtr(x)        (parport_read_data((x)->port))
 #define r_str(x)        (parport_read_status((x)->port))
 #define w_ctr(x, y)     (parport_write_control((x)->port, (y)))
 #define w_dtr(x, y)     (parport_write_data((x)->port, (y)))
 
 /* this defines which bits are to be used and which ones to be ignored */
 /* logical or of the output bits involved in the scan matrix */
 static __u8 scan_mask_o;
 /* logical or of the input bits involved in the scan matrix */
 static __u8 scan_mask_i;
 
 enum input_type {
 	INPUT_TYPE_STD,
 	INPUT_TYPE_KBD,
 };
 
 enum input_state {
 	INPUT_ST_LOW,
 	INPUT_ST_RISING,
 	INPUT_ST_HIGH,
 	INPUT_ST_FALLING,
 };
 
 struct logical_input {
 	struct list_head list;
 	__u64 mask;
 	__u64 value;
 	enum input_type type;
 	enum input_state state;
 	__u8 rise_time, fall_time;
 	__u8 rise_timer, fall_timer, high_timer;
 
 	union {
 		struct {	/* valid when type == INPUT_TYPE_STD */
 			void (*press_fct)(int);
 			void (*release_fct)(int);
 			int press_data;
 			int release_data;
 		} std;
 		struct {	/* valid when type == INPUT_TYPE_KBD */
 			/* strings can be non null-terminated */
 			char press_str[sizeof(void *) + sizeof(int)];
 			char repeat_str[sizeof(void *) + sizeof(int)];
 			char release_str[sizeof(void *) + sizeof(int)];
 		} kbd;
 	} u;
 };
 
 static LIST_HEAD(logical_inputs);	/* list of all defined logical inputs */
 
 /* physical contacts history
  * Physical contacts are a 45 bits string of 9 groups of 5 bits each.
  * The 8 lower groups correspond to output bits 0 to 7, and the 9th group
  * corresponds to the ground.
  * Within each group, bits are stored in the same order as read on the port :
  * BAPSE (busy=4, ack=3, paper empty=2, select=1, error=0).
  * So, each __u64 is represented like this :
  * 0000000000000000000BAPSEBAPSEBAPSEBAPSEBAPSEBAPSEBAPSEBAPSEBAPSE
  * <-----unused------><gnd><d07><d06><d05><d04><d03><d02><d01><d00>
  */
 
 /* what has just been read from the I/O ports */
 static __u64 phys_read;
 /* previous phys_read */
 static __u64 phys_read_prev;
 /* stabilized phys_read (phys_read|phys_read_prev) */
 static __u64 phys_curr;
 /* previous phys_curr */
 static __u64 phys_prev;
 /* 0 means that at least one logical signal needs be computed */
 static char inputs_stable;
 
 /* these variables are specific to the keypad */
 static struct {
 	bool enabled;
 } keypad;
 
 static char keypad_buffer[KEYPAD_BUFFER];
 static int keypad_buflen;
 static int keypad_start;
 static char keypressed;
 static wait_queue_head_t keypad_read_wait;
 
 /* lcd-specific variables */
 static struct {
 	bool enabled;
 	bool initialized;
 	bool must_clear;
 
 	int height;
 	int width;
 	int bwidth;
 	int hwidth;
 	int charset;
 	int proto;
-	int light_tempo;
+
+	struct delayed_work bl_work;
+	struct mutex bl_tempo_lock;	/* Protects access to bl_tempo */
+	bool bl_tempo;
 
 	/* TODO: use union here? */
 	struct {
 		int e;
 		int rs;
 		int rw;
 		int cl;
 		int da;
 		int bl;
 	} pins;
 
 	/* contains the LCD config state */
 	unsigned long int flags;
 
 	/* Contains the LCD X and Y offset */
 	struct {
 		unsigned long int x;
 		unsigned long int y;
 	} addr;
 
 	/* Current escape sequence and it's length or -1 if outside */
 	struct {
 		char buf[LCD_ESCAPE_LEN + 1];
 		int len;
 	} esc_seq;
 } lcd;
 
 /* Needed only for init */
 static int selected_lcd_type = NOT_SET;
 
 /*
  * Bit masks to convert LCD signals to parallel port outputs.
  * _d_ are values for data port, _c_ are for control port.
  * [0] = signal OFF, [1] = signal ON, [2] = mask
  */
 #define BIT_CLR		0
 #define BIT_SET		1
 #define BIT_MSK		2
 #define BIT_STATES	3
 /*
  * one entry for each bit on the LCD
  */
 #define LCD_BIT_E	0
 #define LCD_BIT_RS	1
 #define LCD_BIT_RW	2
 #define LCD_BIT_BL	3
 #define LCD_BIT_CL	4
 #define LCD_BIT_DA	5
 #define LCD_BITS	6
 
 /*
  * each bit can be either connected to a DATA or CTRL port
  */
 #define LCD_PORT_C	0
 #define LCD_PORT_D	1
 #define LCD_PORTS	2
 
 static unsigned char lcd_bits[LCD_PORTS][LCD_BITS][BIT_STATES];
 
 /*
  * LCD protocols
  */
 #define LCD_PROTO_PARALLEL      0
 #define LCD_PROTO_SERIAL        1
 #define LCD_PROTO_TI_DA8XX_LCD	2
 
 /*
  * LCD character sets
  */
 #define LCD_CHARSET_NORMAL      0
 #define LCD_CHARSET_KS0074      1
 
 /*
  * LCD types
  */
 #define LCD_TYPE_NONE		0
 #define LCD_TYPE_CUSTOM		1
 #define LCD_TYPE_OLD		2
 #define LCD_TYPE_KS0074		3
 #define LCD_TYPE_HANTRONIX	4
 #define LCD_TYPE_NEXCOM		5
 
 /*
  * keypad types
  */
 #define KEYPAD_TYPE_NONE	0
 #define KEYPAD_TYPE_OLD		1
 #define KEYPAD_TYPE_NEW		2
 #define KEYPAD_TYPE_NEXCOM	3
 
 /*
  * panel profiles
  */
 #define PANEL_PROFILE_CUSTOM	0
 #define PANEL_PROFILE_OLD	1
 #define PANEL_PROFILE_NEW	2
 #define PANEL_PROFILE_HANTRONIX	3
 #define PANEL_PROFILE_NEXCOM	4
 #define PANEL_PROFILE_LARGE	5
 
 /*
  * Construct custom config from the kernel's configuration
  */
 #define DEFAULT_PARPORT         0
 #define DEFAULT_PROFILE         PANEL_PROFILE_LARGE
 #define DEFAULT_KEYPAD_TYPE     KEYPAD_TYPE_OLD
 #define DEFAULT_LCD_TYPE        LCD_TYPE_OLD
 #define DEFAULT_LCD_HEIGHT      2
 #define DEFAULT_LCD_WIDTH       40
 #define DEFAULT_LCD_BWIDTH      40
 #define DEFAULT_LCD_HWIDTH      64
 #define DEFAULT_LCD_CHARSET     LCD_CHARSET_NORMAL
 #define DEFAULT_LCD_PROTO       LCD_PROTO_PARALLEL
 
 #define DEFAULT_LCD_PIN_E       PIN_AUTOLF
 #define DEFAULT_LCD_PIN_RS      PIN_SELECP
 #define DEFAULT_LCD_PIN_RW      PIN_INITP
 #define DEFAULT_LCD_PIN_SCL     PIN_STROBE
 #define DEFAULT_LCD_PIN_SDA     PIN_D0
 #define DEFAULT_LCD_PIN_BL      PIN_NOT_SET
 
 #ifdef CONFIG_PANEL_PARPORT
 #undef DEFAULT_PARPORT
 #define DEFAULT_PARPORT CONFIG_PANEL_PARPORT
 #endif
 
 #ifdef CONFIG_PANEL_PROFILE
 #undef DEFAULT_PROFILE
 #define DEFAULT_PROFILE CONFIG_PANEL_PROFILE
 #endif
 
 #if DEFAULT_PROFILE == 0	/* custom */
 #ifdef CONFIG_PANEL_KEYPAD
 #undef DEFAULT_KEYPAD_TYPE
 #define DEFAULT_KEYPAD_TYPE CONFIG_PANEL_KEYPAD
 #endif
 
 #ifdef CONFIG_PANEL_LCD
 #undef DEFAULT_LCD_TYPE
 #define DEFAULT_LCD_TYPE CONFIG_PANEL_LCD
 #endif
 
 #ifdef CONFIG_PANEL_LCD_HEIGHT
 #undef DEFAULT_LCD_HEIGHT
 #define DEFAULT_LCD_HEIGHT CONFIG_PANEL_LCD_HEIGHT
 #endif
 
 #ifdef CONFIG_PANEL_LCD_WIDTH
 #undef DEFAULT_LCD_WIDTH
 #define DEFAULT_LCD_WIDTH CONFIG_PANEL_LCD_WIDTH
 #endif
 
 #ifdef CONFIG_PANEL_LCD_BWIDTH
 #undef DEFAULT_LCD_BWIDTH
 #define DEFAULT_LCD_BWIDTH CONFIG_PANEL_LCD_BWIDTH
 #endif
 
 #ifdef CONFIG_PANEL_LCD_HWIDTH
 #undef DEFAULT_LCD_HWIDTH
 #define DEFAULT_LCD_HWIDTH CONFIG_PANEL_LCD_HWIDTH
 #endif
 
 #ifdef CONFIG_PANEL_LCD_CHARSET
 #undef DEFAULT_LCD_CHARSET
 #define DEFAULT_LCD_CHARSET CONFIG_PANEL_LCD_CHARSET
 #endif
 
 #ifdef CONFIG_PANEL_LCD_PROTO
 #undef DEFAULT_LCD_PROTO
 #define DEFAULT_LCD_PROTO CONFIG_PANEL_LCD_PROTO
 #endif
 
 #ifdef CONFIG_PANEL_LCD_PIN_E
 #undef DEFAULT_LCD_PIN_E
 #define DEFAULT_LCD_PIN_E CONFIG_PANEL_LCD_PIN_E
 #endif
 
 #ifdef CONFIG_PANEL_LCD_PIN_RS
 #undef DEFAULT_LCD_PIN_RS
 #define DEFAULT_LCD_PIN_RS CONFIG_PANEL_LCD_PIN_RS
 #endif
 
 #ifdef CONFIG_PANEL_LCD_PIN_RW
 #undef DEFAULT_LCD_PIN_RW
 #define DEFAULT_LCD_PIN_RW CONFIG_PANEL_LCD_PIN_RW
 #endif
 
 #ifdef CONFIG_PANEL_LCD_PIN_SCL
 #undef DEFAULT_LCD_PIN_SCL
 #define DEFAULT_LCD_PIN_SCL CONFIG_PANEL_LCD_PIN_SCL
 #endif
 
 #ifdef CONFIG_PANEL_LCD_PIN_SDA
 #undef DEFAULT_LCD_PIN_SDA
 #define DEFAULT_LCD_PIN_SDA CONFIG_PANEL_LCD_PIN_SDA
 #endif
 
 #ifdef CONFIG_PANEL_LCD_PIN_BL
 #undef DEFAULT_LCD_PIN_BL
 #define DEFAULT_LCD_PIN_BL CONFIG_PANEL_LCD_PIN_BL
 #endif
 
 #endif /* DEFAULT_PROFILE == 0 */
 
 /* global variables */
 
 /* Device single-open policy control */
 static atomic_t lcd_available = ATOMIC_INIT(1);
 static atomic_t keypad_available = ATOMIC_INIT(1);
 
 static struct pardevice *pprt;
 
 static int keypad_initialized;
 
 static void (*lcd_write_cmd)(int);
 static void (*lcd_write_data)(int);
 static void (*lcd_clear_fast)(void);
 
 static DEFINE_SPINLOCK(pprt_lock);
 static struct timer_list scan_timer;
 
 MODULE_DESCRIPTION("Generic parallel port LCD/Keypad driver");
 
 static int parport = DEFAULT_PARPORT;
 module_param(parport, int, 0000);
 MODULE_PARM_DESC(parport, "Parallel port index (0=lpt1, 1=lpt2, ...)");
 
 static int profile = DEFAULT_PROFILE;
 module_param(profile, int, 0000);
 MODULE_PARM_DESC(profile,
 		 "1=16x2 old kp; 2=serial 16x2, new kp; 3=16x2 hantronix; "
 		 "4=16x2 nexcom; default=40x2, old kp");
 
 static int keypad_type = NOT_SET;
 module_param(keypad_type, int, 0000);
 MODULE_PARM_DESC(keypad_type,
 		 "Keypad type: 0=none, 1=old 6 keys, 2=new 6+1 keys, 3=nexcom 4 keys");
 
 static int lcd_type = NOT_SET;
 module_param(lcd_type, int, 0000);
 MODULE_PARM_DESC(lcd_type,
 		 "LCD type: 0=none, 1=compiled-in, 2=old, 3=serial ks0074, 4=hantronix, 5=nexcom");
 
 static int lcd_height = NOT_SET;
 module_param(lcd_height, int, 0000);
 MODULE_PARM_DESC(lcd_height, "Number of lines on the LCD");
 
 static int lcd_width = NOT_SET;
 module_param(lcd_width, int, 0000);
 MODULE_PARM_DESC(lcd_width, "Number of columns on the LCD");
 
 static int lcd_bwidth = NOT_SET;	/* internal buffer width (usually 40) */
 module_param(lcd_bwidth, int, 0000);
 MODULE_PARM_DESC(lcd_bwidth, "Internal LCD line width (40)");
 
 static int lcd_hwidth = NOT_SET;	/* hardware buffer width (usually 64) */
 module_param(lcd_hwidth, int, 0000);
 MODULE_PARM_DESC(lcd_hwidth, "LCD line hardware address (64)");
 
 static int lcd_charset = NOT_SET;
 module_param(lcd_charset, int, 0000);
 MODULE_PARM_DESC(lcd_charset, "LCD character set: 0=standard, 1=KS0074");
 
 static int lcd_proto = NOT_SET;
 module_param(lcd_proto, int, 0000);
 MODULE_PARM_DESC(lcd_proto,
 		 "LCD communication: 0=parallel (//), 1=serial, 2=TI LCD Interface");
 
 /*
  * These are the parallel port pins the LCD control signals are connected to.
  * Set this to 0 if the signal is not used. Set it to its opposite value
  * (negative) if the signal is negated. -MAXINT is used to indicate that the
  * pin has not been explicitly specified.
  *
  * WARNING! no check will be performed about collisions with keypad !
  */
 
 static int lcd_e_pin  = PIN_NOT_SET;
 module_param(lcd_e_pin, int, 0000);
 MODULE_PARM_DESC(lcd_e_pin,
 		 "# of the // port pin connected to LCD 'E' signal, with polarity (-17..17)");
 
 static int lcd_rs_pin = PIN_NOT_SET;
 module_param(lcd_rs_pin, int, 0000);
 MODULE_PARM_DESC(lcd_rs_pin,
 		 "# of the // port pin connected to LCD 'RS' signal, with polarity (-17..17)");
 
 static int lcd_rw_pin = PIN_NOT_SET;
 module_param(lcd_rw_pin, int, 0000);
 MODULE_PARM_DESC(lcd_rw_pin,
 		 "# of the // port pin connected to LCD 'RW' signal, with polarity (-17..17)");
 
 static int lcd_cl_pin = PIN_NOT_SET;
 module_param(lcd_cl_pin, int, 0000);
 MODULE_PARM_DESC(lcd_cl_pin,
 		 "# of the // port pin connected to serial LCD 'SCL' signal, with polarity (-17..17)");
 
 static int lcd_da_pin = PIN_NOT_SET;
 module_param(lcd_da_pin, int, 0000);
 MODULE_PARM_DESC(lcd_da_pin,
 		 "# of the // port pin connected to serial LCD 'SDA' signal, with polarity (-17..17)");
 
 static int lcd_bl_pin = PIN_NOT_SET;
 module_param(lcd_bl_pin, int, 0000);
 MODULE_PARM_DESC(lcd_bl_pin,
 		 "# of the // port pin connected to LCD backlight, with polarity (-17..17)");
 
 /* Deprecated module parameters - consider not using them anymore */
 
 static int lcd_enabled = NOT_SET;
 module_param(lcd_enabled, int, 0000);
 MODULE_PARM_DESC(lcd_enabled, "Deprecated option, use lcd_type instead");
 
 static int keypad_enabled = NOT_SET;
 module_param(keypad_enabled, int, 0000);
 MODULE_PARM_DESC(keypad_enabled, "Deprecated option, use keypad_type instead");
 
 static const unsigned char *lcd_char_conv;
 
 /* for some LCD drivers (ks0074) we need a charset conversion table. */
 static const unsigned char lcd_char_conv_ks0074[256] = {
 	/*          0|8   1|9   2|A   3|B   4|C   5|D   6|E   7|F */
 	/* 0x00 */ 0x00, 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07,
 	/* 0x08 */ 0x08, 0x09, 0x0a, 0x0b, 0x0c, 0x0d, 0x0e, 0x0f,
 	/* 0x10 */ 0x10, 0x11, 0x12, 0x13, 0x14, 0x15, 0x16, 0x17,
 	/* 0x18 */ 0x18, 0x19, 0x1a, 0x1b, 0x1c, 0x1d, 0x1e, 0x1f,
 	/* 0x20 */ 0x20, 0x21, 0x22, 0x23, 0xa2, 0x25, 0x26, 0x27,
 	/* 0x28 */ 0x28, 0x29, 0x2a, 0x2b, 0x2c, 0x2d, 0x2e, 0x2f,
 	/* 0x30 */ 0x30, 0x31, 0x32, 0x33, 0x34, 0x35, 0x36, 0x37,
 	/* 0x38 */ 0x38, 0x39, 0x3a, 0x3b, 0x3c, 0x3d, 0x3e, 0x3f,
 	/* 0x40 */ 0xa0, 0x41, 0x42, 0x43, 0x44, 0x45, 0x46, 0x47,
 	/* 0x48 */ 0x48, 0x49, 0x4a, 0x4b, 0x4c, 0x4d, 0x4e, 0x4f,
 	/* 0x50 */ 0x50, 0x51, 0x52, 0x53, 0x54, 0x55, 0x56, 0x57,
 	/* 0x58 */ 0x58, 0x59, 0x5a, 0xfa, 0xfb, 0xfc, 0x1d, 0xc4,
 	/* 0x60 */ 0x96, 0x61, 0x62, 0x63, 0x64, 0x65, 0x66, 0x67,
 	/* 0x68 */ 0x68, 0x69, 0x6a, 0x6b, 0x6c, 0x6d, 0x6e, 0x6f,
 	/* 0x70 */ 0x70, 0x71, 0x72, 0x73, 0x74, 0x75, 0x76, 0x77,
 	/* 0x78 */ 0x78, 0x79, 0x7a, 0xfd, 0xfe, 0xff, 0xce, 0x20,
 	/* 0x80 */ 0x80, 0x81, 0x82, 0x83, 0x84, 0x85, 0x86, 0x87,
 	/* 0x88 */ 0x88, 0x89, 0x8a, 0x8b, 0x8c, 0x8d, 0x8e, 0x8f,
 	/* 0x90 */ 0x90, 0x91, 0x92, 0x93, 0x94, 0x95, 0x96, 0x97,
 	/* 0x98 */ 0x98, 0x99, 0x9a, 0x9b, 0x9c, 0x9d, 0x9e, 0x9f,
 	/* 0xA0 */ 0x20, 0x40, 0xb1, 0xa1, 0x24, 0xa3, 0xfe, 0x5f,
 	/* 0xA8 */ 0x22, 0xc8, 0x61, 0x14, 0x97, 0x2d, 0xad, 0x96,
 	/* 0xB0 */ 0x80, 0x8c, 0x82, 0x83, 0x27, 0x8f, 0x86, 0xdd,
 	/* 0xB8 */ 0x2c, 0x81, 0x6f, 0x15, 0x8b, 0x8a, 0x84, 0x60,
 	/* 0xC0 */ 0xe2, 0xe2, 0xe2, 0x5b, 0x5b, 0xae, 0xbc, 0xa9,
 	/* 0xC8 */ 0xc5, 0xbf, 0xc6, 0xf1, 0xe3, 0xe3, 0xe3, 0xe3,
 	/* 0xD0 */ 0x44, 0x5d, 0xa8, 0xe4, 0xec, 0xec, 0x5c, 0x78,
 	/* 0xD8 */ 0xab, 0xa6, 0xe5, 0x5e, 0x5e, 0xe6, 0xaa, 0xbe,
 	/* 0xE0 */ 0x7f, 0xe7, 0xaf, 0x7b, 0x7b, 0xaf, 0xbd, 0xc8,
 	/* 0xE8 */ 0xa4, 0xa5, 0xc7, 0xf6, 0xa7, 0xe8, 0x69, 0x69,
 	/* 0xF0 */ 0xed, 0x7d, 0xa8, 0xe4, 0xec, 0x5c, 0x5c, 0x25,
 	/* 0xF8 */ 0xac, 0xa6, 0xea, 0xef, 0x7e, 0xeb, 0xb2, 0x79,
 };
 
 static const char old_keypad_profile[][4][9] = {
 	{"S0", "Left\n", "Left\n", ""},
 	{"S1", "Down\n", "Down\n", ""},
 	{"S2", "Up\n", "Up\n", ""},
 	{"S3", "Right\n", "Right\n", ""},
 	{"S4", "Esc\n", "Esc\n", ""},
 	{"S5", "Ret\n", "Ret\n", ""},
 	{"", "", "", ""}
 };
 
 /* signals, press, repeat, release */
 static const char new_keypad_profile[][4][9] = {
 	{"S0", "Left\n", "Left\n", ""},
 	{"S1", "Down\n", "Down\n", ""},
 	{"S2", "Up\n", "Up\n", ""},
 	{"S3", "Right\n", "Right\n", ""},
 	{"S4s5", "", "Esc\n", "Esc\n"},
 	{"s4S5", "", "Ret\n", "Ret\n"},
 	{"S4S5", "Help\n", "", ""},
 	/* add new signals above this line */
 	{"", "", "", ""}
 };
 
 /* signals, press, repeat, release */
 static const char nexcom_keypad_profile[][4][9] = {
 	{"a-p-e-", "Down\n", "Down\n", ""},
 	{"a-p-E-", "Ret\n", "Ret\n", ""},
 	{"a-P-E-", "Esc\n", "Esc\n", ""},
 	{"a-P-e-", "Up\n", "Up\n", ""},
 	/* add new signals above this line */
 	{"", "", "", ""}
 };
 
 static const char (*keypad_profile)[4][9] = old_keypad_profile;
 
 static DECLARE_BITMAP(bits, LCD_BITS);
 
 static void lcd_get_bits(unsigned int port, int *val)
 {
 	unsigned int bit, state;
 
 	for (bit = 0; bit < LCD_BITS; bit++) {
 		state = test_bit(bit, bits) ? BIT_SET : BIT_CLR;
 		*val &= lcd_bits[port][bit][BIT_MSK];
 		*val |= lcd_bits[port][bit][state];
 	}
 }
 
-static void init_scan_timer(void);
-
 /* sets data port bits according to current signals values */
 static int set_data_bits(void)
 {
 	int val;
 
 	val = r_dtr(pprt);
 	lcd_get_bits(LCD_PORT_D, &val);
 	w_dtr(pprt, val);
 	return val;
 }
 
 /* sets ctrl port bits according to current signals values */
 static int set_ctrl_bits(void)
 {
 	int val;
 
 	val = r_ctr(pprt);
 	lcd_get_bits(LCD_PORT_C, &val);
 	w_ctr(pprt, val);
 	return val;
 }
 
 /* sets ctrl & data port bits according to current signals values */
 static void panel_set_bits(void)
 {
 	set_data_bits();
 	set_ctrl_bits();
 }
 
 /*
  * Converts a parallel port pin (from -25 to 25) to data and control ports
  * masks, and data and control port bits. The signal will be considered
  * unconnected if it's on pin 0 or an invalid pin (<-25 or >25).
  *
  * Result will be used this way :
  *   out(dport, in(dport) & d_val[2] | d_val[signal_state])
  *   out(cport, in(cport) & c_val[2] | c_val[signal_state])
  */
 static void pin_to_bits(int pin, unsigned char *d_val, unsigned char *c_val)
 {
 	int d_bit, c_bit, inv;
 
 	d_val[0] = 0;
 	c_val[0] = 0;
 	d_val[1] = 0;
 	c_val[1] = 0;
 	d_val[2] = 0xFF;
 	c_val[2] = 0xFF;
 
 	if (pin == 0)
 		return;
 
 	inv = (pin < 0);
 	if (inv)
 		pin = -pin;
 
 	d_bit = 0;
 	c_bit = 0;
 
 	switch (pin) {
 	case PIN_STROBE:	/* strobe, inverted */
 		c_bit = PNL_PSTROBE;
 		inv = !inv;
 		break;
 	case PIN_D0...PIN_D7:	/* D0 - D7 = 2 - 9 */
 		d_bit = 1 << (pin - 2);
 		break;
 	case PIN_AUTOLF:	/* autofeed, inverted */
 		c_bit = PNL_PAUTOLF;
 		inv = !inv;
 		break;
 	case PIN_INITP:		/* init, direct */
 		c_bit = PNL_PINITP;
 		break;
 	case PIN_SELECP:	/* select_in, inverted */
 		c_bit = PNL_PSELECP;
 		inv = !inv;
 		break;
 	default:		/* unknown pin, ignore */
 		break;
 	}
 
 	if (c_bit) {
 		c_val[2] &= ~c_bit;
 		c_val[!inv] = c_bit;
 	} else if (d_bit) {
 		d_val[2] &= ~d_bit;
 		d_val[!inv] = d_bit;
 	}
 }
 
 /* sleeps that many milliseconds with a reschedule */
 static void long_sleep(int ms)
 {
 	if (in_interrupt())
 		mdelay(ms);
 	else
 		schedule_timeout_interruptible(msecs_to_jiffies(ms));
 }
 
 /*
  * send a serial byte to the LCD panel. The caller is responsible for locking
  * if needed.
  */
 static void lcd_send_serial(int byte)
 {
 	int bit;
 
 	/*
 	 * the data bit is set on D0, and the clock on STROBE.
 	 * LCD reads D0 on STROBE's rising edge.
 	 */
 	for (bit = 0; bit < 8; bit++) {
 		clear_bit(LCD_BIT_CL, bits);	/* CLK low */
 		panel_set_bits();
 		if (byte & 1) {
 			set_bit(LCD_BIT_DA, bits);
 		} else {
 			clear_bit(LCD_BIT_DA, bits);
 		}
 
 		panel_set_bits();
 		udelay(2);  /* maintain the data during 2 us before CLK up */
 		set_bit(LCD_BIT_CL, bits);	/* CLK high */
 		panel_set_bits();
 		udelay(1);  /* maintain the strobe during 1 us */
 		byte >>= 1;
 	}
 }
 
 /* turn the backlight on or off */
-static void lcd_backlight(int on)
+static void __lcd_backlight(int on)
 {
-	if (lcd.pins.bl == PIN_NONE)
-		return;
-
 	/* The backlight is activated by setting the AUTOFEED line to +5V  */
 	spin_lock_irq(&pprt_lock);
 	if (on)
 		set_bit(LCD_BIT_BL, bits);
 	else
 		clear_bit(LCD_BIT_BL, bits);
 	panel_set_bits();
 	spin_unlock_irq(&pprt_lock);
 }
 
+static void lcd_backlight(int on)
+{
+	if (lcd.pins.bl == PIN_NONE)
+		return;
+
+	mutex_lock(&lcd.bl_tempo_lock);
+	if (!lcd.bl_tempo)
+		__lcd_backlight(on);
+	mutex_unlock(&lcd.bl_tempo_lock);
+}
+
+static void lcd_bl_off(struct work_struct *work)
+{
+	mutex_lock(&lcd.bl_tempo_lock);
+	if (lcd.bl_tempo) {
+		lcd.bl_tempo = false;
+		if (!(lcd.flags & LCD_FLAG_L))
+			__lcd_backlight(0);
+	}
+	mutex_unlock(&lcd.bl_tempo_lock);
+}
+
+/* turn the backlight on for a little while */
+static void lcd_poke(void)
+{
+	if (lcd.pins.bl == PIN_NONE)
+		return;
+
+	cancel_delayed_work_sync(&lcd.bl_work);
+
+	mutex_lock(&lcd.bl_tempo_lock);
+	if (!lcd.bl_tempo && !(lcd.flags & LCD_FLAG_L))
+		__lcd_backlight(1);
+	lcd.bl_tempo = true;
+	schedule_delayed_work(&lcd.bl_work, FLASH_LIGHT_TEMPO * HZ);
+	mutex_unlock(&lcd.bl_tempo_lock);
+}
+
 /* send a command to the LCD panel in serial mode */
 static void lcd_write_cmd_s(int cmd)
 {
 	spin_lock_irq(&pprt_lock);
 	lcd_send_serial(0x1F);	/* R/W=W, RS=0 */
 	lcd_send_serial(cmd & 0x0F);
 	lcd_send_serial((cmd >> 4) & 0x0F);
 	udelay(40);		/* the shortest command takes at least 40 us */
 	spin_unlock_irq(&pprt_lock);
 }
 
 /* send data to the LCD panel in serial mode */
 static void lcd_write_data_s(int data)
 {
 	spin_lock_irq(&pprt_lock);
 	lcd_send_serial(0x5F);	/* R/W=W, RS=1 */
 	lcd_send_serial(data & 0x0F);
 	lcd_send_serial((data >> 4) & 0x0F);
 	udelay(40);		/* the shortest data takes at least 40 us */
 	spin_unlock_irq(&pprt_lock);
 }
 
 /* send a command to the LCD panel in 8 bits parallel mode */
 static void lcd_write_cmd_p8(int cmd)
 {
 	spin_lock_irq(&pprt_lock);
 	/* present the data to the data port */
 	w_dtr(pprt, cmd);
 	udelay(20);	/* maintain the data during 20 us before the strobe */
 
 	set_bit(LCD_BIT_E, bits);
 	clear_bit(LCD_BIT_RS, bits);
 	clear_bit(LCD_BIT_RW, bits);
 	set_ctrl_bits();
 
 	udelay(40);	/* maintain the strobe during 40 us */
 
 	clear_bit(LCD_BIT_E, bits);
 	set_ctrl_bits();
 
 	udelay(120);	/* the shortest command takes at least 120 us */
 	spin_unlock_irq(&pprt_lock);
 }
 
 /* send data to the LCD panel in 8 bits parallel mode */
 static void lcd_write_data_p8(int data)
 {
 	spin_lock_irq(&pprt_lock);
 	/* present the data to the data port */
 	w_dtr(pprt, data);
 	udelay(20);	/* maintain the data during 20 us before the strobe */
 
 	set_bit(LCD_BIT_E, bits);
 	set_bit(LCD_BIT_RS, bits);
 	clear_bit(LCD_BIT_RW, bits);
 	set_ctrl_bits();
 
 	udelay(40);	/* maintain the strobe during 40 us */
 
 	clear_bit(LCD_BIT_E, bits);
 	set_ctrl_bits();
 
 	udelay(45);	/* the shortest data takes at least 45 us */
 	spin_unlock_irq(&pprt_lock);
 }
 
 /* send a command to the TI LCD panel */
 static void lcd_write_cmd_tilcd(int cmd)
 {
 	spin_lock_irq(&pprt_lock);
 	/* present the data to the control port */
 	w_ctr(pprt, cmd);
 	udelay(60);
 	spin_unlock_irq(&pprt_lock);
 }
 
 /* send data to the TI LCD panel */
 static void lcd_write_data_tilcd(int data)
 {
 	spin_lock_irq(&pprt_lock);
 	/* present the data to the data port */
 	w_dtr(pprt, data);
 	udelay(60);
 	spin_unlock_irq(&pprt_lock);
 }
 
 static void lcd_gotoxy(void)
 {
 	lcd_write_cmd(LCD_CMD_SET_DDRAM_ADDR
 		      | (lcd.addr.y ? lcd.hwidth : 0)
 		      /*
 		       * we force the cursor to stay at the end of the
 		       * line if it wants to go farther
 		       */
 		      | ((lcd.addr.x < lcd.bwidth) ? lcd.addr.x &
 			 (lcd.hwidth - 1) : lcd.bwidth - 1));
 }
 
+static void lcd_home(void)
+{
+	lcd.addr.x = 0;
+	lcd.addr.y = 0;
+	lcd_gotoxy();
+}
+
 static void lcd_print(char c)
 {
 	if (lcd.addr.x < lcd.bwidth) {
 		if (lcd_char_conv)
 			c = lcd_char_conv[(unsigned char)c];
 		lcd_write_data(c);
 		lcd.addr.x++;
 	}
 	/* prevents the cursor from wrapping onto the next line */
 	if (lcd.addr.x == lcd.bwidth)
 		lcd_gotoxy();
 }
 
 /* fills the display with spaces and resets X/Y */
 static void lcd_clear_fast_s(void)
 {
 	int pos;
 
-	lcd.addr.x = 0;
-	lcd.addr.y = 0;
-	lcd_gotoxy();
+	lcd_home();
 
 	spin_lock_irq(&pprt_lock);
 	for (pos = 0; pos < lcd.height * lcd.hwidth; pos++) {
 		lcd_send_serial(0x5F);	/* R/W=W, RS=1 */
 		lcd_send_serial(' ' & 0x0F);
 		lcd_send_serial((' ' >> 4) & 0x0F);
 		/* the shortest data takes at least 40 us */
 		udelay(40);
 	}
 	spin_unlock_irq(&pprt_lock);
 
-	lcd.addr.x = 0;
-	lcd.addr.y = 0;
-	lcd_gotoxy();
+	lcd_home();
 }
 
 /* fills the display with spaces and resets X/Y */
 static void lcd_clear_fast_p8(void)
 {
 	int pos;
 
-	lcd.addr.x = 0;
-	lcd.addr.y = 0;
-	lcd_gotoxy();
+	lcd_home();
 
 	spin_lock_irq(&pprt_lock);
 	for (pos = 0; pos < lcd.height * lcd.hwidth; pos++) {
 		/* present the data to the data port */
 		w_dtr(pprt, ' ');
 
 		/* maintain the data during 20 us before the strobe */
 		udelay(20);
 
 		set_bit(LCD_BIT_E, bits);
 		set_bit(LCD_BIT_RS, bits);
 		clear_bit(LCD_BIT_RW, bits);
 		set_ctrl_bits();
 
 		/* maintain the strobe during 40 us */
 		udelay(40);
 
 		clear_bit(LCD_BIT_E, bits);
 		set_ctrl_bits();
 
 		/* the shortest data takes at least 45 us */
 		udelay(45);
 	}
 	spin_unlock_irq(&pprt_lock);
 
-	lcd.addr.x = 0;
-	lcd.addr.y = 0;
-	lcd_gotoxy();
+	lcd_home();
 }
 
 /* fills the display with spaces and resets X/Y */
 static void lcd_clear_fast_tilcd(void)
 {
 	int pos;
 
-	lcd.addr.x = 0;
-	lcd.addr.y = 0;
-	lcd_gotoxy();
+	lcd_home();
 
 	spin_lock_irq(&pprt_lock);
 	for (pos = 0; pos < lcd.height * lcd.hwidth; pos++) {
 		/* present the data to the data port */
 		w_dtr(pprt, ' ');
 		udelay(60);
 	}
 
 	spin_unlock_irq(&pprt_lock);
 
-	lcd.addr.x = 0;
-	lcd.addr.y = 0;
-	lcd_gotoxy();
+	lcd_home();
 }
 
 /* clears the display and resets X/Y */
 static void lcd_clear_display(void)
 {
 	lcd_write_cmd(LCD_CMD_DISPLAY_CLEAR);
 	lcd.addr.x = 0;
 	lcd.addr.y = 0;
 	/* we must wait a few milliseconds (15) */
 	long_sleep(15);
 }
 
 static void lcd_init_display(void)
 {
 	lcd.flags = ((lcd.height > 1) ? LCD_FLAG_N : 0)
 	    | LCD_FLAG_D | LCD_FLAG_C | LCD_FLAG_B;
 
 	long_sleep(20);		/* wait 20 ms after power-up for the paranoid */
 
 	/* 8bits, 1 line, small fonts; let's do it 3 times */
 	lcd_write_cmd(LCD_CMD_FUNCTION_SET | LCD_CMD_DATA_LEN_8BITS);
 	long_sleep(10);
 	lcd_write_cmd(LCD_CMD_FUNCTION_SET | LCD_CMD_DATA_LEN_8BITS);
 	long_sleep(10);
 	lcd_write_cmd(LCD_CMD_FUNCTION_SET | LCD_CMD_DATA_LEN_8BITS);
 	long_sleep(10);
 
 	/* set font height and lines number */
 	lcd_write_cmd(LCD_CMD_FUNCTION_SET | LCD_CMD_DATA_LEN_8BITS
 		      | ((lcd.flags & LCD_FLAG_F) ? LCD_CMD_FONT_5X10_DOTS : 0)
 		      | ((lcd.flags & LCD_FLAG_N) ? LCD_CMD_TWO_LINES : 0)
 	    );
 	long_sleep(10);
 
 	/* display off, cursor off, blink off */
 	lcd_write_cmd(LCD_CMD_DISPLAY_CTRL);
 	long_sleep(10);
 
 	lcd_write_cmd(LCD_CMD_DISPLAY_CTRL	/* set display mode */
 		      | ((lcd.flags & LCD_FLAG_D) ? LCD_CMD_DISPLAY_ON : 0)
 		      | ((lcd.flags & LCD_FLAG_C) ? LCD_CMD_CURSOR_ON : 0)
 		      | ((lcd.flags & LCD_FLAG_B) ? LCD_CMD_BLINK_ON : 0)
 	    );
 
 	lcd_backlight((lcd.flags & LCD_FLAG_L) ? 1 : 0);
 
 	long_sleep(10);
 
 	/* entry mode set : increment, cursor shifting */
 	lcd_write_cmd(LCD_CMD_ENTRY_MODE | LCD_CMD_CURSOR_INC);
 
 	lcd_clear_display();
 }
 
 /*
  * These are the file operation function for user access to /dev/lcd
  * This function can also be called from inside the kernel, by
  * setting file and ppos to NULL.
  *
  */
 
 static inline int handle_lcd_special_code(void)
 {
 	/* LCD special codes */
 
 	int processed = 0;
 
 	char *esc = lcd.esc_seq.buf + 2;
 	int oldflags = lcd.flags;
 
 	/* check for display mode flags */
 	switch (*esc) {
 	case 'D':	/* Display ON */
 		lcd.flags |= LCD_FLAG_D;
 		processed = 1;
 		break;
 	case 'd':	/* Display OFF */
 		lcd.flags &= ~LCD_FLAG_D;
 		processed = 1;
 		break;
 	case 'C':	/* Cursor ON */
 		lcd.flags |= LCD_FLAG_C;
 		processed = 1;
 		break;
 	case 'c':	/* Cursor OFF */
 		lcd.flags &= ~LCD_FLAG_C;
 		processed = 1;
 		break;
 	case 'B':	/* Blink ON */
 		lcd.flags |= LCD_FLAG_B;
 		processed = 1;
 		break;
 	case 'b':	/* Blink OFF */
 		lcd.flags &= ~LCD_FLAG_B;
 		processed = 1;
 		break;
 	case '+':	/* Back light ON */
 		lcd.flags |= LCD_FLAG_L;
 		processed = 1;
 		break;
 	case '-':	/* Back light OFF */
 		lcd.flags &= ~LCD_FLAG_L;
 		processed = 1;
 		break;
 	case '*':
-		/* flash back light using the keypad timer */
-		if (scan_timer.function) {
-			if (lcd.light_tempo == 0 &&
-			    ((lcd.flags & LCD_FLAG_L) == 0))
-				lcd_backlight(1);
-			lcd.light_tempo = FLASH_LIGHT_TEMPO;
-		}
+		/* flash back light */
+		lcd_poke();
 		processed = 1;
 		break;
 	case 'f':	/* Small Font */
 		lcd.flags &= ~LCD_FLAG_F;
 		processed = 1;
 		break;
 	case 'F':	/* Large Font */
 		lcd.flags |= LCD_FLAG_F;
 		processed = 1;
 		break;
 	case 'n':	/* One Line */
 		lcd.flags &= ~LCD_FLAG_N;
 		processed = 1;
 		break;
 	case 'N':	/* Two Lines */
 		lcd.flags |= LCD_FLAG_N;
 		break;
 	case 'l':	/* Shift Cursor Left */
 		if (lcd.addr.x > 0) {
 			/* back one char if not at end of line */
 			if (lcd.addr.x < lcd.bwidth)
 				lcd_write_cmd(LCD_CMD_SHIFT);
 			lcd.addr.x--;
 		}
 		processed = 1;
 		break;
 	case 'r':	/* shift cursor right */
 		if (lcd.addr.x < lcd.width) {
 			/* allow the cursor to pass the end of the line */
 			if (lcd.addr.x < (lcd.bwidth - 1))
 				lcd_write_cmd(LCD_CMD_SHIFT |
 						LCD_CMD_SHIFT_RIGHT);
 			lcd.addr.x++;
 		}
 		processed = 1;
 		break;
 	case 'L':	/* shift display left */
 		lcd_write_cmd(LCD_CMD_SHIFT | LCD_CMD_DISPLAY_SHIFT);
 		processed = 1;
 		break;
 	case 'R':	/* shift display right */
 		lcd_write_cmd(LCD_CMD_SHIFT | LCD_CMD_DISPLAY_SHIFT |
 				LCD_CMD_SHIFT_RIGHT);
 		processed = 1;
 		break;
 	case 'k': {	/* kill end of line */
 		int x;
 
 		for (x = lcd.addr.x; x < lcd.bwidth; x++)
 			lcd_write_data(' ');
 
 		/* restore cursor position */
 		lcd_gotoxy();
 		processed = 1;
 		break;
 	}
 	case 'I':	/* reinitialize display */
 		lcd_init_display();
 		processed = 1;
 		break;
 	case 'G': {
 		/* Generator : LGcxxxxx...xx; must have <c> between '0'
 		 * and '7', representing the numerical ASCII code of the
 		 * redefined character, and <xx...xx> a sequence of 16
 		 * hex digits representing 8 bytes for each character.
 		 * Most LCDs will only use 5 lower bits of the 7 first
 		 * bytes.
 		 */
 
 		unsigned char cgbytes[8];
 		unsigned char cgaddr;
 		int cgoffset;
 		int shift;
 		char value;
 		int addr;
 
 		if (!strchr(esc, ';'))
 			break;
 
 		esc++;
 
 		cgaddr = *(esc++) - '0';
 		if (cgaddr > 7) {
 			processed = 1;
 			break;
 		}
 
 		cgoffset = 0;
 		shift = 0;
 		value = 0;
 		while (*esc && cgoffset < 8) {
 			shift ^= 4;
 			if (*esc >= '0' && *esc <= '9') {
 				value |= (*esc - '0') << shift;
 			} else if (*esc >= 'A' && *esc <= 'Z') {
 				value |= (*esc - 'A' + 10) << shift;
 			} else if (*esc >= 'a' && *esc <= 'z') {
 				value |= (*esc - 'a' + 10) << shift;
 			} else {
 				esc++;
 				continue;
 			}
 
 			if (shift == 0) {
 				cgbytes[cgoffset++] = value;
 				value = 0;
 			}
 
 			esc++;
 		}
 
 		lcd_write_cmd(LCD_CMD_SET_CGRAM_ADDR | (cgaddr * 8));
 		for (addr = 0; addr < cgoffset; addr++)
 			lcd_write_data(cgbytes[addr]);
 
 		/* ensures that we stop writing to CGRAM */
 		lcd_gotoxy();
 		processed = 1;
 		break;
 	}
 	case 'x':	/* gotoxy : LxXXX[yYYY]; */
 	case 'y':	/* gotoxy : LyYYY[xXXX]; */
 		if (!strchr(esc, ';'))
 			break;
 
 		while (*esc) {
 			if (*esc == 'x') {
 				esc++;
 				if (kstrtoul(esc, 10, &lcd.addr.x) < 0)
 					break;
 			} else if (*esc == 'y') {
 				esc++;
 				if (kstrtoul(esc, 10, &lcd.addr.y) < 0)
 					break;
 			} else {
 				break;
 			}
 		}
 
 		lcd_gotoxy();
 		processed = 1;
 		break;
 	}
 
 	/* TODO: This indent party here got ugly, clean it! */
 	/* Check whether one flag was changed */
 	if (oldflags != lcd.flags) {
 		/* check whether one of B,C,D flags were changed */
 		if ((oldflags ^ lcd.flags) &
 		    (LCD_FLAG_B | LCD_FLAG_C | LCD_FLAG_D))
 			/* set display mode */
 			lcd_write_cmd(LCD_CMD_DISPLAY_CTRL
 				      | ((lcd.flags & LCD_FLAG_D)
 						      ? LCD_CMD_DISPLAY_ON : 0)
 				      | ((lcd.flags & LCD_FLAG_C)
 						      ? LCD_CMD_CURSOR_ON : 0)
 				      | ((lcd.flags & LCD_FLAG_B)
 						      ? LCD_CMD_BLINK_ON : 0));
 		/* check whether one of F,N flags was changed */
 		else if ((oldflags ^ lcd.flags) & (LCD_FLAG_F | LCD_FLAG_N))
 			lcd_write_cmd(LCD_CMD_FUNCTION_SET
 				      | LCD_CMD_DATA_LEN_8BITS
 				      | ((lcd.flags & LCD_FLAG_F)
-						      ? LCD_CMD_TWO_LINES : 0)
-				      | ((lcd.flags & LCD_FLAG_N)
 						      ? LCD_CMD_FONT_5X10_DOTS
+								      : 0)
+				      | ((lcd.flags & LCD_FLAG_N)
+						      ? LCD_CMD_TWO_LINES
 								      : 0));
 		/* check whether L flag was changed */
-		else if ((oldflags ^ lcd.flags) & (LCD_FLAG_L)) {
-			if (lcd.flags & (LCD_FLAG_L))
-				lcd_backlight(1);
-			else if (lcd.light_tempo == 0)
-				/*
-				 * switch off the light only when the tempo
-				 * lighting is gone
-				 */
-				lcd_backlight(0);
-		}
+		else if ((oldflags ^ lcd.flags) & (LCD_FLAG_L))
+			lcd_backlight(!!(lcd.flags & LCD_FLAG_L));
 	}
 
 	return processed;
 }
 
 static void lcd_write_char(char c)
 {
 	/* first, we'll test if we're in escape mode */
 	if ((c != '\n') && lcd.esc_seq.len >= 0) {
 		/* yes, let's add this char to the buffer */
 		lcd.esc_seq.buf[lcd.esc_seq.len++] = c;
 		lcd.esc_seq.buf[lcd.esc_seq.len] = 0;
 	} else {
 		/* aborts any previous escape sequence */
 		lcd.esc_seq.len = -1;
 
 		switch (c) {
 		case LCD_ESCAPE_CHAR:
 			/* start of an escape sequence */
 			lcd.esc_seq.len = 0;
 			lcd.esc_seq.buf[lcd.esc_seq.len] = 0;
 			break;
 		case '\b':
 			/* go back one char and clear it */
 			if (lcd.addr.x > 0) {
 				/*
 				 * check if we're not at the
 				 * end of the line
 				 */
 				if (lcd.addr.x < lcd.bwidth)
 					/* back one char */
 					lcd_write_cmd(LCD_CMD_SHIFT);
 				lcd.addr.x--;
 			}
 			/* replace with a space */
 			lcd_write_data(' ');
 			/* back one char again */
 			lcd_write_cmd(LCD_CMD_SHIFT);
 			break;
 		case '\014':
 			/* quickly clear the display */
 			lcd_clear_fast();
 			break;
 		case '\n':
 			/*
 			 * flush the remainder of the current line and
 			 * go to the beginning of the next line
 			 */
 			for (; lcd.addr.x < lcd.bwidth; lcd.addr.x++)
 				lcd_write_data(' ');
 			lcd.addr.x = 0;
 			lcd.addr.y = (lcd.addr.y + 1) % lcd.height;
 			lcd_gotoxy();
 			break;
 		case '\r':
 			/* go to the beginning of the same line */
 			lcd.addr.x = 0;
 			lcd_gotoxy();
 			break;
 		case '\t':
 			/* print a space instead of the tab */
 			lcd_print(' ');
 			break;
 		default:
 			/* simply print this char */
 			lcd_print(c);
 			break;
 		}
 	}
 
 	/*
 	 * now we'll see if we're in an escape mode and if the current
 	 * escape sequence can be understood.
 	 */
 	if (lcd.esc_seq.len >= 2) {
 		int processed = 0;
 
 		if (!strcmp(lcd.esc_seq.buf, "[2J")) {
 			/* clear the display */
 			lcd_clear_fast();
 			processed = 1;
 		} else if (!strcmp(lcd.esc_seq.buf, "[H")) {
 			/* cursor to home */
-			lcd.addr.x = 0;
-			lcd.addr.y = 0;
-			lcd_gotoxy();
+			lcd_home();
 			processed = 1;
 		}
 		/* codes starting with ^[[L */
 		else if ((lcd.esc_seq.len >= 3) &&
 			 (lcd.esc_seq.buf[0] == '[') &&
 			 (lcd.esc_seq.buf[1] == 'L')) {
 			processed = handle_lcd_special_code();
 		}
 
 		/* LCD special escape codes */
 		/*
 		 * flush the escape sequence if it's been processed
 		 * or if it is getting too long.
 		 */
 		if (processed || (lcd.esc_seq.len >= LCD_ESCAPE_LEN))
 			lcd.esc_seq.len = -1;
 	} /* escape codes */
 }
 
 static ssize_t lcd_write(struct file *file,
 			 const char __user *buf, size_t count, loff_t *ppos)
 {
 	const char __user *tmp = buf;
 	char c;
 
 	for (; count-- > 0; (*ppos)++, tmp++) {
 		if (!in_interrupt() && (((count + 1) & 0x1f) == 0))
 			/*
 			 * let's be a little nice with other processes
 			 * that need some CPU
 			 */
 			schedule();
 
 		if (get_user(c, tmp))
 			return -EFAULT;
 
 		lcd_write_char(c);
 	}
 
 	return tmp - buf;
 }
 
 static int lcd_open(struct inode *inode, struct file *file)
 {
 	if (!atomic_dec_and_test(&lcd_available))
 		return -EBUSY;	/* open only once at a time */
 
 	if (file->f_mode & FMODE_READ)	/* device is write-only */
 		return -EPERM;
 
 	if (lcd.must_clear) {
 		lcd_clear_display();
 		lcd.must_clear = false;
 	}
 	return nonseekable_open(inode, file);
 }
 
 static int lcd_release(struct inode *inode, struct file *file)
 {
 	atomic_inc(&lcd_available);
 	return 0;
 }
 
 static const struct file_operations lcd_fops = {
 	.write   = lcd_write,
 	.open    = lcd_open,
 	.release = lcd_release,
 	.llseek  = no_llseek,
 };
 
 static struct miscdevice lcd_dev = {
 	.minor	= LCD_MINOR,
 	.name	= "lcd",
 	.fops	= &lcd_fops,
 };
 
 /* public function usable from the kernel for any purpose */
 static void panel_lcd_print(const char *s)
 {
 	const char *tmp = s;
 	int count = strlen(s);
 
 	if (lcd.enabled && lcd.initialized) {
 		for (; count-- > 0; tmp++) {
 			if (!in_interrupt() && (((count + 1) & 0x1f) == 0))
 				/*
 				 * let's be a little nice with other processes
 				 * that need some CPU
 				 */
 				schedule();
 
 			lcd_write_char(*tmp);
 		}
 	}
 }
 
 /* initialize the LCD driver */
 static void lcd_init(void)
 {
 	switch (selected_lcd_type) {
 	case LCD_TYPE_OLD:
 		/* parallel mode, 8 bits */
 		lcd.proto = LCD_PROTO_PARALLEL;
 		lcd.charset = LCD_CHARSET_NORMAL;
 		lcd.pins.e = PIN_STROBE;
 		lcd.pins.rs = PIN_AUTOLF;
 
 		lcd.width = 40;
 		lcd.bwidth = 40;
 		lcd.hwidth = 64;
 		lcd.height = 2;
 		break;
 	case LCD_TYPE_KS0074:
 		/* serial mode, ks0074 */
 		lcd.proto = LCD_PROTO_SERIAL;
 		lcd.charset = LCD_CHARSET_KS0074;
 		lcd.pins.bl = PIN_AUTOLF;
 		lcd.pins.cl = PIN_STROBE;
 		lcd.pins.da = PIN_D0;
 
 		lcd.width = 16;
 		lcd.bwidth = 40;
 		lcd.hwidth = 16;
 		lcd.height = 2;
 		break;
 	case LCD_TYPE_NEXCOM:
 		/* parallel mode, 8 bits, generic */
 		lcd.proto = LCD_PROTO_PARALLEL;
 		lcd.charset = LCD_CHARSET_NORMAL;
 		lcd.pins.e = PIN_AUTOLF;
 		lcd.pins.rs = PIN_SELECP;
 		lcd.pins.rw = PIN_INITP;
 
 		lcd.width = 16;
 		lcd.bwidth = 40;
 		lcd.hwidth = 64;
 		lcd.height = 2;
 		break;
 	case LCD_TYPE_CUSTOM:
 		/* customer-defined */
 		lcd.proto = DEFAULT_LCD_PROTO;
 		lcd.charset = DEFAULT_LCD_CHARSET;
 		/* default geometry will be set later */
 		break;
 	case LCD_TYPE_HANTRONIX:
 		/* parallel mode, 8 bits, hantronix-like */
 	default:
 		lcd.proto = LCD_PROTO_PARALLEL;
 		lcd.charset = LCD_CHARSET_NORMAL;
 		lcd.pins.e = PIN_STROBE;
 		lcd.pins.rs = PIN_SELECP;
 
 		lcd.width = 16;
 		lcd.bwidth = 40;
 		lcd.hwidth = 64;
 		lcd.height = 2;
 		break;
 	}
 
 	/* Overwrite with module params set on loading */
 	if (lcd_height != NOT_SET)
 		lcd.height = lcd_height;
 	if (lcd_width != NOT_SET)
 		lcd.width = lcd_width;
 	if (lcd_bwidth != NOT_SET)
 		lcd.bwidth = lcd_bwidth;
 	if (lcd_hwidth != NOT_SET)
 		lcd.hwidth = lcd_hwidth;
 	if (lcd_charset != NOT_SET)
 		lcd.charset = lcd_charset;
 	if (lcd_proto != NOT_SET)
 		lcd.proto = lcd_proto;
 	if (lcd_e_pin != PIN_NOT_SET)
 		lcd.pins.e = lcd_e_pin;
 	if (lcd_rs_pin != PIN_NOT_SET)
 		lcd.pins.rs = lcd_rs_pin;
 	if (lcd_rw_pin != PIN_NOT_SET)
 		lcd.pins.rw = lcd_rw_pin;
 	if (lcd_cl_pin != PIN_NOT_SET)
 		lcd.pins.cl = lcd_cl_pin;
 	if (lcd_da_pin != PIN_NOT_SET)
 		lcd.pins.da = lcd_da_pin;
 	if (lcd_bl_pin != PIN_NOT_SET)
 		lcd.pins.bl = lcd_bl_pin;
 
 	/* this is used to catch wrong and default values */
 	if (lcd.width <= 0)
 		lcd.width = DEFAULT_LCD_WIDTH;
 	if (lcd.bwidth <= 0)
 		lcd.bwidth = DEFAULT_LCD_BWIDTH;
 	if (lcd.hwidth <= 0)
 		lcd.hwidth = DEFAULT_LCD_HWIDTH;
 	if (lcd.height <= 0)
 		lcd.height = DEFAULT_LCD_HEIGHT;
 
 	if (lcd.proto == LCD_PROTO_SERIAL) {	/* SERIAL */
 		lcd_write_cmd = lcd_write_cmd_s;
 		lcd_write_data = lcd_write_data_s;
 		lcd_clear_fast = lcd_clear_fast_s;
 
 		if (lcd.pins.cl == PIN_NOT_SET)
 			lcd.pins.cl = DEFAULT_LCD_PIN_SCL;
 		if (lcd.pins.da == PIN_NOT_SET)
 			lcd.pins.da = DEFAULT_LCD_PIN_SDA;
 
 	} else if (lcd.proto == LCD_PROTO_PARALLEL) {	/* PARALLEL */
 		lcd_write_cmd = lcd_write_cmd_p8;
 		lcd_write_data = lcd_write_data_p8;
 		lcd_clear_fast = lcd_clear_fast_p8;
 
 		if (lcd.pins.e == PIN_NOT_SET)
 			lcd.pins.e = DEFAULT_LCD_PIN_E;
 		if (lcd.pins.rs == PIN_NOT_SET)
 			lcd.pins.rs = DEFAULT_LCD_PIN_RS;
 		if (lcd.pins.rw == PIN_NOT_SET)
 			lcd.pins.rw = DEFAULT_LCD_PIN_RW;
 	} else {
 		lcd_write_cmd = lcd_write_cmd_tilcd;
 		lcd_write_data = lcd_write_data_tilcd;
 		lcd_clear_fast = lcd_clear_fast_tilcd;
 	}
 
 	if (lcd.pins.bl == PIN_NOT_SET)
 		lcd.pins.bl = DEFAULT_LCD_PIN_BL;
 
 	if (lcd.pins.e == PIN_NOT_SET)
 		lcd.pins.e = PIN_NONE;
 	if (lcd.pins.rs == PIN_NOT_SET)
 		lcd.pins.rs = PIN_NONE;
 	if (lcd.pins.rw == PIN_NOT_SET)
 		lcd.pins.rw = PIN_NONE;
 	if (lcd.pins.bl == PIN_NOT_SET)
 		lcd.pins.bl = PIN_NONE;
 	if (lcd.pins.cl == PIN_NOT_SET)
 		lcd.pins.cl = PIN_NONE;
 	if (lcd.pins.da == PIN_NOT_SET)
 		lcd.pins.da = PIN_NONE;
 
 	if (lcd.charset == NOT_SET)
 		lcd.charset = DEFAULT_LCD_CHARSET;
 
 	if (lcd.charset == LCD_CHARSET_KS0074)
 		lcd_char_conv = lcd_char_conv_ks0074;
 	else
 		lcd_char_conv = NULL;
 
-	if (lcd.pins.bl != PIN_NONE)
-		init_scan_timer();
+	if (lcd.pins.bl != PIN_NONE) {
+		mutex_init(&lcd.bl_tempo_lock);
+		INIT_DELAYED_WORK(&lcd.bl_work, lcd_bl_off);
+	}
 
 	pin_to_bits(lcd.pins.e, lcd_bits[LCD_PORT_D][LCD_BIT_E],
 		    lcd_bits[LCD_PORT_C][LCD_BIT_E]);
 	pin_to_bits(lcd.pins.rs, lcd_bits[LCD_PORT_D][LCD_BIT_RS],
 		    lcd_bits[LCD_PORT_C][LCD_BIT_RS]);
 	pin_to_bits(lcd.pins.rw, lcd_bits[LCD_PORT_D][LCD_BIT_RW],
 		    lcd_bits[LCD_PORT_C][LCD_BIT_RW]);
 	pin_to_bits(lcd.pins.bl, lcd_bits[LCD_PORT_D][LCD_BIT_BL],
 		    lcd_bits[LCD_PORT_C][LCD_BIT_BL]);
 	pin_to_bits(lcd.pins.cl, lcd_bits[LCD_PORT_D][LCD_BIT_CL],
 		    lcd_bits[LCD_PORT_C][LCD_BIT_CL]);
 	pin_to_bits(lcd.pins.da, lcd_bits[LCD_PORT_D][LCD_BIT_DA],
 		    lcd_bits[LCD_PORT_C][LCD_BIT_DA]);
 
 	/*
 	 * before this line, we must NOT send anything to the display.
 	 * Since lcd_init_display() needs to write data, we have to
 	 * enable mark the LCD initialized just before.
 	 */
 	lcd.initialized = true;
 	lcd_init_display();
 
 	/* display a short message */
 #ifdef CONFIG_PANEL_CHANGE_MESSAGE
 #ifdef CONFIG_PANEL_BOOT_MESSAGE
 	panel_lcd_print("\x1b[Lc\x1b[Lb\x1b[L*" CONFIG_PANEL_BOOT_MESSAGE);
 #endif
 #else
-	panel_lcd_print("\x1b[Lc\x1b[Lb\x1b[L*Linux-" UTS_RELEASE "\nPanel-"
-			PANEL_VERSION);
+	panel_lcd_print("\x1b[Lc\x1b[Lb\x1b[L*Linux-" UTS_RELEASE);
 #endif
-	lcd.addr.x = 0;
-	lcd.addr.y = 0;
 	/* clear the display on the next device opening */
 	lcd.must_clear = true;
-	lcd_gotoxy();
+	lcd_home();
 }
 
 /*
  * These are the file operation function for user access to /dev/keypad
  */
 
 static ssize_t keypad_read(struct file *file,
 			   char __user *buf, size_t count, loff_t *ppos)
 {
 	unsigned i = *ppos;
 	char __user *tmp = buf;
 
 	if (keypad_buflen == 0) {
 		if (file->f_flags & O_NONBLOCK)
 			return -EAGAIN;
 
 		if (wait_event_interruptible(keypad_read_wait,
 					     keypad_buflen != 0))
 			return -EINTR;
 	}
 
 	for (; count-- > 0 && (keypad_buflen > 0);
 	     ++i, ++tmp, --keypad_buflen) {
 		put_user(keypad_buffer[keypad_start], tmp);
 		keypad_start = (keypad_start + 1) % KEYPAD_BUFFER;
 	}
 	*ppos = i;
 
 	return tmp - buf;
 }
 
 static int keypad_open(struct inode *inode, struct file *file)
 {
 	if (!atomic_dec_and_test(&keypad_available))
 		return -EBUSY;	/* open only once at a time */
 
 	if (file->f_mode & FMODE_WRITE)	/* device is read-only */
 		return -EPERM;
 
 	keypad_buflen = 0;	/* flush the buffer on opening */
 	return 0;
 }
 
 static int keypad_release(struct inode *inode, struct file *file)
 {
 	atomic_inc(&keypad_available);
 	return 0;
 }
 
 static const struct file_operations keypad_fops = {
 	.read    = keypad_read,		/* read */
 	.open    = keypad_open,		/* open */
 	.release = keypad_release,	/* close */
 	.llseek  = default_llseek,
 };
 
 static struct miscdevice keypad_dev = {
 	.minor	= KEYPAD_MINOR,
 	.name	= "keypad",
 	.fops	= &keypad_fops,
 };
 
 static void keypad_send_key(const char *string, int max_len)
 {
 	/* send the key to the device only if a process is attached to it. */
 	if (!atomic_read(&keypad_available)) {
 		while (max_len-- && keypad_buflen < KEYPAD_BUFFER && *string) {
 			keypad_buffer[(keypad_start + keypad_buflen++) %
 				      KEYPAD_BUFFER] = *string++;
 		}
 		wake_up_interruptible(&keypad_read_wait);
 	}
 }
 
 /* this function scans all the bits involving at least one logical signal,
  * and puts the results in the bitfield "phys_read" (one bit per established
  * contact), and sets "phys_read_prev" to "phys_read".
  *
  * Note: to debounce input signals, we will only consider as switched a signal
  * which is stable across 2 measures. Signals which are different between two
  * reads will be kept as they previously were in their logical form (phys_prev).
  * A signal which has just switched will have a 1 in
  * (phys_read ^ phys_read_prev).
  */
 static void phys_scan_contacts(void)
 {
 	int bit, bitval;
 	char oldval;
 	char bitmask;
 	char gndmask;
 
 	phys_prev = phys_curr;
 	phys_read_prev = phys_read;
 	phys_read = 0;		/* flush all signals */
 
 	/* keep track of old value, with all outputs disabled */
 	oldval = r_dtr(pprt) | scan_mask_o;
 	/* activate all keyboard outputs (active low) */
 	w_dtr(pprt, oldval & ~scan_mask_o);
 
 	/* will have a 1 for each bit set to gnd */
 	bitmask = PNL_PINPUT(r_str(pprt)) & scan_mask_i;
 	/* disable all matrix signals */
 	w_dtr(pprt, oldval);
 
 	/* now that all outputs are cleared, the only active input bits are
 	 * directly connected to the ground
 	 */
 
 	/* 1 for each grounded input */
 	gndmask = PNL_PINPUT(r_str(pprt)) & scan_mask_i;
 
 	/* grounded inputs are signals 40-44 */
 	phys_read |= (__u64)gndmask << 40;
 
 	if (bitmask != gndmask) {
 		/*
 		 * since clearing the outputs changed some inputs, we know
 		 * that some input signals are currently tied to some outputs.
 		 * So we'll scan them.
 		 */
 		for (bit = 0; bit < 8; bit++) {
 			bitval = BIT(bit);
 
 			if (!(scan_mask_o & bitval))	/* skip unused bits */
 				continue;
 
 			w_dtr(pprt, oldval & ~bitval);	/* enable this output */
 			bitmask = PNL_PINPUT(r_str(pprt)) & ~gndmask;
 			phys_read |= (__u64)bitmask << (5 * bit);
 		}
 		w_dtr(pprt, oldval);	/* disable all outputs */
 	}
 	/*
 	 * this is easy: use old bits when they are flapping,
 	 * use new ones when stable
 	 */
 	phys_curr = (phys_prev & (phys_read ^ phys_read_prev)) |
 		    (phys_read & ~(phys_read ^ phys_read_prev));
 }
 
 static inline int input_state_high(struct logical_input *input)
 {
 #if 0
 	/* FIXME:
 	 * this is an invalid test. It tries to catch
 	 * transitions from single-key to multiple-key, but
 	 * doesn't take into account the contacts polarity.
 	 * The only solution to the problem is to parse keys
 	 * from the most complex to the simplest combinations,
 	 * and mark them as 'caught' once a combination
 	 * matches, then unmatch it for all other ones.
 	 */
 
 	/* try to catch dangerous transitions cases :
 	 * someone adds a bit, so this signal was a false
 	 * positive resulting from a transition. We should
 	 * invalidate the signal immediately and not call the
 	 * release function.
 	 * eg: 0 -(press A)-> A -(press B)-> AB : don't match A's release.
 	 */
 	if (((phys_prev & input->mask) == input->value) &&
 	    ((phys_curr & input->mask) >  input->value)) {
 		input->state = INPUT_ST_LOW; /* invalidate */
 		return 1;
 	}
 #endif
 
 	if ((phys_curr & input->mask) == input->value) {
 		if ((input->type == INPUT_TYPE_STD) &&
 		    (input->high_timer == 0)) {
 			input->high_timer++;
 			if (input->u.std.press_fct)
 				input->u.std.press_fct(input->u.std.press_data);
 		} else if (input->type == INPUT_TYPE_KBD) {
 			/* will turn on the light */
 			keypressed = 1;
 
 			if (input->high_timer == 0) {
 				char *press_str = input->u.kbd.press_str;
 
 				if (press_str[0]) {
 					int s = sizeof(input->u.kbd.press_str);
 
 					keypad_send_key(press_str, s);
 				}
 			}
 
 			if (input->u.kbd.repeat_str[0]) {
 				char *repeat_str = input->u.kbd.repeat_str;
 
 				if (input->high_timer >= KEYPAD_REP_START) {
 					int s = sizeof(input->u.kbd.repeat_str);
 
 					input->high_timer -= KEYPAD_REP_DELAY;
 					keypad_send_key(repeat_str, s);
 				}
 				/* we will need to come back here soon */
 				inputs_stable = 0;
 			}
 
 			if (input->high_timer < 255)
 				input->high_timer++;
 		}
 		return 1;
 	}
 
 	/* else signal falling down. Let's fall through. */
 	input->state = INPUT_ST_FALLING;
 	input->fall_timer = 0;
 
 	return 0;
 }
 
 static inline void input_state_falling(struct logical_input *input)
 {
 #if 0
 	/* FIXME !!! same comment as in input_state_high */
 	if (((phys_prev & input->mask) == input->value) &&
 	    ((phys_curr & input->mask) >  input->value)) {
 		input->state = INPUT_ST_LOW;	/* invalidate */
 		return;
 	}
 #endif
 
 	if ((phys_curr & input->mask) == input->value) {
 		if (input->type == INPUT_TYPE_KBD) {
 			/* will turn on the light */
 			keypressed = 1;
 
 			if (input->u.kbd.repeat_str[0]) {
 				char *repeat_str = input->u.kbd.repeat_str;
 
 				if (input->high_timer >= KEYPAD_REP_START) {
 					int s = sizeof(input->u.kbd.repeat_str);
 
 					input->high_timer -= KEYPAD_REP_DELAY;
 					keypad_send_key(repeat_str, s);
 				}
 				/* we will need to come back here soon */
 				inputs_stable = 0;
 			}
 
 			if (input->high_timer < 255)
 				input->high_timer++;
 		}
 		input->state = INPUT_ST_HIGH;
 	} else if (input->fall_timer >= input->fall_time) {
 		/* call release event */
 		if (input->type == INPUT_TYPE_STD) {
 			void (*release_fct)(int) = input->u.std.release_fct;
 
 			if (release_fct)
 				release_fct(input->u.std.release_data);
 		} else if (input->type == INPUT_TYPE_KBD) {
 			char *release_str = input->u.kbd.release_str;
 
 			if (release_str[0]) {
 				int s = sizeof(input->u.kbd.release_str);
 
 				keypad_send_key(release_str, s);
 			}
 		}
 
 		input->state = INPUT_ST_LOW;
 	} else {
 		input->fall_timer++;
 		inputs_stable = 0;
 	}
 }
 
 static void panel_process_inputs(void)
 {
 	struct list_head *item;
 	struct logical_input *input;
 
 	keypressed = 0;
 	inputs_stable = 1;
 	list_for_each(item, &logical_inputs) {
 		input = list_entry(item, struct logical_input, list);
 
 		switch (input->state) {
 		case INPUT_ST_LOW:
 			if ((phys_curr & input->mask) != input->value)
 				break;
 			/* if all needed ones were already set previously,
 			 * this means that this logical signal has been
 			 * activated by the releasing of another combined
 			 * signal, so we don't want to match.
 			 * eg: AB -(release B)-> A -(release A)-> 0 :
 			 *     don't match A.
 			 */
 			if ((phys_prev & input->mask) == input->value)
 				break;
 			input->rise_timer = 0;
 			input->state = INPUT_ST_RISING;
 			/* no break here, fall through */
 		case INPUT_ST_RISING:
 			if ((phys_curr & input->mask) != input->value) {
 				input->state = INPUT_ST_LOW;
 				break;
 			}
 			if (input->rise_timer < input->rise_time) {
 				inputs_stable = 0;
 				input->rise_timer++;
 				break;
 			}
 			input->high_timer = 0;
 			input->state = INPUT_ST_HIGH;
 			/* no break here, fall through */
 		case INPUT_ST_HIGH:
 			if (input_state_high(input))
 				break;
 			/* no break here, fall through */
 		case INPUT_ST_FALLING:
 			input_state_falling(input);
 		}
 	}
 }
 
 static void panel_scan_timer(void)
 {
 	if (keypad.enabled && keypad_initialized) {
 		if (spin_trylock_irq(&pprt_lock)) {
 			phys_scan_contacts();
 
 			/* no need for the parport anymore */
 			spin_unlock_irq(&pprt_lock);
 		}
 
 		if (!inputs_stable || phys_curr != phys_prev)
 			panel_process_inputs();
 	}
 
-	if (lcd.enabled && lcd.initialized) {
-		if (keypressed) {
-			if (lcd.light_tempo == 0 &&
-			    ((lcd.flags & LCD_FLAG_L) == 0))
-				lcd_backlight(1);
-			lcd.light_tempo = FLASH_LIGHT_TEMPO;
-		} else if (lcd.light_tempo > 0) {
-			lcd.light_tempo--;
-			if (lcd.light_tempo == 0 &&
-			    ((lcd.flags & LCD_FLAG_L) == 0))
-				lcd_backlight(0);
-		}
-	}
+	if (keypressed && lcd.enabled && lcd.initialized)
+		lcd_poke();
 
 	mod_timer(&scan_timer, jiffies + INPUT_POLL_TIME);
 }
 
 static void init_scan_timer(void)
 {
 	if (scan_timer.function)
 		return;		/* already started */
 
 	setup_timer(&scan_timer, (void *)&panel_scan_timer, 0);
 	scan_timer.expires = jiffies + INPUT_POLL_TIME;
 	add_timer(&scan_timer);
 }
 
 /* converts a name of the form "({BbAaPpSsEe}{01234567-})*" to a series of bits.
  * if <omask> or <imask> are non-null, they will be or'ed with the bits
  * corresponding to out and in bits respectively.
  * returns 1 if ok, 0 if error (in which case, nothing is written).
  */
 static u8 input_name2mask(const char *name, __u64 *mask, __u64 *value,
 			  u8 *imask, u8 *omask)
 {
 	const char sigtab[] = "EeSsPpAaBb";
 	u8 im, om;
 	__u64 m, v;
 
 	om = 0;
 	im = 0;
 	m = 0ULL;
 	v = 0ULL;
 	while (*name) {
 		int in, out, bit, neg;
 		const char *idx;
 
 		idx = strchr(sigtab, *name);
 		if (!idx)
 			return 0;	/* input name not found */
 
 		in = idx - sigtab;
 		neg = (in & 1);	/* odd (lower) names are negated */
 		in >>= 1;
 		im |= BIT(in);
 
 		name++;
 		if (*name >= '0' && *name <= '7') {
 			out = *name - '0';
 			om |= BIT(out);
 		} else if (*name == '-') {
 			out = 8;
 		} else {
 			return 0;	/* unknown bit name */
 		}
 
 		bit = (out * 5) + in;
 
 		m |= 1ULL << bit;
 		if (!neg)
 			v |= 1ULL << bit;
 		name++;
 	}
 	*mask = m;
 	*value = v;
 	if (imask)
 		*imask |= im;
 	if (omask)
 		*omask |= om;
 	return 1;
 }
 
 /* tries to bind a key to the signal name <name>. The key will send the
  * strings <press>, <repeat>, <release> for these respective events.
  * Returns the pointer to the new key if ok, NULL if the key could not be bound.
  */
 static struct logical_input *panel_bind_key(const char *name, const char *press,
 					    const char *repeat,
 					    const char *release)
 {
 	struct logical_input *key;
 
 	key = kzalloc(sizeof(*key), GFP_KERNEL);
 	if (!key)
 		return NULL;
 
 	if (!input_name2mask(name, &key->mask, &key->value, &scan_mask_i,
 			     &scan_mask_o)) {
 		kfree(key);
 		return NULL;
 	}
 
 	key->type = INPUT_TYPE_KBD;
 	key->state = INPUT_ST_LOW;
 	key->rise_time = 1;
 	key->fall_time = 1;
 
 	strncpy(key->u.kbd.press_str, press, sizeof(key->u.kbd.press_str));
 	strncpy(key->u.kbd.repeat_str, repeat, sizeof(key->u.kbd.repeat_str));
 	strncpy(key->u.kbd.release_str, release,
 		sizeof(key->u.kbd.release_str));
 	list_add(&key->list, &logical_inputs);
 	return key;
 }
 
 #if 0
 /* tries to bind a callback function to the signal name <name>. The function
  * <press_fct> will be called with the <press_data> arg when the signal is
  * activated, and so on for <release_fct>/<release_data>
  * Returns the pointer to the new signal if ok, NULL if the signal could not
  * be bound.
  */
 static struct logical_input *panel_bind_callback(char *name,
 						 void (*press_fct)(int),
 						 int press_data,
 						 void (*release_fct)(int),
 						 int release_data)
 {
 	struct logical_input *callback;
 
 	callback = kmalloc(sizeof(*callback), GFP_KERNEL);
 	if (!callback)
 		return NULL;
 
 	memset(callback, 0, sizeof(struct logical_input));
 	if (!input_name2mask(name, &callback->mask, &callback->value,
 			     &scan_mask_i, &scan_mask_o))
 		return NULL;
 
 	callback->type = INPUT_TYPE_STD;
 	callback->state = INPUT_ST_LOW;
 	callback->rise_time = 1;
 	callback->fall_time = 1;
 	callback->u.std.press_fct = press_fct;
 	callback->u.std.press_data = press_data;
 	callback->u.std.release_fct = release_fct;
 	callback->u.std.release_data = release_data;
 	list_add(&callback->list, &logical_inputs);
 	return callback;
 }
 #endif
 
 static void keypad_init(void)
 {
 	int keynum;
 
 	init_waitqueue_head(&keypad_read_wait);
 	keypad_buflen = 0;	/* flushes any eventual noisy keystroke */
 
 	/* Let's create all known keys */
 
 	for (keynum = 0; keypad_profile[keynum][0][0]; keynum++) {
 		panel_bind_key(keypad_profile[keynum][0],
 			       keypad_profile[keynum][1],
 			       keypad_profile[keynum][2],
 			       keypad_profile[keynum][3]);
 	}
 
 	init_scan_timer();
 	keypad_initialized = 1;
 }
 
 /**************************************************/
 /* device initialization                          */
 /**************************************************/
 
 static int panel_notify_sys(struct notifier_block *this, unsigned long code,
 			    void *unused)
 {
 	if (lcd.enabled && lcd.initialized) {
 		switch (code) {
 		case SYS_DOWN:
 			panel_lcd_print
 			    ("\x0cReloading\nSystem...\x1b[Lc\x1b[Lb\x1b[L+");
 			break;
 		case SYS_HALT:
 			panel_lcd_print
 			    ("\x0cSystem Halted.\x1b[Lc\x1b[Lb\x1b[L+");
 			break;
 		case SYS_POWER_OFF:
 			panel_lcd_print("\x0cPower off.\x1b[Lc\x1b[Lb\x1b[L+");
 			break;
 		default:
 			break;
 		}
 	}
 	return NOTIFY_DONE;
 }
 
 static struct notifier_block panel_notifier = {
 	panel_notify_sys,
 	NULL,
 	0
 };
 
 static void panel_attach(struct parport *port)
 {
 	struct pardev_cb panel_cb;
 
 	if (port->number != parport)
 		return;
 
 	if (pprt) {
 		pr_err("%s: port->number=%d parport=%d, already registered!\n",
 		       __func__, port->number, parport);
 		return;
 	}
 
 	memset(&panel_cb, 0, sizeof(panel_cb));
 	panel_cb.private = &pprt;
 	/* panel_cb.flags = 0 should be PARPORT_DEV_EXCL? */
 
 	pprt = parport_register_dev_model(port, "panel", &panel_cb, 0);
 	if (!pprt) {
 		pr_err("%s: port->number=%d parport=%d, parport_register_device() failed\n",
 		       __func__, port->number, parport);
 		return;
 	}
 
 	if (parport_claim(pprt)) {
 		pr_err("could not claim access to parport%d. Aborting.\n",
 		       parport);
 		goto err_unreg_device;
 	}
 
 	/* must init LCD first, just in case an IRQ from the keypad is
 	 * generated at keypad init
 	 */
 	if (lcd.enabled) {
 		lcd_init();
 		if (misc_register(&lcd_dev))
 			goto err_unreg_device;
 	}
 
 	if (keypad.enabled) {
 		keypad_init();
 		if (misc_register(&keypad_dev))
 			goto err_lcd_unreg;
 	}
 	register_reboot_notifier(&panel_notifier);
 	return;
 
 err_lcd_unreg:
 	if (lcd.enabled)
 		misc_deregister(&lcd_dev);
 err_unreg_device:
 	parport_unregister_device(pprt);
 	pprt = NULL;
 }
 
 static void panel_detach(struct parport *port)
 {
 	if (port->number != parport)
 		return;
 
 	if (!pprt) {
 		pr_err("%s: port->number=%d parport=%d, nothing to unregister.\n",
 		       __func__, port->number, parport);
 		return;
 	}
 	if (scan_timer.function)
 		del_timer_sync(&scan_timer);
 
-	if (pprt) {
-		if (keypad.enabled) {
-			misc_deregister(&keypad_dev);
-			keypad_initialized = 0;
-		}
+	if (keypad.enabled) {
+		misc_deregister(&keypad_dev);
+		keypad_initialized = 0;
+	}
 
-		if (lcd.enabled) {
-			panel_lcd_print("\x0cLCD driver " PANEL_VERSION
-					"\nunloaded.\x1b[Lc\x1b[Lb\x1b[L-");
-			misc_deregister(&lcd_dev);
-			lcd.initialized = false;
+	if (lcd.enabled) {
+		panel_lcd_print("\x0cLCD driver unloaded.\x1b[Lc\x1b[Lb\x1b[L-");
+		misc_deregister(&lcd_dev);
+		if (lcd.pins.bl != PIN_NONE) {
+			cancel_delayed_work_sync(&lcd.bl_work);
+			__lcd_backlight(0);
 		}
-
-		/* TODO: free all input signals */
-		parport_release(pprt);
-		parport_unregister_device(pprt);
-		pprt = NULL;
-		unregister_reboot_notifier(&panel_notifier);
+		lcd.initialized = false;
 	}
+
+	/* TODO: free all input signals */
+	parport_release(pprt);
+	parport_unregister_device(pprt);
+	pprt = NULL;
+	unregister_reboot_notifier(&panel_notifier);
 }
 
 static struct parport_driver panel_driver = {
 	.name = "panel",
 	.match_port = panel_attach,
 	.detach = panel_detach,
 	.devmodel = true,
 };
 
 /* init function */
 static int __init panel_init_module(void)
 {
 	int selected_keypad_type = NOT_SET, err;
 
 	/* take care of an eventual profile */
 	switch (profile) {
 	case PANEL_PROFILE_CUSTOM:
 		/* custom profile */
 		selected_keypad_type = DEFAULT_KEYPAD_TYPE;
 		selected_lcd_type = DEFAULT_LCD_TYPE;
 		break;
 	case PANEL_PROFILE_OLD:
 		/* 8 bits, 2*16, old keypad */
 		selected_keypad_type = KEYPAD_TYPE_OLD;
 		selected_lcd_type = LCD_TYPE_OLD;
 
 		/* TODO: This two are a little hacky, sort it out later */
 		if (lcd_width == NOT_SET)
 			lcd_width = 16;
 		if (lcd_hwidth == NOT_SET)
 			lcd_hwidth = 16;
 		break;
 	case PANEL_PROFILE_NEW:
 		/* serial, 2*16, new keypad */
 		selected_keypad_type = KEYPAD_TYPE_NEW;
 		selected_lcd_type = LCD_TYPE_KS0074;
 		break;
 	case PANEL_PROFILE_HANTRONIX:
 		/* 8 bits, 2*16 hantronix-like, no keypad */
 		selected_keypad_type = KEYPAD_TYPE_NONE;
 		selected_lcd_type = LCD_TYPE_HANTRONIX;
 		break;
 	case PANEL_PROFILE_NEXCOM:
 		/* generic 8 bits, 2*16, nexcom keypad, eg. Nexcom. */
 		selected_keypad_type = KEYPAD_TYPE_NEXCOM;
 		selected_lcd_type = LCD_TYPE_NEXCOM;
 		break;
 	case PANEL_PROFILE_LARGE:
 		/* 8 bits, 2*40, old keypad */
 		selected_keypad_type = KEYPAD_TYPE_OLD;
 		selected_lcd_type = LCD_TYPE_OLD;
 		break;
 	}
 
 	/*
 	 * Overwrite selection with module param values (both keypad and lcd),
 	 * where the deprecated params have lower prio.
 	 */
 	if (keypad_enabled != NOT_SET)
 		selected_keypad_type = keypad_enabled;
 	if (keypad_type != NOT_SET)
 		selected_keypad_type = keypad_type;
 
 	keypad.enabled = (selected_keypad_type > 0);
 
 	if (lcd_enabled != NOT_SET)
 		selected_lcd_type = lcd_enabled;
 	if (lcd_type != NOT_SET)
 		selected_lcd_type = lcd_type;
 
 	lcd.enabled = (selected_lcd_type > 0);
 
 	if (lcd.enabled) {
 		/*
 		 * Init lcd struct with load-time values to preserve exact
 		 * current functionality (at least for now).
 		 */
 		lcd.height = lcd_height;
 		lcd.width = lcd_width;
 		lcd.bwidth = lcd_bwidth;
 		lcd.hwidth = lcd_hwidth;
 		lcd.charset = lcd_charset;
 		lcd.proto = lcd_proto;
 		lcd.pins.e = lcd_e_pin;
 		lcd.pins.rs = lcd_rs_pin;
 		lcd.pins.rw = lcd_rw_pin;
 		lcd.pins.cl = lcd_cl_pin;
 		lcd.pins.da = lcd_da_pin;
 		lcd.pins.bl = lcd_bl_pin;
 
 		/* Leave it for now, just in case */
 		lcd.esc_seq.len = -1;
 	}
 
 	switch (selected_keypad_type) {
 	case KEYPAD_TYPE_OLD:
 		keypad_profile = old_keypad_profile;
 		break;
 	case KEYPAD_TYPE_NEW:
 		keypad_profile = new_keypad_profile;
 		break;
 	case KEYPAD_TYPE_NEXCOM:
 		keypad_profile = nexcom_keypad_profile;
 		break;
 	default:
 		keypad_profile = NULL;
 		break;
 	}
 
 	if (!lcd.enabled && !keypad.enabled) {
 		/* no device enabled, let's exit */
-		pr_err("driver version " PANEL_VERSION " disabled.\n");
+		pr_err("panel driver disabled.\n");
 		return -ENODEV;
 	}
 
 	err = parport_register_driver(&panel_driver);
 	if (err) {
 		pr_err("could not register with parport. Aborting.\n");
 		return err;
 	}
 
 	if (pprt)
-		pr_info("driver version " PANEL_VERSION
-			" registered on parport%d (io=0x%lx).\n", parport,
-			pprt->port->base);
+		pr_info("panel driver registered on parport%d (io=0x%lx).\n",
+			parport, pprt->port->base);
 	else
-		pr_info("driver version " PANEL_VERSION
-			" not yet registered\n");
+		pr_info("panel driver not yet registered\n");
 	return 0;
 }
 
 static void __exit panel_cleanup_module(void)
 {
 	parport_unregister_driver(&panel_driver);
 }
 
 module_init(panel_init_module);
 module_exit(panel_cleanup_module);
 MODULE_AUTHOR("Willy Tarreau");
 MODULE_LICENSE("GPL");
 
 /*
  * Local variables:
  *  c-indent-level: 4
  *  tab-width: 8
  * End:
  */
diff --git a/drivers/misc/sram-exec.c b/drivers/misc/sram-exec.c
new file mode 100644
index 000000000000..ac522417c462
--- /dev/null
+++ b/drivers/misc/sram-exec.c
@@ -0,0 +1,105 @@
+/*
+ * SRAM protect-exec region helper functions
+ *
+ * Copyright (C) 2017 Texas Instruments Incorporated - http://www.ti.com/
+ *	Dave Gerlach
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed "as is" WITHOUT ANY WARRANTY of any
+ * kind, whether express or implied; without even the implied warranty
+ * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/device.h>
+#include <linux/genalloc.h>
+#include <linux/sram.h>
+
+#include <asm/cacheflush.h>
+
+#include "sram.h"
+
+static DEFINE_MUTEX(exec_pool_list_mutex);
+static LIST_HEAD(exec_pool_list);
+
+int sram_check_protect_exec(struct sram_dev *sram, struct sram_reserve *block,
+			    struct sram_partition *part)
+{
+	unsigned long base = (unsigned long)part->base;
+	unsigned long end = base + block->size;
+
+	if (!PAGE_ALIGNED(base) || !PAGE_ALIGNED(end)) {
+		dev_err(sram->dev,
+			"SRAM pool marked with 'protect-exec' is not page aligned and will not be created.\n");
+		return -ENOMEM;
+	}
+
+	return 0;
+}
+
+int sram_add_protect_exec(struct sram_partition *part)
+{
+	mutex_lock(&exec_pool_list_mutex);
+	list_add_tail(&part->list, &exec_pool_list);
+	mutex_unlock(&exec_pool_list_mutex);
+
+	return 0;
+}
+
+/**
+ * sram_exec_copy - copy data to a protected executable region of sram
+ *
+ * @pool: struct gen_pool retrieved that is part of this sram
+ * @dst: Destination address for the copy, that must be inside pool
+ * @src: Source address for the data to copy
+ * @size: Size of copy to perform, which starting from dst, must reside in pool
+ *
+ * This helper function allows sram driver to act as central control location
+ * of 'protect-exec' pools which are normal sram pools but are always set
+ * read-only and executable except when copying data to them, at which point
+ * they are set to read-write non-executable, to make sure no memory is
+ * writeable and executable at the same time. This region must be page-aligned
+ * and is checked during probe, otherwise page attribute manipulation would
+ * not be possible.
+ */
+int sram_exec_copy(struct gen_pool *pool, void *dst, void *src,
+		   size_t size)
+{
+	struct sram_partition *part = NULL, *p;
+	unsigned long base;
+	int pages;
+
+	mutex_lock(&exec_pool_list_mutex);
+	list_for_each_entry(p, &exec_pool_list, list) {
+		if (p->pool == pool)
+			part = p;
+	}
+	mutex_unlock(&exec_pool_list_mutex);
+
+	if (!part)
+		return -EINVAL;
+
+	if (!addr_in_gen_pool(pool, (unsigned long)dst, size))
+		return -EINVAL;
+
+	base = (unsigned long)part->base;
+	pages = PAGE_ALIGN(size) / PAGE_SIZE;
+
+	mutex_lock(&part->lock);
+
+	set_memory_nx((unsigned long)base, pages);
+	set_memory_rw((unsigned long)base, pages);
+
+	memcpy(dst, src, size);
+
+	set_memory_ro((unsigned long)base, pages);
+	set_memory_x((unsigned long)base, pages);
+
+	mutex_unlock(&part->lock);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(sram_exec_copy);
diff --git a/drivers/misc/sram.c b/drivers/misc/sram.c
index b33ab8ce47ab..d1185b78cf9a 100644
--- a/drivers/misc/sram.c
+++ b/drivers/misc/sram.c
@@ -1,455 +1,448 @@
 /*
  * Generic on-chip SRAM allocation driver
  *
  * Copyright (C) 2012 Philipp Zabel, Pengutronix
  *
  * This program is free software; you can redistribute it and/or
  * modify it under the terms of the GNU General Public License
  * as published by the Free Software Foundation; either version 2
  * of the License, or (at your option) any later version.
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
  *
  * You should have received a copy of the GNU General Public License
  * along with this program; if not, write to the Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
  * MA 02110-1301, USA.
  */
 
 #include <linux/clk.h>
 #include <linux/delay.h>
 #include <linux/genalloc.h>
 #include <linux/io.h>
 #include <linux/list_sort.h>
 #include <linux/of_address.h>
 #include <linux/of_device.h>
 #include <linux/platform_device.h>
 #include <linux/regmap.h>
 #include <linux/slab.h>
 #include <linux/mfd/syscon.h>
 #include <soc/at91/atmel-secumod.h>
 
-#define SRAM_GRANULARITY	32
-
-struct sram_partition {
-	void __iomem *base;
-
-	struct gen_pool *pool;
-	struct bin_attribute battr;
-	struct mutex lock;
-};
-
-struct sram_dev {
-	struct device *dev;
-	void __iomem *virt_base;
-
-	struct gen_pool *pool;
-	struct clk *clk;
+#include "sram.h"
 
-	struct sram_partition *partition;
-	u32 partitions;
-};
-
-struct sram_reserve {
-	struct list_head list;
-	u32 start;
-	u32 size;
-	bool export;
-	bool pool;
-	const char *label;
-};
+#define SRAM_GRANULARITY	32
 
 static ssize_t sram_read(struct file *filp, struct kobject *kobj,
 			 struct bin_attribute *attr,
 			 char *buf, loff_t pos, size_t count)
 {
 	struct sram_partition *part;
 
 	part = container_of(attr, struct sram_partition, battr);
 
 	mutex_lock(&part->lock);
 	memcpy_fromio(buf, part->base + pos, count);
 	mutex_unlock(&part->lock);
 
 	return count;
 }
 
 static ssize_t sram_write(struct file *filp, struct kobject *kobj,
 			  struct bin_attribute *attr,
 			  char *buf, loff_t pos, size_t count)
 {
 	struct sram_partition *part;
 
 	part = container_of(attr, struct sram_partition, battr);
 
 	mutex_lock(&part->lock);
 	memcpy_toio(part->base + pos, buf, count);
 	mutex_unlock(&part->lock);
 
 	return count;
 }
 
 static int sram_add_pool(struct sram_dev *sram, struct sram_reserve *block,
 			 phys_addr_t start, struct sram_partition *part)
 {
 	int ret;
 
 	part->pool = devm_gen_pool_create(sram->dev, ilog2(SRAM_GRANULARITY),
 					  NUMA_NO_NODE, block->label);
 	if (IS_ERR(part->pool))
 		return PTR_ERR(part->pool);
 
 	ret = gen_pool_add_virt(part->pool, (unsigned long)part->base, start,
 				block->size, NUMA_NO_NODE);
 	if (ret < 0) {
 		dev_err(sram->dev, "failed to register subpool: %d\n", ret);
 		return ret;
 	}
 
 	return 0;
 }
 
 static int sram_add_export(struct sram_dev *sram, struct sram_reserve *block,
 			   phys_addr_t start, struct sram_partition *part)
 {
 	sysfs_bin_attr_init(&part->battr);
 	part->battr.attr.name = devm_kasprintf(sram->dev, GFP_KERNEL,
 					       "%llx.sram",
 					       (unsigned long long)start);
 	if (!part->battr.attr.name)
 		return -ENOMEM;
 
 	part->battr.attr.mode = S_IRUSR | S_IWUSR;
 	part->battr.read = sram_read;
 	part->battr.write = sram_write;
 	part->battr.size = block->size;
 
 	return device_create_bin_file(sram->dev, &part->battr);
 }
 
 static int sram_add_partition(struct sram_dev *sram, struct sram_reserve *block,
 			      phys_addr_t start)
 {
 	int ret;
 	struct sram_partition *part = &sram->partition[sram->partitions];
 
 	mutex_init(&part->lock);
 	part->base = sram->virt_base + block->start;
 
 	if (block->pool) {
 		ret = sram_add_pool(sram, block, start, part);
 		if (ret)
 			return ret;
 	}
 	if (block->export) {
 		ret = sram_add_export(sram, block, start, part);
 		if (ret)
 			return ret;
 	}
+	if (block->protect_exec) {
+		ret = sram_check_protect_exec(sram, block, part);
+		if (ret)
+			return ret;
+
+		ret = sram_add_pool(sram, block, start, part);
+		if (ret)
+			return ret;
+
+		sram_add_protect_exec(part);
+	}
+
 	sram->partitions++;
 
 	return 0;
 }
 
 static void sram_free_partitions(struct sram_dev *sram)
 {
 	struct sram_partition *part;
 
 	if (!sram->partitions)
 		return;
 
 	part = &sram->partition[sram->partitions - 1];
 	for (; sram->partitions; sram->partitions--, part--) {
 		if (part->battr.size)
 			device_remove_bin_file(sram->dev, &part->battr);
 
 		if (part->pool &&
 		    gen_pool_avail(part->pool) < gen_pool_size(part->pool))
 			dev_err(sram->dev, "removed pool while SRAM allocated\n");
 	}
 }
 
 static int sram_reserve_cmp(void *priv, struct list_head *a,
 					struct list_head *b)
 {
 	struct sram_reserve *ra = list_entry(a, struct sram_reserve, list);
 	struct sram_reserve *rb = list_entry(b, struct sram_reserve, list);
 
 	return ra->start - rb->start;
 }
 
 static int sram_reserve_regions(struct sram_dev *sram, struct resource *res)
 {
 	struct device_node *np = sram->dev->of_node, *child;
 	unsigned long size, cur_start, cur_size;
 	struct sram_reserve *rblocks, *block;
 	struct list_head reserve_list;
 	unsigned int nblocks, exports = 0;
 	const char *label;
 	int ret = 0;
 
 	INIT_LIST_HEAD(&reserve_list);
 
 	size = resource_size(res);
 
 	/*
 	 * We need an additional block to mark the end of the memory region
 	 * after the reserved blocks from the dt are processed.
 	 */
 	nblocks = (np) ? of_get_available_child_count(np) + 1 : 1;
 	rblocks = kzalloc((nblocks) * sizeof(*rblocks), GFP_KERNEL);
 	if (!rblocks)
 		return -ENOMEM;
 
 	block = &rblocks[0];
 	for_each_available_child_of_node(np, child) {
 		struct resource child_res;
 
 		ret = of_address_to_resource(child, 0, &child_res);
 		if (ret < 0) {
 			dev_err(sram->dev,
 				"could not get address for node %s\n",
 				child->full_name);
 			goto err_chunks;
 		}
 
 		if (child_res.start < res->start || child_res.end > res->end) {
 			dev_err(sram->dev,
 				"reserved block %s outside the sram area\n",
 				child->full_name);
 			ret = -EINVAL;
 			goto err_chunks;
 		}
 
 		block->start = child_res.start - res->start;
 		block->size = resource_size(&child_res);
 		list_add_tail(&block->list, &reserve_list);
 
 		if (of_find_property(child, "export", NULL))
 			block->export = true;
 
 		if (of_find_property(child, "pool", NULL))
 			block->pool = true;
 
-		if ((block->export || block->pool) && block->size) {
+		if (of_find_property(child, "protect-exec", NULL))
+			block->protect_exec = true;
+
+		if ((block->export || block->pool || block->protect_exec) &&
+		    block->size) {
 			exports++;
 
 			label = NULL;
 			ret = of_property_read_string(child, "label", &label);
 			if (ret && ret != -EINVAL) {
 				dev_err(sram->dev,
 					"%s has invalid label name\n",
 					child->full_name);
 				goto err_chunks;
 			}
 			if (!label)
 				label = child->name;
 
 			block->label = devm_kstrdup(sram->dev,
 						    label, GFP_KERNEL);
-			if (!block->label)
+			if (!block->label) {
+				ret = -ENOMEM;
 				goto err_chunks;
+			}
 
 			dev_dbg(sram->dev, "found %sblock '%s' 0x%x-0x%x\n",
 				block->export ? "exported " : "", block->label,
 				block->start, block->start + block->size);
 		} else {
 			dev_dbg(sram->dev, "found reserved block 0x%x-0x%x\n",
 				block->start, block->start + block->size);
 		}
 
 		block++;
 	}
 	child = NULL;
 
 	/* the last chunk marks the end of the region */
 	rblocks[nblocks - 1].start = size;
 	rblocks[nblocks - 1].size = 0;
 	list_add_tail(&rblocks[nblocks - 1].list, &reserve_list);
 
 	list_sort(NULL, &reserve_list, sram_reserve_cmp);
 
 	if (exports) {
 		sram->partition = devm_kzalloc(sram->dev,
 				       exports * sizeof(*sram->partition),
 				       GFP_KERNEL);
 		if (!sram->partition) {
 			ret = -ENOMEM;
 			goto err_chunks;
 		}
 	}
 
 	cur_start = 0;
 	list_for_each_entry(block, &reserve_list, list) {
 		/* can only happen if sections overlap */
 		if (block->start < cur_start) {
 			dev_err(sram->dev,
 				"block at 0x%x starts after current offset 0x%lx\n",
 				block->start, cur_start);
 			ret = -EINVAL;
 			sram_free_partitions(sram);
 			goto err_chunks;
 		}
 
-		if ((block->export || block->pool) && block->size) {
+		if ((block->export || block->pool || block->protect_exec) &&
+		    block->size) {
 			ret = sram_add_partition(sram, block,
 						 res->start + block->start);
 			if (ret) {
 				sram_free_partitions(sram);
 				goto err_chunks;
 			}
 		}
 
 		/* current start is in a reserved block, so continue after it */
 		if (block->start == cur_start) {
 			cur_start = block->start + block->size;
 			continue;
 		}
 
 		/*
 		 * allocate the space between the current starting
 		 * address and the following reserved block, or the
 		 * end of the region.
 		 */
 		cur_size = block->start - cur_start;
 
 		dev_dbg(sram->dev, "adding chunk 0x%lx-0x%lx\n",
 			cur_start, cur_start + cur_size);
 
 		ret = gen_pool_add_virt(sram->pool,
 				(unsigned long)sram->virt_base + cur_start,
 				res->start + cur_start, cur_size, -1);
 		if (ret < 0) {
 			sram_free_partitions(sram);
 			goto err_chunks;
 		}
 
 		/* next allocation after this reserved block */
 		cur_start = block->start + block->size;
 	}
 
  err_chunks:
 	if (child)
 		of_node_put(child);
 
 	kfree(rblocks);
 
 	return ret;
 }
 
 static int atmel_securam_wait(void)
 {
 	struct regmap *regmap;
 	u32 val;
 
 	regmap = syscon_regmap_lookup_by_compatible("atmel,sama5d2-secumod");
 	if (IS_ERR(regmap))
 		return -ENODEV;
 
 	return regmap_read_poll_timeout(regmap, AT91_SECUMOD_RAMRDY, val,
 					val & AT91_SECUMOD_RAMRDY_READY,
 					10000, 500000);
 }
 
 static const struct of_device_id sram_dt_ids[] = {
 	{ .compatible = "mmio-sram" },
 	{ .compatible = "atmel,sama5d2-securam", .data = atmel_securam_wait },
 	{}
 };
 
 static int sram_probe(struct platform_device *pdev)
 {
 	struct sram_dev *sram;
 	struct resource *res;
 	size_t size;
 	int ret;
 	int (*init_func)(void);
 
 	sram = devm_kzalloc(&pdev->dev, sizeof(*sram), GFP_KERNEL);
 	if (!sram)
 		return -ENOMEM;
 
 	sram->dev = &pdev->dev;
 
 	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
 	if (!res) {
 		dev_err(sram->dev, "found no memory resource\n");
 		return -EINVAL;
 	}
 
 	size = resource_size(res);
 
 	if (!devm_request_mem_region(sram->dev, res->start, size, pdev->name)) {
 		dev_err(sram->dev, "could not request region for resource\n");
 		return -EBUSY;
 	}
 
 	if (of_property_read_bool(pdev->dev.of_node, "no-memory-wc"))
 		sram->virt_base = devm_ioremap(sram->dev, res->start, size);
 	else
 		sram->virt_base = devm_ioremap_wc(sram->dev, res->start, size);
 	if (!sram->virt_base)
 		return -ENOMEM;
 
 	sram->pool = devm_gen_pool_create(sram->dev, ilog2(SRAM_GRANULARITY),
 					  NUMA_NO_NODE, NULL);
 	if (IS_ERR(sram->pool))
 		return PTR_ERR(sram->pool);
 
 	ret = sram_reserve_regions(sram, res);
 	if (ret)
 		return ret;
 
 	sram->clk = devm_clk_get(sram->dev, NULL);
 	if (IS_ERR(sram->clk))
 		sram->clk = NULL;
 	else
 		clk_prepare_enable(sram->clk);
 
 	platform_set_drvdata(pdev, sram);
 
 	init_func = of_device_get_match_data(&pdev->dev);
 	if (init_func) {
 		ret = init_func();
 		if (ret)
 			return ret;
 	}
 
 	dev_dbg(sram->dev, "SRAM pool: %zu KiB @ 0x%p\n",
 		gen_pool_size(sram->pool) / 1024, sram->virt_base);
 
 	return 0;
 }
 
 static int sram_remove(struct platform_device *pdev)
 {
 	struct sram_dev *sram = platform_get_drvdata(pdev);
 
 	sram_free_partitions(sram);
 
 	if (gen_pool_avail(sram->pool) < gen_pool_size(sram->pool))
 		dev_err(sram->dev, "removed while SRAM allocated\n");
 
 	if (sram->clk)
 		clk_disable_unprepare(sram->clk);
 
 	return 0;
 }
 
 static struct platform_driver sram_driver = {
 	.driver = {
 		.name = "sram",
 		.of_match_table = sram_dt_ids,
 	},
 	.probe = sram_probe,
 	.remove = sram_remove,
 };
 
 static int __init sram_init(void)
 {
 	return platform_driver_register(&sram_driver);
 }
 
 postcore_initcall(sram_init);
diff --git a/drivers/misc/sram.h b/drivers/misc/sram.h
new file mode 100644
index 000000000000..c181ce4c8fca
--- /dev/null
+++ b/drivers/misc/sram.h
@@ -0,0 +1,58 @@
+/*
+ * Defines for the SRAM driver
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+#ifndef __SRAM_H
+#define __SRAM_H
+
+struct sram_partition {
+	void __iomem *base;
+
+	struct gen_pool *pool;
+	struct bin_attribute battr;
+	struct mutex lock;
+	struct list_head list;
+};
+
+struct sram_dev {
+	struct device *dev;
+	void __iomem *virt_base;
+
+	struct gen_pool *pool;
+	struct clk *clk;
+
+	struct sram_partition *partition;
+	u32 partitions;
+};
+
+struct sram_reserve {
+	struct list_head list;
+	u32 start;
+	u32 size;
+	bool export;
+	bool pool;
+	bool protect_exec;
+	const char *label;
+};
+
+#ifdef CONFIG_SRAM_EXEC
+int sram_check_protect_exec(struct sram_dev *sram, struct sram_reserve *block,
+			    struct sram_partition *part);
+int sram_add_protect_exec(struct sram_partition *part);
+#else
+static inline int sram_check_protect_exec(struct sram_dev *sram,
+					  struct sram_reserve *block,
+					  struct sram_partition *part)
+{
+	return -ENODEV;
+}
+
+static inline int sram_add_protect_exec(struct sram_partition *part)
+{
+	return -ENODEV;
+}
+#endif /* CONFIG_SRAM_EXEC */
+#endif /* __SRAM_H */
diff --git a/drivers/misc/vmw_vmci/vmci_guest.c b/drivers/misc/vmw_vmci/vmci_guest.c
index 189b32519748..9d659542a335 100644
--- a/drivers/misc/vmw_vmci/vmci_guest.c
+++ b/drivers/misc/vmw_vmci/vmci_guest.c
@@ -1,771 +1,736 @@
 /*
  * VMware VMCI Driver
  *
  * Copyright (C) 2012 VMware, Inc. All rights reserved.
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License as published by the
  * Free Software Foundation version 2 and no later version.
  *
  * This program is distributed in the hope that it will be useful, but
  * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  * for more details.
  */
 
 #include <linux/vmw_vmci_defs.h>
 #include <linux/vmw_vmci_api.h>
 #include <linux/moduleparam.h>
 #include <linux/interrupt.h>
 #include <linux/highmem.h>
 #include <linux/kernel.h>
 #include <linux/mm.h>
 #include <linux/module.h>
 #include <linux/sched.h>
 #include <linux/slab.h>
 #include <linux/init.h>
 #include <linux/pci.h>
 #include <linux/smp.h>
 #include <linux/io.h>
 #include <linux/vmalloc.h>
 
 #include "vmci_datagram.h"
 #include "vmci_doorbell.h"
 #include "vmci_context.h"
 #include "vmci_driver.h"
 #include "vmci_event.h"
 
 #define PCI_DEVICE_ID_VMWARE_VMCI	0x0740
 
 #define VMCI_UTIL_NUM_RESOURCES 1
 
 static bool vmci_disable_msi;
 module_param_named(disable_msi, vmci_disable_msi, bool, 0);
 MODULE_PARM_DESC(disable_msi, "Disable MSI use in driver - (default=0)");
 
 static bool vmci_disable_msix;
 module_param_named(disable_msix, vmci_disable_msix, bool, 0);
 MODULE_PARM_DESC(disable_msix, "Disable MSI-X use in driver - (default=0)");
 
 static u32 ctx_update_sub_id = VMCI_INVALID_ID;
 static u32 vm_context_id = VMCI_INVALID_ID;
 
 struct vmci_guest_device {
 	struct device *dev;	/* PCI device we are attached to */
 	void __iomem *iobase;
 
-	unsigned int irq;
-	unsigned int intr_type;
 	bool exclusive_vectors;
-	struct msix_entry msix_entries[VMCI_MAX_INTRS];
 
 	struct tasklet_struct datagram_tasklet;
 	struct tasklet_struct bm_tasklet;
 
 	void *data_buffer;
 	void *notification_bitmap;
 	dma_addr_t notification_base;
 };
 
 /* vmci_dev singleton device and supporting data*/
 struct pci_dev *vmci_pdev;
 static struct vmci_guest_device *vmci_dev_g;
 static DEFINE_SPINLOCK(vmci_dev_spinlock);
 
 static atomic_t vmci_num_guest_devices = ATOMIC_INIT(0);
 
 bool vmci_guest_code_active(void)
 {
 	return atomic_read(&vmci_num_guest_devices) != 0;
 }
 
 u32 vmci_get_vm_context_id(void)
 {
 	if (vm_context_id == VMCI_INVALID_ID) {
 		struct vmci_datagram get_cid_msg;
 		get_cid_msg.dst =
 		    vmci_make_handle(VMCI_HYPERVISOR_CONTEXT_ID,
 				     VMCI_GET_CONTEXT_ID);
 		get_cid_msg.src = VMCI_ANON_SRC_HANDLE;
 		get_cid_msg.payload_size = 0;
 		vm_context_id = vmci_send_datagram(&get_cid_msg);
 	}
 	return vm_context_id;
 }
 
 /*
  * VM to hypervisor call mechanism. We use the standard VMware naming
  * convention since shared code is calling this function as well.
  */
 int vmci_send_datagram(struct vmci_datagram *dg)
 {
 	unsigned long flags;
 	int result;
 
 	/* Check args. */
 	if (dg == NULL)
 		return VMCI_ERROR_INVALID_ARGS;
 
 	/*
 	 * Need to acquire spinlock on the device because the datagram
 	 * data may be spread over multiple pages and the monitor may
 	 * interleave device user rpc calls from multiple
 	 * VCPUs. Acquiring the spinlock precludes that
 	 * possibility. Disabling interrupts to avoid incoming
 	 * datagrams during a "rep out" and possibly landing up in
 	 * this function.
 	 */
 	spin_lock_irqsave(&vmci_dev_spinlock, flags);
 
 	if (vmci_dev_g) {
 		iowrite8_rep(vmci_dev_g->iobase + VMCI_DATA_OUT_ADDR,
 			     dg, VMCI_DG_SIZE(dg));
 		result = ioread32(vmci_dev_g->iobase + VMCI_RESULT_LOW_ADDR);
 	} else {
 		result = VMCI_ERROR_UNAVAILABLE;
 	}
 
 	spin_unlock_irqrestore(&vmci_dev_spinlock, flags);
 
 	return result;
 }
 EXPORT_SYMBOL_GPL(vmci_send_datagram);
 
 /*
  * Gets called with the new context id if updated or resumed.
  * Context id.
  */
 static void vmci_guest_cid_update(u32 sub_id,
 				  const struct vmci_event_data *event_data,
 				  void *client_data)
 {
 	const struct vmci_event_payld_ctx *ev_payload =
 				vmci_event_data_const_payload(event_data);
 
 	if (sub_id != ctx_update_sub_id) {
 		pr_devel("Invalid subscriber (ID=0x%x)\n", sub_id);
 		return;
 	}
 
 	if (!event_data || ev_payload->context_id == VMCI_INVALID_ID) {
 		pr_devel("Invalid event data\n");
 		return;
 	}
 
 	pr_devel("Updating context from (ID=0x%x) to (ID=0x%x) on event (type=%d)\n",
 		 vm_context_id, ev_payload->context_id, event_data->event);
 
 	vm_context_id = ev_payload->context_id;
 }
 
 /*
  * Verify that the host supports the hypercalls we need. If it does not,
  * try to find fallback hypercalls and use those instead.  Returns
  * true if required hypercalls (or fallback hypercalls) are
  * supported by the host, false otherwise.
  */
 static int vmci_check_host_caps(struct pci_dev *pdev)
 {
 	bool result;
 	struct vmci_resource_query_msg *msg;
 	u32 msg_size = sizeof(struct vmci_resource_query_hdr) +
 				VMCI_UTIL_NUM_RESOURCES * sizeof(u32);
 	struct vmci_datagram *check_msg;
 
 	check_msg = kmalloc(msg_size, GFP_KERNEL);
 	if (!check_msg) {
 		dev_err(&pdev->dev, "%s: Insufficient memory\n", __func__);
 		return -ENOMEM;
 	}
 
 	check_msg->dst = vmci_make_handle(VMCI_HYPERVISOR_CONTEXT_ID,
 					  VMCI_RESOURCES_QUERY);
 	check_msg->src = VMCI_ANON_SRC_HANDLE;
 	check_msg->payload_size = msg_size - VMCI_DG_HEADERSIZE;
 	msg = (struct vmci_resource_query_msg *)VMCI_DG_PAYLOAD(check_msg);
 
 	msg->num_resources = VMCI_UTIL_NUM_RESOURCES;
 	msg->resources[0] = VMCI_GET_CONTEXT_ID;
 
 	/* Checks that hyper calls are supported */
 	result = vmci_send_datagram(check_msg) == 0x01;
 	kfree(check_msg);
 
 	dev_dbg(&pdev->dev, "%s: Host capability check: %s\n",
 		__func__, result ? "PASSED" : "FAILED");
 
 	/* We need the vector. There are no fallbacks. */
 	return result ? 0 : -ENXIO;
 }
 
 /*
  * Reads datagrams from the data in port and dispatches them. We
  * always start reading datagrams into only the first page of the
  * datagram buffer. If the datagrams don't fit into one page, we
  * use the maximum datagram buffer size for the remainder of the
  * invocation. This is a simple heuristic for not penalizing
  * small datagrams.
  *
  * This function assumes that it has exclusive access to the data
  * in port for the duration of the call.
  */
 static void vmci_dispatch_dgs(unsigned long data)
 {
 	struct vmci_guest_device *vmci_dev = (struct vmci_guest_device *)data;
 	u8 *dg_in_buffer = vmci_dev->data_buffer;
 	struct vmci_datagram *dg;
 	size_t dg_in_buffer_size = VMCI_MAX_DG_SIZE;
 	size_t current_dg_in_buffer_size = PAGE_SIZE;
 	size_t remaining_bytes;
 
 	BUILD_BUG_ON(VMCI_MAX_DG_SIZE < PAGE_SIZE);
 
 	ioread8_rep(vmci_dev->iobase + VMCI_DATA_IN_ADDR,
 		    vmci_dev->data_buffer, current_dg_in_buffer_size);
 	dg = (struct vmci_datagram *)dg_in_buffer;
 	remaining_bytes = current_dg_in_buffer_size;
 
 	while (dg->dst.resource != VMCI_INVALID_ID ||
 	       remaining_bytes > PAGE_SIZE) {
 		unsigned dg_in_size;
 
 		/*
 		 * When the input buffer spans multiple pages, a datagram can
 		 * start on any page boundary in the buffer.
 		 */
 		if (dg->dst.resource == VMCI_INVALID_ID) {
 			dg = (struct vmci_datagram *)roundup(
 				(uintptr_t)dg + 1, PAGE_SIZE);
 			remaining_bytes =
 				(size_t)(dg_in_buffer +
 					 current_dg_in_buffer_size -
 					 (u8 *)dg);
 			continue;
 		}
 
 		dg_in_size = VMCI_DG_SIZE_ALIGNED(dg);
 
 		if (dg_in_size <= dg_in_buffer_size) {
 			int result;
 
 			/*
 			 * If the remaining bytes in the datagram
 			 * buffer doesn't contain the complete
 			 * datagram, we first make sure we have enough
 			 * room for it and then we read the reminder
 			 * of the datagram and possibly any following
 			 * datagrams.
 			 */
 			if (dg_in_size > remaining_bytes) {
 				if (remaining_bytes !=
 				    current_dg_in_buffer_size) {
 
 					/*
 					 * We move the partial
 					 * datagram to the front and
 					 * read the reminder of the
 					 * datagram and possibly
 					 * following calls into the
 					 * following bytes.
 					 */
 					memmove(dg_in_buffer, dg_in_buffer +
 						current_dg_in_buffer_size -
 						remaining_bytes,
 						remaining_bytes);
 					dg = (struct vmci_datagram *)
 					    dg_in_buffer;
 				}
 
 				if (current_dg_in_buffer_size !=
 				    dg_in_buffer_size)
 					current_dg_in_buffer_size =
 					    dg_in_buffer_size;
 
 				ioread8_rep(vmci_dev->iobase +
 						VMCI_DATA_IN_ADDR,
 					vmci_dev->data_buffer +
 						remaining_bytes,
 					current_dg_in_buffer_size -
 						remaining_bytes);
 			}
 
 			/*
 			 * We special case event datagrams from the
 			 * hypervisor.
 			 */
 			if (dg->src.context == VMCI_HYPERVISOR_CONTEXT_ID &&
 			    dg->dst.resource == VMCI_EVENT_HANDLER) {
 				result = vmci_event_dispatch(dg);
 			} else {
 				result = vmci_datagram_invoke_guest_handler(dg);
 			}
 			if (result < VMCI_SUCCESS)
 				dev_dbg(vmci_dev->dev,
 					"Datagram with resource (ID=0x%x) failed (err=%d)\n",
 					 dg->dst.resource, result);
 
 			/* On to the next datagram. */
 			dg = (struct vmci_datagram *)((u8 *)dg +
 						      dg_in_size);
 		} else {
 			size_t bytes_to_skip;
 
 			/*
 			 * Datagram doesn't fit in datagram buffer of maximal
 			 * size. We drop it.
 			 */
 			dev_dbg(vmci_dev->dev,
 				"Failed to receive datagram (size=%u bytes)\n",
 				 dg_in_size);
 
 			bytes_to_skip = dg_in_size - remaining_bytes;
 			if (current_dg_in_buffer_size != dg_in_buffer_size)
 				current_dg_in_buffer_size = dg_in_buffer_size;
 
 			for (;;) {
 				ioread8_rep(vmci_dev->iobase +
 						VMCI_DATA_IN_ADDR,
 					vmci_dev->data_buffer,
 					current_dg_in_buffer_size);
 				if (bytes_to_skip <= current_dg_in_buffer_size)
 					break;
 
 				bytes_to_skip -= current_dg_in_buffer_size;
 			}
 			dg = (struct vmci_datagram *)(dg_in_buffer +
 						      bytes_to_skip);
 		}
 
 		remaining_bytes =
 		    (size_t) (dg_in_buffer + current_dg_in_buffer_size -
 			      (u8 *)dg);
 
 		if (remaining_bytes < VMCI_DG_HEADERSIZE) {
 			/* Get the next batch of datagrams. */
 
 			ioread8_rep(vmci_dev->iobase + VMCI_DATA_IN_ADDR,
 				    vmci_dev->data_buffer,
 				    current_dg_in_buffer_size);
 			dg = (struct vmci_datagram *)dg_in_buffer;
 			remaining_bytes = current_dg_in_buffer_size;
 		}
 	}
 }
 
 /*
  * Scans the notification bitmap for raised flags, clears them
  * and handles the notifications.
  */
 static void vmci_process_bitmap(unsigned long data)
 {
 	struct vmci_guest_device *dev = (struct vmci_guest_device *)data;
 
 	if (!dev->notification_bitmap) {
 		dev_dbg(dev->dev, "No bitmap present in %s\n", __func__);
 		return;
 	}
 
 	vmci_dbell_scan_notification_entries(dev->notification_bitmap);
 }
 
-/*
- * Enable MSI-X.  Try exclusive vectors first, then shared vectors.
- */
-static int vmci_enable_msix(struct pci_dev *pdev,
-			    struct vmci_guest_device *vmci_dev)
-{
-	int i;
-	int result;
-
-	for (i = 0; i < VMCI_MAX_INTRS; ++i) {
-		vmci_dev->msix_entries[i].entry = i;
-		vmci_dev->msix_entries[i].vector = i;
-	}
-
-	result = pci_enable_msix_exact(pdev,
-				       vmci_dev->msix_entries, VMCI_MAX_INTRS);
-	if (result == 0)
-		vmci_dev->exclusive_vectors = true;
-	else if (result == -ENOSPC)
-		result = pci_enable_msix_exact(pdev, vmci_dev->msix_entries, 1);
-
-	return result;
-}
-
 /*
  * Interrupt handler for legacy or MSI interrupt, or for first MSI-X
  * interrupt (vector VMCI_INTR_DATAGRAM).
  */
 static irqreturn_t vmci_interrupt(int irq, void *_dev)
 {
 	struct vmci_guest_device *dev = _dev;
 
 	/*
 	 * If we are using MSI-X with exclusive vectors then we simply schedule
 	 * the datagram tasklet, since we know the interrupt was meant for us.
 	 * Otherwise we must read the ICR to determine what to do.
 	 */
 
-	if (dev->intr_type == VMCI_INTR_TYPE_MSIX && dev->exclusive_vectors) {
+	if (dev->exclusive_vectors) {
 		tasklet_schedule(&dev->datagram_tasklet);
 	} else {
 		unsigned int icr;
 
 		/* Acknowledge interrupt and determine what needs doing. */
 		icr = ioread32(dev->iobase + VMCI_ICR_ADDR);
 		if (icr == 0 || icr == ~0)
 			return IRQ_NONE;
 
 		if (icr & VMCI_ICR_DATAGRAM) {
 			tasklet_schedule(&dev->datagram_tasklet);
 			icr &= ~VMCI_ICR_DATAGRAM;
 		}
 
 		if (icr & VMCI_ICR_NOTIFICATION) {
 			tasklet_schedule(&dev->bm_tasklet);
 			icr &= ~VMCI_ICR_NOTIFICATION;
 		}
 
 		if (icr != 0)
 			dev_warn(dev->dev,
 				 "Ignoring unknown interrupt cause (%d)\n",
 				 icr);
 	}
 
 	return IRQ_HANDLED;
 }
 
 /*
  * Interrupt handler for MSI-X interrupt vector VMCI_INTR_NOTIFICATION,
  * which is for the notification bitmap.  Will only get called if we are
  * using MSI-X with exclusive vectors.
  */
 static irqreturn_t vmci_interrupt_bm(int irq, void *_dev)
 {
 	struct vmci_guest_device *dev = _dev;
 
 	/* For MSI-X we can just assume it was meant for us. */
 	tasklet_schedule(&dev->bm_tasklet);
 
 	return IRQ_HANDLED;
 }
 
 /*
  * Most of the initialization at module load time is done here.
  */
 static int vmci_guest_probe_device(struct pci_dev *pdev,
 				   const struct pci_device_id *id)
 {
 	struct vmci_guest_device *vmci_dev;
 	void __iomem *iobase;
 	unsigned int capabilities;
 	unsigned long cmd;
 	int vmci_err;
 	int error;
 
 	dev_dbg(&pdev->dev, "Probing for vmci/PCI guest device\n");
 
 	error = pcim_enable_device(pdev);
 	if (error) {
 		dev_err(&pdev->dev,
 			"Failed to enable VMCI device: %d\n", error);
 		return error;
 	}
 
 	error = pcim_iomap_regions(pdev, 1 << 0, KBUILD_MODNAME);
 	if (error) {
 		dev_err(&pdev->dev, "Failed to reserve/map IO regions\n");
 		return error;
 	}
 
 	iobase = pcim_iomap_table(pdev)[0];
 
 	dev_info(&pdev->dev, "Found VMCI PCI device at %#lx, irq %u\n",
 		 (unsigned long)iobase, pdev->irq);
 
 	vmci_dev = devm_kzalloc(&pdev->dev, sizeof(*vmci_dev), GFP_KERNEL);
 	if (!vmci_dev) {
 		dev_err(&pdev->dev,
 			"Can't allocate memory for VMCI device\n");
 		return -ENOMEM;
 	}
 
 	vmci_dev->dev = &pdev->dev;
-	vmci_dev->intr_type = VMCI_INTR_TYPE_INTX;
 	vmci_dev->exclusive_vectors = false;
 	vmci_dev->iobase = iobase;
 
 	tasklet_init(&vmci_dev->datagram_tasklet,
 		     vmci_dispatch_dgs, (unsigned long)vmci_dev);
 	tasklet_init(&vmci_dev->bm_tasklet,
 		     vmci_process_bitmap, (unsigned long)vmci_dev);
 
 	vmci_dev->data_buffer = vmalloc(VMCI_MAX_DG_SIZE);
 	if (!vmci_dev->data_buffer) {
 		dev_err(&pdev->dev,
 			"Can't allocate memory for datagram buffer\n");
 		return -ENOMEM;
 	}
 
 	pci_set_master(pdev);	/* To enable queue_pair functionality. */
 
 	/*
 	 * Verify that the VMCI Device supports the capabilities that
 	 * we need. If the device is missing capabilities that we would
 	 * like to use, check for fallback capabilities and use those
 	 * instead (so we can run a new VM on old hosts). Fail the load if
 	 * a required capability is missing and there is no fallback.
 	 *
 	 * Right now, we need datagrams. There are no fallbacks.
 	 */
 	capabilities = ioread32(vmci_dev->iobase + VMCI_CAPS_ADDR);
 	if (!(capabilities & VMCI_CAPS_DATAGRAM)) {
 		dev_err(&pdev->dev, "Device does not support datagrams\n");
 		error = -ENXIO;
 		goto err_free_data_buffer;
 	}
 
 	/*
 	 * If the hardware supports notifications, we will use that as
 	 * well.
 	 */
 	if (capabilities & VMCI_CAPS_NOTIFICATIONS) {
 		vmci_dev->notification_bitmap = dma_alloc_coherent(
 			&pdev->dev, PAGE_SIZE, &vmci_dev->notification_base,
 			GFP_KERNEL);
 		if (!vmci_dev->notification_bitmap) {
 			dev_warn(&pdev->dev,
 				 "Unable to allocate notification bitmap\n");
 		} else {
 			memset(vmci_dev->notification_bitmap, 0, PAGE_SIZE);
 			capabilities |= VMCI_CAPS_NOTIFICATIONS;
 		}
 	}
 
 	dev_info(&pdev->dev, "Using capabilities 0x%x\n", capabilities);
 
 	/* Let the host know which capabilities we intend to use. */
 	iowrite32(capabilities, vmci_dev->iobase + VMCI_CAPS_ADDR);
 
 	/* Set up global device so that we can start sending datagrams */
 	spin_lock_irq(&vmci_dev_spinlock);
 	vmci_dev_g = vmci_dev;
 	vmci_pdev = pdev;
 	spin_unlock_irq(&vmci_dev_spinlock);
 
 	/*
 	 * Register notification bitmap with device if that capability is
 	 * used.
 	 */
 	if (capabilities & VMCI_CAPS_NOTIFICATIONS) {
 		unsigned long bitmap_ppn =
 			vmci_dev->notification_base >> PAGE_SHIFT;
 		if (!vmci_dbell_register_notification_bitmap(bitmap_ppn)) {
 			dev_warn(&pdev->dev,
 				 "VMCI device unable to register notification bitmap with PPN 0x%x\n",
 				 (u32) bitmap_ppn);
 			error = -ENXIO;
 			goto err_remove_vmci_dev_g;
 		}
 	}
 
 	/* Check host capabilities. */
 	error = vmci_check_host_caps(pdev);
 	if (error)
 		goto err_remove_bitmap;
 
 	/* Enable device. */
 
 	/*
 	 * We subscribe to the VMCI_EVENT_CTX_ID_UPDATE here so we can
 	 * update the internal context id when needed.
 	 */
 	vmci_err = vmci_event_subscribe(VMCI_EVENT_CTX_ID_UPDATE,
 					vmci_guest_cid_update, NULL,
 					&ctx_update_sub_id);
 	if (vmci_err < VMCI_SUCCESS)
 		dev_warn(&pdev->dev,
 			 "Failed to subscribe to event (type=%d): %d\n",
 			 VMCI_EVENT_CTX_ID_UPDATE, vmci_err);
 
 	/*
 	 * Enable interrupts.  Try MSI-X first, then MSI, and then fallback on
 	 * legacy interrupts.
 	 */
-	if (!vmci_disable_msix && !vmci_enable_msix(pdev, vmci_dev)) {
-		vmci_dev->intr_type = VMCI_INTR_TYPE_MSIX;
-		vmci_dev->irq = vmci_dev->msix_entries[0].vector;
-	} else if (!vmci_disable_msi && !pci_enable_msi(pdev)) {
-		vmci_dev->intr_type = VMCI_INTR_TYPE_MSI;
-		vmci_dev->irq = pdev->irq;
+	error = pci_alloc_irq_vectors(pdev, VMCI_MAX_INTRS, VMCI_MAX_INTRS,
+			PCI_IRQ_MSIX);
+	if (error) {
+		error = pci_alloc_irq_vectors(pdev, 1, 1,
+				PCI_IRQ_MSIX | PCI_IRQ_MSI | PCI_IRQ_LEGACY);
+		if (error)
+			goto err_remove_bitmap;
 	} else {
-		vmci_dev->intr_type = VMCI_INTR_TYPE_INTX;
-		vmci_dev->irq = pdev->irq;
+		vmci_dev->exclusive_vectors = true;
 	}
 
 	/*
 	 * Request IRQ for legacy or MSI interrupts, or for first
 	 * MSI-X vector.
 	 */
-	error = request_irq(vmci_dev->irq, vmci_interrupt, IRQF_SHARED,
-			    KBUILD_MODNAME, vmci_dev);
+	error = request_irq(pci_irq_vector(pdev, 0), vmci_interrupt,
+			    IRQF_SHARED, KBUILD_MODNAME, vmci_dev);
 	if (error) {
 		dev_err(&pdev->dev, "Irq %u in use: %d\n",
-			vmci_dev->irq, error);
+			pci_irq_vector(pdev, 0), error);
 		goto err_disable_msi;
 	}
 
 	/*
 	 * For MSI-X with exclusive vectors we need to request an
 	 * interrupt for each vector so that we get a separate
 	 * interrupt handler routine.  This allows us to distinguish
 	 * between the vectors.
 	 */
 	if (vmci_dev->exclusive_vectors) {
-		error = request_irq(vmci_dev->msix_entries[1].vector,
+		error = request_irq(pci_irq_vector(pdev, 1),
 				    vmci_interrupt_bm, 0, KBUILD_MODNAME,
 				    vmci_dev);
 		if (error) {
 			dev_err(&pdev->dev,
 				"Failed to allocate irq %u: %d\n",
-				vmci_dev->msix_entries[1].vector, error);
+				pci_irq_vector(pdev, 1), error);
 			goto err_free_irq;
 		}
 	}
 
 	dev_dbg(&pdev->dev, "Registered device\n");
 
 	atomic_inc(&vmci_num_guest_devices);
 
 	/* Enable specific interrupt bits. */
 	cmd = VMCI_IMR_DATAGRAM;
 	if (capabilities & VMCI_CAPS_NOTIFICATIONS)
 		cmd |= VMCI_IMR_NOTIFICATION;
 	iowrite32(cmd, vmci_dev->iobase + VMCI_IMR_ADDR);
 
 	/* Enable interrupts. */
 	iowrite32(VMCI_CONTROL_INT_ENABLE,
 		  vmci_dev->iobase + VMCI_CONTROL_ADDR);
 
 	pci_set_drvdata(pdev, vmci_dev);
 	return 0;
 
 err_free_irq:
-	free_irq(vmci_dev->irq, vmci_dev);
+	free_irq(pci_irq_vector(pdev, 0), vmci_dev);
 	tasklet_kill(&vmci_dev->datagram_tasklet);
 	tasklet_kill(&vmci_dev->bm_tasklet);
 
 err_disable_msi:
-	if (vmci_dev->intr_type == VMCI_INTR_TYPE_MSIX)
-		pci_disable_msix(pdev);
-	else if (vmci_dev->intr_type == VMCI_INTR_TYPE_MSI)
-		pci_disable_msi(pdev);
+	pci_free_irq_vectors(pdev);
 
 	vmci_err = vmci_event_unsubscribe(ctx_update_sub_id);
 	if (vmci_err < VMCI_SUCCESS)
 		dev_warn(&pdev->dev,
 			 "Failed to unsubscribe from event (type=%d) with subscriber (ID=0x%x): %d\n",
 			 VMCI_EVENT_CTX_ID_UPDATE, ctx_update_sub_id, vmci_err);
 
 err_remove_bitmap:
 	if (vmci_dev->notification_bitmap) {
 		iowrite32(VMCI_CONTROL_RESET,
 			  vmci_dev->iobase + VMCI_CONTROL_ADDR);
 		dma_free_coherent(&pdev->dev, PAGE_SIZE,
 				  vmci_dev->notification_bitmap,
 				  vmci_dev->notification_base);
 	}
 
 err_remove_vmci_dev_g:
 	spin_lock_irq(&vmci_dev_spinlock);
 	vmci_pdev = NULL;
 	vmci_dev_g = NULL;
 	spin_unlock_irq(&vmci_dev_spinlock);
 
 err_free_data_buffer:
 	vfree(vmci_dev->data_buffer);
 
 	/* The rest are managed resources and will be freed by PCI core */
 	return error;
 }
 
 static void vmci_guest_remove_device(struct pci_dev *pdev)
 {
 	struct vmci_guest_device *vmci_dev = pci_get_drvdata(pdev);
 	int vmci_err;
 
 	dev_dbg(&pdev->dev, "Removing device\n");
 
 	atomic_dec(&vmci_num_guest_devices);
 
 	vmci_qp_guest_endpoints_exit();
 
 	vmci_err = vmci_event_unsubscribe(ctx_update_sub_id);
 	if (vmci_err < VMCI_SUCCESS)
 		dev_warn(&pdev->dev,
 			 "Failed to unsubscribe from event (type=%d) with subscriber (ID=0x%x): %d\n",
 			 VMCI_EVENT_CTX_ID_UPDATE, ctx_update_sub_id, vmci_err);
 
 	spin_lock_irq(&vmci_dev_spinlock);
 	vmci_dev_g = NULL;
 	vmci_pdev = NULL;
 	spin_unlock_irq(&vmci_dev_spinlock);
 
 	dev_dbg(&pdev->dev, "Resetting vmci device\n");
 	iowrite32(VMCI_CONTROL_RESET, vmci_dev->iobase + VMCI_CONTROL_ADDR);
 
 	/*
 	 * Free IRQ and then disable MSI/MSI-X as appropriate.  For
 	 * MSI-X, we might have multiple vectors, each with their own
 	 * IRQ, which we must free too.
 	 */
-	free_irq(vmci_dev->irq, vmci_dev);
-	if (vmci_dev->intr_type == VMCI_INTR_TYPE_MSIX) {
-		if (vmci_dev->exclusive_vectors)
-			free_irq(vmci_dev->msix_entries[1].vector, vmci_dev);
-		pci_disable_msix(pdev);
-	} else if (vmci_dev->intr_type == VMCI_INTR_TYPE_MSI) {
-		pci_disable_msi(pdev);
-	}
+	if (vmci_dev->exclusive_vectors)
+		free_irq(pci_irq_vector(pdev, 1), vmci_dev);
+	free_irq(pci_irq_vector(pdev, 0), vmci_dev);
+	pci_free_irq_vectors(pdev);
 
 	tasklet_kill(&vmci_dev->datagram_tasklet);
 	tasklet_kill(&vmci_dev->bm_tasklet);
 
 	if (vmci_dev->notification_bitmap) {
 		/*
 		 * The device reset above cleared the bitmap state of the
 		 * device, so we can safely free it here.
 		 */
 
 		dma_free_coherent(&pdev->dev, PAGE_SIZE,
 				  vmci_dev->notification_bitmap,
 				  vmci_dev->notification_base);
 	}
 
 	vfree(vmci_dev->data_buffer);
 
 	/* The rest are managed resources and will be freed by PCI core */
 }
 
 static const struct pci_device_id vmci_ids[] = {
 	{ PCI_DEVICE(PCI_VENDOR_ID_VMWARE, PCI_DEVICE_ID_VMWARE_VMCI), },
 	{ 0 },
 };
 MODULE_DEVICE_TABLE(pci, vmci_ids);
 
 static struct pci_driver vmci_guest_driver = {
 	.name		= KBUILD_MODNAME,
 	.id_table	= vmci_ids,
 	.probe		= vmci_guest_probe_device,
 	.remove		= vmci_guest_remove_device,
 };
 
 int __init vmci_guest_init(void)
 {
 	return pci_register_driver(&vmci_guest_driver);
 }
 
 void __exit vmci_guest_exit(void)
 {
 	pci_unregister_driver(&vmci_guest_driver);
 }
diff --git a/drivers/net/hyperv/netvsc.c b/drivers/net/hyperv/netvsc.c
index fd6ebbefd919..d35ebd993b38 100644
--- a/drivers/net/hyperv/netvsc.c
+++ b/drivers/net/hyperv/netvsc.c
@@ -1,1338 +1,1323 @@
 /*
  * Copyright (c) 2009, Microsoft Corporation.
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms and conditions of the GNU General Public License,
  * version 2, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope it will be useful, but WITHOUT
  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
  * more details.
  *
  * You should have received a copy of the GNU General Public License along with
  * this program; if not, see <http://www.gnu.org/licenses/>.
  *
  * Authors:
  *   Haiyang Zhang <haiyangz@microsoft.com>
  *   Hank Janssen  <hjanssen@microsoft.com>
  */
 #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
 
 #include <linux/kernel.h>
 #include <linux/sched.h>
 #include <linux/wait.h>
 #include <linux/mm.h>
 #include <linux/delay.h>
 #include <linux/io.h>
 #include <linux/slab.h>
 #include <linux/netdevice.h>
 #include <linux/if_ether.h>
 #include <linux/vmalloc.h>
 #include <asm/sync_bitops.h>
 
 #include "hyperv_net.h"
 
 /*
  * Switch the data path from the synthetic interface to the VF
  * interface.
  */
 void netvsc_switch_datapath(struct net_device *ndev, bool vf)
 {
 	struct net_device_context *net_device_ctx = netdev_priv(ndev);
 	struct hv_device *dev = net_device_ctx->device_ctx;
 	struct netvsc_device *nv_dev = net_device_ctx->nvdev;
 	struct nvsp_message *init_pkt = &nv_dev->channel_init_pkt;
 
 	memset(init_pkt, 0, sizeof(struct nvsp_message));
 	init_pkt->hdr.msg_type = NVSP_MSG4_TYPE_SWITCH_DATA_PATH;
 	if (vf)
 		init_pkt->msg.v4_msg.active_dp.active_datapath =
 			NVSP_DATAPATH_VF;
 	else
 		init_pkt->msg.v4_msg.active_dp.active_datapath =
 			NVSP_DATAPATH_SYNTHETIC;
 
 	vmbus_sendpacket(dev->channel, init_pkt,
 			       sizeof(struct nvsp_message),
 			       (unsigned long)init_pkt,
 			       VM_PKT_DATA_INBAND, 0);
 }
 
 static struct netvsc_device *alloc_net_device(void)
 {
 	struct netvsc_device *net_device;
 
 	net_device = kzalloc(sizeof(struct netvsc_device), GFP_KERNEL);
 	if (!net_device)
 		return NULL;
 
 	net_device->chan_table[0].mrc.buf
 		= vzalloc(NETVSC_RECVSLOT_MAX * sizeof(struct recv_comp_data));
 
 	init_waitqueue_head(&net_device->wait_drain);
 	net_device->destroy = false;
 	atomic_set(&net_device->open_cnt, 0);
 	net_device->max_pkt = RNDIS_MAX_PKT_DEFAULT;
 	net_device->pkt_align = RNDIS_PKT_ALIGN_DEFAULT;
 	init_completion(&net_device->channel_init_wait);
 
 	return net_device;
 }
 
 static void free_netvsc_device(struct netvsc_device *nvdev)
 {
 	int i;
 
 	for (i = 0; i < VRSS_CHANNEL_MAX; i++)
 		vfree(nvdev->chan_table[i].mrc.buf);
 
 	kfree(nvdev);
 }
 
 
 static inline bool netvsc_channel_idle(const struct netvsc_device *net_device,
 				       u16 q_idx)
 {
 	const struct netvsc_channel *nvchan = &net_device->chan_table[q_idx];
 
 	return atomic_read(&net_device->num_outstanding_recvs) == 0 &&
 		atomic_read(&nvchan->queue_sends) == 0;
 }
 
 static struct netvsc_device *get_outbound_net_device(struct hv_device *device)
 {
 	struct netvsc_device *net_device = hv_device_to_netvsc_device(device);
 
 	if (net_device && net_device->destroy)
 		net_device = NULL;
 
 	return net_device;
 }
 
 static void netvsc_destroy_buf(struct hv_device *device)
 {
 	struct nvsp_message *revoke_packet;
 	struct net_device *ndev = hv_get_drvdata(device);
 	struct netvsc_device *net_device = net_device_to_netvsc_device(ndev);
 	int ret;
 
 	/*
 	 * If we got a section count, it means we received a
 	 * SendReceiveBufferComplete msg (ie sent
 	 * NvspMessage1TypeSendReceiveBuffer msg) therefore, we need
 	 * to send a revoke msg here
 	 */
 	if (net_device->recv_section_cnt) {
 		/* Send the revoke receive buffer */
 		revoke_packet = &net_device->revoke_packet;
 		memset(revoke_packet, 0, sizeof(struct nvsp_message));
 
 		revoke_packet->hdr.msg_type =
 			NVSP_MSG1_TYPE_REVOKE_RECV_BUF;
 		revoke_packet->msg.v1_msg.
 		revoke_recv_buf.id = NETVSC_RECEIVE_BUFFER_ID;
 
 		ret = vmbus_sendpacket(device->channel,
 				       revoke_packet,
 				       sizeof(struct nvsp_message),
 				       (unsigned long)revoke_packet,
 				       VM_PKT_DATA_INBAND, 0);
 		/*
 		 * If we failed here, we might as well return and
 		 * have a leak rather than continue and a bugchk
 		 */
 		if (ret != 0) {
 			netdev_err(ndev, "unable to send "
 				"revoke receive buffer to netvsp\n");
 			return;
 		}
 	}
 
 	/* Teardown the gpadl on the vsp end */
 	if (net_device->recv_buf_gpadl_handle) {
 		ret = vmbus_teardown_gpadl(device->channel,
 					   net_device->recv_buf_gpadl_handle);
 
 		/* If we failed here, we might as well return and have a leak
 		 * rather than continue and a bugchk
 		 */
 		if (ret != 0) {
 			netdev_err(ndev,
 				   "unable to teardown receive buffer's gpadl\n");
 			return;
 		}
 		net_device->recv_buf_gpadl_handle = 0;
 	}
 
 	if (net_device->recv_buf) {
 		/* Free up the receive buffer */
 		vfree(net_device->recv_buf);
 		net_device->recv_buf = NULL;
 	}
 
 	if (net_device->recv_section) {
 		net_device->recv_section_cnt = 0;
 		kfree(net_device->recv_section);
 		net_device->recv_section = NULL;
 	}
 
 	/* Deal with the send buffer we may have setup.
 	 * If we got a  send section size, it means we received a
 	 * NVSP_MSG1_TYPE_SEND_SEND_BUF_COMPLETE msg (ie sent
 	 * NVSP_MSG1_TYPE_SEND_SEND_BUF msg) therefore, we need
 	 * to send a revoke msg here
 	 */
 	if (net_device->send_section_size) {
 		/* Send the revoke receive buffer */
 		revoke_packet = &net_device->revoke_packet;
 		memset(revoke_packet, 0, sizeof(struct nvsp_message));
 
 		revoke_packet->hdr.msg_type =
 			NVSP_MSG1_TYPE_REVOKE_SEND_BUF;
 		revoke_packet->msg.v1_msg.revoke_send_buf.id =
 			NETVSC_SEND_BUFFER_ID;
 
 		ret = vmbus_sendpacket(device->channel,
 				       revoke_packet,
 				       sizeof(struct nvsp_message),
 				       (unsigned long)revoke_packet,
 				       VM_PKT_DATA_INBAND, 0);
 		/* If we failed here, we might as well return and
 		 * have a leak rather than continue and a bugchk
 		 */
 		if (ret != 0) {
 			netdev_err(ndev, "unable to send "
 				   "revoke send buffer to netvsp\n");
 			return;
 		}
 	}
 	/* Teardown the gpadl on the vsp end */
 	if (net_device->send_buf_gpadl_handle) {
 		ret = vmbus_teardown_gpadl(device->channel,
 					   net_device->send_buf_gpadl_handle);
 
 		/* If we failed here, we might as well return and have a leak
 		 * rather than continue and a bugchk
 		 */
 		if (ret != 0) {
 			netdev_err(ndev,
 				   "unable to teardown send buffer's gpadl\n");
 			return;
 		}
 		net_device->send_buf_gpadl_handle = 0;
 	}
 	if (net_device->send_buf) {
 		/* Free up the send buffer */
 		vfree(net_device->send_buf);
 		net_device->send_buf = NULL;
 	}
 	kfree(net_device->send_section_map);
 }
 
 static int netvsc_init_buf(struct hv_device *device)
 {
 	int ret = 0;
 	struct netvsc_device *net_device;
 	struct nvsp_message *init_packet;
 	struct net_device *ndev;
 	int node;
 
 	net_device = get_outbound_net_device(device);
 	if (!net_device)
 		return -ENODEV;
 	ndev = hv_get_drvdata(device);
 
 	node = cpu_to_node(device->channel->target_cpu);
 	net_device->recv_buf = vzalloc_node(net_device->recv_buf_size, node);
 	if (!net_device->recv_buf)
 		net_device->recv_buf = vzalloc(net_device->recv_buf_size);
 
 	if (!net_device->recv_buf) {
 		netdev_err(ndev, "unable to allocate receive "
 			"buffer of size %d\n", net_device->recv_buf_size);
 		ret = -ENOMEM;
 		goto cleanup;
 	}
 
 	/*
 	 * Establish the gpadl handle for this buffer on this
 	 * channel.  Note: This call uses the vmbus connection rather
 	 * than the channel to establish the gpadl handle.
 	 */
 	ret = vmbus_establish_gpadl(device->channel, net_device->recv_buf,
 				    net_device->recv_buf_size,
 				    &net_device->recv_buf_gpadl_handle);
 	if (ret != 0) {
 		netdev_err(ndev,
 			"unable to establish receive buffer's gpadl\n");
 		goto cleanup;
 	}
 
 	/* Notify the NetVsp of the gpadl handle */
 	init_packet = &net_device->channel_init_pkt;
 
 	memset(init_packet, 0, sizeof(struct nvsp_message));
 
 	init_packet->hdr.msg_type = NVSP_MSG1_TYPE_SEND_RECV_BUF;
 	init_packet->msg.v1_msg.send_recv_buf.
 		gpadl_handle = net_device->recv_buf_gpadl_handle;
 	init_packet->msg.v1_msg.
 		send_recv_buf.id = NETVSC_RECEIVE_BUFFER_ID;
 
 	/* Send the gpadl notification request */
 	ret = vmbus_sendpacket(device->channel, init_packet,
 			       sizeof(struct nvsp_message),
 			       (unsigned long)init_packet,
 			       VM_PKT_DATA_INBAND,
 			       VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED);
 	if (ret != 0) {
 		netdev_err(ndev,
 			"unable to send receive buffer's gpadl to netvsp\n");
 		goto cleanup;
 	}
 
 	wait_for_completion(&net_device->channel_init_wait);
 
 	/* Check the response */
 	if (init_packet->msg.v1_msg.
 	    send_recv_buf_complete.status != NVSP_STAT_SUCCESS) {
 		netdev_err(ndev, "Unable to complete receive buffer "
 			   "initialization with NetVsp - status %d\n",
 			   init_packet->msg.v1_msg.
 			   send_recv_buf_complete.status);
 		ret = -EINVAL;
 		goto cleanup;
 	}
 
 	/* Parse the response */
 
 	net_device->recv_section_cnt = init_packet->msg.
 		v1_msg.send_recv_buf_complete.num_sections;
 
 	net_device->recv_section = kmemdup(
 		init_packet->msg.v1_msg.send_recv_buf_complete.sections,
 		net_device->recv_section_cnt *
 		sizeof(struct nvsp_1_receive_buffer_section),
 		GFP_KERNEL);
 	if (net_device->recv_section == NULL) {
 		ret = -EINVAL;
 		goto cleanup;
 	}
 
 	/*
 	 * For 1st release, there should only be 1 section that represents the
 	 * entire receive buffer
 	 */
 	if (net_device->recv_section_cnt != 1 ||
 	    net_device->recv_section->offset != 0) {
 		ret = -EINVAL;
 		goto cleanup;
 	}
 
 	/* Now setup the send buffer.
 	 */
 	net_device->send_buf = vzalloc_node(net_device->send_buf_size, node);
 	if (!net_device->send_buf)
 		net_device->send_buf = vzalloc(net_device->send_buf_size);
 	if (!net_device->send_buf) {
 		netdev_err(ndev, "unable to allocate send "
 			   "buffer of size %d\n", net_device->send_buf_size);
 		ret = -ENOMEM;
 		goto cleanup;
 	}
 
 	/* Establish the gpadl handle for this buffer on this
 	 * channel.  Note: This call uses the vmbus connection rather
 	 * than the channel to establish the gpadl handle.
 	 */
 	ret = vmbus_establish_gpadl(device->channel, net_device->send_buf,
 				    net_device->send_buf_size,
 				    &net_device->send_buf_gpadl_handle);
 	if (ret != 0) {
 		netdev_err(ndev,
 			   "unable to establish send buffer's gpadl\n");
 		goto cleanup;
 	}
 
 	/* Notify the NetVsp of the gpadl handle */
 	init_packet = &net_device->channel_init_pkt;
 	memset(init_packet, 0, sizeof(struct nvsp_message));
 	init_packet->hdr.msg_type = NVSP_MSG1_TYPE_SEND_SEND_BUF;
 	init_packet->msg.v1_msg.send_send_buf.gpadl_handle =
 		net_device->send_buf_gpadl_handle;
 	init_packet->msg.v1_msg.send_send_buf.id = NETVSC_SEND_BUFFER_ID;
 
 	/* Send the gpadl notification request */
 	ret = vmbus_sendpacket(device->channel, init_packet,
 			       sizeof(struct nvsp_message),
 			       (unsigned long)init_packet,
 			       VM_PKT_DATA_INBAND,
 			       VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED);
 	if (ret != 0) {
 		netdev_err(ndev,
 			   "unable to send send buffer's gpadl to netvsp\n");
 		goto cleanup;
 	}
 
 	wait_for_completion(&net_device->channel_init_wait);
 
 	/* Check the response */
 	if (init_packet->msg.v1_msg.
 	    send_send_buf_complete.status != NVSP_STAT_SUCCESS) {
 		netdev_err(ndev, "Unable to complete send buffer "
 			   "initialization with NetVsp - status %d\n",
 			   init_packet->msg.v1_msg.
 			   send_send_buf_complete.status);
 		ret = -EINVAL;
 		goto cleanup;
 	}
 
 	/* Parse the response */
 	net_device->send_section_size = init_packet->msg.
 				v1_msg.send_send_buf_complete.section_size;
 
 	/* Section count is simply the size divided by the section size.
 	 */
 	net_device->send_section_cnt =
 		net_device->send_buf_size / net_device->send_section_size;
 
 	netdev_dbg(ndev, "Send section size: %d, Section count:%d\n",
 		   net_device->send_section_size, net_device->send_section_cnt);
 
 	/* Setup state for managing the send buffer. */
 	net_device->map_words = DIV_ROUND_UP(net_device->send_section_cnt,
 					     BITS_PER_LONG);
 
 	net_device->send_section_map = kcalloc(net_device->map_words,
 					       sizeof(ulong), GFP_KERNEL);
 	if (net_device->send_section_map == NULL) {
 		ret = -ENOMEM;
 		goto cleanup;
 	}
 
 	goto exit;
 
 cleanup:
 	netvsc_destroy_buf(device);
 
 exit:
 	return ret;
 }
 
 /* Negotiate NVSP protocol version */
 static int negotiate_nvsp_ver(struct hv_device *device,
 			      struct netvsc_device *net_device,
 			      struct nvsp_message *init_packet,
 			      u32 nvsp_ver)
 {
 	struct net_device *ndev = hv_get_drvdata(device);
 	int ret;
 
 	memset(init_packet, 0, sizeof(struct nvsp_message));
 	init_packet->hdr.msg_type = NVSP_MSG_TYPE_INIT;
 	init_packet->msg.init_msg.init.min_protocol_ver = nvsp_ver;
 	init_packet->msg.init_msg.init.max_protocol_ver = nvsp_ver;
 
 	/* Send the init request */
 	ret = vmbus_sendpacket(device->channel, init_packet,
 			       sizeof(struct nvsp_message),
 			       (unsigned long)init_packet,
 			       VM_PKT_DATA_INBAND,
 			       VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED);
 
 	if (ret != 0)
 		return ret;
 
 	wait_for_completion(&net_device->channel_init_wait);
 
 	if (init_packet->msg.init_msg.init_complete.status !=
 	    NVSP_STAT_SUCCESS)
 		return -EINVAL;
 
 	if (nvsp_ver == NVSP_PROTOCOL_VERSION_1)
 		return 0;
 
 	/* NVSPv2 or later: Send NDIS config */
 	memset(init_packet, 0, sizeof(struct nvsp_message));
 	init_packet->hdr.msg_type = NVSP_MSG2_TYPE_SEND_NDIS_CONFIG;
 	init_packet->msg.v2_msg.send_ndis_config.mtu = ndev->mtu + ETH_HLEN;
 	init_packet->msg.v2_msg.send_ndis_config.capability.ieee8021q = 1;
 
 	if (nvsp_ver >= NVSP_PROTOCOL_VERSION_5) {
 		init_packet->msg.v2_msg.send_ndis_config.capability.sriov = 1;
 
 		/* Teaming bit is needed to receive link speed updates */
 		init_packet->msg.v2_msg.send_ndis_config.capability.teaming = 1;
 	}
 
 	ret = vmbus_sendpacket(device->channel, init_packet,
 				sizeof(struct nvsp_message),
 				(unsigned long)init_packet,
 				VM_PKT_DATA_INBAND, 0);
 
 	return ret;
 }
 
 static int netvsc_connect_vsp(struct hv_device *device)
 {
 	int ret;
 	struct netvsc_device *net_device;
 	struct nvsp_message *init_packet;
 	int ndis_version;
 	const u32 ver_list[] = {
 		NVSP_PROTOCOL_VERSION_1, NVSP_PROTOCOL_VERSION_2,
 		NVSP_PROTOCOL_VERSION_4, NVSP_PROTOCOL_VERSION_5 };
 	int i;
 
 	net_device = get_outbound_net_device(device);
 	if (!net_device)
 		return -ENODEV;
 
 	init_packet = &net_device->channel_init_pkt;
 
 	/* Negotiate the latest NVSP protocol supported */
 	for (i = ARRAY_SIZE(ver_list) - 1; i >= 0; i--)
 		if (negotiate_nvsp_ver(device, net_device, init_packet,
 				       ver_list[i])  == 0) {
 			net_device->nvsp_version = ver_list[i];
 			break;
 		}
 
 	if (i < 0) {
 		ret = -EPROTO;
 		goto cleanup;
 	}
 
 	pr_debug("Negotiated NVSP version:%x\n", net_device->nvsp_version);
 
 	/* Send the ndis version */
 	memset(init_packet, 0, sizeof(struct nvsp_message));
 
 	if (net_device->nvsp_version <= NVSP_PROTOCOL_VERSION_4)
 		ndis_version = 0x00060001;
 	else
 		ndis_version = 0x0006001e;
 
 	init_packet->hdr.msg_type = NVSP_MSG1_TYPE_SEND_NDIS_VER;
 	init_packet->msg.v1_msg.
 		send_ndis_ver.ndis_major_ver =
 				(ndis_version & 0xFFFF0000) >> 16;
 	init_packet->msg.v1_msg.
 		send_ndis_ver.ndis_minor_ver =
 				ndis_version & 0xFFFF;
 
 	/* Send the init request */
 	ret = vmbus_sendpacket(device->channel, init_packet,
 				sizeof(struct nvsp_message),
 				(unsigned long)init_packet,
 				VM_PKT_DATA_INBAND, 0);
 	if (ret != 0)
 		goto cleanup;
 
 	/* Post the big receive buffer to NetVSP */
 	if (net_device->nvsp_version <= NVSP_PROTOCOL_VERSION_2)
 		net_device->recv_buf_size = NETVSC_RECEIVE_BUFFER_SIZE_LEGACY;
 	else
 		net_device->recv_buf_size = NETVSC_RECEIVE_BUFFER_SIZE;
 	net_device->send_buf_size = NETVSC_SEND_BUFFER_SIZE;
 
 	ret = netvsc_init_buf(device);
 
 cleanup:
 	return ret;
 }
 
 static void netvsc_disconnect_vsp(struct hv_device *device)
 {
 	netvsc_destroy_buf(device);
 }
 
 /*
  * netvsc_device_remove - Callback when the root bus device is removed
  */
 void netvsc_device_remove(struct hv_device *device)
 {
 	struct net_device *ndev = hv_get_drvdata(device);
 	struct net_device_context *net_device_ctx = netdev_priv(ndev);
 	struct netvsc_device *net_device = net_device_ctx->nvdev;
 
 	netvsc_disconnect_vsp(device);
 
 	net_device_ctx->nvdev = NULL;
 
 	/*
 	 * At this point, no one should be accessing net_device
 	 * except in here
 	 */
 	netdev_dbg(ndev, "net device safe to remove\n");
 
 	/* Now, we can close the channel safely */
 	vmbus_close(device->channel);
 
 	/* Release all resources */
 	free_netvsc_device(net_device);
 }
 
 #define RING_AVAIL_PERCENT_HIWATER 20
 #define RING_AVAIL_PERCENT_LOWATER 10
 
 /*
  * Get the percentage of available bytes to write in the ring.
  * The return value is in range from 0 to 100.
  */
 static inline u32 hv_ringbuf_avail_percent(
 		struct hv_ring_buffer_info *ring_info)
 {
 	u32 avail_read, avail_write;
 
 	hv_get_ringbuffer_availbytes(ring_info, &avail_read, &avail_write);
 
 	return avail_write * 100 / ring_info->ring_datasize;
 }
 
 static inline void netvsc_free_send_slot(struct netvsc_device *net_device,
 					 u32 index)
 {
 	sync_change_bit(index, net_device->send_section_map);
 }
 
 static void netvsc_send_tx_complete(struct netvsc_device *net_device,
 				    struct vmbus_channel *incoming_channel,
 				    struct hv_device *device,
 				    struct vmpacket_descriptor *packet)
 {
 	struct sk_buff *skb = (struct sk_buff *)(unsigned long)packet->trans_id;
 	struct net_device *ndev = hv_get_drvdata(device);
 	struct net_device_context *net_device_ctx = netdev_priv(ndev);
 	struct vmbus_channel *channel = device->channel;
 	u16 q_idx = 0;
 	int queue_sends;
 
 	/* Notify the layer above us */
 	if (likely(skb)) {
 		const struct hv_netvsc_packet *packet
 			= (struct hv_netvsc_packet *)skb->cb;
 		u32 send_index = packet->send_buf_index;
 		struct netvsc_stats *tx_stats;
 
 		if (send_index != NETVSC_INVALID_INDEX)
 			netvsc_free_send_slot(net_device, send_index);
 		q_idx = packet->q_idx;
 		channel = incoming_channel;
 
 		tx_stats = &net_device->chan_table[q_idx].tx_stats;
 
 		u64_stats_update_begin(&tx_stats->syncp);
 		tx_stats->packets += packet->total_packets;
 		tx_stats->bytes += packet->total_bytes;
 		u64_stats_update_end(&tx_stats->syncp);
 
 		dev_consume_skb_any(skb);
 	}
 
 	queue_sends =
 		atomic_dec_return(&net_device->chan_table[q_idx].queue_sends);
 
 	if (net_device->destroy && queue_sends == 0)
 		wake_up(&net_device->wait_drain);
 
 	if (netif_tx_queue_stopped(netdev_get_tx_queue(ndev, q_idx)) &&
 	    !net_device_ctx->start_remove &&
 	    (hv_ringbuf_avail_percent(&channel->outbound) > RING_AVAIL_PERCENT_HIWATER ||
 	     queue_sends < 1))
 		netif_tx_wake_queue(netdev_get_tx_queue(ndev, q_idx));
 }
 
 static void netvsc_send_completion(struct netvsc_device *net_device,
 				   struct vmbus_channel *incoming_channel,
 				   struct hv_device *device,
 				   struct vmpacket_descriptor *packet)
 {
 	struct nvsp_message *nvsp_packet;
 	struct net_device *ndev = hv_get_drvdata(device);
 
 	nvsp_packet = (struct nvsp_message *)((unsigned long)packet +
 					      (packet->offset8 << 3));
 
 	switch (nvsp_packet->hdr.msg_type) {
 	case NVSP_MSG_TYPE_INIT_COMPLETE:
 	case NVSP_MSG1_TYPE_SEND_RECV_BUF_COMPLETE:
 	case NVSP_MSG1_TYPE_SEND_SEND_BUF_COMPLETE:
 	case NVSP_MSG5_TYPE_SUBCHANNEL:
 		/* Copy the response back */
 		memcpy(&net_device->channel_init_pkt, nvsp_packet,
 		       sizeof(struct nvsp_message));
 		complete(&net_device->channel_init_wait);
 		break;
 
 	case NVSP_MSG1_TYPE_SEND_RNDIS_PKT_COMPLETE:
 		netvsc_send_tx_complete(net_device, incoming_channel,
 					device, packet);
 		break;
 
 	default:
 		netdev_err(ndev,
 			   "Unknown send completion type %d received!!\n",
 			   nvsp_packet->hdr.msg_type);
 	}
 }
 
 static u32 netvsc_get_next_send_section(struct netvsc_device *net_device)
 {
 	unsigned long *map_addr = net_device->send_section_map;
 	unsigned int i;
 
 	for_each_clear_bit(i, map_addr, net_device->map_words) {
 		if (sync_test_and_set_bit(i, map_addr) == 0)
 			return i;
 	}
 
 	return NETVSC_INVALID_INDEX;
 }
 
 static u32 netvsc_copy_to_send_buf(struct netvsc_device *net_device,
 				   unsigned int section_index,
 				   u32 pend_size,
 				   struct hv_netvsc_packet *packet,
 				   struct rndis_message *rndis_msg,
 				   struct hv_page_buffer **pb,
 				   struct sk_buff *skb)
 {
 	char *start = net_device->send_buf;
 	char *dest = start + (section_index * net_device->send_section_size)
 		     + pend_size;
 	int i;
-	bool is_data_pkt = (skb != NULL) ? true : false;
-	bool xmit_more = (skb != NULL) ? skb->xmit_more : false;
 	u32 msg_size = 0;
 	u32 padding = 0;
 	u32 remain = packet->total_data_buflen % net_device->pkt_align;
 	u32 page_count = packet->cp_partial ? packet->rmsg_pgcnt :
 		packet->page_buf_cnt;
 
 	/* Add padding */
-	if (is_data_pkt && xmit_more && remain &&
+	if (skb && skb->xmit_more && remain &&
 	    !packet->cp_partial) {
 		padding = net_device->pkt_align - remain;
 		rndis_msg->msg_len += padding;
 		packet->total_data_buflen += padding;
 	}
 
 	for (i = 0; i < page_count; i++) {
 		char *src = phys_to_virt((*pb)[i].pfn << PAGE_SHIFT);
 		u32 offset = (*pb)[i].offset;
 		u32 len = (*pb)[i].len;
 
 		memcpy(dest, (src + offset), len);
 		msg_size += len;
 		dest += len;
 	}
 
 	if (padding) {
 		memset(dest, 0, padding);
 		msg_size += padding;
 	}
 
 	return msg_size;
 }
 
 static inline int netvsc_send_pkt(
 	struct hv_device *device,
 	struct hv_netvsc_packet *packet,
 	struct netvsc_device *net_device,
 	struct hv_page_buffer **pb,
 	struct sk_buff *skb)
 {
 	struct nvsp_message nvmsg;
 	struct netvsc_channel *nvchan
 		= &net_device->chan_table[packet->q_idx];
 	struct vmbus_channel *out_channel = nvchan->channel;
 	struct net_device *ndev = hv_get_drvdata(device);
 	struct netdev_queue *txq = netdev_get_tx_queue(ndev, packet->q_idx);
 	u64 req_id;
 	int ret;
 	struct hv_page_buffer *pgbuf;
 	u32 ring_avail = hv_ringbuf_avail_percent(&out_channel->outbound);
-	bool xmit_more = (skb != NULL) ? skb->xmit_more : false;
 
 	nvmsg.hdr.msg_type = NVSP_MSG1_TYPE_SEND_RNDIS_PKT;
 	if (skb != NULL) {
 		/* 0 is RMC_DATA; */
 		nvmsg.msg.v1_msg.send_rndis_pkt.channel_type = 0;
 	} else {
 		/* 1 is RMC_CONTROL; */
 		nvmsg.msg.v1_msg.send_rndis_pkt.channel_type = 1;
 	}
 
 	nvmsg.msg.v1_msg.send_rndis_pkt.send_buf_section_index =
 		packet->send_buf_index;
 	if (packet->send_buf_index == NETVSC_INVALID_INDEX)
 		nvmsg.msg.v1_msg.send_rndis_pkt.send_buf_section_size = 0;
 	else
 		nvmsg.msg.v1_msg.send_rndis_pkt.send_buf_section_size =
 			packet->total_data_buflen;
 
 	req_id = (ulong)skb;
 
 	if (out_channel->rescind)
 		return -ENODEV;
 
-	/*
-	 * It is possible that once we successfully place this packet
-	 * on the ringbuffer, we may stop the queue. In that case, we want
-	 * to notify the host independent of the xmit_more flag. We don't
-	 * need to be precise here; in the worst case we may signal the host
-	 * unnecessarily.
-	 */
-	if (ring_avail < (RING_AVAIL_PERCENT_LOWATER + 1))
-		xmit_more = false;
-
 	if (packet->page_buf_cnt) {
 		pgbuf = packet->cp_partial ? (*pb) +
 			packet->rmsg_pgcnt : (*pb);
 		ret = vmbus_sendpacket_pagebuffer_ctl(out_channel,
 						      pgbuf,
 						      packet->page_buf_cnt,
 						      &nvmsg,
 						      sizeof(struct nvsp_message),
 						      req_id,
-						      VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED,
-						      !xmit_more);
+						      VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED);
 	} else {
 		ret = vmbus_sendpacket_ctl(out_channel, &nvmsg,
 					   sizeof(struct nvsp_message),
 					   req_id,
 					   VM_PKT_DATA_INBAND,
-					   VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED,
-					   !xmit_more);
+					   VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED);
 	}
 
 	if (ret == 0) {
 		atomic_inc_return(&nvchan->queue_sends);
 
 		if (ring_avail < RING_AVAIL_PERCENT_LOWATER)
 			netif_tx_stop_queue(txq);
 	} else if (ret == -EAGAIN) {
 		netif_tx_stop_queue(txq);
 		if (atomic_read(&nvchan->queue_sends) < 1) {
 			netif_tx_wake_queue(txq);
 			ret = -ENOSPC;
 		}
 	} else {
 		netdev_err(ndev, "Unable to send packet %p ret %d\n",
 			   packet, ret);
 	}
 
 	return ret;
 }
 
 /* Move packet out of multi send data (msd), and clear msd */
 static inline void move_pkt_msd(struct hv_netvsc_packet **msd_send,
 				struct sk_buff **msd_skb,
 				struct multi_send_data *msdp)
 {
 	*msd_skb = msdp->skb;
 	*msd_send = msdp->pkt;
 	msdp->skb = NULL;
 	msdp->pkt = NULL;
 	msdp->count = 0;
 }
 
 int netvsc_send(struct hv_device *device,
 		struct hv_netvsc_packet *packet,
 		struct rndis_message *rndis_msg,
 		struct hv_page_buffer **pb,
 		struct sk_buff *skb)
 {
 	struct netvsc_device *net_device;
 	int ret = 0;
 	struct netvsc_channel *nvchan;
 	u32 pktlen = packet->total_data_buflen, msd_len = 0;
 	unsigned int section_index = NETVSC_INVALID_INDEX;
 	struct multi_send_data *msdp;
 	struct hv_netvsc_packet *msd_send = NULL, *cur_send = NULL;
 	struct sk_buff *msd_skb = NULL;
 	bool try_batch;
 	bool xmit_more = (skb != NULL) ? skb->xmit_more : false;
 
 	net_device = get_outbound_net_device(device);
 	if (!net_device)
 		return -ENODEV;
 
 	/* We may race with netvsc_connect_vsp()/netvsc_init_buf() and get
 	 * here before the negotiation with the host is finished and
 	 * send_section_map may not be allocated yet.
 	 */
 	if (!net_device->send_section_map)
 		return -EAGAIN;
 
 	nvchan = &net_device->chan_table[packet->q_idx];
 	packet->send_buf_index = NETVSC_INVALID_INDEX;
 	packet->cp_partial = false;
 
 	/* Send control message directly without accessing msd (Multi-Send
 	 * Data) field which may be changed during data packet processing.
 	 */
 	if (!skb) {
 		cur_send = packet;
 		goto send_now;
 	}
 
 	/* batch packets in send buffer if possible */
 	msdp = &nvchan->msd;
 	if (msdp->pkt)
 		msd_len = msdp->pkt->total_data_buflen;
 
 	try_batch = (skb != NULL) && msd_len > 0 && msdp->count <
 		    net_device->max_pkt;
 
 	if (try_batch && msd_len + pktlen + net_device->pkt_align <
 	    net_device->send_section_size) {
 		section_index = msdp->pkt->send_buf_index;
 
 	} else if (try_batch && msd_len + packet->rmsg_size <
 		   net_device->send_section_size) {
 		section_index = msdp->pkt->send_buf_index;
 		packet->cp_partial = true;
 
 	} else if ((skb != NULL) && pktlen + net_device->pkt_align <
 		   net_device->send_section_size) {
 		section_index = netvsc_get_next_send_section(net_device);
 		if (section_index != NETVSC_INVALID_INDEX) {
 			move_pkt_msd(&msd_send, &msd_skb, msdp);
 			msd_len = 0;
 		}
 	}
 
 	if (section_index != NETVSC_INVALID_INDEX) {
 		netvsc_copy_to_send_buf(net_device,
 					section_index, msd_len,
 					packet, rndis_msg, pb, skb);
 
 		packet->send_buf_index = section_index;
 
 		if (packet->cp_partial) {
 			packet->page_buf_cnt -= packet->rmsg_pgcnt;
 			packet->total_data_buflen = msd_len + packet->rmsg_size;
 		} else {
 			packet->page_buf_cnt = 0;
 			packet->total_data_buflen += msd_len;
 		}
 
 		if (msdp->pkt) {
 			packet->total_packets += msdp->pkt->total_packets;
 			packet->total_bytes += msdp->pkt->total_bytes;
 		}
 
 		if (msdp->skb)
 			dev_consume_skb_any(msdp->skb);
 
 		if (xmit_more && !packet->cp_partial) {
 			msdp->skb = skb;
 			msdp->pkt = packet;
 			msdp->count++;
 		} else {
 			cur_send = packet;
 			msdp->skb = NULL;
 			msdp->pkt = NULL;
 			msdp->count = 0;
 		}
 	} else {
 		move_pkt_msd(&msd_send, &msd_skb, msdp);
 		cur_send = packet;
 	}
 
 	if (msd_send) {
 		int m_ret = netvsc_send_pkt(device, msd_send, net_device,
 					    NULL, msd_skb);
 
 		if (m_ret != 0) {
 			netvsc_free_send_slot(net_device,
 					      msd_send->send_buf_index);
 			dev_kfree_skb_any(msd_skb);
 		}
 	}
 
 send_now:
 	if (cur_send)
 		ret = netvsc_send_pkt(device, cur_send, net_device, pb, skb);
 
 	if (ret != 0 && section_index != NETVSC_INVALID_INDEX)
 		netvsc_free_send_slot(net_device, section_index);
 
 	return ret;
 }
 
 static int netvsc_send_recv_completion(struct vmbus_channel *channel,
 				       u64 transaction_id, u32 status)
 {
 	struct nvsp_message recvcompMessage;
 	int ret;
 
 	recvcompMessage.hdr.msg_type =
 				NVSP_MSG1_TYPE_SEND_RNDIS_PKT_COMPLETE;
 
 	recvcompMessage.msg.v1_msg.send_rndis_pkt_complete.status = status;
 
 	/* Send the completion */
 	ret = vmbus_sendpacket(channel, &recvcompMessage,
 			       sizeof(struct nvsp_message_header) + sizeof(u32),
 			       transaction_id, VM_PKT_COMP, 0);
 
 	return ret;
 }
 
 static inline void count_recv_comp_slot(struct netvsc_device *nvdev, u16 q_idx,
 					u32 *filled, u32 *avail)
 {
 	struct multi_recv_comp *mrc = &nvdev->chan_table[q_idx].mrc;
 	u32 first = mrc->first;
 	u32 next = mrc->next;
 
 	*filled = (first > next) ? NETVSC_RECVSLOT_MAX - first + next :
 		  next - first;
 
 	*avail = NETVSC_RECVSLOT_MAX - *filled - 1;
 }
 
 /* Read the first filled slot, no change to index */
 static inline struct recv_comp_data *read_recv_comp_slot(struct netvsc_device
 							 *nvdev, u16 q_idx)
 {
 	struct multi_recv_comp *mrc = &nvdev->chan_table[q_idx].mrc;
 	u32 filled, avail;
 
 	if (unlikely(!mrc->buf))
 		return NULL;
 
 	count_recv_comp_slot(nvdev, q_idx, &filled, &avail);
 	if (!filled)
 		return NULL;
 
 	return mrc->buf + mrc->first * sizeof(struct recv_comp_data);
 }
 
 /* Put the first filled slot back to available pool */
 static inline void put_recv_comp_slot(struct netvsc_device *nvdev, u16 q_idx)
 {
 	struct multi_recv_comp *mrc = &nvdev->chan_table[q_idx].mrc;
 	int num_recv;
 
 	mrc->first = (mrc->first + 1) % NETVSC_RECVSLOT_MAX;
 
 	num_recv = atomic_dec_return(&nvdev->num_outstanding_recvs);
 
 	if (nvdev->destroy && num_recv == 0)
 		wake_up(&nvdev->wait_drain);
 }
 
 /* Check and send pending recv completions */
 static void netvsc_chk_recv_comp(struct netvsc_device *nvdev,
 				 struct vmbus_channel *channel, u16 q_idx)
 {
 	struct recv_comp_data *rcd;
 	int ret;
 
 	while (true) {
 		rcd = read_recv_comp_slot(nvdev, q_idx);
 		if (!rcd)
 			break;
 
 		ret = netvsc_send_recv_completion(channel, rcd->tid,
 						  rcd->status);
 		if (ret)
 			break;
 
 		put_recv_comp_slot(nvdev, q_idx);
 	}
 }
 
 #define NETVSC_RCD_WATERMARK 80
 
 /* Get next available slot */
 static inline struct recv_comp_data *get_recv_comp_slot(
 	struct netvsc_device *nvdev, struct vmbus_channel *channel, u16 q_idx)
 {
 	struct multi_recv_comp *mrc = &nvdev->chan_table[q_idx].mrc;
 	u32 filled, avail, next;
 	struct recv_comp_data *rcd;
 
 	if (unlikely(!nvdev->recv_section))
 		return NULL;
 
 	if (unlikely(!mrc->buf))
 		return NULL;
 
 	if (atomic_read(&nvdev->num_outstanding_recvs) >
 	    nvdev->recv_section->num_sub_allocs * NETVSC_RCD_WATERMARK / 100)
 		netvsc_chk_recv_comp(nvdev, channel, q_idx);
 
 	count_recv_comp_slot(nvdev, q_idx, &filled, &avail);
 	if (!avail)
 		return NULL;
 
 	next = mrc->next;
 	rcd = mrc->buf + next * sizeof(struct recv_comp_data);
 	mrc->next = (next + 1) % NETVSC_RECVSLOT_MAX;
 
 	atomic_inc(&nvdev->num_outstanding_recvs);
 
 	return rcd;
 }
 
 static void netvsc_receive(struct net_device *ndev,
 		   struct netvsc_device *net_device,
 		   struct net_device_context *net_device_ctx,
 		   struct hv_device *device,
 		   struct vmbus_channel *channel,
 		   struct vmtransfer_page_packet_header *vmxferpage_packet,
 		   struct nvsp_message *nvsp)
 {
 	char *recv_buf = net_device->recv_buf;
 	u32 status = NVSP_STAT_SUCCESS;
 	int i;
 	int count = 0;
 	int ret;
 	struct recv_comp_data *rcd;
 	u16 q_idx = channel->offermsg.offer.sub_channel_index;
 
 	/* Make sure this is a valid nvsp packet */
 	if (unlikely(nvsp->hdr.msg_type != NVSP_MSG1_TYPE_SEND_RNDIS_PKT)) {
 		netif_err(net_device_ctx, rx_err, ndev,
 			  "Unknown nvsp packet type received %u\n",
 			  nvsp->hdr.msg_type);
 		return;
 	}
 
 	if (unlikely(vmxferpage_packet->xfer_pageset_id != NETVSC_RECEIVE_BUFFER_ID)) {
 		netif_err(net_device_ctx, rx_err, ndev,
 			  "Invalid xfer page set id - expecting %x got %x\n",
 			  NETVSC_RECEIVE_BUFFER_ID,
 			  vmxferpage_packet->xfer_pageset_id);
 		return;
 	}
 
 	count = vmxferpage_packet->range_cnt;
 
 	/* Each range represents 1 RNDIS pkt that contains 1 ethernet frame */
 	for (i = 0; i < count; i++) {
 		void *data = recv_buf
 			+ vmxferpage_packet->ranges[i].byte_offset;
 		u32 buflen = vmxferpage_packet->ranges[i].byte_count;
 
 		/* Pass it to the upper layer */
 		status = rndis_filter_receive(ndev, net_device, device,
 					      channel, data, buflen);
 	}
 
 	if (!net_device->chan_table[q_idx].mrc.buf) {
 		ret = netvsc_send_recv_completion(channel,
 						  vmxferpage_packet->d.trans_id,
 						  status);
 		if (ret)
 			netdev_err(ndev, "Recv_comp q:%hd, tid:%llx, err:%d\n",
 				   q_idx, vmxferpage_packet->d.trans_id, ret);
 		return;
 	}
 
 	rcd = get_recv_comp_slot(net_device, channel, q_idx);
 
 	if (!rcd) {
 		netdev_err(ndev, "Recv_comp full buf q:%hd, tid:%llx\n",
 			   q_idx, vmxferpage_packet->d.trans_id);
 		return;
 	}
 
 	rcd->tid = vmxferpage_packet->d.trans_id;
 	rcd->status = status;
 }
 
 static void netvsc_send_table(struct hv_device *hdev,
 			      struct nvsp_message *nvmsg)
 {
 	struct netvsc_device *nvscdev;
 	struct net_device *ndev = hv_get_drvdata(hdev);
 	int i;
 	u32 count, *tab;
 
 	nvscdev = get_outbound_net_device(hdev);
 	if (!nvscdev)
 		return;
 
 	count = nvmsg->msg.v5_msg.send_table.count;
 	if (count != VRSS_SEND_TAB_SIZE) {
 		netdev_err(ndev, "Received wrong send-table size:%u\n", count);
 		return;
 	}
 
 	tab = (u32 *)((unsigned long)&nvmsg->msg.v5_msg.send_table +
 		      nvmsg->msg.v5_msg.send_table.offset);
 
 	for (i = 0; i < count; i++)
 		nvscdev->send_table[i] = tab[i];
 }
 
 static void netvsc_send_vf(struct net_device_context *net_device_ctx,
 			   struct nvsp_message *nvmsg)
 {
 	net_device_ctx->vf_alloc = nvmsg->msg.v4_msg.vf_assoc.allocated;
 	net_device_ctx->vf_serial = nvmsg->msg.v4_msg.vf_assoc.serial;
 }
 
 static inline void netvsc_receive_inband(struct hv_device *hdev,
 				 struct net_device_context *net_device_ctx,
 				 struct nvsp_message *nvmsg)
 {
 	switch (nvmsg->hdr.msg_type) {
 	case NVSP_MSG5_TYPE_SEND_INDIRECTION_TABLE:
 		netvsc_send_table(hdev, nvmsg);
 		break;
 
 	case NVSP_MSG4_TYPE_SEND_VF_ASSOCIATION:
 		netvsc_send_vf(net_device_ctx, nvmsg);
 		break;
 	}
 }
 
 static void netvsc_process_raw_pkt(struct hv_device *device,
 				   struct vmbus_channel *channel,
 				   struct netvsc_device *net_device,
 				   struct net_device *ndev,
 				   u64 request_id,
 				   struct vmpacket_descriptor *desc)
 {
 	struct net_device_context *net_device_ctx = netdev_priv(ndev);
 	struct nvsp_message *nvmsg
 		= (struct nvsp_message *)((unsigned long)desc
 					  + (desc->offset8 << 3));
 
 	switch (desc->type) {
 	case VM_PKT_COMP:
 		netvsc_send_completion(net_device, channel, device, desc);
 		break;
 
 	case VM_PKT_DATA_USING_XFER_PAGES:
 		netvsc_receive(ndev, net_device, net_device_ctx,
 			       device, channel,
 			       (struct vmtransfer_page_packet_header *)desc,
 			       nvmsg);
 		break;
 
 	case VM_PKT_DATA_INBAND:
 		netvsc_receive_inband(device, net_device_ctx, nvmsg);
 		break;
 
 	default:
 		netdev_err(ndev, "unhandled packet type %d, tid %llx\n",
 			   desc->type, request_id);
 		break;
 	}
 }
 
 void netvsc_channel_cb(void *context)
 {
 	struct vmbus_channel *channel = context;
 	u16 q_idx = channel->offermsg.offer.sub_channel_index;
 	struct hv_device *device;
 	struct netvsc_device *net_device;
 	struct vmpacket_descriptor *desc;
 	struct net_device *ndev;
 	bool need_to_commit = false;
 
 	if (channel->primary_channel != NULL)
 		device = channel->primary_channel->device_obj;
 	else
 		device = channel->device_obj;
 
 	ndev = hv_get_drvdata(device);
 	if (unlikely(!ndev))
 		return;
 
 	net_device = net_device_to_netvsc_device(ndev);
 	if (unlikely(net_device->destroy) &&
 	    netvsc_channel_idle(net_device, q_idx))
 		return;
 
 	/* commit_rd_index() -> hv_signal_on_read() needs this. */
 	init_cached_read_index(channel);
 
 	while ((desc = get_next_pkt_raw(channel)) != NULL) {
 		netvsc_process_raw_pkt(device, channel, net_device,
 				       ndev, desc->trans_id, desc);
 
 		put_pkt_raw(channel, desc);
 		need_to_commit = true;
 	}
 
 	if (need_to_commit)
 		commit_rd_index(channel);
 
 	netvsc_chk_recv_comp(net_device, channel, q_idx);
 }
 
 /*
  * netvsc_device_add - Callback when the device belonging to this
  * driver is added
  */
 int netvsc_device_add(struct hv_device *device,
 		      const struct netvsc_device_info *device_info)
 {
 	int i, ret = 0;
 	int ring_size = device_info->ring_size;
 	struct netvsc_device *net_device;
 	struct net_device *ndev = hv_get_drvdata(device);
 	struct net_device_context *net_device_ctx = netdev_priv(ndev);
 
 	net_device = alloc_net_device();
 	if (!net_device)
 		return -ENOMEM;
 
 	net_device->ring_size = ring_size;
 
 	/* Open the channel */
 	ret = vmbus_open(device->channel, ring_size * PAGE_SIZE,
 			 ring_size * PAGE_SIZE, NULL, 0,
 			 netvsc_channel_cb, device->channel);
 
 	if (ret != 0) {
 		netdev_err(ndev, "unable to open channel: %d\n", ret);
 		goto cleanup;
 	}
 
 	/* Channel is opened */
 	netdev_dbg(ndev, "hv_netvsc channel opened successfully\n");
 
 	/* If we're reopening the device we may have multiple queues, fill the
 	 * chn_table with the default channel to use it before subchannels are
 	 * opened.
 	 */
 	for (i = 0; i < VRSS_CHANNEL_MAX; i++)
 		net_device->chan_table[i].channel = device->channel;
 
 	/* Writing nvdev pointer unlocks netvsc_send(), make sure chn_table is
 	 * populated.
 	 */
 	wmb();
 
 	net_device_ctx->nvdev = net_device;
 
 	/* Connect with the NetVsp */
 	ret = netvsc_connect_vsp(device);
 	if (ret != 0) {
 		netdev_err(ndev,
 			"unable to connect to NetVSP - %d\n", ret);
 		goto close;
 	}
 
 	return ret;
 
 close:
 	/* Now, we can close the channel safely */
 	vmbus_close(device->channel);
 
 cleanup:
 	free_netvsc_device(net_device);
 
 	return ret;
 }
diff --git a/drivers/nvmem/core.c b/drivers/nvmem/core.c
index 398ea7f54826..408b521ee520 100644
--- a/drivers/nvmem/core.c
+++ b/drivers/nvmem/core.c
@@ -1,1225 +1,1234 @@
 /*
  * nvmem framework core.
  *
  * Copyright (C) 2015 Srinivas Kandagatla <srinivas.kandagatla@linaro.org>
  * Copyright (C) 2013 Maxime Ripard <maxime.ripard@free-electrons.com>
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License version 2 and
  * only version 2 as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
  */
 
 #include <linux/device.h>
 #include <linux/export.h>
 #include <linux/fs.h>
 #include <linux/idr.h>
 #include <linux/init.h>
 #include <linux/module.h>
 #include <linux/nvmem-consumer.h>
 #include <linux/nvmem-provider.h>
 #include <linux/of.h>
 #include <linux/slab.h>
 
 struct nvmem_device {
 	const char		*name;
 	struct module		*owner;
 	struct device		dev;
 	int			stride;
 	int			word_size;
 	int			ncells;
 	int			id;
 	int			users;
 	size_t			size;
 	bool			read_only;
 	int			flags;
 	struct bin_attribute	eeprom;
 	struct device		*base_dev;
 	nvmem_reg_read_t	reg_read;
 	nvmem_reg_write_t	reg_write;
 	void *priv;
 };
 
 #define FLAG_COMPAT		BIT(0)
 
 struct nvmem_cell {
 	const char		*name;
 	int			offset;
 	int			bytes;
 	int			bit_offset;
 	int			nbits;
 	struct nvmem_device	*nvmem;
 	struct list_head	node;
 };
 
 static DEFINE_MUTEX(nvmem_mutex);
 static DEFINE_IDA(nvmem_ida);
 
 static LIST_HEAD(nvmem_cells);
 static DEFINE_MUTEX(nvmem_cells_mutex);
 
 #ifdef CONFIG_DEBUG_LOCK_ALLOC
 static struct lock_class_key eeprom_lock_key;
 #endif
 
 #define to_nvmem_device(d) container_of(d, struct nvmem_device, dev)
 static int nvmem_reg_read(struct nvmem_device *nvmem, unsigned int offset,
 			  void *val, size_t bytes)
 {
 	if (nvmem->reg_read)
 		return nvmem->reg_read(nvmem->priv, offset, val, bytes);
 
 	return -EINVAL;
 }
 
 static int nvmem_reg_write(struct nvmem_device *nvmem, unsigned int offset,
 			   void *val, size_t bytes)
 {
 	if (nvmem->reg_write)
 		return nvmem->reg_write(nvmem->priv, offset, val, bytes);
 
 	return -EINVAL;
 }
 
 static ssize_t bin_attr_nvmem_read(struct file *filp, struct kobject *kobj,
 				    struct bin_attribute *attr,
 				    char *buf, loff_t pos, size_t count)
 {
 	struct device *dev;
 	struct nvmem_device *nvmem;
 	int rc;
 
 	if (attr->private)
 		dev = attr->private;
 	else
 		dev = container_of(kobj, struct device, kobj);
 	nvmem = to_nvmem_device(dev);
 
 	/* Stop the user from reading */
 	if (pos >= nvmem->size)
 		return 0;
 
 	if (count < nvmem->word_size)
 		return -EINVAL;
 
 	if (pos + count > nvmem->size)
 		count = nvmem->size - pos;
 
 	count = round_down(count, nvmem->word_size);
 
 	rc = nvmem_reg_read(nvmem, pos, buf, count);
 
 	if (rc)
 		return rc;
 
 	return count;
 }
 
 static ssize_t bin_attr_nvmem_write(struct file *filp, struct kobject *kobj,
 				     struct bin_attribute *attr,
 				     char *buf, loff_t pos, size_t count)
 {
 	struct device *dev;
 	struct nvmem_device *nvmem;
 	int rc;
 
 	if (attr->private)
 		dev = attr->private;
 	else
 		dev = container_of(kobj, struct device, kobj);
 	nvmem = to_nvmem_device(dev);
 
 	/* Stop the user from writing */
 	if (pos >= nvmem->size)
 		return 0;
 
 	if (count < nvmem->word_size)
 		return -EINVAL;
 
 	if (pos + count > nvmem->size)
 		count = nvmem->size - pos;
 
 	count = round_down(count, nvmem->word_size);
 
 	rc = nvmem_reg_write(nvmem, pos, buf, count);
 
 	if (rc)
 		return rc;
 
 	return count;
 }
 
 /* default read/write permissions */
 static struct bin_attribute bin_attr_rw_nvmem = {
 	.attr	= {
 		.name	= "nvmem",
 		.mode	= S_IWUSR | S_IRUGO,
 	},
 	.read	= bin_attr_nvmem_read,
 	.write	= bin_attr_nvmem_write,
 };
 
 static struct bin_attribute *nvmem_bin_rw_attributes[] = {
 	&bin_attr_rw_nvmem,
 	NULL,
 };
 
 static const struct attribute_group nvmem_bin_rw_group = {
 	.bin_attrs	= nvmem_bin_rw_attributes,
 };
 
 static const struct attribute_group *nvmem_rw_dev_groups[] = {
 	&nvmem_bin_rw_group,
 	NULL,
 };
 
 /* read only permission */
 static struct bin_attribute bin_attr_ro_nvmem = {
 	.attr	= {
 		.name	= "nvmem",
 		.mode	= S_IRUGO,
 	},
 	.read	= bin_attr_nvmem_read,
 };
 
 static struct bin_attribute *nvmem_bin_ro_attributes[] = {
 	&bin_attr_ro_nvmem,
 	NULL,
 };
 
 static const struct attribute_group nvmem_bin_ro_group = {
 	.bin_attrs	= nvmem_bin_ro_attributes,
 };
 
 static const struct attribute_group *nvmem_ro_dev_groups[] = {
 	&nvmem_bin_ro_group,
 	NULL,
 };
 
 /* default read/write permissions, root only */
 static struct bin_attribute bin_attr_rw_root_nvmem = {
 	.attr	= {
 		.name	= "nvmem",
 		.mode	= S_IWUSR | S_IRUSR,
 	},
 	.read	= bin_attr_nvmem_read,
 	.write	= bin_attr_nvmem_write,
 };
 
 static struct bin_attribute *nvmem_bin_rw_root_attributes[] = {
 	&bin_attr_rw_root_nvmem,
 	NULL,
 };
 
 static const struct attribute_group nvmem_bin_rw_root_group = {
 	.bin_attrs	= nvmem_bin_rw_root_attributes,
 };
 
 static const struct attribute_group *nvmem_rw_root_dev_groups[] = {
 	&nvmem_bin_rw_root_group,
 	NULL,
 };
 
 /* read only permission, root only */
 static struct bin_attribute bin_attr_ro_root_nvmem = {
 	.attr	= {
 		.name	= "nvmem",
 		.mode	= S_IRUSR,
 	},
 	.read	= bin_attr_nvmem_read,
 };
 
 static struct bin_attribute *nvmem_bin_ro_root_attributes[] = {
 	&bin_attr_ro_root_nvmem,
 	NULL,
 };
 
 static const struct attribute_group nvmem_bin_ro_root_group = {
 	.bin_attrs	= nvmem_bin_ro_root_attributes,
 };
 
 static const struct attribute_group *nvmem_ro_root_dev_groups[] = {
 	&nvmem_bin_ro_root_group,
 	NULL,
 };
 
 static void nvmem_release(struct device *dev)
 {
 	struct nvmem_device *nvmem = to_nvmem_device(dev);
 
 	ida_simple_remove(&nvmem_ida, nvmem->id);
 	kfree(nvmem);
 }
 
 static const struct device_type nvmem_provider_type = {
 	.release	= nvmem_release,
 };
 
 static struct bus_type nvmem_bus_type = {
 	.name		= "nvmem",
 };
 
 static int of_nvmem_match(struct device *dev, void *nvmem_np)
 {
 	return dev->of_node == nvmem_np;
 }
 
 static struct nvmem_device *of_nvmem_find(struct device_node *nvmem_np)
 {
 	struct device *d;
 
 	if (!nvmem_np)
 		return NULL;
 
 	d = bus_find_device(&nvmem_bus_type, NULL, nvmem_np, of_nvmem_match);
 
 	if (!d)
 		return NULL;
 
 	return to_nvmem_device(d);
 }
 
 static struct nvmem_cell *nvmem_find_cell(const char *cell_id)
 {
 	struct nvmem_cell *p;
 
 	list_for_each_entry(p, &nvmem_cells, node)
 		if (p && !strcmp(p->name, cell_id))
 			return p;
 
 	return NULL;
 }
 
 static void nvmem_cell_drop(struct nvmem_cell *cell)
 {
 	mutex_lock(&nvmem_cells_mutex);
 	list_del(&cell->node);
 	mutex_unlock(&nvmem_cells_mutex);
 	kfree(cell);
 }
 
 static void nvmem_device_remove_all_cells(const struct nvmem_device *nvmem)
 {
 	struct nvmem_cell *cell;
 	struct list_head *p, *n;
 
 	list_for_each_safe(p, n, &nvmem_cells) {
 		cell = list_entry(p, struct nvmem_cell, node);
 		if (cell->nvmem == nvmem)
 			nvmem_cell_drop(cell);
 	}
 }
 
 static void nvmem_cell_add(struct nvmem_cell *cell)
 {
 	mutex_lock(&nvmem_cells_mutex);
 	list_add_tail(&cell->node, &nvmem_cells);
 	mutex_unlock(&nvmem_cells_mutex);
 }
 
 static int nvmem_cell_info_to_nvmem_cell(struct nvmem_device *nvmem,
 				   const struct nvmem_cell_info *info,
 				   struct nvmem_cell *cell)
 {
 	cell->nvmem = nvmem;
 	cell->offset = info->offset;
 	cell->bytes = info->bytes;
 	cell->name = info->name;
 
 	cell->bit_offset = info->bit_offset;
 	cell->nbits = info->nbits;
 
 	if (cell->nbits)
 		cell->bytes = DIV_ROUND_UP(cell->nbits + cell->bit_offset,
 					   BITS_PER_BYTE);
 
 	if (!IS_ALIGNED(cell->offset, nvmem->stride)) {
 		dev_err(&nvmem->dev,
 			"cell %s unaligned to nvmem stride %d\n",
 			cell->name, nvmem->stride);
 		return -EINVAL;
 	}
 
 	return 0;
 }
 
 static int nvmem_add_cells(struct nvmem_device *nvmem,
 			   const struct nvmem_config *cfg)
 {
 	struct nvmem_cell **cells;
 	const struct nvmem_cell_info *info = cfg->cells;
 	int i, rval;
 
 	cells = kcalloc(cfg->ncells, sizeof(*cells), GFP_KERNEL);
 	if (!cells)
 		return -ENOMEM;
 
 	for (i = 0; i < cfg->ncells; i++) {
 		cells[i] = kzalloc(sizeof(**cells), GFP_KERNEL);
 		if (!cells[i]) {
 			rval = -ENOMEM;
 			goto err;
 		}
 
 		rval = nvmem_cell_info_to_nvmem_cell(nvmem, &info[i], cells[i]);
 		if (rval) {
 			kfree(cells[i]);
 			goto err;
 		}
 
 		nvmem_cell_add(cells[i]);
 	}
 
 	nvmem->ncells = cfg->ncells;
 	/* remove tmp array */
 	kfree(cells);
 
 	return 0;
 err:
 	while (i--)
 		nvmem_cell_drop(cells[i]);
 
 	kfree(cells);
 
 	return rval;
 }
 
 /*
  * nvmem_setup_compat() - Create an additional binary entry in
  * drivers sys directory, to be backwards compatible with the older
  * drivers/misc/eeprom drivers.
  */
 static int nvmem_setup_compat(struct nvmem_device *nvmem,
 			      const struct nvmem_config *config)
 {
 	int rval;
 
 	if (!config->base_dev)
 		return -EINVAL;
 
 	if (nvmem->read_only)
 		nvmem->eeprom = bin_attr_ro_root_nvmem;
 	else
 		nvmem->eeprom = bin_attr_rw_root_nvmem;
 	nvmem->eeprom.attr.name = "eeprom";
 	nvmem->eeprom.size = nvmem->size;
 #ifdef CONFIG_DEBUG_LOCK_ALLOC
 	nvmem->eeprom.attr.key = &eeprom_lock_key;
 #endif
 	nvmem->eeprom.private = &nvmem->dev;
 	nvmem->base_dev = config->base_dev;
 
 	rval = device_create_bin_file(nvmem->base_dev, &nvmem->eeprom);
 	if (rval) {
 		dev_err(&nvmem->dev,
 			"Failed to create eeprom binary file %d\n", rval);
 		return rval;
 	}
 
 	nvmem->flags |= FLAG_COMPAT;
 
 	return 0;
 }
 
 /**
  * nvmem_register() - Register a nvmem device for given nvmem_config.
  * Also creates an binary entry in /sys/bus/nvmem/devices/dev-name/nvmem
  *
  * @config: nvmem device configuration with which nvmem device is created.
  *
  * Return: Will be an ERR_PTR() on error or a valid pointer to nvmem_device
  * on success.
  */
 
 struct nvmem_device *nvmem_register(const struct nvmem_config *config)
 {
 	struct nvmem_device *nvmem;
 	struct device_node *np;
 	int rval;
 
 	if (!config->dev)
 		return ERR_PTR(-EINVAL);
 
 	nvmem = kzalloc(sizeof(*nvmem), GFP_KERNEL);
 	if (!nvmem)
 		return ERR_PTR(-ENOMEM);
 
 	rval  = ida_simple_get(&nvmem_ida, 0, 0, GFP_KERNEL);
 	if (rval < 0) {
 		kfree(nvmem);
 		return ERR_PTR(rval);
 	}
 
 	nvmem->id = rval;
 	nvmem->owner = config->owner;
 	nvmem->stride = config->stride;
 	nvmem->word_size = config->word_size;
 	nvmem->size = config->size;
 	nvmem->dev.type = &nvmem_provider_type;
 	nvmem->dev.bus = &nvmem_bus_type;
 	nvmem->dev.parent = config->dev;
 	nvmem->priv = config->priv;
 	nvmem->reg_read = config->reg_read;
 	nvmem->reg_write = config->reg_write;
 	np = config->dev->of_node;
 	nvmem->dev.of_node = np;
 	dev_set_name(&nvmem->dev, "%s%d",
 		     config->name ? : "nvmem", config->id);
 
 	nvmem->read_only = of_property_read_bool(np, "read-only") |
 			   config->read_only;
 
 	if (config->root_only)
 		nvmem->dev.groups = nvmem->read_only ?
 			nvmem_ro_root_dev_groups :
 			nvmem_rw_root_dev_groups;
 	else
 		nvmem->dev.groups = nvmem->read_only ?
 			nvmem_ro_dev_groups :
 			nvmem_rw_dev_groups;
 
 	device_initialize(&nvmem->dev);
 
 	dev_dbg(&nvmem->dev, "Registering nvmem device %s\n", config->name);
 
 	rval = device_add(&nvmem->dev);
 	if (rval)
 		goto out;
 
 	if (config->compat) {
 		rval = nvmem_setup_compat(nvmem, config);
 		if (rval)
 			goto out;
 	}
 
 	if (config->cells)
 		nvmem_add_cells(nvmem, config);
 
 	return nvmem;
 out:
 	ida_simple_remove(&nvmem_ida, nvmem->id);
 	kfree(nvmem);
 	return ERR_PTR(rval);
 }
 EXPORT_SYMBOL_GPL(nvmem_register);
 
 /**
  * nvmem_unregister() - Unregister previously registered nvmem device
  *
  * @nvmem: Pointer to previously registered nvmem device.
  *
  * Return: Will be an negative on error or a zero on success.
  */
 int nvmem_unregister(struct nvmem_device *nvmem)
 {
 	mutex_lock(&nvmem_mutex);
 	if (nvmem->users) {
 		mutex_unlock(&nvmem_mutex);
 		return -EBUSY;
 	}
 	mutex_unlock(&nvmem_mutex);
 
 	if (nvmem->flags & FLAG_COMPAT)
 		device_remove_bin_file(nvmem->base_dev, &nvmem->eeprom);
 
 	nvmem_device_remove_all_cells(nvmem);
 	device_del(&nvmem->dev);
 
 	return 0;
 }
 EXPORT_SYMBOL_GPL(nvmem_unregister);
 
 static struct nvmem_device *__nvmem_device_get(struct device_node *np,
 					       struct nvmem_cell **cellp,
 					       const char *cell_id)
 {
 	struct nvmem_device *nvmem = NULL;
 
 	mutex_lock(&nvmem_mutex);
 
 	if (np) {
 		nvmem = of_nvmem_find(np);
 		if (!nvmem) {
 			mutex_unlock(&nvmem_mutex);
 			return ERR_PTR(-EPROBE_DEFER);
 		}
 	} else {
 		struct nvmem_cell *cell = nvmem_find_cell(cell_id);
 
 		if (cell) {
 			nvmem = cell->nvmem;
 			*cellp = cell;
 		}
 
 		if (!nvmem) {
 			mutex_unlock(&nvmem_mutex);
 			return ERR_PTR(-ENOENT);
 		}
 	}
 
 	nvmem->users++;
 	mutex_unlock(&nvmem_mutex);
 
 	if (!try_module_get(nvmem->owner)) {
 		dev_err(&nvmem->dev,
 			"could not increase module refcount for cell %s\n",
 			nvmem->name);
 
 		mutex_lock(&nvmem_mutex);
 		nvmem->users--;
 		mutex_unlock(&nvmem_mutex);
 
 		return ERR_PTR(-EINVAL);
 	}
 
 	return nvmem;
 }
 
 static void __nvmem_device_put(struct nvmem_device *nvmem)
 {
 	module_put(nvmem->owner);
 	mutex_lock(&nvmem_mutex);
 	nvmem->users--;
 	mutex_unlock(&nvmem_mutex);
 }
 
 static int nvmem_match(struct device *dev, void *data)
 {
 	return !strcmp(dev_name(dev), data);
 }
 
 static struct nvmem_device *nvmem_find(const char *name)
 {
 	struct device *d;
 
 	d = bus_find_device(&nvmem_bus_type, NULL, (void *)name, nvmem_match);
 
 	if (!d)
 		return NULL;
 
 	return to_nvmem_device(d);
 }
 
 #if IS_ENABLED(CONFIG_NVMEM) && IS_ENABLED(CONFIG_OF)
 /**
  * of_nvmem_device_get() - Get nvmem device from a given id
  *
- * @dev node: Device tree node that uses the nvmem device
+ * @np: Device tree node that uses the nvmem device.
  * @id: nvmem name from nvmem-names property.
  *
  * Return: ERR_PTR() on error or a valid pointer to a struct nvmem_device
  * on success.
  */
 struct nvmem_device *of_nvmem_device_get(struct device_node *np, const char *id)
 {
 
 	struct device_node *nvmem_np;
 	int index;
 
 	index = of_property_match_string(np, "nvmem-names", id);
 
 	nvmem_np = of_parse_phandle(np, "nvmem", index);
 	if (!nvmem_np)
 		return ERR_PTR(-EINVAL);
 
 	return __nvmem_device_get(nvmem_np, NULL, NULL);
 }
 EXPORT_SYMBOL_GPL(of_nvmem_device_get);
 #endif
 
 /**
  * nvmem_device_get() - Get nvmem device from a given id
  *
- * @dev : Device that uses the nvmem device
- * @id: nvmem name from nvmem-names property.
+ * @dev: Device that uses the nvmem device.
+ * @dev_name: name of the requested nvmem device.
  *
  * Return: ERR_PTR() on error or a valid pointer to a struct nvmem_device
  * on success.
  */
 struct nvmem_device *nvmem_device_get(struct device *dev, const char *dev_name)
 {
 	if (dev->of_node) { /* try dt first */
 		struct nvmem_device *nvmem;
 
 		nvmem = of_nvmem_device_get(dev->of_node, dev_name);
 
 		if (!IS_ERR(nvmem) || PTR_ERR(nvmem) == -EPROBE_DEFER)
 			return nvmem;
 
 	}
 
 	return nvmem_find(dev_name);
 }
 EXPORT_SYMBOL_GPL(nvmem_device_get);
 
 static int devm_nvmem_device_match(struct device *dev, void *res, void *data)
 {
 	struct nvmem_device **nvmem = res;
 
 	if (WARN_ON(!nvmem || !*nvmem))
 		return 0;
 
 	return *nvmem == data;
 }
 
 static void devm_nvmem_device_release(struct device *dev, void *res)
 {
 	nvmem_device_put(*(struct nvmem_device **)res);
 }
 
 /**
  * devm_nvmem_device_put() - put alredy got nvmem device
  *
+ * @dev: Device that uses the nvmem device.
  * @nvmem: pointer to nvmem device allocated by devm_nvmem_cell_get(),
  * that needs to be released.
  */
 void devm_nvmem_device_put(struct device *dev, struct nvmem_device *nvmem)
 {
 	int ret;
 
 	ret = devres_release(dev, devm_nvmem_device_release,
 			     devm_nvmem_device_match, nvmem);
 
 	WARN_ON(ret);
 }
 EXPORT_SYMBOL_GPL(devm_nvmem_device_put);
 
 /**
  * nvmem_device_put() - put alredy got nvmem device
  *
  * @nvmem: pointer to nvmem device that needs to be released.
  */
 void nvmem_device_put(struct nvmem_device *nvmem)
 {
 	__nvmem_device_put(nvmem);
 }
 EXPORT_SYMBOL_GPL(nvmem_device_put);
 
 /**
  * devm_nvmem_device_get() - Get nvmem cell of device form a given id
  *
- * @dev node: Device tree node that uses the nvmem cell
- * @id: nvmem name in nvmems property.
+ * @dev: Device that requests the nvmem device.
+ * @id: name id for the requested nvmem device.
  *
  * Return: ERR_PTR() on error or a valid pointer to a struct nvmem_cell
  * on success.  The nvmem_cell will be freed by the automatically once the
  * device is freed.
  */
 struct nvmem_device *devm_nvmem_device_get(struct device *dev, const char *id)
 {
 	struct nvmem_device **ptr, *nvmem;
 
 	ptr = devres_alloc(devm_nvmem_device_release, sizeof(*ptr), GFP_KERNEL);
 	if (!ptr)
 		return ERR_PTR(-ENOMEM);
 
 	nvmem = nvmem_device_get(dev, id);
 	if (!IS_ERR(nvmem)) {
 		*ptr = nvmem;
 		devres_add(dev, ptr);
 	} else {
 		devres_free(ptr);
 	}
 
 	return nvmem;
 }
 EXPORT_SYMBOL_GPL(devm_nvmem_device_get);
 
 static struct nvmem_cell *nvmem_cell_get_from_list(const char *cell_id)
 {
 	struct nvmem_cell *cell = NULL;
 	struct nvmem_device *nvmem;
 
 	nvmem = __nvmem_device_get(NULL, &cell, cell_id);
 	if (IS_ERR(nvmem))
 		return ERR_CAST(nvmem);
 
 	return cell;
 }
 
 #if IS_ENABLED(CONFIG_NVMEM) && IS_ENABLED(CONFIG_OF)
 /**
  * of_nvmem_cell_get() - Get a nvmem cell from given device node and cell id
  *
- * @dev node: Device tree node that uses the nvmem cell
- * @id: nvmem cell name from nvmem-cell-names property.
+ * @np: Device tree node that uses the nvmem cell.
+ * @name: nvmem cell name from nvmem-cell-names property, or NULL
+ *	  for the cell at index 0 (the lone cell with no accompanying
+ *	  nvmem-cell-names property).
  *
  * Return: Will be an ERR_PTR() on error or a valid pointer
  * to a struct nvmem_cell.  The nvmem_cell will be freed by the
  * nvmem_cell_put().
  */
 struct nvmem_cell *of_nvmem_cell_get(struct device_node *np,
 					    const char *name)
 {
 	struct device_node *cell_np, *nvmem_np;
 	struct nvmem_cell *cell;
 	struct nvmem_device *nvmem;
 	const __be32 *addr;
-	int rval, len, index;
+	int rval, len;
+	int index = 0;
 
-	index = of_property_match_string(np, "nvmem-cell-names", name);
+	/* if cell name exists, find index to the name */
+	if (name)
+		index = of_property_match_string(np, "nvmem-cell-names", name);
 
 	cell_np = of_parse_phandle(np, "nvmem-cells", index);
 	if (!cell_np)
 		return ERR_PTR(-EINVAL);
 
 	nvmem_np = of_get_next_parent(cell_np);
 	if (!nvmem_np)
 		return ERR_PTR(-EINVAL);
 
 	nvmem = __nvmem_device_get(nvmem_np, NULL, NULL);
 	if (IS_ERR(nvmem))
 		return ERR_CAST(nvmem);
 
 	addr = of_get_property(cell_np, "reg", &len);
 	if (!addr || (len < 2 * sizeof(u32))) {
 		dev_err(&nvmem->dev, "nvmem: invalid reg on %s\n",
 			cell_np->full_name);
 		rval  = -EINVAL;
 		goto err_mem;
 	}
 
 	cell = kzalloc(sizeof(*cell), GFP_KERNEL);
 	if (!cell) {
 		rval = -ENOMEM;
 		goto err_mem;
 	}
 
 	cell->nvmem = nvmem;
 	cell->offset = be32_to_cpup(addr++);
 	cell->bytes = be32_to_cpup(addr);
 	cell->name = cell_np->name;
 
 	addr = of_get_property(cell_np, "bits", &len);
 	if (addr && len == (2 * sizeof(u32))) {
 		cell->bit_offset = be32_to_cpup(addr++);
 		cell->nbits = be32_to_cpup(addr);
 	}
 
 	if (cell->nbits)
 		cell->bytes = DIV_ROUND_UP(cell->nbits + cell->bit_offset,
 					   BITS_PER_BYTE);
 
 	if (!IS_ALIGNED(cell->offset, nvmem->stride)) {
 			dev_err(&nvmem->dev,
 				"cell %s unaligned to nvmem stride %d\n",
 				cell->name, nvmem->stride);
 		rval  = -EINVAL;
 		goto err_sanity;
 	}
 
 	nvmem_cell_add(cell);
 
 	return cell;
 
 err_sanity:
 	kfree(cell);
 
 err_mem:
 	__nvmem_device_put(nvmem);
 
 	return ERR_PTR(rval);
 }
 EXPORT_SYMBOL_GPL(of_nvmem_cell_get);
 #endif
 
 /**
  * nvmem_cell_get() - Get nvmem cell of device form a given cell name
  *
- * @dev node: Device tree node that uses the nvmem cell
- * @id: nvmem cell name to get.
+ * @dev: Device that requests the nvmem cell.
+ * @cell_id: nvmem cell name to get.
  *
  * Return: Will be an ERR_PTR() on error or a valid pointer
  * to a struct nvmem_cell.  The nvmem_cell will be freed by the
  * nvmem_cell_put().
  */
 struct nvmem_cell *nvmem_cell_get(struct device *dev, const char *cell_id)
 {
 	struct nvmem_cell *cell;
 
 	if (dev->of_node) { /* try dt first */
 		cell = of_nvmem_cell_get(dev->of_node, cell_id);
 		if (!IS_ERR(cell) || PTR_ERR(cell) == -EPROBE_DEFER)
 			return cell;
 	}
 
 	return nvmem_cell_get_from_list(cell_id);
 }
 EXPORT_SYMBOL_GPL(nvmem_cell_get);
 
 static void devm_nvmem_cell_release(struct device *dev, void *res)
 {
 	nvmem_cell_put(*(struct nvmem_cell **)res);
 }
 
 /**
  * devm_nvmem_cell_get() - Get nvmem cell of device form a given id
  *
- * @dev node: Device tree node that uses the nvmem cell
- * @id: nvmem id in nvmem-names property.
+ * @dev: Device that requests the nvmem cell.
+ * @id: nvmem cell name id to get.
  *
  * Return: Will be an ERR_PTR() on error or a valid pointer
  * to a struct nvmem_cell.  The nvmem_cell will be freed by the
  * automatically once the device is freed.
  */
 struct nvmem_cell *devm_nvmem_cell_get(struct device *dev, const char *id)
 {
 	struct nvmem_cell **ptr, *cell;
 
 	ptr = devres_alloc(devm_nvmem_cell_release, sizeof(*ptr), GFP_KERNEL);
 	if (!ptr)
 		return ERR_PTR(-ENOMEM);
 
 	cell = nvmem_cell_get(dev, id);
 	if (!IS_ERR(cell)) {
 		*ptr = cell;
 		devres_add(dev, ptr);
 	} else {
 		devres_free(ptr);
 	}
 
 	return cell;
 }
 EXPORT_SYMBOL_GPL(devm_nvmem_cell_get);
 
 static int devm_nvmem_cell_match(struct device *dev, void *res, void *data)
 {
 	struct nvmem_cell **c = res;
 
 	if (WARN_ON(!c || !*c))
 		return 0;
 
 	return *c == data;
 }
 
 /**
  * devm_nvmem_cell_put() - Release previously allocated nvmem cell
  * from devm_nvmem_cell_get.
  *
- * @cell: Previously allocated nvmem cell by devm_nvmem_cell_get()
+ * @dev: Device that requests the nvmem cell.
+ * @cell: Previously allocated nvmem cell by devm_nvmem_cell_get().
  */
 void devm_nvmem_cell_put(struct device *dev, struct nvmem_cell *cell)
 {
 	int ret;
 
 	ret = devres_release(dev, devm_nvmem_cell_release,
 				devm_nvmem_cell_match, cell);
 
 	WARN_ON(ret);
 }
 EXPORT_SYMBOL(devm_nvmem_cell_put);
 
 /**
  * nvmem_cell_put() - Release previously allocated nvmem cell.
  *
- * @cell: Previously allocated nvmem cell by nvmem_cell_get()
+ * @cell: Previously allocated nvmem cell by nvmem_cell_get().
  */
 void nvmem_cell_put(struct nvmem_cell *cell)
 {
 	struct nvmem_device *nvmem = cell->nvmem;
 
 	__nvmem_device_put(nvmem);
 	nvmem_cell_drop(cell);
 }
 EXPORT_SYMBOL_GPL(nvmem_cell_put);
 
 static inline void nvmem_shift_read_buffer_in_place(struct nvmem_cell *cell,
 						    void *buf)
 {
 	u8 *p, *b;
 	int i, bit_offset = cell->bit_offset;
 
 	p = b = buf;
 	if (bit_offset) {
 		/* First shift */
 		*b++ >>= bit_offset;
 
 		/* setup rest of the bytes if any */
 		for (i = 1; i < cell->bytes; i++) {
 			/* Get bits from next byte and shift them towards msb */
 			*p |= *b << (BITS_PER_BYTE - bit_offset);
 
 			p = b;
 			*b++ >>= bit_offset;
 		}
 
 		/* result fits in less bytes */
 		if (cell->bytes != DIV_ROUND_UP(cell->nbits, BITS_PER_BYTE))
 			*p-- = 0;
 	}
 	/* clear msb bits if any leftover in the last byte */
 	*p &= GENMASK((cell->nbits%BITS_PER_BYTE) - 1, 0);
 }
 
 static int __nvmem_cell_read(struct nvmem_device *nvmem,
 		      struct nvmem_cell *cell,
 		      void *buf, size_t *len)
 {
 	int rc;
 
 	rc = nvmem_reg_read(nvmem, cell->offset, buf, cell->bytes);
 
 	if (rc)
 		return rc;
 
 	/* shift bits in-place */
 	if (cell->bit_offset || cell->nbits)
 		nvmem_shift_read_buffer_in_place(cell, buf);
 
-	*len = cell->bytes;
+	if (len)
+		*len = cell->bytes;
 
 	return 0;
 }
 
 /**
  * nvmem_cell_read() - Read a given nvmem cell
  *
  * @cell: nvmem cell to be read.
- * @len: pointer to length of cell which will be populated on successful read.
+ * @len: pointer to length of cell which will be populated on successful read;
+ *	 can be NULL.
  *
  * Return: ERR_PTR() on error or a valid pointer to a buffer on success. The
  * buffer should be freed by the consumer with a kfree().
  */
 void *nvmem_cell_read(struct nvmem_cell *cell, size_t *len)
 {
 	struct nvmem_device *nvmem = cell->nvmem;
 	u8 *buf;
 	int rc;
 
 	if (!nvmem)
 		return ERR_PTR(-EINVAL);
 
 	buf = kzalloc(cell->bytes, GFP_KERNEL);
 	if (!buf)
 		return ERR_PTR(-ENOMEM);
 
 	rc = __nvmem_cell_read(nvmem, cell, buf, len);
 	if (rc) {
 		kfree(buf);
 		return ERR_PTR(rc);
 	}
 
 	return buf;
 }
 EXPORT_SYMBOL_GPL(nvmem_cell_read);
 
 static inline void *nvmem_cell_prepare_write_buffer(struct nvmem_cell *cell,
 						    u8 *_buf, int len)
 {
 	struct nvmem_device *nvmem = cell->nvmem;
 	int i, rc, nbits, bit_offset = cell->bit_offset;
 	u8 v, *p, *buf, *b, pbyte, pbits;
 
 	nbits = cell->nbits;
 	buf = kzalloc(cell->bytes, GFP_KERNEL);
 	if (!buf)
 		return ERR_PTR(-ENOMEM);
 
 	memcpy(buf, _buf, len);
 	p = b = buf;
 
 	if (bit_offset) {
 		pbyte = *b;
 		*b <<= bit_offset;
 
 		/* setup the first byte with lsb bits from nvmem */
 		rc = nvmem_reg_read(nvmem, cell->offset, &v, 1);
 		*b++ |= GENMASK(bit_offset - 1, 0) & v;
 
 		/* setup rest of the byte if any */
 		for (i = 1; i < cell->bytes; i++) {
 			/* Get last byte bits and shift them towards lsb */
 			pbits = pbyte >> (BITS_PER_BYTE - 1 - bit_offset);
 			pbyte = *b;
 			p = b;
 			*b <<= bit_offset;
 			*b++ |= pbits;
 		}
 	}
 
 	/* if it's not end on byte boundary */
 	if ((nbits + bit_offset) % BITS_PER_BYTE) {
 		/* setup the last byte with msb bits from nvmem */
 		rc = nvmem_reg_read(nvmem,
 				    cell->offset + cell->bytes - 1, &v, 1);
 		*p |= GENMASK(7, (nbits + bit_offset) % BITS_PER_BYTE) & v;
 
 	}
 
 	return buf;
 }
 
 /**
  * nvmem_cell_write() - Write to a given nvmem cell
  *
  * @cell: nvmem cell to be written.
  * @buf: Buffer to be written.
  * @len: length of buffer to be written to nvmem cell.
  *
  * Return: length of bytes written or negative on failure.
  */
 int nvmem_cell_write(struct nvmem_cell *cell, void *buf, size_t len)
 {
 	struct nvmem_device *nvmem = cell->nvmem;
 	int rc;
 
 	if (!nvmem || nvmem->read_only ||
 	    (cell->bit_offset == 0 && len != cell->bytes))
 		return -EINVAL;
 
 	if (cell->bit_offset || cell->nbits) {
 		buf = nvmem_cell_prepare_write_buffer(cell, buf, len);
 		if (IS_ERR(buf))
 			return PTR_ERR(buf);
 	}
 
 	rc = nvmem_reg_write(nvmem, cell->offset, buf, cell->bytes);
 
 	/* free the tmp buffer */
 	if (cell->bit_offset || cell->nbits)
 		kfree(buf);
 
 	if (rc)
 		return rc;
 
 	return len;
 }
 EXPORT_SYMBOL_GPL(nvmem_cell_write);
 
 /**
  * nvmem_device_cell_read() - Read a given nvmem device and cell
  *
  * @nvmem: nvmem device to read from.
  * @info: nvmem cell info to be read.
  * @buf: buffer pointer which will be populated on successful read.
  *
  * Return: length of successful bytes read on success and negative
  * error code on error.
  */
 ssize_t nvmem_device_cell_read(struct nvmem_device *nvmem,
 			   struct nvmem_cell_info *info, void *buf)
 {
 	struct nvmem_cell cell;
 	int rc;
 	ssize_t len;
 
 	if (!nvmem)
 		return -EINVAL;
 
 	rc = nvmem_cell_info_to_nvmem_cell(nvmem, info, &cell);
 	if (rc)
 		return rc;
 
 	rc = __nvmem_cell_read(nvmem, &cell, buf, &len);
 	if (rc)
 		return rc;
 
 	return len;
 }
 EXPORT_SYMBOL_GPL(nvmem_device_cell_read);
 
 /**
  * nvmem_device_cell_write() - Write cell to a given nvmem device
  *
  * @nvmem: nvmem device to be written to.
- * @info: nvmem cell info to be written
+ * @info: nvmem cell info to be written.
  * @buf: buffer to be written to cell.
  *
  * Return: length of bytes written or negative error code on failure.
  * */
 int nvmem_device_cell_write(struct nvmem_device *nvmem,
 			    struct nvmem_cell_info *info, void *buf)
 {
 	struct nvmem_cell cell;
 	int rc;
 
 	if (!nvmem)
 		return -EINVAL;
 
 	rc = nvmem_cell_info_to_nvmem_cell(nvmem, info, &cell);
 	if (rc)
 		return rc;
 
 	return nvmem_cell_write(&cell, buf, cell.bytes);
 }
 EXPORT_SYMBOL_GPL(nvmem_device_cell_write);
 
 /**
  * nvmem_device_read() - Read from a given nvmem device
  *
  * @nvmem: nvmem device to read from.
  * @offset: offset in nvmem device.
  * @bytes: number of bytes to read.
  * @buf: buffer pointer which will be populated on successful read.
  *
  * Return: length of successful bytes read on success and negative
  * error code on error.
  */
 int nvmem_device_read(struct nvmem_device *nvmem,
 		      unsigned int offset,
 		      size_t bytes, void *buf)
 {
 	int rc;
 
 	if (!nvmem)
 		return -EINVAL;
 
 	rc = nvmem_reg_read(nvmem, offset, buf, bytes);
 
 	if (rc)
 		return rc;
 
 	return bytes;
 }
 EXPORT_SYMBOL_GPL(nvmem_device_read);
 
 /**
  * nvmem_device_write() - Write cell to a given nvmem device
  *
  * @nvmem: nvmem device to be written to.
  * @offset: offset in nvmem device.
  * @bytes: number of bytes to write.
  * @buf: buffer to be written.
  *
  * Return: length of bytes written or negative error code on failure.
  * */
 int nvmem_device_write(struct nvmem_device *nvmem,
 		       unsigned int offset,
 		       size_t bytes, void *buf)
 {
 	int rc;
 
 	if (!nvmem)
 		return -EINVAL;
 
 	rc = nvmem_reg_write(nvmem, offset, buf, bytes);
 
 	if (rc)
 		return rc;
 
 
 	return bytes;
 }
 EXPORT_SYMBOL_GPL(nvmem_device_write);
 
 static int __init nvmem_init(void)
 {
 	return bus_register(&nvmem_bus_type);
 }
 
 static void __exit nvmem_exit(void)
 {
 	bus_unregister(&nvmem_bus_type);
 }
 
 subsys_initcall(nvmem_init);
 module_exit(nvmem_exit);
 
 MODULE_AUTHOR("Srinivas Kandagatla <srinivas.kandagatla@linaro.org");
 MODULE_AUTHOR("Maxime Ripard <maxime.ripard@free-electrons.com");
 MODULE_DESCRIPTION("nvmem Driver Core");
 MODULE_LICENSE("GPL v2");
diff --git a/drivers/nvmem/imx-ocotp.c b/drivers/nvmem/imx-ocotp.c
index 8e7b120696fa..b8ca1e677b01 100644
--- a/drivers/nvmem/imx-ocotp.c
+++ b/drivers/nvmem/imx-ocotp.c
@@ -1,134 +1,135 @@
 /*
  * i.MX6 OCOTP fusebox driver
  *
  * Copyright (c) 2015 Pengutronix, Philipp Zabel <p.zabel@pengutronix.de>
  *
  * Based on the barebox ocotp driver,
  * Copyright (c) 2010 Baruch Siach <baruch@tkos.co.il>,
  *	Orex Computed Radiography
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation.
  *
  * http://www.opensource.org/licenses/gpl-license.html
  * http://www.gnu.org/copyleft/gpl.html
  */
 
 #include <linux/clk.h>
 #include <linux/device.h>
 #include <linux/io.h>
 #include <linux/module.h>
 #include <linux/nvmem-provider.h>
 #include <linux/of.h>
 #include <linux/of_device.h>
 #include <linux/platform_device.h>
 #include <linux/slab.h>
 
 struct ocotp_priv {
 	struct device *dev;
 	struct clk *clk;
 	void __iomem *base;
 	unsigned int nregs;
 };
 
 static int imx_ocotp_read(void *context, unsigned int offset,
 			  void *val, size_t bytes)
 {
 	struct ocotp_priv *priv = context;
 	unsigned int count;
 	u32 *buf = val;
 	int i, ret;
 	u32 index;
 
 	index = offset >> 2;
 	count = bytes >> 2;
 
 	if (count > (priv->nregs - index))
 		count = priv->nregs - index;
 
 	ret = clk_prepare_enable(priv->clk);
 	if (ret < 0) {
 		dev_err(priv->dev, "failed to prepare/enable ocotp clk\n");
 		return ret;
 	}
 	for (i = index; i < (index + count); i++)
 		*buf++ = readl(priv->base + 0x400 + i * 0x10);
 
 	clk_disable_unprepare(priv->clk);
 
 	return 0;
 }
 
 static struct nvmem_config imx_ocotp_nvmem_config = {
 	.name = "imx-ocotp",
 	.read_only = true,
 	.word_size = 4,
 	.stride = 4,
 	.owner = THIS_MODULE,
 	.reg_read = imx_ocotp_read,
 };
 
 static const struct of_device_id imx_ocotp_dt_ids[] = {
 	{ .compatible = "fsl,imx6q-ocotp",  (void *)128 },
 	{ .compatible = "fsl,imx6sl-ocotp", (void *)64 },
 	{ .compatible = "fsl,imx6sx-ocotp", (void *)128 },
+	{ .compatible = "fsl,imx6ul-ocotp", (void *)128 },
 	{ },
 };
 MODULE_DEVICE_TABLE(of, imx_ocotp_dt_ids);
 
 static int imx_ocotp_probe(struct platform_device *pdev)
 {
 	const struct of_device_id *of_id;
 	struct device *dev = &pdev->dev;
 	struct resource *res;
 	struct ocotp_priv *priv;
 	struct nvmem_device *nvmem;
 
 	priv = devm_kzalloc(dev, sizeof(*priv), GFP_KERNEL);
 	if (!priv)
 		return -ENOMEM;
 
 	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
 	priv->base = devm_ioremap_resource(dev, res);
 	if (IS_ERR(priv->base))
 		return PTR_ERR(priv->base);
 
 	priv->clk = devm_clk_get(&pdev->dev, NULL);
 	if (IS_ERR(priv->clk))
 		return PTR_ERR(priv->clk);
 
 	of_id = of_match_device(imx_ocotp_dt_ids, dev);
 	priv->nregs = (unsigned long)of_id->data;
 	imx_ocotp_nvmem_config.size = 4 * priv->nregs;
 	imx_ocotp_nvmem_config.dev = dev;
 	imx_ocotp_nvmem_config.priv = priv;
 	nvmem = nvmem_register(&imx_ocotp_nvmem_config);
 	if (IS_ERR(nvmem))
 		return PTR_ERR(nvmem);
 
 	platform_set_drvdata(pdev, nvmem);
 
 	return 0;
 }
 
 static int imx_ocotp_remove(struct platform_device *pdev)
 {
 	struct nvmem_device *nvmem = platform_get_drvdata(pdev);
 
 	return nvmem_unregister(nvmem);
 }
 
 static struct platform_driver imx_ocotp_driver = {
 	.probe	= imx_ocotp_probe,
 	.remove	= imx_ocotp_remove,
 	.driver = {
 		.name	= "imx_ocotp",
 		.of_match_table = imx_ocotp_dt_ids,
 	},
 };
 module_platform_driver(imx_ocotp_driver);
 
 MODULE_AUTHOR("Philipp Zabel <p.zabel@pengutronix.de>");
 MODULE_DESCRIPTION("i.MX6 OCOTP fuse box driver");
 MODULE_LICENSE("GPL v2");
diff --git a/drivers/platform/goldfish/pdev_bus.c b/drivers/platform/goldfish/pdev_bus.c
index 1f52462f4cdd..dd9ea463c2a4 100644
--- a/drivers/platform/goldfish/pdev_bus.c
+++ b/drivers/platform/goldfish/pdev_bus.c
@@ -1,229 +1,232 @@
 /*
  * Copyright (C) 2007 Google, Inc.
  * Copyright (C) 2011 Intel, Inc.
  * Copyright (C) 2013 Intel, Inc.
  *
  * This software is licensed under the terms of the GNU General Public
  * License version 2, as published by the Free Software Foundation, and
  * may be copied, distributed, and modified under those terms.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
  *
  */
 
 #include <linux/kernel.h>
 #include <linux/init.h>
 #include <linux/interrupt.h>
 #include <linux/irq.h>
 #include <linux/platform_device.h>
 #include <linux/slab.h>
 #include <linux/io.h>
 
 #define PDEV_BUS_OP_DONE        (0x00)
 #define PDEV_BUS_OP_REMOVE_DEV  (0x04)
 #define PDEV_BUS_OP_ADD_DEV     (0x08)
 
 #define PDEV_BUS_OP_INIT        (0x00)
 
 #define PDEV_BUS_OP             (0x00)
 #define PDEV_BUS_GET_NAME       (0x04)
 #define PDEV_BUS_NAME_LEN       (0x08)
 #define PDEV_BUS_ID             (0x0c)
 #define PDEV_BUS_IO_BASE        (0x10)
 #define PDEV_BUS_IO_SIZE        (0x14)
 #define PDEV_BUS_IRQ            (0x18)
 #define PDEV_BUS_IRQ_COUNT      (0x1c)
 #define PDEV_BUS_GET_NAME_HIGH  (0x20)
 
 struct pdev_bus_dev {
 	struct list_head list;
 	struct platform_device pdev;
 	struct resource resources[0];
 };
 
 static void goldfish_pdev_worker(struct work_struct *work);
 
 static void __iomem *pdev_bus_base;
 static unsigned long pdev_bus_addr;
 static unsigned long pdev_bus_len;
 static u32 pdev_bus_irq;
 static LIST_HEAD(pdev_bus_new_devices);
 static LIST_HEAD(pdev_bus_registered_devices);
 static LIST_HEAD(pdev_bus_removed_devices);
 static DECLARE_WORK(pdev_bus_worker, goldfish_pdev_worker);
 
 
 static void goldfish_pdev_worker(struct work_struct *work)
 {
 	int ret;
 	struct pdev_bus_dev *pos, *n;
 
 	list_for_each_entry_safe(pos, n, &pdev_bus_removed_devices, list) {
 		list_del(&pos->list);
 		platform_device_unregister(&pos->pdev);
 		kfree(pos);
 	}
 	list_for_each_entry_safe(pos, n, &pdev_bus_new_devices, list) {
 		list_del(&pos->list);
 		ret = platform_device_register(&pos->pdev);
 		if (ret)
 			pr_err("goldfish_pdev_worker failed to register device, %s\n",
 								pos->pdev.name);
 		list_add_tail(&pos->list, &pdev_bus_registered_devices);
 	}
 }
 
 static void goldfish_pdev_remove(void)
 {
 	struct pdev_bus_dev *pos, *n;
 	u32 base;
 
 	base = readl(pdev_bus_base + PDEV_BUS_IO_BASE);
 
 	list_for_each_entry_safe(pos, n, &pdev_bus_new_devices, list) {
 		if (pos->resources[0].start == base) {
 			list_del(&pos->list);
 			kfree(pos);
 			return;
 		}
 	}
 	list_for_each_entry_safe(pos, n, &pdev_bus_registered_devices, list) {
 		if (pos->resources[0].start == base) {
 			list_del(&pos->list);
 			list_add_tail(&pos->list, &pdev_bus_removed_devices);
 			schedule_work(&pdev_bus_worker);
 			return;
 		}
 	};
 	pr_err("goldfish_pdev_remove could not find device at %x\n", base);
 }
 
 static int goldfish_new_pdev(void)
 {
 	struct pdev_bus_dev *dev;
 	u32 name_len;
 	u32 irq = -1, irq_count;
 	int resource_count = 2;
 	u32 base;
 	char *name;
 
 	base = readl(pdev_bus_base + PDEV_BUS_IO_BASE);
 
 	irq_count = readl(pdev_bus_base + PDEV_BUS_IRQ_COUNT);
 	name_len = readl(pdev_bus_base + PDEV_BUS_NAME_LEN);
 	if (irq_count)
 		resource_count++;
 
 	dev = kzalloc(sizeof(*dev) +
 		sizeof(struct resource) * resource_count +
 		name_len + 1 + sizeof(*dev->pdev.dev.dma_mask), GFP_ATOMIC);
 	if (dev == NULL)
 		return -ENOMEM;
 
 	dev->pdev.num_resources = resource_count;
 	dev->pdev.resource = (struct resource *)(dev + 1);
 	dev->pdev.name = name = (char *)(dev->pdev.resource + resource_count);
 	dev->pdev.dev.coherent_dma_mask = ~0;
 	dev->pdev.dev.dma_mask = (void *)(dev->pdev.name + name_len + 1);
 	*dev->pdev.dev.dma_mask = ~0;
 
 #ifdef CONFIG_64BIT
 	writel((u32)((u64)name>>32), pdev_bus_base + PDEV_BUS_GET_NAME_HIGH);
 #endif
 	writel((u32)(unsigned long)name, pdev_bus_base + PDEV_BUS_GET_NAME);
 	name[name_len] = '\0';
 	dev->pdev.id = readl(pdev_bus_base + PDEV_BUS_ID);
 	dev->pdev.resource[0].start = base;
 	dev->pdev.resource[0].end = base +
 				readl(pdev_bus_base + PDEV_BUS_IO_SIZE) - 1;
 	dev->pdev.resource[0].flags = IORESOURCE_MEM;
 	if (irq_count) {
 		irq = readl(pdev_bus_base + PDEV_BUS_IRQ);
 		dev->pdev.resource[1].start = irq;
 		dev->pdev.resource[1].end = irq + irq_count - 1;
 		dev->pdev.resource[1].flags = IORESOURCE_IRQ;
 	}
 
 	pr_debug("goldfish_new_pdev %s at %x irq %d\n", name, base, irq);
 	list_add_tail(&dev->list, &pdev_bus_new_devices);
 	schedule_work(&pdev_bus_worker);
 
 	return 0;
 }
 
 static irqreturn_t goldfish_pdev_bus_interrupt(int irq, void *dev_id)
 {
 	irqreturn_t ret = IRQ_NONE;
+
 	while (1) {
 		u32 op = readl(pdev_bus_base + PDEV_BUS_OP);
-		switch (op) {
-		case PDEV_BUS_OP_DONE:
-			return IRQ_NONE;
 
+		switch (op) {
 		case PDEV_BUS_OP_REMOVE_DEV:
 			goldfish_pdev_remove();
+			ret = IRQ_HANDLED;
 			break;
 
 		case PDEV_BUS_OP_ADD_DEV:
 			goldfish_new_pdev();
+			ret = IRQ_HANDLED;
 			break;
+
+		case PDEV_BUS_OP_DONE:
+		default:
+			return ret;
 		}
-		ret = IRQ_HANDLED;
 	}
-	return ret;
 }
 
 static int goldfish_pdev_bus_probe(struct platform_device *pdev)
 {
 	int ret;
 	struct resource *r;
 
 	r = platform_get_resource(pdev, IORESOURCE_MEM, 0);
 	if (r == NULL)
 		return -EINVAL;
 
 	pdev_bus_addr = r->start;
 	pdev_bus_len = resource_size(r);
 
 	pdev_bus_base = ioremap(pdev_bus_addr, pdev_bus_len);
 	if (pdev_bus_base == NULL) {
 		ret = -ENOMEM;
 		dev_err(&pdev->dev, "unable to map Goldfish MMIO.\n");
 		goto free_resources;
 	}
 
 	r = platform_get_resource(pdev, IORESOURCE_IRQ, 0);
 	if (r == NULL) {
 		ret = -ENOENT;
 		goto free_map;
 	}
 
 	pdev_bus_irq = r->start;
 
 	ret = request_irq(pdev_bus_irq, goldfish_pdev_bus_interrupt,
 				IRQF_SHARED, "goldfish_pdev_bus", pdev);
 	if (ret) {
 		dev_err(&pdev->dev, "unable to request Goldfish IRQ\n");
 		goto free_map;
 	}
 
 	writel(PDEV_BUS_OP_INIT, pdev_bus_base + PDEV_BUS_OP);
 	return 0;
 
 free_map:
 	iounmap(pdev_bus_base);
 free_resources:
 	release_mem_region(pdev_bus_addr, pdev_bus_len);
 	return ret;
 }
 
 static struct platform_driver goldfish_pdev_bus_driver = {
 	.probe = goldfish_pdev_bus_probe,
 	.driver = {
 		.name = "goldfish_pdev_bus"
 	}
 };
 builtin_platform_driver(goldfish_pdev_bus_driver);
diff --git a/drivers/uio/uio_hv_generic.c b/drivers/uio/uio_hv_generic.c
index 50958f167305..48d5327d38d4 100644
--- a/drivers/uio/uio_hv_generic.c
+++ b/drivers/uio/uio_hv_generic.c
@@ -1,218 +1,218 @@
 /*
  * uio_hv_generic - generic UIO driver for VMBus
  *
  * Copyright (c) 2013-2016 Brocade Communications Systems, Inc.
  * Copyright (c) 2016, Microsoft Corporation.
  *
  *
  * This work is licensed under the terms of the GNU GPL, version 2.
  *
  * Since the driver does not declare any device ids, you must allocate
  * id and bind the device to the driver yourself.  For example:
  *
  * # echo "f8615163-df3e-46c5-913f-f2d2f965ed0e" \
  *    > /sys/bus/vmbus/drivers/uio_hv_generic
  * # echo -n vmbus-ed963694-e847-4b2a-85af-bc9cfc11d6f3 \
  *    > /sys/bus/vmbus/drivers/hv_netvsc/unbind
  * # echo -n vmbus-ed963694-e847-4b2a-85af-bc9cfc11d6f3 \
  *    > /sys/bus/vmbus/drivers/uio_hv_generic/bind
  */
 
 #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
 
 #include <linux/device.h>
 #include <linux/kernel.h>
 #include <linux/module.h>
 #include <linux/uio_driver.h>
 #include <linux/netdevice.h>
 #include <linux/if_ether.h>
 #include <linux/skbuff.h>
 #include <linux/hyperv.h>
 #include <linux/vmalloc.h>
 #include <linux/slab.h>
 
 #include "../hv/hyperv_vmbus.h"
 
 #define DRIVER_VERSION	"0.02.0"
 #define DRIVER_AUTHOR	"Stephen Hemminger <sthemmin at microsoft.com>"
 #define DRIVER_DESC	"Generic UIO driver for VMBus devices"
 
 /*
  * List of resources to be mapped to user space
  * can be extended up to MAX_UIO_MAPS(5) items
  */
 enum hv_uio_map {
 	TXRX_RING_MAP = 0,
 	INT_PAGE_MAP,
 	MON_PAGE_MAP,
 };
 
 #define HV_RING_SIZE	512
 
 struct hv_uio_private_data {
 	struct uio_info info;
 	struct hv_device *device;
 };
 
 static int
 hv_uio_mmap(struct uio_info *info, struct vm_area_struct *vma)
 {
 	int mi;
 
 	if (vma->vm_pgoff >= MAX_UIO_MAPS)
 		return -EINVAL;
 
 	if (info->mem[vma->vm_pgoff].size == 0)
 		return -EINVAL;
 
 	mi = (int)vma->vm_pgoff;
 
 	return remap_pfn_range(vma, vma->vm_start,
 			info->mem[mi].addr >> PAGE_SHIFT,
 			vma->vm_end - vma->vm_start, vma->vm_page_prot);
 }
 
 /*
  * This is the irqcontrol callback to be registered to uio_info.
  * It can be used to disable/enable interrupt from user space processes.
  *
  * @param info
  *  pointer to uio_info.
  * @param irq_state
  *  state value. 1 to enable interrupt, 0 to disable interrupt.
  */
 static int
 hv_uio_irqcontrol(struct uio_info *info, s32 irq_state)
 {
 	struct hv_uio_private_data *pdata = info->priv;
 	struct hv_device *dev = pdata->device;
 
 	dev->channel->inbound.ring_buffer->interrupt_mask = !irq_state;
 	virt_mb();
 
 	return 0;
 }
 
 /*
  * Callback from vmbus_event when something is in inbound ring.
  */
 static void hv_uio_channel_cb(void *context)
 {
 	struct hv_uio_private_data *pdata = context;
 	struct hv_device *dev = pdata->device;
 
 	dev->channel->inbound.ring_buffer->interrupt_mask = 1;
 	virt_mb();
 
 	uio_event_notify(&pdata->info);
 }
 
 static int
 hv_uio_probe(struct hv_device *dev,
 	     const struct hv_vmbus_device_id *dev_id)
 {
 	struct hv_uio_private_data *pdata;
 	int ret;
 
 	pdata = kzalloc(sizeof(*pdata), GFP_KERNEL);
 	if (!pdata)
 		return -ENOMEM;
 
 	ret = vmbus_open(dev->channel, HV_RING_SIZE * PAGE_SIZE,
 			 HV_RING_SIZE * PAGE_SIZE, NULL, 0,
 			 hv_uio_channel_cb, pdata);
 	if (ret)
 		goto fail;
 
 	dev->channel->inbound.ring_buffer->interrupt_mask = 1;
-	dev->channel->batched_reading = false;
+	set_channel_read_mode(dev->channel, HV_CALL_DIRECT);
 
 	/* Fill general uio info */
 	pdata->info.name = "uio_hv_generic";
 	pdata->info.version = DRIVER_VERSION;
 	pdata->info.irqcontrol = hv_uio_irqcontrol;
 	pdata->info.mmap = hv_uio_mmap;
 	pdata->info.irq = UIO_IRQ_CUSTOM;
 
 	/* mem resources */
 	pdata->info.mem[TXRX_RING_MAP].name = "txrx_rings";
 	pdata->info.mem[TXRX_RING_MAP].addr
 		= virt_to_phys(dev->channel->ringbuffer_pages);
 	pdata->info.mem[TXRX_RING_MAP].size
 		= dev->channel->ringbuffer_pagecount * PAGE_SIZE;
 	pdata->info.mem[TXRX_RING_MAP].memtype = UIO_MEM_LOGICAL;
 
 	pdata->info.mem[INT_PAGE_MAP].name = "int_page";
 	pdata->info.mem[INT_PAGE_MAP].addr =
 		virt_to_phys(vmbus_connection.int_page);
 	pdata->info.mem[INT_PAGE_MAP].size = PAGE_SIZE;
 	pdata->info.mem[INT_PAGE_MAP].memtype = UIO_MEM_LOGICAL;
 
 	pdata->info.mem[MON_PAGE_MAP].name = "monitor_pages";
 	pdata->info.mem[MON_PAGE_MAP].addr =
 		virt_to_phys(vmbus_connection.monitor_pages[1]);
 	pdata->info.mem[MON_PAGE_MAP].size = PAGE_SIZE;
 	pdata->info.mem[MON_PAGE_MAP].memtype = UIO_MEM_LOGICAL;
 
 	pdata->info.priv = pdata;
 	pdata->device = dev;
 
 	ret = uio_register_device(&dev->device, &pdata->info);
 	if (ret) {
 		dev_err(&dev->device, "hv_uio register failed\n");
 		goto fail_close;
 	}
 
 	hv_set_drvdata(dev, pdata);
 
 	return 0;
 
 fail_close:
 	vmbus_close(dev->channel);
 fail:
 	kfree(pdata);
 
 	return ret;
 }
 
 static int
 hv_uio_remove(struct hv_device *dev)
 {
 	struct hv_uio_private_data *pdata = hv_get_drvdata(dev);
 
 	if (!pdata)
 		return 0;
 
 	uio_unregister_device(&pdata->info);
 	hv_set_drvdata(dev, NULL);
 	vmbus_close(dev->channel);
 	kfree(pdata);
 	return 0;
 }
 
 static struct hv_driver hv_uio_drv = {
 	.name = "uio_hv_generic",
 	.id_table = NULL, /* only dynamic id's */
 	.probe = hv_uio_probe,
 	.remove = hv_uio_remove,
 };
 
 static int __init
 hyperv_module_init(void)
 {
 	return vmbus_driver_register(&hv_uio_drv);
 }
 
 static void __exit
 hyperv_module_exit(void)
 {
 	vmbus_driver_unregister(&hv_uio_drv);
 }
 
 module_init(hyperv_module_init);
 module_exit(hyperv_module_exit);
 
 MODULE_VERSION(DRIVER_VERSION);
 MODULE_LICENSE("GPL v2");
 MODULE_AUTHOR(DRIVER_AUTHOR);
 MODULE_DESCRIPTION(DRIVER_DESC);
diff --git a/drivers/vme/vme.c b/drivers/vme/vme.c
index bdbadaa47ef3..0035cf79760a 100644
--- a/drivers/vme/vme.c
+++ b/drivers/vme/vme.c
@@ -1,1639 +1,1654 @@
 /*
  * VME Bridge Framework
  *
  * Author: Martyn Welch <martyn.welch@ge.com>
  * Copyright 2008 GE Intelligent Platforms Embedded Systems, Inc.
  *
  * Based on work by Tom Armistead and Ajit Prem
  * Copyright 2004 Motorola Inc.
  *
  * This program is free software; you can redistribute  it and/or modify it
  * under  the terms of  the GNU General  Public License as published by the
  * Free Software Foundation;  either version 2 of the  License, or (at your
  * option) any later version.
  */
 
 #include <linux/init.h>
 #include <linux/export.h>
 #include <linux/mm.h>
 #include <linux/types.h>
 #include <linux/kernel.h>
 #include <linux/errno.h>
 #include <linux/pci.h>
 #include <linux/poll.h>
 #include <linux/highmem.h>
 #include <linux/interrupt.h>
 #include <linux/pagemap.h>
 #include <linux/device.h>
 #include <linux/dma-mapping.h>
 #include <linux/syscalls.h>
 #include <linux/mutex.h>
 #include <linux/spinlock.h>
 #include <linux/slab.h>
 #include <linux/vme.h>
 
 #include "vme_bridge.h"
 
 /* Bitmask and list of registered buses both protected by common mutex */
 static unsigned int vme_bus_numbers;
 static LIST_HEAD(vme_bus_list);
 static DEFINE_MUTEX(vme_buses_lock);
 
 static int __init vme_init(void);
 
 static struct vme_dev *dev_to_vme_dev(struct device *dev)
 {
 	return container_of(dev, struct vme_dev, dev);
 }
 
 /*
  * Find the bridge that the resource is associated with.
  */
 static struct vme_bridge *find_bridge(struct vme_resource *resource)
 {
 	/* Get list to search */
 	switch (resource->type) {
 	case VME_MASTER:
 		return list_entry(resource->entry, struct vme_master_resource,
 			list)->parent;
 		break;
 	case VME_SLAVE:
 		return list_entry(resource->entry, struct vme_slave_resource,
 			list)->parent;
 		break;
 	case VME_DMA:
 		return list_entry(resource->entry, struct vme_dma_resource,
 			list)->parent;
 		break;
 	case VME_LM:
 		return list_entry(resource->entry, struct vme_lm_resource,
 			list)->parent;
 		break;
 	default:
 		printk(KERN_ERR "Unknown resource type\n");
 		return NULL;
 		break;
 	}
 }
 
 /*
  * Allocate a contiguous block of memory for use by the driver. This is used to
  * create the buffers for the slave windows.
  */
 void *vme_alloc_consistent(struct vme_resource *resource, size_t size,
 	dma_addr_t *dma)
 {
 	struct vme_bridge *bridge;
 
 	if (resource == NULL) {
 		printk(KERN_ERR "No resource\n");
 		return NULL;
 	}
 
 	bridge = find_bridge(resource);
 	if (bridge == NULL) {
 		printk(KERN_ERR "Can't find bridge\n");
 		return NULL;
 	}
 
 	if (bridge->parent == NULL) {
 		printk(KERN_ERR "Dev entry NULL for bridge %s\n", bridge->name);
 		return NULL;
 	}
 
 	if (bridge->alloc_consistent == NULL) {
 		printk(KERN_ERR "alloc_consistent not supported by bridge %s\n",
 		       bridge->name);
 		return NULL;
 	}
 
 	return bridge->alloc_consistent(bridge->parent, size, dma);
 }
 EXPORT_SYMBOL(vme_alloc_consistent);
 
 /*
  * Free previously allocated contiguous block of memory.
  */
 void vme_free_consistent(struct vme_resource *resource, size_t size,
 	void *vaddr, dma_addr_t dma)
 {
 	struct vme_bridge *bridge;
 
 	if (resource == NULL) {
 		printk(KERN_ERR "No resource\n");
 		return;
 	}
 
 	bridge = find_bridge(resource);
 	if (bridge == NULL) {
 		printk(KERN_ERR "Can't find bridge\n");
 		return;
 	}
 
 	if (bridge->parent == NULL) {
 		printk(KERN_ERR "Dev entry NULL for bridge %s\n", bridge->name);
 		return;
 	}
 
 	if (bridge->free_consistent == NULL) {
 		printk(KERN_ERR "free_consistent not supported by bridge %s\n",
 		       bridge->name);
 		return;
 	}
 
 	bridge->free_consistent(bridge->parent, size, vaddr, dma);
 }
 EXPORT_SYMBOL(vme_free_consistent);
 
 size_t vme_get_size(struct vme_resource *resource)
 {
 	int enabled, retval;
 	unsigned long long base, size;
 	dma_addr_t buf_base;
 	u32 aspace, cycle, dwidth;
 
 	switch (resource->type) {
 	case VME_MASTER:
 		retval = vme_master_get(resource, &enabled, &base, &size,
 			&aspace, &cycle, &dwidth);
 		if (retval)
 			return 0;
 
 		return size;
 		break;
 	case VME_SLAVE:
 		retval = vme_slave_get(resource, &enabled, &base, &size,
 			&buf_base, &aspace, &cycle);
 		if (retval)
 			return 0;
 
 		return size;
 		break;
 	case VME_DMA:
 		return 0;
 		break;
 	default:
 		printk(KERN_ERR "Unknown resource type\n");
 		return 0;
 		break;
 	}
 }
 EXPORT_SYMBOL(vme_get_size);
 
 int vme_check_window(u32 aspace, unsigned long long vme_base,
 		     unsigned long long size)
 {
 	int retval = 0;
 
 	switch (aspace) {
 	case VME_A16:
 		if (((vme_base + size) > VME_A16_MAX) ||
 				(vme_base > VME_A16_MAX))
 			retval = -EFAULT;
 		break;
 	case VME_A24:
 		if (((vme_base + size) > VME_A24_MAX) ||
 				(vme_base > VME_A24_MAX))
 			retval = -EFAULT;
 		break;
 	case VME_A32:
 		if (((vme_base + size) > VME_A32_MAX) ||
 				(vme_base > VME_A32_MAX))
 			retval = -EFAULT;
 		break;
 	case VME_A64:
 		if ((size != 0) && (vme_base > U64_MAX + 1 - size))
 			retval = -EFAULT;
 		break;
 	case VME_CRCSR:
 		if (((vme_base + size) > VME_CRCSR_MAX) ||
 				(vme_base > VME_CRCSR_MAX))
 			retval = -EFAULT;
 		break;
 	case VME_USER1:
 	case VME_USER2:
 	case VME_USER3:
 	case VME_USER4:
 		/* User Defined */
 		break;
 	default:
 		printk(KERN_ERR "Invalid address space\n");
 		retval = -EINVAL;
 		break;
 	}
 
 	return retval;
 }
 EXPORT_SYMBOL(vme_check_window);
 
 static u32 vme_get_aspace(int am)
 {
 	switch (am) {
 	case 0x29:
 	case 0x2D:
 		return VME_A16;
 	case 0x38:
 	case 0x39:
 	case 0x3A:
 	case 0x3B:
 	case 0x3C:
 	case 0x3D:
 	case 0x3E:
 	case 0x3F:
 		return VME_A24;
 	case 0x8:
 	case 0x9:
 	case 0xA:
 	case 0xB:
 	case 0xC:
 	case 0xD:
 	case 0xE:
 	case 0xF:
 		return VME_A32;
 	case 0x0:
 	case 0x1:
 	case 0x3:
 		return VME_A64;
 	}
 
 	return 0;
 }
 
 /*
  * Request a slave image with specific attributes, return some unique
  * identifier.
  */
 struct vme_resource *vme_slave_request(struct vme_dev *vdev, u32 address,
 	u32 cycle)
 {
 	struct vme_bridge *bridge;
 	struct list_head *slave_pos = NULL;
 	struct vme_slave_resource *allocated_image = NULL;
 	struct vme_slave_resource *slave_image = NULL;
 	struct vme_resource *resource = NULL;
 
 	bridge = vdev->bridge;
 	if (bridge == NULL) {
 		printk(KERN_ERR "Can't find VME bus\n");
 		goto err_bus;
 	}
 
 	/* Loop through slave resources */
 	list_for_each(slave_pos, &bridge->slave_resources) {
 		slave_image = list_entry(slave_pos,
 			struct vme_slave_resource, list);
 
 		if (slave_image == NULL) {
 			printk(KERN_ERR "Registered NULL Slave resource\n");
 			continue;
 		}
 
 		/* Find an unlocked and compatible image */
 		mutex_lock(&slave_image->mtx);
 		if (((slave_image->address_attr & address) == address) &&
 			((slave_image->cycle_attr & cycle) == cycle) &&
 			(slave_image->locked == 0)) {
 
 			slave_image->locked = 1;
 			mutex_unlock(&slave_image->mtx);
 			allocated_image = slave_image;
 			break;
 		}
 		mutex_unlock(&slave_image->mtx);
 	}
 
 	/* No free image */
 	if (allocated_image == NULL)
 		goto err_image;
 
 	resource = kmalloc(sizeof(struct vme_resource), GFP_KERNEL);
 	if (resource == NULL) {
 		printk(KERN_WARNING "Unable to allocate resource structure\n");
 		goto err_alloc;
 	}
 	resource->type = VME_SLAVE;
 	resource->entry = &allocated_image->list;
 
 	return resource;
 
 err_alloc:
 	/* Unlock image */
 	mutex_lock(&slave_image->mtx);
 	slave_image->locked = 0;
 	mutex_unlock(&slave_image->mtx);
 err_image:
 err_bus:
 	return NULL;
 }
 EXPORT_SYMBOL(vme_slave_request);
 
 int vme_slave_set(struct vme_resource *resource, int enabled,
 	unsigned long long vme_base, unsigned long long size,
 	dma_addr_t buf_base, u32 aspace, u32 cycle)
 {
 	struct vme_bridge *bridge = find_bridge(resource);
 	struct vme_slave_resource *image;
 	int retval;
 
 	if (resource->type != VME_SLAVE) {
 		printk(KERN_ERR "Not a slave resource\n");
 		return -EINVAL;
 	}
 
 	image = list_entry(resource->entry, struct vme_slave_resource, list);
 
 	if (bridge->slave_set == NULL) {
 		printk(KERN_ERR "Function not supported\n");
 		return -ENOSYS;
 	}
 
 	if (!(((image->address_attr & aspace) == aspace) &&
 		((image->cycle_attr & cycle) == cycle))) {
 		printk(KERN_ERR "Invalid attributes\n");
 		return -EINVAL;
 	}
 
 	retval = vme_check_window(aspace, vme_base, size);
 	if (retval)
 		return retval;
 
 	return bridge->slave_set(image, enabled, vme_base, size, buf_base,
 		aspace, cycle);
 }
 EXPORT_SYMBOL(vme_slave_set);
 
 int vme_slave_get(struct vme_resource *resource, int *enabled,
 	unsigned long long *vme_base, unsigned long long *size,
 	dma_addr_t *buf_base, u32 *aspace, u32 *cycle)
 {
 	struct vme_bridge *bridge = find_bridge(resource);
 	struct vme_slave_resource *image;
 
 	if (resource->type != VME_SLAVE) {
 		printk(KERN_ERR "Not a slave resource\n");
 		return -EINVAL;
 	}
 
 	image = list_entry(resource->entry, struct vme_slave_resource, list);
 
 	if (bridge->slave_get == NULL) {
 		printk(KERN_ERR "vme_slave_get not supported\n");
 		return -EINVAL;
 	}
 
 	return bridge->slave_get(image, enabled, vme_base, size, buf_base,
 		aspace, cycle);
 }
 EXPORT_SYMBOL(vme_slave_get);
 
 void vme_slave_free(struct vme_resource *resource)
 {
 	struct vme_slave_resource *slave_image;
 
 	if (resource->type != VME_SLAVE) {
 		printk(KERN_ERR "Not a slave resource\n");
 		return;
 	}
 
 	slave_image = list_entry(resource->entry, struct vme_slave_resource,
 		list);
 	if (slave_image == NULL) {
 		printk(KERN_ERR "Can't find slave resource\n");
 		return;
 	}
 
 	/* Unlock image */
 	mutex_lock(&slave_image->mtx);
 	if (slave_image->locked == 0)
 		printk(KERN_ERR "Image is already free\n");
 
 	slave_image->locked = 0;
 	mutex_unlock(&slave_image->mtx);
 
 	/* Free up resource memory */
 	kfree(resource);
 }
 EXPORT_SYMBOL(vme_slave_free);
 
 /*
  * Request a master image with specific attributes, return some unique
  * identifier.
  */
 struct vme_resource *vme_master_request(struct vme_dev *vdev, u32 address,
 	u32 cycle, u32 dwidth)
 {
 	struct vme_bridge *bridge;
 	struct list_head *master_pos = NULL;
 	struct vme_master_resource *allocated_image = NULL;
 	struct vme_master_resource *master_image = NULL;
 	struct vme_resource *resource = NULL;
 
 	bridge = vdev->bridge;
 	if (bridge == NULL) {
 		printk(KERN_ERR "Can't find VME bus\n");
 		goto err_bus;
 	}
 
 	/* Loop through master resources */
 	list_for_each(master_pos, &bridge->master_resources) {
 		master_image = list_entry(master_pos,
 			struct vme_master_resource, list);
 
 		if (master_image == NULL) {
 			printk(KERN_WARNING "Registered NULL master resource\n");
 			continue;
 		}
 
 		/* Find an unlocked and compatible image */
 		spin_lock(&master_image->lock);
 		if (((master_image->address_attr & address) == address) &&
 			((master_image->cycle_attr & cycle) == cycle) &&
 			((master_image->width_attr & dwidth) == dwidth) &&
 			(master_image->locked == 0)) {
 
 			master_image->locked = 1;
 			spin_unlock(&master_image->lock);
 			allocated_image = master_image;
 			break;
 		}
 		spin_unlock(&master_image->lock);
 	}
 
 	/* Check to see if we found a resource */
 	if (allocated_image == NULL) {
 		printk(KERN_ERR "Can't find a suitable resource\n");
 		goto err_image;
 	}
 
 	resource = kmalloc(sizeof(struct vme_resource), GFP_KERNEL);
 	if (resource == NULL) {
 		printk(KERN_ERR "Unable to allocate resource structure\n");
 		goto err_alloc;
 	}
 	resource->type = VME_MASTER;
 	resource->entry = &allocated_image->list;
 
 	return resource;
 
 err_alloc:
 	/* Unlock image */
 	spin_lock(&master_image->lock);
 	master_image->locked = 0;
 	spin_unlock(&master_image->lock);
 err_image:
 err_bus:
 	return NULL;
 }
 EXPORT_SYMBOL(vme_master_request);
 
 int vme_master_set(struct vme_resource *resource, int enabled,
 	unsigned long long vme_base, unsigned long long size, u32 aspace,
 	u32 cycle, u32 dwidth)
 {
 	struct vme_bridge *bridge = find_bridge(resource);
 	struct vme_master_resource *image;
 	int retval;
 
 	if (resource->type != VME_MASTER) {
 		printk(KERN_ERR "Not a master resource\n");
 		return -EINVAL;
 	}
 
 	image = list_entry(resource->entry, struct vme_master_resource, list);
 
 	if (bridge->master_set == NULL) {
 		printk(KERN_WARNING "vme_master_set not supported\n");
 		return -EINVAL;
 	}
 
 	if (!(((image->address_attr & aspace) == aspace) &&
 		((image->cycle_attr & cycle) == cycle) &&
 		((image->width_attr & dwidth) == dwidth))) {
 		printk(KERN_WARNING "Invalid attributes\n");
 		return -EINVAL;
 	}
 
 	retval = vme_check_window(aspace, vme_base, size);
 	if (retval)
 		return retval;
 
 	return bridge->master_set(image, enabled, vme_base, size, aspace,
 		cycle, dwidth);
 }
 EXPORT_SYMBOL(vme_master_set);
 
 int vme_master_get(struct vme_resource *resource, int *enabled,
 	unsigned long long *vme_base, unsigned long long *size, u32 *aspace,
 	u32 *cycle, u32 *dwidth)
 {
 	struct vme_bridge *bridge = find_bridge(resource);
 	struct vme_master_resource *image;
 
 	if (resource->type != VME_MASTER) {
 		printk(KERN_ERR "Not a master resource\n");
 		return -EINVAL;
 	}
 
 	image = list_entry(resource->entry, struct vme_master_resource, list);
 
 	if (bridge->master_get == NULL) {
 		printk(KERN_WARNING "%s not supported\n", __func__);
 		return -EINVAL;
 	}
 
 	return bridge->master_get(image, enabled, vme_base, size, aspace,
 		cycle, dwidth);
 }
 EXPORT_SYMBOL(vme_master_get);
 
 /*
  * Read data out of VME space into a buffer.
  */
 ssize_t vme_master_read(struct vme_resource *resource, void *buf, size_t count,
 	loff_t offset)
 {
 	struct vme_bridge *bridge = find_bridge(resource);
 	struct vme_master_resource *image;
 	size_t length;
 
 	if (bridge->master_read == NULL) {
 		printk(KERN_WARNING "Reading from resource not supported\n");
 		return -EINVAL;
 	}
 
 	if (resource->type != VME_MASTER) {
 		printk(KERN_ERR "Not a master resource\n");
 		return -EINVAL;
 	}
 
 	image = list_entry(resource->entry, struct vme_master_resource, list);
 
 	length = vme_get_size(resource);
 
 	if (offset > length) {
 		printk(KERN_WARNING "Invalid Offset\n");
 		return -EFAULT;
 	}
 
 	if ((offset + count) > length)
 		count = length - offset;
 
 	return bridge->master_read(image, buf, count, offset);
 
 }
 EXPORT_SYMBOL(vme_master_read);
 
 /*
  * Write data out to VME space from a buffer.
  */
 ssize_t vme_master_write(struct vme_resource *resource, void *buf,
 	size_t count, loff_t offset)
 {
 	struct vme_bridge *bridge = find_bridge(resource);
 	struct vme_master_resource *image;
 	size_t length;
 
 	if (bridge->master_write == NULL) {
 		printk(KERN_WARNING "Writing to resource not supported\n");
 		return -EINVAL;
 	}
 
 	if (resource->type != VME_MASTER) {
 		printk(KERN_ERR "Not a master resource\n");
 		return -EINVAL;
 	}
 
 	image = list_entry(resource->entry, struct vme_master_resource, list);
 
 	length = vme_get_size(resource);
 
 	if (offset > length) {
 		printk(KERN_WARNING "Invalid Offset\n");
 		return -EFAULT;
 	}
 
 	if ((offset + count) > length)
 		count = length - offset;
 
 	return bridge->master_write(image, buf, count, offset);
 }
 EXPORT_SYMBOL(vme_master_write);
 
 /*
  * Perform RMW cycle to provided location.
  */
 unsigned int vme_master_rmw(struct vme_resource *resource, unsigned int mask,
 	unsigned int compare, unsigned int swap, loff_t offset)
 {
 	struct vme_bridge *bridge = find_bridge(resource);
 	struct vme_master_resource *image;
 
 	if (bridge->master_rmw == NULL) {
 		printk(KERN_WARNING "Writing to resource not supported\n");
 		return -EINVAL;
 	}
 
 	if (resource->type != VME_MASTER) {
 		printk(KERN_ERR "Not a master resource\n");
 		return -EINVAL;
 	}
 
 	image = list_entry(resource->entry, struct vme_master_resource, list);
 
 	return bridge->master_rmw(image, mask, compare, swap, offset);
 }
 EXPORT_SYMBOL(vme_master_rmw);
 
 int vme_master_mmap(struct vme_resource *resource, struct vm_area_struct *vma)
 {
 	struct vme_master_resource *image;
 	phys_addr_t phys_addr;
 	unsigned long vma_size;
 
 	if (resource->type != VME_MASTER) {
 		pr_err("Not a master resource\n");
 		return -EINVAL;
 	}
 
 	image = list_entry(resource->entry, struct vme_master_resource, list);
 	phys_addr = image->bus_resource.start + (vma->vm_pgoff << PAGE_SHIFT);
 	vma_size = vma->vm_end - vma->vm_start;
 
 	if (phys_addr + vma_size > image->bus_resource.end + 1) {
 		pr_err("Map size cannot exceed the window size\n");
 		return -EFAULT;
 	}
 
 	vma->vm_page_prot = pgprot_noncached(vma->vm_page_prot);
 
 	return vm_iomap_memory(vma, phys_addr, vma->vm_end - vma->vm_start);
 }
 EXPORT_SYMBOL(vme_master_mmap);
 
 void vme_master_free(struct vme_resource *resource)
 {
 	struct vme_master_resource *master_image;
 
 	if (resource->type != VME_MASTER) {
 		printk(KERN_ERR "Not a master resource\n");
 		return;
 	}
 
 	master_image = list_entry(resource->entry, struct vme_master_resource,
 		list);
 	if (master_image == NULL) {
 		printk(KERN_ERR "Can't find master resource\n");
 		return;
 	}
 
 	/* Unlock image */
 	spin_lock(&master_image->lock);
 	if (master_image->locked == 0)
 		printk(KERN_ERR "Image is already free\n");
 
 	master_image->locked = 0;
 	spin_unlock(&master_image->lock);
 
 	/* Free up resource memory */
 	kfree(resource);
 }
 EXPORT_SYMBOL(vme_master_free);
 
 /*
  * Request a DMA controller with specific attributes, return some unique
  * identifier.
  */
 struct vme_resource *vme_dma_request(struct vme_dev *vdev, u32 route)
 {
 	struct vme_bridge *bridge;
 	struct list_head *dma_pos = NULL;
 	struct vme_dma_resource *allocated_ctrlr = NULL;
 	struct vme_dma_resource *dma_ctrlr = NULL;
 	struct vme_resource *resource = NULL;
 
 	/* XXX Not checking resource attributes */
 	printk(KERN_ERR "No VME resource Attribute tests done\n");
 
 	bridge = vdev->bridge;
 	if (bridge == NULL) {
 		printk(KERN_ERR "Can't find VME bus\n");
 		goto err_bus;
 	}
 
 	/* Loop through DMA resources */
 	list_for_each(dma_pos, &bridge->dma_resources) {
 		dma_ctrlr = list_entry(dma_pos,
 			struct vme_dma_resource, list);
 
 		if (dma_ctrlr == NULL) {
 			printk(KERN_ERR "Registered NULL DMA resource\n");
 			continue;
 		}
 
 		/* Find an unlocked and compatible controller */
 		mutex_lock(&dma_ctrlr->mtx);
 		if (((dma_ctrlr->route_attr & route) == route) &&
 			(dma_ctrlr->locked == 0)) {
 
 			dma_ctrlr->locked = 1;
 			mutex_unlock(&dma_ctrlr->mtx);
 			allocated_ctrlr = dma_ctrlr;
 			break;
 		}
 		mutex_unlock(&dma_ctrlr->mtx);
 	}
 
 	/* Check to see if we found a resource */
 	if (allocated_ctrlr == NULL)
 		goto err_ctrlr;
 
 	resource = kmalloc(sizeof(struct vme_resource), GFP_KERNEL);
 	if (resource == NULL) {
 		printk(KERN_WARNING "Unable to allocate resource structure\n");
 		goto err_alloc;
 	}
 	resource->type = VME_DMA;
 	resource->entry = &allocated_ctrlr->list;
 
 	return resource;
 
 err_alloc:
 	/* Unlock image */
 	mutex_lock(&dma_ctrlr->mtx);
 	dma_ctrlr->locked = 0;
 	mutex_unlock(&dma_ctrlr->mtx);
 err_ctrlr:
 err_bus:
 	return NULL;
 }
 EXPORT_SYMBOL(vme_dma_request);
 
 /*
  * Start new list
  */
 struct vme_dma_list *vme_new_dma_list(struct vme_resource *resource)
 {
 	struct vme_dma_resource *ctrlr;
 	struct vme_dma_list *dma_list;
 
 	if (resource->type != VME_DMA) {
 		printk(KERN_ERR "Not a DMA resource\n");
 		return NULL;
 	}
 
 	ctrlr = list_entry(resource->entry, struct vme_dma_resource, list);
 
 	dma_list = kmalloc(sizeof(struct vme_dma_list), GFP_KERNEL);
 	if (dma_list == NULL) {
 		printk(KERN_ERR "Unable to allocate memory for new DMA list\n");
 		return NULL;
 	}
 	INIT_LIST_HEAD(&dma_list->entries);
 	dma_list->parent = ctrlr;
 	mutex_init(&dma_list->mtx);
 
 	return dma_list;
 }
 EXPORT_SYMBOL(vme_new_dma_list);
 
 /*
  * Create "Pattern" type attributes
  */
 struct vme_dma_attr *vme_dma_pattern_attribute(u32 pattern, u32 type)
 {
 	struct vme_dma_attr *attributes;
 	struct vme_dma_pattern *pattern_attr;
 
 	attributes = kmalloc(sizeof(struct vme_dma_attr), GFP_KERNEL);
 	if (attributes == NULL) {
 		printk(KERN_ERR "Unable to allocate memory for attributes structure\n");
 		goto err_attr;
 	}
 
 	pattern_attr = kmalloc(sizeof(struct vme_dma_pattern), GFP_KERNEL);
 	if (pattern_attr == NULL) {
 		printk(KERN_ERR "Unable to allocate memory for pattern attributes\n");
 		goto err_pat;
 	}
 
 	attributes->type = VME_DMA_PATTERN;
 	attributes->private = (void *)pattern_attr;
 
 	pattern_attr->pattern = pattern;
 	pattern_attr->type = type;
 
 	return attributes;
 
 err_pat:
 	kfree(attributes);
 err_attr:
 	return NULL;
 }
 EXPORT_SYMBOL(vme_dma_pattern_attribute);
 
 /*
  * Create "PCI" type attributes
  */
 struct vme_dma_attr *vme_dma_pci_attribute(dma_addr_t address)
 {
 	struct vme_dma_attr *attributes;
 	struct vme_dma_pci *pci_attr;
 
 	/* XXX Run some sanity checks here */
 
 	attributes = kmalloc(sizeof(struct vme_dma_attr), GFP_KERNEL);
 	if (attributes == NULL) {
 		printk(KERN_ERR "Unable to allocate memory for attributes structure\n");
 		goto err_attr;
 	}
 
 	pci_attr = kmalloc(sizeof(struct vme_dma_pci), GFP_KERNEL);
 	if (pci_attr == NULL) {
 		printk(KERN_ERR "Unable to allocate memory for PCI attributes\n");
 		goto err_pci;
 	}
 
 
 
 	attributes->type = VME_DMA_PCI;
 	attributes->private = (void *)pci_attr;
 
 	pci_attr->address = address;
 
 	return attributes;
 
 err_pci:
 	kfree(attributes);
 err_attr:
 	return NULL;
 }
 EXPORT_SYMBOL(vme_dma_pci_attribute);
 
 /*
  * Create "VME" type attributes
  */
 struct vme_dma_attr *vme_dma_vme_attribute(unsigned long long address,
 	u32 aspace, u32 cycle, u32 dwidth)
 {
 	struct vme_dma_attr *attributes;
 	struct vme_dma_vme *vme_attr;
 
 	attributes = kmalloc(
 		sizeof(struct vme_dma_attr), GFP_KERNEL);
 	if (attributes == NULL) {
 		printk(KERN_ERR "Unable to allocate memory for attributes structure\n");
 		goto err_attr;
 	}
 
 	vme_attr = kmalloc(sizeof(struct vme_dma_vme), GFP_KERNEL);
 	if (vme_attr == NULL) {
 		printk(KERN_ERR "Unable to allocate memory for VME attributes\n");
 		goto err_vme;
 	}
 
 	attributes->type = VME_DMA_VME;
 	attributes->private = (void *)vme_attr;
 
 	vme_attr->address = address;
 	vme_attr->aspace = aspace;
 	vme_attr->cycle = cycle;
 	vme_attr->dwidth = dwidth;
 
 	return attributes;
 
 err_vme:
 	kfree(attributes);
 err_attr:
 	return NULL;
 }
 EXPORT_SYMBOL(vme_dma_vme_attribute);
 
 /*
  * Free attribute
  */
 void vme_dma_free_attribute(struct vme_dma_attr *attributes)
 {
 	kfree(attributes->private);
 	kfree(attributes);
 }
 EXPORT_SYMBOL(vme_dma_free_attribute);
 
 int vme_dma_list_add(struct vme_dma_list *list, struct vme_dma_attr *src,
 	struct vme_dma_attr *dest, size_t count)
 {
 	struct vme_bridge *bridge = list->parent->parent;
 	int retval;
 
 	if (bridge->dma_list_add == NULL) {
 		printk(KERN_WARNING "Link List DMA generation not supported\n");
 		return -EINVAL;
 	}
 
 	if (!mutex_trylock(&list->mtx)) {
 		printk(KERN_ERR "Link List already submitted\n");
 		return -EINVAL;
 	}
 
 	retval = bridge->dma_list_add(list, src, dest, count);
 
 	mutex_unlock(&list->mtx);
 
 	return retval;
 }
 EXPORT_SYMBOL(vme_dma_list_add);
 
 int vme_dma_list_exec(struct vme_dma_list *list)
 {
 	struct vme_bridge *bridge = list->parent->parent;
 	int retval;
 
 	if (bridge->dma_list_exec == NULL) {
 		printk(KERN_ERR "Link List DMA execution not supported\n");
 		return -EINVAL;
 	}
 
 	mutex_lock(&list->mtx);
 
 	retval = bridge->dma_list_exec(list);
 
 	mutex_unlock(&list->mtx);
 
 	return retval;
 }
 EXPORT_SYMBOL(vme_dma_list_exec);
 
 int vme_dma_list_free(struct vme_dma_list *list)
 {
 	struct vme_bridge *bridge = list->parent->parent;
 	int retval;
 
 	if (bridge->dma_list_empty == NULL) {
 		printk(KERN_WARNING "Emptying of Link Lists not supported\n");
 		return -EINVAL;
 	}
 
 	if (!mutex_trylock(&list->mtx)) {
 		printk(KERN_ERR "Link List in use\n");
 		return -EINVAL;
 	}
 
 	/*
 	 * Empty out all of the entries from the DMA list. We need to go to the
 	 * low level driver as DMA entries are driver specific.
 	 */
 	retval = bridge->dma_list_empty(list);
 	if (retval) {
 		printk(KERN_ERR "Unable to empty link-list entries\n");
 		mutex_unlock(&list->mtx);
 		return retval;
 	}
 	mutex_unlock(&list->mtx);
 	kfree(list);
 
 	return retval;
 }
 EXPORT_SYMBOL(vme_dma_list_free);
 
 int vme_dma_free(struct vme_resource *resource)
 {
 	struct vme_dma_resource *ctrlr;
 
 	if (resource->type != VME_DMA) {
 		printk(KERN_ERR "Not a DMA resource\n");
 		return -EINVAL;
 	}
 
 	ctrlr = list_entry(resource->entry, struct vme_dma_resource, list);
 
 	if (!mutex_trylock(&ctrlr->mtx)) {
 		printk(KERN_ERR "Resource busy, can't free\n");
 		return -EBUSY;
 	}
 
 	if (!(list_empty(&ctrlr->pending) && list_empty(&ctrlr->running))) {
 		printk(KERN_WARNING "Resource still processing transfers\n");
 		mutex_unlock(&ctrlr->mtx);
 		return -EBUSY;
 	}
 
 	ctrlr->locked = 0;
 
 	mutex_unlock(&ctrlr->mtx);
 
 	kfree(resource);
 
 	return 0;
 }
 EXPORT_SYMBOL(vme_dma_free);
 
 void vme_bus_error_handler(struct vme_bridge *bridge,
 			   unsigned long long address, int am)
 {
 	struct list_head *handler_pos = NULL;
 	struct vme_error_handler *handler;
 	int handler_triggered = 0;
 	u32 aspace = vme_get_aspace(am);
 
 	list_for_each(handler_pos, &bridge->vme_error_handlers) {
 		handler = list_entry(handler_pos, struct vme_error_handler,
 				     list);
 		if ((aspace == handler->aspace) &&
 		    (address >= handler->start) &&
 		    (address < handler->end)) {
 			if (!handler->num_errors)
 				handler->first_error = address;
 			if (handler->num_errors != UINT_MAX)
 				handler->num_errors++;
 			handler_triggered = 1;
 		}
 	}
 
 	if (!handler_triggered)
 		dev_err(bridge->parent,
 			"Unhandled VME access error at address 0x%llx\n",
 			address);
 }
 EXPORT_SYMBOL(vme_bus_error_handler);
 
 struct vme_error_handler *vme_register_error_handler(
 	struct vme_bridge *bridge, u32 aspace,
 	unsigned long long address, size_t len)
 {
 	struct vme_error_handler *handler;
 
 	handler = kmalloc(sizeof(*handler), GFP_KERNEL);
 	if (!handler)
 		return NULL;
 
 	handler->aspace = aspace;
 	handler->start = address;
 	handler->end = address + len;
 	handler->num_errors = 0;
 	handler->first_error = 0;
 	list_add_tail(&handler->list, &bridge->vme_error_handlers);
 
 	return handler;
 }
 EXPORT_SYMBOL(vme_register_error_handler);
 
 void vme_unregister_error_handler(struct vme_error_handler *handler)
 {
 	list_del(&handler->list);
 	kfree(handler);
 }
 EXPORT_SYMBOL(vme_unregister_error_handler);
 
 void vme_irq_handler(struct vme_bridge *bridge, int level, int statid)
 {
 	void (*call)(int, int, void *);
 	void *priv_data;
 
 	call = bridge->irq[level - 1].callback[statid].func;
 	priv_data = bridge->irq[level - 1].callback[statid].priv_data;
 
 	if (call != NULL)
 		call(level, statid, priv_data);
 	else
 		printk(KERN_WARNING "Spurious VME interrupt, level:%x, vector:%x\n",
 		       level, statid);
 }
 EXPORT_SYMBOL(vme_irq_handler);
 
 int vme_irq_request(struct vme_dev *vdev, int level, int statid,
 	void (*callback)(int, int, void *),
 	void *priv_data)
 {
 	struct vme_bridge *bridge;
 
 	bridge = vdev->bridge;
 	if (bridge == NULL) {
 		printk(KERN_ERR "Can't find VME bus\n");
 		return -EINVAL;
 	}
 
 	if ((level < 1) || (level > 7)) {
 		printk(KERN_ERR "Invalid interrupt level\n");
 		return -EINVAL;
 	}
 
 	if (bridge->irq_set == NULL) {
 		printk(KERN_ERR "Configuring interrupts not supported\n");
 		return -EINVAL;
 	}
 
 	mutex_lock(&bridge->irq_mtx);
 
 	if (bridge->irq[level - 1].callback[statid].func) {
 		mutex_unlock(&bridge->irq_mtx);
 		printk(KERN_WARNING "VME Interrupt already taken\n");
 		return -EBUSY;
 	}
 
 	bridge->irq[level - 1].count++;
 	bridge->irq[level - 1].callback[statid].priv_data = priv_data;
 	bridge->irq[level - 1].callback[statid].func = callback;
 
 	/* Enable IRQ level */
 	bridge->irq_set(bridge, level, 1, 1);
 
 	mutex_unlock(&bridge->irq_mtx);
 
 	return 0;
 }
 EXPORT_SYMBOL(vme_irq_request);
 
 void vme_irq_free(struct vme_dev *vdev, int level, int statid)
 {
 	struct vme_bridge *bridge;
 
 	bridge = vdev->bridge;
 	if (bridge == NULL) {
 		printk(KERN_ERR "Can't find VME bus\n");
 		return;
 	}
 
 	if ((level < 1) || (level > 7)) {
 		printk(KERN_ERR "Invalid interrupt level\n");
 		return;
 	}
 
 	if (bridge->irq_set == NULL) {
 		printk(KERN_ERR "Configuring interrupts not supported\n");
 		return;
 	}
 
 	mutex_lock(&bridge->irq_mtx);
 
 	bridge->irq[level - 1].count--;
 
 	/* Disable IRQ level if no more interrupts attached at this level*/
 	if (bridge->irq[level - 1].count == 0)
 		bridge->irq_set(bridge, level, 0, 1);
 
 	bridge->irq[level - 1].callback[statid].func = NULL;
 	bridge->irq[level - 1].callback[statid].priv_data = NULL;
 
 	mutex_unlock(&bridge->irq_mtx);
 }
 EXPORT_SYMBOL(vme_irq_free);
 
 int vme_irq_generate(struct vme_dev *vdev, int level, int statid)
 {
 	struct vme_bridge *bridge;
 
 	bridge = vdev->bridge;
 	if (bridge == NULL) {
 		printk(KERN_ERR "Can't find VME bus\n");
 		return -EINVAL;
 	}
 
 	if ((level < 1) || (level > 7)) {
 		printk(KERN_WARNING "Invalid interrupt level\n");
 		return -EINVAL;
 	}
 
 	if (bridge->irq_generate == NULL) {
 		printk(KERN_WARNING "Interrupt generation not supported\n");
 		return -EINVAL;
 	}
 
 	return bridge->irq_generate(bridge, level, statid);
 }
 EXPORT_SYMBOL(vme_irq_generate);
 
 /*
  * Request the location monitor, return resource or NULL
  */
 struct vme_resource *vme_lm_request(struct vme_dev *vdev)
 {
 	struct vme_bridge *bridge;
 	struct list_head *lm_pos = NULL;
 	struct vme_lm_resource *allocated_lm = NULL;
 	struct vme_lm_resource *lm = NULL;
 	struct vme_resource *resource = NULL;
 
 	bridge = vdev->bridge;
 	if (bridge == NULL) {
 		printk(KERN_ERR "Can't find VME bus\n");
 		goto err_bus;
 	}
 
 	/* Loop through DMA resources */
 	list_for_each(lm_pos, &bridge->lm_resources) {
 		lm = list_entry(lm_pos,
 			struct vme_lm_resource, list);
 
 		if (lm == NULL) {
 			printk(KERN_ERR "Registered NULL Location Monitor resource\n");
 			continue;
 		}
 
 		/* Find an unlocked controller */
 		mutex_lock(&lm->mtx);
 		if (lm->locked == 0) {
 			lm->locked = 1;
 			mutex_unlock(&lm->mtx);
 			allocated_lm = lm;
 			break;
 		}
 		mutex_unlock(&lm->mtx);
 	}
 
 	/* Check to see if we found a resource */
 	if (allocated_lm == NULL)
 		goto err_lm;
 
 	resource = kmalloc(sizeof(struct vme_resource), GFP_KERNEL);
 	if (resource == NULL) {
 		printk(KERN_ERR "Unable to allocate resource structure\n");
 		goto err_alloc;
 	}
 	resource->type = VME_LM;
 	resource->entry = &allocated_lm->list;
 
 	return resource;
 
 err_alloc:
 	/* Unlock image */
 	mutex_lock(&lm->mtx);
 	lm->locked = 0;
 	mutex_unlock(&lm->mtx);
 err_lm:
 err_bus:
 	return NULL;
 }
 EXPORT_SYMBOL(vme_lm_request);
 
 int vme_lm_count(struct vme_resource *resource)
 {
 	struct vme_lm_resource *lm;
 
 	if (resource->type != VME_LM) {
 		printk(KERN_ERR "Not a Location Monitor resource\n");
 		return -EINVAL;
 	}
 
 	lm = list_entry(resource->entry, struct vme_lm_resource, list);
 
 	return lm->monitors;
 }
 EXPORT_SYMBOL(vme_lm_count);
 
 int vme_lm_set(struct vme_resource *resource, unsigned long long lm_base,
 	u32 aspace, u32 cycle)
 {
 	struct vme_bridge *bridge = find_bridge(resource);
 	struct vme_lm_resource *lm;
 
 	if (resource->type != VME_LM) {
 		printk(KERN_ERR "Not a Location Monitor resource\n");
 		return -EINVAL;
 	}
 
 	lm = list_entry(resource->entry, struct vme_lm_resource, list);
 
 	if (bridge->lm_set == NULL) {
 		printk(KERN_ERR "vme_lm_set not supported\n");
 		return -EINVAL;
 	}
 
 	return bridge->lm_set(lm, lm_base, aspace, cycle);
 }
 EXPORT_SYMBOL(vme_lm_set);
 
 int vme_lm_get(struct vme_resource *resource, unsigned long long *lm_base,
 	u32 *aspace, u32 *cycle)
 {
 	struct vme_bridge *bridge = find_bridge(resource);
 	struct vme_lm_resource *lm;
 
 	if (resource->type != VME_LM) {
 		printk(KERN_ERR "Not a Location Monitor resource\n");
 		return -EINVAL;
 	}
 
 	lm = list_entry(resource->entry, struct vme_lm_resource, list);
 
 	if (bridge->lm_get == NULL) {
 		printk(KERN_ERR "vme_lm_get not supported\n");
 		return -EINVAL;
 	}
 
 	return bridge->lm_get(lm, lm_base, aspace, cycle);
 }
 EXPORT_SYMBOL(vme_lm_get);
 
 int vme_lm_attach(struct vme_resource *resource, int monitor,
 	void (*callback)(void *), void *data)
 {
 	struct vme_bridge *bridge = find_bridge(resource);
 	struct vme_lm_resource *lm;
 
 	if (resource->type != VME_LM) {
 		printk(KERN_ERR "Not a Location Monitor resource\n");
 		return -EINVAL;
 	}
 
 	lm = list_entry(resource->entry, struct vme_lm_resource, list);
 
 	if (bridge->lm_attach == NULL) {
 		printk(KERN_ERR "vme_lm_attach not supported\n");
 		return -EINVAL;
 	}
 
 	return bridge->lm_attach(lm, monitor, callback, data);
 }
 EXPORT_SYMBOL(vme_lm_attach);
 
 int vme_lm_detach(struct vme_resource *resource, int monitor)
 {
 	struct vme_bridge *bridge = find_bridge(resource);
 	struct vme_lm_resource *lm;
 
 	if (resource->type != VME_LM) {
 		printk(KERN_ERR "Not a Location Monitor resource\n");
 		return -EINVAL;
 	}
 
 	lm = list_entry(resource->entry, struct vme_lm_resource, list);
 
 	if (bridge->lm_detach == NULL) {
 		printk(KERN_ERR "vme_lm_detach not supported\n");
 		return -EINVAL;
 	}
 
 	return bridge->lm_detach(lm, monitor);
 }
 EXPORT_SYMBOL(vme_lm_detach);
 
 void vme_lm_free(struct vme_resource *resource)
 {
 	struct vme_lm_resource *lm;
 
 	if (resource->type != VME_LM) {
 		printk(KERN_ERR "Not a Location Monitor resource\n");
 		return;
 	}
 
 	lm = list_entry(resource->entry, struct vme_lm_resource, list);
 
 	mutex_lock(&lm->mtx);
 
 	/* XXX
 	 * Check to see that there aren't any callbacks still attached, if
 	 * there are we should probably be detaching them!
 	 */
 
 	lm->locked = 0;
 
 	mutex_unlock(&lm->mtx);
 
 	kfree(resource);
 }
 EXPORT_SYMBOL(vme_lm_free);
 
 int vme_slot_num(struct vme_dev *vdev)
 {
 	struct vme_bridge *bridge;
 
 	bridge = vdev->bridge;
 	if (bridge == NULL) {
 		printk(KERN_ERR "Can't find VME bus\n");
 		return -EINVAL;
 	}
 
 	if (bridge->slot_get == NULL) {
 		printk(KERN_WARNING "vme_slot_num not supported\n");
 		return -EINVAL;
 	}
 
 	return bridge->slot_get(bridge);
 }
 EXPORT_SYMBOL(vme_slot_num);
 
 int vme_bus_num(struct vme_dev *vdev)
 {
 	struct vme_bridge *bridge;
 
 	bridge = vdev->bridge;
 	if (bridge == NULL) {
 		pr_err("Can't find VME bus\n");
 		return -EINVAL;
 	}
 
 	return bridge->num;
 }
 EXPORT_SYMBOL(vme_bus_num);
 
 /* - Bridge Registration --------------------------------------------------- */
 
 static void vme_dev_release(struct device *dev)
 {
 	kfree(dev_to_vme_dev(dev));
 }
 
 /* Common bridge initialization */
 struct vme_bridge *vme_init_bridge(struct vme_bridge *bridge)
 {
 	INIT_LIST_HEAD(&bridge->vme_error_handlers);
 	INIT_LIST_HEAD(&bridge->master_resources);
 	INIT_LIST_HEAD(&bridge->slave_resources);
 	INIT_LIST_HEAD(&bridge->dma_resources);
 	INIT_LIST_HEAD(&bridge->lm_resources);
 	mutex_init(&bridge->irq_mtx);
 
 	return bridge;
 }
 EXPORT_SYMBOL(vme_init_bridge);
 
 int vme_register_bridge(struct vme_bridge *bridge)
 {
 	int i;
 	int ret = -1;
 
 	mutex_lock(&vme_buses_lock);
 	for (i = 0; i < sizeof(vme_bus_numbers) * 8; i++) {
 		if ((vme_bus_numbers & (1 << i)) == 0) {
 			vme_bus_numbers |= (1 << i);
 			bridge->num = i;
 			INIT_LIST_HEAD(&bridge->devices);
 			list_add_tail(&bridge->bus_list, &vme_bus_list);
 			ret = 0;
 			break;
 		}
 	}
 	mutex_unlock(&vme_buses_lock);
 
 	return ret;
 }
 EXPORT_SYMBOL(vme_register_bridge);
 
 void vme_unregister_bridge(struct vme_bridge *bridge)
 {
 	struct vme_dev *vdev;
 	struct vme_dev *tmp;
 
 	mutex_lock(&vme_buses_lock);
 	vme_bus_numbers &= ~(1 << bridge->num);
 	list_for_each_entry_safe(vdev, tmp, &bridge->devices, bridge_list) {
 		list_del(&vdev->drv_list);
 		list_del(&vdev->bridge_list);
 		device_unregister(&vdev->dev);
 	}
 	list_del(&bridge->bus_list);
 	mutex_unlock(&vme_buses_lock);
 }
 EXPORT_SYMBOL(vme_unregister_bridge);
 
 /* - Driver Registration --------------------------------------------------- */
 
 static int __vme_register_driver_bus(struct vme_driver *drv,
 	struct vme_bridge *bridge, unsigned int ndevs)
 {
 	int err;
 	unsigned int i;
 	struct vme_dev *vdev;
 	struct vme_dev *tmp;
 
 	for (i = 0; i < ndevs; i++) {
 		vdev = kzalloc(sizeof(struct vme_dev), GFP_KERNEL);
 		if (!vdev) {
 			err = -ENOMEM;
 			goto err_devalloc;
 		}
 		vdev->num = i;
 		vdev->bridge = bridge;
 		vdev->dev.platform_data = drv;
 		vdev->dev.release = vme_dev_release;
 		vdev->dev.parent = bridge->parent;
 		vdev->dev.bus = &vme_bus_type;
 		dev_set_name(&vdev->dev, "%s.%u-%u", drv->name, bridge->num,
 			vdev->num);
 
 		err = device_register(&vdev->dev);
 		if (err)
 			goto err_reg;
 
 		if (vdev->dev.platform_data) {
 			list_add_tail(&vdev->drv_list, &drv->devices);
 			list_add_tail(&vdev->bridge_list, &bridge->devices);
 		} else
 			device_unregister(&vdev->dev);
 	}
 	return 0;
 
 err_reg:
 	put_device(&vdev->dev);
 	kfree(vdev);
 err_devalloc:
 	list_for_each_entry_safe(vdev, tmp, &drv->devices, drv_list) {
 		list_del(&vdev->drv_list);
 		list_del(&vdev->bridge_list);
 		device_unregister(&vdev->dev);
 	}
 	return err;
 }
 
 static int __vme_register_driver(struct vme_driver *drv, unsigned int ndevs)
 {
 	struct vme_bridge *bridge;
 	int err = 0;
 
 	mutex_lock(&vme_buses_lock);
 	list_for_each_entry(bridge, &vme_bus_list, bus_list) {
 		/*
 		 * This cannot cause trouble as we already have vme_buses_lock
 		 * and if the bridge is removed, it will have to go through
 		 * vme_unregister_bridge() to do it (which calls remove() on
 		 * the bridge which in turn tries to acquire vme_buses_lock and
 		 * will have to wait).
 		 */
 		err = __vme_register_driver_bus(drv, bridge, ndevs);
 		if (err)
 			break;
 	}
 	mutex_unlock(&vme_buses_lock);
 	return err;
 }
 
 int vme_register_driver(struct vme_driver *drv, unsigned int ndevs)
 {
 	int err;
 
 	drv->driver.name = drv->name;
 	drv->driver.bus = &vme_bus_type;
 	INIT_LIST_HEAD(&drv->devices);
 
 	err = driver_register(&drv->driver);
 	if (err)
 		return err;
 
 	err = __vme_register_driver(drv, ndevs);
 	if (err)
 		driver_unregister(&drv->driver);
 
 	return err;
 }
 EXPORT_SYMBOL(vme_register_driver);
 
 void vme_unregister_driver(struct vme_driver *drv)
 {
 	struct vme_dev *dev, *dev_tmp;
 
 	mutex_lock(&vme_buses_lock);
 	list_for_each_entry_safe(dev, dev_tmp, &drv->devices, drv_list) {
 		list_del(&dev->drv_list);
 		list_del(&dev->bridge_list);
 		device_unregister(&dev->dev);
 	}
 	mutex_unlock(&vme_buses_lock);
 
 	driver_unregister(&drv->driver);
 }
 EXPORT_SYMBOL(vme_unregister_driver);
 
 /* - Bus Registration ------------------------------------------------------ */
 
 static int vme_bus_match(struct device *dev, struct device_driver *drv)
 {
 	struct vme_driver *vme_drv;
 
 	vme_drv = container_of(drv, struct vme_driver, driver);
 
 	if (dev->platform_data == vme_drv) {
 		struct vme_dev *vdev = dev_to_vme_dev(dev);
 
 		if (vme_drv->match && vme_drv->match(vdev))
 			return 1;
 
 		dev->platform_data = NULL;
 	}
 	return 0;
 }
 
 static int vme_bus_probe(struct device *dev)
 {
 	int retval = -ENODEV;
 	struct vme_driver *driver;
 	struct vme_dev *vdev = dev_to_vme_dev(dev);
 
 	driver = dev->platform_data;
 
 	if (driver->probe != NULL)
 		retval = driver->probe(vdev);
 
 	return retval;
 }
 
+static int vme_bus_remove(struct device *dev)
+{
+	int retval = -ENODEV;
+	struct vme_driver *driver;
+	struct vme_dev *vdev = dev_to_vme_dev(dev);
+
+	driver = dev->platform_data;
+
+	if (driver->remove != NULL)
+		retval = driver->remove(vdev);
+
+	return retval;
+}
+
 struct bus_type vme_bus_type = {
 	.name = "vme",
 	.match = vme_bus_match,
 	.probe = vme_bus_probe,
+	.remove = vme_bus_remove,
 };
 EXPORT_SYMBOL(vme_bus_type);
 
 static int __init vme_init(void)
 {
 	return bus_register(&vme_bus_type);
 }
 subsys_initcall(vme_init);
diff --git a/drivers/w1/masters/ds2490.c b/drivers/w1/masters/ds2490.c
index 049a884a756f..be77b7914fad 100644
--- a/drivers/w1/masters/ds2490.c
+++ b/drivers/w1/masters/ds2490.c
@@ -1,1090 +1,1115 @@
 /*
  *	ds2490.c  USB to one wire bridge
  *
  * Copyright (c) 2004 Evgeniy Polyakov <zbr@ioremap.net>
  *
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
  * the Free Software Foundation; either version 2 of the License, or
  * (at your option) any later version.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
  *
  * You should have received a copy of the GNU General Public License
  * along with this program; if not, write to the Free Software
  * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
  */
 
 #include <linux/module.h>
 #include <linux/kernel.h>
 #include <linux/mod_devicetable.h>
 #include <linux/usb.h>
 #include <linux/slab.h>
 
 #include "../w1_int.h"
 #include "../w1.h"
 
 /* USB Standard */
 /* USB Control request vendor type */
 #define VENDOR				0x40
 
 /* COMMAND TYPE CODES */
 #define CONTROL_CMD			0x00
 #define COMM_CMD			0x01
 #define MODE_CMD			0x02
 
 /* CONTROL COMMAND CODES */
 #define CTL_RESET_DEVICE		0x0000
 #define CTL_START_EXE			0x0001
 #define CTL_RESUME_EXE			0x0002
 #define CTL_HALT_EXE_IDLE		0x0003
 #define CTL_HALT_EXE_DONE		0x0004
 #define CTL_FLUSH_COMM_CMDS		0x0007
 #define CTL_FLUSH_RCV_BUFFER		0x0008
 #define CTL_FLUSH_XMT_BUFFER		0x0009
 #define CTL_GET_COMM_CMDS		0x000A
 
 /* MODE COMMAND CODES */
 #define MOD_PULSE_EN			0x0000
 #define MOD_SPEED_CHANGE_EN		0x0001
 #define MOD_1WIRE_SPEED			0x0002
 #define MOD_STRONG_PU_DURATION		0x0003
 #define MOD_PULLDOWN_SLEWRATE		0x0004
 #define MOD_PROG_PULSE_DURATION		0x0005
 #define MOD_WRITE1_LOWTIME		0x0006
 #define MOD_DSOW0_TREC			0x0007
 
 /* COMMUNICATION COMMAND CODES */
 #define COMM_ERROR_ESCAPE		0x0601
 #define COMM_SET_DURATION		0x0012
 #define COMM_BIT_IO			0x0020
 #define COMM_PULSE			0x0030
 #define COMM_1_WIRE_RESET		0x0042
 #define COMM_BYTE_IO			0x0052
 #define COMM_MATCH_ACCESS		0x0064
 #define COMM_BLOCK_IO			0x0074
 #define COMM_READ_STRAIGHT		0x0080
 #define COMM_DO_RELEASE			0x6092
 #define COMM_SET_PATH			0x00A2
 #define COMM_WRITE_SRAM_PAGE		0x00B2
 #define COMM_WRITE_EPROM		0x00C4
 #define COMM_READ_CRC_PROT_PAGE		0x00D4
 #define COMM_READ_REDIRECT_PAGE_CRC	0x21E4
 #define COMM_SEARCH_ACCESS		0x00F4
 
 /* Communication command bits */
 #define COMM_TYPE			0x0008
 #define COMM_SE				0x0008
 #define COMM_D				0x0008
 #define COMM_Z				0x0008
 #define COMM_CH				0x0008
 #define COMM_SM				0x0008
 #define COMM_R				0x0008
 #define COMM_IM				0x0001
 
 #define COMM_PS				0x4000
 #define COMM_PST			0x4000
 #define COMM_CIB			0x4000
 #define COMM_RTS			0x4000
 #define COMM_DT				0x2000
 #define COMM_SPU			0x1000
 #define COMM_F				0x0800
 #define COMM_NTF			0x0400
 #define COMM_ICP			0x0200
 #define COMM_RST			0x0100
 
 #define PULSE_PROG			0x01
 #define PULSE_SPUE			0x02
 
 #define BRANCH_MAIN			0xCC
 #define BRANCH_AUX			0x33
 
 /* Status flags */
 #define ST_SPUA				0x01  /* Strong Pull-up is active */
 #define ST_PRGA				0x02  /* 12V programming pulse is being generated */
 #define ST_12VP				0x04  /* external 12V programming voltage is present */
 #define ST_PMOD				0x08  /* DS2490 powered from USB and external sources */
 #define ST_HALT				0x10  /* DS2490 is currently halted */
 #define ST_IDLE				0x20  /* DS2490 is currently idle */
 #define ST_EPOF				0x80
 /* Status transfer size, 16 bytes status, 16 byte result flags */
 #define ST_SIZE				0x20
 
 /* Result Register flags */
 #define RR_DETECT			0xA5 /* New device detected */
 #define RR_NRS				0x01 /* Reset no presence or ... */
 #define RR_SH				0x02 /* short on reset or set path */
 #define RR_APP				0x04 /* alarming presence on reset */
 #define RR_VPP				0x08 /* 12V expected not seen */
 #define RR_CMP				0x10 /* compare error */
 #define RR_CRC				0x20 /* CRC error detected */
 #define RR_RDP				0x40 /* redirected page */
 #define RR_EOS				0x80 /* end of search error */
 
 #define SPEED_NORMAL			0x00
 #define SPEED_FLEXIBLE			0x01
 #define SPEED_OVERDRIVE			0x02
 
 #define NUM_EP				4
 #define EP_CONTROL			0
 #define EP_STATUS			1
 #define EP_DATA_OUT			2
 #define EP_DATA_IN			3
 
 struct ds_device
 {
 	struct list_head	ds_entry;
 
 	struct usb_device	*udev;
 	struct usb_interface	*intf;
 
 	int			ep[NUM_EP];
 
 	/* Strong PullUp
 	 * 0: pullup not active, else duration in milliseconds
 	 */
 	int			spu_sleep;
 	/* spu_bit contains COMM_SPU or 0 depending on if the strong pullup
 	 * should be active or not for writes.
 	 */
 	u16			spu_bit;
 
+	u8			st_buf[ST_SIZE];
+	u8			byte_buf;
+
 	struct w1_bus_master	master;
 };
 
 struct ds_status
 {
 	u8			enable;
 	u8			speed;
 	u8			pullup_dur;
 	u8			ppuls_dur;
 	u8			pulldown_slew;
 	u8			write1_time;
 	u8			write0_time;
 	u8			reserved0;
 	u8			status;
 	u8			command0;
 	u8			command1;
 	u8			command_buffer_status;
 	u8			data_out_buffer_status;
 	u8			data_in_buffer_status;
 	u8			reserved1;
 	u8			reserved2;
-
 };
 
 static struct usb_device_id ds_id_table [] = {
 	{ USB_DEVICE(0x04fa, 0x2490) },
 	{ },
 };
 MODULE_DEVICE_TABLE(usb, ds_id_table);
 
 static int ds_probe(struct usb_interface *, const struct usb_device_id *);
 static void ds_disconnect(struct usb_interface *);
 
 static int ds_send_control(struct ds_device *, u16, u16);
 static int ds_send_control_cmd(struct ds_device *, u16, u16);
 
 static LIST_HEAD(ds_devices);
 static DEFINE_MUTEX(ds_mutex);
 
 static struct usb_driver ds_driver = {
 	.name =		"DS9490R",
 	.probe =	ds_probe,
 	.disconnect =	ds_disconnect,
 	.id_table =	ds_id_table,
 };
 
 static int ds_send_control_cmd(struct ds_device *dev, u16 value, u16 index)
 {
 	int err;
 
 	err = usb_control_msg(dev->udev, usb_sndctrlpipe(dev->udev, dev->ep[EP_CONTROL]),
 			CONTROL_CMD, VENDOR, value, index, NULL, 0, 1000);
 	if (err < 0) {
 		pr_err("Failed to send command control message %x.%x: err=%d.\n",
 				value, index, err);
 		return err;
 	}
 
 	return err;
 }
 
 static int ds_send_control_mode(struct ds_device *dev, u16 value, u16 index)
 {
 	int err;
 
 	err = usb_control_msg(dev->udev, usb_sndctrlpipe(dev->udev, dev->ep[EP_CONTROL]),
 			MODE_CMD, VENDOR, value, index, NULL, 0, 1000);
 	if (err < 0) {
 		pr_err("Failed to send mode control message %x.%x: err=%d.\n",
 				value, index, err);
 		return err;
 	}
 
 	return err;
 }
 
 static int ds_send_control(struct ds_device *dev, u16 value, u16 index)
 {
 	int err;
 
 	err = usb_control_msg(dev->udev, usb_sndctrlpipe(dev->udev, dev->ep[EP_CONTROL]),
 			COMM_CMD, VENDOR, value, index, NULL, 0, 1000);
 	if (err < 0) {
 		pr_err("Failed to send control message %x.%x: err=%d.\n",
 				value, index, err);
 		return err;
 	}
 
 	return err;
 }
 
-static int ds_recv_status_nodump(struct ds_device *dev, struct ds_status *st,
-				 unsigned char *buf, int size)
-{
-	int count, err;
-
-	memset(st, 0, sizeof(*st));
-
-	count = 0;
-	err = usb_interrupt_msg(dev->udev, usb_rcvintpipe(dev->udev,
-		dev->ep[EP_STATUS]), buf, size, &count, 1000);
-	if (err < 0) {
-		pr_err("Failed to read 1-wire data from 0x%x: err=%d.\n",
-		       dev->ep[EP_STATUS], err);
-		return err;
-	}
-
-	if (count >= sizeof(*st))
-		memcpy(st, buf, sizeof(*st));
-
-	return count;
-}
-
 static inline void ds_print_msg(unsigned char *buf, unsigned char *str, int off)
 {
 	pr_info("%45s: %8x\n", str, buf[off]);
 }
 
 static void ds_dump_status(struct ds_device *dev, unsigned char *buf, int count)
 {
 	int i;
 
 	pr_info("0x%x: count=%d, status: ", dev->ep[EP_STATUS], count);
 	for (i=0; i<count; ++i)
 		pr_info("%02x ", buf[i]);
 	pr_info("\n");
 
 	if (count >= 16) {
 		ds_print_msg(buf, "enable flag", 0);
 		ds_print_msg(buf, "1-wire speed", 1);
 		ds_print_msg(buf, "strong pullup duration", 2);
 		ds_print_msg(buf, "programming pulse duration", 3);
 		ds_print_msg(buf, "pulldown slew rate control", 4);
 		ds_print_msg(buf, "write-1 low time", 5);
 		ds_print_msg(buf, "data sample offset/write-0 recovery time",
 			6);
 		ds_print_msg(buf, "reserved (test register)", 7);
 		ds_print_msg(buf, "device status flags", 8);
 		ds_print_msg(buf, "communication command byte 1", 9);
 		ds_print_msg(buf, "communication command byte 2", 10);
 		ds_print_msg(buf, "communication command buffer status", 11);
 		ds_print_msg(buf, "1-wire data output buffer status", 12);
 		ds_print_msg(buf, "1-wire data input buffer status", 13);
 		ds_print_msg(buf, "reserved", 14);
 		ds_print_msg(buf, "reserved", 15);
 	}
 	for (i = 16; i < count; ++i) {
 		if (buf[i] == RR_DETECT) {
 			ds_print_msg(buf, "new device detect", i);
 			continue;
 		}
 		ds_print_msg(buf, "Result Register Value: ", i);
 		if (buf[i] & RR_NRS)
 			pr_info("NRS: Reset no presence or ...\n");
 		if (buf[i] & RR_SH)
 			pr_info("SH: short on reset or set path\n");
 		if (buf[i] & RR_APP)
 			pr_info("APP: alarming presence on reset\n");
 		if (buf[i] & RR_VPP)
 			pr_info("VPP: 12V expected not seen\n");
 		if (buf[i] & RR_CMP)
 			pr_info("CMP: compare error\n");
 		if (buf[i] & RR_CRC)
 			pr_info("CRC: CRC error detected\n");
 		if (buf[i] & RR_RDP)
 			pr_info("RDP: redirected page\n");
 		if (buf[i] & RR_EOS)
 			pr_info("EOS: end of search error\n");
 	}
 }
 
+static int ds_recv_status(struct ds_device *dev, struct ds_status *st,
+			  bool dump)
+{
+	int count, err;
+
+	if (st)
+		memset(st, 0, sizeof(*st));
+
+	count = 0;
+	err = usb_interrupt_msg(dev->udev,
+				usb_rcvintpipe(dev->udev,
+					       dev->ep[EP_STATUS]),
+				dev->st_buf, sizeof(dev->st_buf),
+				&count, 1000);
+	if (err < 0) {
+		pr_err("Failed to read 1-wire data from 0x%x: err=%d.\n",
+		       dev->ep[EP_STATUS], err);
+		return err;
+	}
+
+	if (dump)
+		ds_dump_status(dev, dev->st_buf, count);
+
+	if (st && count >= sizeof(*st))
+		memcpy(st, dev->st_buf, sizeof(*st));
+
+	return count;
+}
+
 static void ds_reset_device(struct ds_device *dev)
 {
 	ds_send_control_cmd(dev, CTL_RESET_DEVICE, 0);
 	/* Always allow strong pullup which allow individual writes to use
 	 * the strong pullup.
 	 */
 	if (ds_send_control_mode(dev, MOD_PULSE_EN, PULSE_SPUE))
 		pr_err("ds_reset_device: Error allowing strong pullup\n");
 	/* Chip strong pullup time was cleared. */
 	if (dev->spu_sleep) {
 		/* lower 4 bits are 0, see ds_set_pullup */
 		u8 del = dev->spu_sleep>>4;
 		if (ds_send_control(dev, COMM_SET_DURATION | COMM_IM, del))
 			pr_err("ds_reset_device: Error setting duration\n");
 	}
 }
 
 static int ds_recv_data(struct ds_device *dev, unsigned char *buf, int size)
 {
 	int count, err;
-	struct ds_status st;
 
 	/* Careful on size.  If size is less than what is available in
 	 * the input buffer, the device fails the bulk transfer and
 	 * clears the input buffer.  It could read the maximum size of
 	 * the data buffer, but then do you return the first, last, or
 	 * some set of the middle size bytes?  As long as the rest of
 	 * the code is correct there will be size bytes waiting.  A
 	 * call to ds_wait_status will wait until the device is idle
 	 * and any data to be received would have been available.
 	 */
 	count = 0;
 	err = usb_bulk_msg(dev->udev, usb_rcvbulkpipe(dev->udev, dev->ep[EP_DATA_IN]),
 				buf, size, &count, 1000);
 	if (err < 0) {
-		u8 buf[ST_SIZE];
-		int count;
-
 		pr_info("Clearing ep0x%x.\n", dev->ep[EP_DATA_IN]);
 		usb_clear_halt(dev->udev, usb_rcvbulkpipe(dev->udev, dev->ep[EP_DATA_IN]));
-
-		count = ds_recv_status_nodump(dev, &st, buf, sizeof(buf));
-		ds_dump_status(dev, buf, count);
+		ds_recv_status(dev, NULL, true);
 		return err;
 	}
 
 #if 0
 	{
 		int i;
 
 		printk("%s: count=%d: ", __func__, count);
 		for (i=0; i<count; ++i)
 			printk("%02x ", buf[i]);
 		printk("\n");
 	}
 #endif
 	return count;
 }
 
 static int ds_send_data(struct ds_device *dev, unsigned char *buf, int len)
 {
 	int count, err;
 
 	count = 0;
 	err = usb_bulk_msg(dev->udev, usb_sndbulkpipe(dev->udev, dev->ep[EP_DATA_OUT]), buf, len, &count, 1000);
 	if (err < 0) {
 		pr_err("Failed to write 1-wire data to ep0x%x: "
 			"err=%d.\n", dev->ep[EP_DATA_OUT], err);
 		return err;
 	}
 
 	return err;
 }
 
 #if 0
 
 int ds_stop_pulse(struct ds_device *dev, int limit)
 {
 	struct ds_status st;
 	int count = 0, err = 0;
-	u8 buf[ST_SIZE];
 
 	do {
 		err = ds_send_control(dev, CTL_HALT_EXE_IDLE, 0);
 		if (err)
 			break;
 		err = ds_send_control(dev, CTL_RESUME_EXE, 0);
 		if (err)
 			break;
-		err = ds_recv_status_nodump(dev, &st, buf, sizeof(buf));
+		err = ds_recv_status(dev, &st, false);
 		if (err)
 			break;
 
 		if ((st.status & ST_SPUA) == 0) {
 			err = ds_send_control_mode(dev, MOD_PULSE_EN, 0);
 			if (err)
 				break;
 		}
 	} while(++count < limit);
 
 	return err;
 }
 
 int ds_detect(struct ds_device *dev, struct ds_status *st)
 {
 	int err;
 
 	err = ds_send_control_cmd(dev, CTL_RESET_DEVICE, 0);
 	if (err)
 		return err;
 
 	err = ds_send_control(dev, COMM_SET_DURATION | COMM_IM, 0);
 	if (err)
 		return err;
 
 	err = ds_send_control(dev, COMM_SET_DURATION | COMM_IM | COMM_TYPE, 0x40);
 	if (err)
 		return err;
 
 	err = ds_send_control_mode(dev, MOD_PULSE_EN, PULSE_PROG);
 	if (err)
 		return err;
 
 	err = ds_dump_status(dev, st);
 
 	return err;
 }
 
 #endif  /*  0  */
 
 static int ds_wait_status(struct ds_device *dev, struct ds_status *st)
 {
-	u8 buf[ST_SIZE];
 	int err, count = 0;
 
 	do {
 		st->status = 0;
-		err = ds_recv_status_nodump(dev, st, buf, sizeof(buf));
+		err = ds_recv_status(dev, st, false);
 #if 0
 		if (err >= 0) {
 			int i;
 			printk("0x%x: count=%d, status: ", dev->ep[EP_STATUS], err);
 			for (i=0; i<err; ++i)
-				printk("%02x ", buf[i]);
+				printk("%02x ", dev->st_buf[i]);
 			printk("\n");
 		}
 #endif
 	} while (!(st->status & ST_IDLE) && !(err < 0) && ++count < 100);
 
 	if (err >= 16 && st->status & ST_EPOF) {
 		pr_info("Resetting device after ST_EPOF.\n");
 		ds_reset_device(dev);
 		/* Always dump the device status. */
 		count = 101;
 	}
 
 	/* Dump the status for errors or if there is extended return data.
 	 * The extended status includes new device detection (maybe someone
 	 * can do something with it).
 	 */
 	if (err > 16 || count >= 100 || err < 0)
-		ds_dump_status(dev, buf, err);
+		ds_dump_status(dev, dev->st_buf, err);
 
 	/* Extended data isn't an error.  Well, a short is, but the dump
 	 * would have already told the user that and we can't do anything
 	 * about it in software anyway.
 	 */
 	if (count >= 100 || err < 0)
 		return -1;
 	else
 		return 0;
 }
 
 static int ds_reset(struct ds_device *dev)
 {
 	int err;
 
 	/* Other potentionally interesting flags for reset.
 	 *
 	 * COMM_NTF: Return result register feedback.  This could be used to
 	 * detect some conditions such as short, alarming presence, or
 	 * detect if a new device was detected.
 	 *
 	 * COMM_SE which allows SPEED_NORMAL, SPEED_FLEXIBLE, SPEED_OVERDRIVE:
 	 * Select the data transfer rate.
 	 */
 	err = ds_send_control(dev, COMM_1_WIRE_RESET | COMM_IM, SPEED_NORMAL);
 	if (err)
 		return err;
 
 	return 0;
 }
 
 #if 0
 static int ds_set_speed(struct ds_device *dev, int speed)
 {
 	int err;
 
 	if (speed != SPEED_NORMAL && speed != SPEED_FLEXIBLE && speed != SPEED_OVERDRIVE)
 		return -EINVAL;
 
 	if (speed != SPEED_OVERDRIVE)
 		speed = SPEED_FLEXIBLE;
 
 	speed &= 0xff;
 
 	err = ds_send_control_mode(dev, MOD_1WIRE_SPEED, speed);
 	if (err)
 		return err;
 
 	return err;
 }
 #endif  /*  0  */
 
 static int ds_set_pullup(struct ds_device *dev, int delay)
 {
 	int err = 0;
 	u8 del = 1 + (u8)(delay >> 4);
 	/* Just storing delay would not get the trunication and roundup. */
 	int ms = del<<4;
 
 	/* Enable spu_bit if a delay is set. */
 	dev->spu_bit = delay ? COMM_SPU : 0;
 	/* If delay is zero, it has already been disabled, if the time is
 	 * the same as the hardware was last programmed to, there is also
 	 * nothing more to do.  Compare with the recalculated value ms
 	 * rather than del or delay which can have a different value.
 	 */
 	if (delay == 0 || ms == dev->spu_sleep)
 		return err;
 
 	err = ds_send_control(dev, COMM_SET_DURATION | COMM_IM, del);
 	if (err)
 		return err;
 
 	dev->spu_sleep = ms;
 
 	return err;
 }
 
 static int ds_touch_bit(struct ds_device *dev, u8 bit, u8 *tbit)
 {
 	int err;
 	struct ds_status st;
 
 	err = ds_send_control(dev, COMM_BIT_IO | COMM_IM | (bit ? COMM_D : 0),
 		0);
 	if (err)
 		return err;
 
 	ds_wait_status(dev, &st);
 
 	err = ds_recv_data(dev, tbit, sizeof(*tbit));
 	if (err < 0)
 		return err;
 
 	return 0;
 }
 
 #if 0
 static int ds_write_bit(struct ds_device *dev, u8 bit)
 {
 	int err;
 	struct ds_status st;
 
 	/* Set COMM_ICP to write without a readback.  Note, this will
 	 * produce one time slot, a down followed by an up with COMM_D
 	 * only determing the timing.
 	 */
 	err = ds_send_control(dev, COMM_BIT_IO | COMM_IM | COMM_ICP |
 		(bit ? COMM_D : 0), 0);
 	if (err)
 		return err;
 
 	ds_wait_status(dev, &st);
 
 	return 0;
 }
 #endif
 
 static int ds_write_byte(struct ds_device *dev, u8 byte)
 {
 	int err;
 	struct ds_status st;
-	u8 rbyte;
 
 	err = ds_send_control(dev, COMM_BYTE_IO | COMM_IM | dev->spu_bit, byte);
 	if (err)
 		return err;
 
 	if (dev->spu_bit)
 		msleep(dev->spu_sleep);
 
 	err = ds_wait_status(dev, &st);
 	if (err)
 		return err;
 
-	err = ds_recv_data(dev, &rbyte, sizeof(rbyte));
+	err = ds_recv_data(dev, &dev->byte_buf, 1);
 	if (err < 0)
 		return err;
 
-	return !(byte == rbyte);
+	return !(byte == dev->byte_buf);
 }
 
 static int ds_read_byte(struct ds_device *dev, u8 *byte)
 {
 	int err;
 	struct ds_status st;
 
 	err = ds_send_control(dev, COMM_BYTE_IO | COMM_IM , 0xff);
 	if (err)
 		return err;
 
 	ds_wait_status(dev, &st);
 
 	err = ds_recv_data(dev, byte, sizeof(*byte));
 	if (err < 0)
 		return err;
 
 	return 0;
 }
 
 static int ds_read_block(struct ds_device *dev, u8 *buf, int len)
 {
 	struct ds_status st;
 	int err;
 
 	if (len > 64*1024)
 		return -E2BIG;
 
 	memset(buf, 0xFF, len);
 
 	err = ds_send_data(dev, buf, len);
 	if (err < 0)
 		return err;
 
 	err = ds_send_control(dev, COMM_BLOCK_IO | COMM_IM, len);
 	if (err)
 		return err;
 
 	ds_wait_status(dev, &st);
 
 	memset(buf, 0x00, len);
 	err = ds_recv_data(dev, buf, len);
 
 	return err;
 }
 
 static int ds_write_block(struct ds_device *dev, u8 *buf, int len)
 {
 	int err;
 	struct ds_status st;
 
 	err = ds_send_data(dev, buf, len);
 	if (err < 0)
 		return err;
 
 	err = ds_send_control(dev, COMM_BLOCK_IO | COMM_IM | dev->spu_bit, len);
 	if (err)
 		return err;
 
 	if (dev->spu_bit)
 		msleep(dev->spu_sleep);
 
 	ds_wait_status(dev, &st);
 
 	err = ds_recv_data(dev, buf, len);
 	if (err < 0)
 		return err;
 
 	return !(err == len);
 }
 
 static void ds9490r_search(void *data, struct w1_master *master,
 	u8 search_type, w1_slave_found_callback callback)
 {
 	/* When starting with an existing id, the first id returned will
 	 * be that device (if it is still on the bus most likely).
 	 *
 	 * If the number of devices found is less than or equal to the
 	 * search_limit, that number of IDs will be returned.  If there are
 	 * more, search_limit IDs will be returned followed by a non-zero
 	 * discrepency value.
 	 */
 	struct ds_device *dev = data;
 	int err;
 	u16 value, index;
 	struct ds_status st;
-	u8 st_buf[ST_SIZE];
 	int search_limit;
 	int found = 0;
 	int i;
 
 	/* DS18b20 spec, 13.16 ms per device, 75 per second, sleep for
 	 * discovering 8 devices (1 bulk transfer and 1/2 FIFO size) at a time.
 	 */
 	const unsigned long jtime = msecs_to_jiffies(1000*8/75);
 	/* FIFO 128 bytes, bulk packet size 64, read a multiple of the
 	 * packet size.
 	 */
-	u64 buf[2*64/8];
+	const size_t bufsize = 2 * 64;
+	u64 *buf;
+
+	buf = kmalloc(bufsize, GFP_KERNEL);
+	if (!buf)
+		return;
 
 	mutex_lock(&master->bus_mutex);
 
 	/* address to start searching at */
 	if (ds_send_data(dev, (u8 *)&master->search_id, 8) < 0)
 		goto search_out;
 	master->search_id = 0;
 
 	value = COMM_SEARCH_ACCESS | COMM_IM | COMM_RST | COMM_SM | COMM_F |
 		COMM_RTS;
 	search_limit = master->max_slave_count;
 	if (search_limit > 255)
 		search_limit = 0;
 	index = search_type | (search_limit << 8);
 	if (ds_send_control(dev, value, index) < 0)
 		goto search_out;
 
 	do {
 		schedule_timeout(jtime);
 
-		if (ds_recv_status_nodump(dev, &st, st_buf, sizeof(st_buf)) <
-			sizeof(st)) {
+		err = ds_recv_status(dev, &st, false);
+		if (err < 0 || err < sizeof(st))
 			break;
-		}
 
 		if (st.data_in_buffer_status) {
 			/* Bulk in can receive partial ids, but when it does
 			 * they fail crc and will be discarded anyway.
 			 * That has only been seen when status in buffer
 			 * is 0 and bulk is read anyway, so don't read
 			 * bulk without first checking if status says there
 			 * is data to read.
 			 */
-			err = ds_recv_data(dev, (u8 *)buf, sizeof(buf));
+			err = ds_recv_data(dev, (u8 *)buf, bufsize);
 			if (err < 0)
 				break;
 			for (i = 0; i < err/8; ++i) {
 				++found;
 				if (found <= search_limit)
 					callback(master, buf[i]);
 				/* can't know if there will be a discrepancy
 				 * value after until the next id */
 				if (found == search_limit)
 					master->search_id = buf[i];
 			}
 		}
 
 		if (test_bit(W1_ABORT_SEARCH, &master->flags))
 			break;
 	} while (!(st.status & (ST_IDLE | ST_HALT)));
 
 	/* only continue the search if some weren't found */
 	if (found <= search_limit) {
 		master->search_id = 0;
 	} else if (!test_bit(W1_WARN_MAX_COUNT, &master->flags)) {
 		/* Only max_slave_count will be scanned in a search,
 		 * but it will start where it left off next search
 		 * until all ids are identified and then it will start
 		 * over.  A continued search will report the previous
 		 * last id as the first id (provided it is still on the
 		 * bus).
 		 */
 		dev_info(&dev->udev->dev, "%s: max_slave_count %d reached, "
 			"will continue next search.\n", __func__,
 			master->max_slave_count);
 		set_bit(W1_WARN_MAX_COUNT, &master->flags);
 	}
 search_out:
 	mutex_unlock(&master->bus_mutex);
+	kfree(buf);
 }
 
 #if 0
+/*
+ * FIXME: if this disabled code is ever used in the future all ds_send_data()
+ * calls must be changed to use a DMAable buffer.
+ */
 static int ds_match_access(struct ds_device *dev, u64 init)
 {
 	int err;
 	struct ds_status st;
 
 	err = ds_send_data(dev, (unsigned char *)&init, sizeof(init));
 	if (err)
 		return err;
 
 	ds_wait_status(dev, &st);
 
 	err = ds_send_control(dev, COMM_MATCH_ACCESS | COMM_IM | COMM_RST, 0x0055);
 	if (err)
 		return err;
 
 	ds_wait_status(dev, &st);
 
 	return 0;
 }
 
 static int ds_set_path(struct ds_device *dev, u64 init)
 {
 	int err;
 	struct ds_status st;
 	u8 buf[9];
 
 	memcpy(buf, &init, 8);
 	buf[8] = BRANCH_MAIN;
 
 	err = ds_send_data(dev, buf, sizeof(buf));
 	if (err)
 		return err;
 
 	ds_wait_status(dev, &st);
 
 	err = ds_send_control(dev, COMM_SET_PATH | COMM_IM | COMM_RST, 0);
 	if (err)
 		return err;
 
 	ds_wait_status(dev, &st);
 
 	return 0;
 }
 
 #endif  /*  0  */
 
 static u8 ds9490r_touch_bit(void *data, u8 bit)
 {
-	u8 ret;
 	struct ds_device *dev = data;
 
-	if (ds_touch_bit(dev, bit, &ret))
+	if (ds_touch_bit(dev, bit, &dev->byte_buf))
 		return 0;
 
-	return ret;
+	return dev->byte_buf;
 }
 
 #if 0
 static void ds9490r_write_bit(void *data, u8 bit)
 {
 	struct ds_device *dev = data;
 
 	ds_write_bit(dev, bit);
 }
 
 static u8 ds9490r_read_bit(void *data)
 {
 	struct ds_device *dev = data;
 	int err;
-	u8 bit = 0;
 
-	err = ds_touch_bit(dev, 1, &bit);
+	err = ds_touch_bit(dev, 1, &dev->byte_buf);
 	if (err)
 		return 0;
 
-	return bit & 1;
+	return dev->byte_buf & 1;
 }
 #endif
 
 static void ds9490r_write_byte(void *data, u8 byte)
 {
 	struct ds_device *dev = data;
 
 	ds_write_byte(dev, byte);
 }
 
 static u8 ds9490r_read_byte(void *data)
 {
 	struct ds_device *dev = data;
 	int err;
-	u8 byte = 0;
 
-	err = ds_read_byte(dev, &byte);
+	err = ds_read_byte(dev, &dev->byte_buf);
 	if (err)
 		return 0;
 
-	return byte;
+	return dev->byte_buf;
 }
 
 static void ds9490r_write_block(void *data, const u8 *buf, int len)
 {
 	struct ds_device *dev = data;
+	u8 *tbuf;
+
+	if (len <= 0)
+		return;
+
+	tbuf = kmemdup(buf, len, GFP_KERNEL);
+	if (!tbuf)
+		return;
 
-	ds_write_block(dev, (u8 *)buf, len);
+	ds_write_block(dev, tbuf, len);
+
+	kfree(tbuf);
 }
 
 static u8 ds9490r_read_block(void *data, u8 *buf, int len)
 {
 	struct ds_device *dev = data;
 	int err;
+	u8 *tbuf;
 
-	err = ds_read_block(dev, buf, len);
-	if (err < 0)
+	if (len <= 0)
+		return 0;
+
+	tbuf = kmalloc(len, GFP_KERNEL);
+	if (!tbuf)
 		return 0;
 
-	return len;
+	err = ds_read_block(dev, tbuf, len);
+	if (err >= 0)
+		memcpy(buf, tbuf, len);
+
+	kfree(tbuf);
+
+	return err >= 0 ? len : 0;
 }
 
 static u8 ds9490r_reset(void *data)
 {
 	struct ds_device *dev = data;
 	int err;
 
 	err = ds_reset(dev);
 	if (err)
 		return 1;
 
 	return 0;
 }
 
 static u8 ds9490r_set_pullup(void *data, int delay)
 {
 	struct ds_device *dev = data;
 
 	if (ds_set_pullup(dev, delay))
 		return 1;
 
 	return 0;
 }
 
 static int ds_w1_init(struct ds_device *dev)
 {
 	memset(&dev->master, 0, sizeof(struct w1_bus_master));
 
 	/* Reset the device as it can be in a bad state.
 	 * This is necessary because a block write will wait for data
 	 * to be placed in the output buffer and block any later
 	 * commands which will keep accumulating and the device will
 	 * not be idle.  Another case is removing the ds2490 module
 	 * while a bus search is in progress, somehow a few commands
 	 * get through, but the input transfers fail leaving data in
 	 * the input buffer.  This will cause the next read to fail
 	 * see the note in ds_recv_data.
 	 */
 	ds_reset_device(dev);
 
 	dev->master.data	= dev;
 	dev->master.touch_bit	= &ds9490r_touch_bit;
 	/* read_bit and write_bit in w1_bus_master are expected to set and
 	 * sample the line level.  For write_bit that means it is expected to
 	 * set it to that value and leave it there.  ds2490 only supports an
 	 * individual time slot at the lowest level.  The requirement from
 	 * pulling the bus state down to reading the state is 15us, something
 	 * that isn't realistic on the USB bus anyway.
 	dev->master.read_bit	= &ds9490r_read_bit;
 	dev->master.write_bit	= &ds9490r_write_bit;
 	*/
 	dev->master.read_byte	= &ds9490r_read_byte;
 	dev->master.write_byte	= &ds9490r_write_byte;
 	dev->master.read_block	= &ds9490r_read_block;
 	dev->master.write_block	= &ds9490r_write_block;
 	dev->master.reset_bus	= &ds9490r_reset;
 	dev->master.set_pullup	= &ds9490r_set_pullup;
 	dev->master.search	= &ds9490r_search;
 
 	return w1_add_master_device(&dev->master);
 }
 
 static void ds_w1_fini(struct ds_device *dev)
 {
 	w1_remove_master_device(&dev->master);
 }
 
 static int ds_probe(struct usb_interface *intf,
 		    const struct usb_device_id *udev_id)
 {
 	struct usb_device *udev = interface_to_usbdev(intf);
 	struct usb_endpoint_descriptor *endpoint;
 	struct usb_host_interface *iface_desc;
 	struct ds_device *dev;
 	int i, err, alt;
 
 	dev = kzalloc(sizeof(struct ds_device), GFP_KERNEL);
 	if (!dev) {
 		pr_info("Failed to allocate new DS9490R structure.\n");
 		return -ENOMEM;
 	}
 	dev->udev = usb_get_dev(udev);
 	if (!dev->udev) {
 		err = -ENOMEM;
 		goto err_out_free;
 	}
 	memset(dev->ep, 0, sizeof(dev->ep));
 
 	usb_set_intfdata(intf, dev);
 
 	err = usb_reset_configuration(dev->udev);
 	if (err) {
 		dev_err(&dev->udev->dev,
 			"Failed to reset configuration: err=%d.\n", err);
 		goto err_out_clear;
 	}
 
 	/* alternative 3, 1ms interrupt (greatly speeds search), 64 byte bulk */
 	alt = 3;
 	err = usb_set_interface(dev->udev,
 		intf->altsetting[alt].desc.bInterfaceNumber, alt);
 	if (err) {
 		dev_err(&dev->udev->dev, "Failed to set alternative setting %d "
 			"for %d interface: err=%d.\n", alt,
 			intf->altsetting[alt].desc.bInterfaceNumber, err);
 		goto err_out_clear;
 	}
 
 	iface_desc = &intf->altsetting[alt];
 	if (iface_desc->desc.bNumEndpoints != NUM_EP-1) {
 		pr_info("Num endpoints=%d. It is not DS9490R.\n",
 			iface_desc->desc.bNumEndpoints);
 		err = -EINVAL;
 		goto err_out_clear;
 	}
 
 	/*
 	 * This loop doesn'd show control 0 endpoint,
 	 * so we will fill only 1-3 endpoints entry.
 	 */
 	for (i = 0; i < iface_desc->desc.bNumEndpoints; ++i) {
 		endpoint = &iface_desc->endpoint[i].desc;
 
 		dev->ep[i+1] = endpoint->bEndpointAddress;
 #if 0
 		printk("%d: addr=%x, size=%d, dir=%s, type=%x\n",
 			i, endpoint->bEndpointAddress, le16_to_cpu(endpoint->wMaxPacketSize),
 			(endpoint->bEndpointAddress & USB_DIR_IN)?"IN":"OUT",
 			endpoint->bmAttributes & USB_ENDPOINT_XFERTYPE_MASK);
 #endif
 	}
 
 	err = ds_w1_init(dev);
 	if (err)
 		goto err_out_clear;
 
 	mutex_lock(&ds_mutex);
 	list_add_tail(&dev->ds_entry, &ds_devices);
 	mutex_unlock(&ds_mutex);
 
 	return 0;
 
 err_out_clear:
 	usb_set_intfdata(intf, NULL);
 	usb_put_dev(dev->udev);
 err_out_free:
 	kfree(dev);
 	return err;
 }
 
 static void ds_disconnect(struct usb_interface *intf)
 {
 	struct ds_device *dev;
 
 	dev = usb_get_intfdata(intf);
 	if (!dev)
 		return;
 
 	mutex_lock(&ds_mutex);
 	list_del(&dev->ds_entry);
 	mutex_unlock(&ds_mutex);
 
 	ds_w1_fini(dev);
 
 	usb_set_intfdata(intf, NULL);
 
 	usb_put_dev(dev->udev);
 	kfree(dev);
 }
 
 module_usb_driver(ds_driver);
 
 MODULE_LICENSE("GPL");
 MODULE_AUTHOR("Evgeniy Polyakov <zbr@ioremap.net>");
 MODULE_DESCRIPTION("DS2490 USB <-> W1 bus master driver (DS9490*)");
diff --git a/drivers/w1/masters/omap_hdq.c b/drivers/w1/masters/omap_hdq.c
index bb09de633939..fb190c259607 100644
--- a/drivers/w1/masters/omap_hdq.c
+++ b/drivers/w1/masters/omap_hdq.c
@@ -1,797 +1,797 @@
 /*
  * drivers/w1/masters/omap_hdq.c
  *
  * Copyright (C) 2007,2012 Texas Instruments, Inc.
  *
  * This file is licensed under the terms of the GNU General Public License
  * version 2. This program is licensed "as is" without any warranty of any
  * kind, whether express or implied.
  *
  */
 #include <linux/kernel.h>
 #include <linux/module.h>
 #include <linux/platform_device.h>
 #include <linux/interrupt.h>
 #include <linux/slab.h>
 #include <linux/err.h>
 #include <linux/io.h>
 #include <linux/sched.h>
 #include <linux/pm_runtime.h>
 #include <linux/of.h>
 
 #include "../w1.h"
 #include "../w1_int.h"
 
 #define	MOD_NAME	"OMAP_HDQ:"
 
 #define OMAP_HDQ_REVISION			0x00
 #define OMAP_HDQ_TX_DATA			0x04
 #define OMAP_HDQ_RX_DATA			0x08
 #define OMAP_HDQ_CTRL_STATUS			0x0c
 #define OMAP_HDQ_CTRL_STATUS_SINGLE		BIT(7)
 #define OMAP_HDQ_CTRL_STATUS_INTERRUPTMASK	BIT(6)
 #define OMAP_HDQ_CTRL_STATUS_CLOCKENABLE	BIT(5)
 #define OMAP_HDQ_CTRL_STATUS_GO                 BIT(4)
 #define OMAP_HDQ_CTRL_STATUS_PRESENCE		BIT(3)
 #define OMAP_HDQ_CTRL_STATUS_INITIALIZATION	BIT(2)
 #define OMAP_HDQ_CTRL_STATUS_DIR		BIT(1)
 #define OMAP_HDQ_INT_STATUS			0x10
 #define OMAP_HDQ_INT_STATUS_TXCOMPLETE		BIT(2)
 #define OMAP_HDQ_INT_STATUS_RXCOMPLETE		BIT(1)
 #define OMAP_HDQ_INT_STATUS_TIMEOUT		BIT(0)
 #define OMAP_HDQ_SYSCONFIG			0x14
 #define OMAP_HDQ_SYSCONFIG_SOFTRESET		BIT(1)
 #define OMAP_HDQ_SYSCONFIG_AUTOIDLE		BIT(0)
 #define OMAP_HDQ_SYSCONFIG_NOIDLE		0x0
 #define OMAP_HDQ_SYSSTATUS			0x18
 #define OMAP_HDQ_SYSSTATUS_RESETDONE		BIT(0)
 
 #define OMAP_HDQ_FLAG_CLEAR			0
 #define OMAP_HDQ_FLAG_SET			1
 #define OMAP_HDQ_TIMEOUT			(HZ/5)
 
 #define OMAP_HDQ_MAX_USER			4
 
 static DECLARE_WAIT_QUEUE_HEAD(hdq_wait_queue);
 static int w1_id;
 
 struct hdq_data {
 	struct device		*dev;
 	void __iomem		*hdq_base;
 	/* lock status update */
 	struct  mutex		hdq_mutex;
 	int			hdq_usecount;
 	u8			hdq_irqstatus;
 	/* device lock */
 	spinlock_t		hdq_spinlock;
 	/*
 	 * Used to control the call to omap_hdq_get and omap_hdq_put.
 	 * HDQ Protocol: Write the CMD|REG_address first, followed by
 	 * the data wrire or read.
 	 */
 	int			init_trans;
 	int                     rrw;
 	/* mode: 0-HDQ 1-W1 */
 	int                     mode;
 
 };
 
 static int omap_hdq_probe(struct platform_device *pdev);
 static int omap_hdq_remove(struct platform_device *pdev);
 
 static const struct of_device_id omap_hdq_dt_ids[] = {
 	{ .compatible = "ti,omap3-1w" },
 	{ .compatible = "ti,am4372-hdq" },
 	{}
 };
 MODULE_DEVICE_TABLE(of, omap_hdq_dt_ids);
 
 static struct platform_driver omap_hdq_driver = {
 	.probe =	omap_hdq_probe,
 	.remove =	omap_hdq_remove,
 	.driver =	{
 		.name =	"omap_hdq",
 		.of_match_table = omap_hdq_dt_ids,
 	},
 };
 
 static u8 omap_w1_read_byte(void *_hdq);
 static void omap_w1_write_byte(void *_hdq, u8 byte);
 static u8 omap_w1_reset_bus(void *_hdq);
 
 
 static struct w1_bus_master omap_w1_master = {
 	.read_byte	= omap_w1_read_byte,
 	.write_byte	= omap_w1_write_byte,
 	.reset_bus	= omap_w1_reset_bus,
 };
 
 /* HDQ register I/O routines */
 static inline u8 hdq_reg_in(struct hdq_data *hdq_data, u32 offset)
 {
 	return __raw_readl(hdq_data->hdq_base + offset);
 }
 
 static inline void hdq_reg_out(struct hdq_data *hdq_data, u32 offset, u8 val)
 {
 	__raw_writel(val, hdq_data->hdq_base + offset);
 }
 
 static inline u8 hdq_reg_merge(struct hdq_data *hdq_data, u32 offset,
 			u8 val, u8 mask)
 {
 	u8 new_val = (__raw_readl(hdq_data->hdq_base + offset) & ~mask)
 			| (val & mask);
 	__raw_writel(new_val, hdq_data->hdq_base + offset);
 
 	return new_val;
 }
 
 static void hdq_disable_interrupt(struct hdq_data *hdq_data, u32 offset,
 				  u32 mask)
 {
 	u32 ie;
 
 	ie = readl(hdq_data->hdq_base + offset);
 	writel(ie & mask, hdq_data->hdq_base + offset);
 }
 
 /*
  * Wait for one or more bits in flag change.
  * HDQ_FLAG_SET: wait until any bit in the flag is set.
  * HDQ_FLAG_CLEAR: wait until all bits in the flag are cleared.
  * return 0 on success and -ETIMEDOUT in the case of timeout.
  */
 static int hdq_wait_for_flag(struct hdq_data *hdq_data, u32 offset,
 		u8 flag, u8 flag_set, u8 *status)
 {
 	int ret = 0;
 	unsigned long timeout = jiffies + OMAP_HDQ_TIMEOUT;
 
 	if (flag_set == OMAP_HDQ_FLAG_CLEAR) {
 		/* wait for the flag clear */
 		while (((*status = hdq_reg_in(hdq_data, offset)) & flag)
 			&& time_before(jiffies, timeout)) {
 			schedule_timeout_uninterruptible(1);
 		}
 		if (*status & flag)
 			ret = -ETIMEDOUT;
 	} else if (flag_set == OMAP_HDQ_FLAG_SET) {
 		/* wait for the flag set */
 		while (!((*status = hdq_reg_in(hdq_data, offset)) & flag)
 			&& time_before(jiffies, timeout)) {
 			schedule_timeout_uninterruptible(1);
 		}
 		if (!(*status & flag))
 			ret = -ETIMEDOUT;
 	} else
 		return -EINVAL;
 
 	return ret;
 }
 
 /* write out a byte and fill *status with HDQ_INT_STATUS */
 static int hdq_write_byte(struct hdq_data *hdq_data, u8 val, u8 *status)
 {
 	int ret;
 	u8 tmp_status;
 	unsigned long irqflags;
 
 	*status = 0;
 
 	spin_lock_irqsave(&hdq_data->hdq_spinlock, irqflags);
 	/* clear interrupt flags via a dummy read */
 	hdq_reg_in(hdq_data, OMAP_HDQ_INT_STATUS);
 	/* ISR loads it with new INT_STATUS */
 	hdq_data->hdq_irqstatus = 0;
 	spin_unlock_irqrestore(&hdq_data->hdq_spinlock, irqflags);
 
 	hdq_reg_out(hdq_data, OMAP_HDQ_TX_DATA, val);
 
 	/* set the GO bit */
 	hdq_reg_merge(hdq_data, OMAP_HDQ_CTRL_STATUS, OMAP_HDQ_CTRL_STATUS_GO,
 		OMAP_HDQ_CTRL_STATUS_DIR | OMAP_HDQ_CTRL_STATUS_GO);
 	/* wait for the TXCOMPLETE bit */
 	ret = wait_event_timeout(hdq_wait_queue,
 		hdq_data->hdq_irqstatus, OMAP_HDQ_TIMEOUT);
 	if (ret == 0) {
 		dev_dbg(hdq_data->dev, "TX wait elapsed\n");
 		ret = -ETIMEDOUT;
 		goto out;
 	}
 
 	*status = hdq_data->hdq_irqstatus;
 	/* check irqstatus */
 	if (!(*status & OMAP_HDQ_INT_STATUS_TXCOMPLETE)) {
 		dev_dbg(hdq_data->dev, "timeout waiting for"
 			" TXCOMPLETE/RXCOMPLETE, %x", *status);
 		ret = -ETIMEDOUT;
 		goto out;
 	}
 
 	/* wait for the GO bit return to zero */
 	ret = hdq_wait_for_flag(hdq_data, OMAP_HDQ_CTRL_STATUS,
 			OMAP_HDQ_CTRL_STATUS_GO,
 			OMAP_HDQ_FLAG_CLEAR, &tmp_status);
 	if (ret) {
 		dev_dbg(hdq_data->dev, "timeout waiting GO bit"
 			" return to zero, %x", tmp_status);
 	}
 
 out:
 	return ret;
 }
 
 /* HDQ Interrupt service routine */
 static irqreturn_t hdq_isr(int irq, void *_hdq)
 {
 	struct hdq_data *hdq_data = _hdq;
 	unsigned long irqflags;
 
 	spin_lock_irqsave(&hdq_data->hdq_spinlock, irqflags);
 	hdq_data->hdq_irqstatus = hdq_reg_in(hdq_data, OMAP_HDQ_INT_STATUS);
 	spin_unlock_irqrestore(&hdq_data->hdq_spinlock, irqflags);
 	dev_dbg(hdq_data->dev, "hdq_isr: %x", hdq_data->hdq_irqstatus);
 
 	if (hdq_data->hdq_irqstatus &
 		(OMAP_HDQ_INT_STATUS_TXCOMPLETE | OMAP_HDQ_INT_STATUS_RXCOMPLETE
 		| OMAP_HDQ_INT_STATUS_TIMEOUT)) {
 		/* wake up sleeping process */
 		wake_up(&hdq_wait_queue);
 	}
 
 	return IRQ_HANDLED;
 }
 
 /* W1 search callback function  in HDQ mode */
 static void omap_w1_search_bus(void *_hdq, struct w1_master *master_dev,
 		u8 search_type, w1_slave_found_callback slave_found)
 {
 	u64 module_id, rn_le, cs, id;
 
 	if (w1_id)
 		module_id = w1_id;
 	else
 		module_id = 0x1;
 
 	rn_le = cpu_to_le64(module_id);
 	/*
 	 * HDQ might not obey truly the 1-wire spec.
 	 * So calculate CRC based on module parameter.
 	 */
 	cs = w1_calc_crc8((u8 *)&rn_le, 7);
 	id = (cs << 56) | module_id;
 
 	slave_found(master_dev, id);
 }
 
 static int _omap_hdq_reset(struct hdq_data *hdq_data)
 {
 	int ret;
 	u8 tmp_status;
 
 	hdq_reg_out(hdq_data, OMAP_HDQ_SYSCONFIG,
 		    OMAP_HDQ_SYSCONFIG_SOFTRESET);
 	/*
 	 * Select HDQ/1W mode & enable clocks.
 	 * It is observed that INT flags can't be cleared via a read and GO/INIT
 	 * won't return to zero if interrupt is disabled. So we always enable
 	 * interrupt.
 	 */
 	hdq_reg_out(hdq_data, OMAP_HDQ_CTRL_STATUS,
 		OMAP_HDQ_CTRL_STATUS_CLOCKENABLE |
 		OMAP_HDQ_CTRL_STATUS_INTERRUPTMASK);
 
 	/* wait for reset to complete */
 	ret = hdq_wait_for_flag(hdq_data, OMAP_HDQ_SYSSTATUS,
 		OMAP_HDQ_SYSSTATUS_RESETDONE, OMAP_HDQ_FLAG_SET, &tmp_status);
 	if (ret)
 		dev_dbg(hdq_data->dev, "timeout waiting HDQ reset, %x",
 				tmp_status);
 	else {
 		hdq_reg_out(hdq_data, OMAP_HDQ_CTRL_STATUS,
 			OMAP_HDQ_CTRL_STATUS_CLOCKENABLE |
 			OMAP_HDQ_CTRL_STATUS_INTERRUPTMASK |
 			hdq_data->mode);
 		hdq_reg_out(hdq_data, OMAP_HDQ_SYSCONFIG,
 			OMAP_HDQ_SYSCONFIG_AUTOIDLE);
 	}
 
 	return ret;
 }
 
 /* Issue break pulse to the device */
 static int omap_hdq_break(struct hdq_data *hdq_data)
 {
 	int ret = 0;
 	u8 tmp_status;
 	unsigned long irqflags;
 
 	ret = mutex_lock_interruptible(&hdq_data->hdq_mutex);
 	if (ret < 0) {
 		dev_dbg(hdq_data->dev, "Could not acquire mutex\n");
 		ret = -EINTR;
 		goto rtn;
 	}
 
 	spin_lock_irqsave(&hdq_data->hdq_spinlock, irqflags);
 	/* clear interrupt flags via a dummy read */
 	hdq_reg_in(hdq_data, OMAP_HDQ_INT_STATUS);
 	/* ISR loads it with new INT_STATUS */
 	hdq_data->hdq_irqstatus = 0;
 	spin_unlock_irqrestore(&hdq_data->hdq_spinlock, irqflags);
 
 	/* set the INIT and GO bit */
 	hdq_reg_merge(hdq_data, OMAP_HDQ_CTRL_STATUS,
 		OMAP_HDQ_CTRL_STATUS_INITIALIZATION | OMAP_HDQ_CTRL_STATUS_GO,
 		OMAP_HDQ_CTRL_STATUS_DIR | OMAP_HDQ_CTRL_STATUS_INITIALIZATION |
 		OMAP_HDQ_CTRL_STATUS_GO);
 
 	/* wait for the TIMEOUT bit */
 	ret = wait_event_timeout(hdq_wait_queue,
 		hdq_data->hdq_irqstatus, OMAP_HDQ_TIMEOUT);
 	if (ret == 0) {
 		dev_dbg(hdq_data->dev, "break wait elapsed\n");
 		ret = -EINTR;
 		goto out;
 	}
 
 	tmp_status = hdq_data->hdq_irqstatus;
 	/* check irqstatus */
 	if (!(tmp_status & OMAP_HDQ_INT_STATUS_TIMEOUT)) {
 		dev_dbg(hdq_data->dev, "timeout waiting for TIMEOUT, %x",
 				tmp_status);
 		ret = -ETIMEDOUT;
 		goto out;
 	}
 
 	/*
 	 * check for the presence detect bit to get
 	 * set to show that the slave is responding
 	 */
 	if (!(hdq_reg_in(hdq_data, OMAP_HDQ_CTRL_STATUS) &
 			OMAP_HDQ_CTRL_STATUS_PRESENCE)) {
 		dev_dbg(hdq_data->dev, "Presence bit not set\n");
 		ret = -ETIMEDOUT;
 		goto out;
 	}
 
 	/*
 	 * wait for both INIT and GO bits rerurn to zero.
 	 * zero wait time expected for interrupt mode.
 	 */
 	ret = hdq_wait_for_flag(hdq_data, OMAP_HDQ_CTRL_STATUS,
 			OMAP_HDQ_CTRL_STATUS_INITIALIZATION |
 			OMAP_HDQ_CTRL_STATUS_GO, OMAP_HDQ_FLAG_CLEAR,
 			&tmp_status);
 	if (ret)
 		dev_dbg(hdq_data->dev, "timeout waiting INIT&GO bits"
 			" return to zero, %x", tmp_status);
 
 out:
 	mutex_unlock(&hdq_data->hdq_mutex);
 rtn:
 	return ret;
 }
 
 static int hdq_read_byte(struct hdq_data *hdq_data, u8 *val)
 {
 	int ret = 0;
 	u8 status;
 
 	ret = mutex_lock_interruptible(&hdq_data->hdq_mutex);
 	if (ret < 0) {
 		ret = -EINTR;
 		goto rtn;
 	}
 
 	if (!hdq_data->hdq_usecount) {
 		ret = -EINVAL;
 		goto out;
 	}
 
 	if (!(hdq_data->hdq_irqstatus & OMAP_HDQ_INT_STATUS_RXCOMPLETE)) {
 		hdq_reg_merge(hdq_data, OMAP_HDQ_CTRL_STATUS,
 			OMAP_HDQ_CTRL_STATUS_DIR | OMAP_HDQ_CTRL_STATUS_GO,
 			OMAP_HDQ_CTRL_STATUS_DIR | OMAP_HDQ_CTRL_STATUS_GO);
 		/*
 		 * The RX comes immediately after TX.
 		 */
 		wait_event_timeout(hdq_wait_queue,
 				   (hdq_data->hdq_irqstatus
 				    & OMAP_HDQ_INT_STATUS_RXCOMPLETE),
 				   OMAP_HDQ_TIMEOUT);
 
 		hdq_reg_merge(hdq_data, OMAP_HDQ_CTRL_STATUS, 0,
 			OMAP_HDQ_CTRL_STATUS_DIR);
 		status = hdq_data->hdq_irqstatus;
 		/* check irqstatus */
 		if (!(status & OMAP_HDQ_INT_STATUS_RXCOMPLETE)) {
 			dev_dbg(hdq_data->dev, "timeout waiting for"
 				" RXCOMPLETE, %x", status);
 			ret = -ETIMEDOUT;
 			goto out;
 		}
 	}
 	/* the data is ready. Read it in! */
 	*val = hdq_reg_in(hdq_data, OMAP_HDQ_RX_DATA);
 out:
 	mutex_unlock(&hdq_data->hdq_mutex);
 rtn:
 	return ret;
 
 }
 
 /* Enable clocks and set the controller to HDQ/1W mode */
 static int omap_hdq_get(struct hdq_data *hdq_data)
 {
 	int ret = 0;
 
 	ret = mutex_lock_interruptible(&hdq_data->hdq_mutex);
 	if (ret < 0) {
 		ret = -EINTR;
 		goto rtn;
 	}
 
 	if (OMAP_HDQ_MAX_USER == hdq_data->hdq_usecount) {
 		dev_dbg(hdq_data->dev, "attempt to exceed the max use count");
 		ret = -EINVAL;
 		goto out;
 	} else {
 		hdq_data->hdq_usecount++;
 		try_module_get(THIS_MODULE);
 		if (1 == hdq_data->hdq_usecount) {
 
 			pm_runtime_get_sync(hdq_data->dev);
 
 			/* make sure HDQ/1W is out of reset */
 			if (!(hdq_reg_in(hdq_data, OMAP_HDQ_SYSSTATUS) &
 				OMAP_HDQ_SYSSTATUS_RESETDONE)) {
 				ret = _omap_hdq_reset(hdq_data);
 				if (ret)
 					/* back up the count */
 					hdq_data->hdq_usecount--;
 			} else {
 				/* select HDQ/1W mode & enable clocks */
 				hdq_reg_out(hdq_data, OMAP_HDQ_CTRL_STATUS,
 					OMAP_HDQ_CTRL_STATUS_CLOCKENABLE |
 					OMAP_HDQ_CTRL_STATUS_INTERRUPTMASK |
 					hdq_data->mode);
 				hdq_reg_out(hdq_data, OMAP_HDQ_SYSCONFIG,
 					OMAP_HDQ_SYSCONFIG_NOIDLE);
 				hdq_reg_in(hdq_data, OMAP_HDQ_INT_STATUS);
 			}
 		}
 	}
 
 out:
 	mutex_unlock(&hdq_data->hdq_mutex);
 rtn:
 	return ret;
 }
 
 /* Disable clocks to the module */
 static int omap_hdq_put(struct hdq_data *hdq_data)
 {
 	int ret = 0;
 
 	ret = mutex_lock_interruptible(&hdq_data->hdq_mutex);
 	if (ret < 0)
 		return -EINTR;
 
 	hdq_reg_out(hdq_data, OMAP_HDQ_SYSCONFIG,
 		    OMAP_HDQ_SYSCONFIG_AUTOIDLE);
 	if (0 == hdq_data->hdq_usecount) {
 		dev_dbg(hdq_data->dev, "attempt to decrement use count"
 			" when it is zero");
 		ret = -EINVAL;
 	} else {
 		hdq_data->hdq_usecount--;
 		module_put(THIS_MODULE);
 		if (0 == hdq_data->hdq_usecount)
 			pm_runtime_put_sync(hdq_data->dev);
 	}
 	mutex_unlock(&hdq_data->hdq_mutex);
 
 	return ret;
 }
 
 /*
  * W1 triplet callback function - used for searching ROM addresses.
  * Registered only when controller is in 1-wire mode.
  */
 static u8 omap_w1_triplet(void *_hdq, u8 bdir)
 {
 	u8 id_bit, comp_bit;
 	int err;
 	u8 ret = 0x3; /* no slaves responded */
 	struct hdq_data *hdq_data = _hdq;
 	u8 ctrl = OMAP_HDQ_CTRL_STATUS_SINGLE | OMAP_HDQ_CTRL_STATUS_GO |
 		  OMAP_HDQ_CTRL_STATUS_INTERRUPTMASK;
 	u8 mask = ctrl | OMAP_HDQ_CTRL_STATUS_DIR;
 
 	omap_hdq_get(_hdq);
 
 	err = mutex_lock_interruptible(&hdq_data->hdq_mutex);
 	if (err < 0) {
 		dev_dbg(hdq_data->dev, "Could not acquire mutex\n");
 		goto rtn;
 	}
 
 	hdq_data->hdq_irqstatus = 0;
 	/* read id_bit */
 	hdq_reg_merge(_hdq, OMAP_HDQ_CTRL_STATUS,
 		      ctrl | OMAP_HDQ_CTRL_STATUS_DIR, mask);
 	err = wait_event_timeout(hdq_wait_queue,
 				 (hdq_data->hdq_irqstatus
 				  & OMAP_HDQ_INT_STATUS_RXCOMPLETE),
 				 OMAP_HDQ_TIMEOUT);
 	if (err == 0) {
 		dev_dbg(hdq_data->dev, "RX wait elapsed\n");
 		goto out;
 	}
 	id_bit = (hdq_reg_in(_hdq, OMAP_HDQ_RX_DATA) & 0x01);
 
 	hdq_data->hdq_irqstatus = 0;
 	/* read comp_bit */
 	hdq_reg_merge(_hdq, OMAP_HDQ_CTRL_STATUS,
 		      ctrl | OMAP_HDQ_CTRL_STATUS_DIR, mask);
 	err = wait_event_timeout(hdq_wait_queue,
 				 (hdq_data->hdq_irqstatus
 				  & OMAP_HDQ_INT_STATUS_RXCOMPLETE),
 				 OMAP_HDQ_TIMEOUT);
 	if (err == 0) {
 		dev_dbg(hdq_data->dev, "RX wait elapsed\n");
 		goto out;
 	}
 	comp_bit = (hdq_reg_in(_hdq, OMAP_HDQ_RX_DATA) & 0x01);
 
 	if (id_bit && comp_bit) {
 		ret = 0x03;  /* no slaves responded */
 		goto out;
 	}
 	if (!id_bit && !comp_bit) {
 		/* Both bits are valid, take the direction given */
 		ret = bdir ? 0x04 : 0;
 	} else {
 		/* Only one bit is valid, take that direction */
 		bdir = id_bit;
 		ret = id_bit ? 0x05 : 0x02;
 	}
 
 	/* write bdir bit */
 	hdq_reg_out(_hdq, OMAP_HDQ_TX_DATA, bdir);
 	hdq_reg_merge(_hdq, OMAP_HDQ_CTRL_STATUS, ctrl, mask);
 	err = wait_event_timeout(hdq_wait_queue,
 				 (hdq_data->hdq_irqstatus
 				  & OMAP_HDQ_INT_STATUS_TXCOMPLETE),
 				 OMAP_HDQ_TIMEOUT);
 	if (err == 0) {
 		dev_dbg(hdq_data->dev, "TX wait elapsed\n");
 		goto out;
 	}
 
 	hdq_reg_merge(_hdq, OMAP_HDQ_CTRL_STATUS, 0,
 		      OMAP_HDQ_CTRL_STATUS_SINGLE);
 
 out:
 	mutex_unlock(&hdq_data->hdq_mutex);
 rtn:
 	omap_hdq_put(_hdq);
 	return ret;
 }
 
 /* reset callback */
 static u8 omap_w1_reset_bus(void *_hdq)
 {
 	omap_hdq_get(_hdq);
 	omap_hdq_break(_hdq);
 	omap_hdq_put(_hdq);
 	return 0;
 }
 
 /* Read a byte of data from the device */
 static u8 omap_w1_read_byte(void *_hdq)
 {
 	struct hdq_data *hdq_data = _hdq;
 	u8 val = 0;
 	int ret;
 
 	/* First write to initialize the transfer */
 	if (hdq_data->init_trans == 0)
 		omap_hdq_get(hdq_data);
 
 	ret = hdq_read_byte(hdq_data, &val);
 	if (ret) {
 		ret = mutex_lock_interruptible(&hdq_data->hdq_mutex);
 		if (ret < 0) {
 			dev_dbg(hdq_data->dev, "Could not acquire mutex\n");
 			return -EINTR;
 		}
 		hdq_data->init_trans = 0;
 		mutex_unlock(&hdq_data->hdq_mutex);
 		omap_hdq_put(hdq_data);
 		return -1;
 	}
 
 	hdq_disable_interrupt(hdq_data, OMAP_HDQ_CTRL_STATUS,
 			      ~OMAP_HDQ_CTRL_STATUS_INTERRUPTMASK);
 
 	/* Write followed by a read, release the module */
 	if (hdq_data->init_trans) {
 		ret = mutex_lock_interruptible(&hdq_data->hdq_mutex);
 		if (ret < 0) {
 			dev_dbg(hdq_data->dev, "Could not acquire mutex\n");
 			return -EINTR;
 		}
 		hdq_data->init_trans = 0;
 		mutex_unlock(&hdq_data->hdq_mutex);
 		omap_hdq_put(hdq_data);
 	}
 
 	return val;
 }
 
 /* Write a byte of data to the device */
 static void omap_w1_write_byte(void *_hdq, u8 byte)
 {
 	struct hdq_data *hdq_data = _hdq;
 	int ret;
 	u8 status;
 
 	/* First write to initialize the transfer */
 	if (hdq_data->init_trans == 0)
 		omap_hdq_get(hdq_data);
 
 	/*
 	 * We need to reset the slave before
 	 * issuing the SKIP ROM command, else
 	 * the slave will not work.
 	 */
 	if (byte == W1_SKIP_ROM)
 		omap_hdq_break(hdq_data);
 
 	ret = mutex_lock_interruptible(&hdq_data->hdq_mutex);
 	if (ret < 0) {
 		dev_dbg(hdq_data->dev, "Could not acquire mutex\n");
 		return;
 	}
 	hdq_data->init_trans++;
 	mutex_unlock(&hdq_data->hdq_mutex);
 
 	ret = hdq_write_byte(hdq_data, byte, &status);
 	if (ret < 0) {
 		dev_dbg(hdq_data->dev, "TX failure:Ctrl status %x\n", status);
 		return;
 	}
 
 	/* Second write, data transferred. Release the module */
 	if (hdq_data->init_trans > 1) {
 		omap_hdq_put(hdq_data);
 		ret = mutex_lock_interruptible(&hdq_data->hdq_mutex);
 		if (ret < 0) {
 			dev_dbg(hdq_data->dev, "Could not acquire mutex\n");
 			return;
 		}
 		hdq_data->init_trans = 0;
 		mutex_unlock(&hdq_data->hdq_mutex);
 	}
 }
 
 static int omap_hdq_probe(struct platform_device *pdev)
 {
 	struct device *dev = &pdev->dev;
 	struct hdq_data *hdq_data;
 	struct resource *res;
 	int ret, irq;
 	u8 rev;
 	const char *mode;
 
 	hdq_data = devm_kzalloc(dev, sizeof(*hdq_data), GFP_KERNEL);
 	if (!hdq_data) {
 		dev_dbg(&pdev->dev, "unable to allocate memory\n");
 		return -ENOMEM;
 	}
 
 	hdq_data->dev = dev;
 	platform_set_drvdata(pdev, hdq_data);
 
 	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
 	hdq_data->hdq_base = devm_ioremap_resource(dev, res);
 	if (IS_ERR(hdq_data->hdq_base))
 		return PTR_ERR(hdq_data->hdq_base);
 
 	hdq_data->hdq_usecount = 0;
 	hdq_data->rrw = 0;
 	mutex_init(&hdq_data->hdq_mutex);
 
 	pm_runtime_enable(&pdev->dev);
 	ret = pm_runtime_get_sync(&pdev->dev);
 	if (ret < 0) {
 		dev_dbg(&pdev->dev, "pm_runtime_get_sync failed\n");
 		goto err_w1;
 	}
 
 	ret = _omap_hdq_reset(hdq_data);
 	if (ret) {
 		dev_dbg(&pdev->dev, "reset failed\n");
-		return -EINVAL;
+		goto err_irq;
 	}
 
 	rev = hdq_reg_in(hdq_data, OMAP_HDQ_REVISION);
 	dev_info(&pdev->dev, "OMAP HDQ Hardware Rev %c.%c. Driver in %s mode\n",
 		(rev >> 4) + '0', (rev & 0x0f) + '0', "Interrupt");
 
 	spin_lock_init(&hdq_data->hdq_spinlock);
 
 	irq = platform_get_irq(pdev, 0);
 	if (irq	< 0) {
 		ret = -ENXIO;
 		goto err_irq;
 	}
 
 	ret = devm_request_irq(dev, irq, hdq_isr, 0, "omap_hdq", hdq_data);
 	if (ret < 0) {
 		dev_dbg(&pdev->dev, "could not request irq\n");
 		goto err_irq;
 	}
 
 	omap_hdq_break(hdq_data);
 
 	pm_runtime_put_sync(&pdev->dev);
 
 	ret = of_property_read_string(pdev->dev.of_node, "ti,mode", &mode);
 	if (ret < 0 || !strcmp(mode, "hdq")) {
 		hdq_data->mode = 0;
 		omap_w1_master.search = omap_w1_search_bus;
 	} else {
 		hdq_data->mode = 1;
 		omap_w1_master.triplet = omap_w1_triplet;
 	}
 
 	omap_w1_master.data = hdq_data;
 
 	ret = w1_add_master_device(&omap_w1_master);
 	if (ret) {
 		dev_dbg(&pdev->dev, "Failure in registering w1 master\n");
 		goto err_w1;
 	}
 
 	return 0;
 
 err_irq:
 	pm_runtime_put_sync(&pdev->dev);
 err_w1:
 	pm_runtime_disable(&pdev->dev);
 
 	return ret;
 }
 
 static int omap_hdq_remove(struct platform_device *pdev)
 {
 	struct hdq_data *hdq_data = platform_get_drvdata(pdev);
 
 	mutex_lock(&hdq_data->hdq_mutex);
 
 	if (hdq_data->hdq_usecount) {
 		dev_dbg(&pdev->dev, "removed when use count is not zero\n");
 		mutex_unlock(&hdq_data->hdq_mutex);
 		return -EBUSY;
 	}
 
 	mutex_unlock(&hdq_data->hdq_mutex);
 
 	/* remove module dependency */
 	pm_runtime_disable(&pdev->dev);
 
 	return 0;
 }
 
 module_platform_driver(omap_hdq_driver);
 
 module_param(w1_id, int, S_IRUSR);
 MODULE_PARM_DESC(w1_id, "1-wire id for the slave detection in HDQ mode");
 
 MODULE_AUTHOR("Texas Instruments");
 MODULE_DESCRIPTION("HDQ-1W driver Library");
 MODULE_LICENSE("GPL");
diff --git a/drivers/w1/slaves/Kconfig b/drivers/w1/slaves/Kconfig
index cfe74d09932e..0ef9f2663dbd 100644
--- a/drivers/w1/slaves/Kconfig
+++ b/drivers/w1/slaves/Kconfig
@@ -1,135 +1,143 @@
 #
 # 1-wire slaves configuration
 #
 
 menu "1-wire Slaves"
 
 config W1_SLAVE_THERM
 	tristate "Thermal family implementation"
 	help
 	  Say Y here if you want to connect 1-wire thermal sensors to your
 	  wire.
 
 config W1_SLAVE_SMEM
 	tristate "Simple 64bit memory family implementation"
 	help
 	  Say Y here if you want to connect 1-wire
 	  simple 64bit memory rom(ds2401/ds2411/ds1990*) to your wire.
 
+config W1_SLAVE_DS2405
+	tristate "DS2405 Addressable Switch"
+	help
+	  Say Y or M here if you want to use a DS2405 1-wire
+	  single-channel addressable switch.
+	  This device can also work as a single-channel
+	  binary remote sensor.
+
 config W1_SLAVE_DS2408
 	tristate "8-Channel Addressable Switch (IO Expander) 0x29 family support (DS2408)"
 	help
 	  Say Y here if you want to use a 1-wire
 	  DS2408 8-Channel Addressable Switch device support
 
 config W1_SLAVE_DS2408_READBACK
 	bool "Read-back values written to DS2408's output register"
 	depends on W1_SLAVE_DS2408
 	default y
 	help
 	  Enabling this will cause the driver to read back the values written
 	  to the chip's output register in order to detect errors.
 
 	  This is slower but useful when debugging chips and/or busses.
 
 config W1_SLAVE_DS2413
 	tristate "Dual Channel Addressable Switch 0x3a family support (DS2413)"
 	help
 	  Say Y here if you want to use a 1-wire
 	  DS2413 Dual Channel Addressable Switch device support
 
 config W1_SLAVE_DS2406
 	tristate "Dual Channel Addressable Switch 0x12 family support (DS2406)"
 	select CRC16
 	help
 	  Say Y or M here if you want to use a 1-wire
 	  DS2406 Dual Channel Addressable Switch.  EPROM read/write
 	  support for these devices is not implemented.
 
 config W1_SLAVE_DS2423
 	tristate "Counter 1-wire device (DS2423)"
 	select CRC16
 	help
 	  If you enable this you can read the counter values available
 	  in the DS2423 chipset from the w1_slave file under the
 	  sys file system.
 
 	  Say Y here if you want to use a 1-wire
 	  counter family device (DS2423).
 
 config W1_SLAVE_DS2431
 	tristate "1kb EEPROM family support (DS2431)"
 	help
 	  Say Y here if you want to use a 1-wire
 	  1kb EEPROM family device (DS2431)
 
 config W1_SLAVE_DS2433
 	tristate "4kb EEPROM family support (DS2433)"
 	help
 	  Say Y here if you want to use a 1-wire
 	  4kb EEPROM family device (DS2433).
 
 config W1_SLAVE_DS2433_CRC
 	bool "Protect DS2433 data with a CRC16"
 	depends on W1_SLAVE_DS2433
 	select CRC16
 	help
 	  Say Y here to protect DS2433 data with a CRC16.
 	  Each block has 30 bytes of data and a two byte CRC16.
 	  Full block writes are only allowed if the CRC is valid.
 
 config W1_SLAVE_DS2760
 	tristate "Dallas 2760 battery monitor chip (HP iPAQ & others)"
 	help
 	  If you enable this you will have the DS2760 battery monitor
 	  chip support.
 
 	  The battery monitor chip is used in many batteries/devices
 	  as the one who is responsible for charging/discharging/monitoring
 	  Li+ batteries.
 
 	  If you are unsure, say N.
 
 config W1_SLAVE_DS2780
 	tristate "Dallas 2780 battery monitor chip"
 	help
 	  If you enable this you will have the DS2780 battery monitor
 	  chip support.
 
 	  The battery monitor chip is used in many batteries/devices
 	  as the one who is responsible for charging/discharging/monitoring
 	  Li+ batteries.
 
 	  If you are unsure, say N.
 
 config W1_SLAVE_DS2781
 	tristate "Dallas 2781 battery monitor chip"
 	help
 	  If you enable this you will have the DS2781 battery monitor
 	  chip support.
 
 	  The battery monitor chip is used in many batteries/devices
 	  as the one who is responsible for charging/discharging/monitoring
 	  Li+ batteries.
 
 	  If you are unsure, say N.
 
 config W1_SLAVE_DS28E04
 	tristate "4096-Bit Addressable 1-Wire EEPROM with PIO (DS28E04-100)"
 	select CRC16
 	help
 	  If you enable this you will have the DS28E04-100
 	  chip support.
 
 	  Say Y here if you want to use a 1-wire
 	  4kb EEPROM with PIO family device (DS28E04).
 
 	  If you are unsure, say N.
 
 config W1_SLAVE_BQ27000
 	tristate "BQ27000 slave support"
 	help
 	  Say Y here if you want to use a hdq
 	  bq27000 slave support.
 
 endmenu
diff --git a/drivers/w1/slaves/Makefile b/drivers/w1/slaves/Makefile
index 1e9989afe7bf..b4a358955ef9 100644
--- a/drivers/w1/slaves/Makefile
+++ b/drivers/w1/slaves/Makefile
@@ -1,17 +1,18 @@
 #
 # Makefile for the Dallas's 1-wire slaves.
 #
 
 obj-$(CONFIG_W1_SLAVE_THERM)	+= w1_therm.o
 obj-$(CONFIG_W1_SLAVE_SMEM)	+= w1_smem.o
+obj-$(CONFIG_W1_SLAVE_DS2405)	+= w1_ds2405.o
 obj-$(CONFIG_W1_SLAVE_DS2408)	+= w1_ds2408.o
 obj-$(CONFIG_W1_SLAVE_DS2413)	+= w1_ds2413.o
 obj-$(CONFIG_W1_SLAVE_DS2406)	+= w1_ds2406.o
 obj-$(CONFIG_W1_SLAVE_DS2423)	+= w1_ds2423.o
 obj-$(CONFIG_W1_SLAVE_DS2431)	+= w1_ds2431.o
 obj-$(CONFIG_W1_SLAVE_DS2433)	+= w1_ds2433.o
 obj-$(CONFIG_W1_SLAVE_DS2760)	+= w1_ds2760.o
 obj-$(CONFIG_W1_SLAVE_DS2780)	+= w1_ds2780.o
 obj-$(CONFIG_W1_SLAVE_DS2781)	+= w1_ds2781.o
 obj-$(CONFIG_W1_SLAVE_BQ27000)	+= w1_bq27000.o
 obj-$(CONFIG_W1_SLAVE_DS28E04)	+= w1_ds28e04.o
diff --git a/drivers/w1/slaves/w1_ds2405.c b/drivers/w1/slaves/w1_ds2405.c
new file mode 100644
index 000000000000..d5d54876cb64
--- /dev/null
+++ b/drivers/w1/slaves/w1_ds2405.c
@@ -0,0 +1,227 @@
+/*
+ *	w1_ds2405.c
+ *
+ * Copyright (c) 2017 Maciej S. Szmigiero <mail@maciej.szmigiero.name>
+ * Based on w1_therm.c copyright (c) 2004 Evgeniy Polyakov <zbr@ioremap.net>
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the therms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/device.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/moduleparam.h>
+#include <linux/mutex.h>
+#include <linux/string.h>
+#include <linux/types.h>
+
+#include "../w1.h"
+#include "../w1_family.h"
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Maciej S. Szmigiero <mail@maciej.szmigiero.name>");
+MODULE_DESCRIPTION("Driver for 1-wire Dallas DS2405 PIO.");
+MODULE_ALIAS("w1-family-" __stringify(W1_FAMILY_DS2405));
+
+static int w1_ds2405_select(struct w1_slave *sl, bool only_active)
+{
+	struct w1_master *dev = sl->master;
+
+	u64 dev_addr = le64_to_cpu(*(u64 *)&sl->reg_num);
+	unsigned int bit_ctr;
+
+	if (w1_reset_bus(dev) != 0)
+		return 0;
+
+	/*
+	 * We cannot use a normal Match ROM command
+	 * since doing so would toggle PIO state
+	 */
+	w1_write_8(dev, only_active ? W1_ALARM_SEARCH : W1_SEARCH);
+
+	for (bit_ctr = 0; bit_ctr < 64; bit_ctr++) {
+		int bit2send = !!(dev_addr & BIT(bit_ctr));
+		u8 ret;
+
+		ret = w1_triplet(dev, bit2send);
+
+		if ((ret & (BIT(0) | BIT(1))) ==
+		    (BIT(0) | BIT(1))) /* no devices found */
+			return 0;
+
+		if (!!(ret & BIT(2)) != bit2send)
+			/* wrong direction taken - no such device */
+			return 0;
+	}
+
+	return 1;
+}
+
+static int w1_ds2405_read_pio(struct w1_slave *sl)
+{
+	if (w1_ds2405_select(sl, true))
+		return 0; /* "active" means PIO is low */
+
+	if (w1_ds2405_select(sl, false))
+		return 1;
+
+	return -ENODEV;
+}
+
+static ssize_t state_show(struct device *device,
+			  struct device_attribute *attr, char *buf)
+{
+	struct w1_slave *sl = dev_to_w1_slave(device);
+	struct w1_master *dev = sl->master;
+
+	int ret;
+	ssize_t f_retval;
+	u8 state;
+
+	ret = mutex_lock_interruptible(&dev->bus_mutex);
+	if (ret)
+		return ret;
+
+	if (!w1_ds2405_select(sl, false)) {
+		f_retval = -ENODEV;
+		goto out_unlock;
+	}
+
+	state = w1_read_8(dev);
+	if (state != 0 &&
+	    state != 0xff) {
+		dev_err(device, "non-consistent state %x\n", state);
+		f_retval = -EIO;
+		goto out_unlock;
+	}
+
+	*buf = state ? '1' : '0';
+	f_retval = 1;
+
+out_unlock:
+	w1_reset_bus(dev);
+	mutex_unlock(&dev->bus_mutex);
+
+	return f_retval;
+}
+
+static ssize_t output_show(struct device *device,
+			   struct device_attribute *attr, char *buf)
+{
+	struct w1_slave *sl = dev_to_w1_slave(device);
+	struct w1_master *dev = sl->master;
+
+	int ret;
+	ssize_t f_retval;
+
+	ret = mutex_lock_interruptible(&dev->bus_mutex);
+	if (ret)
+		return ret;
+
+	ret = w1_ds2405_read_pio(sl);
+	if (ret < 0) {
+		f_retval = ret;
+		goto out_unlock;
+	}
+
+	*buf = ret ? '1' : '0';
+	f_retval = 1;
+
+out_unlock:
+	w1_reset_bus(dev);
+	mutex_unlock(&dev->bus_mutex);
+
+	return f_retval;
+}
+
+static ssize_t output_store(struct device *device,
+			    struct device_attribute *attr,
+			    const char *buf, size_t count)
+{
+	struct w1_slave *sl = dev_to_w1_slave(device);
+	struct w1_master *dev = sl->master;
+
+	int ret, current_pio;
+	unsigned int val;
+	ssize_t f_retval;
+
+	if (count < 1)
+		return -EINVAL;
+
+	if (sscanf(buf, " %u%n", &val, &ret) < 1)
+		return -EINVAL;
+
+	if (val != 0 && val != 1)
+		return -EINVAL;
+
+	f_retval = ret;
+
+	ret = mutex_lock_interruptible(&dev->bus_mutex);
+	if (ret)
+		return ret;
+
+	current_pio = w1_ds2405_read_pio(sl);
+	if (current_pio < 0) {
+		f_retval = current_pio;
+		goto out_unlock;
+	}
+
+	if (current_pio == val)
+		goto out_unlock;
+
+	if (w1_reset_bus(dev) != 0) {
+		f_retval = -ENODEV;
+		goto out_unlock;
+	}
+
+	/*
+	 * can't use w1_reset_select_slave() here since it uses Skip ROM if
+	 * there is only one device on bus
+	 */
+	do {
+		u64 dev_addr = le64_to_cpu(*(u64 *)&sl->reg_num);
+		u8 cmd[9];
+
+		cmd[0] = W1_MATCH_ROM;
+		memcpy(&cmd[1], &dev_addr, sizeof(dev_addr));
+
+		w1_write_block(dev, cmd, sizeof(cmd));
+	} while (0);
+
+out_unlock:
+	w1_reset_bus(dev);
+	mutex_unlock(&dev->bus_mutex);
+
+	return f_retval;
+}
+
+static DEVICE_ATTR_RO(state);
+static DEVICE_ATTR_RW(output);
+
+static struct attribute *w1_ds2405_attrs[] = {
+	&dev_attr_state.attr,
+	&dev_attr_output.attr,
+	NULL
+};
+
+ATTRIBUTE_GROUPS(w1_ds2405);
+
+static struct w1_family_ops w1_ds2405_fops = {
+	.groups = w1_ds2405_groups
+};
+
+static struct w1_family w1_family_ds2405 = {
+	.fid = W1_FAMILY_DS2405,
+	.fops = &w1_ds2405_fops
+};
+
+module_w1_family(w1_family_ds2405);
diff --git a/drivers/w1/w1.c b/drivers/w1/w1.c
index e213c678bbfe..90a3d9338fd2 100644
--- a/drivers/w1/w1.c
+++ b/drivers/w1/w1.c
@@ -1,1237 +1,1231 @@
 /*
- *	w1.c
- *
  * Copyright (c) 2004 Evgeniy Polyakov <zbr@ioremap.net>
  *
- *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
  * the Free Software Foundation; either version 2 of the License, or
  * (at your option) any later version.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
  */
 
 #include <linux/delay.h>
 #include <linux/kernel.h>
 #include <linux/module.h>
 #include <linux/moduleparam.h>
 #include <linux/list.h>
 #include <linux/interrupt.h>
 #include <linux/spinlock.h>
 #include <linux/timer.h>
 #include <linux/device.h>
 #include <linux/slab.h>
 #include <linux/sched.h>
 #include <linux/kthread.h>
 #include <linux/freezer.h>
 
 #include <linux/atomic.h>
 
 #include "w1.h"
 #include "w1_log.h"
 #include "w1_int.h"
 #include "w1_family.h"
 #include "w1_netlink.h"
 
 MODULE_LICENSE("GPL");
 MODULE_AUTHOR("Evgeniy Polyakov <zbr@ioremap.net>");
 MODULE_DESCRIPTION("Driver for 1-wire Dallas network protocol.");
 
 static int w1_timeout = 10;
 static int w1_timeout_us = 0;
 int w1_max_slave_count = 64;
 int w1_max_slave_ttl = 10;
 
 module_param_named(timeout, w1_timeout, int, 0);
 MODULE_PARM_DESC(timeout, "time in seconds between automatic slave searches");
 module_param_named(timeout_us, w1_timeout_us, int, 0);
 MODULE_PARM_DESC(timeout_us,
 		 "time in microseconds between automatic slave searches");
 /* A search stops when w1_max_slave_count devices have been found in that
  * search.  The next search will start over and detect the same set of devices
  * on a static 1-wire bus.  Memory is not allocated based on this number, just
  * on the number of devices known to the kernel.  Having a high number does not
  * consume additional resources.  As a special case, if there is only one
  * device on the network and w1_max_slave_count is set to 1, the device id can
  * be read directly skipping the normal slower search process.
  */
 module_param_named(max_slave_count, w1_max_slave_count, int, 0);
 MODULE_PARM_DESC(max_slave_count,
 	"maximum number of slaves detected in a search");
 module_param_named(slave_ttl, w1_max_slave_ttl, int, 0);
 MODULE_PARM_DESC(slave_ttl,
 	"Number of searches not seeing a slave before it will be removed");
 
 DEFINE_MUTEX(w1_mlock);
 LIST_HEAD(w1_masters);
 
 static int w1_master_match(struct device *dev, struct device_driver *drv)
 {
 	return 1;
 }
 
 static int w1_master_probe(struct device *dev)
 {
 	return -ENODEV;
 }
 
 static void w1_master_release(struct device *dev)
 {
 	struct w1_master *md = dev_to_w1_master(dev);
 
 	dev_dbg(dev, "%s: Releasing %s.\n", __func__, md->name);
 	memset(md, 0, sizeof(struct w1_master) + sizeof(struct w1_bus_master));
 	kfree(md);
 }
 
 static void w1_slave_release(struct device *dev)
 {
 	struct w1_slave *sl = dev_to_w1_slave(dev);
 
 	dev_dbg(dev, "%s: Releasing %s [%p]\n", __func__, sl->name, sl);
 
 	w1_family_put(sl->family);
 	sl->master->slave_count--;
 }
 
 static ssize_t name_show(struct device *dev, struct device_attribute *attr, char *buf)
 {
 	struct w1_slave *sl = dev_to_w1_slave(dev);
 
 	return sprintf(buf, "%s\n", sl->name);
 }
 static DEVICE_ATTR_RO(name);
 
 static ssize_t id_show(struct device *dev,
 	struct device_attribute *attr, char *buf)
 {
 	struct w1_slave *sl = dev_to_w1_slave(dev);
 	ssize_t count = sizeof(sl->reg_num);
 
 	memcpy(buf, (u8 *)&sl->reg_num, count);
 	return count;
 }
 static DEVICE_ATTR_RO(id);
 
 static struct attribute *w1_slave_attrs[] = {
 	&dev_attr_name.attr,
 	&dev_attr_id.attr,
 	NULL,
 };
 ATTRIBUTE_GROUPS(w1_slave);
 
 /* Default family */
 
 static ssize_t rw_write(struct file *filp, struct kobject *kobj,
 			struct bin_attribute *bin_attr, char *buf, loff_t off,
 			size_t count)
 {
 	struct w1_slave *sl = kobj_to_w1_slave(kobj);
 
 	mutex_lock(&sl->master->mutex);
 	if (w1_reset_select_slave(sl)) {
 		count = 0;
 		goto out_up;
 	}
 
 	w1_write_block(sl->master, buf, count);
 
 out_up:
 	mutex_unlock(&sl->master->mutex);
 	return count;
 }
 
 static ssize_t rw_read(struct file *filp, struct kobject *kobj,
 		       struct bin_attribute *bin_attr, char *buf, loff_t off,
 		       size_t count)
 {
 	struct w1_slave *sl = kobj_to_w1_slave(kobj);
 
 	mutex_lock(&sl->master->mutex);
 	w1_read_block(sl->master, buf, count);
 	mutex_unlock(&sl->master->mutex);
 	return count;
 }
 
 static BIN_ATTR_RW(rw, PAGE_SIZE);
 
 static struct bin_attribute *w1_slave_bin_attrs[] = {
 	&bin_attr_rw,
 	NULL,
 };
 
 static const struct attribute_group w1_slave_default_group = {
 	.bin_attrs = w1_slave_bin_attrs,
 };
 
 static const struct attribute_group *w1_slave_default_groups[] = {
 	&w1_slave_default_group,
 	NULL,
 };
 
 static struct w1_family_ops w1_default_fops = {
 	.groups		= w1_slave_default_groups,
 };
 
 static struct w1_family w1_default_family = {
 	.fops = &w1_default_fops,
 };
 
 static int w1_uevent(struct device *dev, struct kobj_uevent_env *env);
 
 static struct bus_type w1_bus_type = {
 	.name = "w1",
 	.match = w1_master_match,
 	.uevent = w1_uevent,
 };
 
 struct device_driver w1_master_driver = {
 	.name = "w1_master_driver",
 	.bus = &w1_bus_type,
 	.probe = w1_master_probe,
 };
 
 struct device w1_master_device = {
 	.parent = NULL,
 	.bus = &w1_bus_type,
 	.init_name = "w1 bus master",
 	.driver = &w1_master_driver,
 	.release = &w1_master_release
 };
 
 static struct device_driver w1_slave_driver = {
 	.name = "w1_slave_driver",
 	.bus = &w1_bus_type,
 };
 
 #if 0
 struct device w1_slave_device = {
 	.parent = NULL,
 	.bus = &w1_bus_type,
 	.init_name = "w1 bus slave",
 	.driver = &w1_slave_driver,
 	.release = &w1_slave_release
 };
 #endif  /*  0  */
 
 static ssize_t w1_master_attribute_show_name(struct device *dev, struct device_attribute *attr, char *buf)
 {
 	struct w1_master *md = dev_to_w1_master(dev);
 	ssize_t count;
 
 	mutex_lock(&md->mutex);
 	count = sprintf(buf, "%s\n", md->name);
 	mutex_unlock(&md->mutex);
 
 	return count;
 }
 
 static ssize_t w1_master_attribute_store_search(struct device * dev,
 						struct device_attribute *attr,
 						const char * buf, size_t count)
 {
 	long tmp;
 	struct w1_master *md = dev_to_w1_master(dev);
 	int ret;
 
 	ret = kstrtol(buf, 0, &tmp);
 	if (ret)
 		return ret;
 
 	mutex_lock(&md->mutex);
 	md->search_count = tmp;
 	mutex_unlock(&md->mutex);
 	/* Only wake if it is going to be searching. */
 	if (tmp)
 		wake_up_process(md->thread);
 
 	return count;
 }
 
 static ssize_t w1_master_attribute_show_search(struct device *dev,
 					       struct device_attribute *attr,
 					       char *buf)
 {
 	struct w1_master *md = dev_to_w1_master(dev);
 	ssize_t count;
 
 	mutex_lock(&md->mutex);
 	count = sprintf(buf, "%d\n", md->search_count);
 	mutex_unlock(&md->mutex);
 
 	return count;
 }
 
 static ssize_t w1_master_attribute_store_pullup(struct device *dev,
 						struct device_attribute *attr,
 						const char *buf, size_t count)
 {
 	long tmp;
 	struct w1_master *md = dev_to_w1_master(dev);
 	int ret;
 
 	ret = kstrtol(buf, 0, &tmp);
 	if (ret)
 		return ret;
 
 	mutex_lock(&md->mutex);
 	md->enable_pullup = tmp;
 	mutex_unlock(&md->mutex);
 
 	return count;
 }
 
 static ssize_t w1_master_attribute_show_pullup(struct device *dev,
 					       struct device_attribute *attr,
 					       char *buf)
 {
 	struct w1_master *md = dev_to_w1_master(dev);
 	ssize_t count;
 
 	mutex_lock(&md->mutex);
 	count = sprintf(buf, "%d\n", md->enable_pullup);
 	mutex_unlock(&md->mutex);
 
 	return count;
 }
 
 static ssize_t w1_master_attribute_show_pointer(struct device *dev, struct device_attribute *attr, char *buf)
 {
 	struct w1_master *md = dev_to_w1_master(dev);
 	ssize_t count;
 
 	mutex_lock(&md->mutex);
 	count = sprintf(buf, "0x%p\n", md->bus_master);
 	mutex_unlock(&md->mutex);
 	return count;
 }
 
 static ssize_t w1_master_attribute_show_timeout(struct device *dev, struct device_attribute *attr, char *buf)
 {
 	ssize_t count;
 	count = sprintf(buf, "%d\n", w1_timeout);
 	return count;
 }
 
 static ssize_t w1_master_attribute_show_timeout_us(struct device *dev,
 	struct device_attribute *attr, char *buf)
 {
 	ssize_t count;
 	count = sprintf(buf, "%d\n", w1_timeout_us);
 	return count;
 }
 
 static ssize_t w1_master_attribute_store_max_slave_count(struct device *dev,
 	struct device_attribute *attr, const char *buf, size_t count)
 {
 	int tmp;
 	struct w1_master *md = dev_to_w1_master(dev);
 
 	if (kstrtoint(buf, 0, &tmp) || tmp < 1)
 		return -EINVAL;
 
 	mutex_lock(&md->mutex);
 	md->max_slave_count = tmp;
 	/* allow each time the max_slave_count is updated */
 	clear_bit(W1_WARN_MAX_COUNT, &md->flags);
 	mutex_unlock(&md->mutex);
 
 	return count;
 }
 
 static ssize_t w1_master_attribute_show_max_slave_count(struct device *dev, struct device_attribute *attr, char *buf)
 {
 	struct w1_master *md = dev_to_w1_master(dev);
 	ssize_t count;
 
 	mutex_lock(&md->mutex);
 	count = sprintf(buf, "%d\n", md->max_slave_count);
 	mutex_unlock(&md->mutex);
 	return count;
 }
 
 static ssize_t w1_master_attribute_show_attempts(struct device *dev, struct device_attribute *attr, char *buf)
 {
 	struct w1_master *md = dev_to_w1_master(dev);
 	ssize_t count;
 
 	mutex_lock(&md->mutex);
 	count = sprintf(buf, "%lu\n", md->attempts);
 	mutex_unlock(&md->mutex);
 	return count;
 }
 
 static ssize_t w1_master_attribute_show_slave_count(struct device *dev, struct device_attribute *attr, char *buf)
 {
 	struct w1_master *md = dev_to_w1_master(dev);
 	ssize_t count;
 
 	mutex_lock(&md->mutex);
 	count = sprintf(buf, "%d\n", md->slave_count);
 	mutex_unlock(&md->mutex);
 	return count;
 }
 
 static ssize_t w1_master_attribute_show_slaves(struct device *dev,
 	struct device_attribute *attr, char *buf)
 {
 	struct w1_master *md = dev_to_w1_master(dev);
 	int c = PAGE_SIZE;
 	struct list_head *ent, *n;
 	struct w1_slave *sl = NULL;
 
 	mutex_lock(&md->list_mutex);
 
 	list_for_each_safe(ent, n, &md->slist) {
 		sl = list_entry(ent, struct w1_slave, w1_slave_entry);
 
 		c -= snprintf(buf + PAGE_SIZE - c, c, "%s\n", sl->name);
 	}
 	if (!sl)
 		c -= snprintf(buf + PAGE_SIZE - c, c, "not found.\n");
 
 	mutex_unlock(&md->list_mutex);
 
 	return PAGE_SIZE - c;
 }
 
 static ssize_t w1_master_attribute_show_add(struct device *dev,
 	struct device_attribute *attr, char *buf)
 {
 	int c = PAGE_SIZE;
 	c -= snprintf(buf+PAGE_SIZE - c, c,
 		"write device id xx-xxxxxxxxxxxx to add slave\n");
 	return PAGE_SIZE - c;
 }
 
 static int w1_atoreg_num(struct device *dev, const char *buf, size_t count,
 	struct w1_reg_num *rn)
 {
 	unsigned int family;
 	unsigned long long id;
 	int i;
 	u64 rn64_le;
 
 	/* The CRC value isn't read from the user because the sysfs directory
 	 * doesn't include it and most messages from the bus search don't
 	 * print it either.  It would be unreasonable for the user to then
 	 * provide it.
 	 */
 	const char *error_msg = "bad slave string format, expecting "
 		"ff-dddddddddddd\n";
 
 	if (buf[2] != '-') {
 		dev_err(dev, "%s", error_msg);
 		return -EINVAL;
 	}
 	i = sscanf(buf, "%02x-%012llx", &family, &id);
 	if (i != 2) {
 		dev_err(dev, "%s", error_msg);
 		return -EINVAL;
 	}
 	rn->family = family;
 	rn->id = id;
 
 	rn64_le = cpu_to_le64(*(u64 *)rn);
 	rn->crc = w1_calc_crc8((u8 *)&rn64_le, 7);
 
 #if 0
 	dev_info(dev, "With CRC device is %02x.%012llx.%02x.\n",
 		  rn->family, (unsigned long long)rn->id, rn->crc);
 #endif
 
 	return 0;
 }
 
 /* Searches the slaves in the w1_master and returns a pointer or NULL.
  * Note: must not hold list_mutex
  */
 struct w1_slave *w1_slave_search_device(struct w1_master *dev,
 	struct w1_reg_num *rn)
 {
 	struct w1_slave *sl;
 	mutex_lock(&dev->list_mutex);
 	list_for_each_entry(sl, &dev->slist, w1_slave_entry) {
 		if (sl->reg_num.family == rn->family &&
 				sl->reg_num.id == rn->id &&
 				sl->reg_num.crc == rn->crc) {
 			mutex_unlock(&dev->list_mutex);
 			return sl;
 		}
 	}
 	mutex_unlock(&dev->list_mutex);
 	return NULL;
 }
 
 static ssize_t w1_master_attribute_store_add(struct device *dev,
 						struct device_attribute *attr,
 						const char *buf, size_t count)
 {
 	struct w1_master *md = dev_to_w1_master(dev);
 	struct w1_reg_num rn;
 	struct w1_slave *sl;
 	ssize_t result = count;
 
 	if (w1_atoreg_num(dev, buf, count, &rn))
 		return -EINVAL;
 
 	mutex_lock(&md->mutex);
 	sl = w1_slave_search_device(md, &rn);
 	/* It would be nice to do a targeted search one the one-wire bus
 	 * for the new device to see if it is out there or not.  But the
 	 * current search doesn't support that.
 	 */
 	if (sl) {
 		dev_info(dev, "Device %s already exists\n", sl->name);
 		result = -EINVAL;
 	} else {
 		w1_attach_slave_device(md, &rn);
 	}
 	mutex_unlock(&md->mutex);
 
 	return result;
 }
 
 static ssize_t w1_master_attribute_show_remove(struct device *dev,
 	struct device_attribute *attr, char *buf)
 {
 	int c = PAGE_SIZE;
 	c -= snprintf(buf+PAGE_SIZE - c, c,
 		"write device id xx-xxxxxxxxxxxx to remove slave\n");
 	return PAGE_SIZE - c;
 }
 
 static ssize_t w1_master_attribute_store_remove(struct device *dev,
 						struct device_attribute *attr,
 						const char *buf, size_t count)
 {
 	struct w1_master *md = dev_to_w1_master(dev);
 	struct w1_reg_num rn;
 	struct w1_slave *sl;
 	ssize_t result = count;
 
 	if (w1_atoreg_num(dev, buf, count, &rn))
 		return -EINVAL;
 
 	mutex_lock(&md->mutex);
 	sl = w1_slave_search_device(md, &rn);
 	if (sl) {
 		result = w1_slave_detach(sl);
 		/* refcnt 0 means it was detached in the call */
 		if (result == 0)
 			result = count;
 	} else {
 		dev_info(dev, "Device %02x-%012llx doesn't exists\n", rn.family,
 			(unsigned long long)rn.id);
 		result = -EINVAL;
 	}
 	mutex_unlock(&md->mutex);
 
 	return result;
 }
 
 #define W1_MASTER_ATTR_RO(_name, _mode)				\
 	struct device_attribute w1_master_attribute_##_name =	\
 		__ATTR(w1_master_##_name, _mode,		\
 		       w1_master_attribute_show_##_name, NULL)
 
 #define W1_MASTER_ATTR_RW(_name, _mode)				\
 	struct device_attribute w1_master_attribute_##_name =	\
 		__ATTR(w1_master_##_name, _mode,		\
 		       w1_master_attribute_show_##_name,	\
 		       w1_master_attribute_store_##_name)
 
 static W1_MASTER_ATTR_RO(name, S_IRUGO);
 static W1_MASTER_ATTR_RO(slaves, S_IRUGO);
 static W1_MASTER_ATTR_RO(slave_count, S_IRUGO);
 static W1_MASTER_ATTR_RW(max_slave_count, S_IRUGO | S_IWUSR | S_IWGRP);
 static W1_MASTER_ATTR_RO(attempts, S_IRUGO);
 static W1_MASTER_ATTR_RO(timeout, S_IRUGO);
 static W1_MASTER_ATTR_RO(timeout_us, S_IRUGO);
 static W1_MASTER_ATTR_RO(pointer, S_IRUGO);
 static W1_MASTER_ATTR_RW(search, S_IRUGO | S_IWUSR | S_IWGRP);
 static W1_MASTER_ATTR_RW(pullup, S_IRUGO | S_IWUSR | S_IWGRP);
 static W1_MASTER_ATTR_RW(add, S_IRUGO | S_IWUSR | S_IWGRP);
 static W1_MASTER_ATTR_RW(remove, S_IRUGO | S_IWUSR | S_IWGRP);
 
 static struct attribute *w1_master_default_attrs[] = {
 	&w1_master_attribute_name.attr,
 	&w1_master_attribute_slaves.attr,
 	&w1_master_attribute_slave_count.attr,
 	&w1_master_attribute_max_slave_count.attr,
 	&w1_master_attribute_attempts.attr,
 	&w1_master_attribute_timeout.attr,
 	&w1_master_attribute_timeout_us.attr,
 	&w1_master_attribute_pointer.attr,
 	&w1_master_attribute_search.attr,
 	&w1_master_attribute_pullup.attr,
 	&w1_master_attribute_add.attr,
 	&w1_master_attribute_remove.attr,
 	NULL
 };
 
 static struct attribute_group w1_master_defattr_group = {
 	.attrs = w1_master_default_attrs,
 };
 
 int w1_create_master_attributes(struct w1_master *master)
 {
 	return sysfs_create_group(&master->dev.kobj, &w1_master_defattr_group);
 }
 
 void w1_destroy_master_attributes(struct w1_master *master)
 {
 	sysfs_remove_group(&master->dev.kobj, &w1_master_defattr_group);
 }
 
 static int w1_uevent(struct device *dev, struct kobj_uevent_env *env)
 {
 	struct w1_master *md = NULL;
 	struct w1_slave *sl = NULL;
 	char *event_owner, *name;
 	int err = 0;
 
 	if (dev->driver == &w1_master_driver) {
 		md = container_of(dev, struct w1_master, dev);
 		event_owner = "master";
 		name = md->name;
 	} else if (dev->driver == &w1_slave_driver) {
 		sl = container_of(dev, struct w1_slave, dev);
 		event_owner = "slave";
 		name = sl->name;
 	} else {
 		dev_dbg(dev, "Unknown event.\n");
 		return -EINVAL;
 	}
 
 	dev_dbg(dev, "Hotplug event for %s %s, bus_id=%s.\n",
 			event_owner, name, dev_name(dev));
 
 	if (dev->driver != &w1_slave_driver || !sl)
 		goto end;
 
 	err = add_uevent_var(env, "W1_FID=%02X", sl->reg_num.family);
 	if (err)
 		goto end;
 
 	err = add_uevent_var(env, "W1_SLAVE_ID=%024LX",
 			     (unsigned long long)sl->reg_num.id);
 end:
 	return err;
 }
 
 static int w1_family_notify(unsigned long action, struct w1_slave *sl)
 {
 	struct w1_family_ops *fops;
 	int err;
 
 	fops = sl->family->fops;
 
 	if (!fops)
 		return 0;
 
 	switch (action) {
 	case BUS_NOTIFY_ADD_DEVICE:
 		/* if the family driver needs to initialize something... */
 		if (fops->add_slave) {
 			err = fops->add_slave(sl);
 			if (err < 0) {
 				dev_err(&sl->dev,
 					"add_slave() call failed. err=%d\n",
 					err);
 				return err;
 			}
 		}
 		if (fops->groups) {
 			err = sysfs_create_groups(&sl->dev.kobj, fops->groups);
 			if (err) {
 				dev_err(&sl->dev,
 					"sysfs group creation failed. err=%d\n",
 					err);
 				return err;
 			}
 		}
 
 		break;
 	case BUS_NOTIFY_DEL_DEVICE:
 		if (fops->remove_slave)
 			sl->family->fops->remove_slave(sl);
 		if (fops->groups)
 			sysfs_remove_groups(&sl->dev.kobj, fops->groups);
 		break;
 	}
 	return 0;
 }
 
 static int __w1_attach_slave_device(struct w1_slave *sl)
 {
 	int err;
 
 	sl->dev.parent = &sl->master->dev;
 	sl->dev.driver = &w1_slave_driver;
 	sl->dev.bus = &w1_bus_type;
 	sl->dev.release = &w1_slave_release;
 	sl->dev.groups = w1_slave_groups;
 
 	dev_set_name(&sl->dev, "%02x-%012llx",
 		 (unsigned int) sl->reg_num.family,
 		 (unsigned long long) sl->reg_num.id);
 	snprintf(&sl->name[0], sizeof(sl->name),
 		 "%02x-%012llx",
 		 (unsigned int) sl->reg_num.family,
 		 (unsigned long long) sl->reg_num.id);
 
 	dev_dbg(&sl->dev, "%s: registering %s as %p.\n", __func__,
 		dev_name(&sl->dev), sl);
 
 	/* suppress for w1_family_notify before sending KOBJ_ADD */
 	dev_set_uevent_suppress(&sl->dev, true);
 
 	err = device_register(&sl->dev);
 	if (err < 0) {
 		dev_err(&sl->dev,
 			"Device registration [%s] failed. err=%d\n",
 			dev_name(&sl->dev), err);
 		return err;
 	}
 	w1_family_notify(BUS_NOTIFY_ADD_DEVICE, sl);
 
 	dev_set_uevent_suppress(&sl->dev, false);
 	kobject_uevent(&sl->dev.kobj, KOBJ_ADD);
 
 	mutex_lock(&sl->master->list_mutex);
 	list_add_tail(&sl->w1_slave_entry, &sl->master->slist);
 	mutex_unlock(&sl->master->list_mutex);
 
 	return 0;
 }
 
 int w1_attach_slave_device(struct w1_master *dev, struct w1_reg_num *rn)
 {
 	struct w1_slave *sl;
 	struct w1_family *f;
 	int err;
 	struct w1_netlink_msg msg;
 
 	sl = kzalloc(sizeof(struct w1_slave), GFP_KERNEL);
 	if (!sl) {
 		dev_err(&dev->dev,
 			 "%s: failed to allocate new slave device.\n",
 			 __func__);
 		return -ENOMEM;
 	}
 
 
 	sl->owner = THIS_MODULE;
 	sl->master = dev;
 	set_bit(W1_SLAVE_ACTIVE, &sl->flags);
 
 	memset(&msg, 0, sizeof(msg));
 	memcpy(&sl->reg_num, rn, sizeof(sl->reg_num));
 	atomic_set(&sl->refcnt, 1);
 	atomic_inc(&sl->master->refcnt);
 
 	/* slave modules need to be loaded in a context with unlocked mutex */
 	mutex_unlock(&dev->mutex);
 	request_module("w1-family-0x%02x", rn->family);
 	mutex_lock(&dev->mutex);
 
 	spin_lock(&w1_flock);
 	f = w1_family_registered(rn->family);
 	if (!f) {
 		f= &w1_default_family;
 		dev_info(&dev->dev, "Family %x for %02x.%012llx.%02x is not registered.\n",
 			  rn->family, rn->family,
 			  (unsigned long long)rn->id, rn->crc);
 	}
 	__w1_family_get(f);
 	spin_unlock(&w1_flock);
 
 	sl->family = f;
 
 
 	err = __w1_attach_slave_device(sl);
 	if (err < 0) {
 		dev_err(&dev->dev, "%s: Attaching %s failed.\n", __func__,
 			 sl->name);
 		w1_family_put(sl->family);
+		atomic_dec(&sl->master->refcnt);
 		kfree(sl);
 		return err;
 	}
 
 	sl->ttl = dev->slave_ttl;
 	dev->slave_count++;
 
 	memcpy(msg.id.id, rn, sizeof(msg.id));
 	msg.type = W1_SLAVE_ADD;
 	w1_netlink_send(dev, &msg);
 
 	return 0;
 }
 
 int w1_unref_slave(struct w1_slave *sl)
 {
 	struct w1_master *dev = sl->master;
 	int refcnt;
 	mutex_lock(&dev->list_mutex);
 	refcnt = atomic_sub_return(1, &sl->refcnt);
 	if (refcnt == 0) {
 		struct w1_netlink_msg msg;
 
 		dev_dbg(&sl->dev, "%s: detaching %s [%p].\n", __func__,
 			sl->name, sl);
 
 		list_del(&sl->w1_slave_entry);
 
 		memset(&msg, 0, sizeof(msg));
 		memcpy(msg.id.id, &sl->reg_num, sizeof(msg.id));
 		msg.type = W1_SLAVE_REMOVE;
 		w1_netlink_send(sl->master, &msg);
 
 		w1_family_notify(BUS_NOTIFY_DEL_DEVICE, sl);
 		device_unregister(&sl->dev);
 		#ifdef DEBUG
 		memset(sl, 0, sizeof(*sl));
 		#endif
 		kfree(sl);
 	}
 	atomic_dec(&dev->refcnt);
 	mutex_unlock(&dev->list_mutex);
 	return refcnt;
 }
 
 int w1_slave_detach(struct w1_slave *sl)
 {
 	/* Only detach a slave once as it decreases the refcnt each time. */
 	int destroy_now;
 	mutex_lock(&sl->master->list_mutex);
 	destroy_now = !test_bit(W1_SLAVE_DETACH, &sl->flags);
 	set_bit(W1_SLAVE_DETACH, &sl->flags);
 	mutex_unlock(&sl->master->list_mutex);
 
 	if (destroy_now)
 		destroy_now = !w1_unref_slave(sl);
 	return destroy_now ? 0 : -EBUSY;
 }
 
 struct w1_master *w1_search_master_id(u32 id)
 {
 	struct w1_master *dev;
 	int found = 0;
 
 	mutex_lock(&w1_mlock);
 	list_for_each_entry(dev, &w1_masters, w1_master_entry) {
 		if (dev->id == id) {
 			found = 1;
 			atomic_inc(&dev->refcnt);
 			break;
 		}
 	}
 	mutex_unlock(&w1_mlock);
 
 	return (found)?dev:NULL;
 }
 
 struct w1_slave *w1_search_slave(struct w1_reg_num *id)
 {
 	struct w1_master *dev;
 	struct w1_slave *sl = NULL;
 	int found = 0;
 
 	mutex_lock(&w1_mlock);
 	list_for_each_entry(dev, &w1_masters, w1_master_entry) {
 		mutex_lock(&dev->list_mutex);
 		list_for_each_entry(sl, &dev->slist, w1_slave_entry) {
 			if (sl->reg_num.family == id->family &&
 					sl->reg_num.id == id->id &&
 					sl->reg_num.crc == id->crc) {
 				found = 1;
 				atomic_inc(&dev->refcnt);
 				atomic_inc(&sl->refcnt);
 				break;
 			}
 		}
 		mutex_unlock(&dev->list_mutex);
 
 		if (found)
 			break;
 	}
 	mutex_unlock(&w1_mlock);
 
 	return (found)?sl:NULL;
 }
 
 void w1_reconnect_slaves(struct w1_family *f, int attach)
 {
 	struct w1_slave *sl, *sln;
 	struct w1_master *dev;
 
 	mutex_lock(&w1_mlock);
 	list_for_each_entry(dev, &w1_masters, w1_master_entry) {
 		dev_dbg(&dev->dev, "Reconnecting slaves in device %s "
 			"for family %02x.\n", dev->name, f->fid);
 		mutex_lock(&dev->mutex);
 		mutex_lock(&dev->list_mutex);
 		list_for_each_entry_safe(sl, sln, &dev->slist, w1_slave_entry) {
 			/* If it is a new family, slaves with the default
 			 * family driver and are that family will be
 			 * connected.  If the family is going away, devices
 			 * matching that family are reconneced.
 			 */
 			if ((attach && sl->family->fid == W1_FAMILY_DEFAULT
 				&& sl->reg_num.family == f->fid) ||
 				(!attach && sl->family->fid == f->fid)) {
 				struct w1_reg_num rn;
 
 				mutex_unlock(&dev->list_mutex);
 				memcpy(&rn, &sl->reg_num, sizeof(rn));
 				/* If it was already in use let the automatic
 				 * scan pick it up again later.
 				 */
 				if (!w1_slave_detach(sl))
 					w1_attach_slave_device(dev, &rn);
 				mutex_lock(&dev->list_mutex);
 			}
 		}
 		dev_dbg(&dev->dev, "Reconnecting slaves in device %s "
 			"has been finished.\n", dev->name);
 		mutex_unlock(&dev->list_mutex);
 		mutex_unlock(&dev->mutex);
 	}
 	mutex_unlock(&w1_mlock);
 }
 
 void w1_slave_found(struct w1_master *dev, u64 rn)
 {
 	struct w1_slave *sl;
 	struct w1_reg_num *tmp;
 	u64 rn_le = cpu_to_le64(rn);
 
 	atomic_inc(&dev->refcnt);
 
 	tmp = (struct w1_reg_num *) &rn;
 
 	sl = w1_slave_search_device(dev, tmp);
 	if (sl) {
 		set_bit(W1_SLAVE_ACTIVE, &sl->flags);
 	} else {
 		if (rn && tmp->crc == w1_calc_crc8((u8 *)&rn_le, 7))
 			w1_attach_slave_device(dev, tmp);
 	}
 
 	atomic_dec(&dev->refcnt);
 }
 
 /**
  * w1_search() - Performs a ROM Search & registers any devices found.
  * @dev: The master device to search
  * @search_type: W1_SEARCH to search all devices, or W1_ALARM_SEARCH
  * to return only devices in the alarmed state
  * @cb: Function to call when a device is found
  *
  * The 1-wire search is a simple binary tree search.
  * For each bit of the address, we read two bits and write one bit.
  * The bit written will put to sleep all devies that don't match that bit.
  * When the two reads differ, the direction choice is obvious.
  * When both bits are 0, we must choose a path to take.
  * When we can scan all 64 bits without having to choose a path, we are done.
  *
  * See "Application note 187 1-wire search algorithm" at www.maxim-ic.com
  *
  */
 void w1_search(struct w1_master *dev, u8 search_type, w1_slave_found_callback cb)
 {
 	u64 last_rn, rn, tmp64;
 	int i, slave_count = 0;
 	int last_zero, last_device;
 	int search_bit, desc_bit;
 	u8  triplet_ret = 0;
 
 	search_bit = 0;
 	rn = dev->search_id;
 	last_rn = 0;
 	last_device = 0;
 	last_zero = -1;
 
 	desc_bit = 64;
 
 	while ( !last_device && (slave_count++ < dev->max_slave_count) ) {
 		last_rn = rn;
 		rn = 0;
 
 		/*
 		 * Reset bus and all 1-wire device state machines
 		 * so they can respond to our requests.
 		 *
 		 * Return 0 - device(s) present, 1 - no devices present.
 		 */
 		mutex_lock(&dev->bus_mutex);
 		if (w1_reset_bus(dev)) {
 			mutex_unlock(&dev->bus_mutex);
 			dev_dbg(&dev->dev, "No devices present on the wire.\n");
 			break;
 		}
 
 		/* Do fast search on single slave bus */
 		if (dev->max_slave_count == 1) {
 			int rv;
 			w1_write_8(dev, W1_READ_ROM);
 			rv = w1_read_block(dev, (u8 *)&rn, 8);
 			mutex_unlock(&dev->bus_mutex);
 
 			if (rv == 8 && rn)
 				cb(dev, rn);
 
 			break;
 		}
 
 		/* Start the search */
 		w1_write_8(dev, search_type);
 		for (i = 0; i < 64; ++i) {
 			/* Determine the direction/search bit */
 			if (i == desc_bit)
 				search_bit = 1;	  /* took the 0 path last time, so take the 1 path */
 			else if (i > desc_bit)
 				search_bit = 0;	  /* take the 0 path on the next branch */
 			else
 				search_bit = ((last_rn >> i) & 0x1);
 
 			/* Read two bits and write one bit */
 			triplet_ret = w1_triplet(dev, search_bit);
 
 			/* quit if no device responded */
 			if ( (triplet_ret & 0x03) == 0x03 )
 				break;
 
 			/* If both directions were valid, and we took the 0 path... */
 			if (triplet_ret == 0)
 				last_zero = i;
 
 			/* extract the direction taken & update the device number */
 			tmp64 = (triplet_ret >> 2);
 			rn |= (tmp64 << i);
 
 			if (test_bit(W1_ABORT_SEARCH, &dev->flags)) {
 				mutex_unlock(&dev->bus_mutex);
 				dev_dbg(&dev->dev, "Abort w1_search\n");
 				return;
 			}
 		}
 		mutex_unlock(&dev->bus_mutex);
 
 		if ( (triplet_ret & 0x03) != 0x03 ) {
 			if ((desc_bit == last_zero) || (last_zero < 0)) {
 				last_device = 1;
 				dev->search_id = 0;
 			} else {
 				dev->search_id = rn;
 			}
 			desc_bit = last_zero;
 			cb(dev, rn);
 		}
 
 		if (!last_device && slave_count == dev->max_slave_count &&
 			!test_bit(W1_WARN_MAX_COUNT, &dev->flags)) {
 			/* Only max_slave_count will be scanned in a search,
 			 * but it will start where it left off next search
 			 * until all ids are identified and then it will start
 			 * over.  A continued search will report the previous
 			 * last id as the first id (provided it is still on the
 			 * bus).
 			 */
 			dev_info(&dev->dev, "%s: max_slave_count %d reached, "
 				"will continue next search.\n", __func__,
 				dev->max_slave_count);
 			set_bit(W1_WARN_MAX_COUNT, &dev->flags);
 		}
 	}
 }
 
 void w1_search_process_cb(struct w1_master *dev, u8 search_type,
 	w1_slave_found_callback cb)
 {
 	struct w1_slave *sl, *sln;
 
 	mutex_lock(&dev->list_mutex);
 	list_for_each_entry(sl, &dev->slist, w1_slave_entry)
 		clear_bit(W1_SLAVE_ACTIVE, &sl->flags);
 	mutex_unlock(&dev->list_mutex);
 
 	w1_search_devices(dev, search_type, cb);
 
 	mutex_lock(&dev->list_mutex);
 	list_for_each_entry_safe(sl, sln, &dev->slist, w1_slave_entry) {
 		if (!test_bit(W1_SLAVE_ACTIVE, &sl->flags) && !--sl->ttl) {
 			mutex_unlock(&dev->list_mutex);
 			w1_slave_detach(sl);
 			mutex_lock(&dev->list_mutex);
 		}
 		else if (test_bit(W1_SLAVE_ACTIVE, &sl->flags))
 			sl->ttl = dev->slave_ttl;
 	}
 	mutex_unlock(&dev->list_mutex);
 
 	if (dev->search_count > 0)
 		dev->search_count--;
 }
 
 static void w1_search_process(struct w1_master *dev, u8 search_type)
 {
 	w1_search_process_cb(dev, search_type, w1_slave_found);
 }
 
 /**
  * w1_process_callbacks() - execute each dev->async_list callback entry
  * @dev: w1_master device
  *
  * The w1 master list_mutex must be held.
  *
  * Return: 1 if there were commands to executed 0 otherwise
  */
 int w1_process_callbacks(struct w1_master *dev)
 {
 	int ret = 0;
 	struct w1_async_cmd *async_cmd, *async_n;
 
 	/* The list can be added to in another thread, loop until it is empty */
 	while (!list_empty(&dev->async_list)) {
 		list_for_each_entry_safe(async_cmd, async_n, &dev->async_list,
 			async_entry) {
 			/* drop the lock, if it is a search it can take a long
 			 * time */
 			mutex_unlock(&dev->list_mutex);
 			async_cmd->cb(dev, async_cmd);
 			ret = 1;
 			mutex_lock(&dev->list_mutex);
 		}
 	}
 	return ret;
 }
 
 int w1_process(void *data)
 {
 	struct w1_master *dev = (struct w1_master *) data;
 	/* As long as w1_timeout is only set by a module parameter the sleep
 	 * time can be calculated in jiffies once.
 	 */
 	const unsigned long jtime =
 	  usecs_to_jiffies(w1_timeout * 1000000 + w1_timeout_us);
 	/* remainder if it woke up early */
 	unsigned long jremain = 0;
 
 	for (;;) {
 
 		if (!jremain && dev->search_count) {
 			mutex_lock(&dev->mutex);
 			w1_search_process(dev, W1_SEARCH);
 			mutex_unlock(&dev->mutex);
 		}
 
 		mutex_lock(&dev->list_mutex);
 		/* Note, w1_process_callback drops the lock while processing,
 		 * but locks it again before returning.
 		 */
 		if (!w1_process_callbacks(dev) && jremain) {
 			/* a wake up is either to stop the thread, process
 			 * callbacks, or search, it isn't process callbacks, so
 			 * schedule a search.
 			 */
 			jremain = 1;
 		}
 
 		__set_current_state(TASK_INTERRUPTIBLE);
 
 		/* hold list_mutex until after interruptible to prevent loosing
 		 * the wakeup signal when async_cmd is added.
 		 */
 		mutex_unlock(&dev->list_mutex);
 
 		if (kthread_should_stop())
 			break;
 
 		/* Only sleep when the search is active. */
 		if (dev->search_count) {
 			if (!jremain)
 				jremain = jtime;
 			jremain = schedule_timeout(jremain);
 		}
 		else
 			schedule();
 	}
 
 	atomic_dec(&dev->refcnt);
 
 	return 0;
 }
 
 static int __init w1_init(void)
 {
 	int retval;
 
 	pr_info("Driver for 1-wire Dallas network protocol.\n");
 
 	w1_init_netlink();
 
 	retval = bus_register(&w1_bus_type);
 	if (retval) {
 		pr_err("Failed to register bus. err=%d.\n", retval);
 		goto err_out_exit_init;
 	}
 
 	retval = driver_register(&w1_master_driver);
 	if (retval) {
 		pr_err("Failed to register master driver. err=%d.\n",
 			retval);
 		goto err_out_bus_unregister;
 	}
 
 	retval = driver_register(&w1_slave_driver);
 	if (retval) {
 		pr_err("Failed to register slave driver. err=%d.\n",
 			retval);
 		goto err_out_master_unregister;
 	}
 
 	return 0;
 
 #if 0
 /* For undoing the slave register if there was a step after it. */
 err_out_slave_unregister:
 	driver_unregister(&w1_slave_driver);
 #endif
 
 err_out_master_unregister:
 	driver_unregister(&w1_master_driver);
 
 err_out_bus_unregister:
 	bus_unregister(&w1_bus_type);
 
 err_out_exit_init:
 	return retval;
 }
 
 static void __exit w1_fini(void)
 {
 	struct w1_master *dev;
 
 	/* Set netlink removal messages and some cleanup */
 	list_for_each_entry(dev, &w1_masters, w1_master_entry)
 		__w1_remove_master_device(dev);
 
 	w1_fini_netlink();
 
 	driver_unregister(&w1_slave_driver);
 	driver_unregister(&w1_master_driver);
 	bus_unregister(&w1_bus_type);
 }
 
 module_init(w1_init);
 module_exit(w1_fini);
diff --git a/drivers/w1/w1.h b/drivers/w1/w1.h
index 129895f562b0..758a7a6322e9 100644
--- a/drivers/w1/w1.h
+++ b/drivers/w1/w1.h
@@ -1,343 +1,336 @@
 /*
- *	w1.h
- *
  * Copyright (c) 2004 Evgeniy Polyakov <zbr@ioremap.net>
  *
- *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
  * the Free Software Foundation; either version 2 of the License, or
  * (at your option) any later version.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
  */
 
 #ifndef __W1_H
 #define __W1_H
 
 /**
  * struct w1_reg_num - broken out slave device id
  *
  * @family: identifies the type of device
  * @id: along with family is the unique device id
  * @crc: checksum of the other bytes
  */
 struct w1_reg_num
 {
 #if defined(__LITTLE_ENDIAN_BITFIELD)
 	__u64	family:8,
 		id:48,
 		crc:8;
 #elif defined(__BIG_ENDIAN_BITFIELD)
 	__u64	crc:8,
 		id:48,
 		family:8;
 #else
 #error "Please fix <asm/byteorder.h>"
 #endif
 };
 
 #ifdef __KERNEL__
 
 #include <linux/completion.h>
 #include <linux/device.h>
 #include <linux/mutex.h>
 
 #include "w1_family.h"
 
 #define W1_MAXNAMELEN		32
 
 #define W1_SEARCH		0xF0
 #define W1_ALARM_SEARCH		0xEC
 #define W1_CONVERT_TEMP		0x44
 #define W1_SKIP_ROM		0xCC
 #define W1_COPY_SCRATCHPAD	0x48
 #define W1_WRITE_SCRATCHPAD	0x4E
 #define W1_READ_SCRATCHPAD	0xBE
 #define W1_READ_ROM		0x33
 #define W1_READ_PSUPPLY		0xB4
 #define W1_MATCH_ROM		0x55
 #define W1_RESUME_CMD		0xA5
 
 #define W1_SLAVE_ACTIVE		0
 #define W1_SLAVE_DETACH		1
 
 /**
  * struct w1_slave - holds a single slave device on the bus
  *
  * @owner: Points to the one wire "wire" kernel module.
  * @name: Device id is ascii.
  * @w1_slave_entry: data for the linked list
  * @reg_num: the slave id in binary
  * @refcnt: reference count, delete when 0
  * @flags: bit flags for W1_SLAVE_ACTIVE W1_SLAVE_DETACH
  * @ttl: decrement per search this slave isn't found, deatch at 0
  * @master: bus which this slave is on
  * @family: module for device family type
  * @family_data: pointer for use by the family module
  * @dev: kernel device identifier
  *
  */
 struct w1_slave
 {
 	struct module		*owner;
 	unsigned char		name[W1_MAXNAMELEN];
 	struct list_head	w1_slave_entry;
 	struct w1_reg_num	reg_num;
 	atomic_t		refcnt;
 	int			ttl;
 	unsigned long		flags;
 
 	struct w1_master	*master;
 	struct w1_family	*family;
 	void			*family_data;
 	struct device		dev;
 };
 
 typedef void (*w1_slave_found_callback)(struct w1_master *, u64);
 
 
 /**
  * struct w1_bus_master - operations available on a bus master
  *
  * @data: the first parameter in all the functions below
  *
  * @read_bit: Sample the line level @return the level read (0 or 1)
  *
  * @write_bit: Sets the line level
  *
  * @touch_bit: the lowest-level function for devices that really support the
  * 1-wire protocol.
  * touch_bit(0) = write-0 cycle
  * touch_bit(1) = write-1 / read cycle
  * @return the bit read (0 or 1)
  *
  * @read_byte: Reads a bytes. Same as 8 touch_bit(1) calls.
  * @return the byte read
  *
  * @write_byte: Writes a byte. Same as 8 touch_bit(x) calls.
  *
  * @read_block: Same as a series of read_byte() calls
  * @return the number of bytes read
  *
  * @write_block: Same as a series of write_byte() calls
  *
  * @triplet: Combines two reads and a smart write for ROM searches
  * @return bit0=Id bit1=comp_id bit2=dir_taken
  *
  * @reset_bus: long write-0 with a read for the presence pulse detection
  * @return -1=Error, 0=Device present, 1=No device present
  *
  * @set_pullup: Put out a strong pull-up pulse of the specified duration.
  * @return -1=Error, 0=completed
  *
  * @search: Really nice hardware can handles the different types of ROM search
  * w1_master* is passed to the slave found callback.
  * u8 is search_type, W1_SEARCH or W1_ALARM_SEARCH
  *
  * Note: read_bit and write_bit are very low level functions and should only
  * be used with hardware that doesn't really support 1-wire operations,
  * like a parallel/serial port.
  * Either define read_bit and write_bit OR define, at minimum, touch_bit and
  * reset_bus.
  *
  */
 struct w1_bus_master
 {
 	void		*data;
 
 	u8		(*read_bit)(void *);
 
 	void		(*write_bit)(void *, u8);
 
 	u8		(*touch_bit)(void *, u8);
 
 	u8		(*read_byte)(void *);
 
 	void		(*write_byte)(void *, u8);
 
 	u8		(*read_block)(void *, u8 *, int);
 
 	void		(*write_block)(void *, const u8 *, int);
 
 	u8		(*triplet)(void *, u8);
 
 	u8		(*reset_bus)(void *);
 
 	u8		(*set_pullup)(void *, int);
 
 	void		(*search)(void *, struct w1_master *,
 		u8, w1_slave_found_callback);
 };
 
 /**
  * enum w1_master_flags - bitfields used in w1_master.flags
  * @W1_ABORT_SEARCH: abort searching early on shutdown
  * @W1_WARN_MAX_COUNT: limit warning when the maximum count is reached
  */
 enum w1_master_flags {
 	W1_ABORT_SEARCH = 0,
 	W1_WARN_MAX_COUNT = 1,
 };
 
 /**
  * struct w1_master - one per bus master
  * @w1_master_entry:	master linked list
  * @owner:		module owner
  * @name:		dynamically allocate bus name
  * @list_mutex:		protect slist and async_list
  * @slist:		linked list of slaves
  * @async_list:		linked list of netlink commands to execute
  * @max_slave_count:	maximum number of slaves to search for at a time
  * @slave_count:	current number of slaves known
  * @attempts:		number of searches ran
  * @slave_ttl:		number of searches before a slave is timed out
  * @initialized:	prevent init/removal race conditions
  * @id:			w1 bus number
  * @search_count:	number of automatic searches to run, -1 unlimited
  * @search_id:		allows continuing a search
  * @refcnt:		reference count
  * @priv:		private data storage
  * @enable_pullup:	allows a strong pullup
  * @pullup_duration:	time for the next strong pullup
  * @flags:		one of w1_master_flags
  * @thread:		thread for bus search and netlink commands
  * @mutex:		protect most of w1_master
  * @bus_mutex:		pretect concurrent bus access
  * @driver:		sysfs driver
  * @dev:		sysfs device
  * @bus_master:		io operations available
  * @seq:		sequence number used for netlink broadcasts
  */
 struct w1_master
 {
 	struct list_head	w1_master_entry;
 	struct module		*owner;
 	unsigned char		name[W1_MAXNAMELEN];
 	/* list_mutex protects just slist and async_list so slaves can be
 	 * searched for and async commands added while the master has
 	 * w1_master.mutex locked and is operating on the bus.
 	 * lock order w1_mlock, w1_master.mutex, w1_master.list_mutex
 	 */
 	struct mutex		list_mutex;
 	struct list_head	slist;
 	struct list_head	async_list;
 	int			max_slave_count, slave_count;
 	unsigned long		attempts;
 	int			slave_ttl;
 	int			initialized;
 	u32			id;
 	int			search_count;
 	/* id to start searching on, to continue a search or 0 to restart */
 	u64			search_id;
 
 	atomic_t		refcnt;
 
 	void			*priv;
 
 	/** 5V strong pullup enabled flag, 1 enabled, zero disabled. */
 	int			enable_pullup;
 	/** 5V strong pullup duration in milliseconds, zero disabled. */
 	int			pullup_duration;
 
 	long			flags;
 
 	struct task_struct	*thread;
 	struct mutex		mutex;
 	struct mutex		bus_mutex;
 
 	struct device_driver	*driver;
 	struct device		dev;
 
 	struct w1_bus_master	*bus_master;
 
 	u32			seq;
 };
 
 /**
  * struct w1_async_cmd - execute callback from the w1_process kthread
  * @async_entry: link entry
  * @cb: callback function, must list_del and destroy this list before
  * returning
  *
  * When inserted into the w1_master async_list, w1_process will execute
  * the callback.  Embed this into the structure with the command details.
  */
 struct w1_async_cmd {
 	struct list_head	async_entry;
 	void (*cb)(struct w1_master *dev, struct w1_async_cmd *async_cmd);
 };
 
 int w1_create_master_attributes(struct w1_master *);
 void w1_destroy_master_attributes(struct w1_master *master);
 void w1_search(struct w1_master *dev, u8 search_type, w1_slave_found_callback cb);
 void w1_search_devices(struct w1_master *dev, u8 search_type, w1_slave_found_callback cb);
 /* call w1_unref_slave to release the reference counts w1_search_slave added */
 struct w1_slave *w1_search_slave(struct w1_reg_num *id);
 /* decrements the reference on sl->master and sl, and cleans up if zero
  * returns the reference count after it has been decremented */
 int w1_unref_slave(struct w1_slave *sl);
 void w1_slave_found(struct w1_master *dev, u64 rn);
 void w1_search_process_cb(struct w1_master *dev, u8 search_type,
 	w1_slave_found_callback cb);
 struct w1_slave *w1_slave_search_device(struct w1_master *dev,
 	struct w1_reg_num *rn);
 struct w1_master *w1_search_master_id(u32 id);
 
 /* Disconnect and reconnect devices in the given family.  Used for finding
  * unclaimed devices after a family has been registered or releasing devices
  * after a family has been unregistered.  Set attach to 1 when a new family
  * has just been registered, to 0 when it has been unregistered.
  */
 void w1_reconnect_slaves(struct w1_family *f, int attach);
 int w1_attach_slave_device(struct w1_master *dev, struct w1_reg_num *rn);
 /* 0 success, otherwise EBUSY */
 int w1_slave_detach(struct w1_slave *sl);
 
 u8 w1_triplet(struct w1_master *dev, int bdir);
 void w1_write_8(struct w1_master *, u8);
 u8 w1_read_8(struct w1_master *);
 int w1_reset_bus(struct w1_master *);
 u8 w1_calc_crc8(u8 *, int);
 void w1_write_block(struct w1_master *, const u8 *, int);
 void w1_touch_block(struct w1_master *, u8 *, int);
 u8 w1_read_block(struct w1_master *, u8 *, int);
 int w1_reset_select_slave(struct w1_slave *sl);
 int w1_reset_resume_command(struct w1_master *);
 void w1_next_pullup(struct w1_master *, int);
 
 static inline struct w1_slave* dev_to_w1_slave(struct device *dev)
 {
 	return container_of(dev, struct w1_slave, dev);
 }
 
 static inline struct w1_slave* kobj_to_w1_slave(struct kobject *kobj)
 {
 	return dev_to_w1_slave(container_of(kobj, struct device, kobj));
 }
 
 static inline struct w1_master* dev_to_w1_master(struct device *dev)
 {
 	return container_of(dev, struct w1_master, dev);
 }
 
 extern struct device_driver w1_master_driver;
 extern struct device w1_master_device;
 extern int w1_max_slave_count;
 extern int w1_max_slave_ttl;
 extern struct list_head w1_masters;
 extern struct mutex w1_mlock;
 
 extern int w1_process_callbacks(struct w1_master *dev);
 extern int w1_process(void *);
 
 #endif /* __KERNEL__ */
 
 #endif /* __W1_H */
diff --git a/drivers/w1/w1_family.c b/drivers/w1/w1_family.c
index 1dc3051f7d76..df1c9bb90eb5 100644
--- a/drivers/w1/w1_family.c
+++ b/drivers/w1/w1_family.c
@@ -1,148 +1,141 @@
 /*
- *	w1_family.c
- *
  * Copyright (c) 2004 Evgeniy Polyakov <zbr@ioremap.net>
  *
- *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
  * the Free Software Foundation; either version 2 of the License, or
  * (at your option) any later version.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
  */
 
 #include <linux/spinlock.h>
 #include <linux/list.h>
 #include <linux/sched.h>	/* schedule_timeout() */
 #include <linux/delay.h>
 #include <linux/export.h>
 
 #include "w1_family.h"
 #include "w1.h"
 
 DEFINE_SPINLOCK(w1_flock);
 static LIST_HEAD(w1_families);
 
 /**
  * w1_register_family() - register a device family driver
  * @newf:	family to register
  */
 int w1_register_family(struct w1_family *newf)
 {
 	struct list_head *ent, *n;
 	struct w1_family *f;
 	int ret = 0;
 
 	spin_lock(&w1_flock);
 	list_for_each_safe(ent, n, &w1_families) {
 		f = list_entry(ent, struct w1_family, family_entry);
 
 		if (f->fid == newf->fid) {
 			ret = -EEXIST;
 			break;
 		}
 	}
 
 	if (!ret) {
 		atomic_set(&newf->refcnt, 0);
 		list_add_tail(&newf->family_entry, &w1_families);
 	}
 	spin_unlock(&w1_flock);
 
 	/* check default devices against the new set of drivers */
 	w1_reconnect_slaves(newf, 1);
 
 	return ret;
 }
 
 /**
  * w1_unregister_family() - unregister a device family driver
  * @fent:	family to unregister
  */
 void w1_unregister_family(struct w1_family *fent)
 {
 	struct list_head *ent, *n;
 	struct w1_family *f;
 
 	spin_lock(&w1_flock);
 	list_for_each_safe(ent, n, &w1_families) {
 		f = list_entry(ent, struct w1_family, family_entry);
 
 		if (f->fid == fent->fid) {
 			list_del(&fent->family_entry);
 			break;
 		}
 	}
 	spin_unlock(&w1_flock);
 
 	/* deatch devices using this family code */
 	w1_reconnect_slaves(fent, 0);
 
 	while (atomic_read(&fent->refcnt)) {
 		pr_info("Waiting for family %u to become free: refcnt=%d.\n",
 				fent->fid, atomic_read(&fent->refcnt));
 
 		if (msleep_interruptible(1000))
 			flush_signals(current);
 	}
 }
 
 /*
  * Should be called under w1_flock held.
  */
 struct w1_family * w1_family_registered(u8 fid)
 {
 	struct list_head *ent, *n;
 	struct w1_family *f = NULL;
 	int ret = 0;
 
 	list_for_each_safe(ent, n, &w1_families) {
 		f = list_entry(ent, struct w1_family, family_entry);
 
 		if (f->fid == fid) {
 			ret = 1;
 			break;
 		}
 	}
 
 	return (ret) ? f : NULL;
 }
 
 static void __w1_family_put(struct w1_family *f)
 {
 	atomic_dec(&f->refcnt);
 }
 
 void w1_family_put(struct w1_family *f)
 {
 	spin_lock(&w1_flock);
 	__w1_family_put(f);
 	spin_unlock(&w1_flock);
 }
 
 #if 0
 void w1_family_get(struct w1_family *f)
 {
 	spin_lock(&w1_flock);
 	__w1_family_get(f);
 	spin_unlock(&w1_flock);
 }
 #endif  /*  0  */
 
 void __w1_family_get(struct w1_family *f)
 {
 	smp_mb__before_atomic();
 	atomic_inc(&f->refcnt);
 	smp_mb__after_atomic();
 }
 
 EXPORT_SYMBOL(w1_unregister_family);
 EXPORT_SYMBOL(w1_register_family);
diff --git a/drivers/w1/w1_family.h b/drivers/w1/w1_family.h
index 10a7a0767187..c4a6b257a367 100644
--- a/drivers/w1/w1_family.h
+++ b/drivers/w1/w1_family.h
@@ -1,103 +1,97 @@
 /*
- *	w1_family.h
- *
  * Copyright (c) 2004 Evgeniy Polyakov <zbr@ioremap.net>
  *
- *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
  * the Free Software Foundation; either version 2 of the License, or
  * (at your option) any later version.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
  */
 
 #ifndef __W1_FAMILY_H
 #define __W1_FAMILY_H
 
 #include <linux/types.h>
 #include <linux/device.h>
 #include <linux/atomic.h>
 
 #define W1_FAMILY_DEFAULT	0
 #define W1_FAMILY_BQ27000	0x01
 #define W1_FAMILY_SMEM_01	0x01
 #define W1_FAMILY_SMEM_81	0x81
+#define W1_FAMILY_DS2405	0x05
 #define W1_THERM_DS18S20 	0x10
 #define W1_FAMILY_DS28E04	0x1C
 #define W1_COUNTER_DS2423	0x1D
 #define W1_THERM_DS1822  	0x22
 #define W1_EEPROM_DS2433  	0x23
 #define W1_THERM_DS18B20 	0x28
 #define W1_FAMILY_DS2408	0x29
 #define W1_EEPROM_DS2431	0x2D
 #define W1_FAMILY_DS2760	0x30
 #define W1_FAMILY_DS2780	0x32
 #define W1_FAMILY_DS2413	0x3A
 #define W1_FAMILY_DS2406	0x12
 #define W1_THERM_DS1825		0x3B
 #define W1_FAMILY_DS2781	0x3D
 #define W1_THERM_DS28EA00	0x42
 
 #define MAXNAMELEN		32
 
 struct w1_slave;
 
 /**
  * struct w1_family_ops - operations for a family type
  * @add_slave: add_slave
  * @remove_slave: remove_slave
  * @groups: sysfs group
  */
 struct w1_family_ops
 {
 	int  (* add_slave)(struct w1_slave *);
 	void (* remove_slave)(struct w1_slave *);
 	const struct attribute_group **groups;
 };
 
 /**
  * struct w1_family - reference counted family structure.
  * @family_entry:	family linked list
  * @fid:		8 bit family identifier
  * @fops:		operations for this family
  * @refcnt:		reference counter
  */
 struct w1_family
 {
 	struct list_head	family_entry;
 	u8			fid;
 
 	struct w1_family_ops	*fops;
 
 	atomic_t		refcnt;
 };
 
 extern spinlock_t w1_flock;
 
 void w1_family_put(struct w1_family *);
 void __w1_family_get(struct w1_family *);
 struct w1_family * w1_family_registered(u8);
 void w1_unregister_family(struct w1_family *);
 int w1_register_family(struct w1_family *);
 
 /**
  * module_w1_driver() - Helper macro for registering a 1-Wire families
  * @__w1_family: w1_family struct
  *
  * Helper macro for 1-Wire families which do not do anything special in module
  * init/exit. This eliminates a lot of boilerplate. Each module may only
  * use this macro once, and calling it replaces module_init() and module_exit()
  */
 #define module_w1_family(__w1_family) \
 	module_driver(__w1_family, w1_register_family, \
 			w1_unregister_family)
 
 #endif /* __W1_FAMILY_H */
diff --git a/drivers/w1/w1_int.c b/drivers/w1/w1_int.c
index 20f766afa4c7..4ce1b66d5092 100644
--- a/drivers/w1/w1_int.c
+++ b/drivers/w1/w1_int.c
@@ -1,263 +1,256 @@
 /*
- *	w1_int.c
- *
  * Copyright (c) 2004 Evgeniy Polyakov <zbr@ioremap.net>
  *
- *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
  * the Free Software Foundation; either version 2 of the License, or
  * (at your option) any later version.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
  */
 
 #include <linux/kernel.h>
 #include <linux/list.h>
 #include <linux/delay.h>
 #include <linux/kthread.h>
 #include <linux/slab.h>
 #include <linux/export.h>
 #include <linux/moduleparam.h>
 
 #include "w1.h"
 #include "w1_log.h"
 #include "w1_netlink.h"
 #include "w1_int.h"
 
 static int w1_search_count = -1; /* Default is continual scan */
 module_param_named(search_count, w1_search_count, int, 0);
 
 static int w1_enable_pullup = 1;
 module_param_named(enable_pullup, w1_enable_pullup, int, 0);
 
 static struct w1_master *w1_alloc_dev(u32 id, int slave_count, int slave_ttl,
 				       struct device_driver *driver,
 				       struct device *device)
 {
 	struct w1_master *dev;
 	int err;
 
 	/*
 	 * We are in process context(kernel thread), so can sleep.
 	 */
 	dev = kzalloc(sizeof(struct w1_master) + sizeof(struct w1_bus_master), GFP_KERNEL);
 	if (!dev) {
 		pr_err("Failed to allocate %zd bytes for new w1 device.\n",
 			sizeof(struct w1_master));
 		return NULL;
 	}
 
 
 	dev->bus_master = (struct w1_bus_master *)(dev + 1);
 
 	dev->owner		= THIS_MODULE;
 	dev->max_slave_count	= slave_count;
 	dev->slave_count	= 0;
 	dev->attempts		= 0;
 	dev->initialized	= 0;
 	dev->id			= id;
 	dev->slave_ttl		= slave_ttl;
 	dev->search_count	= w1_search_count;
 	dev->enable_pullup	= w1_enable_pullup;
 
 	/* 1 for w1_process to decrement
 	 * 1 for __w1_remove_master_device to decrement
 	 */
 	atomic_set(&dev->refcnt, 2);
 
 	INIT_LIST_HEAD(&dev->slist);
 	INIT_LIST_HEAD(&dev->async_list);
 	mutex_init(&dev->mutex);
 	mutex_init(&dev->bus_mutex);
 	mutex_init(&dev->list_mutex);
 
 	memcpy(&dev->dev, device, sizeof(struct device));
 	dev_set_name(&dev->dev, "w1_bus_master%u", dev->id);
 	snprintf(dev->name, sizeof(dev->name), "w1_bus_master%u", dev->id);
 	dev->dev.init_name = dev->name;
 
 	dev->driver = driver;
 
 	dev->seq = 1;
 
 	err = device_register(&dev->dev);
 	if (err) {
 		pr_err("Failed to register master device. err=%d\n", err);
 		put_device(&dev->dev);
 		dev = NULL;
 	}
 
 	return dev;
 }
 
 static void w1_free_dev(struct w1_master *dev)
 {
 	device_unregister(&dev->dev);
 }
 
 /**
  * w1_add_master_device() - registers a new master device
  * @master:	master bus device to register
  */
 int w1_add_master_device(struct w1_bus_master *master)
 {
 	struct w1_master *dev, *entry;
 	int retval = 0;
 	struct w1_netlink_msg msg;
 	int id, found;
 
 	/* validate minimum functionality */
 	if (!(master->touch_bit && master->reset_bus) &&
 	    !(master->write_bit && master->read_bit) &&
 	    !(master->write_byte && master->read_byte && master->reset_bus)) {
 		pr_err("w1_add_master_device: invalid function set\n");
 		return(-EINVAL);
 	}
 
 	/* Lock until the device is added (or not) to w1_masters. */
 	mutex_lock(&w1_mlock);
 	/* Search for the first available id (starting at 1). */
 	id = 0;
 	do {
 		++id;
 		found = 0;
 		list_for_each_entry(entry, &w1_masters, w1_master_entry) {
 			if (entry->id == id) {
 				found = 1;
 				break;
 			}
 		}
 	} while (found);
 
 	dev = w1_alloc_dev(id, w1_max_slave_count, w1_max_slave_ttl,
 		&w1_master_driver, &w1_master_device);
 	if (!dev) {
 		mutex_unlock(&w1_mlock);
 		return -ENOMEM;
 	}
 
 	retval =  w1_create_master_attributes(dev);
 	if (retval) {
 		mutex_unlock(&w1_mlock);
 		goto err_out_free_dev;
 	}
 
 	memcpy(dev->bus_master, master, sizeof(struct w1_bus_master));
 
 	dev->initialized = 1;
 
 	dev->thread = kthread_run(&w1_process, dev, "%s", dev->name);
 	if (IS_ERR(dev->thread)) {
 		retval = PTR_ERR(dev->thread);
 		dev_err(&dev->dev,
 			 "Failed to create new kernel thread. err=%d\n",
 			 retval);
 		mutex_unlock(&w1_mlock);
 		goto err_out_rm_attr;
 	}
 
 	list_add(&dev->w1_master_entry, &w1_masters);
 	mutex_unlock(&w1_mlock);
 
 	memset(&msg, 0, sizeof(msg));
 	msg.id.mst.id = dev->id;
 	msg.type = W1_MASTER_ADD;
 	w1_netlink_send(dev, &msg);
 
 	return 0;
 
 #if 0 /* Thread cleanup code, not required currently. */
 err_out_kill_thread:
 	set_bit(W1_ABORT_SEARCH, &dev->flags);
 	kthread_stop(dev->thread);
 #endif
 err_out_rm_attr:
 	w1_destroy_master_attributes(dev);
 err_out_free_dev:
 	w1_free_dev(dev);
 
 	return retval;
 }
 
 void __w1_remove_master_device(struct w1_master *dev)
 {
 	struct w1_netlink_msg msg;
 	struct w1_slave *sl, *sln;
 
 	mutex_lock(&w1_mlock);
 	list_del(&dev->w1_master_entry);
 	mutex_unlock(&w1_mlock);
 
 	set_bit(W1_ABORT_SEARCH, &dev->flags);
 	kthread_stop(dev->thread);
 
 	mutex_lock(&dev->mutex);
 	mutex_lock(&dev->list_mutex);
 	list_for_each_entry_safe(sl, sln, &dev->slist, w1_slave_entry) {
 		mutex_unlock(&dev->list_mutex);
 		w1_slave_detach(sl);
 		mutex_lock(&dev->list_mutex);
 	}
 	w1_destroy_master_attributes(dev);
 	mutex_unlock(&dev->list_mutex);
 	mutex_unlock(&dev->mutex);
 	atomic_dec(&dev->refcnt);
 
 	while (atomic_read(&dev->refcnt)) {
 		dev_info(&dev->dev, "Waiting for %s to become free: refcnt=%d.\n",
 				dev->name, atomic_read(&dev->refcnt));
 
 		if (msleep_interruptible(1000))
 			flush_signals(current);
 		mutex_lock(&dev->list_mutex);
 		w1_process_callbacks(dev);
 		mutex_unlock(&dev->list_mutex);
 	}
 	mutex_lock(&dev->list_mutex);
 	w1_process_callbacks(dev);
 	mutex_unlock(&dev->list_mutex);
 
 	memset(&msg, 0, sizeof(msg));
 	msg.id.mst.id = dev->id;
 	msg.type = W1_MASTER_REMOVE;
 	w1_netlink_send(dev, &msg);
 
 	w1_free_dev(dev);
 }
 
 /**
  * w1_remove_master_device() - unregister a master device
  * @bm:	master bus device to remove
  */
 void w1_remove_master_device(struct w1_bus_master *bm)
 {
 	struct w1_master *dev, *found = NULL;
 
 	list_for_each_entry(dev, &w1_masters, w1_master_entry) {
 		if (!dev->initialized)
 			continue;
 
 		if (dev->bus_master->data == bm->data) {
 			found = dev;
 			break;
 		}
 	}
 
 	if (!found) {
 		pr_err("Device doesn't exist.\n");
 		return;
 	}
 
 	__w1_remove_master_device(found);
 }
 
 EXPORT_SYMBOL(w1_add_master_device);
 EXPORT_SYMBOL(w1_remove_master_device);
diff --git a/drivers/w1/w1_int.h b/drivers/w1/w1_int.h
index 2ad7d4414bed..371989159216 100644
--- a/drivers/w1/w1_int.h
+++ b/drivers/w1/w1_int.h
@@ -1,34 +1,27 @@
 /*
- *	w1_int.h
- *
  * Copyright (c) 2004 Evgeniy Polyakov <zbr@ioremap.net>
  *
- *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
  * the Free Software Foundation; either version 2 of the License, or
  * (at your option) any later version.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
  */
 
 #ifndef __W1_INT_H
 #define __W1_INT_H
 
 #include <linux/kernel.h>
 #include <linux/device.h>
 
 #include "w1.h"
 
 int w1_add_master_device(struct w1_bus_master *);
 void w1_remove_master_device(struct w1_bus_master *);
 void __w1_remove_master_device(struct w1_master *);
 
 #endif /* __W1_INT_H */
diff --git a/drivers/w1/w1_io.c b/drivers/w1/w1_io.c
index f4bc8c100a01..de8bebc27896 100644
--- a/drivers/w1/w1_io.c
+++ b/drivers/w1/w1_io.c
@@ -1,464 +1,458 @@
 /*
- *	w1_io.c
- *
  * Copyright (c) 2004 Evgeniy Polyakov <zbr@ioremap.net>
  *
- *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
  * the Free Software Foundation; either version 2 of the License, or
  * (at your option) any later version.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
  */
 
 #include <asm/io.h>
 
 #include <linux/delay.h>
 #include <linux/moduleparam.h>
 #include <linux/module.h>
 
 #include "w1.h"
 #include "w1_log.h"
 
 static int w1_delay_parm = 1;
 module_param_named(delay_coef, w1_delay_parm, int, 0);
 
 static int w1_disable_irqs = 0;
 module_param_named(disable_irqs, w1_disable_irqs, int, 0);
 
 static u8 w1_crc8_table[] = {
 	0, 94, 188, 226, 97, 63, 221, 131, 194, 156, 126, 32, 163, 253, 31, 65,
 	157, 195, 33, 127, 252, 162, 64, 30, 95, 1, 227, 189, 62, 96, 130, 220,
 	35, 125, 159, 193, 66, 28, 254, 160, 225, 191, 93, 3, 128, 222, 60, 98,
 	190, 224, 2, 92, 223, 129, 99, 61, 124, 34, 192, 158, 29, 67, 161, 255,
 	70, 24, 250, 164, 39, 121, 155, 197, 132, 218, 56, 102, 229, 187, 89, 7,
 	219, 133, 103, 57, 186, 228, 6, 88, 25, 71, 165, 251, 120, 38, 196, 154,
 	101, 59, 217, 135, 4, 90, 184, 230, 167, 249, 27, 69, 198, 152, 122, 36,
 	248, 166, 68, 26, 153, 199, 37, 123, 58, 100, 134, 216, 91, 5, 231, 185,
 	140, 210, 48, 110, 237, 179, 81, 15, 78, 16, 242, 172, 47, 113, 147, 205,
 	17, 79, 173, 243, 112, 46, 204, 146, 211, 141, 111, 49, 178, 236, 14, 80,
 	175, 241, 19, 77, 206, 144, 114, 44, 109, 51, 209, 143, 12, 82, 176, 238,
 	50, 108, 142, 208, 83, 13, 239, 177, 240, 174, 76, 18, 145, 207, 45, 115,
 	202, 148, 118, 40, 171, 245, 23, 73, 8, 86, 180, 234, 105, 55, 213, 139,
 	87, 9, 235, 181, 54, 104, 138, 212, 149, 203, 41, 119, 244, 170, 72, 22,
 	233, 183, 85, 11, 136, 214, 52, 106, 43, 117, 151, 201, 74, 20, 246, 168,
 	116, 42, 200, 150, 21, 75, 169, 247, 182, 232, 10, 84, 215, 137, 107, 53
 };
 
 static void w1_delay(unsigned long tm)
 {
 	udelay(tm * w1_delay_parm);
 }
 
 static void w1_write_bit(struct w1_master *dev, int bit);
 static u8 w1_read_bit(struct w1_master *dev);
 
 /**
  * w1_touch_bit() - Generates a write-0 or write-1 cycle and samples the level.
  * @dev:	the master device
  * @bit:	0 - write a 0, 1 - write a 0 read the level
  */
 static u8 w1_touch_bit(struct w1_master *dev, int bit)
 {
 	if (dev->bus_master->touch_bit)
 		return dev->bus_master->touch_bit(dev->bus_master->data, bit);
 	else if (bit)
 		return w1_read_bit(dev);
 	else {
 		w1_write_bit(dev, 0);
 		return 0;
 	}
 }
 
 /**
  * w1_write_bit() - Generates a write-0 or write-1 cycle.
  * @dev:	the master device
  * @bit:	bit to write
  *
  * Only call if dev->bus_master->touch_bit is NULL
  */
 static void w1_write_bit(struct w1_master *dev, int bit)
 {
 	unsigned long flags = 0;
 
 	if(w1_disable_irqs) local_irq_save(flags);
 
 	if (bit) {
 		dev->bus_master->write_bit(dev->bus_master->data, 0);
 		w1_delay(6);
 		dev->bus_master->write_bit(dev->bus_master->data, 1);
 		w1_delay(64);
 	} else {
 		dev->bus_master->write_bit(dev->bus_master->data, 0);
 		w1_delay(60);
 		dev->bus_master->write_bit(dev->bus_master->data, 1);
 		w1_delay(10);
 	}
 
 	if(w1_disable_irqs) local_irq_restore(flags);
 }
 
 /**
  * w1_pre_write() - pre-write operations
  * @dev:	the master device
  *
  * Pre-write operation, currently only supporting strong pullups.
  * Program the hardware for a strong pullup, if one has been requested and
  * the hardware supports it.
  */
 static void w1_pre_write(struct w1_master *dev)
 {
 	if (dev->pullup_duration &&
 		dev->enable_pullup && dev->bus_master->set_pullup) {
 		dev->bus_master->set_pullup(dev->bus_master->data,
 			dev->pullup_duration);
 	}
 }
 
 /**
  * w1_post_write() - post-write options
  * @dev:	the master device
  *
  * Post-write operation, currently only supporting strong pullups.
  * If a strong pullup was requested, clear it if the hardware supports
  * them, or execute the delay otherwise, in either case clear the request.
  */
 static void w1_post_write(struct w1_master *dev)
 {
 	if (dev->pullup_duration) {
 		if (dev->enable_pullup && dev->bus_master->set_pullup)
 			dev->bus_master->set_pullup(dev->bus_master->data, 0);
 		else
 			msleep(dev->pullup_duration);
 		dev->pullup_duration = 0;
 	}
 }
 
 /**
  * w1_write_8() - Writes 8 bits.
  * @dev:	the master device
  * @byte:	the byte to write
  */
 void w1_write_8(struct w1_master *dev, u8 byte)
 {
 	int i;
 
 	if (dev->bus_master->write_byte) {
 		w1_pre_write(dev);
 		dev->bus_master->write_byte(dev->bus_master->data, byte);
 	}
 	else
 		for (i = 0; i < 8; ++i) {
 			if (i == 7)
 				w1_pre_write(dev);
 			w1_touch_bit(dev, (byte >> i) & 0x1);
 		}
 	w1_post_write(dev);
 }
 EXPORT_SYMBOL_GPL(w1_write_8);
 
 
 /**
  * w1_read_bit() - Generates a write-1 cycle and samples the level.
  * @dev:	the master device
  *
  * Only call if dev->bus_master->touch_bit is NULL
  */
 static u8 w1_read_bit(struct w1_master *dev)
 {
 	int result;
 	unsigned long flags = 0;
 
 	/* sample timing is critical here */
 	local_irq_save(flags);
 	dev->bus_master->write_bit(dev->bus_master->data, 0);
 	w1_delay(6);
 	dev->bus_master->write_bit(dev->bus_master->data, 1);
 	w1_delay(9);
 
 	result = dev->bus_master->read_bit(dev->bus_master->data);
 	local_irq_restore(flags);
 
 	w1_delay(55);
 
 	return result & 0x1;
 }
 
 /**
  * w1_triplet() - * Does a triplet - used for searching ROM addresses.
  * @dev:	the master device
  * @bdir:	the bit to write if both id_bit and comp_bit are 0
  *
  * Return bits:
  *  bit 0 = id_bit
  *  bit 1 = comp_bit
  *  bit 2 = dir_taken
  * If both bits 0 & 1 are set, the search should be restarted.
  *
  * Return:        bit fields - see above
  */
 u8 w1_triplet(struct w1_master *dev, int bdir)
 {
 	if (dev->bus_master->triplet)
 		return dev->bus_master->triplet(dev->bus_master->data, bdir);
 	else {
 		u8 id_bit   = w1_touch_bit(dev, 1);
 		u8 comp_bit = w1_touch_bit(dev, 1);
 		u8 retval;
 
 		if (id_bit && comp_bit)
 			return 0x03;  /* error */
 
 		if (!id_bit && !comp_bit) {
 			/* Both bits are valid, take the direction given */
 			retval = bdir ? 0x04 : 0;
 		} else {
 			/* Only one bit is valid, take that direction */
 			bdir = id_bit;
 			retval = id_bit ? 0x05 : 0x02;
 		}
 
 		if (dev->bus_master->touch_bit)
 			w1_touch_bit(dev, bdir);
 		else
 			w1_write_bit(dev, bdir);
 		return retval;
 	}
 }
+EXPORT_SYMBOL_GPL(w1_triplet);
 
 /**
  * w1_read_8() - Reads 8 bits.
  * @dev:	the master device
  *
  * Return:        the byte read
  */
 u8 w1_read_8(struct w1_master *dev)
 {
 	int i;
 	u8 res = 0;
 
 	if (dev->bus_master->read_byte)
 		res = dev->bus_master->read_byte(dev->bus_master->data);
 	else
 		for (i = 0; i < 8; ++i)
 			res |= (w1_touch_bit(dev,1) << i);
 
 	return res;
 }
 EXPORT_SYMBOL_GPL(w1_read_8);
 
 /**
  * w1_write_block() - Writes a series of bytes.
  * @dev:	the master device
  * @buf:	pointer to the data to write
  * @len:	the number of bytes to write
  */
 void w1_write_block(struct w1_master *dev, const u8 *buf, int len)
 {
 	int i;
 
 	if (dev->bus_master->write_block) {
 		w1_pre_write(dev);
 		dev->bus_master->write_block(dev->bus_master->data, buf, len);
 	}
 	else
 		for (i = 0; i < len; ++i)
 			w1_write_8(dev, buf[i]); /* calls w1_pre_write */
 	w1_post_write(dev);
 }
 EXPORT_SYMBOL_GPL(w1_write_block);
 
 /**
  * w1_touch_block() - Touches a series of bytes.
  * @dev:	the master device
  * @buf:	pointer to the data to write
  * @len:	the number of bytes to write
  */
 void w1_touch_block(struct w1_master *dev, u8 *buf, int len)
 {
 	int i, j;
 	u8 tmp;
 
 	for (i = 0; i < len; ++i) {
 		tmp = 0;
 		for (j = 0; j < 8; ++j) {
 			if (j == 7)
 				w1_pre_write(dev);
 			tmp |= w1_touch_bit(dev, (buf[i] >> j) & 0x1) << j;
 		}
 
 		buf[i] = tmp;
 	}
 }
 EXPORT_SYMBOL_GPL(w1_touch_block);
 
 /**
  * w1_read_block() - Reads a series of bytes.
  * @dev:	the master device
  * @buf:	pointer to the buffer to fill
  * @len:	the number of bytes to read
  * Return:	the number of bytes read
  */
 u8 w1_read_block(struct w1_master *dev, u8 *buf, int len)
 {
 	int i;
 	u8 ret;
 
 	if (dev->bus_master->read_block)
 		ret = dev->bus_master->read_block(dev->bus_master->data, buf, len);
 	else {
 		for (i = 0; i < len; ++i)
 			buf[i] = w1_read_8(dev);
 		ret = len;
 	}
 
 	return ret;
 }
 EXPORT_SYMBOL_GPL(w1_read_block);
 
 /**
  * w1_reset_bus() - Issues a reset bus sequence.
  * @dev:	the master device
  * Return:	0=Device present, 1=No device present or error
  */
 int w1_reset_bus(struct w1_master *dev)
 {
 	int result;
 	unsigned long flags = 0;
 
 	if(w1_disable_irqs) local_irq_save(flags);
 
 	if (dev->bus_master->reset_bus)
 		result = dev->bus_master->reset_bus(dev->bus_master->data) & 0x1;
 	else {
 		dev->bus_master->write_bit(dev->bus_master->data, 0);
 		/* minimum 480, max ? us
 		 * be nice and sleep, except 18b20 spec lists 960us maximum,
 		 * so until we can sleep with microsecond accuracy, spin.
 		 * Feel free to come up with some other way to give up the
 		 * cpu for such a short amount of time AND get it back in
 		 * the maximum amount of time.
 		 */
 		w1_delay(500);
 		dev->bus_master->write_bit(dev->bus_master->data, 1);
 		w1_delay(70);
 
 		result = dev->bus_master->read_bit(dev->bus_master->data) & 0x1;
 		/* minimum 70 (above) + 430 = 500 us
 		 * There aren't any timing requirements between a reset and
 		 * the following transactions.  Sleeping is safe here.
 		 */
 		/* w1_delay(430); min required time */
 		msleep(1);
 	}
 
 	if(w1_disable_irqs) local_irq_restore(flags);
 
 	return result;
 }
 EXPORT_SYMBOL_GPL(w1_reset_bus);
 
 u8 w1_calc_crc8(u8 * data, int len)
 {
 	u8 crc = 0;
 
 	while (len--)
 		crc = w1_crc8_table[crc ^ *data++];
 
 	return crc;
 }
 EXPORT_SYMBOL_GPL(w1_calc_crc8);
 
 void w1_search_devices(struct w1_master *dev, u8 search_type, w1_slave_found_callback cb)
 {
 	dev->attempts++;
 	if (dev->bus_master->search)
 		dev->bus_master->search(dev->bus_master->data, dev,
 			search_type, cb);
 	else
 		w1_search(dev, search_type, cb);
 }
 
 /**
  * w1_reset_select_slave() - reset and select a slave
  * @sl:		the slave to select
  *
  * Resets the bus and then selects the slave by sending either a skip rom
  * or a rom match.  A skip rom is issued if there is only one device
  * registered on the bus.
  * The w1 master lock must be held.
  *
  * Return:	0=success, anything else=error
  */
 int w1_reset_select_slave(struct w1_slave *sl)
 {
 	if (w1_reset_bus(sl->master))
 		return -1;
 
 	if (sl->master->slave_count == 1)
 		w1_write_8(sl->master, W1_SKIP_ROM);
 	else {
 		u8 match[9] = {W1_MATCH_ROM, };
 		u64 rn = le64_to_cpu(*((u64*)&sl->reg_num));
 
 		memcpy(&match[1], &rn, 8);
 		w1_write_block(sl->master, match, 9);
 	}
 	return 0;
 }
 EXPORT_SYMBOL_GPL(w1_reset_select_slave);
 
 /**
  * w1_reset_resume_command() - resume instead of another match ROM
  * @dev:	the master device
  *
  * When the workflow with a slave amongst many requires several
  * successive commands a reset between each, this function is similar
  * to doing a reset then a match ROM for the last matched ROM. The
  * advantage being that the matched ROM step is skipped in favor of the
  * resume command. The slave must support the command of course.
  *
  * If the bus has only one slave, traditionnaly the match ROM is skipped
  * and a "SKIP ROM" is done for efficiency. On multi-slave busses, this
  * doesn't work of course, but the resume command is the next best thing.
  *
  * The w1 master lock must be held.
  */
 int w1_reset_resume_command(struct w1_master *dev)
 {
 	if (w1_reset_bus(dev))
 		return -1;
 
 	/* This will make only the last matched slave perform a skip ROM. */
 	w1_write_8(dev, W1_RESUME_CMD);
 	return 0;
 }
 EXPORT_SYMBOL_GPL(w1_reset_resume_command);
 
 /**
  * w1_next_pullup() - register for a strong pullup
  * @dev:	the master device
  * @delay:	time in milliseconds
  *
  * Put out a strong pull-up of the specified duration after the next write
  * operation.  Not all hardware supports strong pullups.  Hardware that
  * doesn't support strong pullups will sleep for the given time after the
  * write operation without a strong pullup.  This is a one shot request for
  * the next write, specifying zero will clear a previous request.
  * The w1 master lock must be held.
  *
  * Return:	0=success, anything else=error
  */
 void w1_next_pullup(struct w1_master *dev, int delay)
 {
 	dev->pullup_duration = delay;
 }
 EXPORT_SYMBOL_GPL(w1_next_pullup);
diff --git a/drivers/w1/w1_log.h b/drivers/w1/w1_log.h
index f9eecff23b8d..dd1422b6afbb 100644
--- a/drivers/w1/w1_log.h
+++ b/drivers/w1/w1_log.h
@@ -1,38 +1,31 @@
 /*
- *	w1_log.h
- *
  * Copyright (c) 2004 Evgeniy Polyakov <zbr@ioremap.net>
  *
- *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
  * the Free Software Foundation; either version 2 of the License, or
  * (at your option) any later version.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
  */
 
 #ifndef __W1_LOG_H
 #define __W1_LOG_H
 
 #define DEBUG
 
 #ifdef W1_DEBUG
 #  define assert(expr) do {} while (0)
 #else
 #  define assert(expr) \
         if(unlikely(!(expr))) {				        \
 		pr_err("Assertion failed! %s,%s,%s,line=%d\n",	\
 		#expr, __FILE__, __func__, __LINE__);		\
         }
 #endif
 
 #endif /* __W1_LOG_H */
 
diff --git a/drivers/w1/w1_netlink.c b/drivers/w1/w1_netlink.c
index 881597a191b8..49e520ca79c5 100644
--- a/drivers/w1/w1_netlink.c
+++ b/drivers/w1/w1_netlink.c
@@ -1,758 +1,751 @@
 /*
- * w1_netlink.c
- *
  * Copyright (c) 2003 Evgeniy Polyakov <zbr@ioremap.net>
  *
- *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
  * the Free Software Foundation; either version 2 of the License, or
  * (at your option) any later version.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
  */
 
 #include <linux/slab.h>
 #include <linux/skbuff.h>
 #include <linux/netlink.h>
 #include <linux/connector.h>
 
 #include "w1.h"
 #include "w1_log.h"
 #include "w1_netlink.h"
 
 #if defined(CONFIG_W1_CON) && (defined(CONFIG_CONNECTOR) || (defined(CONFIG_CONNECTOR_MODULE) && defined(CONFIG_W1_MODULE)))
 
 #define MIN(a, b)                   (((a) < (b)) ? (a) : (b))
 
 /* Bundle together everything required to process a request in one memory
  * allocation.
  */
 struct w1_cb_block {
 	atomic_t refcnt;
 	u32 portid; /* Sending process port ID */
 	/* maximum value for first_cn->len */
 	u16 maxlen;
 	/* pointers to building up the reply message */
 	struct cn_msg *first_cn; /* fixed once the structure is populated */
 	struct cn_msg *cn; /* advances as cn_msg is appeneded */
 	struct w1_netlink_msg *msg; /* advances as w1_netlink_msg is appened */
 	struct w1_netlink_cmd *cmd; /* advances as cmds are appened */
 	struct w1_netlink_msg *cur_msg; /* currently message being processed */
 	/* copy of the original request follows */
 	struct cn_msg request_cn;
 	/* followed by variable length:
 	 * cn_msg, data (w1_netlink_msg and w1_netlink_cmd)
 	 * one or more struct w1_cb_node
 	 * reply first_cn, data (w1_netlink_msg and w1_netlink_cmd)
 	 */
 };
 struct w1_cb_node {
 	struct w1_async_cmd async;
 	/* pointers within w1_cb_block and cn data */
 	struct w1_cb_block *block;
 	struct w1_netlink_msg *msg;
 	struct w1_slave *sl;
 	struct w1_master *dev;
 };
 
 /**
  * w1_reply_len() - calculate current reply length, compare to maxlen
  * @block: block to calculate
  *
  * Calculates the current message length including possible multiple
  * cn_msg and data, excludes the first sizeof(struct cn_msg).  Direclty
  * compariable to maxlen and usable to send the message.
  */
 static u16 w1_reply_len(struct w1_cb_block *block)
 {
 	if (!block->cn)
 		return 0;
 	return (u8 *)block->cn - (u8 *)block->first_cn + block->cn->len;
 }
 
 static void w1_unref_block(struct w1_cb_block *block)
 {
 	if (atomic_sub_return(1, &block->refcnt) == 0) {
 		u16 len = w1_reply_len(block);
 		if (len) {
 			cn_netlink_send_mult(block->first_cn, len,
 				block->portid, 0, GFP_KERNEL);
 		}
 		kfree(block);
 	}
 }
 
 /**
  * w1_reply_make_space() - send message if needed to make space
  * @block: block to make space on
  * @space: how many bytes requested
  *
  * Verify there is enough room left for the caller to add "space" bytes to the
  * message, if there isn't send the message and reset.
  */
 static void w1_reply_make_space(struct w1_cb_block *block, u16 space)
 {
 	u16 len = w1_reply_len(block);
 	if (len + space >= block->maxlen) {
 		cn_netlink_send_mult(block->first_cn, len, block->portid, 0, GFP_KERNEL);
 		block->first_cn->len = 0;
 		block->cn = NULL;
 		block->msg = NULL;
 		block->cmd = NULL;
 	}
 }
 
 /* Early send when replies aren't bundled. */
 static void w1_netlink_check_send(struct w1_cb_block *block)
 {
 	if (!(block->request_cn.flags & W1_CN_BUNDLE) && block->cn)
 		w1_reply_make_space(block, block->maxlen);
 }
 
 /**
  * w1_netlink_setup_msg() - prepare to write block->msg
  * @block: block to operate on
  * @ack: determines if cn can be reused
  *
  * block->cn will be setup with the correct ack, advancing if needed
  * block->cn->len does not include space for block->msg
  * block->msg advances but remains uninitialized
  */
 static void w1_netlink_setup_msg(struct w1_cb_block *block, u32 ack)
 {
 	if (block->cn && block->cn->ack == ack) {
 		block->msg = (struct w1_netlink_msg *)(block->cn->data + block->cn->len);
 	} else {
 		/* advance or set to data */
 		if (block->cn)
 			block->cn = (struct cn_msg *)(block->cn->data +
 				block->cn->len);
 		else
 			block->cn = block->first_cn;
 
 		memcpy(block->cn, &block->request_cn, sizeof(*block->cn));
 		block->cn->len = 0;
 		block->cn->ack = ack;
 		block->msg = (struct w1_netlink_msg *)block->cn->data;
 	}
 }
 
 /* Append cmd to msg, include cmd->data as well.  This is because
  * any following data goes with the command and in the case of a read is
  * the results.
  */
 static void w1_netlink_queue_cmd(struct w1_cb_block *block,
 	struct w1_netlink_cmd *cmd)
 {
 	u32 space;
 	w1_reply_make_space(block, sizeof(struct cn_msg) +
 		sizeof(struct w1_netlink_msg) + sizeof(*cmd) + cmd->len);
 
 	/* There's a status message sent after each command, so no point
 	 * in trying to bundle this cmd after an existing one, because
 	 * there won't be one.  Allocate and copy over a new cn_msg.
 	 */
 	w1_netlink_setup_msg(block, block->request_cn.seq + 1);
 	memcpy(block->msg, block->cur_msg, sizeof(*block->msg));
 	block->cn->len += sizeof(*block->msg);
 	block->msg->len = 0;
 	block->cmd = (struct w1_netlink_cmd *)(block->msg->data);
 
 	space = sizeof(*cmd) + cmd->len;
 	if (block->cmd != cmd)
 		memcpy(block->cmd, cmd, space);
 	block->cn->len += space;
 	block->msg->len += space;
 }
 
 /* Append req_msg and req_cmd, no other commands and no data from req_cmd are
  * copied.
  */
 static void w1_netlink_queue_status(struct w1_cb_block *block,
 	struct w1_netlink_msg *req_msg, struct w1_netlink_cmd *req_cmd,
 	int error)
 {
 	u16 space = sizeof(struct cn_msg) + sizeof(*req_msg) + sizeof(*req_cmd);
 	w1_reply_make_space(block, space);
 	w1_netlink_setup_msg(block, block->request_cn.ack);
 
 	memcpy(block->msg, req_msg, sizeof(*req_msg));
 	block->cn->len += sizeof(*req_msg);
 	block->msg->len = 0;
 	block->msg->status = (u8)-error;
 	if (req_cmd) {
 		struct w1_netlink_cmd *cmd = (struct w1_netlink_cmd *)block->msg->data;
 		memcpy(cmd, req_cmd, sizeof(*cmd));
 		block->cn->len += sizeof(*cmd);
 		block->msg->len += sizeof(*cmd);
 		cmd->len = 0;
 	}
 	w1_netlink_check_send(block);
 }
 
 /**
  * w1_netlink_send_error() - sends the error message now
  * @cn: original cn_msg
  * @msg: original w1_netlink_msg
  * @portid: where to send it
  * @error: error status
  *
  * Use when a block isn't available to queue the message to and cn, msg
  * might not be contiguous.
  */
 static void w1_netlink_send_error(struct cn_msg *cn, struct w1_netlink_msg *msg,
 	int portid, int error)
 {
 	struct {
 		struct cn_msg cn;
 		struct w1_netlink_msg msg;
 	} packet;
 	memcpy(&packet.cn, cn, sizeof(packet.cn));
 	memcpy(&packet.msg, msg, sizeof(packet.msg));
 	packet.cn.len = sizeof(packet.msg);
 	packet.msg.len = 0;
 	packet.msg.status = (u8)-error;
 	cn_netlink_send(&packet.cn, portid, 0, GFP_KERNEL);
 }
 
 /**
  * w1_netlink_send() - sends w1 netlink notifications
  * @dev: w1_master the even is associated with or for
  * @msg: w1_netlink_msg message to be sent
  *
  * This are notifications generated from the kernel.
  */
 void w1_netlink_send(struct w1_master *dev, struct w1_netlink_msg *msg)
 {
 	struct {
 		struct cn_msg cn;
 		struct w1_netlink_msg msg;
 	} packet;
 	memset(&packet, 0, sizeof(packet));
 
 	packet.cn.id.idx = CN_W1_IDX;
 	packet.cn.id.val = CN_W1_VAL;
 
 	packet.cn.seq = dev->seq++;
 	packet.cn.len = sizeof(*msg);
 
 	memcpy(&packet.msg, msg, sizeof(*msg));
 	packet.msg.len = 0;
 
 	cn_netlink_send(&packet.cn, 0, 0, GFP_KERNEL);
 }
 
 static void w1_send_slave(struct w1_master *dev, u64 rn)
 {
 	struct w1_cb_block *block = dev->priv;
 	struct w1_netlink_cmd *cache_cmd = block->cmd;
 	u64 *data;
 
 	w1_reply_make_space(block, sizeof(*data));
 
 	/* Add cmd back if the packet was sent */
 	if (!block->cmd) {
 		cache_cmd->len = 0;
 		w1_netlink_queue_cmd(block, cache_cmd);
 	}
 
 	data = (u64 *)(block->cmd->data + block->cmd->len);
 
 	*data = rn;
 	block->cn->len += sizeof(*data);
 	block->msg->len += sizeof(*data);
 	block->cmd->len += sizeof(*data);
 }
 
 static void w1_found_send_slave(struct w1_master *dev, u64 rn)
 {
 	/* update kernel slave list */
 	w1_slave_found(dev, rn);
 
 	w1_send_slave(dev, rn);
 }
 
 /* Get the current slave list, or search (with or without alarm) */
 static int w1_get_slaves(struct w1_master *dev, struct w1_netlink_cmd *req_cmd)
 {
 	struct w1_slave *sl;
 
 	req_cmd->len = 0;
 	w1_netlink_queue_cmd(dev->priv, req_cmd);
 
 	if (req_cmd->cmd == W1_CMD_LIST_SLAVES) {
 		u64 rn;
 		mutex_lock(&dev->list_mutex);
 		list_for_each_entry(sl, &dev->slist, w1_slave_entry) {
 			memcpy(&rn, &sl->reg_num, sizeof(rn));
 			w1_send_slave(dev, rn);
 		}
 		mutex_unlock(&dev->list_mutex);
 	} else {
 		w1_search_process_cb(dev, req_cmd->cmd == W1_CMD_ALARM_SEARCH ?
 			W1_ALARM_SEARCH : W1_SEARCH, w1_found_send_slave);
 	}
 
 	return 0;
 }
 
 static int w1_process_command_io(struct w1_master *dev,
 	struct w1_netlink_cmd *cmd)
 {
 	int err = 0;
 
 	switch (cmd->cmd) {
 	case W1_CMD_TOUCH:
 		w1_touch_block(dev, cmd->data, cmd->len);
 		w1_netlink_queue_cmd(dev->priv, cmd);
 		break;
 	case W1_CMD_READ:
 		w1_read_block(dev, cmd->data, cmd->len);
 		w1_netlink_queue_cmd(dev->priv, cmd);
 		break;
 	case W1_CMD_WRITE:
 		w1_write_block(dev, cmd->data, cmd->len);
 		break;
 	default:
 		err = -EINVAL;
 		break;
 	}
 
 	return err;
 }
 
 static int w1_process_command_addremove(struct w1_master *dev,
 	struct w1_netlink_cmd *cmd)
 {
 	struct w1_slave *sl;
 	int err = 0;
 	struct w1_reg_num *id;
 
 	if (cmd->len != sizeof(*id))
 		return -EINVAL;
 
 	id = (struct w1_reg_num *)cmd->data;
 
 	sl = w1_slave_search_device(dev, id);
 	switch (cmd->cmd) {
 	case W1_CMD_SLAVE_ADD:
 		if (sl)
 			err = -EINVAL;
 		else
 			err = w1_attach_slave_device(dev, id);
 		break;
 	case W1_CMD_SLAVE_REMOVE:
 		if (sl)
 			w1_slave_detach(sl);
 		else
 			err = -EINVAL;
 		break;
 	default:
 		err = -EINVAL;
 		break;
 	}
 
 	return err;
 }
 
 static int w1_process_command_master(struct w1_master *dev,
 	struct w1_netlink_cmd *req_cmd)
 {
 	int err = -EINVAL;
 
 	/* drop bus_mutex for search (does it's own locking), and add/remove
 	 * which doesn't use the bus
 	 */
 	switch (req_cmd->cmd) {
 	case W1_CMD_SEARCH:
 	case W1_CMD_ALARM_SEARCH:
 	case W1_CMD_LIST_SLAVES:
 		mutex_unlock(&dev->bus_mutex);
 		err = w1_get_slaves(dev, req_cmd);
 		mutex_lock(&dev->bus_mutex);
 		break;
 	case W1_CMD_READ:
 	case W1_CMD_WRITE:
 	case W1_CMD_TOUCH:
 		err = w1_process_command_io(dev, req_cmd);
 		break;
 	case W1_CMD_RESET:
 		err = w1_reset_bus(dev);
 		break;
 	case W1_CMD_SLAVE_ADD:
 	case W1_CMD_SLAVE_REMOVE:
 		mutex_unlock(&dev->bus_mutex);
 		mutex_lock(&dev->mutex);
 		err = w1_process_command_addremove(dev, req_cmd);
 		mutex_unlock(&dev->mutex);
 		mutex_lock(&dev->bus_mutex);
 		break;
 	default:
 		err = -EINVAL;
 		break;
 	}
 
 	return err;
 }
 
 static int w1_process_command_slave(struct w1_slave *sl,
 		struct w1_netlink_cmd *cmd)
 {
 	dev_dbg(&sl->master->dev, "%s: %02x.%012llx.%02x: cmd=%02x, len=%u.\n",
 		__func__, sl->reg_num.family, (unsigned long long)sl->reg_num.id,
 		sl->reg_num.crc, cmd->cmd, cmd->len);
 
 	return w1_process_command_io(sl->master, cmd);
 }
 
 static int w1_process_command_root(struct cn_msg *req_cn, u32 portid)
 {
 	struct w1_master *dev;
 	struct cn_msg *cn;
 	struct w1_netlink_msg *msg;
 	u32 *id;
 
 	cn = kmalloc(PAGE_SIZE, GFP_KERNEL);
 	if (!cn)
 		return -ENOMEM;
 
 	cn->id.idx = CN_W1_IDX;
 	cn->id.val = CN_W1_VAL;
 
 	cn->seq = req_cn->seq;
 	cn->ack = req_cn->seq + 1;
 	cn->len = sizeof(struct w1_netlink_msg);
 	msg = (struct w1_netlink_msg *)cn->data;
 
 	msg->type = W1_LIST_MASTERS;
 	msg->status = 0;
 	msg->len = 0;
 	id = (u32 *)msg->data;
 
 	mutex_lock(&w1_mlock);
 	list_for_each_entry(dev, &w1_masters, w1_master_entry) {
 		if (cn->len + sizeof(*id) > PAGE_SIZE - sizeof(struct cn_msg)) {
 			cn_netlink_send(cn, portid, 0, GFP_KERNEL);
 			cn->len = sizeof(struct w1_netlink_msg);
 			msg->len = 0;
 			id = (u32 *)msg->data;
 		}
 
 		*id = dev->id;
 		msg->len += sizeof(*id);
 		cn->len += sizeof(*id);
 		id++;
 	}
 	cn_netlink_send(cn, portid, 0, GFP_KERNEL);
 	mutex_unlock(&w1_mlock);
 
 	kfree(cn);
 	return 0;
 }
 
 static void w1_process_cb(struct w1_master *dev, struct w1_async_cmd *async_cmd)
 {
 	struct w1_cb_node *node = container_of(async_cmd, struct w1_cb_node,
 		async);
 	u16 mlen = node->msg->len;
 	u16 len;
 	int err = 0;
 	struct w1_slave *sl = node->sl;
 	struct w1_netlink_cmd *cmd = (struct w1_netlink_cmd *)node->msg->data;
 
 	mutex_lock(&dev->bus_mutex);
 	dev->priv = node->block;
 	if (sl && w1_reset_select_slave(sl))
 		err = -ENODEV;
 	node->block->cur_msg = node->msg;
 
 	while (mlen && !err) {
 		if (cmd->len + sizeof(struct w1_netlink_cmd) > mlen) {
 			err = -E2BIG;
 			break;
 		}
 
 		if (sl)
 			err = w1_process_command_slave(sl, cmd);
 		else
 			err = w1_process_command_master(dev, cmd);
 		w1_netlink_check_send(node->block);
 
 		w1_netlink_queue_status(node->block, node->msg, cmd, err);
 		err = 0;
 
 		len = sizeof(*cmd) + cmd->len;
 		cmd = (struct w1_netlink_cmd *)((u8 *)cmd + len);
 		mlen -= len;
 	}
 
 	if (!cmd || err)
 		w1_netlink_queue_status(node->block, node->msg, cmd, err);
 
 	/* ref taken in w1_search_slave or w1_search_master_id when building
 	 * the block
 	 */
 	if (sl)
 		w1_unref_slave(sl);
 	else
 		atomic_dec(&dev->refcnt);
 	dev->priv = NULL;
 	mutex_unlock(&dev->bus_mutex);
 
 	mutex_lock(&dev->list_mutex);
 	list_del(&async_cmd->async_entry);
 	mutex_unlock(&dev->list_mutex);
 
 	w1_unref_block(node->block);
 }
 
 static void w1_list_count_cmds(struct w1_netlink_msg *msg, int *cmd_count,
 	u16 *slave_len)
 {
 	struct w1_netlink_cmd *cmd = (struct w1_netlink_cmd *)msg->data;
 	u16 mlen = msg->len;
 	u16 len;
 	int slave_list = 0;
 	while (mlen) {
 		if (cmd->len + sizeof(struct w1_netlink_cmd) > mlen)
 			break;
 
 		switch (cmd->cmd) {
 		case W1_CMD_SEARCH:
 		case W1_CMD_ALARM_SEARCH:
 		case W1_CMD_LIST_SLAVES:
 			++slave_list;
 		}
 		++*cmd_count;
 		len = sizeof(*cmd) + cmd->len;
 		cmd = (struct w1_netlink_cmd *)((u8 *)cmd + len);
 		mlen -= len;
 	}
 
 	if (slave_list) {
 		struct w1_master *dev = w1_search_master_id(msg->id.mst.id);
 		if (dev) {
 			/* Bytes, and likely an overstimate, and if it isn't
 			 * the results can still be split between packets.
 			 */
 			*slave_len += sizeof(struct w1_reg_num) * slave_list *
 				(dev->slave_count + dev->max_slave_count);
 			/* search incremented it */
 			atomic_dec(&dev->refcnt);
 		}
 	}
 }
 
 static void w1_cn_callback(struct cn_msg *cn, struct netlink_skb_parms *nsp)
 {
 	struct w1_netlink_msg *msg = (struct w1_netlink_msg *)(cn + 1);
 	struct w1_slave *sl;
 	struct w1_master *dev;
 	u16 msg_len;
 	u16 slave_len = 0;
 	int err = 0;
 	struct w1_cb_block *block = NULL;
 	struct w1_cb_node *node = NULL;
 	int node_count = 0;
 	int cmd_count = 0;
 
 	/* If any unknown flag is set let the application know, that way
 	 * applications can detect the absence of features in kernels that
 	 * don't know about them.  http://lwn.net/Articles/587527/
 	 */
 	if (cn->flags & ~(W1_CN_BUNDLE)) {
 		w1_netlink_send_error(cn, msg, nsp->portid, -EINVAL);
 		return;
 	}
 
 	/* Count the number of master or slave commands there are to allocate
 	 * space for one cb_node each.
 	 */
 	msg_len = cn->len;
 	while (msg_len && !err) {
 		if (msg->len + sizeof(struct w1_netlink_msg) > msg_len) {
 			err = -E2BIG;
 			break;
 		}
 
 		/* count messages for nodes and allocate any additional space
 		 * required for slave lists
 		 */
 		if (msg->type == W1_MASTER_CMD || msg->type == W1_SLAVE_CMD) {
 			++node_count;
 			w1_list_count_cmds(msg, &cmd_count, &slave_len);
 		}
 
 		msg_len -= sizeof(struct w1_netlink_msg) + msg->len;
 		msg = (struct w1_netlink_msg *)(((u8 *)msg) +
 			sizeof(struct w1_netlink_msg) + msg->len);
 	}
 	msg = (struct w1_netlink_msg *)(cn + 1);
 	if (node_count) {
 		int size;
 		int reply_size = sizeof(*cn) + cn->len + slave_len;
 		if (cn->flags & W1_CN_BUNDLE) {
 			/* bundling duplicats some of the messages */
 			reply_size += 2 * cmd_count * (sizeof(struct cn_msg) +
 				sizeof(struct w1_netlink_msg) +
 				sizeof(struct w1_netlink_cmd));
 		}
 		reply_size = MIN(CONNECTOR_MAX_MSG_SIZE, reply_size);
 
 		/* allocate space for the block, a copy of the original message,
 		 * one node per cmd to point into the original message,
 		 * space for replies which is the original message size plus
 		 * space for any list slave data and status messages
 		 * cn->len doesn't include itself which is part of the block
 		 * */
 		size =  /* block + original message */
 			sizeof(struct w1_cb_block) + sizeof(*cn) + cn->len +
 			/* space for nodes */
 			node_count * sizeof(struct w1_cb_node) +
 			/* replies */
 			sizeof(struct cn_msg) + reply_size;
 		block = kzalloc(size, GFP_KERNEL);
 		if (!block) {
 			/* if the system is already out of memory,
 			 * (A) will this work, and (B) would it be better
 			 * to not try?
 			 */
 			w1_netlink_send_error(cn, msg, nsp->portid, -ENOMEM);
 			return;
 		}
 		atomic_set(&block->refcnt, 1);
 		block->portid = nsp->portid;
 		memcpy(&block->request_cn, cn, sizeof(*cn) + cn->len);
 		node = (struct w1_cb_node *)(block->request_cn.data + cn->len);
 
 		/* Sneeky, when not bundling, reply_size is the allocated space
 		 * required for the reply, cn_msg isn't part of maxlen so
 		 * it should be reply_size - sizeof(struct cn_msg), however
 		 * when checking if there is enough space, w1_reply_make_space
 		 * is called with the full message size including cn_msg,
 		 * because it isn't known at that time if an additional cn_msg
 		 * will need to be allocated.  So an extra cn_msg is added
 		 * above in "size".
 		 */
 		block->maxlen = reply_size;
 		block->first_cn = (struct cn_msg *)(node + node_count);
 		memset(block->first_cn, 0, sizeof(*block->first_cn));
 	}
 
 	msg_len = cn->len;
 	while (msg_len && !err) {
 
 		dev = NULL;
 		sl = NULL;
 
 		if (msg->len + sizeof(struct w1_netlink_msg) > msg_len) {
 			err = -E2BIG;
 			break;
 		}
 
 		/* execute on this thread, no need to process later */
 		if (msg->type == W1_LIST_MASTERS) {
 			err = w1_process_command_root(cn, nsp->portid);
 			goto out_cont;
 		}
 
 		/* All following message types require additional data,
 		 * check here before references are taken.
 		 */
 		if (!msg->len) {
 			err = -EPROTO;
 			goto out_cont;
 		}
 
 		/* both search calls take references */
 		if (msg->type == W1_MASTER_CMD) {
 			dev = w1_search_master_id(msg->id.mst.id);
 		} else if (msg->type == W1_SLAVE_CMD) {
 			sl = w1_search_slave((struct w1_reg_num *)msg->id.id);
 			if (sl)
 				dev = sl->master;
 		} else {
 			pr_notice("%s: cn: %x.%x, wrong type: %u, len: %u.\n",
 				__func__, cn->id.idx, cn->id.val,
 				msg->type, msg->len);
 			err = -EPROTO;
 			goto out_cont;
 		}
 
 		if (!dev) {
 			err = -ENODEV;
 			goto out_cont;
 		}
 
 		err = 0;
 
 		atomic_inc(&block->refcnt);
 		node->async.cb = w1_process_cb;
 		node->block = block;
 		node->msg = (struct w1_netlink_msg *)((u8 *)&block->request_cn +
 			(size_t)((u8 *)msg - (u8 *)cn));
 		node->sl = sl;
 		node->dev = dev;
 
 		mutex_lock(&dev->list_mutex);
 		list_add_tail(&node->async.async_entry, &dev->async_list);
 		wake_up_process(dev->thread);
 		mutex_unlock(&dev->list_mutex);
 		++node;
 
 out_cont:
 		/* Can't queue because that modifies block and another
 		 * thread could be processing the messages by now and
 		 * there isn't a lock, send directly.
 		 */
 		if (err)
 			w1_netlink_send_error(cn, msg, nsp->portid, err);
 		msg_len -= sizeof(struct w1_netlink_msg) + msg->len;
 		msg = (struct w1_netlink_msg *)(((u8 *)msg) +
 			sizeof(struct w1_netlink_msg) + msg->len);
 
 		/*
 		 * Let's allow requests for nonexisting devices.
 		 */
 		if (err == -ENODEV)
 			err = 0;
 	}
 	if (block)
 		w1_unref_block(block);
 }
 
 int w1_init_netlink(void)
 {
 	struct cb_id w1_id = {.idx = CN_W1_IDX, .val = CN_W1_VAL};
 
 	return cn_add_callback(&w1_id, "w1", &w1_cn_callback);
 }
 
 void w1_fini_netlink(void)
 {
 	struct cb_id w1_id = {.idx = CN_W1_IDX, .val = CN_W1_VAL};
 
 	cn_del_callback(&w1_id);
 }
 #else
 void w1_netlink_send(struct w1_master *dev, struct w1_netlink_msg *cn)
 {
 }
 
 int w1_init_netlink(void)
 {
 	return 0;
 }
 
 void w1_fini_netlink(void)
 {
 }
 #endif
diff --git a/drivers/w1/w1_netlink.h b/drivers/w1/w1_netlink.h
index c99a9ce05e62..b389e5ff5fa5 100644
--- a/drivers/w1/w1_netlink.h
+++ b/drivers/w1/w1_netlink.h
@@ -1,147 +1,140 @@
 /*
- * w1_netlink.h
- *
  * Copyright (c) 2003 Evgeniy Polyakov <zbr@ioremap.net>
  *
- *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
  * the Free Software Foundation; either version 2 of the License, or
  * (at your option) any later version.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
  */
 
 #ifndef __W1_NETLINK_H
 #define __W1_NETLINK_H
 
 #include <asm/types.h>
 #include <linux/connector.h>
 
 #include "w1.h"
 
 /**
  * enum w1_cn_msg_flags - bitfield flags for struct cn_msg.flags
  *
  * @W1_CN_BUNDLE: Request bundling replies into fewer messagse.  Be prepared
  * to handle multiple struct cn_msg, struct w1_netlink_msg, and
  * struct w1_netlink_cmd in one packet.
  */
 enum w1_cn_msg_flags {
 	W1_CN_BUNDLE = 1,
 };
 
 /**
  * enum w1_netlink_message_types - message type
  *
  * @W1_SLAVE_ADD: notification that a slave device was added
  * @W1_SLAVE_REMOVE: notification that a slave device was removed
  * @W1_MASTER_ADD: notification that a new bus master was added
  * @W1_MASTER_REMOVE: notification that a bus masterwas removed
  * @W1_MASTER_CMD: initiate operations on a specific master
  * @W1_SLAVE_CMD: sends reset, selects the slave, then does a read/write/touch
  * operation
  * @W1_LIST_MASTERS: used to determine the bus master identifiers
  */
 enum w1_netlink_message_types {
 	W1_SLAVE_ADD = 0,
 	W1_SLAVE_REMOVE,
 	W1_MASTER_ADD,
 	W1_MASTER_REMOVE,
 	W1_MASTER_CMD,
 	W1_SLAVE_CMD,
 	W1_LIST_MASTERS,
 };
 
 /**
  * struct w1_netlink_msg - holds w1 message type, id, and result
  *
  * @type: one of enum w1_netlink_message_types
  * @status: kernel feedback for success 0 or errno failure value
  * @len: length of data following w1_netlink_msg
  * @id: union holding master bus id (msg.id) and slave device id (id[8]).
  * @data: start address of any following data
  *
  * The base message structure for w1 messages over netlink.
  * The netlink connector data sequence is, struct nlmsghdr, struct cn_msg,
  * then one or more struct w1_netlink_msg (each with optional data).
  */
 struct w1_netlink_msg
 {
 	__u8				type;
 	__u8				status;
 	__u16				len;
 	union {
 		__u8			id[8];
 		struct w1_mst {
 			__u32		id;
 			__u32		res;
 		} mst;
 	} id;
 	__u8				data[0];
 };
 
 /**
  * enum w1_commands - commands available for master or slave operations
  *
  * @W1_CMD_READ: read len bytes
  * @W1_CMD_WRITE: write len bytes
  * @W1_CMD_SEARCH: initiate a standard search, returns only the slave
  * devices found during that search
  * @W1_CMD_ALARM_SEARCH: search for devices that are currently alarming
  * @W1_CMD_TOUCH: Touches a series of bytes.
  * @W1_CMD_RESET: sends a bus reset on the given master
  * @W1_CMD_SLAVE_ADD: adds a slave to the given master,
  * 8 byte slave id at data[0]
  * @W1_CMD_SLAVE_REMOVE: removes a slave to the given master,
  * 8 byte slave id at data[0]
  * @W1_CMD_LIST_SLAVES: list of slaves registered on this master
  * @W1_CMD_MAX: number of available commands
  */
 enum w1_commands {
 	W1_CMD_READ = 0,
 	W1_CMD_WRITE,
 	W1_CMD_SEARCH,
 	W1_CMD_ALARM_SEARCH,
 	W1_CMD_TOUCH,
 	W1_CMD_RESET,
 	W1_CMD_SLAVE_ADD,
 	W1_CMD_SLAVE_REMOVE,
 	W1_CMD_LIST_SLAVES,
 	W1_CMD_MAX
 };
 
 /**
  * struct w1_netlink_cmd - holds the command and data
  *
  * @cmd: one of enum w1_commands
  * @res: reserved
  * @len: length of data following w1_netlink_cmd
  * @data: start address of any following data
  *
  * One or more struct w1_netlink_cmd is placed starting at w1_netlink_msg.data
  * each with optional data.
  */
 struct w1_netlink_cmd
 {
 	__u8				cmd;
 	__u8				res;
 	__u16				len;
 	__u8				data[0];
 };
 
 #ifdef __KERNEL__
 
 void w1_netlink_send(struct w1_master *, struct w1_netlink_msg *);
 int w1_init_netlink(void);
 void w1_fini_netlink(void);
 
 #endif /* __KERNEL__ */
 #endif /* __W1_NETLINK_H */
diff --git a/include/linux/extcon.h b/include/linux/extcon.h
index b871c0cb1f02..7010fb01a81a 100644
--- a/include/linux/extcon.h
+++ b/include/linux/extcon.h
@@ -1,468 +1,425 @@
 /*
  *  External connector (extcon) class driver
  *
  * Copyright (C) 2015 Samsung Electronics
  * Author: Chanwoo Choi <cw00.choi@samsung.com>
  *
  * Copyright (C) 2012 Samsung Electronics
  * Author: Donggeun Kim <dg77.kim@samsung.com>
  * Author: MyungJoo Ham <myungjoo.ham@samsung.com>
  *
  * based on switch class driver
  * Copyright (C) 2008 Google, Inc.
  * Author: Mike Lockwood <lockwood@android.com>
  *
  * This software is licensed under the terms of the GNU General Public
  * License version 2, as published by the Free Software Foundation, and
  * may be copied, distributed, and modified under those terms.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
  *
 */
 
 #ifndef __LINUX_EXTCON_H__
 #define __LINUX_EXTCON_H__
 
 #include <linux/device.h>
 
 /*
  * Define the type of supported external connectors
  */
 #define EXTCON_TYPE_USB		BIT(0)	/* USB connector */
 #define EXTCON_TYPE_CHG		BIT(1)	/* Charger connector */
 #define EXTCON_TYPE_JACK	BIT(2)	/* Jack connector */
 #define EXTCON_TYPE_DISP	BIT(3)	/* Display connector */
 #define EXTCON_TYPE_MISC	BIT(4)	/* Miscellaneous connector */
 
 /*
  * Define the unique id of supported external connectors
  */
 #define EXTCON_NONE		0
 
 /* USB external connector */
 #define EXTCON_USB		1
 #define EXTCON_USB_HOST		2
 
-/* Charging external connector */
+/*
+ * Charging external connector
+ *
+ * When one SDP charger connector was reported, we should also report
+ * the USB connector, which means EXTCON_CHG_USB_SDP should always
+ * appear together with EXTCON_USB. The same as ACA charger connector,
+ * EXTCON_CHG_USB_ACA would normally appear with EXTCON_USB_HOST.
+ *
+ * The EXTCON_CHG_USB_SLOW connector can provide at least 500mA of
+ * current at 5V. The EXTCON_CHG_USB_FAST connector can provide at
+ * least 1A of current at 5V.
+ */
 #define EXTCON_CHG_USB_SDP	5	/* Standard Downstream Port */
 #define EXTCON_CHG_USB_DCP	6	/* Dedicated Charging Port */
 #define EXTCON_CHG_USB_CDP	7	/* Charging Downstream Port */
 #define EXTCON_CHG_USB_ACA	8	/* Accessory Charger Adapter */
 #define EXTCON_CHG_USB_FAST	9
 #define EXTCON_CHG_USB_SLOW	10
 #define EXTCON_CHG_WPT		11	/* Wireless Power Transfer */
+#define EXTCON_CHG_USB_PD	12	/* USB Power Delivery */
 
 /* Jack external connector */
 #define EXTCON_JACK_MICROPHONE	20
 #define EXTCON_JACK_HEADPHONE	21
 #define EXTCON_JACK_LINE_IN	22
 #define EXTCON_JACK_LINE_OUT	23
 #define EXTCON_JACK_VIDEO_IN	24
 #define EXTCON_JACK_VIDEO_OUT	25
 #define EXTCON_JACK_SPDIF_IN	26	/* Sony Philips Digital InterFace */
 #define EXTCON_JACK_SPDIF_OUT	27
 
 /* Display external connector */
 #define EXTCON_DISP_HDMI	40	/* High-Definition Multimedia Interface */
 #define EXTCON_DISP_MHL		41	/* Mobile High-Definition Link */
 #define EXTCON_DISP_DVI		42	/* Digital Visual Interface */
 #define EXTCON_DISP_VGA		43	/* Video Graphics Array */
 #define EXTCON_DISP_DP		44	/* Display Port */
 #define EXTCON_DISP_HMD		45	/* Head-Mounted Display */
 
 /* Miscellaneous external connector */
 #define EXTCON_DOCK		60
 #define EXTCON_JIG		61
 #define EXTCON_MECHANICAL	62
 
 #define EXTCON_NUM		63
 
 /*
  * Define the property of supported external connectors.
  *
  * When adding the new extcon property, they *must* have
  * the type/value/default information. Also, you *have to*
  * modify the EXTCON_PROP_[type]_START/END definitions
  * which mean the range of the supported properties
  * for each extcon type.
  *
  * The naming style of property
  * : EXTCON_PROP_[type]_[property name]
  *
  * EXTCON_PROP_USB_[property name]	: USB property
  * EXTCON_PROP_CHG_[property name]	: Charger property
  * EXTCON_PROP_JACK_[property name]	: Jack property
  * EXTCON_PROP_DISP_[property name]	: Display property
  */
 
 /*
  * Properties of EXTCON_TYPE_USB.
  *
  * - EXTCON_PROP_USB_VBUS
  * @type:	integer (intval)
  * @value:	0 (low) or 1 (high)
  * @default:	0 (low)
  * - EXTCON_PROP_USB_TYPEC_POLARITY
  * @type:	integer (intval)
  * @value:	0 (normal) or 1 (flip)
  * @default:	0 (normal)
  * - EXTCON_PROP_USB_SS (SuperSpeed)
  * @type:       integer (intval)
  * @value:      0 (USB/USB2) or 1 (USB3)
  * @default:    0 (USB/USB2)
  *
  */
 #define EXTCON_PROP_USB_VBUS		0
 #define EXTCON_PROP_USB_TYPEC_POLARITY	1
 #define EXTCON_PROP_USB_SS		2
 
 #define EXTCON_PROP_USB_MIN		0
 #define EXTCON_PROP_USB_MAX		2
 #define EXTCON_PROP_USB_CNT	(EXTCON_PROP_USB_MAX - EXTCON_PROP_USB_MIN + 1)
 
 /* Properties of EXTCON_TYPE_CHG. */
 #define EXTCON_PROP_CHG_MIN		50
 #define EXTCON_PROP_CHG_MAX		50
 #define EXTCON_PROP_CHG_CNT	(EXTCON_PROP_CHG_MAX - EXTCON_PROP_CHG_MIN + 1)
 
 /* Properties of EXTCON_TYPE_JACK. */
 #define EXTCON_PROP_JACK_MIN		100
 #define EXTCON_PROP_JACK_MAX		100
 #define EXTCON_PROP_JACK_CNT (EXTCON_PROP_JACK_MAX - EXTCON_PROP_JACK_MIN + 1)
 
 /*
  * Properties of EXTCON_TYPE_DISP.
  *
  * - EXTCON_PROP_DISP_HPD (Hot Plug Detect)
  * @type:       integer (intval)
  * @value:      0 (no hpd) or 1 (hpd)
  * @default:    0 (no hpd)
  *
  */
 #define EXTCON_PROP_DISP_HPD		150
 
 /* Properties of EXTCON_TYPE_DISP. */
 #define EXTCON_PROP_DISP_MIN		150
 #define EXTCON_PROP_DISP_MAX		151
 #define EXTCON_PROP_DISP_CNT (EXTCON_PROP_DISP_MAX - EXTCON_PROP_DISP_MIN + 1)
 
 /*
  * Define the type of property's value.
  *
  * Define the property's value as union type. Because each property
  * would need the different data type to store it.
  */
 union extcon_property_value {
 	int intval;	/* type : integer (intval) */
 };
 
 struct extcon_cable;
-
-/**
- * struct extcon_dev - An extcon device represents one external connector.
- * @name:		The name of this extcon device. Parent device name is
- *			used if NULL.
- * @supported_cable:	Array of supported cable names ending with EXTCON_NONE.
- *			If supported_cable is NULL, cable name related APIs
- *			are disabled.
- * @mutually_exclusive:	Array of mutually exclusive set of cables that cannot
- *			be attached simultaneously. The array should be
- *			ending with NULL or be NULL (no mutually exclusive
- *			cables). For example, if it is { 0x7, 0x30, 0}, then,
- *			{0, 1}, {0, 1, 2}, {0, 2}, {1, 2}, or {4, 5} cannot
- *			be attached simulataneously. {0x7, 0} is equivalent to
- *			{0x3, 0x6, 0x5, 0}. If it is {0xFFFFFFFF, 0}, there
- *			can be no simultaneous connections.
- * @dev:		Device of this extcon.
- * @state:		Attach/detach state of this extcon. Do not provide at
- *			register-time.
- * @nh:			Notifier for the state change events from this extcon
- * @entry:		To support list of extcon devices so that users can
- *			search for extcon devices based on the extcon name.
- * @lock:
- * @max_supported:	Internal value to store the number of cables.
- * @extcon_dev_type:	Device_type struct to provide attribute_groups
- *			customized for each extcon device.
- * @cables:		Sysfs subdirectories. Each represents one cable.
- *
- * In most cases, users only need to provide "User initializing data" of
- * this struct when registering an extcon. In some exceptional cases,
- * optional callbacks may be needed. However, the values in "internal data"
- * are overwritten by register function.
- */
-struct extcon_dev {
-	/* Optional user initializing data */
-	const char *name;
-	const unsigned int *supported_cable;
-	const u32 *mutually_exclusive;
-
-	/* Internal data. Please do not set. */
-	struct device dev;
-	struct raw_notifier_head *nh;
-	struct list_head entry;
-	int max_supported;
-	spinlock_t lock;	/* could be called by irq handler */
-	u32 state;
-
-	/* /sys/class/extcon/.../cable.n/... */
-	struct device_type extcon_dev_type;
-	struct extcon_cable *cables;
-
-	/* /sys/class/extcon/.../mutually_exclusive/... */
-	struct attribute_group attr_g_muex;
-	struct attribute **attrs_muex;
-	struct device_attribute *d_attrs_muex;
-};
+struct extcon_dev;
 
 #if IS_ENABLED(CONFIG_EXTCON)
 
 /*
  * Following APIs are for notifiers or configurations.
  * Notifiers are the external port and connection devices.
  */
 extern int extcon_dev_register(struct extcon_dev *edev);
 extern void extcon_dev_unregister(struct extcon_dev *edev);
 extern int devm_extcon_dev_register(struct device *dev,
 				    struct extcon_dev *edev);
 extern void devm_extcon_dev_unregister(struct device *dev,
 				       struct extcon_dev *edev);
 extern struct extcon_dev *extcon_get_extcon_dev(const char *extcon_name);
 
 /*
  * Following APIs control the memory of extcon device.
  */
 extern struct extcon_dev *extcon_dev_allocate(const unsigned int *cable);
 extern void extcon_dev_free(struct extcon_dev *edev);
 extern struct extcon_dev *devm_extcon_dev_allocate(struct device *dev,
 						   const unsigned int *cable);
 extern void devm_extcon_dev_free(struct device *dev, struct extcon_dev *edev);
 
 /*
  * get/set_state access each bit of the 32b encoded state value.
  * They are used to access the status of each cable based on the cable id.
  */
 extern int extcon_get_state(struct extcon_dev *edev, unsigned int id);
 extern int extcon_set_state(struct extcon_dev *edev, unsigned int id,
 				   bool cable_state);
 extern int extcon_set_state_sync(struct extcon_dev *edev, unsigned int id,
 				bool cable_state);
 /*
  * Synchronize the state and property data for a specific external connector.
  */
 extern int extcon_sync(struct extcon_dev *edev, unsigned int id);
 
 /*
  * get/set_property access the property value of each external connector.
  * They are used to access the property of each cable based on the property id.
  */
 extern int extcon_get_property(struct extcon_dev *edev, unsigned int id,
 				unsigned int prop,
 				union extcon_property_value *prop_val);
 extern int extcon_set_property(struct extcon_dev *edev, unsigned int id,
 				unsigned int prop,
 				union extcon_property_value prop_val);
 extern int extcon_set_property_sync(struct extcon_dev *edev, unsigned int id,
 				unsigned int prop,
 				union extcon_property_value prop_val);
 
 /*
  * get/set_property_capability set the capability of the property for each
  * external connector. They are used to set the capability of the property
  * of each external connector based on the id and property.
  */
 extern int extcon_get_property_capability(struct extcon_dev *edev,
 				unsigned int id, unsigned int prop);
 extern int extcon_set_property_capability(struct extcon_dev *edev,
 				unsigned int id, unsigned int prop);
 
 /*
  * Following APIs are to monitor every action of a notifier.
  * Registrar gets notified for every external port of a connection device.
  * Probably this could be used to debug an action of notifier; however,
  * we do not recommend to use this for normal 'notifiee' device drivers who
  * want to be notified by a specific external port of the notifier.
  */
 extern int extcon_register_notifier(struct extcon_dev *edev, unsigned int id,
 				    struct notifier_block *nb);
 extern int extcon_unregister_notifier(struct extcon_dev *edev, unsigned int id,
 				    struct notifier_block *nb);
 extern int devm_extcon_register_notifier(struct device *dev,
 				struct extcon_dev *edev, unsigned int id,
 				struct notifier_block *nb);
 extern void devm_extcon_unregister_notifier(struct device *dev,
 				struct extcon_dev *edev, unsigned int id,
 				struct notifier_block *nb);
 
 /*
  * Following API get the extcon device from devicetree.
  * This function use phandle of devicetree to get extcon device directly.
  */
 extern struct extcon_dev *extcon_get_edev_by_phandle(struct device *dev,
 						     int index);
 
 /* Following API to get information of extcon device */
 extern const char *extcon_get_edev_name(struct extcon_dev *edev);
 
 
 #else /* CONFIG_EXTCON */
 static inline int extcon_dev_register(struct extcon_dev *edev)
 {
 	return 0;
 }
 
 static inline void extcon_dev_unregister(struct extcon_dev *edev) { }
 
 static inline int devm_extcon_dev_register(struct device *dev,
 					   struct extcon_dev *edev)
 {
 	return -EINVAL;
 }
 
 static inline void devm_extcon_dev_unregister(struct device *dev,
 					      struct extcon_dev *edev) { }
 
 static inline struct extcon_dev *extcon_dev_allocate(const unsigned int *cable)
 {
 	return ERR_PTR(-ENOSYS);
 }
 
 static inline void extcon_dev_free(struct extcon_dev *edev) { }
 
 static inline struct extcon_dev *devm_extcon_dev_allocate(struct device *dev,
 						const unsigned int *cable)
 {
 	return ERR_PTR(-ENOSYS);
 }
 
 static inline void devm_extcon_dev_free(struct extcon_dev *edev) { }
 
 
 static inline int extcon_get_state(struct extcon_dev *edev, unsigned int id)
 {
 	return 0;
 }
 
 static inline int extcon_set_state(struct extcon_dev *edev, unsigned int id,
 				bool cable_state)
 {
 	return 0;
 }
 
 static inline int extcon_set_state_sync(struct extcon_dev *edev, unsigned int id,
 				bool cable_state)
 {
 	return 0;
 }
 
 static inline int extcon_sync(struct extcon_dev *edev, unsigned int id)
 {
 	return 0;
 }
 
 static inline int extcon_get_property(struct extcon_dev *edev, unsigned int id,
 					unsigned int prop,
 					union extcon_property_value *prop_val)
 {
 	return 0;
 }
 static inline int extcon_set_property(struct extcon_dev *edev, unsigned int id,
 					unsigned int prop,
 					union extcon_property_value prop_val)
 {
 	return 0;
 }
 
 static inline int extcon_set_property_sync(struct extcon_dev *edev,
 					unsigned int id, unsigned int prop,
 					union extcon_property_value prop_val)
 {
 	return 0;
 }
 
 static inline int extcon_get_property_capability(struct extcon_dev *edev,
 					unsigned int id, unsigned int prop)
 {
 	return 0;
 }
 
 static inline int extcon_set_property_capability(struct extcon_dev *edev,
 					unsigned int id, unsigned int prop)
 {
 	return 0;
 }
 
 static inline struct extcon_dev *extcon_get_extcon_dev(const char *extcon_name)
 {
 	return NULL;
 }
 
 static inline int extcon_register_notifier(struct extcon_dev *edev,
 					unsigned int id,
 					struct notifier_block *nb)
 {
 	return 0;
 }
 
 static inline int extcon_unregister_notifier(struct extcon_dev *edev,
 					unsigned int id,
 					struct notifier_block *nb)
 {
 	return 0;
 }
 
 static inline int devm_extcon_register_notifier(struct device *dev,
 				struct extcon_dev *edev, unsigned int id,
 				struct notifier_block *nb)
 {
 	return -ENOSYS;
 }
 
 static inline  void devm_extcon_unregister_notifier(struct device *dev,
 				struct extcon_dev *edev, unsigned int id,
 				struct notifier_block *nb) { }
 
 static inline struct extcon_dev *extcon_get_edev_by_phandle(struct device *dev,
 							    int index)
 {
 	return ERR_PTR(-ENODEV);
 }
 #endif /* CONFIG_EXTCON */
 
 /*
  * Following structure and API are deprecated. EXTCON remains the function
  * definition to prevent the build break.
  */
 struct extcon_specific_cable_nb {
        struct notifier_block *user_nb;
        int cable_index;
        struct extcon_dev *edev;
        unsigned long previous_value;
 };
 
 static inline int extcon_register_interest(struct extcon_specific_cable_nb *obj,
 			const char *extcon_name, const char *cable_name,
 			struct notifier_block *nb)
 {
 	return -EINVAL;
 }
 
 static inline int extcon_unregister_interest(struct extcon_specific_cable_nb
 						    *obj)
 {
 	return -EINVAL;
 }
 
 static inline int extcon_get_cable_state_(struct extcon_dev *edev, unsigned int id)
 {
 	return extcon_get_state(edev, id);
 }
 
 static inline int extcon_set_cable_state_(struct extcon_dev *edev, unsigned int id,
 				   bool cable_state)
 {
 	return extcon_set_state_sync(edev, id, cable_state);
 }
 #endif /* __LINUX_EXTCON_H__ */
diff --git a/include/linux/extcon/extcon-adc-jack.h b/include/linux/extcon/extcon-adc-jack.h
index a0e03b13b449..2aa32075bca1 100644
--- a/include/linux/extcon/extcon-adc-jack.h
+++ b/include/linux/extcon/extcon-adc-jack.h
@@ -1,72 +1,72 @@
 /*
  * include/linux/extcon/extcon-adc-jack.h
  *
  * Analog Jack extcon driver with ADC-based detection capability.
  *
  * Copyright (C) 2012 Samsung Electronics
  * MyungJoo Ham <myungjoo.ham@samsung.com>
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License version 2 as
  * published by the Free Software Foundation.
  *
  */
 
 #ifndef _EXTCON_ADC_JACK_H_
 #define _EXTCON_ADC_JACK_H_ __FILE__
 
 #include <linux/module.h>
 #include <linux/extcon.h>
 
 /**
  * struct adc_jack_cond - condition to use an extcon state
  *			denotes the last adc_jack_cond element among the array)
  * @id:			the unique id of each external connector
  * @min_adc:		min adc value for this condition
  * @max_adc:		max adc value for this condition
  *
  * For example, if { .state = 0x3, .min_adc = 100, .max_adc = 200}, it means
  * that if ADC value is between (inclusive) 100 and 200, than the cable 0 and
  * 1 are attached (1<<0 | 1<<1 == 0x3)
  *
  * Note that you don't need to describe condition for "no cable attached"
  * because when no adc_jack_cond is met, state = 0 is automatically chosen.
  */
 struct adc_jack_cond {
 	unsigned int id;
 	u32 min_adc;
 	u32 max_adc;
 };
 
 /**
  * struct adc_jack_pdata - platform data for adc jack device.
  * @name:		name of the extcon device. If null, "adc-jack" is used.
  * @consumer_channel:	Unique name to identify the channel on the consumer
  *			side. This typically describes the channels used within
  *			the consumer. E.g. 'battery_voltage'
  * @cable_names:	array of extcon id for supported cables.
  * @adc_contitions:	array of struct adc_jack_cond conditions ending
  *			with .state = 0 entry. This describes how to decode
  *			adc values into extcon state.
  * @irq_flags:		irq flags used for the @irq
  * @handling_delay_ms:	in some devices, we need to read ADC value some
  *			milli-seconds after the interrupt occurs. You may
  *			describe such delays with @handling_delay_ms, which
  *			is rounded-off by jiffies.
  * @wakeup_source:	flag to wake up the system for extcon events.
  */
 struct adc_jack_pdata {
 	const char *name;
 	const char *consumer_channel;
 
-	const enum extcon *cable_names;
+	const unsigned int *cable_names;
 
 	/* The last entry's state should be 0 */
 	struct adc_jack_cond *adc_conditions;
 
 	unsigned long irq_flags;
 	unsigned long handling_delay_ms; /* in ms */
 	bool wakeup_source;
 };
 
 #endif /* _EXTCON_ADC_JACK_H */
diff --git a/include/linux/fpga/fpga-mgr.h b/include/linux/fpga/fpga-mgr.h
index 16551d5eac36..57beb5d09bfc 100644
--- a/include/linux/fpga/fpga-mgr.h
+++ b/include/linux/fpga/fpga-mgr.h
@@ -1,148 +1,153 @@
 /*
  * FPGA Framework
  *
  *  Copyright (C) 2013-2015 Altera Corporation
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms and conditions of the GNU General Public License,
  * version 2, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope it will be useful, but WITHOUT
  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
  * more details.
  *
  * You should have received a copy of the GNU General Public License along with
  * this program.  If not, see <http://www.gnu.org/licenses/>.
  */
 #include <linux/mutex.h>
 #include <linux/platform_device.h>
 
 #ifndef _LINUX_FPGA_MGR_H
 #define _LINUX_FPGA_MGR_H
 
 struct fpga_manager;
+struct sg_table;
 
 /**
  * enum fpga_mgr_states - fpga framework states
  * @FPGA_MGR_STATE_UNKNOWN: can't determine state
  * @FPGA_MGR_STATE_POWER_OFF: FPGA power is off
  * @FPGA_MGR_STATE_POWER_UP: FPGA reports power is up
  * @FPGA_MGR_STATE_RESET: FPGA in reset state
  * @FPGA_MGR_STATE_FIRMWARE_REQ: firmware request in progress
  * @FPGA_MGR_STATE_FIRMWARE_REQ_ERR: firmware request failed
  * @FPGA_MGR_STATE_WRITE_INIT: preparing FPGA for programming
  * @FPGA_MGR_STATE_WRITE_INIT_ERR: Error during WRITE_INIT stage
  * @FPGA_MGR_STATE_WRITE: writing image to FPGA
  * @FPGA_MGR_STATE_WRITE_ERR: Error while writing FPGA
  * @FPGA_MGR_STATE_WRITE_COMPLETE: Doing post programming steps
  * @FPGA_MGR_STATE_WRITE_COMPLETE_ERR: Error during WRITE_COMPLETE
  * @FPGA_MGR_STATE_OPERATING: FPGA is programmed and operating
  */
 enum fpga_mgr_states {
 	/* default FPGA states */
 	FPGA_MGR_STATE_UNKNOWN,
 	FPGA_MGR_STATE_POWER_OFF,
 	FPGA_MGR_STATE_POWER_UP,
 	FPGA_MGR_STATE_RESET,
 
 	/* getting an image for loading */
 	FPGA_MGR_STATE_FIRMWARE_REQ,
 	FPGA_MGR_STATE_FIRMWARE_REQ_ERR,
 
 	/* write sequence: init, write, complete */
 	FPGA_MGR_STATE_WRITE_INIT,
 	FPGA_MGR_STATE_WRITE_INIT_ERR,
 	FPGA_MGR_STATE_WRITE,
 	FPGA_MGR_STATE_WRITE_ERR,
 	FPGA_MGR_STATE_WRITE_COMPLETE,
 	FPGA_MGR_STATE_WRITE_COMPLETE_ERR,
 
 	/* fpga is programmed and operating */
 	FPGA_MGR_STATE_OPERATING,
 };
 
 /*
  * FPGA Manager flags
  * FPGA_MGR_PARTIAL_RECONFIG: do partial reconfiguration if supported
  * FPGA_MGR_EXTERNAL_CONFIG: FPGA has been configured prior to Linux booting
  */
 #define FPGA_MGR_PARTIAL_RECONFIG	BIT(0)
 #define FPGA_MGR_EXTERNAL_CONFIG	BIT(1)
 
 /**
  * struct fpga_image_info - information specific to a FPGA image
  * @flags: boolean flags as defined above
  * @enable_timeout_us: maximum time to enable traffic through bridge (uSec)
  * @disable_timeout_us: maximum time to disable traffic through bridge (uSec)
  */
 struct fpga_image_info {
 	u32 flags;
 	u32 enable_timeout_us;
 	u32 disable_timeout_us;
 };
 
 /**
  * struct fpga_manager_ops - ops for low level fpga manager drivers
  * @initial_header_size: Maximum number of bytes that should be passed into write_init
  * @state: returns an enum value of the FPGA's state
  * @write_init: prepare the FPGA to receive confuration data
  * @write: write count bytes of configuration data to the FPGA
+ * @write_sg: write the scatter list of configuration data to the FPGA
  * @write_complete: set FPGA to operating state after writing is done
  * @fpga_remove: optional: Set FPGA into a specific state during driver remove
  *
  * fpga_manager_ops are the low level functions implemented by a specific
  * fpga manager driver.  The optional ones are tested for NULL before being
  * called, so leaving them out is fine.
  */
 struct fpga_manager_ops {
 	size_t initial_header_size;
 	enum fpga_mgr_states (*state)(struct fpga_manager *mgr);
 	int (*write_init)(struct fpga_manager *mgr,
 			  struct fpga_image_info *info,
 			  const char *buf, size_t count);
 	int (*write)(struct fpga_manager *mgr, const char *buf, size_t count);
+	int (*write_sg)(struct fpga_manager *mgr, struct sg_table *sgt);
 	int (*write_complete)(struct fpga_manager *mgr,
 			      struct fpga_image_info *info);
 	void (*fpga_remove)(struct fpga_manager *mgr);
 };
 
 /**
  * struct fpga_manager - fpga manager structure
  * @name: name of low level fpga manager
  * @dev: fpga manager device
  * @ref_mutex: only allows one reference to fpga manager
  * @state: state of fpga manager
  * @mops: pointer to struct of fpga manager ops
  * @priv: low level driver private date
  */
 struct fpga_manager {
 	const char *name;
 	struct device dev;
 	struct mutex ref_mutex;
 	enum fpga_mgr_states state;
 	const struct fpga_manager_ops *mops;
 	void *priv;
 };
 
 #define to_fpga_manager(d) container_of(d, struct fpga_manager, dev)
 
 int fpga_mgr_buf_load(struct fpga_manager *mgr, struct fpga_image_info *info,
 		      const char *buf, size_t count);
+int fpga_mgr_buf_load_sg(struct fpga_manager *mgr, struct fpga_image_info *info,
+			 struct sg_table *sgt);
 
 int fpga_mgr_firmware_load(struct fpga_manager *mgr,
 			   struct fpga_image_info *info,
 			   const char *image_name);
 
 struct fpga_manager *of_fpga_mgr_get(struct device_node *node);
 
 struct fpga_manager *fpga_mgr_get(struct device *dev);
 
 void fpga_mgr_put(struct fpga_manager *mgr);
 
 int fpga_mgr_register(struct device *dev, const char *name,
 		      const struct fpga_manager_ops *mops, void *priv);
 
 void fpga_mgr_unregister(struct device *dev);
 
 #endif /*_LINUX_FPGA_MGR_H */
diff --git a/include/linux/fsi.h b/include/linux/fsi.h
new file mode 100644
index 000000000000..273cbf6400ea
--- /dev/null
+++ b/include/linux/fsi.h
@@ -0,0 +1,50 @@
+/* FSI device & driver interfaces
+ *
+ * Copyright (C) IBM Corporation 2016
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef LINUX_FSI_H
+#define LINUX_FSI_H
+
+#include <linux/device.h>
+
+struct fsi_device {
+	struct device		dev;
+	u8			engine_type;
+	u8			version;
+};
+
+struct fsi_device_id {
+	u8	engine_type;
+	u8	version;
+};
+
+#define FSI_VERSION_ANY		0
+
+#define FSI_DEVICE(t) \
+	.engine_type = (t), .version = FSI_VERSION_ANY,
+
+#define FSI_DEVICE_VERSIONED(t, v) \
+	.engine_type = (t), .version = (v),
+
+
+struct fsi_driver {
+	struct device_driver		drv;
+	const struct fsi_device_id	*id_table;
+};
+
+#define to_fsi_dev(devp) container_of(devp, struct fsi_device, dev)
+#define to_fsi_drv(drvp) container_of(drvp, struct fsi_driver, drv)
+
+extern struct bus_type fsi_bus_type;
+
+#endif /* LINUX_FSI_H */
diff --git a/include/linux/hyperv.h b/include/linux/hyperv.h
index 183efde54269..62bbf3c1aa4a 100644
--- a/include/linux/hyperv.h
+++ b/include/linux/hyperv.h
@@ -1,1622 +1,1620 @@
 /*
  *
  * Copyright (c) 2011, Microsoft Corporation.
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms and conditions of the GNU General Public License,
  * version 2, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope it will be useful, but WITHOUT
  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
  * more details.
  *
  * You should have received a copy of the GNU General Public License along with
  * this program; if not, write to the Free Software Foundation, Inc., 59 Temple
  * Place - Suite 330, Boston, MA 02111-1307 USA.
  *
  * Authors:
  *   Haiyang Zhang <haiyangz@microsoft.com>
  *   Hank Janssen  <hjanssen@microsoft.com>
  *   K. Y. Srinivasan <kys@microsoft.com>
  *
  */
 
 #ifndef _HYPERV_H
 #define _HYPERV_H
 
 #include <uapi/linux/hyperv.h>
 #include <uapi/asm/hyperv.h>
 
 #include <linux/types.h>
 #include <linux/scatterlist.h>
 #include <linux/list.h>
 #include <linux/timer.h>
-#include <linux/workqueue.h>
 #include <linux/completion.h>
 #include <linux/device.h>
 #include <linux/mod_devicetable.h>
-
+#include <linux/interrupt.h>
 
 #define MAX_PAGE_BUFFER_COUNT				32
 #define MAX_MULTIPAGE_BUFFER_COUNT			32 /* 128K */
 
 #pragma pack(push, 1)
 
 /* Single-page buffer */
 struct hv_page_buffer {
 	u32 len;
 	u32 offset;
 	u64 pfn;
 };
 
 /* Multiple-page buffer */
 struct hv_multipage_buffer {
 	/* Length and Offset determines the # of pfns in the array */
 	u32 len;
 	u32 offset;
 	u64 pfn_array[MAX_MULTIPAGE_BUFFER_COUNT];
 };
 
 /*
  * Multiple-page buffer array; the pfn array is variable size:
  * The number of entries in the PFN array is determined by
  * "len" and "offset".
  */
 struct hv_mpb_array {
 	/* Length and Offset determines the # of pfns in the array */
 	u32 len;
 	u32 offset;
 	u64 pfn_array[];
 };
 
 /* 0x18 includes the proprietary packet header */
 #define MAX_PAGE_BUFFER_PACKET		(0x18 +			\
 					(sizeof(struct hv_page_buffer) * \
 					 MAX_PAGE_BUFFER_COUNT))
 #define MAX_MULTIPAGE_BUFFER_PACKET	(0x18 +			\
 					 sizeof(struct hv_multipage_buffer))
 
 
 #pragma pack(pop)
 
 struct hv_ring_buffer {
 	/* Offset in bytes from the start of ring data below */
 	u32 write_index;
 
 	/* Offset in bytes from the start of ring data below */
 	u32 read_index;
 
 	u32 interrupt_mask;
 
 	/*
 	 * Win8 uses some of the reserved bits to implement
 	 * interrupt driven flow management. On the send side
 	 * we can request that the receiver interrupt the sender
 	 * when the ring transitions from being full to being able
 	 * to handle a message of size "pending_send_sz".
 	 *
 	 * Add necessary state for this enhancement.
 	 */
 	u32 pending_send_sz;
 
 	u32 reserved1[12];
 
 	union {
 		struct {
 			u32 feat_pending_send_sz:1;
 		};
 		u32 value;
 	} feature_bits;
 
 	/* Pad it to PAGE_SIZE so that data starts on page boundary */
 	u8	reserved2[4028];
 
 	/*
 	 * Ring data starts here + RingDataStartOffset
 	 * !!! DO NOT place any fields below this !!!
 	 */
 	u8 buffer[0];
 } __packed;
 
 struct hv_ring_buffer_info {
 	struct hv_ring_buffer *ring_buffer;
 	u32 ring_size;			/* Include the shared header */
 	spinlock_t ring_lock;
 
 	u32 ring_datasize;		/* < ring_size */
 	u32 ring_data_startoffset;
 	u32 priv_write_index;
 	u32 priv_read_index;
 	u32 cached_read_index;
 };
 
 /*
  *
  * hv_get_ringbuffer_availbytes()
  *
  * Get number of bytes available to read and to write to
  * for the specified ring buffer
  */
 static inline void
-hv_get_ringbuffer_availbytes(struct hv_ring_buffer_info *rbi,
-			  u32 *read, u32 *write)
+hv_get_ringbuffer_availbytes(const struct hv_ring_buffer_info *rbi,
+			     u32 *read, u32 *write)
 {
 	u32 read_loc, write_loc, dsize;
 
 	/* Capture the read/write indices before they changed */
 	read_loc = rbi->ring_buffer->read_index;
 	write_loc = rbi->ring_buffer->write_index;
 	dsize = rbi->ring_datasize;
 
 	*write = write_loc >= read_loc ? dsize - (write_loc - read_loc) :
 		read_loc - write_loc;
 	*read = dsize - *write;
 }
 
-static inline u32 hv_get_bytes_to_read(struct hv_ring_buffer_info *rbi)
+static inline u32 hv_get_bytes_to_read(const struct hv_ring_buffer_info *rbi)
 {
 	u32 read_loc, write_loc, dsize, read;
 
 	dsize = rbi->ring_datasize;
 	read_loc = rbi->ring_buffer->read_index;
 	write_loc = READ_ONCE(rbi->ring_buffer->write_index);
 
 	read = write_loc >= read_loc ? (write_loc - read_loc) :
 		(dsize - read_loc) + write_loc;
 
 	return read;
 }
 
-static inline u32 hv_get_bytes_to_write(struct hv_ring_buffer_info *rbi)
+static inline u32 hv_get_bytes_to_write(const struct hv_ring_buffer_info *rbi)
 {
 	u32 read_loc, write_loc, dsize, write;
 
 	dsize = rbi->ring_datasize;
 	read_loc = READ_ONCE(rbi->ring_buffer->read_index);
 	write_loc = rbi->ring_buffer->write_index;
 
 	write = write_loc >= read_loc ? dsize - (write_loc - read_loc) :
 		read_loc - write_loc;
 	return write;
 }
 
 static inline u32 hv_get_cached_bytes_to_write(
 	const struct hv_ring_buffer_info *rbi)
 {
 	u32 read_loc, write_loc, dsize, write;
 
 	dsize = rbi->ring_datasize;
 	read_loc = rbi->cached_read_index;
 	write_loc = rbi->ring_buffer->write_index;
 
 	write = write_loc >= read_loc ? dsize - (write_loc - read_loc) :
 		read_loc - write_loc;
 	return write;
 }
 /*
  * VMBUS version is 32 bit entity broken up into
  * two 16 bit quantities: major_number. minor_number.
  *
  * 0 . 13 (Windows Server 2008)
  * 1 . 1  (Windows 7)
  * 2 . 4  (Windows 8)
  * 3 . 0  (Windows 8 R2)
  * 4 . 0  (Windows 10)
  */
 
 #define VERSION_WS2008  ((0 << 16) | (13))
 #define VERSION_WIN7    ((1 << 16) | (1))
 #define VERSION_WIN8    ((2 << 16) | (4))
 #define VERSION_WIN8_1    ((3 << 16) | (0))
 #define VERSION_WIN10	((4 << 16) | (0))
 
 #define VERSION_INVAL -1
 
 #define VERSION_CURRENT VERSION_WIN10
 
 /* Make maximum size of pipe payload of 16K */
 #define MAX_PIPE_DATA_PAYLOAD		(sizeof(u8) * 16384)
 
 /* Define PipeMode values. */
 #define VMBUS_PIPE_TYPE_BYTE		0x00000000
 #define VMBUS_PIPE_TYPE_MESSAGE		0x00000004
 
 /* The size of the user defined data buffer for non-pipe offers. */
 #define MAX_USER_DEFINED_BYTES		120
 
 /* The size of the user defined data buffer for pipe offers. */
 #define MAX_PIPE_USER_DEFINED_BYTES	116
 
 /*
  * At the center of the Channel Management library is the Channel Offer. This
  * struct contains the fundamental information about an offer.
  */
 struct vmbus_channel_offer {
 	uuid_le if_type;
 	uuid_le if_instance;
 
 	/*
 	 * These two fields are not currently used.
 	 */
 	u64 reserved1;
 	u64 reserved2;
 
 	u16 chn_flags;
 	u16 mmio_megabytes;		/* in bytes * 1024 * 1024 */
 
 	union {
 		/* Non-pipes: The user has MAX_USER_DEFINED_BYTES bytes. */
 		struct {
 			unsigned char user_def[MAX_USER_DEFINED_BYTES];
 		} std;
 
 		/*
 		 * Pipes:
 		 * The following sructure is an integrated pipe protocol, which
 		 * is implemented on top of standard user-defined data. Pipe
 		 * clients have MAX_PIPE_USER_DEFINED_BYTES left for their own
 		 * use.
 		 */
 		struct {
 			u32  pipe_mode;
 			unsigned char user_def[MAX_PIPE_USER_DEFINED_BYTES];
 		} pipe;
 	} u;
 	/*
 	 * The sub_channel_index is defined in win8.
 	 */
 	u16 sub_channel_index;
 	u16 reserved3;
 } __packed;
 
 /* Server Flags */
 #define VMBUS_CHANNEL_ENUMERATE_DEVICE_INTERFACE	1
 #define VMBUS_CHANNEL_SERVER_SUPPORTS_TRANSFER_PAGES	2
 #define VMBUS_CHANNEL_SERVER_SUPPORTS_GPADLS		4
 #define VMBUS_CHANNEL_NAMED_PIPE_MODE			0x10
 #define VMBUS_CHANNEL_LOOPBACK_OFFER			0x100
 #define VMBUS_CHANNEL_PARENT_OFFER			0x200
 #define VMBUS_CHANNEL_REQUEST_MONITORED_NOTIFICATION	0x400
 #define VMBUS_CHANNEL_TLNPI_PROVIDER_OFFER		0x2000
 
 struct vmpacket_descriptor {
 	u16 type;
 	u16 offset8;
 	u16 len8;
 	u16 flags;
 	u64 trans_id;
 } __packed;
 
 struct vmpacket_header {
 	u32 prev_pkt_start_offset;
 	struct vmpacket_descriptor descriptor;
 } __packed;
 
 struct vmtransfer_page_range {
 	u32 byte_count;
 	u32 byte_offset;
 } __packed;
 
 struct vmtransfer_page_packet_header {
 	struct vmpacket_descriptor d;
 	u16 xfer_pageset_id;
 	u8  sender_owns_set;
 	u8 reserved;
 	u32 range_cnt;
 	struct vmtransfer_page_range ranges[1];
 } __packed;
 
 struct vmgpadl_packet_header {
 	struct vmpacket_descriptor d;
 	u32 gpadl;
 	u32 reserved;
 } __packed;
 
 struct vmadd_remove_transfer_page_set {
 	struct vmpacket_descriptor d;
 	u32 gpadl;
 	u16 xfer_pageset_id;
 	u16 reserved;
 } __packed;
 
 /*
  * This structure defines a range in guest physical space that can be made to
  * look virtually contiguous.
  */
 struct gpa_range {
 	u32 byte_count;
 	u32 byte_offset;
 	u64 pfn_array[0];
 };
 
 /*
  * This is the format for an Establish Gpadl packet, which contains a handle by
  * which this GPADL will be known and a set of GPA ranges associated with it.
  * This can be converted to a MDL by the guest OS.  If there are multiple GPA
  * ranges, then the resulting MDL will be "chained," representing multiple VA
  * ranges.
  */
 struct vmestablish_gpadl {
 	struct vmpacket_descriptor d;
 	u32 gpadl;
 	u32 range_cnt;
 	struct gpa_range range[1];
 } __packed;
 
 /*
  * This is the format for a Teardown Gpadl packet, which indicates that the
  * GPADL handle in the Establish Gpadl packet will never be referenced again.
  */
 struct vmteardown_gpadl {
 	struct vmpacket_descriptor d;
 	u32 gpadl;
 	u32 reserved;	/* for alignment to a 8-byte boundary */
 } __packed;
 
 /*
  * This is the format for a GPA-Direct packet, which contains a set of GPA
  * ranges, in addition to commands and/or data.
  */
 struct vmdata_gpa_direct {
 	struct vmpacket_descriptor d;
 	u32 reserved;
 	u32 range_cnt;
 	struct gpa_range range[1];
 } __packed;
 
 /* This is the format for a Additional Data Packet. */
 struct vmadditional_data {
 	struct vmpacket_descriptor d;
 	u64 total_bytes;
 	u32 offset;
 	u32 byte_cnt;
 	unsigned char data[1];
 } __packed;
 
 union vmpacket_largest_possible_header {
 	struct vmpacket_descriptor simple_hdr;
 	struct vmtransfer_page_packet_header xfer_page_hdr;
 	struct vmgpadl_packet_header gpadl_hdr;
 	struct vmadd_remove_transfer_page_set add_rm_xfer_page_hdr;
 	struct vmestablish_gpadl establish_gpadl_hdr;
 	struct vmteardown_gpadl teardown_gpadl_hdr;
 	struct vmdata_gpa_direct data_gpa_direct_hdr;
 };
 
 #define VMPACKET_DATA_START_ADDRESS(__packet)	\
 	(void *)(((unsigned char *)__packet) +	\
 	 ((struct vmpacket_descriptor)__packet)->offset8 * 8)
 
 #define VMPACKET_DATA_LENGTH(__packet)		\
 	((((struct vmpacket_descriptor)__packet)->len8 -	\
 	  ((struct vmpacket_descriptor)__packet)->offset8) * 8)
 
 #define VMPACKET_TRANSFER_MODE(__packet)	\
 	(((struct IMPACT)__packet)->type)
 
 enum vmbus_packet_type {
 	VM_PKT_INVALID				= 0x0,
 	VM_PKT_SYNCH				= 0x1,
 	VM_PKT_ADD_XFER_PAGESET			= 0x2,
 	VM_PKT_RM_XFER_PAGESET			= 0x3,
 	VM_PKT_ESTABLISH_GPADL			= 0x4,
 	VM_PKT_TEARDOWN_GPADL			= 0x5,
 	VM_PKT_DATA_INBAND			= 0x6,
 	VM_PKT_DATA_USING_XFER_PAGES		= 0x7,
 	VM_PKT_DATA_USING_GPADL			= 0x8,
 	VM_PKT_DATA_USING_GPA_DIRECT		= 0x9,
 	VM_PKT_CANCEL_REQUEST			= 0xa,
 	VM_PKT_COMP				= 0xb,
 	VM_PKT_DATA_USING_ADDITIONAL_PKT	= 0xc,
 	VM_PKT_ADDITIONAL_DATA			= 0xd
 };
 
 #define VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED	1
 
 
 /* Version 1 messages */
 enum vmbus_channel_message_type {
 	CHANNELMSG_INVALID			=  0,
 	CHANNELMSG_OFFERCHANNEL		=  1,
 	CHANNELMSG_RESCIND_CHANNELOFFER	=  2,
 	CHANNELMSG_REQUESTOFFERS		=  3,
 	CHANNELMSG_ALLOFFERS_DELIVERED	=  4,
 	CHANNELMSG_OPENCHANNEL		=  5,
 	CHANNELMSG_OPENCHANNEL_RESULT		=  6,
 	CHANNELMSG_CLOSECHANNEL		=  7,
 	CHANNELMSG_GPADL_HEADER		=  8,
 	CHANNELMSG_GPADL_BODY			=  9,
 	CHANNELMSG_GPADL_CREATED		= 10,
 	CHANNELMSG_GPADL_TEARDOWN		= 11,
 	CHANNELMSG_GPADL_TORNDOWN		= 12,
 	CHANNELMSG_RELID_RELEASED		= 13,
 	CHANNELMSG_INITIATE_CONTACT		= 14,
 	CHANNELMSG_VERSION_RESPONSE		= 15,
 	CHANNELMSG_UNLOAD			= 16,
 	CHANNELMSG_UNLOAD_RESPONSE		= 17,
 	CHANNELMSG_18				= 18,
 	CHANNELMSG_19				= 19,
 	CHANNELMSG_20				= 20,
 	CHANNELMSG_TL_CONNECT_REQUEST		= 21,
 	CHANNELMSG_COUNT
 };
 
 struct vmbus_channel_message_header {
 	enum vmbus_channel_message_type msgtype;
 	u32 padding;
 } __packed;
 
 /* Query VMBus Version parameters */
 struct vmbus_channel_query_vmbus_version {
 	struct vmbus_channel_message_header header;
 	u32 version;
 } __packed;
 
 /* VMBus Version Supported parameters */
 struct vmbus_channel_version_supported {
 	struct vmbus_channel_message_header header;
 	u8 version_supported;
 } __packed;
 
 /* Offer Channel parameters */
 struct vmbus_channel_offer_channel {
 	struct vmbus_channel_message_header header;
 	struct vmbus_channel_offer offer;
 	u32 child_relid;
 	u8 monitorid;
 	/*
 	 * win7 and beyond splits this field into a bit field.
 	 */
 	u8 monitor_allocated:1;
 	u8 reserved:7;
 	/*
 	 * These are new fields added in win7 and later.
 	 * Do not access these fields without checking the
 	 * negotiated protocol.
 	 *
 	 * If "is_dedicated_interrupt" is set, we must not set the
 	 * associated bit in the channel bitmap while sending the
 	 * interrupt to the host.
 	 *
 	 * connection_id is to be used in signaling the host.
 	 */
 	u16 is_dedicated_interrupt:1;
 	u16 reserved1:15;
 	u32 connection_id;
 } __packed;
 
 /* Rescind Offer parameters */
 struct vmbus_channel_rescind_offer {
 	struct vmbus_channel_message_header header;
 	u32 child_relid;
 } __packed;
 
 /*
  * Request Offer -- no parameters, SynIC message contains the partition ID
  * Set Snoop -- no parameters, SynIC message contains the partition ID
  * Clear Snoop -- no parameters, SynIC message contains the partition ID
  * All Offers Delivered -- no parameters, SynIC message contains the partition
  *		           ID
  * Flush Client -- no parameters, SynIC message contains the partition ID
  */
 
 /* Open Channel parameters */
 struct vmbus_channel_open_channel {
 	struct vmbus_channel_message_header header;
 
 	/* Identifies the specific VMBus channel that is being opened. */
 	u32 child_relid;
 
 	/* ID making a particular open request at a channel offer unique. */
 	u32 openid;
 
 	/* GPADL for the channel's ring buffer. */
 	u32 ringbuffer_gpadlhandle;
 
 	/*
 	 * Starting with win8, this field will be used to specify
 	 * the target virtual processor on which to deliver the interrupt for
 	 * the host to guest communication.
 	 * Prior to win8, incoming channel interrupts would only
 	 * be delivered on cpu 0. Setting this value to 0 would
 	 * preserve the earlier behavior.
 	 */
 	u32 target_vp;
 
 	/*
 	* The upstream ring buffer begins at offset zero in the memory
 	* described by RingBufferGpadlHandle. The downstream ring buffer
 	* follows it at this offset (in pages).
 	*/
 	u32 downstream_ringbuffer_pageoffset;
 
 	/* User-specific data to be passed along to the server endpoint. */
 	unsigned char userdata[MAX_USER_DEFINED_BYTES];
 } __packed;
 
 /* Open Channel Result parameters */
 struct vmbus_channel_open_result {
 	struct vmbus_channel_message_header header;
 	u32 child_relid;
 	u32 openid;
 	u32 status;
 } __packed;
 
 /* Close channel parameters; */
 struct vmbus_channel_close_channel {
 	struct vmbus_channel_message_header header;
 	u32 child_relid;
 } __packed;
 
 /* Channel Message GPADL */
 #define GPADL_TYPE_RING_BUFFER		1
 #define GPADL_TYPE_SERVER_SAVE_AREA	2
 #define GPADL_TYPE_TRANSACTION		8
 
 /*
  * The number of PFNs in a GPADL message is defined by the number of
  * pages that would be spanned by ByteCount and ByteOffset.  If the
  * implied number of PFNs won't fit in this packet, there will be a
  * follow-up packet that contains more.
  */
 struct vmbus_channel_gpadl_header {
 	struct vmbus_channel_message_header header;
 	u32 child_relid;
 	u32 gpadl;
 	u16 range_buflen;
 	u16 rangecount;
 	struct gpa_range range[0];
 } __packed;
 
 /* This is the followup packet that contains more PFNs. */
 struct vmbus_channel_gpadl_body {
 	struct vmbus_channel_message_header header;
 	u32 msgnumber;
 	u32 gpadl;
 	u64 pfn[0];
 } __packed;
 
 struct vmbus_channel_gpadl_created {
 	struct vmbus_channel_message_header header;
 	u32 child_relid;
 	u32 gpadl;
 	u32 creation_status;
 } __packed;
 
 struct vmbus_channel_gpadl_teardown {
 	struct vmbus_channel_message_header header;
 	u32 child_relid;
 	u32 gpadl;
 } __packed;
 
 struct vmbus_channel_gpadl_torndown {
 	struct vmbus_channel_message_header header;
 	u32 gpadl;
 } __packed;
 
 struct vmbus_channel_relid_released {
 	struct vmbus_channel_message_header header;
 	u32 child_relid;
 } __packed;
 
 struct vmbus_channel_initiate_contact {
 	struct vmbus_channel_message_header header;
 	u32 vmbus_version_requested;
 	u32 target_vcpu; /* The VCPU the host should respond to */
 	u64 interrupt_page;
 	u64 monitor_page1;
 	u64 monitor_page2;
 } __packed;
 
 /* Hyper-V socket: guest's connect()-ing to host */
 struct vmbus_channel_tl_connect_request {
 	struct vmbus_channel_message_header header;
 	uuid_le guest_endpoint_id;
 	uuid_le host_service_id;
 } __packed;
 
 struct vmbus_channel_version_response {
 	struct vmbus_channel_message_header header;
 	u8 version_supported;
 } __packed;
 
 enum vmbus_channel_state {
 	CHANNEL_OFFER_STATE,
 	CHANNEL_OPENING_STATE,
 	CHANNEL_OPEN_STATE,
 	CHANNEL_OPENED_STATE,
 };
 
 /*
  * Represents each channel msg on the vmbus connection This is a
  * variable-size data structure depending on the msg type itself
  */
 struct vmbus_channel_msginfo {
 	/* Bookkeeping stuff */
 	struct list_head msglistentry;
 
 	/* So far, this is only used to handle gpadl body message */
 	struct list_head submsglist;
 
 	/* Synchronize the request/response if needed */
 	struct completion  waitevent;
+	struct vmbus_channel *waiting_channel;
 	union {
 		struct vmbus_channel_version_supported version_supported;
 		struct vmbus_channel_open_result open_result;
 		struct vmbus_channel_gpadl_torndown gpadl_torndown;
 		struct vmbus_channel_gpadl_created gpadl_created;
 		struct vmbus_channel_version_response version_response;
 	} response;
 
 	u32 msgsize;
 	/*
 	 * The channel message that goes out on the "wire".
 	 * It will contain at minimum the VMBUS_CHANNEL_MESSAGE_HEADER header
 	 */
 	unsigned char msg[0];
 };
 
 struct vmbus_close_msg {
 	struct vmbus_channel_msginfo info;
 	struct vmbus_channel_close_channel msg;
 };
 
 /* Define connection identifier type. */
 union hv_connection_id {
 	u32 asu32;
 	struct {
 		u32 id:24;
 		u32 reserved:8;
 	} u;
 };
 
 /* Definition of the hv_signal_event hypercall input structure. */
 struct hv_input_signal_event {
 	union hv_connection_id connectionid;
 	u16 flag_number;
 	u16 rsvdz;
 };
 
 struct hv_input_signal_event_buffer {
 	u64 align8;
 	struct hv_input_signal_event event;
 };
 
-enum hv_signal_policy {
-	HV_SIGNAL_POLICY_DEFAULT = 0,
-	HV_SIGNAL_POLICY_EXPLICIT,
-};
-
 enum hv_numa_policy {
 	HV_BALANCED = 0,
 	HV_LOCALIZED,
 };
 
 enum vmbus_device_type {
 	HV_IDE = 0,
 	HV_SCSI,
 	HV_FC,
 	HV_NIC,
 	HV_ND,
 	HV_PCIE,
 	HV_FB,
 	HV_KBD,
 	HV_MOUSE,
 	HV_KVP,
 	HV_TS,
 	HV_HB,
 	HV_SHUTDOWN,
 	HV_FCOPY,
 	HV_BACKUP,
 	HV_DM,
 	HV_UNKNOWN,
 };
 
 struct vmbus_device {
 	u16  dev_type;
 	uuid_le guid;
 	bool perf_device;
 };
 
 struct vmbus_channel {
 	struct list_head listentry;
 
 	struct hv_device *device_obj;
 
 	enum vmbus_channel_state state;
 
 	struct vmbus_channel_offer_channel offermsg;
 	/*
 	 * These are based on the OfferMsg.MonitorId.
 	 * Save it here for easy access.
 	 */
 	u8 monitor_grp;
 	u8 monitor_bit;
 
 	bool rescind; /* got rescind msg */
 
 	u32 ringbuffer_gpadlhandle;
 
 	/* Allocated memory for ring buffer */
 	void *ringbuffer_pages;
 	u32 ringbuffer_pagecount;
 	struct hv_ring_buffer_info outbound;	/* send to parent */
 	struct hv_ring_buffer_info inbound;	/* receive from parent */
 	spinlock_t inbound_lock;
 
 	struct vmbus_close_msg close_msg;
 
-	/* Channel callback are invoked in this workqueue context */
-	/* HANDLE dataWorkQueue; */
-
+	/* Channel callback's invoked in softirq context */
+	struct tasklet_struct callback_event;
 	void (*onchannel_callback)(void *context);
 	void *channel_callback_context;
 
 	/*
-	 * A channel can be marked for efficient (batched)
-	 * reading:
-	 * If batched_reading is set to "true", we read until the
-	 * channel is empty and hold off interrupts from the host
-	 * during the entire read process.
-	 * If batched_reading is set to "false", the client is not
-	 * going to perform batched reading.
-	 *
-	 * By default we will enable batched reading; specific
-	 * drivers that don't want this behavior can turn it off.
+	 * A channel can be marked for one of three modes of reading:
+	 *   BATCHED - callback called from taslket and should read
+	 *            channel until empty. Interrupts from the host
+	 *            are masked while read is in process (default).
+	 *   DIRECT - callback called from tasklet (softirq).
+	 *   ISR - callback called in interrupt context and must
+	 *         invoke its own deferred processing.
+	 *         Host interrupts are disabled and must be re-enabled
+	 *         when ring is empty.
 	 */
-
-	bool batched_reading;
+	enum hv_callback_mode {
+		HV_CALL_BATCHED,
+		HV_CALL_DIRECT,
+		HV_CALL_ISR
+	} callback_mode;
 
 	bool is_dedicated_interrupt;
 	struct hv_input_signal_event_buffer sig_buf;
 	struct hv_input_signal_event *sig_event;
 
 	/*
 	 * Starting with win8, this field will be used to specify
 	 * the target virtual processor on which to deliver the interrupt for
 	 * the host to guest communication.
 	 * Prior to win8, incoming channel interrupts would only
 	 * be delivered on cpu 0. Setting this value to 0 would
 	 * preserve the earlier behavior.
 	 */
 	u32 target_vp;
 	/* The corresponding CPUID in the guest */
 	u32 target_cpu;
 	/*
 	 * State to manage the CPU affiliation of channels.
 	 */
 	struct cpumask alloced_cpus_in_node;
 	int numa_node;
 	/*
 	 * Support for sub-channels. For high performance devices,
 	 * it will be useful to have multiple sub-channels to support
 	 * a scalable communication infrastructure with the host.
 	 * The support for sub-channels is implemented as an extention
 	 * to the current infrastructure.
 	 * The initial offer is considered the primary channel and this
 	 * offer message will indicate if the host supports sub-channels.
 	 * The guest is free to ask for sub-channels to be offerred and can
 	 * open these sub-channels as a normal "primary" channel. However,
 	 * all sub-channels will have the same type and instance guids as the
 	 * primary channel. Requests sent on a given channel will result in a
 	 * response on the same channel.
 	 */
 
 	/*
 	 * Sub-channel creation callback. This callback will be called in
 	 * process context when a sub-channel offer is received from the host.
 	 * The guest can open the sub-channel in the context of this callback.
 	 */
 	void (*sc_creation_callback)(struct vmbus_channel *new_sc);
 
 	/*
 	 * Channel rescind callback. Some channels (the hvsock ones), need to
 	 * register a callback which is invoked in vmbus_onoffer_rescind().
 	 */
 	void (*chn_rescind_callback)(struct vmbus_channel *channel);
 
 	/*
 	 * The spinlock to protect the structure. It is being used to protect
 	 * test-and-set access to various attributes of the structure as well
 	 * as all sc_list operations.
 	 */
 	spinlock_t lock;
 	/*
 	 * All Sub-channels of a primary channel are linked here.
 	 */
 	struct list_head sc_list;
 	/*
 	 * Current number of sub-channels.
 	 */
 	int num_sc;
 	/*
 	 * Number of a sub-channel (position within sc_list) which is supposed
 	 * to be used as the next outgoing channel.
 	 */
 	int next_oc;
 	/*
 	 * The primary channel this sub-channel belongs to.
 	 * This will be NULL for the primary channel.
 	 */
 	struct vmbus_channel *primary_channel;
 	/*
 	 * Support per-channel state for use by vmbus drivers.
 	 */
 	void *per_channel_state;
 	/*
 	 * To support per-cpu lookup mapping of relid to channel,
 	 * link up channels based on their CPU affinity.
 	 */
 	struct list_head percpu_list;
-	/*
-	 * Host signaling policy: The default policy will be
-	 * based on the ring buffer state. We will also support
-	 * a policy where the client driver can have explicit
-	 * signaling control.
-	 */
-	enum hv_signal_policy  signal_policy;
-	/*
-	 * On the channel send side, many of the VMBUS
-	 * device drivers explicity serialize access to the
-	 * outgoing ring buffer. Give more control to the
-	 * VMBUS device drivers in terms how to serialize
-	 * accesss to the outgoing ring buffer.
-	 * The default behavior will be to aquire the
-	 * ring lock to preserve the current behavior.
-	 */
-	bool acquire_ring_lock;
 	/*
 	 * For performance critical channels (storage, networking
 	 * etc,), Hyper-V has a mechanism to enhance the throughput
 	 * at the expense of latency:
 	 * When the host is to be signaled, we just set a bit in a shared page
 	 * and this bit will be inspected by the hypervisor within a certain
 	 * window and if the bit is set, the host will be signaled. The window
 	 * of time is the monitor latency - currently around 100 usecs. This
 	 * mechanism improves throughput by:
 	 *
 	 * A) Making the host more efficient - each time it wakes up,
 	 *    potentially it will process morev number of packets. The
 	 *    monitor latency allows a batch to build up.
 	 * B) By deferring the hypercall to signal, we will also minimize
 	 *    the interrupts.
 	 *
 	 * Clearly, these optimizations improve throughput at the expense of
 	 * latency. Furthermore, since the channel is shared for both
 	 * control and data messages, control messages currently suffer
 	 * unnecessary latency adversley impacting performance and boot
 	 * time. To fix this issue, permit tagging the channel as being
 	 * in "low latency" mode. In this mode, we will bypass the monitor
 	 * mechanism.
 	 */
 	bool low_latency;
 
 	/*
 	 * NUMA distribution policy:
 	 * We support teo policies:
 	 * 1) Balanced: Here all performance critical channels are
 	 *    distributed evenly amongst all the NUMA nodes.
 	 *    This policy will be the default policy.
 	 * 2) Localized: All channels of a given instance of a
 	 *    performance critical service will be assigned CPUs
 	 *    within a selected NUMA node.
 	 */
 	enum hv_numa_policy affinity_policy;
 
 };
 
-static inline void set_channel_lock_state(struct vmbus_channel *c, bool state)
-{
-	c->acquire_ring_lock = state;
-}
-
 static inline bool is_hvsock_channel(const struct vmbus_channel *c)
 {
 	return !!(c->offermsg.offer.chn_flags &
 		  VMBUS_CHANNEL_TLNPI_PROVIDER_OFFER);
 }
 
-static inline void set_channel_signal_state(struct vmbus_channel *c,
-					    enum hv_signal_policy policy)
-{
-	c->signal_policy = policy;
-}
-
 static inline void set_channel_affinity_state(struct vmbus_channel *c,
 					      enum hv_numa_policy policy)
 {
 	c->affinity_policy = policy;
 }
 
-static inline void set_channel_read_state(struct vmbus_channel *c, bool state)
+static inline void set_channel_read_mode(struct vmbus_channel *c,
+					enum hv_callback_mode mode)
 {
-	c->batched_reading = state;
+	c->callback_mode = mode;
 }
 
 static inline void set_per_channel_state(struct vmbus_channel *c, void *s)
 {
 	c->per_channel_state = s;
 }
 
 static inline void *get_per_channel_state(struct vmbus_channel *c)
 {
 	return c->per_channel_state;
 }
 
 static inline void set_channel_pending_send_size(struct vmbus_channel *c,
 						 u32 size)
 {
 	c->outbound.ring_buffer->pending_send_sz = size;
 }
 
 static inline void set_low_latency_mode(struct vmbus_channel *c)
 {
 	c->low_latency = true;
 }
 
 static inline void clear_low_latency_mode(struct vmbus_channel *c)
 {
 	c->low_latency = false;
 }
 
 void vmbus_onmessage(void *context);
 
 int vmbus_request_offers(void);
 
 /*
  * APIs for managing sub-channels.
  */
 
 void vmbus_set_sc_create_callback(struct vmbus_channel *primary_channel,
 			void (*sc_cr_cb)(struct vmbus_channel *new_sc));
 
 void vmbus_set_chn_rescind_callback(struct vmbus_channel *channel,
 		void (*chn_rescind_cb)(struct vmbus_channel *));
 
 /*
  * Retrieve the (sub) channel on which to send an outgoing request.
  * When a primary channel has multiple sub-channels, we choose a
  * channel whose VCPU binding is closest to the VCPU on which
  * this call is being made.
  */
 struct vmbus_channel *vmbus_get_outgoing_channel(struct vmbus_channel *primary);
 
 /*
  * Check if sub-channels have already been offerred. This API will be useful
  * when the driver is unloaded after establishing sub-channels. In this case,
  * when the driver is re-loaded, the driver would have to check if the
  * subchannels have already been established before attempting to request
  * the creation of sub-channels.
  * This function returns TRUE to indicate that subchannels have already been
  * created.
  * This function should be invoked after setting the callback function for
  * sub-channel creation.
  */
 bool vmbus_are_subchannels_present(struct vmbus_channel *primary);
 
 /* The format must be the same as struct vmdata_gpa_direct */
 struct vmbus_channel_packet_page_buffer {
 	u16 type;
 	u16 dataoffset8;
 	u16 length8;
 	u16 flags;
 	u64 transactionid;
 	u32 reserved;
 	u32 rangecount;
 	struct hv_page_buffer range[MAX_PAGE_BUFFER_COUNT];
 } __packed;
 
 /* The format must be the same as struct vmdata_gpa_direct */
 struct vmbus_channel_packet_multipage_buffer {
 	u16 type;
 	u16 dataoffset8;
 	u16 length8;
 	u16 flags;
 	u64 transactionid;
 	u32 reserved;
 	u32 rangecount;		/* Always 1 in this case */
 	struct hv_multipage_buffer range;
 } __packed;
 
 /* The format must be the same as struct vmdata_gpa_direct */
 struct vmbus_packet_mpb_array {
 	u16 type;
 	u16 dataoffset8;
 	u16 length8;
 	u16 flags;
 	u64 transactionid;
 	u32 reserved;
 	u32 rangecount;         /* Always 1 in this case */
 	struct hv_mpb_array range;
 } __packed;
 
 
 extern int vmbus_open(struct vmbus_channel *channel,
 			    u32 send_ringbuffersize,
 			    u32 recv_ringbuffersize,
 			    void *userdata,
 			    u32 userdatalen,
 			    void(*onchannel_callback)(void *context),
 			    void *context);
 
 extern void vmbus_close(struct vmbus_channel *channel);
 
 extern int vmbus_sendpacket(struct vmbus_channel *channel,
 				  void *buffer,
 				  u32 bufferLen,
 				  u64 requestid,
 				  enum vmbus_packet_type type,
 				  u32 flags);
 
 extern int vmbus_sendpacket_ctl(struct vmbus_channel *channel,
 				  void *buffer,
 				  u32 bufferLen,
 				  u64 requestid,
 				  enum vmbus_packet_type type,
-				  u32 flags,
-				  bool kick_q);
+				  u32 flags);
 
 extern int vmbus_sendpacket_pagebuffer(struct vmbus_channel *channel,
 					    struct hv_page_buffer pagebuffers[],
 					    u32 pagecount,
 					    void *buffer,
 					    u32 bufferlen,
 					    u64 requestid);
 
 extern int vmbus_sendpacket_pagebuffer_ctl(struct vmbus_channel *channel,
 					   struct hv_page_buffer pagebuffers[],
 					   u32 pagecount,
 					   void *buffer,
 					   u32 bufferlen,
 					   u64 requestid,
-					   u32 flags,
-					   bool kick_q);
+					   u32 flags);
 
 extern int vmbus_sendpacket_multipagebuffer(struct vmbus_channel *channel,
 					struct hv_multipage_buffer *mpb,
 					void *buffer,
 					u32 bufferlen,
 					u64 requestid);
 
 extern int vmbus_sendpacket_mpb_desc(struct vmbus_channel *channel,
 				     struct vmbus_packet_mpb_array *mpb,
 				     u32 desc_size,
 				     void *buffer,
 				     u32 bufferlen,
 				     u64 requestid);
 
 extern int vmbus_establish_gpadl(struct vmbus_channel *channel,
 				      void *kbuffer,
 				      u32 size,
 				      u32 *gpadl_handle);
 
 extern int vmbus_teardown_gpadl(struct vmbus_channel *channel,
 				     u32 gpadl_handle);
 
 extern int vmbus_recvpacket(struct vmbus_channel *channel,
 				  void *buffer,
 				  u32 bufferlen,
 				  u32 *buffer_actual_len,
 				  u64 *requestid);
 
 extern int vmbus_recvpacket_raw(struct vmbus_channel *channel,
 				     void *buffer,
 				     u32 bufferlen,
 				     u32 *buffer_actual_len,
 				     u64 *requestid);
 
 
 extern void vmbus_ontimer(unsigned long data);
 
 /* Base driver object */
 struct hv_driver {
 	const char *name;
 
 	/*
 	 * A hvsock offer, which has a VMBUS_CHANNEL_TLNPI_PROVIDER_OFFER
 	 * channel flag, actually doesn't mean a synthetic device because the
 	 * offer's if_type/if_instance can change for every new hvsock
 	 * connection.
 	 *
 	 * However, to facilitate the notification of new-offer/rescind-offer
 	 * from vmbus driver to hvsock driver, we can handle hvsock offer as
 	 * a special vmbus device, and hence we need the below flag to
 	 * indicate if the driver is the hvsock driver or not: we need to
 	 * specially treat the hvosck offer & driver in vmbus_match().
 	 */
 	bool hvsock;
 
 	/* the device type supported by this driver */
 	uuid_le dev_type;
 	const struct hv_vmbus_device_id *id_table;
 
 	struct device_driver driver;
 
 	/* dynamic device GUID's */
 	struct  {
 		spinlock_t lock;
 		struct list_head list;
 	} dynids;
 
 	int (*probe)(struct hv_device *, const struct hv_vmbus_device_id *);
 	int (*remove)(struct hv_device *);
 	void (*shutdown)(struct hv_device *);
 
 };
 
 /* Base device object */
 struct hv_device {
 	/* the device type id of this device */
 	uuid_le dev_type;
 
 	/* the device instance id of this device */
 	uuid_le dev_instance;
 	u16 vendor_id;
 	u16 device_id;
 
 	struct device device;
 
 	struct vmbus_channel *channel;
 };
 
 
 static inline struct hv_device *device_to_hv_device(struct device *d)
 {
 	return container_of(d, struct hv_device, device);
 }
 
 static inline struct hv_driver *drv_to_hv_drv(struct device_driver *d)
 {
 	return container_of(d, struct hv_driver, driver);
 }
 
 static inline void hv_set_drvdata(struct hv_device *dev, void *data)
 {
 	dev_set_drvdata(&dev->device, data);
 }
 
 static inline void *hv_get_drvdata(struct hv_device *dev)
 {
 	return dev_get_drvdata(&dev->device);
 }
 
 /* Vmbus interface */
 #define vmbus_driver_register(driver)	\
 	__vmbus_driver_register(driver, THIS_MODULE, KBUILD_MODNAME)
 int __must_check __vmbus_driver_register(struct hv_driver *hv_driver,
 					 struct module *owner,
 					 const char *mod_name);
 void vmbus_driver_unregister(struct hv_driver *hv_driver);
 
 void vmbus_hvsock_device_unregister(struct vmbus_channel *channel);
 
 int vmbus_allocate_mmio(struct resource **new, struct hv_device *device_obj,
 			resource_size_t min, resource_size_t max,
 			resource_size_t size, resource_size_t align,
 			bool fb_overlap_ok);
 void vmbus_free_mmio(resource_size_t start, resource_size_t size);
 int vmbus_cpu_number_to_vp_number(int cpu_number);
 u64 hv_do_hypercall(u64 control, void *input, void *output);
 
 /*
  * GUID definitions of various offer types - services offered to the guest.
  */
 
 /*
  * Network GUID
  * {f8615163-df3e-46c5-913f-f2d2f965ed0e}
  */
 #define HV_NIC_GUID \
 	.guid = UUID_LE(0xf8615163, 0xdf3e, 0x46c5, 0x91, 0x3f, \
 			0xf2, 0xd2, 0xf9, 0x65, 0xed, 0x0e)
 
 /*
  * IDE GUID
  * {32412632-86cb-44a2-9b5c-50d1417354f5}
  */
 #define HV_IDE_GUID \
 	.guid = UUID_LE(0x32412632, 0x86cb, 0x44a2, 0x9b, 0x5c, \
 			0x50, 0xd1, 0x41, 0x73, 0x54, 0xf5)
 
 /*
  * SCSI GUID
  * {ba6163d9-04a1-4d29-b605-72e2ffb1dc7f}
  */
 #define HV_SCSI_GUID \
 	.guid = UUID_LE(0xba6163d9, 0x04a1, 0x4d29, 0xb6, 0x05, \
 			0x72, 0xe2, 0xff, 0xb1, 0xdc, 0x7f)
 
 /*
  * Shutdown GUID
  * {0e0b6031-5213-4934-818b-38d90ced39db}
  */
 #define HV_SHUTDOWN_GUID \
 	.guid = UUID_LE(0x0e0b6031, 0x5213, 0x4934, 0x81, 0x8b, \
 			0x38, 0xd9, 0x0c, 0xed, 0x39, 0xdb)
 
 /*
  * Time Synch GUID
  * {9527E630-D0AE-497b-ADCE-E80AB0175CAF}
  */
 #define HV_TS_GUID \
 	.guid = UUID_LE(0x9527e630, 0xd0ae, 0x497b, 0xad, 0xce, \
 			0xe8, 0x0a, 0xb0, 0x17, 0x5c, 0xaf)
 
 /*
  * Heartbeat GUID
  * {57164f39-9115-4e78-ab55-382f3bd5422d}
  */
 #define HV_HEART_BEAT_GUID \
 	.guid = UUID_LE(0x57164f39, 0x9115, 0x4e78, 0xab, 0x55, \
 			0x38, 0x2f, 0x3b, 0xd5, 0x42, 0x2d)
 
 /*
  * KVP GUID
  * {a9a0f4e7-5a45-4d96-b827-8a841e8c03e6}
  */
 #define HV_KVP_GUID \
 	.guid = UUID_LE(0xa9a0f4e7, 0x5a45, 0x4d96, 0xb8, 0x27, \
 			0x8a, 0x84, 0x1e, 0x8c, 0x03, 0xe6)
 
 /*
  * Dynamic memory GUID
  * {525074dc-8985-46e2-8057-a307dc18a502}
  */
 #define HV_DM_GUID \
 	.guid = UUID_LE(0x525074dc, 0x8985, 0x46e2, 0x80, 0x57, \
 			0xa3, 0x07, 0xdc, 0x18, 0xa5, 0x02)
 
 /*
  * Mouse GUID
  * {cfa8b69e-5b4a-4cc0-b98b-8ba1a1f3f95a}
  */
 #define HV_MOUSE_GUID \
 	.guid = UUID_LE(0xcfa8b69e, 0x5b4a, 0x4cc0, 0xb9, 0x8b, \
 			0x8b, 0xa1, 0xa1, 0xf3, 0xf9, 0x5a)
 
 /*
  * Keyboard GUID
  * {f912ad6d-2b17-48ea-bd65-f927a61c7684}
  */
 #define HV_KBD_GUID \
 	.guid = UUID_LE(0xf912ad6d, 0x2b17, 0x48ea, 0xbd, 0x65, \
 			0xf9, 0x27, 0xa6, 0x1c, 0x76, 0x84)
 
 /*
  * VSS (Backup/Restore) GUID
  */
 #define HV_VSS_GUID \
 	.guid = UUID_LE(0x35fa2e29, 0xea23, 0x4236, 0x96, 0xae, \
 			0x3a, 0x6e, 0xba, 0xcb, 0xa4, 0x40)
 /*
  * Synthetic Video GUID
  * {DA0A7802-E377-4aac-8E77-0558EB1073F8}
  */
 #define HV_SYNTHVID_GUID \
 	.guid = UUID_LE(0xda0a7802, 0xe377, 0x4aac, 0x8e, 0x77, \
 			0x05, 0x58, 0xeb, 0x10, 0x73, 0xf8)
 
 /*
  * Synthetic FC GUID
  * {2f9bcc4a-0069-4af3-b76b-6fd0be528cda}
  */
 #define HV_SYNTHFC_GUID \
 	.guid = UUID_LE(0x2f9bcc4a, 0x0069, 0x4af3, 0xb7, 0x6b, \
 			0x6f, 0xd0, 0xbe, 0x52, 0x8c, 0xda)
 
 /*
  * Guest File Copy Service
  * {34D14BE3-DEE4-41c8-9AE7-6B174977C192}
  */
 
 #define HV_FCOPY_GUID \
 	.guid = UUID_LE(0x34d14be3, 0xdee4, 0x41c8, 0x9a, 0xe7, \
 			0x6b, 0x17, 0x49, 0x77, 0xc1, 0x92)
 
 /*
  * NetworkDirect. This is the guest RDMA service.
  * {8c2eaf3d-32a7-4b09-ab99-bd1f1c86b501}
  */
 #define HV_ND_GUID \
 	.guid = UUID_LE(0x8c2eaf3d, 0x32a7, 0x4b09, 0xab, 0x99, \
 			0xbd, 0x1f, 0x1c, 0x86, 0xb5, 0x01)
 
 /*
  * PCI Express Pass Through
  * {44C4F61D-4444-4400-9D52-802E27EDE19F}
  */
 
 #define HV_PCIE_GUID \
 	.guid = UUID_LE(0x44c4f61d, 0x4444, 0x4400, 0x9d, 0x52, \
 			0x80, 0x2e, 0x27, 0xed, 0xe1, 0x9f)
 
 /*
  * Linux doesn't support the 3 devices: the first two are for
  * Automatic Virtual Machine Activation, and the third is for
  * Remote Desktop Virtualization.
  * {f8e65716-3cb3-4a06-9a60-1889c5cccab5}
  * {3375baf4-9e15-4b30-b765-67acb10d607b}
  * {276aacf4-ac15-426c-98dd-7521ad3f01fe}
  */
 
 #define HV_AVMA1_GUID \
 	.guid = UUID_LE(0xf8e65716, 0x3cb3, 0x4a06, 0x9a, 0x60, \
 			0x18, 0x89, 0xc5, 0xcc, 0xca, 0xb5)
 
 #define HV_AVMA2_GUID \
 	.guid = UUID_LE(0x3375baf4, 0x9e15, 0x4b30, 0xb7, 0x65, \
 			0x67, 0xac, 0xb1, 0x0d, 0x60, 0x7b)
 
 #define HV_RDV_GUID \
 	.guid = UUID_LE(0x276aacf4, 0xac15, 0x426c, 0x98, 0xdd, \
 			0x75, 0x21, 0xad, 0x3f, 0x01, 0xfe)
 
 /*
  * Common header for Hyper-V ICs
  */
 
 #define ICMSGTYPE_NEGOTIATE		0
 #define ICMSGTYPE_HEARTBEAT		1
 #define ICMSGTYPE_KVPEXCHANGE		2
 #define ICMSGTYPE_SHUTDOWN		3
 #define ICMSGTYPE_TIMESYNC		4
 #define ICMSGTYPE_VSS			5
 
 #define ICMSGHDRFLAG_TRANSACTION	1
 #define ICMSGHDRFLAG_REQUEST		2
 #define ICMSGHDRFLAG_RESPONSE		4
 
 
 /*
  * While we want to handle util services as regular devices,
  * there is only one instance of each of these services; so
  * we statically allocate the service specific state.
  */
 
 struct hv_util_service {
 	u8 *recv_buffer;
 	void *channel;
 	void (*util_cb)(void *);
 	int (*util_init)(struct hv_util_service *);
 	void (*util_deinit)(void);
 };
 
 struct vmbuspipe_hdr {
 	u32 flags;
 	u32 msgsize;
 } __packed;
 
 struct ic_version {
 	u16 major;
 	u16 minor;
 } __packed;
 
 struct icmsg_hdr {
 	struct ic_version icverframe;
 	u16 icmsgtype;
 	struct ic_version icvermsg;
 	u16 icmsgsize;
 	u32 status;
 	u8 ictransaction_id;
 	u8 icflags;
 	u8 reserved[2];
 } __packed;
 
 struct icmsg_negotiate {
 	u16 icframe_vercnt;
 	u16 icmsg_vercnt;
 	u32 reserved;
 	struct ic_version icversion_data[1]; /* any size array */
 } __packed;
 
 struct shutdown_msg_data {
 	u32 reason_code;
 	u32 timeout_seconds;
 	u32 flags;
 	u8  display_message[2048];
 } __packed;
 
 struct heartbeat_msg_data {
 	u64 seq_num;
 	u32 reserved[8];
 } __packed;
 
 /* Time Sync IC defs */
 #define ICTIMESYNCFLAG_PROBE	0
 #define ICTIMESYNCFLAG_SYNC	1
 #define ICTIMESYNCFLAG_SAMPLE	2
 
 #ifdef __x86_64__
 #define WLTIMEDELTA	116444736000000000L	/* in 100ns unit */
 #else
 #define WLTIMEDELTA	116444736000000000LL
 #endif
 
 struct ictimesync_data {
 	u64 parenttime;
 	u64 childtime;
 	u64 roundtriptime;
 	u8 flags;
 } __packed;
 
 struct ictimesync_ref_data {
 	u64 parenttime;
 	u64 vmreferencetime;
 	u8 flags;
 	char leapflags;
 	char stratum;
 	u8 reserved[3];
 } __packed;
 
 struct hyperv_service_callback {
 	u8 msg_type;
 	char *log_msg;
 	uuid_le data;
 	struct vmbus_channel *channel;
 	void (*callback) (void *context);
 };
 
 #define MAX_SRV_VER	0x7ffffff
-extern bool vmbus_prep_negotiate_resp(struct icmsg_hdr *,
-					struct icmsg_negotiate *, u8 *, int,
-					int);
+extern bool vmbus_prep_negotiate_resp(struct icmsg_hdr *icmsghdrp, u8 *buf,
+				const int *fw_version, int fw_vercnt,
+				const int *srv_version, int srv_vercnt,
+				int *nego_fw_version, int *nego_srv_version);
 
 void hv_event_tasklet_disable(struct vmbus_channel *channel);
 void hv_event_tasklet_enable(struct vmbus_channel *channel);
 
 void hv_process_channel_removal(struct vmbus_channel *channel, u32 relid);
 
 void vmbus_setevent(struct vmbus_channel *channel);
 /*
  * Negotiated version with the Host.
  */
 
 extern __u32 vmbus_proto_version;
 
 int vmbus_send_tl_connect_request(const uuid_le *shv_guest_servie_id,
 				  const uuid_le *shv_host_servie_id);
 void vmbus_set_event(struct vmbus_channel *channel);
 
 /* Get the start of the ring buffer. */
 static inline void *
-hv_get_ring_buffer(struct hv_ring_buffer_info *ring_info)
+hv_get_ring_buffer(const struct hv_ring_buffer_info *ring_info)
 {
-	return (void *)ring_info->ring_buffer->buffer;
+	return ring_info->ring_buffer->buffer;
 }
 
 /*
  * To optimize the flow management on the send-side,
  * when the sender is blocked because of lack of
  * sufficient space in the ring buffer, potential the
  * consumer of the ring buffer can signal the producer.
  * This is controlled by the following parameters:
  *
  * 1. pending_send_sz: This is the size in bytes that the
  *    producer is trying to send.
  * 2. The feature bit feat_pending_send_sz set to indicate if
  *    the consumer of the ring will signal when the ring
  *    state transitions from being full to a state where
  *    there is room for the producer to send the pending packet.
  */
 
 static inline  void hv_signal_on_read(struct vmbus_channel *channel)
 {
 	u32 cur_write_sz, cached_write_sz;
 	u32 pending_sz;
 	struct hv_ring_buffer_info *rbi = &channel->inbound;
 
 	/*
 	 * Issue a full memory barrier before making the signaling decision.
 	 * Here is the reason for having this barrier:
 	 * If the reading of the pend_sz (in this function)
 	 * were to be reordered and read before we commit the new read
 	 * index (in the calling function)  we could
 	 * have a problem. If the host were to set the pending_sz after we
 	 * have sampled pending_sz and go to sleep before we commit the
 	 * read index, we could miss sending the interrupt. Issue a full
 	 * memory barrier to address this.
 	 */
 	virt_mb();
 
 	pending_sz = READ_ONCE(rbi->ring_buffer->pending_send_sz);
 	/* If the other end is not blocked on write don't bother. */
 	if (pending_sz == 0)
 		return;
 
 	cur_write_sz = hv_get_bytes_to_write(rbi);
 
 	if (cur_write_sz < pending_sz)
 		return;
 
 	cached_write_sz = hv_get_cached_bytes_to_write(rbi);
 	if (cached_write_sz < pending_sz)
 		vmbus_setevent(channel);
 
 	return;
 }
 
 static inline void
 init_cached_read_index(struct vmbus_channel *channel)
 {
 	struct hv_ring_buffer_info *rbi = &channel->inbound;
 
 	rbi->cached_read_index = rbi->ring_buffer->read_index;
 }
 
+/*
+ * Mask off host interrupt callback notifications
+ */
+static inline void hv_begin_read(struct hv_ring_buffer_info *rbi)
+{
+	rbi->ring_buffer->interrupt_mask = 1;
+
+	/* make sure mask update is not reordered */
+	virt_mb();
+}
+
+/*
+ * Re-enable host callback and return number of outstanding bytes
+ */
+static inline u32 hv_end_read(struct hv_ring_buffer_info *rbi)
+{
+
+	rbi->ring_buffer->interrupt_mask = 0;
+
+	/* make sure mask update is not reordered */
+	virt_mb();
+
+	/*
+	 * Now check to see if the ring buffer is still empty.
+	 * If it is not, we raced and we need to process new
+	 * incoming messages.
+	 */
+	return hv_get_bytes_to_read(rbi);
+}
+
 /*
  * An API to support in-place processing of incoming VMBUS packets.
  */
 #define VMBUS_PKT_TRAILER	8
 
 static inline struct vmpacket_descriptor *
 get_next_pkt_raw(struct vmbus_channel *channel)
 {
 	struct hv_ring_buffer_info *ring_info = &channel->inbound;
 	u32 priv_read_loc = ring_info->priv_read_index;
 	void *ring_buffer = hv_get_ring_buffer(ring_info);
 	u32 dsize = ring_info->ring_datasize;
 	/*
 	 * delta is the difference between what is available to read and
 	 * what was already consumed in place. We commit read index after
 	 * the whole batch is processed.
 	 */
 	u32 delta = priv_read_loc >= ring_info->ring_buffer->read_index ?
 		priv_read_loc - ring_info->ring_buffer->read_index :
 		(dsize - ring_info->ring_buffer->read_index) + priv_read_loc;
 	u32 bytes_avail_toread = (hv_get_bytes_to_read(ring_info) - delta);
 
 	if (bytes_avail_toread < sizeof(struct vmpacket_descriptor))
 		return NULL;
 
 	return ring_buffer + priv_read_loc;
 }
 
 /*
  * A helper function to step through packets "in-place"
  * This API is to be called after each successful call
  * get_next_pkt_raw().
  */
 static inline void put_pkt_raw(struct vmbus_channel *channel,
 				struct vmpacket_descriptor *desc)
 {
 	struct hv_ring_buffer_info *ring_info = &channel->inbound;
 	u32 packetlen = desc->len8 << 3;
 	u32 dsize = ring_info->ring_datasize;
 
 	/*
 	 * Include the packet trailer.
 	 */
 	ring_info->priv_read_index += packetlen + VMBUS_PKT_TRAILER;
 	ring_info->priv_read_index %= dsize;
 }
 
 /*
  * This call commits the read index and potentially signals the host.
  * Here is the pattern for using the "in-place" consumption APIs:
  *
  * init_cached_read_index();
  *
  * while (get_next_pkt_raw() {
  *	process the packet "in-place";
  *	put_pkt_raw();
  * }
  * if (packets processed in place)
  *	commit_rd_index();
  */
 static inline void commit_rd_index(struct vmbus_channel *channel)
 {
 	struct hv_ring_buffer_info *ring_info = &channel->inbound;
 	/*
 	 * Make sure all reads are done before we update the read index since
 	 * the writer may start writing to the read area once the read index
 	 * is updated.
 	 */
 	virt_rmb();
 	ring_info->ring_buffer->read_index = ring_info->priv_read_index;
 
 	hv_signal_on_read(channel);
 }
 
 
 #endif /* _HYPERV_H */
diff --git a/include/linux/miscdevice.h b/include/linux/miscdevice.h
index ed30d5d713e3..0590263c462c 100644
--- a/include/linux/miscdevice.h
+++ b/include/linux/miscdevice.h
@@ -1,92 +1,93 @@
 #ifndef _LINUX_MISCDEVICE_H
 #define _LINUX_MISCDEVICE_H
 #include <linux/major.h>
 #include <linux/list.h>
 #include <linux/types.h>
 #include <linux/device.h>
 
 /*
  *	These allocations are managed by device@lanana.org. If you use an
  *	entry that is not in assigned your entry may well be moved and
  *	reassigned, or set dynamic if a fixed value is not justified.
  */
 
 #define PSMOUSE_MINOR		1
 #define MS_BUSMOUSE_MINOR	2	/* unused */
 #define ATIXL_BUSMOUSE_MINOR	3	/* unused */
 /*#define AMIGAMOUSE_MINOR	4	FIXME OBSOLETE */
 #define ATARIMOUSE_MINOR	5	/* unused */
 #define SUN_MOUSE_MINOR		6	/* unused */
 #define APOLLO_MOUSE_MINOR	7	/* unused */
 #define PC110PAD_MINOR		9	/* unused */
 /*#define ADB_MOUSE_MINOR	10	FIXME OBSOLETE */
 #define WATCHDOG_MINOR		130	/* Watchdog timer     */
 #define TEMP_MINOR		131	/* Temperature Sensor */
+#define APM_MINOR_DEV		134
 #define RTC_MINOR		135
 #define EFI_RTC_MINOR		136	/* EFI Time services */
 #define VHCI_MINOR		137
 #define SUN_OPENPROM_MINOR	139
 #define DMAPI_MINOR		140	/* unused */
 #define NVRAM_MINOR		144
 #define SGI_MMTIMER		153
 #define STORE_QUEUE_MINOR	155	/* unused */
 #define I2O_MINOR		166
 #define MICROCODE_MINOR		184
 #define IRNET_MINOR		187
 #define VFIO_MINOR		196
 #define TUN_MINOR		200
 #define CUSE_MINOR		203
 #define MWAVE_MINOR		219	/* ACP/Mwave Modem */
 #define MPT_MINOR		220
 #define MPT2SAS_MINOR		221
 #define MPT3SAS_MINOR		222
 #define UINPUT_MINOR		223
 #define MISC_MCELOG_MINOR	227
 #define HPET_MINOR		228
 #define FUSE_MINOR		229
 #define KVM_MINOR		232
 #define BTRFS_MINOR		234
 #define AUTOFS_MINOR		235
 #define MAPPER_CTRL_MINOR	236
 #define LOOP_CTRL_MINOR		237
 #define VHOST_NET_MINOR		238
 #define UHID_MINOR		239
 #define USERIO_MINOR		240
 #define MISC_DYNAMIC_MINOR	255
 
 struct device;
 struct attribute_group;
 
 struct miscdevice  {
 	int minor;
 	const char *name;
 	const struct file_operations *fops;
 	struct list_head list;
 	struct device *parent;
 	struct device *this_device;
 	const struct attribute_group **groups;
 	const char *nodename;
 	umode_t mode;
 };
 
 extern int misc_register(struct miscdevice *misc);
 extern void misc_deregister(struct miscdevice *misc);
 
 /*
  * Helper macro for drivers that don't do anything special in the initcall.
  * This helps in eleminating of boilerplate code.
  */
 #define builtin_misc_device(__misc_device) \
 	builtin_driver(__misc_device, misc_register)
 
 /*
  * Helper macro for drivers that don't do anything special in module init / exit
  * call. This helps in eleminating of boilerplate code.
  */
 #define module_misc_device(__misc_device) \
 	module_driver(__misc_device, misc_register, misc_deregister)
 
 #define MODULE_ALIAS_MISCDEV(minor)				\
 	MODULE_ALIAS("char-major-" __stringify(MISC_MAJOR)	\
 	"-" __stringify(minor))
 #endif
diff --git a/include/linux/platform_data/ti-aemif.h b/include/linux/platform_data/ti-aemif.h
new file mode 100644
index 000000000000..ac72e115093c
--- /dev/null
+++ b/include/linux/platform_data/ti-aemif.h
@@ -0,0 +1,23 @@
+/*
+ * TI DaVinci AEMIF platform glue.
+ *
+ * Copyright (C) 2017 BayLibre SAS
+ *
+ * Author:
+ *   Bartosz Golaszewski <bgolaszewski@baylibre.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#ifndef __TI_DAVINCI_AEMIF_DATA_H__
+#define __TI_DAVINCI_AEMIF_DATA_H__
+
+#include <linux/of_platform.h>
+
+struct aemif_platform_data {
+	struct of_dev_auxdata *dev_lookup;
+};
+
+#endif /* __TI_DAVINCI_AEMIF_DATA_H__ */
diff --git a/include/linux/sram.h b/include/linux/sram.h
new file mode 100644
index 000000000000..c97dcbe8ce25
--- /dev/null
+++ b/include/linux/sram.h
@@ -0,0 +1,27 @@
+/*
+ * Generic SRAM Driver Interface
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation version 2.
+ *
+ * This program is distributed "as is" WITHOUT ANY WARRANTY of any
+ * kind, whether express or implied; without even the implied warranty
+ * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+#ifndef __LINUX_SRAM_H__
+#define __LINUX_SRAM_H__
+
+struct gen_pool;
+
+#ifdef CONFIG_SRAM_EXEC
+int sram_exec_copy(struct gen_pool *pool, void *dst, void *src, size_t size);
+#else
+static inline int sram_exec_copy(struct gen_pool *pool, void *dst, void *src,
+				 size_t size)
+{
+	return -ENODEV;
+}
+#endif /* CONFIG_SRAM_EXEC */
+#endif /* __LINUX_SRAM_H__ */
diff --git a/include/linux/vme.h b/include/linux/vme.h
index 8c589176c2f8..ec5e8bf6118e 100644
--- a/include/linux/vme.h
+++ b/include/linux/vme.h
@@ -1,180 +1,179 @@
 #ifndef _VME_H_
 #define _VME_H_
 
 /* Resource Type */
 enum vme_resource_type {
 	VME_MASTER,
 	VME_SLAVE,
 	VME_DMA,
 	VME_LM
 };
 
 /* VME Address Spaces */
 #define VME_A16		0x1
 #define VME_A24		0x2
 #define	VME_A32		0x4
 #define VME_A64		0x8
 #define VME_CRCSR	0x10
 #define VME_USER1	0x20
 #define VME_USER2	0x40
 #define VME_USER3	0x80
 #define VME_USER4	0x100
 
 #define VME_A16_MAX	0x10000ULL
 #define VME_A24_MAX	0x1000000ULL
 #define VME_A32_MAX	0x100000000ULL
 #define VME_A64_MAX	0x10000000000000000ULL
 #define VME_CRCSR_MAX	0x1000000ULL
 
 
 /* VME Cycle Types */
 #define VME_SCT		0x1
 #define VME_BLT		0x2
 #define VME_MBLT	0x4
 #define VME_2eVME	0x8
 #define VME_2eSST	0x10
 #define VME_2eSSTB	0x20
 
 #define VME_2eSST160	0x100
 #define VME_2eSST267	0x200
 #define VME_2eSST320	0x400
 
 #define	VME_SUPER	0x1000
 #define	VME_USER	0x2000
 #define	VME_PROG	0x4000
 #define	VME_DATA	0x8000
 
 /* VME Data Widths */
 #define VME_D8		0x1
 #define VME_D16		0x2
 #define VME_D32		0x4
 #define VME_D64		0x8
 
 /* Arbitration Scheduling Modes */
 #define VME_R_ROBIN_MODE	0x1
 #define VME_PRIORITY_MODE	0x2
 
 #define VME_DMA_PATTERN			(1<<0)
 #define VME_DMA_PCI			(1<<1)
 #define VME_DMA_VME			(1<<2)
 
 #define VME_DMA_PATTERN_BYTE		(1<<0)
 #define VME_DMA_PATTERN_WORD		(1<<1)
 #define VME_DMA_PATTERN_INCREMENT	(1<<2)
 
 #define VME_DMA_VME_TO_MEM		(1<<0)
 #define VME_DMA_MEM_TO_VME		(1<<1)
 #define VME_DMA_VME_TO_VME		(1<<2)
 #define VME_DMA_MEM_TO_MEM		(1<<3)
 #define VME_DMA_PATTERN_TO_VME		(1<<4)
 #define VME_DMA_PATTERN_TO_MEM		(1<<5)
 
 struct vme_dma_attr {
 	u32 type;
 	void *private;
 };
 
 struct vme_resource {
 	enum vme_resource_type type;
 	struct list_head *entry;
 };
 
 extern struct bus_type vme_bus_type;
 
 /* Number of VME interrupt vectors */
 #define VME_NUM_STATUSID	256
 
 /* VME_MAX_BRIDGES comes from the type of vme_bus_numbers */
 #define VME_MAX_BRIDGES		(sizeof(unsigned int)*8)
 #define VME_MAX_SLOTS		32
 
 #define VME_SLOT_CURRENT	-1
 #define VME_SLOT_ALL		-2
 
 /**
  * Structure representing a VME device
  * @num: The device number
  * @bridge: Pointer to the bridge device this device is on
  * @dev: Internal device structure
  * @drv_list: List of devices (per driver)
  * @bridge_list: List of devices (per bridge)
  */
 struct vme_dev {
 	int num;
 	struct vme_bridge *bridge;
 	struct device dev;
 	struct list_head drv_list;
 	struct list_head bridge_list;
 };
 
 struct vme_driver {
-	struct list_head node;
 	const char *name;
 	int (*match)(struct vme_dev *);
 	int (*probe)(struct vme_dev *);
 	int (*remove)(struct vme_dev *);
 	struct device_driver driver;
 	struct list_head devices;
 };
 
 void *vme_alloc_consistent(struct vme_resource *, size_t, dma_addr_t *);
 void vme_free_consistent(struct vme_resource *, size_t,  void *,
 	dma_addr_t);
 
 size_t vme_get_size(struct vme_resource *);
 int vme_check_window(u32 aspace, unsigned long long vme_base,
 		     unsigned long long size);
 
 struct vme_resource *vme_slave_request(struct vme_dev *, u32, u32);
 int vme_slave_set(struct vme_resource *, int, unsigned long long,
 	unsigned long long, dma_addr_t, u32, u32);
 int vme_slave_get(struct vme_resource *, int *, unsigned long long *,
 	unsigned long long *, dma_addr_t *, u32 *, u32 *);
 void vme_slave_free(struct vme_resource *);
 
 struct vme_resource *vme_master_request(struct vme_dev *, u32, u32, u32);
 int vme_master_set(struct vme_resource *, int, unsigned long long,
 	unsigned long long, u32, u32, u32);
 int vme_master_get(struct vme_resource *, int *, unsigned long long *,
 	unsigned long long *, u32 *, u32 *, u32 *);
 ssize_t vme_master_read(struct vme_resource *, void *, size_t, loff_t);
 ssize_t vme_master_write(struct vme_resource *, void *, size_t, loff_t);
 unsigned int vme_master_rmw(struct vme_resource *, unsigned int, unsigned int,
 	unsigned int, loff_t);
 int vme_master_mmap(struct vme_resource *resource, struct vm_area_struct *vma);
 void vme_master_free(struct vme_resource *);
 
 struct vme_resource *vme_dma_request(struct vme_dev *, u32);
 struct vme_dma_list *vme_new_dma_list(struct vme_resource *);
 struct vme_dma_attr *vme_dma_pattern_attribute(u32, u32);
 struct vme_dma_attr *vme_dma_pci_attribute(dma_addr_t);
 struct vme_dma_attr *vme_dma_vme_attribute(unsigned long long, u32, u32, u32);
 void vme_dma_free_attribute(struct vme_dma_attr *);
 int vme_dma_list_add(struct vme_dma_list *, struct vme_dma_attr *,
 	struct vme_dma_attr *, size_t);
 int vme_dma_list_exec(struct vme_dma_list *);
 int vme_dma_list_free(struct vme_dma_list *);
 int vme_dma_free(struct vme_resource *);
 
 int vme_irq_request(struct vme_dev *, int, int,
 	void (*callback)(int, int, void *), void *);
 void vme_irq_free(struct vme_dev *, int, int);
 int vme_irq_generate(struct vme_dev *, int, int);
 
 struct vme_resource *vme_lm_request(struct vme_dev *);
 int vme_lm_count(struct vme_resource *);
 int vme_lm_set(struct vme_resource *, unsigned long long, u32, u32);
 int vme_lm_get(struct vme_resource *, unsigned long long *, u32 *, u32 *);
 int vme_lm_attach(struct vme_resource *, int, void (*callback)(void *), void *);
 int vme_lm_detach(struct vme_resource *, int);
 void vme_lm_free(struct vme_resource *);
 
 int vme_slot_num(struct vme_dev *);
 int vme_bus_num(struct vme_dev *);
 
 int vme_register_driver(struct vme_driver *, unsigned int);
 void vme_unregister_driver(struct vme_driver *);
 
 
 #endif /* _VME_H_ */
 
diff --git a/include/linux/vmw_vmci_defs.h b/include/linux/vmw_vmci_defs.h
index 1bd31a38c51e..b724ef7005de 100644
--- a/include/linux/vmw_vmci_defs.h
+++ b/include/linux/vmw_vmci_defs.h
@@ -1,915 +1,908 @@
 /*
  * VMware VMCI Driver
  *
  * Copyright (C) 2012 VMware, Inc. All rights reserved.
  *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License as published by the
  * Free Software Foundation version 2 and no later version.
  *
  * This program is distributed in the hope that it will be useful, but
  * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  * for more details.
  */
 
 #ifndef _VMW_VMCI_DEF_H_
 #define _VMW_VMCI_DEF_H_
 
 #include <linux/atomic.h>
 
 /* Register offsets. */
 #define VMCI_STATUS_ADDR      0x00
 #define VMCI_CONTROL_ADDR     0x04
 #define VMCI_ICR_ADDR	      0x08
 #define VMCI_IMR_ADDR         0x0c
 #define VMCI_DATA_OUT_ADDR    0x10
 #define VMCI_DATA_IN_ADDR     0x14
 #define VMCI_CAPS_ADDR        0x18
 #define VMCI_RESULT_LOW_ADDR  0x1c
 #define VMCI_RESULT_HIGH_ADDR 0x20
 
 /* Max number of devices. */
 #define VMCI_MAX_DEVICES 1
 
 /* Status register bits. */
 #define VMCI_STATUS_INT_ON     0x1
 
 /* Control register bits. */
 #define VMCI_CONTROL_RESET        0x1
 #define VMCI_CONTROL_INT_ENABLE   0x2
 #define VMCI_CONTROL_INT_DISABLE  0x4
 
 /* Capabilities register bits. */
 #define VMCI_CAPS_HYPERCALL     0x1
 #define VMCI_CAPS_GUESTCALL     0x2
 #define VMCI_CAPS_DATAGRAM      0x4
 #define VMCI_CAPS_NOTIFICATIONS 0x8
 
 /* Interrupt Cause register bits. */
 #define VMCI_ICR_DATAGRAM      0x1
 #define VMCI_ICR_NOTIFICATION  0x2
 
 /* Interrupt Mask register bits. */
 #define VMCI_IMR_DATAGRAM      0x1
 #define VMCI_IMR_NOTIFICATION  0x2
 
-/* Interrupt type. */
-enum {
-	VMCI_INTR_TYPE_INTX = 0,
-	VMCI_INTR_TYPE_MSI = 1,
-	VMCI_INTR_TYPE_MSIX = 2,
-};
-
 /* Maximum MSI/MSI-X interrupt vectors in the device. */
 #define VMCI_MAX_INTRS 2
 
 /*
  * Supported interrupt vectors.  There is one for each ICR value above,
  * but here they indicate the position in the vector array/message ID.
  */
 enum {
 	VMCI_INTR_DATAGRAM = 0,
 	VMCI_INTR_NOTIFICATION = 1,
 };
 
 /*
  * A single VMCI device has an upper limit of 128MB on the amount of
  * memory that can be used for queue pairs.
  */
 #define VMCI_MAX_GUEST_QP_MEMORY (128 * 1024 * 1024)
 
 /*
  * Queues with pre-mapped data pages must be small, so that we don't pin
  * too much kernel memory (especially on vmkernel).  We limit a queuepair to
  * 32 KB, or 16 KB per queue for symmetrical pairs.
  */
 #define VMCI_MAX_PINNED_QP_MEMORY (32 * 1024)
 
 /*
  * We have a fixed set of resource IDs available in the VMX.
  * This allows us to have a very simple implementation since we statically
  * know how many will create datagram handles. If a new caller arrives and
  * we have run out of slots we can manually increment the maximum size of
  * available resource IDs.
  *
  * VMCI reserved hypervisor datagram resource IDs.
  */
 enum {
 	VMCI_RESOURCES_QUERY = 0,
 	VMCI_GET_CONTEXT_ID = 1,
 	VMCI_SET_NOTIFY_BITMAP = 2,
 	VMCI_DOORBELL_LINK = 3,
 	VMCI_DOORBELL_UNLINK = 4,
 	VMCI_DOORBELL_NOTIFY = 5,
 	/*
 	 * VMCI_DATAGRAM_REQUEST_MAP and VMCI_DATAGRAM_REMOVE_MAP are
 	 * obsoleted by the removal of VM to VM communication.
 	 */
 	VMCI_DATAGRAM_REQUEST_MAP = 6,
 	VMCI_DATAGRAM_REMOVE_MAP = 7,
 	VMCI_EVENT_SUBSCRIBE = 8,
 	VMCI_EVENT_UNSUBSCRIBE = 9,
 	VMCI_QUEUEPAIR_ALLOC = 10,
 	VMCI_QUEUEPAIR_DETACH = 11,
 
 	/*
 	 * VMCI_VSOCK_VMX_LOOKUP was assigned to 12 for Fusion 3.0/3.1,
 	 * WS 7.0/7.1 and ESX 4.1
 	 */
 	VMCI_HGFS_TRANSPORT = 13,
 	VMCI_UNITY_PBRPC_REGISTER = 14,
 	VMCI_RPC_PRIVILEGED = 15,
 	VMCI_RPC_UNPRIVILEGED = 16,
 	VMCI_RESOURCE_MAX = 17,
 };
 
 /*
  * struct vmci_handle - Ownership information structure
  * @context:    The VMX context ID.
  * @resource:   The resource ID (used for locating in resource hash).
  *
  * The vmci_handle structure is used to track resources used within
  * vmw_vmci.
  */
 struct vmci_handle {
 	u32 context;
 	u32 resource;
 };
 
 #define vmci_make_handle(_cid, _rid) \
 	(struct vmci_handle){ .context = _cid, .resource = _rid }
 
 static inline bool vmci_handle_is_equal(struct vmci_handle h1,
 					struct vmci_handle h2)
 {
 	return h1.context == h2.context && h1.resource == h2.resource;
 }
 
 #define VMCI_INVALID_ID ~0
 static const struct vmci_handle VMCI_INVALID_HANDLE = {
 	.context = VMCI_INVALID_ID,
 	.resource = VMCI_INVALID_ID
 };
 
 static inline bool vmci_handle_is_invalid(struct vmci_handle h)
 {
 	return vmci_handle_is_equal(h, VMCI_INVALID_HANDLE);
 }
 
 /*
  * The below defines can be used to send anonymous requests.
  * This also indicates that no response is expected.
  */
 #define VMCI_ANON_SRC_CONTEXT_ID   VMCI_INVALID_ID
 #define VMCI_ANON_SRC_RESOURCE_ID  VMCI_INVALID_ID
 static const struct vmci_handle VMCI_ANON_SRC_HANDLE = {
 	.context = VMCI_ANON_SRC_CONTEXT_ID,
 	.resource = VMCI_ANON_SRC_RESOURCE_ID
 };
 
 /* The lowest 16 context ids are reserved for internal use. */
 #define VMCI_RESERVED_CID_LIMIT ((u32) 16)
 
 /*
  * Hypervisor context id, used for calling into hypervisor
  * supplied services from the VM.
  */
 #define VMCI_HYPERVISOR_CONTEXT_ID 0
 
 /*
  * Well-known context id, a logical context that contains a set of
  * well-known services. This context ID is now obsolete.
  */
 #define VMCI_WELL_KNOWN_CONTEXT_ID 1
 
 /*
  * Context ID used by host endpoints.
  */
 #define VMCI_HOST_CONTEXT_ID  2
 
 #define VMCI_CONTEXT_IS_VM(_cid) (VMCI_INVALID_ID != (_cid) &&		\
 				  (_cid) > VMCI_HOST_CONTEXT_ID)
 
 /*
  * The VMCI_CONTEXT_RESOURCE_ID is used together with vmci_make_handle to make
  * handles that refer to a specific context.
  */
 #define VMCI_CONTEXT_RESOURCE_ID 0
 
 /*
  * VMCI error codes.
  */
 enum {
 	VMCI_SUCCESS_QUEUEPAIR_ATTACH	= 5,
 	VMCI_SUCCESS_QUEUEPAIR_CREATE	= 4,
 	VMCI_SUCCESS_LAST_DETACH	= 3,
 	VMCI_SUCCESS_ACCESS_GRANTED	= 2,
 	VMCI_SUCCESS_ENTRY_DEAD		= 1,
 	VMCI_SUCCESS			 = 0,
 	VMCI_ERROR_INVALID_RESOURCE	 = (-1),
 	VMCI_ERROR_INVALID_ARGS		 = (-2),
 	VMCI_ERROR_NO_MEM		 = (-3),
 	VMCI_ERROR_DATAGRAM_FAILED	 = (-4),
 	VMCI_ERROR_MORE_DATA		 = (-5),
 	VMCI_ERROR_NO_MORE_DATAGRAMS	 = (-6),
 	VMCI_ERROR_NO_ACCESS		 = (-7),
 	VMCI_ERROR_NO_HANDLE		 = (-8),
 	VMCI_ERROR_DUPLICATE_ENTRY	 = (-9),
 	VMCI_ERROR_DST_UNREACHABLE	 = (-10),
 	VMCI_ERROR_PAYLOAD_TOO_LARGE	 = (-11),
 	VMCI_ERROR_INVALID_PRIV		 = (-12),
 	VMCI_ERROR_GENERIC		 = (-13),
 	VMCI_ERROR_PAGE_ALREADY_SHARED	 = (-14),
 	VMCI_ERROR_CANNOT_SHARE_PAGE	 = (-15),
 	VMCI_ERROR_CANNOT_UNSHARE_PAGE	 = (-16),
 	VMCI_ERROR_NO_PROCESS		 = (-17),
 	VMCI_ERROR_NO_DATAGRAM		 = (-18),
 	VMCI_ERROR_NO_RESOURCES		 = (-19),
 	VMCI_ERROR_UNAVAILABLE		 = (-20),
 	VMCI_ERROR_NOT_FOUND		 = (-21),
 	VMCI_ERROR_ALREADY_EXISTS	 = (-22),
 	VMCI_ERROR_NOT_PAGE_ALIGNED	 = (-23),
 	VMCI_ERROR_INVALID_SIZE		 = (-24),
 	VMCI_ERROR_REGION_ALREADY_SHARED = (-25),
 	VMCI_ERROR_TIMEOUT		 = (-26),
 	VMCI_ERROR_DATAGRAM_INCOMPLETE	 = (-27),
 	VMCI_ERROR_INCORRECT_IRQL	 = (-28),
 	VMCI_ERROR_EVENT_UNKNOWN	 = (-29),
 	VMCI_ERROR_OBSOLETE		 = (-30),
 	VMCI_ERROR_QUEUEPAIR_MISMATCH	 = (-31),
 	VMCI_ERROR_QUEUEPAIR_NOTSET	 = (-32),
 	VMCI_ERROR_QUEUEPAIR_NOTOWNER	 = (-33),
 	VMCI_ERROR_QUEUEPAIR_NOTATTACHED = (-34),
 	VMCI_ERROR_QUEUEPAIR_NOSPACE	 = (-35),
 	VMCI_ERROR_QUEUEPAIR_NODATA	 = (-36),
 	VMCI_ERROR_BUSMEM_INVALIDATION	 = (-37),
 	VMCI_ERROR_MODULE_NOT_LOADED	 = (-38),
 	VMCI_ERROR_DEVICE_NOT_FOUND	 = (-39),
 	VMCI_ERROR_QUEUEPAIR_NOT_READY	 = (-40),
 	VMCI_ERROR_WOULD_BLOCK		 = (-41),
 
 	/* VMCI clients should return error code within this range */
 	VMCI_ERROR_CLIENT_MIN		 = (-500),
 	VMCI_ERROR_CLIENT_MAX		 = (-550),
 
 	/* Internal error codes. */
 	VMCI_SHAREDMEM_ERROR_BAD_CONTEXT = (-1000),
 };
 
 /* VMCI reserved events. */
 enum {
 	/* Only applicable to guest endpoints */
 	VMCI_EVENT_CTX_ID_UPDATE  = 0,
 
 	/* Applicable to guest and host */
 	VMCI_EVENT_CTX_REMOVED	  = 1,
 
 	/* Only applicable to guest endpoints */
 	VMCI_EVENT_QP_RESUMED	  = 2,
 
 	/* Applicable to guest and host */
 	VMCI_EVENT_QP_PEER_ATTACH = 3,
 
 	/* Applicable to guest and host */
 	VMCI_EVENT_QP_PEER_DETACH = 4,
 
 	/*
 	 * Applicable to VMX and vmk.  On vmk,
 	 * this event has the Context payload type.
 	 */
 	VMCI_EVENT_MEM_ACCESS_ON  = 5,
 
 	/*
 	 * Applicable to VMX and vmk.  Same as
 	 * above for the payload type.
 	 */
 	VMCI_EVENT_MEM_ACCESS_OFF = 6,
 	VMCI_EVENT_MAX		  = 7,
 };
 
 /*
  * Of the above events, a few are reserved for use in the VMX, and
  * other endpoints (guest and host kernel) should not use them. For
  * the rest of the events, we allow both host and guest endpoints to
  * subscribe to them, to maintain the same API for host and guest
  * endpoints.
  */
 #define VMCI_EVENT_VALID_VMX(_event) ((_event) == VMCI_EVENT_MEM_ACCESS_ON || \
 				      (_event) == VMCI_EVENT_MEM_ACCESS_OFF)
 
 #define VMCI_EVENT_VALID(_event) ((_event) < VMCI_EVENT_MAX &&		\
 				  !VMCI_EVENT_VALID_VMX(_event))
 
 /* Reserved guest datagram resource ids. */
 #define VMCI_EVENT_HANDLER 0
 
 /*
  * VMCI coarse-grained privileges (per context or host
  * process/endpoint. An entity with the restricted flag is only
  * allowed to interact with the hypervisor and trusted entities.
  */
 enum {
 	VMCI_NO_PRIVILEGE_FLAGS = 0,
 	VMCI_PRIVILEGE_FLAG_RESTRICTED = 1,
 	VMCI_PRIVILEGE_FLAG_TRUSTED = 2,
 	VMCI_PRIVILEGE_ALL_FLAGS = (VMCI_PRIVILEGE_FLAG_RESTRICTED |
 				    VMCI_PRIVILEGE_FLAG_TRUSTED),
 	VMCI_DEFAULT_PROC_PRIVILEGE_FLAGS = VMCI_NO_PRIVILEGE_FLAGS,
 	VMCI_LEAST_PRIVILEGE_FLAGS = VMCI_PRIVILEGE_FLAG_RESTRICTED,
 	VMCI_MAX_PRIVILEGE_FLAGS = VMCI_PRIVILEGE_FLAG_TRUSTED,
 };
 
 /* 0 through VMCI_RESERVED_RESOURCE_ID_MAX are reserved. */
 #define VMCI_RESERVED_RESOURCE_ID_MAX 1023
 
 /*
  * Driver version.
  *
  * Increment major version when you make an incompatible change.
  * Compatibility goes both ways (old driver with new executable
  * as well as new driver with old executable).
  */
 
 /* Never change VMCI_VERSION_SHIFT_WIDTH */
 #define VMCI_VERSION_SHIFT_WIDTH 16
 #define VMCI_MAKE_VERSION(_major, _minor)			\
 	((_major) << VMCI_VERSION_SHIFT_WIDTH | (u16) (_minor))
 
 #define VMCI_VERSION_MAJOR(v)  ((u32) (v) >> VMCI_VERSION_SHIFT_WIDTH)
 #define VMCI_VERSION_MINOR(v)  ((u16) (v))
 
 /*
  * VMCI_VERSION is always the current version.  Subsequently listed
  * versions are ways of detecting previous versions of the connecting
  * application (i.e., VMX).
  *
  * VMCI_VERSION_NOVMVM: This version removed support for VM to VM
  * communication.
  *
  * VMCI_VERSION_NOTIFY: This version introduced doorbell notification
  * support.
  *
  * VMCI_VERSION_HOSTQP: This version introduced host end point support
  * for hosted products.
  *
  * VMCI_VERSION_PREHOSTQP: This is the version prior to the adoption of
  * support for host end-points.
  *
  * VMCI_VERSION_PREVERS2: This fictional version number is intended to
  * represent the version of a VMX which doesn't call into the driver
  * with ioctl VERSION2 and thus doesn't establish its version with the
  * driver.
  */
 
 #define VMCI_VERSION                VMCI_VERSION_NOVMVM
 #define VMCI_VERSION_NOVMVM         VMCI_MAKE_VERSION(11, 0)
 #define VMCI_VERSION_NOTIFY         VMCI_MAKE_VERSION(10, 0)
 #define VMCI_VERSION_HOSTQP         VMCI_MAKE_VERSION(9, 0)
 #define VMCI_VERSION_PREHOSTQP      VMCI_MAKE_VERSION(8, 0)
 #define VMCI_VERSION_PREVERS2       VMCI_MAKE_VERSION(1, 0)
 
 #define VMCI_SOCKETS_MAKE_VERSION(_p)					\
 	((((_p)[0] & 0xFF) << 24) | (((_p)[1] & 0xFF) << 16) | ((_p)[2]))
 
 /*
  * The VMCI IOCTLs.  We use identity code 7, as noted in ioctl-number.h, and
  * we start at sequence 9f.  This gives us the same values that our shipping
  * products use, starting at 1951, provided we leave out the direction and
  * structure size.  Note that VMMon occupies the block following us, starting
  * at 2001.
  */
 #define IOCTL_VMCI_VERSION			_IO(7, 0x9f)	/* 1951 */
 #define IOCTL_VMCI_INIT_CONTEXT			_IO(7, 0xa0)
 #define IOCTL_VMCI_QUEUEPAIR_SETVA		_IO(7, 0xa4)
 #define IOCTL_VMCI_NOTIFY_RESOURCE		_IO(7, 0xa5)
 #define IOCTL_VMCI_NOTIFICATIONS_RECEIVE	_IO(7, 0xa6)
 #define IOCTL_VMCI_VERSION2			_IO(7, 0xa7)
 #define IOCTL_VMCI_QUEUEPAIR_ALLOC		_IO(7, 0xa8)
 #define IOCTL_VMCI_QUEUEPAIR_SETPAGEFILE	_IO(7, 0xa9)
 #define IOCTL_VMCI_QUEUEPAIR_DETACH		_IO(7, 0xaa)
 #define IOCTL_VMCI_DATAGRAM_SEND		_IO(7, 0xab)
 #define IOCTL_VMCI_DATAGRAM_RECEIVE		_IO(7, 0xac)
 #define IOCTL_VMCI_CTX_ADD_NOTIFICATION		_IO(7, 0xaf)
 #define IOCTL_VMCI_CTX_REMOVE_NOTIFICATION	_IO(7, 0xb0)
 #define IOCTL_VMCI_CTX_GET_CPT_STATE		_IO(7, 0xb1)
 #define IOCTL_VMCI_CTX_SET_CPT_STATE		_IO(7, 0xb2)
 #define IOCTL_VMCI_GET_CONTEXT_ID		_IO(7, 0xb3)
 #define IOCTL_VMCI_SOCKETS_VERSION		_IO(7, 0xb4)
 #define IOCTL_VMCI_SOCKETS_GET_AF_VALUE		_IO(7, 0xb8)
 #define IOCTL_VMCI_SOCKETS_GET_LOCAL_CID	_IO(7, 0xb9)
 #define IOCTL_VMCI_SET_NOTIFY			_IO(7, 0xcb)	/* 1995 */
 /*IOCTL_VMMON_START				_IO(7, 0xd1)*/	/* 2001 */
 
 /*
  * struct vmci_queue_header - VMCI Queue Header information.
  *
  * A Queue cannot stand by itself as designed.  Each Queue's header
  * contains a pointer into itself (the producer_tail) and into its peer
  * (consumer_head).  The reason for the separation is one of
  * accessibility: Each end-point can modify two things: where the next
  * location to enqueue is within its produce_q (producer_tail); and
  * where the next dequeue location is in its consume_q (consumer_head).
  *
  * An end-point cannot modify the pointers of its peer (guest to
  * guest; NOTE that in the host both queue headers are mapped r/w).
  * But, each end-point needs read access to both Queue header
  * structures in order to determine how much space is used (or left)
  * in the Queue.  This is because for an end-point to know how full
  * its produce_q is, it needs to use the consumer_head that points into
  * the produce_q but -that- consumer_head is in the Queue header for
  * that end-points consume_q.
  *
  * Thoroughly confused?  Sorry.
  *
  * producer_tail: the point to enqueue new entrants.  When you approach
  * a line in a store, for example, you walk up to the tail.
  *
  * consumer_head: the point in the queue from which the next element is
  * dequeued.  In other words, who is next in line is he who is at the
  * head of the line.
  *
  * Also, producer_tail points to an empty byte in the Queue, whereas
  * consumer_head points to a valid byte of data (unless producer_tail ==
  * consumer_head in which case consumer_head does not point to a valid
  * byte of data).
  *
  * For a queue of buffer 'size' bytes, the tail and head pointers will be in
  * the range [0, size-1].
  *
  * If produce_q_header->producer_tail == consume_q_header->consumer_head
  * then the produce_q is empty.
  */
 struct vmci_queue_header {
 	/* All fields are 64bit and aligned. */
 	struct vmci_handle handle;	/* Identifier. */
 	atomic64_t producer_tail;	/* Offset in this queue. */
 	atomic64_t consumer_head;	/* Offset in peer queue. */
 };
 
 /*
  * struct vmci_datagram - Base struct for vmci datagrams.
  * @dst:        A vmci_handle that tracks the destination of the datagram.
  * @src:        A vmci_handle that tracks the source of the datagram.
  * @payload_size:       The size of the payload.
  *
  * vmci_datagram structs are used when sending vmci datagrams.  They include
  * the necessary source and destination information to properly route
  * the information along with the size of the package.
  */
 struct vmci_datagram {
 	struct vmci_handle dst;
 	struct vmci_handle src;
 	u64 payload_size;
 };
 
 /*
  * Second flag is for creating a well-known handle instead of a per context
  * handle.  Next flag is for deferring datagram delivery, so that the
  * datagram callback is invoked in a delayed context (not interrupt context).
  */
 #define VMCI_FLAG_DG_NONE          0
 #define VMCI_FLAG_WELLKNOWN_DG_HND 0x1
 #define VMCI_FLAG_ANYCID_DG_HND    0x2
 #define VMCI_FLAG_DG_DELAYED_CB    0x4
 
 /*
  * Maximum supported size of a VMCI datagram for routable datagrams.
  * Datagrams going to the hypervisor are allowed to be larger.
  */
 #define VMCI_MAX_DG_SIZE (17 * 4096)
 #define VMCI_MAX_DG_PAYLOAD_SIZE (VMCI_MAX_DG_SIZE - \
 				  sizeof(struct vmci_datagram))
 #define VMCI_DG_PAYLOAD(_dg) (void *)((char *)(_dg) +			\
 				      sizeof(struct vmci_datagram))
 #define VMCI_DG_HEADERSIZE sizeof(struct vmci_datagram)
 #define VMCI_DG_SIZE(_dg) (VMCI_DG_HEADERSIZE + (size_t)(_dg)->payload_size)
 #define VMCI_DG_SIZE_ALIGNED(_dg) ((VMCI_DG_SIZE(_dg) + 7) & (~((size_t) 0x7)))
 #define VMCI_MAX_DATAGRAM_QUEUE_SIZE (VMCI_MAX_DG_SIZE * 2)
 
 struct vmci_event_payload_qp {
 	struct vmci_handle handle;  /* queue_pair handle. */
 	u32 peer_id;		    /* Context id of attaching/detaching VM. */
 	u32 _pad;
 };
 
 /* Flags for VMCI queue_pair API. */
 enum {
 	/* Fail alloc if QP not created by peer. */
 	VMCI_QPFLAG_ATTACH_ONLY = 1 << 0,
 
 	/* Only allow attaches from local context. */
 	VMCI_QPFLAG_LOCAL = 1 << 1,
 
 	/* Host won't block when guest is quiesced. */
 	VMCI_QPFLAG_NONBLOCK = 1 << 2,
 
 	/* Pin data pages in ESX.  Used with NONBLOCK */
 	VMCI_QPFLAG_PINNED = 1 << 3,
 
 	/* Update the following flag when adding new flags. */
 	VMCI_QP_ALL_FLAGS = (VMCI_QPFLAG_ATTACH_ONLY | VMCI_QPFLAG_LOCAL |
 			     VMCI_QPFLAG_NONBLOCK | VMCI_QPFLAG_PINNED),
 
 	/* Convenience flags */
 	VMCI_QP_ASYMM = (VMCI_QPFLAG_NONBLOCK | VMCI_QPFLAG_PINNED),
 	VMCI_QP_ASYMM_PEER = (VMCI_QPFLAG_ATTACH_ONLY | VMCI_QP_ASYMM),
 };
 
 /*
  * We allow at least 1024 more event datagrams from the hypervisor past the
  * normally allowed datagrams pending for a given context.  We define this
  * limit on event datagrams from the hypervisor to guard against DoS attack
  * from a malicious VM which could repeatedly attach to and detach from a queue
  * pair, causing events to be queued at the destination VM.  However, the rate
  * at which such events can be generated is small since it requires a VM exit
  * and handling of queue pair attach/detach call at the hypervisor.  Event
  * datagrams may be queued up at the destination VM if it has interrupts
  * disabled or if it is not draining events for some other reason.  1024
  * datagrams is a grossly conservative estimate of the time for which
  * interrupts may be disabled in the destination VM, but at the same time does
  * not exacerbate the memory pressure problem on the host by much (size of each
  * event datagram is small).
  */
 #define VMCI_MAX_DATAGRAM_AND_EVENT_QUEUE_SIZE				\
 	(VMCI_MAX_DATAGRAM_QUEUE_SIZE +					\
 	 1024 * (sizeof(struct vmci_datagram) +				\
 		 sizeof(struct vmci_event_data_max)))
 
 /*
  * Struct used for querying, via VMCI_RESOURCES_QUERY, the availability of
  * hypervisor resources.  Struct size is 16 bytes. All fields in struct are
  * aligned to their natural alignment.
  */
 struct vmci_resource_query_hdr {
 	struct vmci_datagram hdr;
 	u32 num_resources;
 	u32 _padding;
 };
 
 /*
  * Convenience struct for negotiating vectors. Must match layout of
  * VMCIResourceQueryHdr minus the struct vmci_datagram header.
  */
 struct vmci_resource_query_msg {
 	u32 num_resources;
 	u32 _padding;
 	u32 resources[1];
 };
 
 /*
  * The maximum number of resources that can be queried using
  * VMCI_RESOURCE_QUERY is 31, as the result is encoded in the lower 31
  * bits of a positive return value. Negative values are reserved for
  * errors.
  */
 #define VMCI_RESOURCE_QUERY_MAX_NUM 31
 
 /* Maximum size for the VMCI_RESOURCE_QUERY request. */
 #define VMCI_RESOURCE_QUERY_MAX_SIZE				\
 	(sizeof(struct vmci_resource_query_hdr) +		\
 	 sizeof(u32) * VMCI_RESOURCE_QUERY_MAX_NUM)
 
 /*
  * Struct used for setting the notification bitmap.  All fields in
  * struct are aligned to their natural alignment.
  */
 struct vmci_notify_bm_set_msg {
 	struct vmci_datagram hdr;
 	u32 bitmap_ppn;
 	u32 _pad;
 };
 
 /*
  * Struct used for linking a doorbell handle with an index in the
  * notify bitmap. All fields in struct are aligned to their natural
  * alignment.
  */
 struct vmci_doorbell_link_msg {
 	struct vmci_datagram hdr;
 	struct vmci_handle handle;
 	u64 notify_idx;
 };
 
 /*
  * Struct used for unlinking a doorbell handle from an index in the
  * notify bitmap. All fields in struct are aligned to their natural
  * alignment.
  */
 struct vmci_doorbell_unlink_msg {
 	struct vmci_datagram hdr;
 	struct vmci_handle handle;
 };
 
 /*
  * Struct used for generating a notification on a doorbell handle. All
  * fields in struct are aligned to their natural alignment.
  */
 struct vmci_doorbell_notify_msg {
 	struct vmci_datagram hdr;
 	struct vmci_handle handle;
 };
 
 /*
  * This struct is used to contain data for events.  Size of this struct is a
  * multiple of 8 bytes, and all fields are aligned to their natural alignment.
  */
 struct vmci_event_data {
 	u32 event;		/* 4 bytes. */
 	u32 _pad;
 	/* Event payload is put here. */
 };
 
 /*
  * Define the different VMCI_EVENT payload data types here.  All structs must
  * be a multiple of 8 bytes, and fields must be aligned to their natural
  * alignment.
  */
 struct vmci_event_payld_ctx {
 	u32 context_id;	/* 4 bytes. */
 	u32 _pad;
 };
 
 struct vmci_event_payld_qp {
 	struct vmci_handle handle;  /* queue_pair handle. */
 	u32 peer_id;	    /* Context id of attaching/detaching VM. */
 	u32 _pad;
 };
 
 /*
  * We define the following struct to get the size of the maximum event
  * data the hypervisor may send to the guest.  If adding a new event
  * payload type above, add it to the following struct too (inside the
  * union).
  */
 struct vmci_event_data_max {
 	struct vmci_event_data event_data;
 	union {
 		struct vmci_event_payld_ctx context_payload;
 		struct vmci_event_payld_qp qp_payload;
 	} ev_data_payload;
 };
 
 /*
  * Struct used for VMCI_EVENT_SUBSCRIBE/UNSUBSCRIBE and
  * VMCI_EVENT_HANDLER messages.  Struct size is 32 bytes.  All fields
  * in struct are aligned to their natural alignment.
  */
 struct vmci_event_msg {
 	struct vmci_datagram hdr;
 
 	/* Has event type and payload. */
 	struct vmci_event_data event_data;
 
 	/* Payload gets put here. */
 };
 
 /* Event with context payload. */
 struct vmci_event_ctx {
 	struct vmci_event_msg msg;
 	struct vmci_event_payld_ctx payload;
 };
 
 /* Event with QP payload. */
 struct vmci_event_qp {
 	struct vmci_event_msg msg;
 	struct vmci_event_payld_qp payload;
 };
 
 /*
  * Structs used for queue_pair alloc and detach messages.  We align fields of
  * these structs to 64bit boundaries.
  */
 struct vmci_qp_alloc_msg {
 	struct vmci_datagram hdr;
 	struct vmci_handle handle;
 	u32 peer;
 	u32 flags;
 	u64 produce_size;
 	u64 consume_size;
 	u64 num_ppns;
 
 	/* List of PPNs placed here. */
 };
 
 struct vmci_qp_detach_msg {
 	struct vmci_datagram hdr;
 	struct vmci_handle handle;
 };
 
 /* VMCI Doorbell API. */
 #define VMCI_FLAG_DELAYED_CB 0x01
 
 typedef void (*vmci_callback) (void *client_data);
 
 /*
  * struct vmci_qp - A vmw_vmci queue pair handle.
  *
  * This structure is used as a handle to a queue pair created by
  * VMCI.  It is intentionally left opaque to clients.
  */
 struct vmci_qp;
 
 /* Callback needed for correctly waiting on events. */
 typedef int (*vmci_datagram_recv_cb) (void *client_data,
 				      struct vmci_datagram *msg);
 
 /* VMCI Event API. */
 typedef void (*vmci_event_cb) (u32 sub_id, const struct vmci_event_data *ed,
 			       void *client_data);
 
 /*
  * We use the following inline function to access the payload data
  * associated with an event data.
  */
 static inline const void *
 vmci_event_data_const_payload(const struct vmci_event_data *ev_data)
 {
 	return (const char *)ev_data + sizeof(*ev_data);
 }
 
 static inline void *vmci_event_data_payload(struct vmci_event_data *ev_data)
 {
 	return (void *)vmci_event_data_const_payload(ev_data);
 }
 
 /*
  * Helper to read a value from a head or tail pointer. For X86_32, the
  * pointer is treated as a 32bit value, since the pointer value
  * never exceeds a 32bit value in this case. Also, doing an
  * atomic64_read on X86_32 uniprocessor systems may be implemented
  * as a non locked cmpxchg8b, that may end up overwriting updates done
  * by the VMCI device to the memory location. On 32bit SMP, the lock
  * prefix will be used, so correctness isn't an issue, but using a
  * 64bit operation still adds unnecessary overhead.
  */
 static inline u64 vmci_q_read_pointer(atomic64_t *var)
 {
 #if defined(CONFIG_X86_32)
 	return atomic_read((atomic_t *)var);
 #else
 	return atomic64_read(var);
 #endif
 }
 
 /*
  * Helper to set the value of a head or tail pointer. For X86_32, the
  * pointer is treated as a 32bit value, since the pointer value
  * never exceeds a 32bit value in this case. On 32bit SMP, using a
  * locked cmpxchg8b adds unnecessary overhead.
  */
 static inline void vmci_q_set_pointer(atomic64_t *var,
 				      u64 new_val)
 {
 #if defined(CONFIG_X86_32)
 	return atomic_set((atomic_t *)var, (u32)new_val);
 #else
 	return atomic64_set(var, new_val);
 #endif
 }
 
 /*
  * Helper to add a given offset to a head or tail pointer. Wraps the
  * value of the pointer around the max size of the queue.
  */
 static inline void vmci_qp_add_pointer(atomic64_t *var,
 				       size_t add,
 				       u64 size)
 {
 	u64 new_val = vmci_q_read_pointer(var);
 
 	if (new_val >= size - add)
 		new_val -= size;
 
 	new_val += add;
 
 	vmci_q_set_pointer(var, new_val);
 }
 
 /*
  * Helper routine to get the Producer Tail from the supplied queue.
  */
 static inline u64
 vmci_q_header_producer_tail(const struct vmci_queue_header *q_header)
 {
 	struct vmci_queue_header *qh = (struct vmci_queue_header *)q_header;
 	return vmci_q_read_pointer(&qh->producer_tail);
 }
 
 /*
  * Helper routine to get the Consumer Head from the supplied queue.
  */
 static inline u64
 vmci_q_header_consumer_head(const struct vmci_queue_header *q_header)
 {
 	struct vmci_queue_header *qh = (struct vmci_queue_header *)q_header;
 	return vmci_q_read_pointer(&qh->consumer_head);
 }
 
 /*
  * Helper routine to increment the Producer Tail.  Fundamentally,
  * vmci_qp_add_pointer() is used to manipulate the tail itself.
  */
 static inline void
 vmci_q_header_add_producer_tail(struct vmci_queue_header *q_header,
 				size_t add,
 				u64 queue_size)
 {
 	vmci_qp_add_pointer(&q_header->producer_tail, add, queue_size);
 }
 
 /*
  * Helper routine to increment the Consumer Head.  Fundamentally,
  * vmci_qp_add_pointer() is used to manipulate the head itself.
  */
 static inline void
 vmci_q_header_add_consumer_head(struct vmci_queue_header *q_header,
 				size_t add,
 				u64 queue_size)
 {
 	vmci_qp_add_pointer(&q_header->consumer_head, add, queue_size);
 }
 
 /*
  * Helper routine for getting the head and the tail pointer for a queue.
  * Both the VMCIQueues are needed to get both the pointers for one queue.
  */
 static inline void
 vmci_q_header_get_pointers(const struct vmci_queue_header *produce_q_header,
 			   const struct vmci_queue_header *consume_q_header,
 			   u64 *producer_tail,
 			   u64 *consumer_head)
 {
 	if (producer_tail)
 		*producer_tail = vmci_q_header_producer_tail(produce_q_header);
 
 	if (consumer_head)
 		*consumer_head = vmci_q_header_consumer_head(consume_q_header);
 }
 
 static inline void vmci_q_header_init(struct vmci_queue_header *q_header,
 				      const struct vmci_handle handle)
 {
 	q_header->handle = handle;
 	atomic64_set(&q_header->producer_tail, 0);
 	atomic64_set(&q_header->consumer_head, 0);
 }
 
 /*
  * Finds available free space in a produce queue to enqueue more
  * data or reports an error if queue pair corruption is detected.
  */
 static s64
 vmci_q_header_free_space(const struct vmci_queue_header *produce_q_header,
 			 const struct vmci_queue_header *consume_q_header,
 			 const u64 produce_q_size)
 {
 	u64 tail;
 	u64 head;
 	u64 free_space;
 
 	tail = vmci_q_header_producer_tail(produce_q_header);
 	head = vmci_q_header_consumer_head(consume_q_header);
 
 	if (tail >= produce_q_size || head >= produce_q_size)
 		return VMCI_ERROR_INVALID_SIZE;
 
 	/*
 	 * Deduct 1 to avoid tail becoming equal to head which causes
 	 * ambiguity. If head and tail are equal it means that the
 	 * queue is empty.
 	 */
 	if (tail >= head)
 		free_space = produce_q_size - (tail - head) - 1;
 	else
 		free_space = head - tail - 1;
 
 	return free_space;
 }
 
 /*
  * vmci_q_header_free_space() does all the heavy lifting of
  * determing the number of free bytes in a Queue.  This routine,
  * then subtracts that size from the full size of the Queue so
  * the caller knows how many bytes are ready to be dequeued.
  * Results:
  * On success, available data size in bytes (up to MAX_INT64).
  * On failure, appropriate error code.
  */
 static inline s64
 vmci_q_header_buf_ready(const struct vmci_queue_header *consume_q_header,
 			const struct vmci_queue_header *produce_q_header,
 			const u64 consume_q_size)
 {
 	s64 free_space;
 
 	free_space = vmci_q_header_free_space(consume_q_header,
 					      produce_q_header, consume_q_size);
 	if (free_space < VMCI_SUCCESS)
 		return free_space;
 
 	return consume_q_size - free_space - 1;
 }
 
 
 #endif /* _VMW_VMCI_DEF_H_ */
diff --git a/include/uapi/linux/android/binder.h b/include/uapi/linux/android/binder.h
index 41420e341e75..51f891fb1b18 100644
--- a/include/uapi/linux/android/binder.h
+++ b/include/uapi/linux/android/binder.h
@@ -1,352 +1,450 @@
 /*
  * Copyright (C) 2008 Google, Inc.
  *
  * Based on, but no longer compatible with, the original
  * OpenBinder.org binder driver interface, which is:
  *
  * Copyright (c) 2005 Palmsource, Inc.
  *
  * This software is licensed under the terms of the GNU General Public
  * License version 2, as published by the Free Software Foundation, and
  * may be copied, distributed, and modified under those terms.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
  *
  */
 
 #ifndef _UAPI_LINUX_BINDER_H
 #define _UAPI_LINUX_BINDER_H
 
 #include <linux/types.h>
 #include <linux/ioctl.h>
 
 #define B_PACK_CHARS(c1, c2, c3, c4) \
 	((((c1)<<24)) | (((c2)<<16)) | (((c3)<<8)) | (c4))
 #define B_TYPE_LARGE 0x85
 
 enum {
 	BINDER_TYPE_BINDER	= B_PACK_CHARS('s', 'b', '*', B_TYPE_LARGE),
 	BINDER_TYPE_WEAK_BINDER	= B_PACK_CHARS('w', 'b', '*', B_TYPE_LARGE),
 	BINDER_TYPE_HANDLE	= B_PACK_CHARS('s', 'h', '*', B_TYPE_LARGE),
 	BINDER_TYPE_WEAK_HANDLE	= B_PACK_CHARS('w', 'h', '*', B_TYPE_LARGE),
 	BINDER_TYPE_FD		= B_PACK_CHARS('f', 'd', '*', B_TYPE_LARGE),
+	BINDER_TYPE_FDA		= B_PACK_CHARS('f', 'd', 'a', B_TYPE_LARGE),
+	BINDER_TYPE_PTR		= B_PACK_CHARS('p', 't', '*', B_TYPE_LARGE),
 };
 
 enum {
 	FLAT_BINDER_FLAG_PRIORITY_MASK = 0xff,
 	FLAT_BINDER_FLAG_ACCEPTS_FDS = 0x100,
 };
 
 #ifdef BINDER_IPC_32BIT
 typedef __u32 binder_size_t;
 typedef __u32 binder_uintptr_t;
 #else
 typedef __u64 binder_size_t;
 typedef __u64 binder_uintptr_t;
 #endif
 
+/**
+ * struct binder_object_header - header shared by all binder metadata objects.
+ * @type:	type of the object
+ */
+struct binder_object_header {
+	__u32        type;
+};
+
 /*
  * This is the flattened representation of a Binder object for transfer
  * between processes.  The 'offsets' supplied as part of a binder transaction
  * contains offsets into the data where these structures occur.  The Binder
  * driver takes care of re-writing the structure type and data as it moves
  * between processes.
  */
 struct flat_binder_object {
-	/* 8 bytes for large_flat_header. */
-	__u32		type;
-	__u32		flags;
+	struct binder_object_header	hdr;
+	__u32				flags;
 
 	/* 8 bytes of data. */
 	union {
 		binder_uintptr_t	binder;	/* local object */
 		__u32			handle;	/* remote object */
 	};
 
 	/* extra data associated with local object */
 	binder_uintptr_t	cookie;
 };
 
+/**
+ * struct binder_fd_object - describes a filedescriptor to be fixed up.
+ * @hdr:	common header structure
+ * @pad_flags:	padding to remain compatible with old userspace code
+ * @pad_binder:	padding to remain compatible with old userspace code
+ * @fd:		file descriptor
+ * @cookie:	opaque data, used by user-space
+ */
+struct binder_fd_object {
+	struct binder_object_header	hdr;
+	__u32				pad_flags;
+	union {
+		binder_uintptr_t	pad_binder;
+		__u32			fd;
+	};
+
+	binder_uintptr_t		cookie;
+};
+
+/* struct binder_buffer_object - object describing a userspace buffer
+ * @hdr:		common header structure
+ * @flags:		one or more BINDER_BUFFER_* flags
+ * @buffer:		address of the buffer
+ * @length:		length of the buffer
+ * @parent:		index in offset array pointing to parent buffer
+ * @parent_offset:	offset in @parent pointing to this buffer
+ *
+ * A binder_buffer object represents an object that the
+ * binder kernel driver can copy verbatim to the target
+ * address space. A buffer itself may be pointed to from
+ * within another buffer, meaning that the pointer inside
+ * that other buffer needs to be fixed up as well. This
+ * can be done by setting the BINDER_BUFFER_FLAG_HAS_PARENT
+ * flag in @flags, by setting @parent buffer to the index
+ * in the offset array pointing to the parent binder_buffer_object,
+ * and by setting @parent_offset to the offset in the parent buffer
+ * at which the pointer to this buffer is located.
+ */
+struct binder_buffer_object {
+	struct binder_object_header	hdr;
+	__u32				flags;
+	binder_uintptr_t		buffer;
+	binder_size_t			length;
+	binder_size_t			parent;
+	binder_size_t			parent_offset;
+};
+
+enum {
+	BINDER_BUFFER_FLAG_HAS_PARENT = 0x01,
+};
+
+/* struct binder_fd_array_object - object describing an array of fds in a buffer
+ * @hdr:		common header structure
+ * @num_fds:		number of file descriptors in the buffer
+ * @parent:		index in offset array to buffer holding the fd array
+ * @parent_offset:	start offset of fd array in the buffer
+ *
+ * A binder_fd_array object represents an array of file
+ * descriptors embedded in a binder_buffer_object. It is
+ * different from a regular binder_buffer_object because it
+ * describes a list of file descriptors to fix up, not an opaque
+ * blob of memory, and hence the kernel needs to treat it differently.
+ *
+ * An example of how this would be used is with Android's
+ * native_handle_t object, which is a struct with a list of integers
+ * and a list of file descriptors. The native_handle_t struct itself
+ * will be represented by a struct binder_buffer_objct, whereas the
+ * embedded list of file descriptors is represented by a
+ * struct binder_fd_array_object with that binder_buffer_object as
+ * a parent.
+ */
+struct binder_fd_array_object {
+	struct binder_object_header	hdr;
+	binder_size_t			num_fds;
+	binder_size_t			parent;
+	binder_size_t			parent_offset;
+};
+
 /*
  * On 64-bit platforms where user code may run in 32-bits the driver must
  * translate the buffer (and local binder) addresses appropriately.
  */
 
 struct binder_write_read {
 	binder_size_t		write_size;	/* bytes to write */
 	binder_size_t		write_consumed;	/* bytes consumed by driver */
 	binder_uintptr_t	write_buffer;
 	binder_size_t		read_size;	/* bytes to read */
 	binder_size_t		read_consumed;	/* bytes consumed by driver */
 	binder_uintptr_t	read_buffer;
 };
 
 /* Use with BINDER_VERSION, driver fills in fields. */
 struct binder_version {
 	/* driver protocol version -- increment with incompatible change */
 	__s32       protocol_version;
 };
 
 /* This is the current protocol version. */
 #ifdef BINDER_IPC_32BIT
 #define BINDER_CURRENT_PROTOCOL_VERSION 7
 #else
 #define BINDER_CURRENT_PROTOCOL_VERSION 8
 #endif
 
 #define BINDER_WRITE_READ		_IOWR('b', 1, struct binder_write_read)
 #define BINDER_SET_IDLE_TIMEOUT		_IOW('b', 3, __s64)
 #define BINDER_SET_MAX_THREADS		_IOW('b', 5, __u32)
 #define BINDER_SET_IDLE_PRIORITY	_IOW('b', 6, __s32)
 #define BINDER_SET_CONTEXT_MGR		_IOW('b', 7, __s32)
 #define BINDER_THREAD_EXIT		_IOW('b', 8, __s32)
 #define BINDER_VERSION			_IOWR('b', 9, struct binder_version)
 
 /*
  * NOTE: Two special error codes you should check for when calling
  * in to the driver are:
  *
  * EINTR -- The operation has been interupted.  This should be
  * handled by retrying the ioctl() until a different error code
  * is returned.
  *
  * ECONNREFUSED -- The driver is no longer accepting operations
  * from your process.  That is, the process is being destroyed.
  * You should handle this by exiting from your process.  Note
  * that once this error code is returned, all further calls to
  * the driver from any thread will return this same code.
  */
 
 enum transaction_flags {
 	TF_ONE_WAY	= 0x01,	/* this is a one-way call: async, no return */
 	TF_ROOT_OBJECT	= 0x04,	/* contents are the component's root object */
 	TF_STATUS_CODE	= 0x08,	/* contents are a 32-bit status code */
 	TF_ACCEPT_FDS	= 0x10,	/* allow replies with file descriptors */
 };
 
 struct binder_transaction_data {
 	/* The first two are only used for bcTRANSACTION and brTRANSACTION,
 	 * identifying the target and contents of the transaction.
 	 */
 	union {
 		/* target descriptor of command transaction */
 		__u32	handle;
 		/* target descriptor of return transaction */
 		binder_uintptr_t ptr;
 	} target;
 	binder_uintptr_t	cookie;	/* target object cookie */
 	__u32		code;		/* transaction command */
 
 	/* General information about the transaction. */
 	__u32	        flags;
 	pid_t		sender_pid;
 	uid_t		sender_euid;
 	binder_size_t	data_size;	/* number of bytes of data */
 	binder_size_t	offsets_size;	/* number of bytes of offsets */
 
 	/* If this transaction is inline, the data immediately
 	 * follows here; otherwise, it ends with a pointer to
 	 * the data buffer.
 	 */
 	union {
 		struct {
 			/* transaction data */
 			binder_uintptr_t	buffer;
 			/* offsets from buffer to flat_binder_object structs */
 			binder_uintptr_t	offsets;
 		} ptr;
 		__u8	buf[8];
 	} data;
 };
 
+struct binder_transaction_data_sg {
+	struct binder_transaction_data transaction_data;
+	binder_size_t buffers_size;
+};
+
 struct binder_ptr_cookie {
 	binder_uintptr_t ptr;
 	binder_uintptr_t cookie;
 };
 
 struct binder_handle_cookie {
 	__u32 handle;
 	binder_uintptr_t cookie;
 } __packed;
 
 struct binder_pri_desc {
 	__s32 priority;
 	__u32 desc;
 };
 
 struct binder_pri_ptr_cookie {
 	__s32 priority;
 	binder_uintptr_t ptr;
 	binder_uintptr_t cookie;
 };
 
 enum binder_driver_return_protocol {
 	BR_ERROR = _IOR('r', 0, __s32),
 	/*
 	 * int: error code
 	 */
 
 	BR_OK = _IO('r', 1),
 	/* No parameters! */
 
 	BR_TRANSACTION = _IOR('r', 2, struct binder_transaction_data),
 	BR_REPLY = _IOR('r', 3, struct binder_transaction_data),
 	/*
 	 * binder_transaction_data: the received command.
 	 */
 
 	BR_ACQUIRE_RESULT = _IOR('r', 4, __s32),
 	/*
 	 * not currently supported
 	 * int: 0 if the last bcATTEMPT_ACQUIRE was not successful.
 	 * Else the remote object has acquired a primary reference.
 	 */
 
 	BR_DEAD_REPLY = _IO('r', 5),
 	/*
 	 * The target of the last transaction (either a bcTRANSACTION or
 	 * a bcATTEMPT_ACQUIRE) is no longer with us.  No parameters.
 	 */
 
 	BR_TRANSACTION_COMPLETE = _IO('r', 6),
 	/*
 	 * No parameters... always refers to the last transaction requested
 	 * (including replies).  Note that this will be sent even for
 	 * asynchronous transactions.
 	 */
 
 	BR_INCREFS = _IOR('r', 7, struct binder_ptr_cookie),
 	BR_ACQUIRE = _IOR('r', 8, struct binder_ptr_cookie),
 	BR_RELEASE = _IOR('r', 9, struct binder_ptr_cookie),
 	BR_DECREFS = _IOR('r', 10, struct binder_ptr_cookie),
 	/*
 	 * void *:	ptr to binder
 	 * void *: cookie for binder
 	 */
 
 	BR_ATTEMPT_ACQUIRE = _IOR('r', 11, struct binder_pri_ptr_cookie),
 	/*
 	 * not currently supported
 	 * int:	priority
 	 * void *: ptr to binder
 	 * void *: cookie for binder
 	 */
 
 	BR_NOOP = _IO('r', 12),
 	/*
 	 * No parameters.  Do nothing and examine the next command.  It exists
 	 * primarily so that we can replace it with a BR_SPAWN_LOOPER command.
 	 */
 
 	BR_SPAWN_LOOPER = _IO('r', 13),
 	/*
 	 * No parameters.  The driver has determined that a process has no
 	 * threads waiting to service incoming transactions.  When a process
 	 * receives this command, it must spawn a new service thread and
 	 * register it via bcENTER_LOOPER.
 	 */
 
 	BR_FINISHED = _IO('r', 14),
 	/*
 	 * not currently supported
 	 * stop threadpool thread
 	 */
 
 	BR_DEAD_BINDER = _IOR('r', 15, binder_uintptr_t),
 	/*
 	 * void *: cookie
 	 */
 	BR_CLEAR_DEATH_NOTIFICATION_DONE = _IOR('r', 16, binder_uintptr_t),
 	/*
 	 * void *: cookie
 	 */
 
 	BR_FAILED_REPLY = _IO('r', 17),
 	/*
 	 * The the last transaction (either a bcTRANSACTION or
 	 * a bcATTEMPT_ACQUIRE) failed (e.g. out of memory).  No parameters.
 	 */
 };
 
 enum binder_driver_command_protocol {
 	BC_TRANSACTION = _IOW('c', 0, struct binder_transaction_data),
 	BC_REPLY = _IOW('c', 1, struct binder_transaction_data),
 	/*
 	 * binder_transaction_data: the sent command.
 	 */
 
 	BC_ACQUIRE_RESULT = _IOW('c', 2, __s32),
 	/*
 	 * not currently supported
 	 * int:  0 if the last BR_ATTEMPT_ACQUIRE was not successful.
 	 * Else you have acquired a primary reference on the object.
 	 */
 
 	BC_FREE_BUFFER = _IOW('c', 3, binder_uintptr_t),
 	/*
 	 * void *: ptr to transaction data received on a read
 	 */
 
 	BC_INCREFS = _IOW('c', 4, __u32),
 	BC_ACQUIRE = _IOW('c', 5, __u32),
 	BC_RELEASE = _IOW('c', 6, __u32),
 	BC_DECREFS = _IOW('c', 7, __u32),
 	/*
 	 * int:	descriptor
 	 */
 
 	BC_INCREFS_DONE = _IOW('c', 8, struct binder_ptr_cookie),
 	BC_ACQUIRE_DONE = _IOW('c', 9, struct binder_ptr_cookie),
 	/*
 	 * void *: ptr to binder
 	 * void *: cookie for binder
 	 */
 
 	BC_ATTEMPT_ACQUIRE = _IOW('c', 10, struct binder_pri_desc),
 	/*
 	 * not currently supported
 	 * int: priority
 	 * int: descriptor
 	 */
 
 	BC_REGISTER_LOOPER = _IO('c', 11),
 	/*
 	 * No parameters.
 	 * Register a spawned looper thread with the device.
 	 */
 
 	BC_ENTER_LOOPER = _IO('c', 12),
 	BC_EXIT_LOOPER = _IO('c', 13),
 	/*
 	 * No parameters.
 	 * These two commands are sent as an application-level thread
 	 * enters and exits the binder loop, respectively.  They are
 	 * used so the binder can have an accurate count of the number
 	 * of looping threads it has available.
 	 */
 
 	BC_REQUEST_DEATH_NOTIFICATION = _IOW('c', 14,
 						struct binder_handle_cookie),
 	/*
 	 * int: handle
 	 * void *: cookie
 	 */
 
 	BC_CLEAR_DEATH_NOTIFICATION = _IOW('c', 15,
 						struct binder_handle_cookie),
 	/*
 	 * int: handle
 	 * void *: cookie
 	 */
 
 	BC_DEAD_BINDER_DONE = _IOW('c', 16, binder_uintptr_t),
 	/*
 	 * void *: cookie
 	 */
+
+	BC_TRANSACTION_SG = _IOW('c', 17, struct binder_transaction_data_sg),
+	BC_REPLY_SG = _IOW('c', 18, struct binder_transaction_data_sg),
+	/*
+	 * binder_transaction_data_sg: the sent command.
+	 */
 };
 
 #endif /* _UAPI_LINUX_BINDER_H */
 
diff --git a/init/Kconfig b/init/Kconfig
index 2655abb8f310..55bb6fbc294e 100644
--- a/init/Kconfig
+++ b/init/Kconfig
@@ -1,2154 +1,2161 @@
 config ARCH
 	string
 	option env="ARCH"
 
 config KERNELVERSION
 	string
 	option env="KERNELVERSION"
 
 config DEFCONFIG_LIST
 	string
 	depends on !UML
 	option defconfig_list
 	default "/lib/modules/$UNAME_RELEASE/.config"
 	default "/etc/kernel-config"
 	default "/boot/config-$UNAME_RELEASE"
 	default "$ARCH_DEFCONFIG"
 	default "arch/$ARCH/defconfig"
 
 config CONSTRUCTORS
 	bool
 	depends on !UML
 
 config IRQ_WORK
 	bool
 
 config BUILDTIME_EXTABLE_SORT
 	bool
 
 config THREAD_INFO_IN_TASK
 	bool
 	help
 	  Select this to move thread_info off the stack into task_struct.  To
 	  make this work, an arch will need to remove all thread_info fields
 	  except flags and fix any runtime bugs.
 
 	  One subtle change that will be needed is to use try_get_task_stack()
 	  and put_task_stack() in save_thread_stack_tsk() and get_wchan().
 
 menu "General setup"
 
 config BROKEN
 	bool
 
 config BROKEN_ON_SMP
 	bool
 	depends on BROKEN || !SMP
 	default y
 
 config INIT_ENV_ARG_LIMIT
 	int
 	default 32 if !UML
 	default 128 if UML
 	help
 	  Maximum of each of the number of arguments and environment
 	  variables passed to init from the kernel command line.
 
 
 config CROSS_COMPILE
 	string "Cross-compiler tool prefix"
 	help
 	  Same as running 'make CROSS_COMPILE=prefix-' but stored for
 	  default make runs in this kernel build directory.  You don't
 	  need to set this unless you want the configured kernel build
 	  directory to select the cross-compiler automatically.
 
 config COMPILE_TEST
 	bool "Compile also drivers which will not load"
 	depends on !UML
 	default n
 	help
 	  Some drivers can be compiled on a different platform than they are
 	  intended to be run on. Despite they cannot be loaded there (or even
 	  when they load they cannot be used due to missing HW support),
 	  developers still, opposing to distributors, might want to build such
 	  drivers to compile-test them.
 
 	  If you are a developer and want to build everything available, say Y
 	  here. If you are a user/distributor, say N here to exclude useless
 	  drivers to be distributed.
 
 config LOCALVERSION
 	string "Local version - append to kernel release"
 	help
 	  Append an extra string to the end of your kernel version.
 	  This will show up when you type uname, for example.
 	  The string you set here will be appended after the contents of
 	  any files with a filename matching localversion* in your
 	  object and source tree, in that order.  Your total string can
 	  be a maximum of 64 characters.
 
 config LOCALVERSION_AUTO
 	bool "Automatically append version information to the version string"
 	default y
 	depends on !COMPILE_TEST
 	help
 	  This will try to automatically determine if the current tree is a
 	  release tree by looking for git tags that belong to the current
 	  top of tree revision.
 
 	  A string of the format -gxxxxxxxx will be added to the localversion
 	  if a git-based tree is found.  The string generated by this will be
 	  appended after any matching localversion* files, and after the value
 	  set in CONFIG_LOCALVERSION.
 
 	  (The actual string used here is the first eight characters produced
 	  by running the command:
 
 	    $ git rev-parse --verify HEAD
 
 	  which is done within the script "scripts/setlocalversion".)
 
 config HAVE_KERNEL_GZIP
 	bool
 
 config HAVE_KERNEL_BZIP2
 	bool
 
 config HAVE_KERNEL_LZMA
 	bool
 
 config HAVE_KERNEL_XZ
 	bool
 
 config HAVE_KERNEL_LZO
 	bool
 
 config HAVE_KERNEL_LZ4
 	bool
 
 choice
 	prompt "Kernel compression mode"
 	default KERNEL_GZIP
 	depends on HAVE_KERNEL_GZIP || HAVE_KERNEL_BZIP2 || HAVE_KERNEL_LZMA || HAVE_KERNEL_XZ || HAVE_KERNEL_LZO || HAVE_KERNEL_LZ4
 	help
 	  The linux kernel is a kind of self-extracting executable.
 	  Several compression algorithms are available, which differ
 	  in efficiency, compression and decompression speed.
 	  Compression speed is only relevant when building a kernel.
 	  Decompression speed is relevant at each boot.
 
 	  If you have any problems with bzip2 or lzma compressed
 	  kernels, mail me (Alain Knaff) <alain@knaff.lu>. (An older
 	  version of this functionality (bzip2 only), for 2.4, was
 	  supplied by Christian Ludwig)
 
 	  High compression options are mostly useful for users, who
 	  are low on disk space (embedded systems), but for whom ram
 	  size matters less.
 
 	  If in doubt, select 'gzip'
 
 config KERNEL_GZIP
 	bool "Gzip"
 	depends on HAVE_KERNEL_GZIP
 	help
 	  The old and tried gzip compression. It provides a good balance
 	  between compression ratio and decompression speed.
 
 config KERNEL_BZIP2
 	bool "Bzip2"
 	depends on HAVE_KERNEL_BZIP2
 	help
 	  Its compression ratio and speed is intermediate.
 	  Decompression speed is slowest among the choices.  The kernel
 	  size is about 10% smaller with bzip2, in comparison to gzip.
 	  Bzip2 uses a large amount of memory. For modern kernels you
 	  will need at least 8MB RAM or more for booting.
 
 config KERNEL_LZMA
 	bool "LZMA"
 	depends on HAVE_KERNEL_LZMA
 	help
 	  This compression algorithm's ratio is best.  Decompression speed
 	  is between gzip and bzip2.  Compression is slowest.
 	  The kernel size is about 33% smaller with LZMA in comparison to gzip.
 
 config KERNEL_XZ
 	bool "XZ"
 	depends on HAVE_KERNEL_XZ
 	help
 	  XZ uses the LZMA2 algorithm and instruction set specific
 	  BCJ filters which can improve compression ratio of executable
 	  code. The size of the kernel is about 30% smaller with XZ in
 	  comparison to gzip. On architectures for which there is a BCJ
 	  filter (i386, x86_64, ARM, IA-64, PowerPC, and SPARC), XZ
 	  will create a few percent smaller kernel than plain LZMA.
 
 	  The speed is about the same as with LZMA: The decompression
 	  speed of XZ is better than that of bzip2 but worse than gzip
 	  and LZO. Compression is slow.
 
 config KERNEL_LZO
 	bool "LZO"
 	depends on HAVE_KERNEL_LZO
 	help
 	  Its compression ratio is the poorest among the choices. The kernel
 	  size is about 10% bigger than gzip; however its speed
 	  (both compression and decompression) is the fastest.
 
 config KERNEL_LZ4
 	bool "LZ4"
 	depends on HAVE_KERNEL_LZ4
 	help
 	  LZ4 is an LZ77-type compressor with a fixed, byte-oriented encoding.
 	  A preliminary version of LZ4 de/compression tool is available at
 	  <https://code.google.com/p/lz4/>.
 
 	  Its compression ratio is worse than LZO. The size of the kernel
 	  is about 8% bigger than LZO. But the decompression speed is
 	  faster than LZO.
 
 endchoice
 
 config DEFAULT_HOSTNAME
 	string "Default hostname"
 	default "(none)"
 	help
 	  This option determines the default system hostname before userspace
 	  calls sethostname(2). The kernel traditionally uses "(none)" here,
 	  but you may wish to use a different default here to make a minimal
 	  system more usable with less configuration.
 
 config SWAP
 	bool "Support for paging of anonymous memory (swap)"
 	depends on MMU && BLOCK
 	default y
 	help
 	  This option allows you to choose whether you want to have support
 	  for so called swap devices or swap files in your kernel that are
 	  used to provide more virtual memory than the actual RAM present
 	  in your computer.  If unsure say Y.
 
 config SYSVIPC
 	bool "System V IPC"
 	---help---
 	  Inter Process Communication is a suite of library functions and
 	  system calls which let processes (running programs) synchronize and
 	  exchange information. It is generally considered to be a good thing,
 	  and some programs won't run unless you say Y here. In particular, if
 	  you want to run the DOS emulator dosemu under Linux (read the
 	  DOSEMU-HOWTO, available from <http://www.tldp.org/docs.html#howto>),
 	  you'll need to say Y here.
 
 	  You can find documentation about IPC with "info ipc" and also in
 	  section 6.4 of the Linux Programmer's Guide, available from
 	  <http://www.tldp.org/guides.html>.
 
 config SYSVIPC_SYSCTL
 	bool
 	depends on SYSVIPC
 	depends on SYSCTL
 	default y
 
 config POSIX_MQUEUE
 	bool "POSIX Message Queues"
 	depends on NET
 	---help---
 	  POSIX variant of message queues is a part of IPC. In POSIX message
 	  queues every message has a priority which decides about succession
 	  of receiving it by a process. If you want to compile and run
 	  programs written e.g. for Solaris with use of its POSIX message
 	  queues (functions mq_*) say Y here.
 
 	  POSIX message queues are visible as a filesystem called 'mqueue'
 	  and can be mounted somewhere if you want to do filesystem
 	  operations on message queues.
 
 	  If unsure, say Y.
 
 config POSIX_MQUEUE_SYSCTL
 	bool
 	depends on POSIX_MQUEUE
 	depends on SYSCTL
 	default y
 
 config CROSS_MEMORY_ATTACH
 	bool "Enable process_vm_readv/writev syscalls"
 	depends on MMU
 	default y
 	help
 	  Enabling this option adds the system calls process_vm_readv and
 	  process_vm_writev which allow a process with the correct privileges
 	  to directly read from or write to another process' address space.
 	  See the man page for more details.
 
 config FHANDLE
 	bool "open by fhandle syscalls" if EXPERT
 	select EXPORTFS
 	default y
 	help
 	  If you say Y here, a user level program will be able to map
 	  file names to handle and then later use the handle for
 	  different file system operations. This is useful in implementing
 	  userspace file servers, which now track files using handles instead
 	  of names. The handle would remain the same even if file names
 	  get renamed. Enables open_by_handle_at(2) and name_to_handle_at(2)
 	  syscalls.
 
 config USELIB
 	bool "uselib syscall"
 	def_bool ALPHA || M68K || SPARC || X86_32 || IA32_EMULATION
 	help
 	  This option enables the uselib syscall, a system call used in the
 	  dynamic linker from libc5 and earlier.  glibc does not use this
 	  system call.  If you intend to run programs built on libc5 or
 	  earlier, you may need to enable this syscall.  Current systems
 	  running glibc can safely disable this.
 
 config AUDIT
 	bool "Auditing support"
 	depends on NET
 	help
 	  Enable auditing infrastructure that can be used with another
 	  kernel subsystem, such as SELinux (which requires this for
 	  logging of avc messages output).  System call auditing is included
 	  on architectures which support it.
 
 config HAVE_ARCH_AUDITSYSCALL
 	bool
 
 config AUDITSYSCALL
 	def_bool y
 	depends on AUDIT && HAVE_ARCH_AUDITSYSCALL
 
 config AUDIT_WATCH
 	def_bool y
 	depends on AUDITSYSCALL
 	select FSNOTIFY
 
 config AUDIT_TREE
 	def_bool y
 	depends on AUDITSYSCALL
 	select FSNOTIFY
 
 source "kernel/irq/Kconfig"
 source "kernel/time/Kconfig"
 
 menu "CPU/Task time and stats accounting"
 
 config VIRT_CPU_ACCOUNTING
 	bool
 
 choice
 	prompt "Cputime accounting"
 	default TICK_CPU_ACCOUNTING if !PPC64
 	default VIRT_CPU_ACCOUNTING_NATIVE if PPC64
 
 # Kind of a stub config for the pure tick based cputime accounting
 config TICK_CPU_ACCOUNTING
 	bool "Simple tick based cputime accounting"
 	depends on !S390 && !NO_HZ_FULL
 	help
 	  This is the basic tick based cputime accounting that maintains
 	  statistics about user, system and idle time spent on per jiffies
 	  granularity.
 
 	  If unsure, say Y.
 
 config VIRT_CPU_ACCOUNTING_NATIVE
 	bool "Deterministic task and CPU time accounting"
 	depends on HAVE_VIRT_CPU_ACCOUNTING && !NO_HZ_FULL
 	select VIRT_CPU_ACCOUNTING
 	help
 	  Select this option to enable more accurate task and CPU time
 	  accounting.  This is done by reading a CPU counter on each
 	  kernel entry and exit and on transitions within the kernel
 	  between system, softirq and hardirq state, so there is a
 	  small performance impact.  In the case of s390 or IBM POWER > 5,
 	  this also enables accounting of stolen time on logically-partitioned
 	  systems.
 
 config VIRT_CPU_ACCOUNTING_GEN
 	bool "Full dynticks CPU time accounting"
 	depends on HAVE_CONTEXT_TRACKING
 	depends on HAVE_VIRT_CPU_ACCOUNTING_GEN
 	select VIRT_CPU_ACCOUNTING
 	select CONTEXT_TRACKING
 	help
 	  Select this option to enable task and CPU time accounting on full
 	  dynticks systems. This accounting is implemented by watching every
 	  kernel-user boundaries using the context tracking subsystem.
 	  The accounting is thus performed at the expense of some significant
 	  overhead.
 
 	  For now this is only useful if you are working on the full
 	  dynticks subsystem development.
 
 	  If unsure, say N.
 
 endchoice
 
 config IRQ_TIME_ACCOUNTING
 	bool "Fine granularity task level IRQ time accounting"
 	depends on HAVE_IRQ_TIME_ACCOUNTING && !VIRT_CPU_ACCOUNTING_NATIVE
 	help
 	  Select this option to enable fine granularity task irq time
 	  accounting. This is done by reading a timestamp on each
 	  transitions between softirq and hardirq state, so there can be a
 	  small performance impact.
 
 	  If in doubt, say N here.
 
 config BSD_PROCESS_ACCT
 	bool "BSD Process Accounting"
 	depends on MULTIUSER
 	help
 	  If you say Y here, a user level program will be able to instruct the
 	  kernel (via a special system call) to write process accounting
 	  information to a file: whenever a process exits, information about
 	  that process will be appended to the file by the kernel.  The
 	  information includes things such as creation time, owning user,
 	  command name, memory usage, controlling terminal etc. (the complete
 	  list is in the struct acct in <file:include/linux/acct.h>).  It is
 	  up to the user level program to do useful things with this
 	  information.  This is generally a good idea, so say Y.
 
 config BSD_PROCESS_ACCT_V3
 	bool "BSD Process Accounting version 3 file format"
 	depends on BSD_PROCESS_ACCT
 	default n
 	help
 	  If you say Y here, the process accounting information is written
 	  in a new file format that also logs the process IDs of each
 	  process and it's parent. Note that this file format is incompatible
 	  with previous v0/v1/v2 file formats, so you will need updated tools
 	  for processing it. A preliminary version of these tools is available
 	  at <http://www.gnu.org/software/acct/>.
 
 config TASKSTATS
 	bool "Export task/process statistics through netlink"
 	depends on NET
 	depends on MULTIUSER
 	default n
 	help
 	  Export selected statistics for tasks/processes through the
 	  generic netlink interface. Unlike BSD process accounting, the
 	  statistics are available during the lifetime of tasks/processes as
 	  responses to commands. Like BSD accounting, they are sent to user
 	  space on task exit.
 
 	  Say N if unsure.
 
 config TASK_DELAY_ACCT
 	bool "Enable per-task delay accounting"
 	depends on TASKSTATS
 	select SCHED_INFO
 	help
 	  Collect information on time spent by a task waiting for system
 	  resources like cpu, synchronous block I/O completion and swapping
 	  in pages. Such statistics can help in setting a task's priorities
 	  relative to other tasks for cpu, io, rss limits etc.
 
 	  Say N if unsure.
 
 config TASK_XACCT
 	bool "Enable extended accounting over taskstats"
 	depends on TASKSTATS
 	help
 	  Collect extended task accounting data and send the data
 	  to userland for processing over the taskstats interface.
 
 	  Say N if unsure.
 
 config TASK_IO_ACCOUNTING
 	bool "Enable per-task storage I/O accounting"
 	depends on TASK_XACCT
 	help
 	  Collect information on the number of bytes of storage I/O which this
 	  task has caused.
 
 	  Say N if unsure.
 
 endmenu # "CPU/Task time and stats accounting"
 
 menu "RCU Subsystem"
 
 config TREE_RCU
 	bool
 	default y if !PREEMPT && SMP
 	help
 	  This option selects the RCU implementation that is
 	  designed for very large SMP system with hundreds or
 	  thousands of CPUs.  It also scales down nicely to
 	  smaller systems.
 
 config PREEMPT_RCU
 	bool
 	default y if PREEMPT
 	help
 	  This option selects the RCU implementation that is
 	  designed for very large SMP systems with hundreds or
 	  thousands of CPUs, but for which real-time response
 	  is also required.  It also scales down nicely to
 	  smaller systems.
 
 	  Select this option if you are unsure.
 
 config TINY_RCU
 	bool
 	default y if !PREEMPT && !SMP
 	help
 	  This option selects the RCU implementation that is
 	  designed for UP systems from which real-time response
 	  is not required.  This option greatly reduces the
 	  memory footprint of RCU.
 
 config RCU_EXPERT
 	bool "Make expert-level adjustments to RCU configuration"
 	default n
 	help
 	  This option needs to be enabled if you wish to make
 	  expert-level adjustments to RCU configuration.  By default,
 	  no such adjustments can be made, which has the often-beneficial
 	  side-effect of preventing "make oldconfig" from asking you all
 	  sorts of detailed questions about how you would like numerous
 	  obscure RCU options to be set up.
 
 	  Say Y if you need to make expert-level adjustments to RCU.
 
 	  Say N if you are unsure.
 
 config SRCU
 	bool
 	help
 	  This option selects the sleepable version of RCU. This version
 	  permits arbitrary sleeping or blocking within RCU read-side critical
 	  sections.
 
 config TASKS_RCU
 	bool
 	default n
 	select SRCU
 	help
 	  This option enables a task-based RCU implementation that uses
 	  only voluntary context switch (not preemption!), idle, and
 	  user-mode execution as quiescent states.
 
 config RCU_STALL_COMMON
 	def_bool ( TREE_RCU || PREEMPT_RCU || RCU_TRACE )
 	help
 	  This option enables RCU CPU stall code that is common between
 	  the TINY and TREE variants of RCU.  The purpose is to allow
 	  the tiny variants to disable RCU CPU stall warnings, while
 	  making these warnings mandatory for the tree variants.
 
 config CONTEXT_TRACKING
        bool
 
 config CONTEXT_TRACKING_FORCE
 	bool "Force context tracking"
 	depends on CONTEXT_TRACKING
 	default y if !NO_HZ_FULL
 	help
 	  The major pre-requirement for full dynticks to work is to
 	  support the context tracking subsystem. But there are also
 	  other dependencies to provide in order to make the full
 	  dynticks working.
 
 	  This option stands for testing when an arch implements the
 	  context tracking backend but doesn't yet fullfill all the
 	  requirements to make the full dynticks feature working.
 	  Without the full dynticks, there is no way to test the support
 	  for context tracking and the subsystems that rely on it: RCU
 	  userspace extended quiescent state and tickless cputime
 	  accounting. This option copes with the absence of the full
 	  dynticks subsystem by forcing the context tracking on all
 	  CPUs in the system.
 
 	  Say Y only if you're working on the development of an
 	  architecture backend for the context tracking.
 
 	  Say N otherwise, this option brings an overhead that you
 	  don't want in production.
 
 
 config RCU_FANOUT
 	int "Tree-based hierarchical RCU fanout value"
 	range 2 64 if 64BIT
 	range 2 32 if !64BIT
 	depends on (TREE_RCU || PREEMPT_RCU) && RCU_EXPERT
 	default 64 if 64BIT
 	default 32 if !64BIT
 	help
 	  This option controls the fanout of hierarchical implementations
 	  of RCU, allowing RCU to work efficiently on machines with
 	  large numbers of CPUs.  This value must be at least the fourth
 	  root of NR_CPUS, which allows NR_CPUS to be insanely large.
 	  The default value of RCU_FANOUT should be used for production
 	  systems, but if you are stress-testing the RCU implementation
 	  itself, small RCU_FANOUT values allow you to test large-system
 	  code paths on small(er) systems.
 
 	  Select a specific number if testing RCU itself.
 	  Take the default if unsure.
 
 config RCU_FANOUT_LEAF
 	int "Tree-based hierarchical RCU leaf-level fanout value"
 	range 2 64 if 64BIT
 	range 2 32 if !64BIT
 	depends on (TREE_RCU || PREEMPT_RCU) && RCU_EXPERT
 	default 16
 	help
 	  This option controls the leaf-level fanout of hierarchical
 	  implementations of RCU, and allows trading off cache misses
 	  against lock contention.  Systems that synchronize their
 	  scheduling-clock interrupts for energy-efficiency reasons will
 	  want the default because the smaller leaf-level fanout keeps
 	  lock contention levels acceptably low.  Very large systems
 	  (hundreds or thousands of CPUs) will instead want to set this
 	  value to the maximum value possible in order to reduce the
 	  number of cache misses incurred during RCU's grace-period
 	  initialization.  These systems tend to run CPU-bound, and thus
 	  are not helped by synchronized interrupts, and thus tend to
 	  skew them, which reduces lock contention enough that large
 	  leaf-level fanouts work well.
 
 	  Select a specific number if testing RCU itself.
 
 	  Select the maximum permissible value for large systems.
 
 	  Take the default if unsure.
 
 config RCU_FAST_NO_HZ
 	bool "Accelerate last non-dyntick-idle CPU's grace periods"
 	depends on NO_HZ_COMMON && SMP && RCU_EXPERT
 	default n
 	help
 	  This option permits CPUs to enter dynticks-idle state even if
 	  they have RCU callbacks queued, and prevents RCU from waking
 	  these CPUs up more than roughly once every four jiffies (by
 	  default, you can adjust this using the rcutree.rcu_idle_gp_delay
 	  parameter), thus improving energy efficiency.  On the other
 	  hand, this option increases the duration of RCU grace periods,
 	  for example, slowing down synchronize_rcu().
 
 	  Say Y if energy efficiency is critically important, and you
 	  	don't care about increased grace-period durations.
 
 	  Say N if you are unsure.
 
 config TREE_RCU_TRACE
 	def_bool RCU_TRACE && ( TREE_RCU || PREEMPT_RCU )
 	select DEBUG_FS
 	help
 	  This option provides tracing for the TREE_RCU and
 	  PREEMPT_RCU implementations, permitting Makefile to
 	  trivially select kernel/rcutree_trace.c.
 
 config RCU_BOOST
 	bool "Enable RCU priority boosting"
 	depends on RT_MUTEXES && PREEMPT_RCU && RCU_EXPERT
 	default n
 	help
 	  This option boosts the priority of preempted RCU readers that
 	  block the current preemptible RCU grace period for too long.
 	  This option also prevents heavy loads from blocking RCU
 	  callback invocation for all flavors of RCU.
 
 	  Say Y here if you are working with real-time apps or heavy loads
 	  Say N here if you are unsure.
 
 config RCU_KTHREAD_PRIO
 	int "Real-time priority to use for RCU worker threads"
 	range 1 99 if RCU_BOOST
 	range 0 99 if !RCU_BOOST
 	default 1 if RCU_BOOST
 	default 0 if !RCU_BOOST
 	depends on RCU_EXPERT
 	help
 	  This option specifies the SCHED_FIFO priority value that will be
 	  assigned to the rcuc/n and rcub/n threads and is also the value
 	  used for RCU_BOOST (if enabled). If you are working with a
 	  real-time application that has one or more CPU-bound threads
 	  running at a real-time priority level, you should set
 	  RCU_KTHREAD_PRIO to a priority higher than the highest-priority
 	  real-time CPU-bound application thread.  The default RCU_KTHREAD_PRIO
 	  value of 1 is appropriate in the common case, which is real-time
 	  applications that do not have any CPU-bound threads.
 
 	  Some real-time applications might not have a single real-time
 	  thread that saturates a given CPU, but instead might have
 	  multiple real-time threads that, taken together, fully utilize
 	  that CPU.  In this case, you should set RCU_KTHREAD_PRIO to
 	  a priority higher than the lowest-priority thread that is
 	  conspiring to prevent the CPU from running any non-real-time
 	  tasks.  For example, if one thread at priority 10 and another
 	  thread at priority 5 are between themselves fully consuming
 	  the CPU time on a given CPU, then RCU_KTHREAD_PRIO should be
 	  set to priority 6 or higher.
 
 	  Specify the real-time priority, or take the default if unsure.
 
 config RCU_BOOST_DELAY
 	int "Milliseconds to delay boosting after RCU grace-period start"
 	range 0 3000
 	depends on RCU_BOOST
 	default 500
 	help
 	  This option specifies the time to wait after the beginning of
 	  a given grace period before priority-boosting preempted RCU
 	  readers blocking that grace period.  Note that any RCU reader
 	  blocking an expedited RCU grace period is boosted immediately.
 
 	  Accept the default if unsure.
 
 config RCU_NOCB_CPU
 	bool "Offload RCU callback processing from boot-selected CPUs"
 	depends on TREE_RCU || PREEMPT_RCU
 	depends on RCU_EXPERT || NO_HZ_FULL
 	default n
 	help
 	  Use this option to reduce OS jitter for aggressive HPC or
 	  real-time workloads.	It can also be used to offload RCU
 	  callback invocation to energy-efficient CPUs in battery-powered
 	  asymmetric multiprocessors.
 
 	  This option offloads callback invocation from the set of
 	  CPUs specified at boot time by the rcu_nocbs parameter.
 	  For each such CPU, a kthread ("rcuox/N") will be created to
 	  invoke callbacks, where the "N" is the CPU being offloaded,
 	  and where the "x" is "b" for RCU-bh, "p" for RCU-preempt, and
 	  "s" for RCU-sched.  Nothing prevents this kthread from running
 	  on the specified CPUs, but (1) the kthreads may be preempted
 	  between each callback, and (2) affinity or cgroups can be used
 	  to force the kthreads to run on whatever set of CPUs is desired.
 
 	  Say Y here if you want to help to debug reduced OS jitter.
 	  Say N here if you are unsure.
 
 choice
 	prompt "Build-forced no-CBs CPUs"
 	default RCU_NOCB_CPU_NONE
 	depends on RCU_NOCB_CPU
 	help
 	  This option allows no-CBs CPUs (whose RCU callbacks are invoked
 	  from kthreads rather than from softirq context) to be specified
 	  at build time.  Additional no-CBs CPUs may be specified by
 	  the rcu_nocbs= boot parameter.
 
 config RCU_NOCB_CPU_NONE
 	bool "No build_forced no-CBs CPUs"
 	help
 	  This option does not force any of the CPUs to be no-CBs CPUs.
 	  Only CPUs designated by the rcu_nocbs= boot parameter will be
 	  no-CBs CPUs, whose RCU callbacks will be invoked by per-CPU
 	  kthreads whose names begin with "rcuo".  All other CPUs will
 	  invoke their own RCU callbacks in softirq context.
 
 	  Select this option if you want to choose no-CBs CPUs at
 	  boot time, for example, to allow testing of different no-CBs
 	  configurations without having to rebuild the kernel each time.
 
 config RCU_NOCB_CPU_ZERO
 	bool "CPU 0 is a build_forced no-CBs CPU"
 	help
 	  This option forces CPU 0 to be a no-CBs CPU, so that its RCU
 	  callbacks are invoked by a per-CPU kthread whose name begins
 	  with "rcuo".	Additional CPUs may be designated as no-CBs
 	  CPUs using the rcu_nocbs= boot parameter will be no-CBs CPUs.
 	  All other CPUs will invoke their own RCU callbacks in softirq
 	  context.
 
 	  Select this if CPU 0 needs to be a no-CBs CPU for real-time
 	  or energy-efficiency reasons, but the real reason it exists
 	  is to ensure that randconfig testing covers mixed systems.
 
 config RCU_NOCB_CPU_ALL
 	bool "All CPUs are build_forced no-CBs CPUs"
 	help
 	  This option forces all CPUs to be no-CBs CPUs.  The rcu_nocbs=
 	  boot parameter will be ignored.  All CPUs' RCU callbacks will
 	  be executed in the context of per-CPU rcuo kthreads created for
 	  this purpose.  Assuming that the kthreads whose names start with
 	  "rcuo" are bound to "housekeeping" CPUs, this reduces OS jitter
 	  on the remaining CPUs, but might decrease memory locality during
 	  RCU-callback invocation, thus potentially degrading throughput.
 
 	  Select this if all CPUs need to be no-CBs CPUs for real-time
 	  or energy-efficiency reasons.
 
 endchoice
 
 endmenu # "RCU Subsystem"
 
 config BUILD_BIN2C
 	bool
 	default n
 
 config IKCONFIG
 	tristate "Kernel .config support"
 	select BUILD_BIN2C
 	---help---
 	  This option enables the complete Linux kernel ".config" file
 	  contents to be saved in the kernel. It provides documentation
 	  of which kernel options are used in a running kernel or in an
 	  on-disk kernel.  This information can be extracted from the kernel
 	  image file with the script scripts/extract-ikconfig and used as
 	  input to rebuild the current kernel or to build another kernel.
 	  It can also be extracted from a running kernel by reading
 	  /proc/config.gz if enabled (below).
 
 config IKCONFIG_PROC
 	bool "Enable access to .config through /proc/config.gz"
 	depends on IKCONFIG && PROC_FS
 	---help---
 	  This option enables access to the kernel configuration file
 	  through /proc/config.gz.
 
 config LOG_BUF_SHIFT
 	int "Kernel log buffer size (16 => 64KB, 17 => 128KB)"
 	range 12 25
 	default 17
 	depends on PRINTK
 	help
 	  Select the minimal kernel log buffer size as a power of 2.
 	  The final size is affected by LOG_CPU_MAX_BUF_SHIFT config
 	  parameter, see below. Any higher size also might be forced
 	  by "log_buf_len" boot parameter.
 
 	  Examples:
 		     17 => 128 KB
 		     16 => 64 KB
 		     15 => 32 KB
 		     14 => 16 KB
 		     13 =>  8 KB
 		     12 =>  4 KB
 
 config LOG_CPU_MAX_BUF_SHIFT
 	int "CPU kernel log buffer size contribution (13 => 8 KB, 17 => 128KB)"
 	depends on SMP
 	range 0 21
 	default 12 if !BASE_SMALL
 	default 0 if BASE_SMALL
 	depends on PRINTK
 	help
 	  This option allows to increase the default ring buffer size
 	  according to the number of CPUs. The value defines the contribution
 	  of each CPU as a power of 2. The used space is typically only few
 	  lines however it might be much more when problems are reported,
 	  e.g. backtraces.
 
 	  The increased size means that a new buffer has to be allocated and
 	  the original static one is unused. It makes sense only on systems
 	  with more CPUs. Therefore this value is used only when the sum of
 	  contributions is greater than the half of the default kernel ring
 	  buffer as defined by LOG_BUF_SHIFT. The default values are set
 	  so that more than 64 CPUs are needed to trigger the allocation.
 
 	  Also this option is ignored when "log_buf_len" kernel parameter is
 	  used as it forces an exact (power of two) size of the ring buffer.
 
 	  The number of possible CPUs is used for this computation ignoring
 	  hotplugging making the computation optimal for the worst case
 	  scenario while allowing a simple algorithm to be used from bootup.
 
 	  Examples shift values and their meaning:
 		     17 => 128 KB for each CPU
 		     16 =>  64 KB for each CPU
 		     15 =>  32 KB for each CPU
 		     14 =>  16 KB for each CPU
 		     13 =>   8 KB for each CPU
 		     12 =>   4 KB for each CPU
 
 config NMI_LOG_BUF_SHIFT
 	int "Temporary per-CPU NMI log buffer size (12 => 4KB, 13 => 8KB)"
 	range 10 21
 	default 13
 	depends on PRINTK_NMI
 	help
 	  Select the size of a per-CPU buffer where NMI messages are temporary
 	  stored. They are copied to the main log buffer in a safe context
 	  to avoid a deadlock. The value defines the size as a power of 2.
 
 	  NMI messages are rare and limited. The largest one is when
 	  a backtrace is printed. It usually fits into 4KB. Select
 	  8KB if you want to be on the safe side.
 
 	  Examples:
 		     17 => 128 KB for each CPU
 		     16 =>  64 KB for each CPU
 		     15 =>  32 KB for each CPU
 		     14 =>  16 KB for each CPU
 		     13 =>   8 KB for each CPU
 		     12 =>   4 KB for each CPU
 
 #
 # Architectures with an unreliable sched_clock() should select this:
 #
 config HAVE_UNSTABLE_SCHED_CLOCK
 	bool
 
 config GENERIC_SCHED_CLOCK
 	bool
 
 #
 # For architectures that want to enable the support for NUMA-affine scheduler
 # balancing logic:
 #
 config ARCH_SUPPORTS_NUMA_BALANCING
 	bool
 
 #
 # For architectures that prefer to flush all TLBs after a number of pages
 # are unmapped instead of sending one IPI per page to flush. The architecture
 # must provide guarantees on what happens if a clean TLB cache entry is
 # written after the unmap. Details are in mm/rmap.c near the check for
 # should_defer_flush. The architecture should also consider if the full flush
 # and the refill costs are offset by the savings of sending fewer IPIs.
 config ARCH_WANT_BATCHED_UNMAP_TLB_FLUSH
 	bool
 
 #
 # For architectures that know their GCC __int128 support is sound
 #
 config ARCH_SUPPORTS_INT128
 	bool
 
 # For architectures that (ab)use NUMA to represent different memory regions
 # all cpu-local but of different latencies, such as SuperH.
 #
 config ARCH_WANT_NUMA_VARIABLE_LOCALITY
 	bool
 
 config NUMA_BALANCING
 	bool "Memory placement aware NUMA scheduler"
 	depends on ARCH_SUPPORTS_NUMA_BALANCING
 	depends on !ARCH_WANT_NUMA_VARIABLE_LOCALITY
 	depends on SMP && NUMA && MIGRATION
 	help
 	  This option adds support for automatic NUMA aware memory/task placement.
 	  The mechanism is quite primitive and is based on migrating memory when
 	  it has references to the node the task is running on.
 
 	  This system will be inactive on UMA systems.
 
 config NUMA_BALANCING_DEFAULT_ENABLED
 	bool "Automatically enable NUMA aware memory/task placement"
 	default y
 	depends on NUMA_BALANCING
 	help
 	  If set, automatic NUMA balancing will be enabled if running on a NUMA
 	  machine.
 
 menuconfig CGROUPS
 	bool "Control Group support"
 	select KERNFS
 	help
 	  This option adds support for grouping sets of processes together, for
 	  use with process control subsystems such as Cpusets, CFS, memory
 	  controls or device isolation.
 	  See
 		- Documentation/scheduler/sched-design-CFS.txt	(CFS)
 		- Documentation/cgroup-v1/ (features for grouping, isolation
 					  and resource control)
 
 	  Say N if unsure.
 
 if CGROUPS
 
 config PAGE_COUNTER
        bool
 
 config MEMCG
 	bool "Memory controller"
 	select PAGE_COUNTER
 	select EVENTFD
 	help
 	  Provides control over the memory footprint of tasks in a cgroup.
 
 config MEMCG_SWAP
 	bool "Swap controller"
 	depends on MEMCG && SWAP
 	help
 	  Provides control over the swap space consumed by tasks in a cgroup.
 
 config MEMCG_SWAP_ENABLED
 	bool "Swap controller enabled by default"
 	depends on MEMCG_SWAP
 	default y
 	help
 	  Memory Resource Controller Swap Extension comes with its price in
 	  a bigger memory consumption. General purpose distribution kernels
 	  which want to enable the feature but keep it disabled by default
 	  and let the user enable it by swapaccount=1 boot command line
 	  parameter should have this option unselected.
 	  For those who want to have the feature enabled by default should
 	  select this option (if, for some reason, they need to disable it
 	  then swapaccount=0 does the trick).
 
 config BLK_CGROUP
 	bool "IO controller"
 	depends on BLOCK
 	default n
 	---help---
 	Generic block IO controller cgroup interface. This is the common
 	cgroup interface which should be used by various IO controlling
 	policies.
 
 	Currently, CFQ IO scheduler uses it to recognize task groups and
 	control disk bandwidth allocation (proportional time slice allocation)
 	to such task groups. It is also used by bio throttling logic in
 	block layer to implement upper limit in IO rates on a device.
 
 	This option only enables generic Block IO controller infrastructure.
 	One needs to also enable actual IO controlling logic/policy. For
 	enabling proportional weight division of disk bandwidth in CFQ, set
 	CONFIG_CFQ_GROUP_IOSCHED=y; for enabling throttling policy, set
 	CONFIG_BLK_DEV_THROTTLING=y.
 
 	See Documentation/cgroup-v1/blkio-controller.txt for more information.
 
 config DEBUG_BLK_CGROUP
 	bool "IO controller debugging"
 	depends on BLK_CGROUP
 	default n
 	---help---
 	Enable some debugging help. Currently it exports additional stat
 	files in a cgroup which can be useful for debugging.
 
 config CGROUP_WRITEBACK
 	bool
 	depends on MEMCG && BLK_CGROUP
 	default y
 
 menuconfig CGROUP_SCHED
 	bool "CPU controller"
 	default n
 	help
 	  This feature lets CPU scheduler recognize task groups and control CPU
 	  bandwidth allocation to such task groups. It uses cgroups to group
 	  tasks.
 
 if CGROUP_SCHED
 config FAIR_GROUP_SCHED
 	bool "Group scheduling for SCHED_OTHER"
 	depends on CGROUP_SCHED
 	default CGROUP_SCHED
 
 config CFS_BANDWIDTH
 	bool "CPU bandwidth provisioning for FAIR_GROUP_SCHED"
 	depends on FAIR_GROUP_SCHED
 	default n
 	help
 	  This option allows users to define CPU bandwidth rates (limits) for
 	  tasks running within the fair group scheduler.  Groups with no limit
 	  set are considered to be unconstrained and will run with no
 	  restriction.
 	  See tip/Documentation/scheduler/sched-bwc.txt for more information.
 
 config RT_GROUP_SCHED
 	bool "Group scheduling for SCHED_RR/FIFO"
 	depends on CGROUP_SCHED
 	default n
 	help
 	  This feature lets you explicitly allocate real CPU bandwidth
 	  to task groups. If enabled, it will also make it impossible to
 	  schedule realtime tasks for non-root users until you allocate
 	  realtime bandwidth for them.
 	  See Documentation/scheduler/sched-rt-group.txt for more information.
 
 endif #CGROUP_SCHED
 
 config CGROUP_PIDS
 	bool "PIDs controller"
 	help
 	  Provides enforcement of process number limits in the scope of a
 	  cgroup. Any attempt to fork more processes than is allowed in the
 	  cgroup will fail. PIDs are fundamentally a global resource because it
 	  is fairly trivial to reach PID exhaustion before you reach even a
 	  conservative kmemcg limit. As a result, it is possible to grind a
 	  system to halt without being limited by other cgroup policies. The
 	  PIDs controller is designed to stop this from happening.
 
 	  It should be noted that organisational operations (such as attaching
 	  to a cgroup hierarchy will *not* be blocked by the PIDs controller),
 	  since the PIDs limit only affects a process's ability to fork, not to
 	  attach to a cgroup.
 
 config CGROUP_FREEZER
 	bool "Freezer controller"
 	help
 	  Provides a way to freeze and unfreeze all tasks in a
 	  cgroup.
 
 	  This option affects the ORIGINAL cgroup interface. The cgroup2 memory
 	  controller includes important in-kernel memory consumers per default.
 
 	  If you're using cgroup2, say N.
 
 config CGROUP_HUGETLB
 	bool "HugeTLB controller"
 	depends on HUGETLB_PAGE
 	select PAGE_COUNTER
 	default n
 	help
 	  Provides a cgroup controller for HugeTLB pages.
 	  When you enable this, you can put a per cgroup limit on HugeTLB usage.
 	  The limit is enforced during page fault. Since HugeTLB doesn't
 	  support page reclaim, enforcing the limit at page fault time implies
 	  that, the application will get SIGBUS signal if it tries to access
 	  HugeTLB pages beyond its limit. This requires the application to know
 	  beforehand how much HugeTLB pages it would require for its use. The
 	  control group is tracked in the third page lru pointer. This means
 	  that we cannot use the controller with huge page less than 3 pages.
 
 config CPUSETS
 	bool "Cpuset controller"
 	help
 	  This option will let you create and manage CPUSETs which
 	  allow dynamically partitioning a system into sets of CPUs and
 	  Memory Nodes and assigning tasks to run only within those sets.
 	  This is primarily useful on large SMP or NUMA systems.
 
 	  Say N if unsure.
 
 config PROC_PID_CPUSET
 	bool "Include legacy /proc/<pid>/cpuset file"
 	depends on CPUSETS
 	default y
 
 config CGROUP_DEVICE
 	bool "Device controller"
 	help
 	  Provides a cgroup controller implementing whitelists for
 	  devices which a process in the cgroup can mknod or open.
 
 config CGROUP_CPUACCT
 	bool "Simple CPU accounting controller"
 	help
 	  Provides a simple controller for monitoring the
 	  total CPU consumed by the tasks in a cgroup.
 
 config CGROUP_PERF
 	bool "Perf controller"
 	depends on PERF_EVENTS
 	help
 	  This option extends the perf per-cpu mode to restrict monitoring
 	  to threads which belong to the cgroup specified and run on the
 	  designated cpu.
 
 	  Say N if unsure.
 
 config CGROUP_BPF
 	bool "Support for eBPF programs attached to cgroups"
 	depends on BPF_SYSCALL
 	select SOCK_CGROUP_DATA
 	help
 	  Allow attaching eBPF programs to a cgroup using the bpf(2)
 	  syscall command BPF_PROG_ATTACH.
 
 	  In which context these programs are accessed depends on the type
 	  of attachment. For instance, programs that are attached using
 	  BPF_CGROUP_INET_INGRESS will be executed on the ingress path of
 	  inet sockets.
 
 config CGROUP_DEBUG
 	bool "Example controller"
 	default n
 	help
 	  This option enables a simple controller that exports
 	  debugging information about the cgroups framework.
 
 	  Say N.
 
 config SOCK_CGROUP_DATA
 	bool
 	default n
 
 endif # CGROUPS
 
 config CHECKPOINT_RESTORE
 	bool "Checkpoint/restore support" if EXPERT
 	select PROC_CHILDREN
 	default n
 	help
 	  Enables additional kernel features in a sake of checkpoint/restore.
 	  In particular it adds auxiliary prctl codes to setup process text,
 	  data and heap segment sizes, and a few additional /proc filesystem
 	  entries.
 
 	  If unsure, say N here.
 
 menuconfig NAMESPACES
 	bool "Namespaces support" if EXPERT
 	depends on MULTIUSER
 	default !EXPERT
 	help
 	  Provides the way to make tasks work with different objects using
 	  the same id. For example same IPC id may refer to different objects
 	  or same user id or pid may refer to different tasks when used in
 	  different namespaces.
 
 if NAMESPACES
 
 config UTS_NS
 	bool "UTS namespace"
 	default y
 	help
 	  In this namespace tasks see different info provided with the
 	  uname() system call
 
 config IPC_NS
 	bool "IPC namespace"
 	depends on (SYSVIPC || POSIX_MQUEUE)
 	default y
 	help
 	  In this namespace tasks work with IPC ids which correspond to
 	  different IPC objects in different namespaces.
 
 config USER_NS
 	bool "User namespace"
 	default n
 	help
 	  This allows containers, i.e. vservers, to use user namespaces
 	  to provide different user info for different servers.
 
 	  When user namespaces are enabled in the kernel it is
 	  recommended that the MEMCG option also be enabled and that
 	  user-space use the memory control groups to limit the amount
 	  of memory a memory unprivileged users can use.
 
 	  If unsure, say N.
 
 config PID_NS
 	bool "PID Namespaces"
 	default y
 	help
 	  Support process id namespaces.  This allows having multiple
 	  processes with the same pid as long as they are in different
 	  pid namespaces.  This is a building block of containers.
 
 config NET_NS
 	bool "Network namespace"
 	depends on NET
 	default y
 	help
 	  Allow user space to create what appear to be multiple instances
 	  of the network stack.
 
 endif # NAMESPACES
 
 config SCHED_AUTOGROUP
 	bool "Automatic process group scheduling"
 	select CGROUPS
 	select CGROUP_SCHED
 	select FAIR_GROUP_SCHED
 	help
 	  This option optimizes the scheduler for common desktop workloads by
 	  automatically creating and populating task groups.  This separation
 	  of workloads isolates aggressive CPU burners (like build jobs) from
 	  desktop applications.  Task group autogeneration is currently based
 	  upon task session.
 
 config SYSFS_DEPRECATED
 	bool "Enable deprecated sysfs features to support old userspace tools"
 	depends on SYSFS
 	default n
 	help
 	  This option adds code that switches the layout of the "block" class
 	  devices, to not show up in /sys/class/block/, but only in
 	  /sys/block/.
 
 	  This switch is only active when the sysfs.deprecated=1 boot option is
 	  passed or the SYSFS_DEPRECATED_V2 option is set.
 
 	  This option allows new kernels to run on old distributions and tools,
 	  which might get confused by /sys/class/block/. Since 2007/2008 all
 	  major distributions and tools handle this just fine.
 
 	  Recent distributions and userspace tools after 2009/2010 depend on
 	  the existence of /sys/class/block/, and will not work with this
 	  option enabled.
 
 	  Only if you are using a new kernel on an old distribution, you might
 	  need to say Y here.
 
 config SYSFS_DEPRECATED_V2
 	bool "Enable deprecated sysfs features by default"
 	default n
 	depends on SYSFS
 	depends on SYSFS_DEPRECATED
 	help
 	  Enable deprecated sysfs by default.
 
 	  See the CONFIG_SYSFS_DEPRECATED option for more details about this
 	  option.
 
 	  Only if you are using a new kernel on an old distribution, you might
 	  need to say Y here. Even then, odds are you would not need it
 	  enabled, you can always pass the boot option if absolutely necessary.
 
 config RELAY
 	bool "Kernel->user space relay support (formerly relayfs)"
 	select IRQ_WORK
 	help
 	  This option enables support for relay interface support in
 	  certain file systems (such as debugfs).
 	  It is designed to provide an efficient mechanism for tools and
 	  facilities to relay large amounts of data from kernel space to
 	  user space.
 
 	  If unsure, say N.
 
 config BLK_DEV_INITRD
 	bool "Initial RAM filesystem and RAM disk (initramfs/initrd) support"
 	depends on BROKEN || !FRV
 	help
 	  The initial RAM filesystem is a ramfs which is loaded by the
 	  boot loader (loadlin or lilo) and that is mounted as root
 	  before the normal boot procedure. It is typically used to
 	  load modules needed to mount the "real" root file system,
 	  etc. See <file:Documentation/admin-guide/initrd.rst> for details.
 
 	  If RAM disk support (BLK_DEV_RAM) is also included, this
 	  also enables initial RAM disk (initrd) support and adds
 	  15 Kbytes (more on some other architectures) to the kernel size.
 
 	  If unsure say Y.
 
 if BLK_DEV_INITRD
 
 source "usr/Kconfig"
 
 endif
 
 choice
 	prompt "Compiler optimization level"
 	default CONFIG_CC_OPTIMIZE_FOR_PERFORMANCE
 
 config CC_OPTIMIZE_FOR_PERFORMANCE
 	bool "Optimize for performance"
 	help
 	  This is the default optimization level for the kernel, building
 	  with the "-O2" compiler flag for best performance and most
 	  helpful compile-time warnings.
 
 config CC_OPTIMIZE_FOR_SIZE
 	bool "Optimize for size"
 	help
 	  Enabling this option will pass "-Os" instead of "-O2" to
 	  your compiler resulting in a smaller kernel.
 
 	  If unsure, say N.
 
 endchoice
 
 config SYSCTL
 	bool
 
 config ANON_INODES
 	bool
 
 config HAVE_UID16
 	bool
 
 config SYSCTL_EXCEPTION_TRACE
 	bool
 	help
 	  Enable support for /proc/sys/debug/exception-trace.
 
 config SYSCTL_ARCH_UNALIGN_NO_WARN
 	bool
 	help
 	  Enable support for /proc/sys/kernel/ignore-unaligned-usertrap
 	  Allows arch to define/use @no_unaligned_warning to possibly warn
 	  about unaligned access emulation going on under the hood.
 
 config SYSCTL_ARCH_UNALIGN_ALLOW
 	bool
 	help
 	  Enable support for /proc/sys/kernel/unaligned-trap
 	  Allows arches to define/use @unaligned_enabled to runtime toggle
 	  the unaligned access emulation.
 	  see arch/parisc/kernel/unaligned.c for reference
 
 config HAVE_PCSPKR_PLATFORM
 	bool
 
 # interpreter that classic socket filters depend on
 config BPF
 	bool
 
 menuconfig EXPERT
 	bool "Configure standard kernel features (expert users)"
 	# Unhide debug options, to make the on-by-default options visible
 	select DEBUG_KERNEL
 	help
 	  This option allows certain base kernel options and settings
           to be disabled or tweaked. This is for specialized
           environments which can tolerate a "non-standard" kernel.
           Only use this if you really know what you are doing.
 
 config UID16
 	bool "Enable 16-bit UID system calls" if EXPERT
 	depends on HAVE_UID16 && MULTIUSER
 	default y
 	help
 	  This enables the legacy 16-bit UID syscall wrappers.
 
 config MULTIUSER
 	bool "Multiple users, groups and capabilities support" if EXPERT
 	default y
 	help
 	  This option enables support for non-root users, groups and
 	  capabilities.
 
 	  If you say N here, all processes will run with UID 0, GID 0, and all
 	  possible capabilities.  Saying N here also compiles out support for
 	  system calls related to UIDs, GIDs, and capabilities, such as setuid,
 	  setgid, and capset.
 
 	  If unsure, say Y here.
 
 config SGETMASK_SYSCALL
 	bool "sgetmask/ssetmask syscalls support" if EXPERT
 	def_bool PARISC || MN10300 || BLACKFIN || M68K || PPC || MIPS || X86 || SPARC || CRIS || MICROBLAZE || SUPERH
 	---help---
 	  sys_sgetmask and sys_ssetmask are obsolete system calls
 	  no longer supported in libc but still enabled by default in some
 	  architectures.
 
 	  If unsure, leave the default option here.
 
 config SYSFS_SYSCALL
 	bool "Sysfs syscall support" if EXPERT
 	default y
 	---help---
 	  sys_sysfs is an obsolete system call no longer supported in libc.
 	  Note that disabling this option is more secure but might break
 	  compatibility with some systems.
 
 	  If unsure say Y here.
 
 config SYSCTL_SYSCALL
 	bool "Sysctl syscall support" if EXPERT
 	depends on PROC_SYSCTL
 	default n
 	select SYSCTL
 	---help---
 	  sys_sysctl uses binary paths that have been found challenging
 	  to properly maintain and use.  The interface in /proc/sys
 	  using paths with ascii names is now the primary path to this
 	  information.
 
 	  Almost nothing using the binary sysctl interface so if you are
 	  trying to save some space it is probably safe to disable this,
 	  making your kernel marginally smaller.
 
 	  If unsure say N here.
 
 config POSIX_TIMERS
 	bool "Posix Clocks & timers" if EXPERT
 	default y
 	help
 	  This includes native support for POSIX timers to the kernel.
 	  Some embedded systems have no use for them and therefore they
 	  can be configured out to reduce the size of the kernel image.
 
 	  When this option is disabled, the following syscalls won't be
 	  available: timer_create, timer_gettime: timer_getoverrun,
 	  timer_settime, timer_delete, clock_adjtime, getitimer,
 	  setitimer, alarm. Furthermore, the clock_settime, clock_gettime,
 	  clock_getres and clock_nanosleep syscalls will be limited to
 	  CLOCK_REALTIME, CLOCK_MONOTONIC and CLOCK_BOOTTIME only.
 
 	  If unsure say y.
 
 config KALLSYMS
 	 bool "Load all symbols for debugging/ksymoops" if EXPERT
 	 default y
 	 help
 	   Say Y here to let the kernel print out symbolic crash information and
 	   symbolic stack backtraces. This increases the size of the kernel
 	   somewhat, as all symbols have to be loaded into the kernel image.
 
 config KALLSYMS_ALL
 	bool "Include all symbols in kallsyms"
 	depends on DEBUG_KERNEL && KALLSYMS
 	help
 	   Normally kallsyms only contains the symbols of functions for nicer
 	   OOPS messages and backtraces (i.e., symbols from the text and inittext
 	   sections). This is sufficient for most cases. And only in very rare
 	   cases (e.g., when a debugger is used) all symbols are required (e.g.,
 	   names of variables from the data sections, etc).
 
 	   This option makes sure that all symbols are loaded into the kernel
 	   image (i.e., symbols from all sections) in cost of increased kernel
 	   size (depending on the kernel configuration, it may be 300KiB or
 	   something like this).
 
 	   Say N unless you really need all symbols.
 
 config KALLSYMS_ABSOLUTE_PERCPU
 	bool
 	depends on KALLSYMS
 	default X86_64 && SMP
 
 config KALLSYMS_BASE_RELATIVE
 	bool
 	depends on KALLSYMS
 	default !IA64 && !(TILE && 64BIT)
 	help
 	  Instead of emitting them as absolute values in the native word size,
 	  emit the symbol references in the kallsyms table as 32-bit entries,
 	  each containing a relative value in the range [base, base + U32_MAX]
 	  or, when KALLSYMS_ABSOLUTE_PERCPU is in effect, each containing either
 	  an absolute value in the range [0, S32_MAX] or a relative value in the
 	  range [base, base + S32_MAX], where base is the lowest relative symbol
 	  address encountered in the image.
 
 	  On 64-bit builds, this reduces the size of the address table by 50%,
 	  but more importantly, it results in entries whose values are build
 	  time constants, and no relocation pass is required at runtime to fix
 	  up the entries based on the runtime load address of the kernel.
 
 config PRINTK
 	default y
 	bool "Enable support for printk" if EXPERT
 	select IRQ_WORK
 	help
 	  This option enables normal printk support. Removing it
 	  eliminates most of the message strings from the kernel image
 	  and makes the kernel more or less silent. As this makes it
 	  very difficult to diagnose system problems, saying N here is
 	  strongly discouraged.
 
 config PRINTK_NMI
 	def_bool y
 	depends on PRINTK
 	depends on HAVE_NMI
 
 config BUG
 	bool "BUG() support" if EXPERT
 	default y
 	help
           Disabling this option eliminates support for BUG and WARN, reducing
           the size of your kernel image and potentially quietly ignoring
           numerous fatal conditions. You should only consider disabling this
           option for embedded systems with no facilities for reporting errors.
           Just say Y.
 
 config ELF_CORE
 	depends on COREDUMP
 	default y
 	bool "Enable ELF core dumps" if EXPERT
 	help
 	  Enable support for generating core dumps. Disabling saves about 4k.
 
 
 config PCSPKR_PLATFORM
 	bool "Enable PC-Speaker support" if EXPERT
 	depends on HAVE_PCSPKR_PLATFORM
 	select I8253_LOCK
 	default y
 	help
           This option allows to disable the internal PC-Speaker
           support, saving some memory.
 
 config BASE_FULL
 	default y
 	bool "Enable full-sized data structures for core" if EXPERT
 	help
 	  Disabling this option reduces the size of miscellaneous core
 	  kernel data structures. This saves memory on small machines,
 	  but may reduce performance.
 
 config FUTEX
 	bool "Enable futex support" if EXPERT
 	default y
 	select RT_MUTEXES
 	help
 	  Disabling this option will cause the kernel to be built without
 	  support for "fast userspace mutexes".  The resulting kernel may not
 	  run glibc-based applications correctly.
 
 config HAVE_FUTEX_CMPXCHG
 	bool
 	depends on FUTEX
 	help
 	  Architectures should select this if futex_atomic_cmpxchg_inatomic()
 	  is implemented and always working. This removes a couple of runtime
 	  checks.
 
 config EPOLL
 	bool "Enable eventpoll support" if EXPERT
 	default y
 	select ANON_INODES
 	help
 	  Disabling this option will cause the kernel to be built without
 	  support for epoll family of system calls.
 
 config SIGNALFD
 	bool "Enable signalfd() system call" if EXPERT
 	select ANON_INODES
 	default y
 	help
 	  Enable the signalfd() system call that allows to receive signals
 	  on a file descriptor.
 
 	  If unsure, say Y.
 
 config TIMERFD
 	bool "Enable timerfd() system call" if EXPERT
 	select ANON_INODES
 	default y
 	help
 	  Enable the timerfd() system call that allows to receive timer
 	  events on a file descriptor.
 
 	  If unsure, say Y.
 
 config EVENTFD
 	bool "Enable eventfd() system call" if EXPERT
 	select ANON_INODES
 	default y
 	help
 	  Enable the eventfd() system call that allows to receive both
 	  kernel notification (ie. KAIO) or userspace notifications.
 
 	  If unsure, say Y.
 
 # syscall, maps, verifier
 config BPF_SYSCALL
 	bool "Enable bpf() system call"
 	select ANON_INODES
 	select BPF
 	default n
 	help
 	  Enable the bpf() system call that allows to manipulate eBPF
 	  programs and maps via file descriptors.
 
 config SHMEM
 	bool "Use full shmem filesystem" if EXPERT
 	default y
 	depends on MMU
 	help
 	  The shmem is an internal filesystem used to manage shared memory.
 	  It is backed by swap and manages resource limits. It is also exported
 	  to userspace as tmpfs if TMPFS is enabled. Disabling this
 	  option replaces shmem and tmpfs with the much simpler ramfs code,
 	  which may be appropriate on small systems without swap.
 
 config AIO
 	bool "Enable AIO support" if EXPERT
 	default y
 	help
 	  This option enables POSIX asynchronous I/O which may by used
 	  by some high performance threaded applications. Disabling
 	  this option saves about 7k.
 
 config ADVISE_SYSCALLS
 	bool "Enable madvise/fadvise syscalls" if EXPERT
 	default y
 	help
 	  This option enables the madvise and fadvise syscalls, used by
 	  applications to advise the kernel about their future memory or file
 	  usage, improving performance. If building an embedded system where no
 	  applications use these syscalls, you can disable this option to save
 	  space.
 
 config USERFAULTFD
 	bool "Enable userfaultfd() system call"
 	select ANON_INODES
 	depends on MMU
 	help
 	  Enable the userfaultfd() system call that allows to intercept and
 	  handle page faults in userland.
 
 config PCI_QUIRKS
 	default y
 	bool "Enable PCI quirk workarounds" if EXPERT
 	depends on PCI
 	help
 	  This enables workarounds for various PCI chipset
 	  bugs/quirks. Disable this only if your target machine is
 	  unaffected by PCI quirks.
 
 config MEMBARRIER
 	bool "Enable membarrier() system call" if EXPERT
 	default y
 	help
 	  Enable the membarrier() system call that allows issuing memory
 	  barriers across all running threads, which can be used to distribute
 	  the cost of user-space memory barriers asymmetrically by transforming
 	  pairs of memory barriers into pairs consisting of membarrier() and a
 	  compiler barrier.
 
 	  If unsure, say Y.
 
 config EMBEDDED
 	bool "Embedded system"
 	option allnoconfig_y
 	select EXPERT
 	help
 	  This option should be enabled if compiling the kernel for
 	  an embedded system so certain expert options are available
 	  for configuration.
 
 config HAVE_PERF_EVENTS
 	bool
 	help
 	  See tools/perf/design.txt for details.
 
 config PERF_USE_VMALLOC
 	bool
 	help
 	  See tools/perf/design.txt for details
 
+config PC104
+	bool "PC/104 support"
+	help
+	  Expose PC/104 form factor device drivers and options available for
+	  selection and configuration. Enable this option if your target
+	  machine has a PC/104 bus.
+
 menu "Kernel Performance Events And Counters"
 
 config PERF_EVENTS
 	bool "Kernel performance events and counters"
 	default y if PROFILING
 	depends on HAVE_PERF_EVENTS
 	select ANON_INODES
 	select IRQ_WORK
 	select SRCU
 	help
 	  Enable kernel support for various performance events provided
 	  by software and hardware.
 
 	  Software events are supported either built-in or via the
 	  use of generic tracepoints.
 
 	  Most modern CPUs support performance events via performance
 	  counter registers. These registers count the number of certain
 	  types of hw events: such as instructions executed, cachemisses
 	  suffered, or branches mis-predicted - without slowing down the
 	  kernel or applications. These registers can also trigger interrupts
 	  when a threshold number of events have passed - and can thus be
 	  used to profile the code that runs on that CPU.
 
 	  The Linux Performance Event subsystem provides an abstraction of
 	  these software and hardware event capabilities, available via a
 	  system call and used by the "perf" utility in tools/perf/. It
 	  provides per task and per CPU counters, and it provides event
 	  capabilities on top of those.
 
 	  Say Y if unsure.
 
 config DEBUG_PERF_USE_VMALLOC
 	default n
 	bool "Debug: use vmalloc to back perf mmap() buffers"
 	depends on PERF_EVENTS && DEBUG_KERNEL && !PPC
 	select PERF_USE_VMALLOC
 	help
 	 Use vmalloc memory to back perf mmap() buffers.
 
 	 Mostly useful for debugging the vmalloc code on platforms
 	 that don't require it.
 
 	 Say N if unsure.
 
 endmenu
 
 config VM_EVENT_COUNTERS
 	default y
 	bool "Enable VM event counters for /proc/vmstat" if EXPERT
 	help
 	  VM event counters are needed for event counts to be shown.
 	  This option allows the disabling of the VM event counters
 	  on EXPERT systems.  /proc/vmstat will only show page counts
 	  if VM event counters are disabled.
 
 config SLUB_DEBUG
 	default y
 	bool "Enable SLUB debugging support" if EXPERT
 	depends on SLUB && SYSFS
 	help
 	  SLUB has extensive debug support features. Disabling these can
 	  result in significant savings in code size. This also disables
 	  SLUB sysfs support. /sys/slab will not exist and there will be
 	  no support for cache validation etc.
 
 config COMPAT_BRK
 	bool "Disable heap randomization"
 	default y
 	help
 	  Randomizing heap placement makes heap exploits harder, but it
 	  also breaks ancient binaries (including anything libc5 based).
 	  This option changes the bootup default to heap randomization
 	  disabled, and can be overridden at runtime by setting
 	  /proc/sys/kernel/randomize_va_space to 2.
 
 	  On non-ancient distros (post-2000 ones) N is usually a safe choice.
 
 choice
 	prompt "Choose SLAB allocator"
 	default SLUB
 	help
 	   This option allows to select a slab allocator.
 
 config SLAB
 	bool "SLAB"
 	select HAVE_HARDENED_USERCOPY_ALLOCATOR
 	help
 	  The regular slab allocator that is established and known to work
 	  well in all environments. It organizes cache hot objects in
 	  per cpu and per node queues.
 
 config SLUB
 	bool "SLUB (Unqueued Allocator)"
 	select HAVE_HARDENED_USERCOPY_ALLOCATOR
 	help
 	   SLUB is a slab allocator that minimizes cache line usage
 	   instead of managing queues of cached objects (SLAB approach).
 	   Per cpu caching is realized using slabs of objects instead
 	   of queues of objects. SLUB can use memory efficiently
 	   and has enhanced diagnostics. SLUB is the default choice for
 	   a slab allocator.
 
 config SLOB
 	depends on EXPERT
 	bool "SLOB (Simple Allocator)"
 	help
 	   SLOB replaces the stock allocator with a drastically simpler
 	   allocator. SLOB is generally more space efficient but
 	   does not perform as well on large systems.
 
 endchoice
 
 config SLAB_FREELIST_RANDOM
 	default n
 	depends on SLAB || SLUB
 	bool "SLAB freelist randomization"
 	help
 	  Randomizes the freelist order used on creating new pages. This
 	  security feature reduces the predictability of the kernel slab
 	  allocator against heap overflows.
 
 config SLUB_CPU_PARTIAL
 	default y
 	depends on SLUB && SMP
 	bool "SLUB per cpu partial cache"
 	help
 	  Per cpu partial caches accellerate objects allocation and freeing
 	  that is local to a processor at the price of more indeterminism
 	  in the latency of the free. On overflow these caches will be cleared
 	  which requires the taking of locks that may cause latency spikes.
 	  Typically one would choose no for a realtime system.
 
 config MMAP_ALLOW_UNINITIALIZED
 	bool "Allow mmapped anonymous memory to be uninitialized"
 	depends on EXPERT && !MMU
 	default n
 	help
 	  Normally, and according to the Linux spec, anonymous memory obtained
 	  from mmap() has it's contents cleared before it is passed to
 	  userspace.  Enabling this config option allows you to request that
 	  mmap() skip that if it is given an MAP_UNINITIALIZED flag, thus
 	  providing a huge performance boost.  If this option is not enabled,
 	  then the flag will be ignored.
 
 	  This is taken advantage of by uClibc's malloc(), and also by
 	  ELF-FDPIC binfmt's brk and stack allocator.
 
 	  Because of the obvious security issues, this option should only be
 	  enabled on embedded devices where you control what is run in
 	  userspace.  Since that isn't generally a problem on no-MMU systems,
 	  it is normally safe to say Y here.
 
 	  See Documentation/nommu-mmap.txt for more information.
 
 config SYSTEM_DATA_VERIFICATION
 	def_bool n
 	select SYSTEM_TRUSTED_KEYRING
 	select KEYS
 	select CRYPTO
 	select CRYPTO_RSA
 	select ASYMMETRIC_KEY_TYPE
 	select ASYMMETRIC_PUBLIC_KEY_SUBTYPE
 	select ASN1
 	select OID_REGISTRY
 	select X509_CERTIFICATE_PARSER
 	select PKCS7_MESSAGE_PARSER
 	help
 	  Provide PKCS#7 message verification using the contents of the system
 	  trusted keyring to provide public keys.  This then can be used for
 	  module verification, kexec image verification and firmware blob
 	  verification.
 
 config PROFILING
 	bool "Profiling support"
 	help
 	  Say Y here to enable the extended profiling support mechanisms used
 	  by profilers such as OProfile.
 
 #
 # Place an empty function call at each tracepoint site. Can be
 # dynamically changed for a probe function.
 #
 config TRACEPOINTS
 	bool
 
 source "arch/Kconfig"
 
 endmenu		# General setup
 
 config HAVE_GENERIC_DMA_COHERENT
 	bool
 	default n
 
 config SLABINFO
 	bool
 	depends on PROC_FS
 	depends on SLAB || SLUB_DEBUG
 	default y
 
 config RT_MUTEXES
 	bool
 
 config BASE_SMALL
 	int
 	default 0 if BASE_FULL
 	default 1 if !BASE_FULL
 
 menuconfig MODULES
 	bool "Enable loadable module support"
 	option modules
 	help
 	  Kernel modules are small pieces of compiled code which can
 	  be inserted in the running kernel, rather than being
 	  permanently built into the kernel.  You use the "modprobe"
 	  tool to add (and sometimes remove) them.  If you say Y here,
 	  many parts of the kernel can be built as modules (by
 	  answering M instead of Y where indicated): this is most
 	  useful for infrequently used options which are not required
 	  for booting.  For more information, see the man pages for
 	  modprobe, lsmod, modinfo, insmod and rmmod.
 
 	  If you say Y here, you will need to run "make
 	  modules_install" to put the modules under /lib/modules/
 	  where modprobe can find them (you may need to be root to do
 	  this).
 
 	  If unsure, say Y.
 
 if MODULES
 
 config MODULE_FORCE_LOAD
 	bool "Forced module loading"
 	default n
 	help
 	  Allow loading of modules without version information (ie. modprobe
 	  --force).  Forced module loading sets the 'F' (forced) taint flag and
 	  is usually a really bad idea.
 
 config MODULE_UNLOAD
 	bool "Module unloading"
 	help
 	  Without this option you will not be able to unload any
 	  modules (note that some modules may not be unloadable
 	  anyway), which makes your kernel smaller, faster
 	  and simpler.  If unsure, say Y.
 
 config MODULE_FORCE_UNLOAD
 	bool "Forced module unloading"
 	depends on MODULE_UNLOAD
 	help
 	  This option allows you to force a module to unload, even if the
 	  kernel believes it is unsafe: the kernel will remove the module
 	  without waiting for anyone to stop using it (using the -f option to
 	  rmmod).  This is mainly for kernel developers and desperate users.
 	  If unsure, say N.
 
 config MODVERSIONS
 	bool "Module versioning support"
 	help
 	  Usually, you have to use modules compiled with your kernel.
 	  Saying Y here makes it sometimes possible to use modules
 	  compiled for different kernels, by adding enough information
 	  to the modules to (hopefully) spot any changes which would
 	  make them incompatible with the kernel you are running.  If
 	  unsure, say N.
 
 config MODULE_REL_CRCS
 	bool
 	depends on MODVERSIONS
 
 config MODULE_SRCVERSION_ALL
 	bool "Source checksum for all modules"
 	help
 	  Modules which contain a MODULE_VERSION get an extra "srcversion"
 	  field inserted into their modinfo section, which contains a
     	  sum of the source files which made it.  This helps maintainers
 	  see exactly which source was used to build a module (since
 	  others sometimes change the module source without updating
 	  the version).  With this option, such a "srcversion" field
 	  will be created for all modules.  If unsure, say N.
 
 config MODULE_SIG
 	bool "Module signature verification"
 	depends on MODULES
 	select SYSTEM_DATA_VERIFICATION
 	help
 	  Check modules for valid signatures upon load: the signature
 	  is simply appended to the module. For more information see
 	  Documentation/module-signing.txt.
 
 	  Note that this option adds the OpenSSL development packages as a
 	  kernel build dependency so that the signing tool can use its crypto
 	  library.
 
 	  !!!WARNING!!!  If you enable this option, you MUST make sure that the
 	  module DOES NOT get stripped after being signed.  This includes the
 	  debuginfo strip done by some packagers (such as rpmbuild) and
 	  inclusion into an initramfs that wants the module size reduced.
 
 config MODULE_SIG_FORCE
 	bool "Require modules to be validly signed"
 	depends on MODULE_SIG
 	help
 	  Reject unsigned modules or signed modules for which we don't have a
 	  key.  Without this, such modules will simply taint the kernel.
 
 config MODULE_SIG_ALL
 	bool "Automatically sign all modules"
 	default y
 	depends on MODULE_SIG
 	help
 	  Sign all modules during make modules_install. Without this option,
 	  modules must be signed manually, using the scripts/sign-file tool.
 
 comment "Do not forget to sign required modules with scripts/sign-file"
 	depends on MODULE_SIG_FORCE && !MODULE_SIG_ALL
 
 choice
 	prompt "Which hash algorithm should modules be signed with?"
 	depends on MODULE_SIG
 	help
 	  This determines which sort of hashing algorithm will be used during
 	  signature generation.  This algorithm _must_ be built into the kernel
 	  directly so that signature verification can take place.  It is not
 	  possible to load a signed module containing the algorithm to check
 	  the signature on that module.
 
 config MODULE_SIG_SHA1
 	bool "Sign modules with SHA-1"
 	select CRYPTO_SHA1
 
 config MODULE_SIG_SHA224
 	bool "Sign modules with SHA-224"
 	select CRYPTO_SHA256
 
 config MODULE_SIG_SHA256
 	bool "Sign modules with SHA-256"
 	select CRYPTO_SHA256
 
 config MODULE_SIG_SHA384
 	bool "Sign modules with SHA-384"
 	select CRYPTO_SHA512
 
 config MODULE_SIG_SHA512
 	bool "Sign modules with SHA-512"
 	select CRYPTO_SHA512
 
 endchoice
 
 config MODULE_SIG_HASH
 	string
 	depends on MODULE_SIG
 	default "sha1" if MODULE_SIG_SHA1
 	default "sha224" if MODULE_SIG_SHA224
 	default "sha256" if MODULE_SIG_SHA256
 	default "sha384" if MODULE_SIG_SHA384
 	default "sha512" if MODULE_SIG_SHA512
 
 config MODULE_COMPRESS
 	bool "Compress modules on installation"
 	depends on MODULES
 	help
 
 	  Compresses kernel modules when 'make modules_install' is run; gzip or
 	  xz depending on "Compression algorithm" below.
 
 	  module-init-tools MAY support gzip, and kmod MAY support gzip and xz.
 
 	  Out-of-tree kernel modules installed using Kbuild will also be
 	  compressed upon installation.
 
 	  Note: for modules inside an initrd or initramfs, it's more efficient
 	  to compress the whole initrd or initramfs instead.
 
 	  Note: This is fully compatible with signed modules.
 
 	  If in doubt, say N.
 
 choice
 	prompt "Compression algorithm"
 	depends on MODULE_COMPRESS
 	default MODULE_COMPRESS_GZIP
 	help
 	  This determines which sort of compression will be used during
 	  'make modules_install'.
 
 	  GZIP (default) and XZ are supported.
 
 config MODULE_COMPRESS_GZIP
 	bool "GZIP"
 
 config MODULE_COMPRESS_XZ
 	bool "XZ"
 
 endchoice
 
 config TRIM_UNUSED_KSYMS
 	bool "Trim unused exported kernel symbols"
 	depends on MODULES && !UNUSED_SYMBOLS
 	help
 	  The kernel and some modules make many symbols available for
 	  other modules to use via EXPORT_SYMBOL() and variants. Depending
 	  on the set of modules being selected in your kernel configuration,
 	  many of those exported symbols might never be used.
 
 	  This option allows for unused exported symbols to be dropped from
 	  the build. In turn, this provides the compiler more opportunities
 	  (especially when using LTO) for optimizing the code and reducing
 	  binary size.  This might have some security advantages as well.
 
 	  If unsure, or if you need to build out-of-tree modules, say N.
 
 endif # MODULES
 
 config MODULES_TREE_LOOKUP
 	def_bool y
 	depends on PERF_EVENTS || TRACING
 
 config INIT_ALL_POSSIBLE
 	bool
 	help
 	  Back when each arch used to define their own cpu_online_mask and
 	  cpu_possible_mask, some of them chose to initialize cpu_possible_mask
 	  with all 1s, and others with all 0s.  When they were centralised,
 	  it was better to provide this option than to break all the archs
 	  and have several arch maintainers pursuing me down dark alleys.
 
 source "block/Kconfig"
 
 config PREEMPT_NOTIFIERS
 	bool
 
 config PADATA
 	depends on SMP
 	bool
 
 config ASN1
 	tristate
 	help
 	  Build a simple ASN.1 grammar compiler that produces a bytecode output
 	  that can be interpreted by the ASN.1 stream decoder and used to
 	  inform it as to what tags are to be expected in a stream and what
 	  functions to call on what tags.
 
 source "kernel/Kconfig.locks"
diff --git a/lib/test_firmware.c b/lib/test_firmware.c
index a3e8ec3fb1c5..09371b0a9baf 100644
--- a/lib/test_firmware.c
+++ b/lib/test_firmware.c
@@ -1,186 +1,218 @@
 /*
  * This module provides an interface to trigger and test firmware loading.
  *
  * It is designed to be used for basic evaluation of the firmware loading
  * subsystem (for example when validating firmware verification). It lacks
  * any extra dependencies, and will not normally be loaded by the system
  * unless explicitly requested by name.
  */
 
 #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
 
 #include <linux/init.h>
 #include <linux/module.h>
 #include <linux/printk.h>
 #include <linux/completion.h>
 #include <linux/firmware.h>
 #include <linux/device.h>
 #include <linux/fs.h>
 #include <linux/miscdevice.h>
 #include <linux/slab.h>
 #include <linux/uaccess.h>
 
 static DEFINE_MUTEX(test_fw_mutex);
 static const struct firmware *test_firmware;
 
 static ssize_t test_fw_misc_read(struct file *f, char __user *buf,
 				 size_t size, loff_t *offset)
 {
 	ssize_t rc = 0;
 
 	mutex_lock(&test_fw_mutex);
 	if (test_firmware)
 		rc = simple_read_from_buffer(buf, size, offset,
 					     test_firmware->data,
 					     test_firmware->size);
 	mutex_unlock(&test_fw_mutex);
 	return rc;
 }
 
 static const struct file_operations test_fw_fops = {
 	.owner          = THIS_MODULE,
 	.read           = test_fw_misc_read,
 };
 
-static struct miscdevice test_fw_misc_device = {
-	.minor          = MISC_DYNAMIC_MINOR,
-	.name           = "test_firmware",
-	.fops           = &test_fw_fops,
-};
-
 static ssize_t trigger_request_store(struct device *dev,
 				     struct device_attribute *attr,
 				     const char *buf, size_t count)
 {
 	int rc;
 	char *name;
 
 	name = kstrndup(buf, count, GFP_KERNEL);
 	if (!name)
 		return -ENOSPC;
 
 	pr_info("loading '%s'\n", name);
 
 	mutex_lock(&test_fw_mutex);
 	release_firmware(test_firmware);
 	test_firmware = NULL;
 	rc = request_firmware(&test_firmware, name, dev);
 	if (rc) {
 		pr_info("load of '%s' failed: %d\n", name, rc);
 		goto out;
 	}
 	pr_info("loaded: %zu\n", test_firmware->size);
 	rc = count;
 
 out:
 	mutex_unlock(&test_fw_mutex);
 
 	kfree(name);
 
 	return rc;
 }
 static DEVICE_ATTR_WO(trigger_request);
 
 static DECLARE_COMPLETION(async_fw_done);
 
 static void trigger_async_request_cb(const struct firmware *fw, void *context)
 {
 	test_firmware = fw;
 	complete(&async_fw_done);
 }
 
 static ssize_t trigger_async_request_store(struct device *dev,
 					   struct device_attribute *attr,
 					   const char *buf, size_t count)
 {
 	int rc;
 	char *name;
 
 	name = kstrndup(buf, count, GFP_KERNEL);
 	if (!name)
 		return -ENOSPC;
 
 	pr_info("loading '%s'\n", name);
 
 	mutex_lock(&test_fw_mutex);
 	release_firmware(test_firmware);
 	test_firmware = NULL;
 	rc = request_firmware_nowait(THIS_MODULE, 1, name, dev, GFP_KERNEL,
 				     NULL, trigger_async_request_cb);
 	if (rc) {
 		pr_info("async load of '%s' failed: %d\n", name, rc);
 		kfree(name);
 		goto out;
 	}
 	/* Free 'name' ASAP, to test for race conditions */
 	kfree(name);
 
 	wait_for_completion(&async_fw_done);
 
 	if (test_firmware) {
 		pr_info("loaded: %zu\n", test_firmware->size);
 		rc = count;
 	} else {
 		pr_err("failed to async load firmware\n");
 		rc = -ENODEV;
 	}
 
 out:
 	mutex_unlock(&test_fw_mutex);
 
 	return rc;
 }
 static DEVICE_ATTR_WO(trigger_async_request);
 
-static int __init test_firmware_init(void)
+static ssize_t trigger_custom_fallback_store(struct device *dev,
+					     struct device_attribute *attr,
+					     const char *buf, size_t count)
 {
 	int rc;
+	char *name;
 
-	rc = misc_register(&test_fw_misc_device);
+	name = kstrndup(buf, count, GFP_KERNEL);
+	if (!name)
+		return -ENOSPC;
+
+	pr_info("loading '%s' using custom fallback mechanism\n", name);
+
+	mutex_lock(&test_fw_mutex);
+	release_firmware(test_firmware);
+	test_firmware = NULL;
+	rc = request_firmware_nowait(THIS_MODULE, FW_ACTION_NOHOTPLUG, name,
+				     dev, GFP_KERNEL, NULL,
+				     trigger_async_request_cb);
 	if (rc) {
-		pr_err("could not register misc device: %d\n", rc);
-		return rc;
+		pr_info("async load of '%s' failed: %d\n", name, rc);
+		kfree(name);
+		goto out;
 	}
-	rc = device_create_file(test_fw_misc_device.this_device,
-				&dev_attr_trigger_request);
-	if (rc) {
-		pr_err("could not create sysfs interface: %d\n", rc);
-		goto dereg;
+	/* Free 'name' ASAP, to test for race conditions */
+	kfree(name);
+
+	wait_for_completion(&async_fw_done);
+
+	if (test_firmware) {
+		pr_info("loaded: %zu\n", test_firmware->size);
+		rc = count;
+	} else {
+		pr_err("failed to async load firmware\n");
+		rc = -ENODEV;
 	}
 
-	rc = device_create_file(test_fw_misc_device.this_device,
-				&dev_attr_trigger_async_request);
+out:
+	mutex_unlock(&test_fw_mutex);
+
+	return rc;
+}
+static DEVICE_ATTR_WO(trigger_custom_fallback);
+
+#define TEST_FW_DEV_ATTR(name)          &dev_attr_##name.attr
+
+static struct attribute *test_dev_attrs[] = {
+	TEST_FW_DEV_ATTR(trigger_request),
+	TEST_FW_DEV_ATTR(trigger_async_request),
+	TEST_FW_DEV_ATTR(trigger_custom_fallback),
+	NULL,
+};
+
+ATTRIBUTE_GROUPS(test_dev);
+
+static struct miscdevice test_fw_misc_device = {
+	.minor          = MISC_DYNAMIC_MINOR,
+	.name           = "test_firmware",
+	.fops           = &test_fw_fops,
+	.groups 	= test_dev_groups,
+};
+
+static int __init test_firmware_init(void)
+{
+	int rc;
+
+	rc = misc_register(&test_fw_misc_device);
 	if (rc) {
-		pr_err("could not create async sysfs interface: %d\n", rc);
-		goto remove_file;
+		pr_err("could not register misc device: %d\n", rc);
+		return rc;
 	}
 
 	pr_warn("interface ready\n");
 
 	return 0;
-
-remove_file:
-	device_remove_file(test_fw_misc_device.this_device,
-			   &dev_attr_trigger_async_request);
-dereg:
-	misc_deregister(&test_fw_misc_device);
-	return rc;
 }
 
 module_init(test_firmware_init);
 
 static void __exit test_firmware_exit(void)
 {
 	release_firmware(test_firmware);
-	device_remove_file(test_fw_misc_device.this_device,
-			   &dev_attr_trigger_async_request);
-	device_remove_file(test_fw_misc_device.this_device,
-			   &dev_attr_trigger_request);
 	misc_deregister(&test_fw_misc_device);
 	pr_warn("removed interface\n");
 }
 
 module_exit(test_firmware_exit);
 
 MODULE_AUTHOR("Kees Cook <keescook@chromium.org>");
 MODULE_LICENSE("GPL");
diff --git a/scripts/checkkconfigsymbols.py b/scripts/checkkconfigsymbols.py
index 3820f00b066a..8cd16c65d3c5 100755
--- a/scripts/checkkconfigsymbols.py
+++ b/scripts/checkkconfigsymbols.py
@@ -1,476 +1,476 @@
 #!/usr/bin/env python3
 
 """Find Kconfig symbols that are referenced but not defined."""
 
-# (c) 2014-2016 Valentin Rothberg <valentinrothberg@gmail.com>
+# (c) 2014-2017 Valentin Rothberg <valentinrothberg@gmail.com>
 # (c) 2014 Stefan Hengelein <stefan.hengelein@fau.de>
 #
 # Licensed under the terms of the GNU GPL License version 2
 
 
 import argparse
 import difflib
 import os
 import re
 import signal
 import subprocess
 import sys
 from multiprocessing import Pool, cpu_count
 
 
 # regex expressions
 OPERATORS = r"&|\(|\)|\||\!"
 SYMBOL = r"(?:\w*[A-Z0-9]\w*){2,}"
 DEF = r"^\s*(?:menu){,1}config\s+(" + SYMBOL + r")\s*"
 EXPR = r"(?:" + OPERATORS + r"|\s|" + SYMBOL + r")+"
 DEFAULT = r"default\s+.*?(?:if\s.+){,1}"
-STMT = r"^\s*(?:if|select|depends\s+on|(?:" + DEFAULT + r"))\s+" + EXPR
+STMT = r"^\s*(?:if|select|imply|depends\s+on|(?:" + DEFAULT + r"))\s+" + EXPR
 SOURCE_SYMBOL = r"(?:\W|\b)+[D]{,1}CONFIG_(" + SYMBOL + r")"
 
 # regex objects
 REGEX_FILE_KCONFIG = re.compile(r".*Kconfig[\.\w+\-]*$")
 REGEX_SYMBOL = re.compile(r'(?!\B)' + SYMBOL + r'(?!\B)')
 REGEX_SOURCE_SYMBOL = re.compile(SOURCE_SYMBOL)
 REGEX_KCONFIG_DEF = re.compile(DEF)
 REGEX_KCONFIG_EXPR = re.compile(EXPR)
 REGEX_KCONFIG_STMT = re.compile(STMT)
 REGEX_KCONFIG_HELP = re.compile(r"^\s+(help|---help---)\s*$")
 REGEX_FILTER_SYMBOLS = re.compile(r"[A-Za-z0-9]$")
 REGEX_NUMERIC = re.compile(r"0[xX][0-9a-fA-F]+|[0-9]+")
 REGEX_QUOTES = re.compile("(\"(.*?)\")")
 
 
 def parse_options():
     """The user interface of this module."""
     usage = "Run this tool to detect Kconfig symbols that are referenced but " \
             "not defined in Kconfig.  If no option is specified, "             \
             "checkkconfigsymbols defaults to check your current tree.  "       \
             "Please note that specifying commits will 'git reset --hard\' "    \
             "your current tree!  You may save uncommitted changes to avoid "   \
             "losing data."
 
     parser = argparse.ArgumentParser(description=usage)
 
     parser.add_argument('-c', '--commit', dest='commit', action='store',
                         default="",
                         help="check if the specified commit (hash) introduces "
                              "undefined Kconfig symbols")
 
     parser.add_argument('-d', '--diff', dest='diff', action='store',
                         default="",
                         help="diff undefined symbols between two commits "
                              "(e.g., -d commmit1..commit2)")
 
     parser.add_argument('-f', '--find', dest='find', action='store_true',
                         default=False,
                         help="find and show commits that may cause symbols to be "
                              "missing (required to run with --diff)")
 
     parser.add_argument('-i', '--ignore', dest='ignore', action='store',
                         default="",
                         help="ignore files matching this Python regex "
                              "(e.g., -i '.*defconfig')")
 
     parser.add_argument('-s', '--sim', dest='sim', action='store', default="",
                         help="print a list of max. 10 string-similar symbols")
 
     parser.add_argument('--force', dest='force', action='store_true',
                         default=False,
                         help="reset current Git tree even when it's dirty")
 
     parser.add_argument('--no-color', dest='color', action='store_false',
                         default=True,
                         help="don't print colored output (default when not "
                              "outputting to a terminal)")
 
     args = parser.parse_args()
 
     if args.commit and args.diff:
         sys.exit("Please specify only one option at once.")
 
     if args.diff and not re.match(r"^[\w\-\.\^]+\.\.[\w\-\.\^]+$", args.diff):
         sys.exit("Please specify valid input in the following format: "
                  "\'commit1..commit2\'")
 
     if args.commit or args.diff:
         if not args.force and tree_is_dirty():
             sys.exit("The current Git tree is dirty (see 'git status').  "
                      "Running this script may\ndelete important data since it "
                      "calls 'git reset --hard' for some performance\nreasons. "
                      " Please run this script in a clean Git tree or pass "
                      "'--force' if you\nwant to ignore this warning and "
                      "continue.")
 
     if args.commit:
         args.find = False
 
     if args.ignore:
         try:
             re.match(args.ignore, "this/is/just/a/test.c")
         except:
             sys.exit("Please specify a valid Python regex.")
 
     return args
 
 
 def main():
     """Main function of this module."""
     args = parse_options()
 
     global COLOR
     COLOR = args.color and sys.stdout.isatty()
 
     if args.sim and not args.commit and not args.diff:
         sims = find_sims(args.sim, args.ignore)
         if sims:
             print("%s: %s" % (yel("Similar symbols"), ', '.join(sims)))
         else:
             print("%s: no similar symbols found" % yel("Similar symbols"))
         sys.exit(0)
 
     # dictionary of (un)defined symbols
     defined = {}
     undefined = {}
 
     if args.commit or args.diff:
         head = get_head()
 
         # get commit range
         commit_a = None
         commit_b = None
         if args.commit:
             commit_a = args.commit + "~"
             commit_b = args.commit
         elif args.diff:
             split = args.diff.split("..")
             commit_a = split[0]
             commit_b = split[1]
             undefined_a = {}
             undefined_b = {}
 
         # get undefined items before the commit
         reset(commit_a)
         undefined_a, _ = check_symbols(args.ignore)
 
         # get undefined items for the commit
         reset(commit_b)
         undefined_b, defined = check_symbols(args.ignore)
 
         # report cases that are present for the commit but not before
         for symbol in sorted(undefined_b):
             # symbol has not been undefined before
             if symbol not in undefined_a:
                 files = sorted(undefined_b.get(symbol))
                 undefined[symbol] = files
             # check if there are new files that reference the undefined symbol
             else:
                 files = sorted(undefined_b.get(symbol) -
                                undefined_a.get(symbol))
                 if files:
                     undefined[symbol] = files
 
         # reset to head
         reset(head)
 
     # default to check the entire tree
     else:
         undefined, defined = check_symbols(args.ignore)
 
     # now print the output
     for symbol in sorted(undefined):
         print(red(symbol))
 
         files = sorted(undefined.get(symbol))
         print("%s: %s" % (yel("Referencing files"), ", ".join(files)))
 
         sims = find_sims(symbol, args.ignore, defined)
         sims_out = yel("Similar symbols")
         if sims:
             print("%s: %s" % (sims_out, ', '.join(sims)))
         else:
             print("%s: %s" % (sims_out, "no similar symbols found"))
 
         if args.find:
             print("%s:" % yel("Commits changing symbol"))
             commits = find_commits(symbol, args.diff)
             if commits:
                 for commit in commits:
                     commit = commit.split(" ", 1)
                     print("\t- %s (\"%s\")" % (yel(commit[0]), commit[1]))
             else:
                 print("\t- no commit found")
         print()  # new line
 
 
 def reset(commit):
     """Reset current git tree to %commit."""
     execute(["git", "reset", "--hard", commit])
 
 
 def yel(string):
     """
     Color %string yellow.
     """
     return "\033[33m%s\033[0m" % string if COLOR else string
 
 
 def red(string):
     """
     Color %string red.
     """
     return "\033[31m%s\033[0m" % string if COLOR else string
 
 
 def execute(cmd):
     """Execute %cmd and return stdout.  Exit in case of error."""
     try:
         stdout = subprocess.check_output(cmd, stderr=subprocess.STDOUT, shell=False)
         stdout = stdout.decode(errors='replace')
     except subprocess.CalledProcessError as fail:
         exit(fail)
     return stdout
 
 
 def find_commits(symbol, diff):
     """Find commits changing %symbol in the given range of %diff."""
     commits = execute(["git", "log", "--pretty=oneline",
                        "--abbrev-commit", "-G",
                        symbol, diff])
     return [x for x in commits.split("\n") if x]
 
 
 def tree_is_dirty():
     """Return true if the current working tree is dirty (i.e., if any file has
     been added, deleted, modified, renamed or copied but not committed)."""
     stdout = execute(["git", "status", "--porcelain"])
     for line in stdout:
         if re.findall(r"[URMADC]{1}", line[:2]):
             return True
     return False
 
 
 def get_head():
     """Return commit hash of current HEAD."""
     stdout = execute(["git", "rev-parse", "HEAD"])
     return stdout.strip('\n')
 
 
 def partition(lst, size):
     """Partition list @lst into eveni-sized lists of size @size."""
     return [lst[i::size] for i in range(size)]
 
 
 def init_worker():
     """Set signal handler to ignore SIGINT."""
     signal.signal(signal.SIGINT, signal.SIG_IGN)
 
 
 def find_sims(symbol, ignore, defined=[]):
     """Return a list of max. ten Kconfig symbols that are string-similar to
     @symbol."""
     if defined:
-        return sorted(difflib.get_close_matches(symbol, set(defined), 10))
+        return difflib.get_close_matches(symbol, set(defined), 10)
 
     pool = Pool(cpu_count(), init_worker)
     kfiles = []
     for gitfile in get_files():
         if REGEX_FILE_KCONFIG.match(gitfile):
             kfiles.append(gitfile)
 
     arglist = []
     for part in partition(kfiles, cpu_count()):
         arglist.append((part, ignore))
 
     for res in pool.map(parse_kconfig_files, arglist):
         defined.extend(res[0])
 
-    return sorted(difflib.get_close_matches(symbol, set(defined), 10))
+    return difflib.get_close_matches(symbol, set(defined), 10)
 
 
 def get_files():
     """Return a list of all files in the current git directory."""
     # use 'git ls-files' to get the worklist
     stdout = execute(["git", "ls-files"])
     if len(stdout) > 0 and stdout[-1] == "\n":
         stdout = stdout[:-1]
 
     files = []
     for gitfile in stdout.rsplit("\n"):
         if ".git" in gitfile or "ChangeLog" in gitfile or      \
                 ".log" in gitfile or os.path.isdir(gitfile) or \
                 gitfile.startswith("tools/"):
             continue
         files.append(gitfile)
     return files
 
 
 def check_symbols(ignore):
     """Find undefined Kconfig symbols and return a dict with the symbol as key
     and a list of referencing files as value.  Files matching %ignore are not
     checked for undefined symbols."""
     pool = Pool(cpu_count(), init_worker)
     try:
         return check_symbols_helper(pool, ignore)
     except KeyboardInterrupt:
         pool.terminate()
         pool.join()
         sys.exit(1)
 
 
 def check_symbols_helper(pool, ignore):
     """Helper method for check_symbols().  Used to catch keyboard interrupts in
     check_symbols() in order to properly terminate running worker processes."""
     source_files = []
     kconfig_files = []
     defined_symbols = []
     referenced_symbols = dict()  # {file: [symbols]}
 
     for gitfile in get_files():
         if REGEX_FILE_KCONFIG.match(gitfile):
             kconfig_files.append(gitfile)
         else:
             if ignore and not re.match(ignore, gitfile):
                 continue
             # add source files that do not match the ignore pattern
             source_files.append(gitfile)
 
     # parse source files
     arglist = partition(source_files, cpu_count())
     for res in pool.map(parse_source_files, arglist):
         referenced_symbols.update(res)
 
     # parse kconfig files
     arglist = []
     for part in partition(kconfig_files, cpu_count()):
         arglist.append((part, ignore))
     for res in pool.map(parse_kconfig_files, arglist):
         defined_symbols.extend(res[0])
         referenced_symbols.update(res[1])
     defined_symbols = set(defined_symbols)
 
     # inverse mapping of referenced_symbols to dict(symbol: [files])
     inv_map = dict()
     for _file, symbols in referenced_symbols.items():
         for symbol in symbols:
             inv_map[symbol] = inv_map.get(symbol, set())
             inv_map[symbol].add(_file)
     referenced_symbols = inv_map
 
     undefined = {}  # {symbol: [files]}
     for symbol in sorted(referenced_symbols):
         # filter some false positives
         if symbol == "FOO" or symbol == "BAR" or \
                 symbol == "FOO_BAR" or symbol == "XXX":
             continue
         if symbol not in defined_symbols:
             if symbol.endswith("_MODULE"):
                 # avoid false positives for kernel modules
                 if symbol[:-len("_MODULE")] in defined_symbols:
                     continue
             undefined[symbol] = referenced_symbols.get(symbol)
     return undefined, defined_symbols
 
 
 def parse_source_files(source_files):
     """Parse each source file in @source_files and return dictionary with source
     files as keys and lists of references Kconfig symbols as values."""
     referenced_symbols = dict()
     for sfile in source_files:
         referenced_symbols[sfile] = parse_source_file(sfile)
     return referenced_symbols
 
 
 def parse_source_file(sfile):
     """Parse @sfile and return a list of referenced Kconfig symbols."""
     lines = []
     references = []
 
     if not os.path.exists(sfile):
         return references
 
     with open(sfile, "r", encoding='utf-8', errors='replace') as stream:
         lines = stream.readlines()
 
     for line in lines:
         if "CONFIG_" not in line:
             continue
         symbols = REGEX_SOURCE_SYMBOL.findall(line)
         for symbol in symbols:
             if not REGEX_FILTER_SYMBOLS.search(symbol):
                 continue
             references.append(symbol)
 
     return references
 
 
 def get_symbols_in_line(line):
     """Return mentioned Kconfig symbols in @line."""
     return REGEX_SYMBOL.findall(line)
 
 
 def parse_kconfig_files(args):
     """Parse kconfig files and return tuple of defined and references Kconfig
     symbols.  Note, @args is a tuple of a list of files and the @ignore
     pattern."""
     kconfig_files = args[0]
     ignore = args[1]
     defined_symbols = []
     referenced_symbols = dict()
 
     for kfile in kconfig_files:
         defined, references = parse_kconfig_file(kfile)
         defined_symbols.extend(defined)
         if ignore and re.match(ignore, kfile):
             # do not collect references for files that match the ignore pattern
             continue
         referenced_symbols[kfile] = references
     return (defined_symbols, referenced_symbols)
 
 
 def parse_kconfig_file(kfile):
     """Parse @kfile and update symbol definitions and references."""
     lines = []
     defined = []
     references = []
     skip = False
 
     if not os.path.exists(kfile):
         return defined, references
 
     with open(kfile, "r", encoding='utf-8', errors='replace') as stream:
         lines = stream.readlines()
 
     for i in range(len(lines)):
         line = lines[i]
         line = line.strip('\n')
         line = line.split("#")[0]  # ignore comments
 
         if REGEX_KCONFIG_DEF.match(line):
             symbol_def = REGEX_KCONFIG_DEF.findall(line)
             defined.append(symbol_def[0])
             skip = False
         elif REGEX_KCONFIG_HELP.match(line):
             skip = True
         elif skip:
             # ignore content of help messages
             pass
         elif REGEX_KCONFIG_STMT.match(line):
             line = REGEX_QUOTES.sub("", line)
             symbols = get_symbols_in_line(line)
             # multi-line statements
             while line.endswith("\\"):
                 i += 1
                 line = lines[i]
                 line = line.strip('\n')
                 symbols.extend(get_symbols_in_line(line))
             for symbol in set(symbols):
                 if REGEX_NUMERIC.match(symbol):
                     # ignore numeric values
                     continue
                 references.append(symbol)
 
     return defined, references
 
 
 if __name__ == "__main__":
     main()
diff --git a/tools/testing/selftests/firmware/Makefile b/tools/testing/selftests/firmware/Makefile
index 9bf82234855b..1894d625af2d 100644
--- a/tools/testing/selftests/firmware/Makefile
+++ b/tools/testing/selftests/firmware/Makefile
@@ -1,11 +1,11 @@
 # Makefile for firmware loading selftests
 
 # No binaries, but make sure arg-less "make" doesn't trigger "run_tests"
 all:
 
-TEST_PROGS := fw_filesystem.sh fw_userhelper.sh
+TEST_PROGS := fw_filesystem.sh fw_fallback.sh
 
 include ../lib.mk
 
 # Nothing to clean up.
 clean:
diff --git a/tools/testing/selftests/firmware/fw_fallback.sh b/tools/testing/selftests/firmware/fw_fallback.sh
new file mode 100755
index 000000000000..2e4c22d5abf7
--- /dev/null
+++ b/tools/testing/selftests/firmware/fw_fallback.sh
@@ -0,0 +1,224 @@
+#!/bin/sh
+# This validates that the kernel will fall back to using the fallback mechanism
+# to load firmware it can't find on disk itself. We must request a firmware
+# that the kernel won't find, and any installed helper (e.g. udev) also
+# won't find so that we can do the load ourself manually.
+set -e
+
+modprobe test_firmware
+
+DIR=/sys/devices/virtual/misc/test_firmware
+
+# CONFIG_FW_LOADER_USER_HELPER has a sysfs class under /sys/class/firmware/
+# These days no one enables CONFIG_FW_LOADER_USER_HELPER so check for that
+# as an indicator for CONFIG_FW_LOADER_USER_HELPER.
+HAS_FW_LOADER_USER_HELPER=$(if [ -d /sys/class/firmware/ ]; then echo yes; else echo no; fi)
+
+if [ "$HAS_FW_LOADER_USER_HELPER" = "yes" ]; then
+       OLD_TIMEOUT=$(cat /sys/class/firmware/timeout)
+else
+	echo "usermode helper disabled so ignoring test"
+	exit 0
+fi
+
+FWPATH=$(mktemp -d)
+FW="$FWPATH/test-firmware.bin"
+
+test_finish()
+{
+	echo "$OLD_TIMEOUT" >/sys/class/firmware/timeout
+	rm -f "$FW"
+	rmdir "$FWPATH"
+}
+
+load_fw()
+{
+	local name="$1"
+	local file="$2"
+
+	# This will block until our load (below) has finished.
+	echo -n "$name" >"$DIR"/trigger_request &
+
+	# Give kernel a chance to react.
+	local timeout=10
+	while [ ! -e "$DIR"/"$name"/loading ]; do
+		sleep 0.1
+		timeout=$(( $timeout - 1 ))
+		if [ "$timeout" -eq 0 ]; then
+			echo "$0: firmware interface never appeared" >&2
+			exit 1
+		fi
+	done
+
+	echo 1 >"$DIR"/"$name"/loading
+	cat "$file" >"$DIR"/"$name"/data
+	echo 0 >"$DIR"/"$name"/loading
+
+	# Wait for request to finish.
+	wait
+}
+
+load_fw_cancel()
+{
+	local name="$1"
+	local file="$2"
+
+	# This will block until our load (below) has finished.
+	echo -n "$name" >"$DIR"/trigger_request 2>/dev/null &
+
+	# Give kernel a chance to react.
+	local timeout=10
+	while [ ! -e "$DIR"/"$name"/loading ]; do
+		sleep 0.1
+		timeout=$(( $timeout - 1 ))
+		if [ "$timeout" -eq 0 ]; then
+			echo "$0: firmware interface never appeared" >&2
+			exit 1
+		fi
+	done
+
+	echo -1 >"$DIR"/"$name"/loading
+
+	# Wait for request to finish.
+	wait
+}
+
+load_fw_custom()
+{
+	local name="$1"
+	local file="$2"
+
+	echo -n "$name" >"$DIR"/trigger_custom_fallback 2>/dev/null &
+
+	# Give kernel a chance to react.
+	local timeout=10
+	while [ ! -e "$DIR"/"$name"/loading ]; do
+		sleep 0.1
+		timeout=$(( $timeout - 1 ))
+		if [ "$timeout" -eq 0 ]; then
+			echo "$0: firmware interface never appeared" >&2
+			exit 1
+		fi
+	done
+
+	echo 1 >"$DIR"/"$name"/loading
+	cat "$file" >"$DIR"/"$name"/data
+	echo 0 >"$DIR"/"$name"/loading
+
+	# Wait for request to finish.
+	wait
+}
+
+
+load_fw_custom_cancel()
+{
+	local name="$1"
+	local file="$2"
+
+	echo -n "$name" >"$DIR"/trigger_custom_fallback 2>/dev/null &
+
+	# Give kernel a chance to react.
+	local timeout=10
+	while [ ! -e "$DIR"/"$name"/loading ]; do
+		sleep 0.1
+		timeout=$(( $timeout - 1 ))
+		if [ "$timeout" -eq 0 ]; then
+			echo "$0: firmware interface never appeared" >&2
+			exit 1
+		fi
+	done
+
+	echo -1 >"$DIR"/"$name"/loading
+
+	# Wait for request to finish.
+	wait
+}
+
+
+trap "test_finish" EXIT
+
+# This is an unlikely real-world firmware content. :)
+echo "ABCD0123" >"$FW"
+NAME=$(basename "$FW")
+
+DEVPATH="$DIR"/"nope-$NAME"/loading
+
+# Test failure when doing nothing (timeout works).
+echo -n 2 >/sys/class/firmware/timeout
+echo -n "nope-$NAME" >"$DIR"/trigger_request 2>/dev/null &
+
+# Give the kernel some time to load the loading file, must be less
+# than the timeout above.
+sleep 1
+if [ ! -f $DEVPATH ]; then
+	echo "$0: fallback mechanism immediately cancelled"
+	echo ""
+	echo "The file never appeared: $DEVPATH"
+	echo ""
+	echo "This might be a distribution udev rule setup by your distribution"
+	echo "to immediately cancel all fallback requests, this must be"
+	echo "removed before running these tests. To confirm look for"
+	echo "a firmware rule like /lib/udev/rules.d/50-firmware.rules"
+	echo "and see if you have something like this:"
+	echo ""
+	echo "SUBSYSTEM==\"firmware\", ACTION==\"add\", ATTR{loading}=\"-1\""
+	echo ""
+	echo "If you do remove this file or comment out this line before"
+	echo "proceeding with these tests."
+	exit 1
+fi
+
+if diff -q "$FW" /dev/test_firmware >/dev/null ; then
+	echo "$0: firmware was not expected to match" >&2
+	exit 1
+else
+	echo "$0: timeout works"
+fi
+
+# Put timeout high enough for us to do work but not so long that failures
+# slow down this test too much.
+echo 4 >/sys/class/firmware/timeout
+
+# Load this script instead of the desired firmware.
+load_fw "$NAME" "$0"
+if diff -q "$FW" /dev/test_firmware >/dev/null ; then
+	echo "$0: firmware was not expected to match" >&2
+	exit 1
+else
+	echo "$0: firmware comparison works"
+fi
+
+# Do a proper load, which should work correctly.
+load_fw "$NAME" "$FW"
+if ! diff -q "$FW" /dev/test_firmware >/dev/null ; then
+	echo "$0: firmware was not loaded" >&2
+	exit 1
+else
+	echo "$0: fallback mechanism works"
+fi
+
+load_fw_cancel "nope-$NAME" "$FW"
+if diff -q "$FW" /dev/test_firmware >/dev/null ; then
+	echo "$0: firmware was expected to be cancelled" >&2
+	exit 1
+else
+	echo "$0: cancelling fallback mechanism works"
+fi
+
+load_fw_custom "$NAME" "$FW"
+if ! diff -q "$FW" /dev/test_firmware >/dev/null ; then
+	echo "$0: firmware was not loaded" >&2
+	exit 1
+else
+	echo "$0: custom fallback loading mechanism works"
+fi
+
+load_fw_custom_cancel "nope-$NAME" "$FW"
+if diff -q "$FW" /dev/test_firmware >/dev/null ; then
+	echo "$0: firmware was expected to be cancelled" >&2
+	exit 1
+else
+	echo "$0: cancelling custom fallback mechanism works"
+fi
+
+exit 0
diff --git a/tools/testing/selftests/firmware/fw_userhelper.sh b/tools/testing/selftests/firmware/fw_userhelper.sh
deleted file mode 100755
index b9983f8e09f6..000000000000
--- a/tools/testing/selftests/firmware/fw_userhelper.sh
+++ /dev/null
@@ -1,99 +0,0 @@
-#!/bin/sh
-# This validates that the kernel will fall back to using the user helper
-# to load firmware it can't find on disk itself. We must request a firmware
-# that the kernel won't find, and any installed helper (e.g. udev) also
-# won't find so that we can do the load ourself manually.
-set -e
-
-modprobe test_firmware
-
-DIR=/sys/devices/virtual/misc/test_firmware
-
-# CONFIG_FW_LOADER_USER_HELPER has a sysfs class under /sys/class/firmware/
-# These days no one enables CONFIG_FW_LOADER_USER_HELPER so check for that
-# as an indicator for CONFIG_FW_LOADER_USER_HELPER.
-HAS_FW_LOADER_USER_HELPER=$(if [ -d /sys/class/firmware/ ]; then echo yes; else echo no; fi)
-
-if [ "$HAS_FW_LOADER_USER_HELPER" = "yes" ]; then
-       OLD_TIMEOUT=$(cat /sys/class/firmware/timeout)
-else
-	echo "usermode helper disabled so ignoring test"
-	exit 0
-fi
-
-FWPATH=$(mktemp -d)
-FW="$FWPATH/test-firmware.bin"
-
-test_finish()
-{
-	echo "$OLD_TIMEOUT" >/sys/class/firmware/timeout
-	rm -f "$FW"
-	rmdir "$FWPATH"
-}
-
-load_fw()
-{
-	local name="$1"
-	local file="$2"
-
-	# This will block until our load (below) has finished.
-	echo -n "$name" >"$DIR"/trigger_request &
-
-	# Give kernel a chance to react.
-	local timeout=10
-	while [ ! -e "$DIR"/"$name"/loading ]; do
-		sleep 0.1
-		timeout=$(( $timeout - 1 ))
-		if [ "$timeout" -eq 0 ]; then
-			echo "$0: firmware interface never appeared" >&2
-			exit 1
-		fi
-	done
-
-	echo 1 >"$DIR"/"$name"/loading
-	cat "$file" >"$DIR"/"$name"/data
-	echo 0 >"$DIR"/"$name"/loading
-
-	# Wait for request to finish.
-	wait
-}
-
-trap "test_finish" EXIT
-
-# This is an unlikely real-world firmware content. :)
-echo "ABCD0123" >"$FW"
-NAME=$(basename "$FW")
-
-# Test failure when doing nothing (timeout works).
-echo 1 >/sys/class/firmware/timeout
-echo -n "$NAME" >"$DIR"/trigger_request
-if diff -q "$FW" /dev/test_firmware >/dev/null ; then
-	echo "$0: firmware was not expected to match" >&2
-	exit 1
-else
-	echo "$0: timeout works"
-fi
-
-# Put timeout high enough for us to do work but not so long that failures
-# slow down this test too much.
-echo 4 >/sys/class/firmware/timeout
-
-# Load this script instead of the desired firmware.
-load_fw "$NAME" "$0"
-if diff -q "$FW" /dev/test_firmware >/dev/null ; then
-	echo "$0: firmware was not expected to match" >&2
-	exit 1
-else
-	echo "$0: firmware comparison works"
-fi
-
-# Do a proper load, which should work correctly.
-load_fw "$NAME" "$FW"
-if ! diff -q "$FW" /dev/test_firmware >/dev/null ; then
-	echo "$0: firmware was not loaded" >&2
-	exit 1
-else
-	echo "$0: user helper firmware loading works"
-fi
-
-exit 0
